Rethinking Neural Networks With Benford’s Law
SuryaKantSahu,1 AbhinavJava,21 ArshadShaikh1 andYannicKilcher3
1TheLearningMachines
2DelhiTechnologicalUniversity
3ETHZu¨rich
surya.oju@pm.me,java.abhinav99@gmail.com
Abstract Throughthiswork,wehopetobringattentiontotheMa-
chineLearningcommunitythatBLcanhavepotentialappli-
Benford’sLaw(BL)ortheSignificantDigitLawdefinesthe cations in training and evaluation of Neural Networks. We
probabilitydistributionofthefirstdigitofnumericalvalues summarizeourcontributionsasfollows:
inadatasample.ThisLawisobservedinmanynaturallyoc-
curring datasets. It can be seen as a measure of naturalness • We show with strong empirical evidence that a metric
ofagivendistributionandfindsitsapplicationinareaslike that we propose based on BL contains non-trivial infor-
anomaly and fraud detection. In this work, we address the mationaboutanNN’sgeneralizationtounseendata.
followingquestion:IsthedistributionoftheNeuralNetwork
• Wepresentadirectapplicationofthisresult,byreplacing
parametersrelatedtothenetwork’sgeneralizationcapability?
Validationmetricsforearlystopping,andhenceremov-
Tothatend,wefirstdefineametric,MLH(ModelEnthalpy),
ingtheneedofavalidationset.
thatmeasurestheclosenessofasetofnumberstoBenford’s
Lawandweshowempiricallythatitisastrongpredictorof • WeconnectourresultstotheFreeEnergyPrinciple(Gao
ValidationAccuracy.Second,weuseMLHasanalternative and Chaudhari 2020), (Alemi and Fischer 2018) and
toValidationAccuracyforEarlyStopping,removingtheneed
(Friston 2010) and attempt to explain why BL contains
for a Validation set. We provide experimental evidence that
informationaboutanNN’sgeneralization.
eveniftheoptimalsizeofthevalidationsetisknownbefore-
hand,thepeaktestaccuracyattainedislowerthannotusing • Andhencedefineacheap-to-computeInformationCrite-
avalidationsetatall.Finally,weinvestigatetheconnection rionforagivennetwork.
of BL to Free Energy Principle and First Law of Thermo-
dynamics,showingthatMLHisacomponentoftheinternal Preliminaries
energyofthelearningsystemandoptimizationasananalogy
tominimizingthetotalenergytoattainequilibrium. ThermodynamicsofMachineLearning
Previous work has established the formal connection of
Thermodynamicsandmachinelearning.(AlemiandFischer
Introduction
2018) define four information-theoretic functionals, out of
Benford’s Law (BL) has been observed in many naturally which,wefocusonRelativeEntropyS.Itmeasurestheen-
occurring populations, including the physical constants, tropybetweenthedistributionp(θ|X,Y)thatisassignedaf-
populations of countries, areas of lakes, stock market in- tertrainingondata(X,Y)priorq(θ)formodelparameters
dices, tax accounts, etc. (Shao and Ma 2010). Researchers θ.S canmeasuretheriskofoverfittingtheparameters.
havealsodiscoveredthepresenceofthislawinnaturalsci-
p(θ|X,Y)
ences (Sambridge, Tkalcˇic´, and Jackson 2010), image gra- S ≡log (1)
dientmagnitude(Jolion2001),syntheticandnaturalimages q(θ)
(Acebo and Sbert 2005), etc. Attempts have been made to
Astheauthorsclaim,thismeasureisintractable.
explain the underlying reason for BL’s emergence for spe-
cificdomains.However,auniversallyacceptedexplanation
Free-EnergyPrincipleandInformationCriteria
doesnotyetexist.
The fact that BL occurs in many naturally occurring Free-Energy Principle (Friston 2010) is a well-known
datasets,andthesampleswhichdon’tnotobeyBLareprob- principlethattriestoexplainthemechanismoflearningand
ableanomalies,isoneofthereasonswhyBLisalsoknown behaviour in living beings (referred to as ”agents”). This
as”TheLawofAnomalousNumbers”.Duetothis,BLhas principlestatesthatagentstakeactionstosensoryinput,and
beenusedtoascertainfraudintaxingandaccountingandin itsowninternalstatethroughaninternalmodeloftheworld.
machinelearningliteratureforAnomalyDetection,suchas This model is updated based on the outcome of the action.
detectingGAN-generatedimages(Bonettinietal.2020). Thelearningobjective,accordingtotheFree-EnergyPrinci-
ple,istominimize”surprise”inadditiontominimizingthe
Preprint. complexityofthelearnedmodel.
1202
tcO
22
]GL.sc[
4v31330.2012:viXra
Figure1:MLHforTrainedandRandomly-InitializedModels.Regardlessofinitialization,theMLHoftrainedmodelsremains
high.
ThisstatementcaneasilybeappliedtoMachineLearning
and Bayesian Inference; the minimization objective is then
givenas:
argminJ(θ)=E [L(x;θ)]+D(θ) (2)
x∈X
θ
whereJ(θ)istheenergythatistobeminimized,thefirst
termmeasurestheerrorforadatasetX,andthesecondterm
measuresthecomplexityofthemodelwithparametersθ.
Simply put, the learned model must have low prediction
errorwhilealsonotbeingcomplex.Notethatthisstatement
alsorelatestoOccam’sRazorandInformation-basedCrite-
riainMLliterature.
Information-based Criteria are used frequently for
model selection in the ML Community. Bayesian Informa-
tionCriterion(BIC)andAkaikeInformationCriteria(AIC)
(BurnhamandAnderson2003)aresomeofthewidely-used
Figure 2: ResNet152; Trained and Random Weights’ Sig-
criteriaformodelselection.
nificantDigitDistributionv/s.Benford’sLaw.Notethatthe
AIC(m)=−2logL(m)+2p(m) (3) trainedmodelfollowsBLmoreclosely.
BIC(m)=−2logL(m)+2p(m)logn (4)
wheremisamodel,L(m)istheerrorofthemodelm,p(m) the similarity of histograms of significant digits of model
is the number of parameters of m, and n is the number of parameters.WedefineasimplemetricMLH,thatmeasures
data-pointsusedtolearnm. thecorrelationbetweenBenford’sLawandhistogramofsig-
ItcanbeclearlyseenthatAICandBICarespecialcases nificantdigitsofagivenset.
of2,wherenumberofparametersisusedasthemeasurefor MLH is based on the Pearson’s Correlation Coefficient
modelcomplexityD.
(Pearson1895)isdefinedasfollows:
NeuralNetsandBenford’sLaw MLH(θ)=PearsonR(BinCount(θ),P ) (6)
B
BLdefinesaprobabilitydistributionofagivensample’ssig-
nificant(leftmost)digit.Theleftmostnon-zerodigit’soccur- [f ,f ,...,f ]
BinCount(θ)= 0 1 9 (7)
renceintheobservationsofapopulationislog-uniformfor D
θ
several datasets, with 1 occurring the maximum number of
times,followedby2,3,till9.AccordingtoBenford’sLaw Here,BinCount(θ)isthedistributionofSignificantDigits
(BL)(Benford1938),theprobabilityforasamplehavinga ofnetworkparametersetθ.P B isthedistributiondefinedby
significantdigitdisgivenasfollows: BL,f k isisthefrequencyofsignificantdigitkoccurringin
θ,D isthedimensionalityofθ.
θ
1
P =P(d)=log (d+ ),d=1,2,3,...,9 (5) We did not include parameters that are initialized with a
B 10 d constantvalue,suchasBiasandBatchNormparameters.In
AsitisknownthatRGBimages’pixelvaluesfollowBL, ourimplementation,wemultiplyallelementsinthesetbya
wehypothesizethatNeuralNetworkweightsmightalsofol- constant1010 sothattheresultantelementsaregreaterthan
low BL, for which, we devise a simple metric to measure zero, and then take the first non-zero digit. This represen-
tation is required for a fast vectorized1 implementation of Method/Metric Spearman’sR
BinCount(.).Notethatmultiplyingwithaconstantscalar A 0.214
doesn’t change the distribution of significant digits due to MLH 0.583
BL’spropertyofScaleInvariance(Hill1995b). -1*EICw/oScaling 0.292
This formulation of MLH allows simple implementation -1*EICw/Scaling 0.654
andinterpretationofthevalues:ThehighertheMLHvalue, -1*EIC-SR 0.679
thehighertheparameters’matchwithBL2. GPR(A) 0.418
In Fig.2, we compare the Mantissa Distribution of a GPR(MLH) 0.627
ResNet152trainedonImageNetandarandomlyinitialized GPR(MLH,A) 0.774
ResNet152 (Xavier Normal; Bias and BatchNorm are ini-
tializedwithaconstant).WeseethatbothcloselyfollowBL Table 1: Correlation between proposed metrics and
(>0.99Pearson’sR). Validation Accuracy. A is the Training accuracy.
GPR(x ,x ,x ,...) refer to GaussianProcessRegres-
1 2 3
EffectofInitializationonMLH sorfittedwithx ,x ,x ,...asinputfeatures.Itcanbeseen
1 2 3
that Min-max scaling drastically increases correlation for
ThisresultpointstothepossibilitythatthewayNeuralNet-
EIC,andimprovesbeyondthecorrelationofMLHonly.
work weights (Xavier Normal) are initialized follow BL
closelyattheinitialization,andaftertraining,thecloseness
increasesevenfurther.
inRGB4 Datasets(CIFAR,StanfordDogs,OxfordFlowers
In the this section, we present results on initializing net-
etc.) to be 0.974, while the minimum and maximum were
works with various methods, and show that they achieve
0.9462and0.9999respectively.Wemin-maxscaleMLHto
highMLHattheendoftrainingregardlessofhowthenet-
bringittotherange[0,1].
workwasinitialized.ToshowthataNeuralNet’smatchwith
BLisnotjustduetothevirtueoftheinitializationmethod. MLH −0.9462
EIC (θ)=−A − θ (9)
In Fig. 1, we show results of an experiment where we re- scaled θ 0.0537
peatedlytrain20ShallowAlexnet-likenetworkseachonCI-
EIC is related to other information criteria such as
FAR10foreachinitializationmethod,includinginitializing
Bayesian Information Criteria (BIC) (Schwarz 1978) or
sub-optimally; we show that the MLH after training is al-
AkaikeInformationCriteria(AIC)(Akaike1998).However,
wayshighregardlessoftheinitialMLH3
BIC and AIC both use the number of parameters of the
IntheAppendixweexplorehowMLHvariesthroughout
modelasameasureofmodelcomplexity;unlikeEIC,which
thedepthofpretrainedTransformersandImageNetmodels,
computes a statistic based on the values of the parameters,
andapeculiarpatternisobserved;attempttofindtheeffect
hencemodelcomplexitycandifferforthesamemodelwith
oftrainingdataonMLHforvariousarchitectures(LSTMs,
differentparametervalues.
CNNs,MLPsetc.).
WeshowinthefollowingsectionsthatthepropertyofS
tomeasuretheriskofoverfitting,isdemonstratedbyMLH
EnthalpyInformationCriterion(EIC)
andconsequentlybyEIC.
We can think of BL as a prior over significant digits of
MLHandValidationAccuracy
parameters θ. The choice of BL as a prior is substanti-
ated by the fact that MLH is not an artifact of initializa- For deep learning projects, researchers and practitioners
tionandthereforepossiblycontainsnon-trivialinformation splittheavailabledataintoatleastthreesets:Training,Val-
about a neural network’s initialization. In Eq. 1, S mea- idation,andTest.
sures the entropy between the distribution over parameters Practitionersusethevalidationsetmetricsformanypur-
and the prior, however MLH measures distribution of sig- poses,onesuchusecaseisdecidingwhentostopthetrain-
nificantdigits’closenesstoBL.Ifweassumethattheprior ingi.e.detectoverfittingandstoppingthetrainingbeforethe
distributionq(θ)tobeapproximatedbyBenford’sLaw;p(θ) modeloverfitstothetrainset.ThisisknownasEarlyStop-
by Bincount(θ), we can see that S is approximated by ping.EarlyStoppingrequiresacriterionthatcandetermine
MLH(θ). Estimating prior distribution q(θ) over the pa- thedegreeofoverfitting,usuallygivenbythevalidationset
rametersetwouldotherwisebeatediousexercise. accuracy(asaproxyforgeneralizationtounseendata).
We now define a novel Information Criterion based on Inthissection,weexplorewhetherclosenesstoBLisre-
MLH: latedtovalidationaccuracy.Tothisend,wetrain100shal-
EIC(θ)=−A −MLH (8) low AlexNet-like models without dropout on the CIFAR10
θ θ
dataset,manuallysplitintotrain(90%)andvalidation(10%)
It can be observed that in Fig. 2, even the randomly ini- sets;andcollectMLH,validationandtrainaccuracyoverthe
tializednetworkhasMLHvalueover0.99.Inexperiments, courseoftraining.
we found that the mean MLH of all runs across all steps InFig.3,werandomlyselectafewtrainingrunsandplot
their metrics. We observe that MLH and validation accu-
1Codeisprovidedintheappendix
racy follow a similar trajectory. We make this observation
2SubstitutingwithJS-Divergenceyieldsmirroredcurves.
3DefaultPyTorchvalueswereusedforInitialization. 4MLHislowerforMNISTandFMNIST.
Figure3:AlexNet-likemodelswithoutdropouttrainedonCIFAR10.(LefttoRight)Trainingaccuracy,validationaccuracyand
MLHagainsttrainingiterations.Ataround1Kiterations,thevalidationaccuracydrops,whilethetrainingaccuracyreaches1.
ItcanbeclearlyobservedthattheproposedmetricMLHfollowsasimilartrajectorytothevalidationaccuracy.
concrete by computing Spearman’s correlation coefficient Stopping Validation
Mean(TA) Std(TA)
(spe2008)betweenvariousmetricsandvalidationaccuracy. Criterion Proportion
Spearman’sCorrelationCoefficientmeasuresthemonotonic MLH 0 58.968 1.51
relationshipbetweentworandomsamples. 0.0001 53.948 3.48
In Table 1, we observe a strong correlation5 between 0.0004 56.177 2.78
MLHandvalidationaccuracy.Thecorrelationisevenhigher 0.0016 57.407 2.12
if we define a quantity that simply sums training accuracy Validation 0.0251 58.039 1.80
andmin-maxscaledMLH.ThisresultshowsthatMLHand Accuracy 0.1 57.903 2.10
training accuracy could be used to estimate validation ac- 0.2 57.575 1.58
curacy. In section , we present the motivation behind using 0.3 56.371 1.96
both MLH and training accuracy for estimating validation 0.4 55.538 1.75
accuracy.
We also fit Gaussian Process Regression (GPR) models
Table2:MeanandStandarddeviationofTestAccuracy(TA)
fromscikit-learn(Pedregosaetal.2011)onthemetricscol-
for100trainingrunswithvariousvalidationproportions.
lectedsothatitlearnsafunctionmappingfromeithertrain-
ingaccuracyorMLHorbothtovalidationaccuracy.Weob-
serve that the GPR which uses both training accuracy and
finedconditioninvolvingthecriterionismet,thetrainingis
MLH has the highest correlation with validation accuracy,
stopped. Usually, the criterion used is the accuracy on the
strongly indicating that MLH contains non-trivial informa-
validationset.
tionaboutthenetwork’sgeneralizationperformance.
If the data splits are not predefined, as they are in many
Similarly, we also run Symbolic Regression using gp-
competitions,thepractitionerhastodecideonthesizeofthe
learntolearnamappingfromTrainingAccuracyandMLH
splits.EarlyStoppingbasedonvalidationsetcriteriarequire
to Validation Accuracy. We obtain a simple program that
avalidationsettobesplitofffromthetrainingdata,which,
doesn’trequiremin-maxscalingwhileachievinghighercor-
dependingonthesize,resultsinasignificantreductioninthe
relationthanEq.9.
amountofavailabletrainingdata.Thesizeofthevalidation
logMLH(θ) set can also be seen as a hyperparameter. Larger validation
EIC sr (θ)=− A(θ) (10) sets can result in poorer models due to lower amounts of
trainingdata.Ontheotherhand,smallervalidationsetscan
EarlyStoppingwithMLH resultininaccurateestimatesofgeneralizationperformance,
andthecriteriabeingunreliable,leadingtoprematureorlate
In this section, we present a direct application of MLH. In
stopping.Theoptimalsizeofthevalidationsetfindsthebest
the previous section, we established that MLH is strongly
trade-off,asobservedinFig.4.Butfindingthisoptimalsize
correlated to validation accuracy. We use this result to re-
ofthevalidationsetisnon-trivialandrequiresmultipletrain-
placevalidationset-basedcriteriaforEarlyStopping,while
ingruns.
usingthedatasavedasadditionaltrainingdata.
Fortheexperimentsinthissection,weusetheCIFAR10
In Early Stopping, the stopping criterion is monitored
dataset, and a smaller AlexNet-like model without dropout
throughout the training procedure, and if a certain prede-
tomakesurethemodelsoverfitandhencemakeourobserva-
5p-valuesareomittedbecausetheirvalueswereextremelylow tionsconcrete.Wedoasweepofvariousvalidationsetsizes
(orderof10−12). and use Validation Accuracy as the Early Stopping metric.
Figure4:(Red)TestaccuracyofmodelstrainedusingMLHasearlystopping.(Blue)Testaccuracyofvalidationproportions
usedtodictateearlystopping.ComplementsTable2.
For each setting, we train 100 such models for computing DeepLearning GasChamber
confidence intervals. Fig. 4 (Blue) illustrates the validation
Weights EnergyStates
setsizetrade-off.
SynapticConnections GasParticles
For one set of models, Fig. 4 (Red), we use MLH as
SGDSteps ReciprocalofTemperature
theEarlyStoppingcriterion,andincludevalidationdatafor
TrainAccuracy HeatGiven
training.Fig.4showsthatevenifthepractitionerknowsthe
MLHofWeights HeatReleased
optimal validation set size beforehand, the mean test accu-
TrainAccuracy+
racyissignificantlylowerthanwhennotusingavalidation InternalEnergy
MLH
setatall.
MLHandThermodynamics Table3:AnalogiesbetweenDeepLearningandThermody-
namics
Intheprevioussections,weusedshallowAlexnet-Likenet-
worksthatwerepronetooverfitting.Recentworkhasshown
that larger and deeper neural network architectures are ro-
Here,kistheBoltzmannConstant.WecomputeMLHof
busttooverfitting(Zhangetal.2017).
energies at 1/kT = 0.1 to 1/kT = 10 at 10000 equally-
As observed in Fig. 5 (Bottom), when we swap out the
spaced values. Fig. 5 (Top) shows how MLH changes as a
smallerAlexNet-likemodelwithalargerDenseNet-121,we
function of temperature T which strikingly resembles Fig.
observe that the model never clearly overfits. As a result,
5 (Bottom), where we plot 6 models trained on 6 different
MLH oscillates periodically; we note this observation on
datasets,andcomputeMLHoftheirweights6.
multipledatasets.
Weusethisobservationtopresentinformalevidencethat Furthermore,thismotivatesustothinkaboutTemperature
trainingNNscanbethoughtofasathermodynamicprocess. as an analogous to Gradient Descent iterations, and value
WeconnectthisoscillatorypatternofMLHtoacontribution of the weights analogous to the Energy states. In Table 3,
by(ShaoandMa2010)wheretheyfindthatforsystemsfol- welistdowntheanalogiesdrawnbetweenThermodynamics
lowingBoltzmann-Gibbsstatistics,suchasanidealgasina andDeepLearning.WecanthinkofMLHofweightsasthe
sealedchamber,theirmantissadistributionofenergystates measureofstability,i.e.higherMLHmeansthedistribution
of particles oscillates around BL with change in tempera- ofweightsismorenatural.
ture.ThisisillustratedbyFig.5(Top).Here,werunasimu- Throughout this work, we assumed that MLH is a mea-
lationwherewesamplealargenumberofEnergystatesata sure of model complexity, however, explaining why MLH
Temperature T with the probability density function for an contains this information would possibly also require us to
energystateE from(ShaoandMa2010), answerwhyBLevenemergesinthefirstplace,whichhasre-
1
f(E)= e− k E T (11) 6Additionaldetailsareprovidedintheappendix
kT
Figure5:Left:MLHofEnergystatesatdifferentvaluesofTemperatureT.Right:MLHofDenseNet121weightsonmultiple
datasets.
mained unexplained since the phenomenon was discovered Hill, T. P. 1995b. Base-invariance implies Benford’s law.
nearlytwocenturiesago. ProceedingsoftheAmericanMathematicalSociety,123(3):
887–895.
References Hochreiter,S.;andSchmidhuber,J.1997a. Longshort-term
memory. Neuralcomputation,9(8):1735–1780.
2008. Spearman Rank Correlation Coefficient, 502–505.
New York, NY: Springer New York. ISBN 978-0-387- Hochreiter, S.; and Schmidhuber, J. 1997b. Long Short-
32833-1. TermMemory. NeuralComputation,9(8):1735–1780.
Acebo,E.;andSbert,M.2005.Benford’slawfornaturaland Huang, G.; Liu, Z.; Van Der Maaten, L.; and Weinberger,
syntheticimages. InProceedingsoftheFirstEurographics K.Q.2017. Denselyconnectedconvolutionalnetworks. In
conferenceonComputationalAestheticsinGraphics,Visu- ProceedingsoftheIEEEconferenceoncomputervisionand
alizationandImaging,169–176. patternrecognition,4700–4708.
Jolion, J.-M. 2001. Images and Benford’s law. Journal of
Akaike, H. 1998. Information Theory and an Extension of
MathematicalImagingandVision,14(1):73–81.
the Maximum Likelihood Principle, 199–213. New York,
NY:SpringerNewYork. ISBN978-1-4612-1694-0. Kingma, D. P.; and Ba, J. 2014. Adam: A method for
stochasticoptimization. arXivpreprintarXiv:1412.6980.
Alemi, A. A.; and Fischer, I. 2018. TherML: Thermody-
namicsofMachineLearning. arXiv:1807.04162. Krizhevsky,A.;etal.2009. Learningmultiplelayersoffea-
turesfromtinyimages.
Benford, F. 1938. The Law of Anomalous Numbers. Pro-
LeCun, Y.; Bottou, L.; Bengio, Y.; and Haffner, P. 1998.
ceedingsoftheAmericanPhilosophicalSociety,78(4):551–
Gradient-based learning applied to document recognition.
572.
ProceedingsoftheIEEE,86(11):2278–2324.
Bonettini,N.;Bestagini,P.;Milani,S.;andTubaro,S.2020.
LeCun, Y.; and Cortes, C. 2010. MNIST handwritten digit
On the use of Benford’s law to detect GAN-generated im-
database.
ages. arXivpreprintarXiv:2004.07682.
Pearson, K. 1895. VII. Note on regression and inheritance
Burnham, K.; and Anderson, D. R. 2003. Model selection
inthecaseoftwoparents. proceedingsoftheroyalsociety
andmultimodelinference:apracticalinformation-theoretic
ofLondon,58(347-352):240–242.
approach. JournalofWildlifeManagement,67:655.
Pedregosa, F.; Varoquaux, G.; Gramfort, A.; Michel, V.;
Falcon, W. 2019. PyTorch Lightning. GitHub. Note:
Thirion,B.;Grisel,O.;Blondel,M.;Prettenhofer,P.;Weiss,
https://github.com/PyTorchLightning/pytorch-lightning,3.
R.;Dubourg,V.;Vanderplas,J.;Passos,A.;Cournapeau,D.;
Friston,K.2010. Thefree-energyprinciple:aunifiedbrain Brucher, M.; Perrot, M.; and Duchesnay, E. 2011. Scikit-
theory? Naturereviewsneuroscience,11(2):127–138. learn: Machine Learning in Python. Journal of Machine
LearningResearch,12:2825–2830.
Gao, Y.; and Chaudhari, P. 2020. A Free-Energy Principle
for Representation Learning. In III, H. D.; and Singh, A., Sambridge, M.; Tkalcˇic´, H.; and Jackson, A. 2010. Ben-
eds., Proceedings of the 37th International Conference on ford’slawinthenaturalsciences. Geophysicalresearchlet-
MachineLearning,volume119ofProceedingsofMachine ters,37(22).
LearningResearch,3367–3376.PMLR. Schwarz, G. 1978. Estimating the Dimension of a Model.
Goodfellow, I. J.; Mirza, M.; Xiao, D.; Courville, A.; and TheAnnalsofStatistics,6(2):461–464.
Bengio,Y.2013. Anempiricalinvestigationofcatastrophic Shao, L.; and Ma, B.-Q. 2010. The significant digit law in
forgettingingradient-basedneuralnetworks. arXivpreprint statisticalphysics. PhysicaA:StatisticalMechanicsandits
arXiv:1312.6211. Applications,389:3109–3116.
Hill, T. P. 1995a. Base-Invariance Implies Benford’s Law. Xiao,H.;Rasul,K.;andVollgraf,R.2017. Fashion-mnist:
ProceedingsoftheAmericanMathematicalSociety,123(3): a novel image dataset for benchmarking machine learning
887–895. algorithms. arXivpreprintarXiv:1708.07747.
Zhang, C.; Bengio, S.; Hardt, M.; Recht, B.; and Vinyals, Dataset Architecture
O. 2017. Understanding deep learning requires rethinking MNIST LeNet
generalization. FashionMNIST LeNet
CIFAR10 DenseNet-121
Appendix SequentialMNIST LSTM
Synthetic-Uniform MLP
VariationofMLHacrossLayerDepth
Synthetic-Boolean MLP
In Fig. 6, we compute MLH for various pre-trained con- Oxford-Flowers DenseNet-121
volutional neural networks and Transformers and plot their Stanford-Dogs DenseNet-121
layer-wiseMLH.Weseethatgenerally,theMLHishighat Aircrafts DenseNet-121
the first layers, decreases gradually, but spikes again at the
lastlayer.AsimilartrendisobservedforLanguageModels Table 4: Model architectures used for training on corre-
(right). spondingdatasets.
EffectofDataonMLH
Parameter Value
ItiswellknownthatRGBImagesandtheirpixelvaluesfol-
LearningRate 3e-3
low Benford’s Law (Bonettini et al. 2020). We investigate
EarlyStoppingPatience 15
whether the data distribution affects the Network Weights,
ValidationFrequency 0.33
causingthemtomatchBenford’sLaw.
BatchSize 64
We investigate CIFAR10 (Krizhevsky et al. 2009),
MNIST (LeCun and Cortes 2010), FashionMNIST (Xiao,
Table5:Hyperparametersusedduringtraining
Rasul, and Vollgraf 2017), Sequential MNIST (SeqM-
NIST) (Goodfellow et al. 2013), two Synthetically Gener-
ated Datasets, and 100 Models trained7 on each of these
• LeNet (LeCun et al. 1998) architecture is a simple
datasets. We train a small LeNet-inspired network for
network with two(2) blocks of Strided Convolution-
MNIST and FashionMNIST, DenseNet121 for CIFAR10,
LeakyReLU Network followed by a fully-connected
LSTM(HochreiterandSchmidhuber1997a)forSeqMNIST,
classificationlayer.
andMLPforSyntheticDatasets.
For Synthetic-Boolean Dataset, We generate a random • DenseNet-121 (Huang et al. 2017) implementation is
boolean function taking the argmax over a randomly ini- borrowedfromthisGitHubrepository8.
tialized Network with 64 boolean input features. Since the • LSTMisasimple2-layeredRNNwithLong-ShortTerm
inputsareboolean,i.e.,Base2,Benford’sLawforBase2is Memory(HochreiterandSchmidhuber1997b)followed
1(Hill1995a). byafully-connectedlayerforclassification.
ForSynthetic-UniformDataset,wedothesameasabove,
• MLP is a 2 fully-connected network with Classifica-
buttheinputsaredrawnuniformlyfromtherange[0,1].
tion(Softmax)andRegression(Linear)outputlayersfor
SincetheScaleInvariancePropertyofBLholds,weonly
Synthetic-BooleanandSyntheticUniformDatasets.
divideby255forImageDatasetsanddonotnormalizethis
experiment’sfeatures.
Hyperparameters
AsObservedinFigure7,CIFAR10haspositiveMLH,and
Unless stated otherwise, all of the experiments use Py-
othershaveNegativeMLH,whereasallofthemodelsexcept
Torch’s implementation of Adam (Kingma and Ba 2014),
fortheonestrainedonSynthetic-Booleanhave>0.9median
and PyTorch Lightning’s (Falcon 2019) default values ex-
MLH.ModelstrainedonSynthetic-Booleanhavealowbut
ceptthefollowingwhereverapplicable.
positivemedianMLHofabout0.2.WebelievethatMLHof
thenetworkismorerelatedtofeaturevariancethanMLHof
DataSplits
theData.
Forthedatasetsotherthansyntheticallygenerated,wepro-
PreprocessingofData videtheTrain/Validation/Testsets.Allofthemarerandomly
Forallexperiments,weonlydividebythemaximummagni- splitunlessPyTorchhasTrain/Testsplits.
tudeacrossfeaturesratherthannormalizingthem.Thiswas
SyntheticDataGeneration
topreservetheScaleInvariancePropertyofBenford’sLaw.
Weusesyntheticdatasetfortrainingaregressionandaclas-
ModelArchitectures sificationmodel.Thesyntheticdataisgeneratedusingasin-
Forallexperimentsinthepaper,weusethefollowingarchi- gle layered neural network that is randomly initialized. We
tecturesandtheirrespectivedatasets. describe the process of the generation process below. Both
Thedetailsofthemodelsthathavebeenusedfortheex- thedatasetshaveaninputvectorlengthof64andthesein-
perimentsaregivenbelow: putvectorsarealsodrawnrandomlyfromUniform[0,1]and
7Experiments were conducted in an Ubuntu system, PyTorch 8https://github.com/kuangliu/pytorch-cifar/blob/master/
1.7,withasingleNVIDIARTX2060GPU,16GBofRAM models/densenet.py
Figure6:MLHacrossdifferentlayersofpretrainedmodels.
Figure7:MLHforDatasetsandNetworksTrainedonthem.
Dataset Train Validation Test Regressiondataset
MNIST 45000 5000 10000 x ∈ R64 isaninputvectorsampledfromUniform[0,1].
i
FashionMNIST 45000 5000 10000 Thetargetlabely ∈Risobtainedbyfeedingx asinputto
i i
CIFAR10 45000 5000 10000 arandomlyinitializedsinglelayeredlinearkernelwithone
SequentialMNIST 45000 5000 10000 outputunit,f .
θ
Synthetic-Boolean 6000 2000 2000
y =f (x ),x ∈Uniform[0,1] (12)
Synthetic-Uniform 6000 2000 2000 i θ i i
Oxford-Flowers 6149 2040 0 Classificationdataset
Stanford-Dogs 12000 8580 0
x ∈ R64 isaninputvectorsampledfromBernoulli[0,1].
Aircrafts 6667 3333 0 i
Thetargetlabely ∈Risobtainedbyfeedingx asinputto
i i
arandomlyinitializedsinglelayeredlinearkernelwithtwo
Table 6: Train, Validation and Test set splits for Datasets
outputunitsandargmax-edovertheoutputvector.
used.
y =argmax[f (x )],x ∈Bernoulli[0,1] (13)
i θ i i
PyTorchCodeforComputingMLH
BernoulliforSynthetic-UniformandSynthetic-Booleanre-
spectively. We generate 10000 pairs of input-output. These InthecodeprovidedinFig.8,thevectorbenfordisthedis-
aresplitintheratio60:20:20forTrain,ValidationandTest tribution defined by Benford’s Law, bin percent is a func-
setsrespectively. tionthattakesatensorasinputandreturnsthedistributionof
benford = np.array([30.1, 17.6, 12.5, 9.7,
7.9, 6.7, 5.8, 5.1, 4.6]
) / 100
def mlh(bin_percent):
return scipy.stats.pearsonr(
benford,
bin_percent[1:]
)[0]
def bincount(tensor):
counts = torch.zeros(10)
for i in range(10):
counts[i] = torch.count_nonzero(
tensor == i
)
return counts
@torch.no_grad()
def bin_percent(tensor):
tensor = tensor.abs() * 1e10
long_tensor = torch.log10(tensor).long()
tensor = tensor // 10 ** long_tensor
tensor = bincount(tensor.long())
return tensor / tensor.sum()
Figure8:PyTorchcodeforcomputingMLH
digitsinit.bincountisafunctionthattakesaflattenedten-
sor of integers ∈ [0,9] and returns a vector of frequencies.
MLHisthefunctiontocomputetheproposedMLHscore.