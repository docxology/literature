This is a portion of the eBook at doi:10.7551/mitpress/12441.001.0001
9
Model- Based Data Analy sis
Just because we have the best hammer does not mean that every probl em is a nail.
— Barack Obama
9.1 Introduction
Ultimately, the models described in this book are only useful if they can
answer scientific questions. In this chapter, we focus on the ways in which
Active Inference can be applied in understanding empirical data. The cen-
tral idea is that we, as scientists, can appeal to the same maths as we have
assumed the brain uses in previous chapters. Our general goal is to recover
the para meters of the generative model that a subject’s brain uses to pro-
duce be hav ior— the subjective model. For this, we can use our own genera-
tive model (of how the subjective model produces beh avi or)—t he objective
model. We can invert our objective model on the basis of the beh avi or we
observe to draw inferences about the para meters of the subjective genera-
tive model. This meta-B ayesian inference affords the opportunity to test
hypotheses about the model we assume the brain uses and to phenotype
individuals on the basis of the prior beliefs they would have to hold for
their beh avi or to be Bayes optimal. Belief-b ased computational phenotyp-
ing of this sort holds promise in the emerging fields of computational psy-
chiatry, neuropsychology, and neurology.
9.2 Meta- Bayesian Methods
This chapter deals with the utility of Active Inference formulations in analyz-
ing data from behavioral experiments. This goes beyond the proof-o f-p rinciple
Downloaded from http://direct.mit.edu/books/oa-monograph/chapter-pdf/2246588/c007400_9780262369978.pdf by guest on 12 December 2025
This is a portion of the eBook at doi:10.7551/mitpress/12441.001.0001
174 Chapter 9
simulations we have seen in previous chapters and instead exploits Active
Inference in answering scientific questions. We have seen already that a sub-
ject’s generative model is the key determinant of beh avi or u nder Active Infer-
ence. This implies that hypotheses about the c auses of empirical behavioral
meas urem ents must be framed in terms of the alternative generative models
used to select t hose actions. Our challenge, then, is to fit an Active Inference
scheme to observed data by manipulating the para meters (i.e., prior beliefs)
of the generative model.
Broadly speaking, t here are two (related) reasons for fitting a computa-
tional model to observed beh avi or. The first is to estimate par ameters of
interest from that model that best explain the be havi or of a specific subject
or group of subjects. This is useful in characterizing subjective beh avi or in
terms of the computations that generate it, a proc ess known as computa-
tional phenotyping (Montague et al. 2012, Schwartenbeck and Friston 2016,
Friston 2017). Computational phenotypes may be used in combination
with other meas ures (e.g., to establish links between neuroimaging find-
ings and function) or may be used alone in forecasting beh avi ors in other
settings (e.g., following a therapeutic intervention).
The second reason is to compare alternative hypotheses, expressed as
models, that represent diff ere nt explanations for a behavioral phenomenon
(Mirza et al. 2018). T hese two agendas—p arameter estimation and model
comparison—m ap to one side of Bayes’ theorem. Par ame t er estimation is
the proc ess of finding the posterior probability, under a model, of a par am-
et er setting. Model comparison rests on finding the marginal likelihoods
(i.e., evidence) for each model. To recap, Bayes’ theorem is
P(u|θ,m)P(θ|m)=P(θ|u,m)P(u|m).
!#"#$!#"#$ !#"#$!#"#$ (9.1)
Likelihood Prior Posterior Evidence
The right-h and side deals with the posterior probability of para meters (θ )
given behavioral data (u) u nder a model (m) and the model evidence, and
the left-h and side tells us what we need to specify for our model: we need
prior beliefs about our para meters of interest and a likelihood function.
Importantly, while we appeal to the same Bayesian inference scheme as
used in previous chapters, our purpose is diff ere nt h ere. This rests on the
fact that t here are two inference proc esses g oing on (figure 9.1). The first
is that creatures use their model of the proc esses generating their sensory
data to draw inferences about their world (and about how to act). This has
been the focus of the preceding chapters. The second is that we as objective
Downloaded from http://direct.mit.edu/books/oa-monograph/chapter-pdf/2246588/c007400_9780262369978.pdf by guest on 12 December 2025
This is a portion of the eBook at doi:10.7551/mitpress/12441.001.0001
Model- Based Data Analy sis 175
Θ P (θ | m)
θ Parameters
Experimental stimuli
õ
P(õ, s(cid:25), (cid:24) | θ, m)
G
(cid:24)
P(ũ | θ, õ, m)
Sτ-1 B Sτ B Sτ+1
A A A
Oτ-1 Oτ Oτ+1
Subjective model
ũ Observed behavior
Objective model
Figure 9.1
Relationship between the subjective and objective models of meta- Bayesian infer-
ence. Inner dashed box: Subjective model assumed to be used by an experimental
subject. This could be a POMDP model as illustrated or some other form of model.
The import ant features are that it depends on para meters (θ ) whose value we do not
know and that it generates sensory data (o). Outer dashed box: Experimenter’s objec-
tive model (m) includes prior beliefs about the para meters and predicts the beh av-
ior (u) we would expect on presenting experimental stimuli (sensory data from the
subjective model’s perspective). Crucially, the likelihood distribution of the objective
model depends on the subjective model. This means we evaluate the likelihood of
para meters taking a part icu l ar value as follows. First, we incorporate the para meters
in the subjective model. We then use the Active Inference schemes described in pre-
vious chapters to solve this model, presenting our experimental stimuli as sensory
data, and infer a distribution over the most probable course of action. Fin ally, we
evaluate the probability of the observed actions or choices, given this distribution.
This is the likelihood of observed be havi or given para meters and stimuli—i .e., the
likelihood distribution in the objective model.
Downloaded from http://direct.mit.edu/books/oa-monograph/chapter-pdf/2246588/c007400_9780262369978.pdf by guest on 12 December 2025
This is a portion of the eBook at doi:10.7551/mitpress/12441.001.0001
176 Chapter 9
scientists observe the creature’s beh avi or and seek to draw inferences about
the (subjective) generative model it is using by inverting our own (objective)
generative model. The implication h ere is that we are drawing inferences
about an inferential process—s ometimes referred to as “meta-B ayesian”
inference (Daunizeau et al. 2010).
More formally, this approach defines the likelihood distribution in terms
of the solution to an Active Inference probl em. By using a given par am-
et er setting, we can simulate beh avi or u nder Active Inference and quan-
tify the likelihood that a series of actions would have been taken. Equipped
with prior beliefs about the value of t hese para meters, we have a generative
model of how a creature uses its generative model to produce actions. While
our focus is on Active Inference (and discrete-t ime models specifically), the
generic methods used h ere may be used with any arbitrary likelihood func-
tion. Other normative models of beh avi or (such as t hose used in reinforce-
ment learning) may be substituted in place of the Active Inference models.
The following sections unpack an example of a generic inference scheme
that may be used for meta-B ayesian inference (namely, variational Laplace)
and the use of hierarchical models for model comparison. We then pro-
vide a s imple r ecipe for model-b ased data analys is and fin ally review a key
example of this procedure. It is impor tant to emphasize that understanding
the technical details is not required to use t hese methods effectively; thus,
readers uninterested in t hese details are invited to skip sections 9.3 and 9.4.
In brief, the basic idea is to evaluate the likelihood of any observed set
of choices, given the unknown para meters of interest—n amely, the par-
ameters of a subject’s prior beliefs. We then combine this likelihood with
our objective prior over t hose para meters to evaluate the posterior over the
subject’s priors, in the usual way. If we have several subjects, t hese poste-
riors can be combined to make inferences about group or between- subject
effects, using parametric empirical Bayes (PEB). The requisite likelihood is
simply the probability of sampling the observed sequence of choices, u nder
the subject’s posterior beliefs about action. T hese posterior beliefs depend
on what the subject sees (i.e., cues or stimuli) and her prior beliefs—a nd
are evaluated in a straightforward way by solving the appropriate Active
Inference scheme. Note that we are using Bayesian procedures twice: first
to evaluate the subject’s posterior beliefs about action, and second to evalu-
ate our posterior beliefs about the unknown priors that characterize the
subject. We now rehearse the vario us parts of this meta-B ayesian procedure.
Downloaded from http://direct.mit.edu/books/oa-monograph/chapter-pdf/2246588/c007400_9780262369978.pdf by guest on 12 December 2025
This is a portion of the eBook at doi:10.7551/mitpress/12441.001.0001
Model- Based Data Analy sis 177
9.3 Variational Laplace
Variational Laplace is an inference scheme based on the same princip les as
predictive coding (Friston, Mattout et al. 2007). However, it may be used for
more generic likelihood functions than those encountered earlier—w hich
were defined as Gaussian. We w ill start this section with an overview of the
likelihood function L(θ ) of interest here. This should give the probability of
actions for an Active Inference scheme with a generative model with par-
ameters set at value θ. The actions selected depend on the observations made:
L(θ)=lnP(u!|θ,m,o!)
P(u!|θ,m,o!)=u!iσ(θ
α
lnu!)
(9.2)
u! =πiU
π=argmin F
π
Unpacking this, the first term gives the log likelihood of an observed
sequence of actions (ũ) as a function of para meters (θ ), the model (m), and a
sequence of stimuli (õ) presented during a real experiment. The probability
of t hese actions is found by using the para meters to set the prior beliefs in
a POMDP model of the sort described in chapter 7. We can then solve the
POMDP as described in chapters 4 and 7, forcing the simulation to take
the observed action sequence and presenting it with the same experimental
stimuli. As we described in preceding chapters, this involves computing the
beliefs (π) a synthetic subject holds about the policy or course of action she
chooses to pursue. This minimizes the f ree energy (F ) associated with her
generative model of the world. We can then take t hese beliefs and calculate
the average probability of pursuing an action sequence. This requires us to
distribute the probability for each policy over the actions implied by that
policy (indexed by an array U ). Fin ally, a softmax temperature par ame t er
(θ ) is applied to account for randomness (shaky- handedness) in beh avi or not
α
accounted for by the model. If this softmax par ame t er is one, we are effec-
tively assuming that the subject samples her actions from posterior beliefs
about her actions; sometimes, this is called matching beh avi or. Alterna-
tively, if the softmax par ame t er is very large, the action emitted is the action
with the greatest subjective posterior—t hat is, the subject always chooses
the most likely option. This softmax par ame t er can itself be estimated.
The result is the probability of the actions u nder the model, given a
sequence of stimuli and para meters—t hat is, a likelihood of behavioral
Downloaded from http://direct.mit.edu/books/oa-monograph/chapter-pdf/2246588/c007400_9780262369978.pdf by guest on 12 December 2025
This is a portion of the eBook at doi:10.7551/mitpress/12441.001.0001
178 Chapter 9
data given a model. Equipping the objective par ameters with Gaussian pri-
ors1 (θ∼N(η,Π(1))), we can use the Laplace assumption to express a ( free
energy) approximation to model evidence:
lnP(u!|m,o!)≈L(µ)+
2
1( εiΠ(1)ε+ln ∇
µµ
L(µ)−Π(1) )
ε=η−µ (9.3)
µ=argmax { L(µ)−
2
1( εiΠ(1)ε+ln ∇
µµ
L(µ)−Π(1) )}
µ
Equation 9.3 is the same as that unpacked in box 4.3 (generalized to a
multidimensional pa ram e ter space), but here we have substituted an
explicit form for the posterior covariance and assumed a normally distrib-
uted prior. In chapter 4 and in the applications in chapter 8, we ignored
the terms in equation 9.3 that did not depend on the mode. However, it
is impor tant to include these here when we consider model comparison
probl ems.
To find the value of μ that maximizes the last line of equation 9.3, we
perform a gradient ascent. U nder quadratic assumptions, this reduces to
the following:
.
µ=∇ L(µ)+Π(1)ε (9.4)
µ
While an explicit form for the gradient of the log likelihood used h ere
may not be available, finite difference methods2 may be used to calculate
a reasonable numerical approximation. T hese may also be used to find the
posterior precision, which is the second derivative (or Hessian) of the nega-
tive log likelihood plus the prior precision. Equation 9.4 is the simplest
form of update, but often more sophisticated methods based on the local
curvature are used.
9.4 Parametric Empirical Bayes (PEB)
The variational Laplace procedure in the previous section lets us draw infer-
ences about, and quantify the evidence for a model of, choice be havi or.
This enables us to computationally phenotype an individual and to com-
pare alternative hypotheses about that individual. However, the int ere sti ng
questions often lie at a group level. For example, we might be interested in
how a parameter—s uch as the precision of prior preferences—v aries with
age. To answer this question, we can use the approach of section 9.3 to fit
Downloaded from http://direct.mit.edu/books/oa-monograph/chapter-pdf/2246588/c007400_9780262369978.pdf by guest on 12 December 2025
This is a portion of the eBook at doi:10.7551/mitpress/12441.001.0001
Model- Based Data Analy sis 179
models to the beh avi or of individual participants with a range of ages. We
then formulate a general linear model that generates the par ame t er of inter-
est, taking age into account:
P(θ|β,X)=N(Xβ,Π(2)) (9.5)
Here, X is a matrix whose columns are alternative explanatory variables and
whose rows indicate each participant. The first column of X typically com-
prises a matrix of ones (to indicate the effect of the mean par ame t er over
subjects). The second column, in our example, might be the age of each
participant. The β vector indicates the size of effect of each of the explana-
tory variables in X. The first elem ent of β is then the average value of the
precision (or any other par ame t er), while the second is the effect of age on
precision. This value is the slope of the line in a plot of age ( x- axis) against
predicted precision ( y-a xis). T here may be an arbitrary number of columns
of X, with an arbitrary number of elem ents in β.
Once we have fit the model expressed in equation 9.5, supplemented
with priors for the β values, we can ask questions about the role of the
explanatory variables. For example, we can ask w hether age has an effect on
the precision of prior preferences by comparing the evidence for a model
in which the second elem ent of β is allowed to deviate from zero with the
evidence for a model with a precise belief that it is zero. Practically speak-
ing, this can be done without multiple model inversions through use of
Bayesian model reduction (Friston, Parr, and Zeidman 2018).
9.5 Instructions for Model-B ased Analys is
In practice, we follow the steps outlined below to analyze empirical choice
beh avi or using active inference (Schwartenbeck and Friston 2016). T hese
refer to the relevant routines available in the SPM12 Matlab package.
1. Collect behavioral data, including the choices made and the sensory
input available to the person making that choice. In addition, collect
data of interest for second-l evel, between-s ubject analys is (e.g., w hether
the subject is a patient or a control subject, relevant demographic infor-
mation, and so on).
2. Formulate a POMDP model as in chapter 7. This should be a function
that takes para meters as inputs and outputs a fully specified (but not yet
solved) POMDP.
Downloaded from http://direct.mit.edu/books/oa-monograph/chapter-pdf/2246588/c007400_9780262369978.pdf by guest on 12 December 2025
This is a portion of the eBook at doi:10.7551/mitpress/12441.001.0001
180 Chapter 9
3. Specify a likelihood function (i.e., equation 9.2). This tells us how the
model should be used to calculate a likelihood. This typically calls a
POMDP solver (like the spm_MDP_VB_X.m routine) to simulate beh avi or
and quantifies the likelihood of observed actions.
4. Specify prior beliefs about the para meters in terms of expectations and
precisions. Often these will be centered on zero, with precisions reflect-
ing plausible ranges.
5. Solve for posterior probability and model evidence. This uses a stan-
dard inference scheme such as the variational Laplace procedure out-
lined above (equation 9.4). The spm_nlsi_Newton.m routine will do
this automatically.
6. Perform group- level analy sis. This typically makes use of PEB, which
treats the estimated para meters for each individual as if they w ere gener-
ated by a second-l evel model. This allows us to test hypotheses about the
causes of t hose para meters. Practically, this may be performed using the
spm_dcm_peb.m routine. Alternative analyses include standard statisti-
cal tests of association between the inferred para meters for each subject
and other subject-s pecific meas ures. For example, a canonical variates
analys is may be used to assess the relationship between questionnaire
scores and inferred para meters.
Figure 9.2’s summary of t hese instructions are based on the beh avi or
of the rat in the T-m aze task described in chapter 7. First, we place a rat in
a T-m aze with a rewarding stimulus in either the left or right arm and an
informative cue in the central arm. We then reco rd the sequence of actions
taken by the rat. This procedure may be repeated over multiple trials to
reco rd learned beh avi or, and it may be repeated for multiple diff ere nt rats
under diff ere nt interventions (e.g., pharmacological or optogen et ic).
Once these behavioral data have been obtained, we need a likelihood
function that lets us quantify the probability of beh avi or (for a given rat
in a given condition) u nder specific par ame t er settings. We can do this by
formulating the POMDP model we considered in chapter 7. This must be
par ame t erized in terms of the par ameters whose likelihood we seek to find.
For example, if we wanted to assess the precision associated with prefer-
ences, we might include a log scale par ame t er that makes the preference
distribution more or less peaky.
Having set up the generative model (from the perspective of the rat),
we can automatically solve the POMDP using the belief-u pdate equations
Downloaded from http://direct.mit.edu/books/oa-monograph/chapter-pdf/2246588/c007400_9780262369978.pdf by guest on 12 December 2025
Model- Based Data Analy sis 181
1 Data collection 2 POMDP model 3 Likelihood function
G (cid:28)
τ = 1 τ = 2 τ = 3 (cid:31) ς ς ς
(cid:31)τ─1 (cid:31)τ (cid:31)τ+1
s s s
R D Sτ-1 B Sτ B Sτ+1 τ─1 τ τ+1
R R R A s (cid:31)τ─1 s (cid:31)τ s (cid:31)τ+1
Oτ-1 Oτ Oτ+1 ε (cid:31)τ─1 ε (cid:31)τ ε (cid:31)τ+1
Chapter 7 Oτ-1 Oτ Oτ+1
6 PEB analysis 5 Invert model 4 Prior beliefs
in chapter 4. This lets us calculate the probability of the data (i.e., the
sequence of arms visited) conditioned on the model with the (preferences)
scale pa ram e ter at a par tic u lar value. Combining this likelihood with
our prior completes the specification of a generative model for be hav ior
(from the perspective of the scientist). This may be solved using variational
Laplace to find a posterior probability distribution over the scale par ame t er
for each rat.
Chapter
4
This is a portion of the eBook at doi:10.7551/mitpress/12441.001.0001
A A
ũ P(ũ | θ, õ, m)
θ = X β + ω P(θ | m, õ, ũ) P(θ | m)
∞ P(θ | m) P(ũ | θ, õ, m)
Figure 9.2
Roadmap of the six-s tep inversion procedure for model-b ased data analys is, as out-
lined in the main text (with reference to the chapters where more detail may be
found). The arrows indicate the dependencies between each part of the proc ess. The
POMDP model must be defined for the likelihood to be evaluated. The model inver-
sion requires collected data and the likelihood and priors; the PEB analys is cannot
take place u ntil a fter model inversion for each subject. Steps 4 and 5 schematize the
update from a prior distribution over para meters u nder a model to a posterior distri-
bution. The evidence and posterior from each model can then be combined using
PEB to find posterior densities (shown as expectations with accompanying credible
intervals) for the β coefficients of a linear model predicting t hese para meters.
Downloaded from http://direct.mit.edu/books/oa-monograph/chapter-pdf/2246588/c007400_9780262369978.pdf by guest on 12 December 2025
This is a portion of the eBook at doi:10.7551/mitpress/12441.001.0001
182 Chapter 9
In practice, before analyzing a ctual data, we may want to check the
face validity of the POMDP model by using it to generate fictive data—
and considering w hether they are qualitatively plausible given the probl em
at hand. A second sensible test for the model is pa ram e ter recovery. This
entails generating fictive data u nder some (known) par ame t erization to see
whether t hese para meters can be recovered on inverting the model. This is
useful to verify w hether some para meters (or their combinations) are poss i-
ble to recover (i.e., identifiable).
Fin ally, we can construct a design matrix for a linear model, each row of
which represents a computational phenotype (e.g., a posterior density over
each subject’s preferences), with columns representing diff ere nt attributes
of t hose subjects. T hese attributes are variables that could explain differ-
ences in a rat’s preferences. In addition to a column of ones indicating
the average preferences over all rats, these will include things like their
age, w hether a drug has been administered, and so on. With this model of
between-s ubject effects, we now perform a PEB analys is to assess the contri-
bution of t hese explanatory variables to prior preferences.
9.6 Examples of Generative Models
In this section, we leverage two examples in the lite ra t ure illustrating the
use of continuous and discrete generative models. First, we briefly overview
the methods used by Adams, Aponte et al. (2015) and Adams, Bauer et al.
(2016) (hereafter in this section, Adams et al.) to model smooth pursuit
eye movements as a way of quantifying the precision par ameters of each
subject’s generative models. An import ant aspect of this design was the
simultaneous collection of electrophysiological data (via magnetoencepha-
lography) that enabled the authors to ask questions about the neurobio-
logical substrates of precision or confidence encoding. We then turn to an
analys is of saccadic eye movements by Mirza et al. (2018; hereafter in this
section, Mirza et al.) formulated as a POMDP model. Each of the associated
experiments is cartooned in figure 9.3. Our hope is that t hese examples w ill
help readers understand how the generic methods outlined above can be
used empirically to answer scientific questions.
In terms of the sequence of steps outlined in figure 9.2, Adams et al.
collected data (step 1) from a task in which subjects had to maintain fixa-
tion on a moving visual target. The details are not import ant, but this task
Downloaded from http://direct.mit.edu/books/oa-monograph/chapter-pdf/2246588/c007400_9780262369978.pdf by guest on 12 December 2025
Model- Based Data Analy sis 183
Eye-tracking Eye-tracking
Time
Target Eyes vertical
Eyes Eyes horizontal
Target Foveation
Cat
Bird
comprised two conditions. In the first, the target moved according to a
predictable sinusoid. In the second, it followed the same trajectory with
additive Gaussian noise. The data collected included the eye-m ovement
trajectories. The authors formulated a subjective model (step 2). Unlike the
POMDP model shown in figure 9.2, they opted for a continuous model of
the sort described in chapter 8. In brief, the model predicted propriocep-
tive and visual input from the eyes, where the fixation point was assumed
to be attracted to the target location. The likelihood (step 3) is constructed
using the (active) predictive coding schemes outlined in chapter 4. This
quantifies the probability of the actions (eye movements) under a set of
noitacoL
Time
noitacoL
This is a portion of the eBook at doi:10.7551/mitpress/12441.001.0001
Figure 9.3
Two experiments outlined in section 9.5. The details are not import ant but high-
light where meta-B ayesian inference has been successfully exploited and the kinds of
behavioral data it can be applied to. Left: Experiment of Adams et al., who meas ured
smooth pursuit eye movements as subjects tracked a moving target. Right: Experi-
ment from Mirza et al., who meas ured saccadic eye movements during an explora-
tion task. The visual display was divided into four quadrants, two of which included
stimuli (cat and bird). Diff ere nt scene categories involved diff ere nt configurations of
stimuli, meaning participants had to select which quadrants to foveate to gain suffi-
cient information to categorize the scene. The Adams task (left ) generates continuous
eye-t racking data, while the Mirza task (right ) leads to a sequence of fixations and
may be discretized. T hese are the behavioral data (u) from step 1 in figure 9.2.
Downloaded from http://direct.mit.edu/books/oa-monograph/chapter-pdf/2246588/c007400_9780262369978.pdf by guest on 12 December 2025
This is a portion of the eBook at doi:10.7551/mitpress/12441.001.0001
184 Chapter 9
log precision par ameters and the model set out in step 2. Moving on to
step 4, the authors specified prior beliefs as normal distributions over the
log precisions. They inverted the model (step 5) to find posterior distribu-
tions over t hese precision para meters. Step 6 did not use a PEB analy sis
but used the neuroimaging data collected concurrently with the behavioral
task. The authors used dynamic causal modeling to estimate the gain of
superficial pyramidal cells in the primary visual cortex. This means they
had estimates of precision and synaptic gain for each subject. This allowed
the authors to perform a group-l evel analys is by assessing the correlation
between para meters of the subjective model and their biological substrates.
Their demonstration of this correlation provides an import ant example of
how Active Inference formulations of beh avi or let us ask (and answer) ques-
tions about the relationship between belief updating and neurobiology.
In our second example, Mirza et al. used the POMDP formulation of
Active Inference to address the role of information gain in driving human
beh avi or. Again, we unpack this in terms of figure 9.2’s steps. Mirza et al.
collected behavioral data (step 1) while subjects performed a visual foraging
task. H ere, the aim was to classify a visual scene into one of several groups.
Each elem ent of the scene was only revealed once subjects fixated t hose
locations; this meant multiple fixations w ere required to acquire enough
evidence for a given scene category. The data collected by the authors
included the sequence of saccades (fast eye movements) performed. The
model (step 2) used was a POMDP model described in Mirza et al. (2016)
that predicted discretized proprioceptive, visual, and feedback outcomes,
conditioned on the current fixation location and the scene category. Pref-
erences (see chapter 7) w ere placed over the feedback outcome such that
the model anticipates (and thus prefers) being correct in the categoriza-
tion. The likelihood function (step 3) was obtained by solving the model
using the scheme outlined in chapter 4 under diff ere nt par ame t er settings.
The para meters in question included (among o thers) a log scaling par am-
et er for the precision of the preference distribution. The authors specified
prior distributions (step 4) over the log scaling (and other para meters) and
inverted the model for each subject (step 5). They used the log evidence
estimated for each subject to assess the evidence for models that did or did
not motivate beh avi or using the epistemic component of the expected free
energy, finding greater evidence for those models that included epistemic
affordance in all subjects. They then employed a PEB analys is (step 6) to
Downloaded from http://direct.mit.edu/books/oa-monograph/chapter-pdf/2246588/c007400_9780262369978.pdf by guest on 12 December 2025
This is a portion of the eBook at doi:10.7551/mitpress/12441.001.0001
Model- Based Data Analy sis 185
assess changes in prior beliefs for subjects over the course of multiple t rials,
finding evidence in f avor of changes in belief para meters (i.e., active learn-
ing). Fin ally, they used a canonical covariates analys is to assess the relation-
ship between linear combinations of the phenotypic variables estimated
for each subject (e.g., precision of preferences) and linear combinations of
perf orm ance meas ures (e.g., percentage correct and reaction time).
9.7 Models of False Inference
Men in general are quick to believe that which they wish to be true.
— Julius Caesar
Given the relevance of these methods for fields like computational psychia-
try (Friston, Stephan et al. 2014), we end with an overview of false inference,
which is central to the notion of psychopathology as a failure of belief
updating. One benefit of using an inferential framework like Active Infer-
ence is that it sim ult an eously addresses multiple dimensions of psychiat-
ric disorders, linking together maladaptive beh avi or (e.g., compulsions or
addictions) and psychological-l evel (e.g., false beliefs) and biological-l evel
phenomena (e.g., abnormalities of neuromodulators).
As we cannot do justice h ere to the extensive lite ra t ure that uses Active
Inference in the modeling of disease proc esses, this section provides the
briefest of overviews to suggest a framework in which to think about com-
putational pathologies. See t able 9.1 for a nonexhaustive sampling of illus-
trative examples, which include models specified in discrete and continuous
time (based on t hose in chapters 7 and 8, respectively). In our discussion,
we w ill appeal to the structure of POMDP-l ike models; the princip les that
underwrite false inference in t hese settings are largely the same.
The hypothesis underl ying inferential approaches (like Active Inference)
is that psychopathological conditions may be conceptualized as disorders of
inference. The term disorder does not necessarily imply that the inferential
mechanism is flawed (e.g., generates incorrect posterior probabilities). In
most of the studies reviewed in t able 9.1, the inferential mechanism oper-
ates normally, but based on a flawed generative model (i.e., a generative
model endowed with aberrant prior beliefs). This means that, ultimately,
pathology is a consequence of aberrant prior beliefs— and one can recover
these priors using the model-b ased data analys is outlined in this chapter.
Downloaded from http://direct.mit.edu/books/oa-monograph/chapter-pdf/2246588/c007400_9780262369978.pdf by guest on 12 December 2025
This is a portion of the eBook at doi:10.7551/mitpress/12441.001.0001
186 Chapter 9
Table 9.1
Computational pathology
Pathology Sources Notes
Addiction, FitzGerald, Schwartenbeck Addiction is an import ant example
impulsivity, and et al. 2015 of beh avi or that appears aberrant but
compulsivity Schwartenbeck, FitzGerald, can be framed as optimal inference
Mathys, Dolan, Wurst et al. under the right sort of generative
2015 model. Work by Schwartenbeck et al.
Mirza et al. 2019 illustrated this using a l imited offer
Fradkin et al. 2020 task wherein participants are more or
less confident about w hether they w ill
receive a reward on waiting. Low con-
fidence leads to compulsive beh avi or
of the sort associated with addiction.
Subsequent work on this theme looks
at the prior beliefs associated with
more or less impulsive beh avi or, using
the patch-l eaving paradigm, and
examines the role of attenuated prior
precision in obsessive compulsive
disorder.
Delusions Brown et al. 2013 Delusions, characterized by fixed,
Friston, Parr et al. 2020 false beliefs, are simply articulated in
Active Inference as precise poste-
rior probability distributions in the
absence of supportive evidence. If
sufficiently precise, they will be fixed
even in the face of (subsequent)
contradictory evidence. The mecha-
nisms under lying each delusion may
be dif fer ent. For example, failures of
sensory attenuation may be central
to delusions of agency. Recent work
provides an example of a shared delu-
sion (folie à deux), which depends on
two agents—w ith no information—
reaching a confident consensus about
the state of the world.
Hallucinations Adams, Stephan et al. 2013 These simulations rest on imbalances
Benrimoh et al. 2018 between prior and likelihood preci-
Parr, Benrimoh et al. 2018 sions. Overinterpretation of spuri-
Corlett et al. 2019 ous sensory data due to a failure of
attenuation of likelihood precision,
or a failure to correct prior beliefs
due to excessive attenuation, each
offer mechanisms for false perceptual
inference.
Downloaded from http://direct.mit.edu/books/oa-monograph/chapter-pdf/2246588/c007400_9780262369978.pdf by guest on 12 December 2025
This is a portion of the eBook at doi:10.7551/mitpress/12441.001.0001
Model- Based Data Analy sis 187
Table 9.1
(continued)
Pathology Sources Notes
Interpersonal Moutoussis et al. 2014 Interpersonal inference depends on
and personality Prosser et al. 2018 having models about other p eople and
disorders how they may react to our decisions.
This has prompted the development
of models of trust games, which rely
on interactions between two (or more)
parties, and charity games. The latter
have been used to reproduce the
self-a ggrandizing and remorselessness
associated with psychopathy. T hese
traits are simulated by modulating
the degree to which beliefs about
self-w orth depend on decisions to be
charitable versus selfish and sensitivity
to the approval of o thers.
Oculomotor Adams, Perrinet, and Friston In t hese papers, continuous-t ime
syndromes 2012 generative models are employed
Parr and Friston 2018a to predict dynamic evolution of
Newtonian systems. By rendering
vario us aspects of the generative
model conditionally in de pen dent of
others, oculomotor syndromes such
as internuclear ophthalmoplegias may
be induced.
Pharmacotherapy Parr and Friston 2019b Given the associations we proposed
between precision para meters and neu-
rochemicals in chapter 5, it should be
poss ib le to simulate the consequences
of pharmacological manipulation of
these systems. This work illustrates
the consequences of several syn-
thetic pharmacological interventions
on perf orm ance of an oculomotor
delay-p eriod task, providing a proof of
princip le that t hese methods can be
used to simulate not only pathology
but also the influence of therapeutics.
Prefrontal Parr, Rikhye et al. 2019 These simulations set out a difference
syndromes between medial and lateral prefrontal
syndromes by attenuating the
precision of transitions to impair the
perf orm ance of a memory guided task
(lateral) versus the precision of an
interoceptive likelihood that deter-
mines motivation to engage in the
task (medial).
(continued)
Downloaded from http://direct.mit.edu/books/oa-monograph/chapter-pdf/2246588/c007400_9780262369978.pdf by guest on 12 December 2025
This is a portion of the eBook at doi:10.7551/mitpress/12441.001.0001
188 Chapter 9
Table 9.1
(continued)
Pathology Sources Notes
Visual neglect Parr and Friston 2017a Inattention to the left side of space
may be induced by several alterna-
tive lesioned priors. Among t hese,
an increase in Dirichlet par ameters
for this side of space reduces the
novelty associated with saccades to
the left, increasing visual sampling
of the right instead. Alternatively,
setting preferences consistent with
right- sided proprioceptive or visual
outcomes or increasing habitual
engagement in right- sided saccades
reproduces qualitatively similar
be hav ior.
Disorders of Barrett et al. 2016 Simulations of interoceptive inference
interoceptive Allen et al. 2019 (or active inference in the interocep-
inference Maisto, Barca et al. 2019 tive domain) suggest that imbalances
Pezzulo, Maisto et al. 2019 between prior and likelihood preci-
Barca and Pezzulo 2020 sions about (for example) cardiac or
Tschantz et al. 2021 gastric signals can cause false beliefs
about the internal state of the body,
misperceptions of bodily symptoms,
and psychosomatic hallucinations.
Furthermore, they can have cascad-
ing effects on autonomic regulation
and action se lection, causing vari ous
types of maladaptive be havi or, such
as hypervigilance, excessive medicine
use, and excessive food restrictions.
Aberrant priors may be about states or precisions, or they may be struc-
tural priors about the form of the generative model. A useful way of thinking
about the c auses of pathological beh avi or is to think about the prior belief
used for policies and about how each part of this may be disrupted to give
rise to abnormal policy sel ection. Policy priors depend on the expected free
energy, which itself depends on posterior beliefs, the potential for informa-
tion gain, and prior preferences (C). Priors over policies may additionally be
equipped with a fixed form term (E ), representing habitual biases.
Taking each of these in turn: Posterior beliefs depend on priors and likeli-
hoods. To form an aberrant posterior belief, one or both must be disrupted.
Typically, this disruption takes the form of under- or overestimation of the
Downloaded from http://direct.mit.edu/books/oa-monograph/chapter-pdf/2246588/c007400_9780262369978.pdf by guest on 12 December 2025
This is a portion of the eBook at doi:10.7551/mitpress/12441.001.0001
Model- Based Data Analy sis 189
balance of precisions. Excessively high likelihood, compared to prior, preci-
sion leads to overinterpretation of (potentially noisy) sensory input. This
leads to overfitting in the sense that unwarranted conclusions may be drawn
from spurious data. If the balance is disrupted in the opposite direction,
favoring confidence in the prior, internally generated percepts become resis-
tant to conflicting sensory input. Both mechanisms have been associated
with the development of hallucinations, and the two can coexist when hier-
archical models are employed. Given the association of vario us precisions
with neuromodulatory chemicals (see chapter 5), it seems sensible that con-
ditions such as Lewy body dementia, where cholinergic signaling is impaired,
and schizop hren ia, with abnormalities of the dopaminergic system, pres ent
with hallucinatory phenomena—t hat is, false perceptual inference.
Next, we consider the role of information gain. H ere, the precision of
the likelihood and the precision of prior beliefs tell us the degree to which
uncertainty is resolvable and the amount of uncertainty t here is to resolve,
respectively. The precision of the prior beliefs applies to e ither para meters
of the generative model (i.e., influences novelty) or to the states (i.e., influ-
ences salience). Interpreting the para meters of conditional probabilities as
synaptic efficacies or the precisions as synaptic gains suggests that synaptic
disconnection syndromes may be thought of as disruption of one or both
of t hese. Absent synapses cannot be modulated, so this is very much like
having extremely confident prior beliefs about a conditional probability, as
new data cannot update the associated efficacy. This has import ant impli-
cations for the potential information gain of diff ere nt policies, as has been
exploited in modeling sensory neglect syndromes.
Fin ally, the preferences and policy priors provide a clear influence over
beh avi or. These could underwrite the development of addictive habits or
the apathy associated with vario us psychiatric and neurological syndromes
(Hezemans, Wolpe, and Rowe 2020). In summary, defective prior beliefs
at vario us places in the generative models described above provide a func-
tional or teleological explanation for pathological beh avi or.
9.8 Summary
In this chapter, we outlined an approach that uses the theoretical models
described in previous chapters to pose questions to empirical data. This lets
us use Active Inference as a noninvasive tool to probe the computational
Downloaded from http://direct.mit.edu/books/oa-monograph/chapter-pdf/2246588/c007400_9780262369978.pdf by guest on 12 December 2025
This is a portion of the eBook at doi:10.7551/mitpress/12441.001.0001
190 Chapter 9
proc esses that individuals use to make decisions. We have focused on a few
simple examples. However, Active Inference–b ased models have been devel-
oped for more realistic and complicated tasks (Cullen et al. 2018) designed
to evoke richer beh avi or for computational phenotyping. In addition to
setting out a six-s tep proc ess for model-b ased analys is, we highlighted two
examples of the use of t hese methods. T hese bring out key variations in
how this may proceed, including the kinds of beh avi or meas ured (smooth
trajectories or discrete choices), the choice of model (continuous or dis-
crete), and the diff ere nt scientific questions being asked. The last of t hese
is the most import ant, as it determines the preceding choices. We saw the
use of computational phenotyping in combination with neuroimaging
(Adams, Bauer et al. 2016) to ask questions about the relationship between
synaptic gain and precision. In addition, we saw how model inversion may
be used to assess the contributions of alternative behavioral drives and
predictors of perf orm ance (Mirza et al. 2018). Ultimately, the six steps in
figure 9.1 provide a generic method for designing experiments to noninva-
sively interrogate the implicit generative models people (or other animals)
use to drive beh avi or. This offers an opportunity to answer questions about
the function of the ner vous system in health and disease.
Downloaded from http://direct.mit.edu/books/oa-monograph/chapter-pdf/2246588/c007400_9780262369978.pdf by guest on 12 December 2025
This is a section of doi:10.7551/mitpress/12441.001.0001
Active Inference
The Free Energy Principle in Mind, Brain, and
Behavior
By: Thomas Parr, Giovanni Pezzulo, Karl J.
Friston
Citation:
ActiveInference:TheFreeEnergyPrincipleinMind,Brain,and
Behavior
By:ThomasParr,GiovanniPezzulo,KarlJ.Friston
DOI:10.7551/mitpress/12441.001.0001
ISBN(electronic):9780262369978
Publisher:TheMITPress
Published:2022
The open access edition of this book was made possible by
generous funding and support from MIT Press Direct to Open
Downloaded from http://direct.mit.edu/books/oa-monograph/chapter-pdf/2246588/c007400_9780262369978.pdf by guest on 12 December 2025
MIT Press Direct
© 2022 Massachusetts Institute of Technology
This work is subject to a Creative Commons CC BY-NC-ND license.
Subject to such license, all rights are reserved.
The MIT Press would like to thank the anonymous peer reviewers who provided
comments on drafts of this book. The generous work of academic experts is essential
for establishing the authority and quality of our publications. We acknowledge with
gratitude the contributions of these otherwise uncredited readers.
This book was set in Stone Serif and Stone Sans by Westchester Publishing Services.
Library of Congress Cataloging-in-Publication Data is available.
Names: Parr, Thomas, 1993– author. | Pezzulo, Giovanni, author. | Friston, K. J.
(Karl J.), author.
Title: Active inference : the free energy principle in mind, brain, and behavior /
Thomas Parr, Giovanni Pezzulo, and Karl J. Friston.
Description: Cambridge, Massachusetts : The MIT Press, [2022] | Includes
bibliographical references and index.
Identifiers: LCCN 2021023032 | ISBN 9780262045353 (hardcover)
Subjects: LCSH: Perception. | Inference. | Neurobiology. | Human behavior models. |
Knowledge, Theory of. | Bayesian statistical decision theory.
Classification: LCC BF311 .P31366 2022 | DDC 153—dc23
LC record available at https://lccn.loc.gov/2021023032
Downloaded from http://direct.mit.edu/books/oa-monograph/chapter-pdf/2246588/c007400_9780262369978.pdf by guest on 12 December 2025