arXiv:2111.10530v1  [q-bio.NC]  20 Nov 2021
Kalman ﬁlters as the steady-state solution of gradient desc ent on
variational free energy
Manuel Baltieri 1,∗, Takuya Isomura 2
1 Araya Inc., Tokyo, Japan
2 Brain Intelligence Theory Unit,
RIKEN Centre for Brain Science, Saitama, Japan
∗ Corresponding author: manuel baltieri@araya.org
Abstract
The Kalman ﬁlter is an algorithm for the estimation of hidden variables in dynamical systems under
linear Gauss-Markov assumptions with widespread applicat ions across diﬀerent ﬁelds. Recently, its Bayesian
interpretation has received a growing amount of attention e specially in neuroscience, robotics and machine
learning. In neuroscience, in particular, models of percep tion and control under the banners of predictive
coding, optimal feedback control, active inference and mor e generally the so-called Bayesian brain hypothesis,
have all heavily relied on ideas behind the Kalman ﬁlter. Act ive inference, an algorithmic theory based
on the free energy principle, speciﬁcally builds on approxi mate Bayesian inference methods proposing a
variational account of neural computation and behaviour in terms of gradients of variational free energy.
Using this ambitious framework, several works have discuss ed diﬀerent possible relations between free energy
minimisation and standard Kalman ﬁlters. With a few excepti ons, however, such relations point at a mere
qualitative resemblance or are built on a set of very diverse comparisons based on purported diﬀerences
between free energy minimisation and Kalman ﬁltering. In th is work, we present a straightforward derivation
of Kalman ﬁlters consistent with active inference via a vari ational treatment of free energy minimisation in
terms of gradient descent. The approach considered here oﬀe rs a more direct link between models of neural
dynamics as gradient descent and standard accounts of perce ption and decision making based on probabilistic
inference, further bridging the gap between hypotheses abo ut neural implementation and computational
principles in brain and behavioural sciences.
1 Introduction
The Kalman ﬁlter is a method for the solution of estimation problems in d ynamical models and arguably one
of the most signiﬁcant advances in estimation and ﬁltering theory of the last century. Estimation, or inference,
refers to the task of evaluating some latent, or hidden, variables g iven the availability of some other measurable
quantities, usually named observations. Estimation problems on dyn amical (i.e., time-dependent) quantities in
time series models are usually classiﬁed as either ﬁltering, smoothing o r prediction (forecasting). In ﬁltering,
estimation is deﬁned for some hidden variable s at time t, st, given a (time) series of observations y at previous
and present time steps 0 : t, i.e., y0:t. Smoothing problems correspond to the estimation of a hidden varia ble st
given past, present and future observations y0:T up to some (future) time T such that 0 < t < T . Forecasting, or
prediction, on the other hand entails inference on a future hidden v ariable st given only previous measurements
y0:t− k, with k > 0.
The Kalman ﬁlter provides a standard tool to approach ﬁltering pro blems under a well-deﬁned set of as-
sumptions including: Gaussian white noise, known inputs and paramet ers, linear dynamics and observation
laws and quadratic cost functions. Over the years, the Kalman ﬁlte r has been (re)derived using a number of
diﬀerent methods, e.g., orthogonal projections, innovations app roach, partial diﬀerential equations, maximum
likelihood and a-posterior estimates, recursive Bayesian inference , variational methods/Lagrange multipliers,
hidden Markov models (for some reviews see for instance [54, 17]). R ecently, following the use of Bayesian prin-
ciples for models in brain and behavioural studies, and the very emer gence of the so-called “Bayesian brain”
hypothesis [83, 61, 25, 18], Kalman ﬁlters and a more general class o f methods, i.e., Bayesian ﬁlters, have been
linked to diﬀerent emerging frameworks in neuroscience. These inclu de, among others, predictive coding [82, 83],
optimal feedback control [88, 87] and active inference [45, 41]. Of ten, connections are proposed at a functional
level, but in some cases we can also ﬁnd more direct, concrete hypot heses about their neural implementations
[24, 94], see in particular [27] for a recent review (and a new proposa l).
1
Active inference is an ambitious framework originally developed in the n atural sciences that is claimed to
provide a mathematical treatment of biological, cognitive and even s ocio-cultural processes under the umbrella
of Bayesian mechanics, i.e., “laws of motion” describing spatio-temporal dynamics of param etrised Bayesian
beliefs modelled in brains, biological organisms and other self-sustain ing non-living systems at higher and lower
scales [45, 32, 34, 77, 91, 9, 59, 20]. In analogy with the principle of s tationary action in physics, from which
Newtonian, Lagrangian and Hamiltonian dynamics can be obtained und er diﬀerent sets of assumptions, active
inference proponents claim that this framework is an attempt to de rive Bayesian mechanics from a principle of
(variational) free energy minimisation. Bayesian mechanics can thus essentially be seen as a set of dynamical
Bayesian inference updates corresponding to a gradient descent /ﬂow on parametrised statistical manifolds (cf.
similar work on Wesserstein spaces [16, 89] building on the JKO equatio n [56]).
In this light, we will then look at how such a proposal relates to estab lished methods in Bayesian estimation,
in particular whether such methods can be derived as solutions to a s et of variational problems formulated with
diﬀerent sets of assumptions under the same Bayesian principle. Th is follows works such as [7], approximating
active inference on trajectories for multiple embedding orders to o btain PID control, and builds on established
results that more generally link variational treatments of Bayesian inference to classical estimation and control
(via the inference/control duality) [26, 70, 22].
While diﬀerent connections between Kalman, and more in general Bay esian, ﬁlters and active inference have
been proposed in the literature, see section 2, only a few have mana ged to show a clear and formal relation
[23, 90], speciﬁcally using factor graphs. The goal of this work is to f urther elucidate this connection under a
diﬀerent light, with a variational (Gaussian) treatment of Bayesian ﬁlters, presented in section 3, followed by a
generative model and related free energy function for a Kalman ﬁlt er in section 4. In section 5 we then derive a
standard gradient descent/ﬂow of free energy minimisation as spe ciﬁed by the Bayesian mechanics formulation
of active inference [45, 32, 34, 77, 91, 59, 20]. As we shall see, Kalm an ﬁlters will emerge as the steady state
solution of a gradient descent on variational free energy under th e right generative model. This derivation
will allow us to draw more direct connections to gradient-based fram eworks in diﬀerent ﬁelds, see concluding
remarks in section 6, highlighting then their role in neuroscience as a p ossible connection between models of
neural dynamics relying on gradient descent schemes and computa tional principles describing cognitive functions
as Bayesian belief updates.
2 Related work
Several works in the literature propose diﬀerent — and at times con tradicting — relations between active
inference and Kalman or Kalman-Bucy ﬁlters (the discrete observa tions continuous dynamics version of Kalman
ﬁlters). For instance, some works suggest that Kalman ﬁlters are equivalent to predictive coding (itself claimed
to be a special case of active inference), at least in some cases and under some implicit assumptions [11, 71,
19, 10]. It is then often claimed that Kalman or Kalman-Bucy ﬁlters ar e superseded, generalised or entailed
by the free energy principle and/or active inference [45, 31, 2, 39, 3, 1, 60], but a formal derivation is usually
missing. At times, Kalman(-Bucy) and the more general Bayesian ﬁlt ers are said to “resemble”, be “formally
similar to” or “consistent with”, “have the same form as” or “take t he form of” equations in active inference
[58, 43, 36, 33, 37, 28, 29, 35, 2, 15, 80, 30, 81, 34, 77, 67]. Othe r works suggest that active inference proposes a
form of Bayesian ﬁltering and in some cases generalises it [44, 42, 40 , 41, 78, 52, 75, 20] 1. Related arguments are
sometimes used to claim that generative models can be deﬁned to sup port both active inference and Kalman
ﬁltering [79], although the exact deﬁnition of such generative models is not provided. In some cases, it is also
stated that using variational free energy minimisation one can deriv e Kalman ﬁlters [62], but to the best of our
knowledge, no explicit proof of a gradient-based approach consist ent with active inference and the free energy
principle has been provided. On the other hand, Kalman ﬁlters have b een formally described via a factor graphs
description of active inference algorithms [23, 90] relating to exact treatments of message passing [84].
Other works then argue that Kalman ﬁlters and variational free en ergy derivations in active inference are
distinct and in some cases can be compared to each other [45, 31, 6 , 64, 60, 63, 67, 8, 5, 14, 4], often claiming
that active inference formulations outperform Kalman ﬁlters [45, 3 1, 6, 64, 60, 67, 14, 4]. In [69, 68] we then also
ﬁnd claims that approximations of Kalman ﬁlters derived from active in ference are supposedly more biological
plausible than their counterpart in standard ﬁlters. Finally, due to t he connections between active inference
and control as inference, Kalman ﬁlters have also been contraste d to active inference in [51], even if their exact
relation remains unstated.
In this literature we ﬁnd that only but a few works attempted to pro vide explicit formal connections via
gradient descent on variational free energy [8, 67, 69, 68], or via message passing on factor graphs [23, 90]. Even
fewer then have managed to correctly capture the actual equiva lence [23, 90], none of which using gradient-
based algorithms. To address this series of inconsistencies, and to expand on previous results, in what follows
1Notice that in these accounts, Kalman ﬁlters are not mention ed directly as in other references, but their connection can be
inferred from the very deﬁnition of Bayesian ﬁlters.
2
we derive state estimation for continuous-state distributions und er active inference, with a focus on ﬁltering
algorithms. For a closely related variational treatment, relying on a lgebraic manipulations over gradients and
with applications also to smoothing, regression and other inference problems, see also [74].
3 A variational (Gaussian) treatment of Bayesian ﬁlters
The standard formulation of Bayesian ﬁltering problems for linear Ga uss-Markov models can be described in
terms of recursive Bayesian estimates [17, 48, 85] over hidden sta tes st with observations y0:t for t = 0 . . . T :
p(st|y0:t) = p(y0:t, s t)
p(y0:t)
= p(yt, y 0:t− 1, s t)
p(yt, y 0:t− 1)
= p(yt|st, y 0:t− 1)p(st|y0:t− 1)p(y0:t− 1)
p(yt|y0:t− 1)p(y0:t− 1)
= p(yt|st)p(st|y0:t− 1)
p(yt|y0:t− 1) (1)
where in the last line we used the fact that observations at time t, yt, are conditionally independent of their
past given st. From this, we can then derive a variational treatment establishing a bound for the surprisal (i.e.,
the negative log-model evidence), − ln p(yt|y0:t− 1), introducing a variational density q(st)
− ln p(yt|y0:t− 1) = ln p(st|yt, y 0:t− 1) − ln p(yt, s t|y0:t− 1)
= ln p(st|yt, y 0:t− 1) − ln p(yt, s t|y0:t− 1) + ln q(st) − ln q(st)
= ln q(st)
p(yt, s t|y0:t− 1) − ln q(st)
p(st|yt, y 0:t− 1)
=
∫
q(st) ln q(st)
p(yt, s t|y0:t− 1) dst −
∫
q(st) ln q(st)
p(st|yt, y 0:t− 1) dst (2)
and deﬁning the variational free energy as
F ≡
∫
q(st) ln q(st)
p(yt, s t|y0:t− 1) dst
= Eq(st)[− ln p(yt, s t|y0:t− 1) + ln q(st)] (3)
where Eq(st)[•] denotes the expectation of • over q(st). This gives an upper bound of the surprisal owing to the
non-negativity of the Kullback-Leibler divergence in the second ter m of the last line of equation (2). Under a
variational Gaussian assumption [73], the variational density is deﬁn ed as
q(st) = N (st; µ+
st , Σ +
st ) = (2 π)− N/ 2 | Σ +
st |− 1/ 2e− 1
2 (st− µ +
st )T (Σ +
st )
− 1
(st− µ +
st ) (4)
The “ +-notation” is introduced here to compare this derivation with stand ard Kalman ﬁlter treatments diﬀer-
entiating between parameters that take into account information about observations yt at time t (corrections,
or a-posteriori estimates of st) and parameters that don’t (predictions, or a-priori estimates o f st for which we
will later adopt a “ − -notation”). Using textbook results for the diﬀerential entropy of a multivariate Gaussian
distribution, the variational free energy reduces to
F = Eq(st)[− ln p(yt, s t|y0:t− 1)] − N
2 ln(2πe) − 1
2 ln | Σ +
st | (5)
Following [45], we then apply a Laplace approximation to the joint p(yt, y 0:t− 1, s t)2 [66]. In particular, this
reduces to a Taylor expansion up to second order of the log-joint d istribution at the maximum a posteriori
(mode) of the posterior, ˆ st
ln p(yt, s t|y0:t− 1) = ln p(yt, s t|y0:t− 1)
⏐
⏐
⏐
st=ˆst
− 1
2 (st − ˆst)T S− 1
t (st − ˆst) + . . . (6)
2Notice that with the variational treatment applied in [45], the posterior is eﬀectively of the form: eEq(st )[− ln p(yt,y0:t− 1,st)],
which entails the equivalence of the variational Gaussian a pproximation applied to q(st) and the Laplace method applied to
p(yt, y0:t− 1, st) [73].
3
with the ﬁrst order term not appearing (i.e., = 0) at the expansion po int, the mode, and with the matrix S− 1
t
equal to the Hessian of ln p(yt, y 0:t− 1, s t)) evaluated at the mode st = ˆst
∇st ln p(yt, s t|y0:t− 1)
⏐
⏐
⏐
st=ˆst
= 0
∇st ∇st ln p(yt, s t|y0:t− 1)
⏐
⏐
⏐
st=ˆst
= −S− 1
t
⇒ S− 1
t = −∇st ∇st ln p(yt, s t|y0:t− 1)
⏐
⏐
⏐
st=ˆst
(7)
At this stage, the free energy can be rewritten, omitting higher or der terms, as
F ≈ − ln p(yt, s t|y0:t− 1)
⏐
⏐
⏐
st=ˆst
+ 1
2 Eq(st)
[
(st − ˆst)T S− 1
t (st − ˆst)
]
− N
2 ln(2πe) − 1
2 ln | Σ +
st | (8)
Following standard treatments, [45, 73] we will simplify the above fre e energy F by considering the case where
the variational density q(st) is centred at the mode of the posterior ˆ st, i.e., µ+
st = ˆst, and where Σ +
st = St,
i.e., the covariance of the variational density Σ +
st is equal to the covariance of the generative density St at each
expansion point (i.e., the mode) of the Laplace method. This then implie s that, using the trace trick, 3
F ≈ − ln p(yt, s t|y0:t− 1)
⏐
⏐
⏐
st=ˆst
− N
2 ln(2π) − 1
2 ln | Σ +
st | (9)
4 Variational free energy for a Kalman ﬁlter
After writing down the variational free energy (under Gaussian as sumptions) for a generic Bayesian ﬁltering
problem, we now specify the components of a linear generative mode l, p(yt, s t|y0:t− 1) = p(yt|st)p(st|y0:t− 1) as
follows:
p(yt|st) = N (Cµ +
st , Σ z)
p(st|y0:t− 1) = N (µ−
st , Σ −
st ) (10)
using the +− and − − notations described previously. Here, the a-priori estimates are given as functions of the
a-posteriori estimates at the last time step
µ−
st ≡ Aµ+
st− 1
Σ −
st ≡ AΣ +
st− 1 AT + Σ w (11)
Notice that this can be seen, equivalently, as a linear state-space m odel under Gauss-Markov assumptions
s0 = w0
st = Ast− 1 + wt, for t > 0
yt = Cst + zt (12)
with Gaussian noise wt ∼ N (0, Σ w), z t ∼ N (0, Σ z). In probabilistic form this is then
p(s1|s0) = N (0, Σ w)
p(st|st− 1) = N (Ast− 1, Σ w)
p(yt|st) = N (Cst, Σ z ) (13)
with equations that can be combined to form, using the Chapman-Ko lmogorov equation [85] for standard
Gaussian distributions (i.e., a convolution of Gaussians), the following
p(st|y0:t− 1) =
∫
p(st|st− 1)p(st− 1|y0:t− 1) dst− 1
=
∫
N (Ast− 1, Σ w)N (µ+
st− 1 , Σ +
st− 1 ) dst− 1
= N (Aµ+
st− 1 , A Σ +
st− 1 AT + Σ w)
= N (µ−
st , Σ −
st ) (14)
as seen in equation (10).
3Notice that the equality holds strictly only for the case whe re both q(st) and p(yt, st|y0:t− 1) are Gaussian.
4
The generative model described in equation (10) can be plugged into equation (9), with ˆ st = µ+
st , thus
obtaining the variational free energy 4
F = 1
2
[ (
yt − Cµ +
st
) T
Σ − 1
z
(
yt − Cµ +
st
)
+
(
µ+
st − µ−
st
) T (
Σ −
st
) − 1 (
µ+
st − µ−
st
) ]
+ 1
2 ln | Σ zt | + 1
2 ln | Σ wt |
− N
2 ln(2π) − 1
2 ln | Σ +
st | (15)
5 Free energy minimisation with respect to (µ+
st , Σ +
st )
A Kalman ﬁlter can be derived from the minimisation of equation (15) wit h respect to ( µ+
st , Σ +
st ) after providing
the following gradients of free energy:
∇µ +
st
F = −CT Σ − 1
z
(
yt − Cµ +
st
)
+
(
Σ −
st
) − 1 (
µ+
st − µ−
st
)
∇Σ +
st
F = ∇Σ +
st
[
− ln p(yt, s t|y0:t− 1)
⏐
⏐
⏐
st=µ +
st
]
− 1
2
(
Σ +
st
) − 1
= 1
2∇µ +
st
∇µ +
st
[
− ln p(yt, s t|y0:t− 1)
⏐
⏐
⏐
st=µ +
st
]
− 1
2
(
Σ +
st
) − 1
= 1
2
(
CT Σ − 1
z C +
(
Σ −
st
) − 1)
− 1
2
(
Σ +
st
) − 1
(16)
Notice that in the second equation, we applied Price’s and Bonnet’s th eorems [73, 57] to compute (ﬁrst order)
derivatives with respect to Σ +
st using (second order) derivatives with respect to µ+
st .
5.1 Covariance estimation
The equation for the correction updates of the covariance param eters Σ +
st can be obtained starting from the
steady-state solution for ∇Σ +
st
F = 0
(
Σ +
st
) − 1
= CT Σ − 1
z C +
(
Σ −
st
) − 1
⇒ Σ +
st =
(
CT Σ − 1
z C +
(
Σ −
st
) − 1) − 1
= Σ −
st − Σ −
st CT (
Σ z + CΣ −
st CT ) − 1
CΣ −
st
= ( I − Kst C)Σ −
st (17)
where in the second line we applied the standard matrix inversion (She rman–Morrison–Woodbury) lemma and
in the last line we used the familiar deﬁnition of the Kalman gain [86]
Kst = Σ −
st CT (
Σ z + CΣ −
st CT ) − 1
(18)
The deﬁnition of Σ −
st in equation (11) reﬂects then the prediction step
Σ −
st = AΣ +
st− 1 AT + Σ w (19)
and can be substituted in equation (17) to obtain a standard one-s tep update equation [86].
5.2 Mean estimation
For expectation parameters µ+
st , once again at steady-state ( ∇µ +
st
F = 0), we obtain after a few manipulations
the following variational updates
0 = − CT Σ − 1
z
(
yt − Cµ +
st
)
+
(
Σ −
st
) − 1 (
µ+
st − µ−
st
)
(
CT Σ − 1
z C +
(
Σ −
st
) − 1)
µ+
st =CT Σ − 1
z yt +
(
Σ −
st
) − 1
µ−
st
(
(I − Kst C)Σ −
st
) − 1
µ+
st =CT Σ − 1
z yt +
(
Σ −
st
) − 1
µ−
st
µ+
st =µ−
st + (I − Kst C)Σ −
st CT Σ − 1
z
(
yt − Cµ −
st
)
=µ−
st + Kst (yt − Cµ −
st ) (20)
4Notice that, unlike in equation (8) and equation (9), here we use an equality sign. Having by now assumed that both q(st) and
p(yt, st|y0:t− 1) are Gaussian, there are in fact no higher order terms to be co nsidered in the Laplace method.
5
where in the last line we used the equivalent form of the Kalman gain in eq uation (18)
Kst
(
Σ z + CΣ −
st CT )
= Σ −
st CT
Kst
(
I + CΣ −
st CT Σ − 1
z
)
= Σ −
st CT Σ − 1
z
Kst = Σ −
st CT Σ − 1
z − Kst CΣ −
st CT Σ − 1
z
= ( I − Kst C)Σ −
st CT Σ − 1
z
= Σ +
st CT Σ − 1
z (21)
The deﬁnition of µ−
st in equation (11) then implements the prediction step:
µ−
st = Aµ+
st− 1 (22)
and, similarly to the covariance updates, can be plugged in equation ( 20) for a one-step update rule that
concludes our derivation.
6 Concluding remarks
Kalman ﬁlters are a cornerstone method for state estimation of dy namical systems under linear Gauss-Markov
assumptions and are often nowadays formulated as a process of r ecursive Bayesian inference. Active inference
is a framework originally developed in neuroscience with the goal of de scribing processes of neural computation
and behavioural features of cognitive agents as approximate Bay esian inference [32, 42, 38]. More recently, this
framework has been explicitly formalised in terms of Bayesian mechanics, equations of motion for parameter
updates in a statistical manifold. In practice, these equations cor respond to a gradient descent/ﬂow in variational
free energy schemes, usually under Gaussian assumptions [34, 59 , 20].
In this note we shed light on a connection between Kalman ﬁlters and a ctive inference, speciﬁcally its
formulation in terms of gradient descent/ﬂow. In particular, we sh owed that Kalman ﬁlters are the steady-state
solution of a gradient descent scheme on the parameters (means a nd covariance matrix) of a linear generative
model under Gaussian assumptions (Laplace approximation/variat ional Gauss [73]). This complements existing
algebraic formulations [74], including the ones based on message pas sing algorithms [23, 90], and clariﬁes the
role of Kalman ﬁlters as gradients of variational free energy, prov iding a precise connection between standard
ﬁltering methods and gradients in Bayesian belief space.
Importantly, this derivation should not be confused with the idea of “steady-state (Kalman) ﬁltering” [86]:
our derivation shows a generic Kalman ﬁlter as the steady-state so lution of free energy minimisation, while
steady-state ﬁlters refer to methods where the dynamics of the ﬁlters themselves reach steady-state, i.e., the
covariance Σ +
st becomes stationary.
With the assumption of linear generative models, it would then be natural also to question the nec essity
of a variational treatment in the ﬁrst place, given the usual interp retation of variational Bayes as a method
to provide an approximate bound for the model evidence of an analy tically or numerically intractable problem
[55, 12, 13, 45]. Here however, we take a diﬀerent perspective and see the current work as inspired by treatments
such as [56], highlighting the tight connections between geometric (g radient descent on statistical manifolds),
variational (bounds in terms of free energy or ELBO) and Bayesian inference interpretations of ﬁltering. This
approach can be seen for example in complementary works for Kalma n ﬁlters in continuous-time (both dynamics
and observations) such as [46, 47].
In this light, the present variational Bayesian derivation of the Kalm an ﬁlter shows as a way to 1) preserve its
classical connections to Bayesian inference for the exact (i.e., linea r) case [49], 2) understand the Kalman ﬁlter
as the optimal linear estimator for non-linear systems [17, 85] in ter ms of a ﬁxed-form (variational) Gaussian
approximation of arbitrary distributions [73, 50] and 3) link the ﬁlter to more recent (information) geometric
treatments of probabilistic inference [65, 72].
In addition, our gradient-based approach preserves, more direc tly, (potential) connections that have been
proposed between active inference and frameworks in, e.g., physic s [34, 9, 59], chemistry [76], and brain science,
speciﬁcally for neural dynamics [38, 92, 93, 53, 21]. Finally, this clariﬁ es a series of claims about the relation
between Kalman ﬁlters and active inference [45, 31, 44, 6, 64, 58, 1 1, 33, 29, 35, 28, 43, 36, 37, 2, 3, 39, 71, 15,
1, 60, 80, 30, 42, 81, 40, 23, 41, 63, 78, 52, 34, 79, 77, 67, 19, 1 0, 75, 62, 8, 51, 69, 68, 5, 90, 20, 14, 4], resolving
puzzles derived from ambiguous and inconsistent treatments foun d in the literature.
7 Acknowledgments
The authors would like to thank Lancelot Da Costa for constructive feedback on a previous draft of the
manuscript.
6
References
[1] Rick A Adams, Harriet R Brown, and Karl J Friston. Bayesia n inference, predictive coding and delusions. AVANT. J. Philos.
Int. Vanguard, 5:51–88, 2014.
[2] Rick A Adams, Laurent U Perrinet, and Karl Friston. Smoot h pursuit and visual occlusion: active inference and oculom otor
control in schizophrenia. PloS one , 7(10):e47502, 2012.
[3] Rick A Adams, Klaas Stephan, Harriet Brown, Christopher Frith, and Karl J Friston. The computational anatomy of psyc hosis.
Frontiers in Psychiatry , 4:47, 2013.
[4] Ajith Anil Meera and Martijn Wisse. Dynamic expectation maximization algorithm for estimation of linear systems wi th
colored noise. Entropy, 23(10):1306, 2021.
[5] Mohamed Baioumy, Corrado Pezzato, Riccardo Ferrari, Ca rlos Hern´ andez Corbato, and Nick Hawes. Fault-tolerant co ntrol of
robot manipulators with sensory faults using unbiased acti ve inference. arXiv preprint arXiv:2104.01817 , 2021.
[6] Bhashyam Balaji and Karl Friston. Bayesian state estima tion using generalized coordinates. In Signal Processing, Sensor
Fusion, and Target Recognition XX , volume 8050, page 80501Y. International Society for Optic s and Photonics, 2011.
[7] Manuel Baltieri and Christopher L Buckley. A probabilis tic interpretation of PID controllers using active inferen ce. In
International Conference on Simulation of Adaptive Behavi or, pages 15–26. Springer, 2018.
[8] Manuel Baltieri and Christopher L. Buckley. On Kalman-B ucy ﬁlters, linear quadratic control and active inference. arXiv
preprint arXiv:2005.06269 , 2020.
[9] Manuel Baltieri, Christopher L Buckley, and Jelle Bruin eberg. Predictions in the eye of the beholder: an active infe rence
account of watt governors. arXiv preprint arXiv:2006.11495 , 2020.
[10] Helen C Barron, Ryszard Auksztulewicz, and Karl Fristo n. Prediction and memory: A predictive coding account. Progress in
neurobiology, 192:101821, 2020.
[11] Andre M Bastos, W Martin Usrey, Rick A Adams, George R Man gun, Pascal Fries, and Karl J Friston. Canonical microcircu its
for predictive coding. Neuron, 76(4):695–711, 2012.
[12] Matthew J. Beal. Variational algorithms for approximate Bayesian inferenc e. University of London London, 2003.
[13] Christopher M Bishop. Pattern Recognition and Machine Learning . Springer-Verlag New York, 2006.
[14] Fred Bos, Ajith Anil Meera, Dennis Benders, and Martijn Wisse. Free energy principle for state and input estimation of a
quadcopter ﬂying in wind. arXiv preprint arXiv:2109.12052 , 2021.
[15] Harriet Brown, Rick A Adams, Isabel Parees, Mark Edward s, and Karl J Friston. Active inference, sensory attenuatio n and
illusions. Cognitive processing, 14(4):411–427, 2013.
[16] Pratik Chaudhari and Stefano Soatto. Stochastic gradi ent descent performs variational inference, converges to l imit cycles for
deep networks. In International Conference on Learning Representations , 2018.
[17] Zhe Chen. Bayesian ﬁltering: From Kalman ﬁlters to part icle ﬁlters, and beyond. Statistics, 182(1):1–69, 2003.
[18] Andy Clark. Whatever next? predictive brains, situate d agents, and the future of cognitive science. Behavioral and Brain
Sciences, 36(03):181–204, 2013.
[19] Andrew W Corcoran, Giovanni Pezzulo, and Jakob Hohwy. F rom allostatic agents to counterfactual cognisers: active inference,
biological regulation, and the origins of cognition. Biology & Philosophy , 35(3):1–45, 2020.
[20] Lancelot Da Costa, Karl Friston, Conor Heins, and Grigo rios A Pavliotis. Bayesian mechanics for stationary proces ses. arXiv
preprint arXiv:2106.13830 , 2021.
[21] Lancelot Da Costa, Thomas Parr, Biswa Sengupta, and Kar l Friston. Neural dynamics under active inference: Plausib ility
and eﬃciency of information processing. Entropy, 23(4):454, 2021.
[22] Jean Daunizeau, Karl J Friston, and Stefan J Kiebel. Var iational bayesian identiﬁcation and prediction of stochas tic nonlinear
dynamic causal models. Physica D: nonlinear phenomena , 238(21):2089–2118, 2009.
[23] Bert De Vries and Karl J Friston. A factor graph descript ion of deep temporal active inference. Frontiers in computational
neuroscience, 11:95, 2017.
[24] Sophie Deneve, Jean-Ren´ e Duhamel, and Alexandre Poug et. Optimal sensorimotor integration in recurrent cortica l networks:
a neural implementation of kalman ﬁlters. Journal of neuroscience , 27(21):5744–5756, 2007.
[25] Kenji Doya. Bayesian brain: Probabilistic approaches to neural coding . MIT press, 2007.
[26] Gregory L Eyink. A variational formulation of optimal n onlinear estimation. arXiv preprint physics/0011049 , 2000.
[27] Johannes Friedrich, Siavash Golkar, Shiva Farashahi, Alexander Genkin, Anirvan M. Sengupta, and Dmitri B. Chklov skii.
Neural optimal feedback control with local learning rules, 2021.
[28] Karl Friston. Embodied inference and spatial cognitio n. Cognitive Processing, 13(1):171–177, 2012.
[29] Karl Friston, Michael Breakspear, and Gustavo Deco. Pe rception and self-organized instability. Frontiers in computational
neuroscience, 6:44, 2012.
[30] Karl Friston, Biswa Sengupta, and Gennaro Auletta. Cog nitive dynamics: From attractors to active inference. Proceedings of
the IEEE , 102(4):427–445, 2014.
[31] Karl J Friston. Hierarchical models in the brain. PLoS Computational Biology , 4(11), 2008.
[32] Karl J Friston. The free-energy principle: a uniﬁed bra in theory? Nature reviews. Neuroscience , 11(2):127–138, 2010.
[33] Karl J Friston. A free energy principle for biological s ystems. Entropy, 14(11):2100–2121, 2012.
[34] Karl J Friston. A free energy principle for a particular physics. arXiv preprint arXiv:1906.10184 , 2019.
[35] Karl J Friston, Rick Adams, Laurent Perrinet, and Micha el Breakspear. Perceptions as hypotheses: saccades as expe riments.
Frontiers in psychology , 3:151, 2012.
7
[36] Karl J Friston, Rick A Adams, and Read Montague. What is v alue? accumulated reward or evidence? Frontiers in
Neurorobotics, 6, 2012.
[37] Karl J Friston and Ping Ao. Free energy, value, and attra ctors. Computational and mathematical methods in medicine , 2012,
2012.
[38] Karl J Friston, Thomas FitzGerald, Francesco Rigoli, P hilipp Schwartenbeck, and Giovanni Pezzulo. Active infere nce: a
process theory. Neural Computation , 29(1):1–49, 2017.
[39] Karl J Friston and Dominic A Friston. A free energy formu lation of music generation and perception: Helmholtz revis ited. In
Sound-Perception-Performance, pages 43–69. Springer, 2013.
[40] Karl J Friston, Michael Levin, Biswa Sengupta, and Giov anni Pezzulo. Knowing one’s place: a free-energy approach t o pattern
regulation. Journal of The Royal Society Interface , 12(105):20141383, 2015.
[41] Karl J Friston, Thomas Parr, and Bert de Vries. The graph ical brain: belief propagation and active inference. Network
Neuroscience, 1(4):381–414, 2017.
[42] Karl J Friston, Francesco Rigoli, Dimitri Ognibene, Ch ristoph Mathys, Thomas Fitzgerald, and Giovanni Pezzulo. A ctive
inference and epistemic value. Cognitive neuroscience, pages 1–28, 2015.
[43] Karl J Friston, Tamara Shiner, Thomas FitzGerald, Jose ph M Galea, Rick Adams, Harriet Brown, Raymond J Dolan, Rosal yn
Moran, Klaas Enno Stephan, and Sven Bestmann. Dopamine, aﬀo rdance and active inference. PLoS computational biology ,
8(1):e1002327, 2012.
[44] Karl J Friston, Klaas Stephan, Baojuan Li, and Jean Daun izeau. Generalised ﬁltering. Mathematical Problems in Engineering ,
2010, 2010.
[45] Karl J Friston, N. Trujillo-Barreto, and J. Daunizeau. DEM: A variational treatment of dynamic systems. NeuroImage,
41(3):849–885, 2008.
[46] Abhishek Halder and Tryphon T Georgiou. Gradient ﬂows i n uncertainty propagation and ﬁltering of linear gaussian s ystems.
In 2017 IEEE 56th Annual Conference on Decision and Control (CD C), pages 3081–3088. IEEE, 2017.
[47] Abhishek Halder and Tryphon T Georgiou. Gradient ﬂows i n ﬁltering and ﬁsher-rao geometry. In 2018 Annual American
Control Conference (ACC) , pages 4281–4286. IEEE, 2018.
[48] Simon Haykin. Neural networks and learning machines . New York: Prentice Hall,, 2009.
[49] Y. C. Ho and R. C. K. Lee. A Bayesian approach to problems i n stochastic estimation and control. IEEE transactions on
automatic control , 9(4):333–339, 1964.
[50] Antti Honkela, Tapani Raiko, Mikael Kuusela, Matti Tor nio, and Juha Karhunen. Approximate Riemannian conjugate g radient
learning for ﬁxed-form variational Bayes. The Journal of Machine Learning Research , 11:3235–3268, 2010.
[51] Abraham Imohiosen, Joe Watson, and Jan Peters. Active i nference or control as inference? a unifying view. In International
Workshop on Active Inference , pages 12–19. Springer, 2020.
[52] Takuya Isomura, Thomas Parr, and Karl Friston. Bayesia n ﬁltering with multiple internal models: toward a theory of social
intelligence. Neural computation, 31(12):2390–2431, 2019.
[53] Takuya Isomura, Hideaki Shimazaki, and Karl Friston. C anonical neural networks perform active inference. bioRxiv, 2020.
[54] Andrew H Jazwinski. Stochastic Processes and Filtering Theory , volume 64. Academic Press, 1970.
[55] Michael I Jordan, Zoubin Ghahramani, Tommi S Jaakkola, and Lawrence K Saul. An introduction to variational methods for
graphical models. Machine learning , 37(2):183–233, 1999.
[56] Richard Jordan, David Kinderlehrer, and Felix Otto. Th e variational formulation of the fokker–planck equation. SIAM journal
on mathematical analysis , 29(1):1–17, 1998.
[57] Mohammad Emtiyaz Khan and H ˚ avard Rue. The bayesian lea rning rule. arXiv preprint arXiv:2107.04562 , 2021.
[58] Stefan J Kiebel and Karl J Friston. Free energy and dendr itic self-organization. Frontiers in systems neuroscience , 5:80, 2011.
[59] Chang Sub Kim. Bayesian mechanics of perceptual infere nce and motor control in the brain. Biological Cybernetics, 115(1):87–
102, 2021.
[60] Jan Kneissler, Jan Drugowitsch, Karl Friston, and Mart in V Butz. Simultaneous learning and ﬁltering without delus ions: A
bayes-optimal derivation of combining predictive inferen ce and adaptive ﬁltering. Frontiers in computational neuroscience ,
9:47, 2015.
[61] David C Knill and Alexandre Pouget. The Bayesian brain: the role of uncertainty in neural coding and computation. Trends
in Neurosciences , 27(12):712–719, 2004.
[62] Franz Kuchling, Karl J Friston, Georgi Georgiev, and Mi chael Levin. Morphogenesis as Bayesian inference: A variat ional
approach to pattern formation and control in complex biolog ical systems. Physics of Life Reviews , 33:88–108, 2020.
[63] Pablo Lanillos and Gordon Cheng. Adaptive robot body le arning and estimation through predictive coding. In 2018 IEEE/RSJ
International Conference on Intelligent Robots and System s (IROS) , pages 4083–4090. IEEE, 2018.
[64] Baojuan Li, Jean Daunizeau, Klaas E Stephan, Will Penny , Dewen Hu, and Karl J Friston. Generalised ﬁltering and stoc hastic
dcm for fmri. Neuroimage, 58(2):442–457, 2011.
[65] Yubo Li, Yongqiang Cheng, Xiang Li, Hongqiang Wang, Xia oqiang Hua, and Yuliang Qin. Bayesian nonlinear ﬁltering vi a
information geometric optimization. Entropy, 19(12):655, 2017.
[66] David JC MacKay. Information theory, inference and learning algorithms . Cambridge university press, 2003.
[67] Ajith Anil Meera and Martijn Wisse. Free energy princip le based state and input observer design for linear systems w ith
colored noise. In 2020 American Control Conference (ACC) , pages 5052–5058. IEEE, 2020.
[68] Beren Millidge, Anil Seth, and Christopher L Buckley. P redictive coding: a theoretical and experimental review. arXiv
preprint arXiv:2107.12979 , 2021.
[69] Beren Millidge, Alexander Tschantz, Anil K Seth, and Ch ristopher L Buckley. On the relationship between active inf erence
and control as inference. In International Workshop on Active Inference , pages 3–11. Springer, 2020.
8
[70] Sanjoy K Mitter and Nigel J Newton. A variational approa ch to nonlinear estimation. SIAM journal on control and optimiza-
tion, 42(5):1813–1833, 2003.
[71] Rosalyn J Moran, Pablo Campo, Mkael Symmonds, Klaas E St ephan, Raymond J Dolan, and Karl J Friston. Free energy,
precision and learning: the role of cholinergic neuromodul ation. Journal of Neuroscience , 33(19):8227–8236, 2013.
[72] Yann Ollivier. The extended Kalman ﬁlter is a natural gr adient descent in trajectory space. arXiv preprint arXiv:1901.00696 ,
2019.
[73] Manfred Opper and C´ edric Archambeau. The variational Gaussian approximation revisited. Neural computation , 21(3):786–
792, 2009.
[74] Dirk Ostwald, Evgeniya Kirilina, Ludger Starke, and Fe lix Blankenburg. A tutorial on variational Bayes for latent linear
stochastic time-series models. Journal of Mathematical Psychology , 60:1–19, 2014.
[75] Ensor Rafael Palacios, Adeel Razi, Thomas Parr, Michae l Kirchhoﬀ, and Karl Friston. On markov blankets and hierarc hical
self-organisation. Journal of Theoretical Biology , 486:110089, 2020.
[76] Thomas Parr. Message passing and metabolism. Entropy, 23(5):606, 2021.
[77] Thomas Parr, Lancelot Da Costa, and Karl Friston. Marko v blankets, information geometry and stochastic thermodyn amics.
Philosophical Transactions of the Royal Society A , 378(2164):20190159, 2020.
[78] Thomas Parr and Karl J Friston. Active inference and the anatomy of oculomotion. Neuropsychologia, 111:334–343, 2018.
[79] Thomas Parr, Dimitrije Markovic, Stefan J Kiebel, and K arl J Friston. Neuronal message passing using mean-ﬁeld, Be the,
and marginal approximations. Scientiﬁc reports , 9(1):1–18, 2019.
[80] Laurent U Perrinet, Rick A Adams, and Karl J Friston. Act ive inference, eye movements and oculomotor delays. Biological
cybernetics, 108(6):777–801, 2014.
[81] L´ eo Pio-Lopez, Ange Nizard, Karl Friston, and Giovann i Pezzulo. Active inference and robot control: a case study. Journal
of The Royal Society Interface , 13(122):20160616, 2016.
[82] Rajesh PN Rao. An optimal estimation approach to visual perception and learning. Vision research, 39(11):1963–1989, 1999.
[83] Rajesh PN Rao and Dana H Ballard. Predictive coding in th e visual cortex: a functional interpretation of some extra- classical
receptive-ﬁeld eﬀects. Nature neuroscience, 2(1):79–87, 1999.
[84] Sam Roweis and Zoubin Ghahramani. A unifying review of l inear gaussian models. Neural computation, 11(2):305–345, 1999.
[85] Simo S¨ arkk¨ a.Bayesian ﬁltering and smoothing . Cambridge University Press, 2013.
[86] Dan Simon. Optimal state estimation: Kalman, H inﬁnity, and nonlinear approaches. John Wiley & Sons, 2006.
[87] Emanuel Todorov. Stochastic optimal control and estim ation methods adapted to the noise characteristics of the se nsorimotor
system. Neural computation , 17(5):1084–1108, 2005.
[88] Emanuel Todorov and Michael I Jordan. Optimal feedback control as a theory of motor coordination. Nature neuroscience ,
5(11):1226, 2002.
[89] Nicolas Garcia Trillos and Daniel Sanz-Alonso. The bay esian update: variational formulations and gradient ﬂows. Bayesian
Analysis, 15(1):29–56, 2020.
[90] Thijs van de Laar, Ay¸ ca ¨Oz¸ celikkale, and Henk Wymeersch. Application of the free e nergy principle to estimation and control.
IEEE Transactions on Signal Processing , 69:4234–4244, 2021.
[91] Samuel PL Veissi` ere, Axel Constant, Maxwell JD Ramste ad, Karl J Friston, and Laurence J Kirmayer. Thinking throug h
other minds: A variational approach to cognition and cultur e. Behavioral and Brain Sciences , 43, 2020.
[92] James CR Whittington and Rafal Bogacz. An approximatio n of the error backpropagation algorithm in a predictive cod ing
network with local hebbian synaptic plasticity. Neural computation, 29(5):1229–1262, 2017.
[93] James CR Whittington and Rafal Bogacz. Theories of erro r back-propagation in the brain. Trends in cognitive sciences ,
23(3):235–250, 2019.
[94] Robert Wilson and Leif Finkel. A neural implementation of the Kalman ﬁlter. Advances in neural information processing
systems, 22:2062–2070, 2009.
9