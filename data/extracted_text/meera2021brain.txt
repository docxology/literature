A Brain Inspired Learning Algorithm for the Perception of a
Quadrotor in Wind
Ajith Anil Meera 1 and Martijn Wisse 2
Abstract— The quest for a brain-inspired learning algorithm
for robots has culminated in the free energy principle from
neuroscience that models the brain’s perception and action
as an optimization over its free energy objectives. Based on
this idea, we propose an estimation algorithm for accurate
output prediction of a quadrotor ﬂying under unmodelled wind
conditions. The key idea behind this work is the handling of
unmodelled wind dynamics and the model’s non-linearity errors
as coloured noise in the system, and leveraging it for accurate
output predictions. This paper provides the ﬁrst experimental
validation for the usefulness of generalized coordinates for robot
perception using Dynamic Expectation Maximization (DEM).
Through real ﬂight experiments, we show that the estimator
outperforms classical estimators with the least error in output
predictions. Based on the experimental results, we extend
the DEM algorithm for model order selection for complete
black box identiﬁcation. With this paper, we provide the ﬁrst
experimental validation of DEM applied to robot learning.
I. INTRODUCTION
The inferior uncertainty handling capabilities of modern
robot algorithms when compared to a human brain has been
inspiring roboticists to search for brain inspired algorithms
for robot perception. The recent advancements in compu-
tational neuroscience has culminated in the Free Energy
Principle (FEP) that models the brain’s perception and action
under one optimization scheme. Fundamentally rooted in
Bayesian Inference, FEP emerges as a brain theory that can
learn hierarchical causal dynamic models from limited data
under uncertainties. In light of these developments, we aim
to bridge the gap between FEP and robotics by providing
the ﬁrst experimental proof of concept for one of its variant
called Dynamic Expectation Maximization (DEM), applied
to robot model learning.
With this work, we introduce the idea of leveraging the
information content from the unmodelled system dynamics
for accurate output predictions under uncertainty. We propose
a DEM based perception scheme that models this noise
(prediction error) as colored using generalized coordinates
for accurate output predictions. Fig. 1 shows our proposed
perception scheme applied to a quadrotor hovering under
unmodelled wind conditions. The possible applications of
this approach is wide and include the handling of unmodelled
wind dynamics on a delivery drone, non-linearity errors of
an industrial manipulator robot, friction dynamics of a skid
steer ground robot in unknown terrains like martian surface,
search and rescue environments etc. The core contributions
of the paper include:
1,2 are with Cognitive Robotics, Faculty of Mechanical Maritime and
Materials Engineering, Delft Institute of Technology, The Netherlands,
Corresponding author: ajitham1994@gmail.com
Fig. 1: The proposed DEM based perception scheme. The unmod-
elled wind and the non linearity errors in the robot brain’s internal
model manifests as the sensory surprisal (output prediction errors).
The free energy principle (DEM) drives the robot brain to update
its internal model of the world (quadrotor dynamics) for uncertainty
resolution, resulting in better output predictions.
1) introduce a DEM based perception scheme for the
output prediction of a quadrotor hovering in wind,
2) provide the ﬁrst experimental conﬁrmation for the use-
fulness of generalized coordinates for robot perception,
3) extend the DEM algorithm with model order estima-
tion for the black-box identiﬁcation of linear systems.
II. RELATED WORK
In this section, we capture the multidisciplinary nature of
FEP literature, connecting neuroscience and robotics.
A. Cognitive neuroscience
FEP emerges from neuroscience as a unifying brain theory
[1] that explains the brain functions under a single framework
- free energy optimization. According to FEP, every self
organising system that is in equilibrium with the environment
should minimize its free energy. This drives a biological
agent into minimizing its sensory surprisal for uncertainty
resolution while interacting with the environment. This is
done in two ways - through perception (learning) and action
(active inference). Perception involves learning the gener-
ative process in the environment for accurate predictions,
whereas active inference involves acting on the environment
to suppress sensory surprisal. Numerous methods have been
developed around these ideas to explain brain functions
including predictive coding [2], hierarchical brain models [3],
active inference [4], DEM [5] etc. The biological plausiblity
of FEP rests in its capability to provide a mathematical
arXiv:2109.11971v1  [cs.RO]  24 Sep 2021
description of brain functions [6], to unify action and per-
ception [7], to connect physiological constructs like memory,
attention, value, reinforcement and salience [6], to explain
active vision [8], while remaining consistent with Freudian
ideas[9]. Similarities of FEP with reinforcement learning
[10], neural networks [11], [3], Kalman Filtering [12], PID
control [13] and active learning [7] further guides the quest
for a brain inspired robot learning algorithm towards FEP as
the uniﬁed robot learning algorithm.
B. Robotics
Recent applications of FEP in robotics include the body
perception of humanoid robots [14], adaptive control for
robot manipulators [15], robot navigation and mapping
(SLAM) [16] etc. Simultaneous state and input observer
designs for linear time invariant (LTI) systems with colored
noise was developed [12] and applied to quadrotors [17]. On
the learning side, DEM was developed into a system identi-
ﬁcation method [18] with theoretical convergence guarantees
[19]. In this paper we provide the proof of concept for DEM
by learning a quadrotor model for output prediction.
C. System identiﬁcation
In control systems, output predictions can be done using
system identiﬁcation, which is a mature ﬁeld [20] with
methods like Subspace (SS) method, Expectation Maximiza-
tion (EM), Prediction Error Minimization (PEM). However,
most of them consider the noises to be white, which is
often a wrong assumption in practice and results in biased
estimation for least square based methods [21] and inaccurate
convergence for the iterative methods [22]. Although various
bias compensation methods have been proposed to solve
this problem [23], [24], none of them perform simultaneous
state, input, parameter and noise hyperparameter estimation,
except for DEM. Therefore, DEM is of importance to the
research community and requires experimental validation on
real robots. With this paper, we aim to ﬁll this research gap.
III. PROBLEM STATEMENT
Consider the linearized plant dynamics given in Equation 1
where A, B and C are constant system matrices, with hidden
state x ∈Rn, input v ∈Rr and output y ∈Rm.
˙x = Ax + Bv + w, y = Cx + z. (1)
Here w ∈ Rn and z ∈ Rm represent the process and
measurement noise respectively. In this paper, we consider a
special case where the system is a hovering quadrotor. Vari-
ables of the plant are denoted in boldface, while its estimates
are denoted in non-boldface. The noises are assumed to be
colored such that it was generated by the convolution of
white noise with a Gaussian ﬁlter. The unmodelled wind dy-
namics and the non-linearity errors enter the system through
w, making it colored. The problems considered in the paper
are: 1) learn an LTI model to accurately predict the output
y from the inputs v, and 2) learn the order of the system n
for black box identiﬁcation.
IV. PRELIMINARIES
To lay the foundations of our perception and system iden-
tiﬁcation scheme, this section introduces the key concepts
behind DEM.
A. Generalized coordinates
The key concept that differentiates DEM from other
methods is its use of Generalized Coordinates (GC). GC
is a relatively new concept in robotics and shouldn’t be
confused with the deﬁnition in multi-body dynamics. GC
enables the estimator to gracefully handle colored noise by
modelling the trajectory (instead of point estimates) of all the
time dependent components like states, inputs, outputs and
noises using their higher order derivatives, thereby providing
additional information for perception. For example, the states
in GC is given by ˜x = [ x x′ x′′ ...]T. The variables in
generalized coordinates are denoted by a tilde, and their
components (higher derivatives) are denoted by primes. In
Section V-G we will demonstrate the usefulness of GC in
providing additional information for robot perception.
B. Generative model
The generative model denotes the robot brain’s internal
model of the generative process in the environment that is
responsible for data generation. Since the time dependent
components of the generative model are differentiable and
because the noises are coloured, the evolution of states of
an LTI system (generative process) in Equation 1 can be
extended as:
x′= Ax+ Bv+ w
x′′= Ax′+ Bv′+ w′
...
y= Cx+ z
y′= Cx′+ z′
...
(2)
which can be compactly written as:
˜x′= Dx˜x= ˜A˜x+ ˜B˜v+ ˜w ˜y= ˜C˜x+ ˜z (3)
where Dx =
[0 1
0 1
. .
0 1
0
]
(p+1)×(p+1)
⊗In×n
performs derivative operation, equivalent to shifting up all
components in generalized coordinates by one block. p and
d are the order of generalized motion of states and inputs
respectively. Here, ˜A = Ip+1 ⊗A, ˜B = Ip+1 ⊗B and
˜C = Ip+1 ⊗C, where ⊗is the Kronecker tensor product.
The generalized motion of output ˜y are computed from the
discrete measurements y [12].
C. Colored noise modeling
The colored noises are analytic such that the covari-
ance of noise derivatives ˜z = [ z,z′,z′′,...]T and ˜w =
[w,w′,w′′,...]T are well deﬁned. The correlation between
noise derivatives are represented using the temporal precision
matrix S(inverse of covariance matrix). Since the correlation
is assumed to be due to a Gaussian ﬁlter, S becomes [5]:
S(σ2) =


1 0 − 1
2σ2 ..
0 1
2σ2 0 ..
− 1
2σ2 0 3
4σ4 ..
.. .. .. ..


−1
(p+1)×(p+1)
(4)
where σ2 is the variance of Gaussian ﬁlter, with σ denoting
the noise smoothness. While σ2 = 0 denotes white noise,
non-zero σ2 denotes colored noise. The generalized noise
precision matrices are given by ˜Πw = S(σ2) ⊗Πw and
˜Πz = S(σ2) ⊗Πz, where Πw and Πz are the inverse noise
covariances.
D. Parameters and noise hyperparameters
The parameter θis composed of vectorized A, B, Cmatri-
ces deﬁned as θ =
[
vec(AT)T vec(BT)T vec(CT)T]T
,
and the noise hyperparameters λ =
[λz λw]T
models the
noise precision:
Πw(λw) = eλw
Ωw, Πz(λz) = eλz
Ωz, (5)
where Ωw and Ωz represent constant matrices encoding how
different noises are correlated. We use Ωw and Ωz as iden-
tity matrices for this work. Parameter and hyperparameter
estimation entails the estimation of θ and λ respectively.
E. Priors of the brain
DEM enables the transfer of prior knowledge through
Gaussian prior distributions for inputs, parameters and hy-
perparameters, centred around η as p(˜v) = N(η˜v,P ˜v),
p(θ) = N(ηθ,Pθ) and p(λ) = N(ηλ,Pλ) respectively.
The mean η acts as the starting point for the perception on
new data and the precision P shapes the conﬁdence on these
priors. P controls the robot brain’s exploration-exploitation
trade off during learning - lower P favours exploration,
whereas higher P favours exploitation. We will exhaustively
use this idea to pass known information to the algorithm (for
example, known inputs ) through η with high P.
F . Perception as Bayesian Inference
The biological brain’s perception is modelled as a
Bayesian Inference which involves the computation of the
posterior probability density p(ϑ/y) of parameter θ, given the
sensory measurement y[5]. Since it involves the computation
of an intractable integral p(ϑ/y) = p(ϑ,y)/
∫
p(ϑ,y)dϑ,
a variational density q(ϑ) called the recognition density
is deﬁned to closely approximate the posterior as q(ϑ) ≈
p(ϑ/y). This approximation is achieved by minimizing the
Kullback-Leibler (KL) divergence of the distributions given
by KL(q(ϑ)||p(ϑ/y)) = ⟨ln q(ϑ)⟩q(ϑ) −⟨ln p(ϑ/y)⟩q(ϑ),
where ⟨.⟩q(ϑ) represents the expectation over q(ϑ). Upon
simpliﬁcation using p(ϑ/y) = p(ϑ,y)/p(y), it can be rewrit-
ten as:
ln p(y) = ⟨ln p(ϑ,y)⟩q(ϑ) −⟨ln q(ϑ)⟩q(ϑ)
  
free energy
+KL(q(ϑ)||p(ϑ/y)),
(6)
where ln p(y) is called the log-evidence. Since ln p(y) is
independent of ϑ, the minimization of KL divergence for
inference results in the maximization of free energy. This
is the core idea behind using free energy as a proxy for
perception through Bayesian Inference.
G. Free energy objectives
Two types of free energy objectives are used by DEM
for perception: 1) free energy F for the estimation of
time varying components ( X =
[
˜x
˜v
]
) and 2) free energy
action ¯F =
∫
Fdt for the estimation of time invariant
components ( θ and λ). The free energy F emerges from
Bayesian statistics (Variational Inference) as an upper bound
on surprise [1], and can be written as the sum of its internal
energy U, mean ﬁeld term W and the entropy term H as:
F = U + W + H. (7)
After Laplace approximation and mean-ﬁeld approximation,
U,W and H for an LTI system can be simpliﬁed as [5], [18]:
U = −1
2˜ϵT ˜Π˜ϵ−1
2ϵθTPθϵθ −1
2ϵλTPλϵλ
+ 1
2 ln |˜Π|+ 1
2 ln |Pθ|+ 1
2 ln |Pλ|,
W = tr(Σ˜xU˜x˜x + Σ˜vU˜v˜v + ΣθUθθ + ΣλUλλ),
H = 1
2 ln |Σθ|+ 1
2 ln |Σλ|+ 1
2 ln |Σ˜x|+ 1
2 ln |Σ˜v|,
(8)
where ˜ϵ=


˜y −˜C˜x
˜v−˜ηv
Dx˜x−˜A˜x−˜B˜v

, ϵθ = θ −θ and ϵλ = λ −λ
are the prediction error for components in generalized co-
ordinates, parameters and hyperparameters respectively. The
prediction errors are precision weighed with the generalized
precision matrix ˜Π = diag(˜Πz,P ˜v,˜Πw), where diag(.) is
the block diagonal operation. Here Σ˜x, Σ˜v, Σθ and Σλ
are the covariance matrices denoting the uncertainty in the
estimation of states, inputs, parameters and hyperparameters
respectively. The free energy action ¯F can be written as [18]:
¯F = −1
2ϵθTPθϵθ −1
2ϵλTPλϵλ + 1
2
∑
ϑi
∑
t
Wϑi
+ 1
2
∑
t
(
−˜ϵT ˜Π˜ϵ+ ln|˜Π|+ ln|˜Σx|+ ln|˜Σv|
)
+ 1
2 ln |Pθ|+ 1
2 ln |Pλ|+ 1
2 ln |Σθ|+ 1
2 ln |Σλ|,
(9)
where Wϑi
= tr(Σϑi
Uϑiϑi ) is the mean ﬁeld term of ϑi ∈
{˜x,˜v,θ,λ }. ¯F can be seen as a generalized objective for
Expectation Maximization (EM) algorithm with additional
capabilities to handle colored noise. Removing generalized
coordinates, brain’s priors and the mean-ﬁeld terms equates
the objective functions of EM and DEM.
H. Perception as free energy optimization
DEM models the brain’s inference process probabilis-
tically through the estimation of two main components:
the mean estimate and the uncertainty (inverse precision)
in estimation. The mean estimate is computed through a
gradient ascend on the free energy manifold. Accordingly,
the update equation at time t, ath parameter update and bth
hyperparameter update can be written as [5]:
∂X
∂t = DX+kX ∂F
∂X, ∂θ
∂a = kθ∂¯F
∂θ , ∂λ
∂b = kλ∂¯F
∂λ, (10)
(a) ¯Fo with respect to parameters A and B.
 (b) Perception as maximization of ¯Fo.
 (c) Top view of Fig. 2b.
Fig. 2: (a) The shape of the free energy manifold ¯Fo with respect to parameters A and B (both chosen as scalars for vizualization)
changes with each E step iteration i, because of the interdependence between ˜x and θ. Gradient ascend over ¯Fo at each E step sharpens
the peak around the real parameters, where ¯Fo is the maximum. (b) Visualization of perception as a gradient ascend over free energy
objective. 50 randomly sampled ηθ (green dots) lying on a circle climb up the free energy curve to converge to the same parameters
(magenta dot) that coincides with the peak of one of the realizations of the free energy curve. (c) Top view of Fig. 2b.
where kX,kθ and kλ are the learning rates. ¯F is maximized
with respect to the estimation uncertainty Σϑi
when the ﬁrst
gradient is zero and the second gradient is negative deﬁnite.
∂¯F
∂Σϑi =1
2
∂
∂Σϑi
(
ln |Σϑi
|+
∑
t
tr(Σϑi
Uϑiϑi )
)
=1
2
(
(Σϑi
)−1 + ¯Uϑiϑi
)
,
∂2 ¯F
(∂Σϑi
)2 = −1
2(Σϑi
)−2 ≺O.
(11)
Forcing the ﬁrst gradient to zero yields the optimal precision
(inverse covariance) of estimates as:
Π˜x = −U˜x˜x, Π˜v = −U˜v˜v, Πθ = −¯Uθθ, Πλ = −¯Uλλ (12)
Fig. 3: Perception as the maximization of ¯Fo. The parameter
estimates (circles) start at i= 1 with wrong priors (ηA = −8,ηB =
8) and converges to the correct parameters (yellow and violet lines)
at A= −2 and B= 2. The ¯Fo curves (red and blue) are the cross
sections of the manifold similar to the one in Fig. 2a at different E
step iteration i. The peak of these curves rise and narrows around
the correct parameter until convergence. The increasing curvature
of these peaks during learning is indicative of increasing conﬁdence
in estimation Πθ as given in Equation 12.
Note that ¯U and U are used for time independent and time
dependent ϑi respectively. Therefore, the mean estimates
and the uncertainty in their estimation can be obtained from
Equations 10 and 12, only by using the ﬁrst two gradients
of the energy terms ( F, ¯F,U, ¯U). Substituting Equation 12
in 9 eliminates the mean ﬁeld terms and simpliﬁes ¯F for
an LTI system at optimal precision as the sum of weighted
prediction errors and entropy [18]:
¯Fo = 1
2nt
[
ln |˜Πz|+ ln|˜Pv|+ ln|˜Πw|  
noise entropy
]
+ 1
2ntln |˜ΣX|
  
state and input entropy
+ 1
2 ln |ΣθPθ|
  
parameter entropy
+ 1
2 ln |ΣλPλ|
  
hyperparameter entropy
−1
2
∑
t
[
(˜y −˜C˜x)T ˜Πz(˜y −˜C˜x)  
prediction error of outputs
+ (˜v−˜ηv)T ˜Pv(˜v−˜ηv)  
prediction error of inputs
]
−1
2
∑
t
[
(Dx˜x−˜A˜x−˜B˜v)T ˜Πw(Dx˜x−˜A˜x−˜B˜v)  
prediction error of states
]
−1
2 (θ−ηθ)TPθ(θ−ηθ)  
prediction error of parameters
−1
2 (λ−ηλ)TPλ(λ−ηλ)  
prediction error of hyperparameters
(13)
Maximizing ¯F for perception is equivalent to minimizing the
prediction error, while maximizing the uncertainty in estima-
tion through the entropy terms. This acts like regularization,
preventing the brain from overﬁtting the model to the data,
making it an ideal objective function for robot learning.
I. Dynamic Expectation Maximization
DEM postulates the brain’s perception as a gradient ascend
of its free energy objectives using three steps [5]:
• D step - state ( ˜x) and input ( ˜v) estimation,
• E step - parameter ( θ) estimation and
• M step - hyperparameter ( λ) estimation.
DEM results in Gaussian probability distributions with its
mean as the estimate and its standard deviation as the
uncertainty in estimation. The D steps follows the gradient
ascend over F given in Equation 7 to estimate ˜x,˜v,Π˜x and
Π˜v. The E and M steps follows the gradient ascend over ¯F
given in Equation 9 to estimate θ,Πθ and λ,Πλ respectively.
We use the reformulated version of DEM for LTI systems
from our previous work [18] for rest of the paper. Fig. 2
demonstrates DEM’s parameter learning procedure, whereas
Fig. 3 demonstrates the evolution of the cross sections of ¯Fo
manifold during perception.
Fig. 4: The quadcopter and the wind blower in the lab environment.
V. EXPERIMENTAL RESULTS AND ANALYSIS
This section aims to provide a proof of concept for DEM
through real quadrotor ﬂights in wind conditions.
A. Experimental setup
A Parrot AR drone 2.0 was used to hover in wind in a
controlled lab environment as shown in Fig. 4. A simple
linear state space model (Equation 1) that maps four rotor
PWM signals of the quadrotor to its roll angle φ and roll
angular velocity ˙φ is constructed (System 2 in Table I).
We consider a simple system where the optitrack motion
capture system directly observes the internal states ( x) of
the quadcopter through measurements y with a precision
of measurement noise Πz. The model is derived from [25]
after linearization around the equilibrium point. The key
idea behind this experimental design is to introduce the
linearization error and the error from unmodelled wind
dynamics to the system as colored process noise w.
B. Data preparation
We consider ﬁve quadrotor ﬂights under different wind
conditions (wind speed and blower orientation), all for a
duration of 850 time steps each with dt= 0.0083s. Although
Fig. 5: The histograms of process noise w
˙φ for all ﬁve ﬂight
experiments follow a Gaussian distribution.
different wind conditions might induce different levels of
noise color, it doesn’t inﬂuence our ﬁnal result. We split each
time series data into two parts: training data (700 time steps
≃80%) and test data (150 time steps ≃20%). The training
data is used to learn the model, whereas the test data (unseen
data) is used to test the performance of the learned model for
output prediction. As a pre-processing step, the input pwm
signal to the rotor was mean shifted to zero, and scaled down
from high values using: v= v−mean(v)
max(v)−min(v) .
C. Noise color and Laplace approximation
We validate the two fundamental assumptions of DEM,
the Laplace approximation and the noise color assumption,
by using noise histogram and noise autocorrelation graph
respectively on all experiments. Fig. 5 demonstrates that the
histogram of process noise w˙φ is Gaussian in nature, con-
ﬁrming DEM’s Laplace approximation. Fig. 7 demonstrates
that the autocorrelation plot of w˙φ does not correspond
to white noise where it should have been bounded within
the conﬁdence bounds for lags above 0. This conﬁrms the
presence of strong color in process noise, which was induced
by unmodelled wind dynamics and linearization errors.
D. Algorithm settings for DEM
The parameter priors ηθ were randomly selected from [-
1,1], and a moderate level of parameter precision ( Pθ = e4)
was set to encourage exploration in the parameter space,
starting from random priors ηθ. A high observation noise
hyperparameter ( λz = 20 ) was used with high conﬁdence
(Pλz
= e25) to represent the accurate motion capture system
TABLE I: LINEARIZED QUADCOPTER MODELS of DIFFERENT ORDER.
Order x A B C v
System 1 1 ˙φ 0
[0.3748 −0.3748 −0.3748 0 .3748]
I1
[
pwm1 pwm2 pwm3 pwm4]T
System 2 2
[φ
˙φ
] [
0 1
0 0
] [
0 0 0 0
0.3748 −0.3748 −0.3748 0 .3748
]
I2
[
pwm1 pwm2 pwm3 pwm4]T
System 3 3


˙y
φ
˙φ




0 −9.81 0
0 0 1
0 0 0




0 0 0 0
0 0 0 0
0.3748 −0.3748 −0.3748 0 .3748

 I3
[
pwm1 pwm2 pwm3 pwm4]T
System 4 4


y
˙y
φ
˙φ




0 1 0 0
0 0 −9.81 0
0 0 0 1
0 0 0 0




0 0 0 0
0 0 0 0
0 0 0 0
0.3748 −0.3748 −0.3748 0 .3748

 I4
[
pwm1 pwm2 pwm3 pwm4]T
(a) Output prediction.
 (b) Parameter estimation.
 (c) Maximize free energy action ¯F(i) − ¯F(0).
Fig. 6: The robot brain’s perception as a free energy optimization scheme (DEM) for the output prediction of a quadcopter hovering under
wind conditions. (a) The coinciding blue and red curves demonstrate that DEM can accurately perform one step ahead output prediction
on the training data (white background). The green curve following the trend of the red curve demonstrates that DEM can perform 150
step ahead output predictions on unseen data (grey background) using the learned model. (b) The parameter estimation step (E step)
explores the parameter space to ﬁnally converge to a solution for A, B and C matrices. (c) Perception driven by the maximization of ¯F.
measurements (optitrack). A low process noise hyperparam-
eter (λw = 3) was used with high conﬁdence ( Pλw
= e20) to
represent high process noise emerging from wind and non-
linearity errors. The noises were assumed to have a Gaussian
temporal correlation with a noise smoothness of s= dt for
all the experiments. To handle colored noise, the generalized
coordinate was used with an order of generalization for states
and inputs as p= 2 and d= 1 respectively. DEM used the
same settings to process all data.
E. Output prediction using DEM
The robot brain’s perception of a quadrotor hovering in
wind was emulated using the DEM algorithm. The quadrotor
model was learned by maximizing ¯F using the experiment 2
data and the result is shown in Fig. 6. The parameter estima-
tion (E step) explores the parameter space and converges to a
solution within few iterations (Fig. 6b), despite starting from
wrong random priors ( ηθ) in the range [-1,1]. The learned
model is tested for one step ahead output prediction on the
training data, and for output predictions until 150 step ahead
on the test data. The coinciding predictions and measured
output in Fig. 6a demonstrates DEM’s successful model
learning for output prediction, both on seen and unseen data.
Fig. 7: The autocorrelation plot of process noise ( w
˙φ) for all ﬁve
experiments doesn’t drop within the conﬁdence bound immediately
after zero lag, conﬁrming the presence of a range of noise color.
Fig. 6c shows the maximization of ¯F during perception.
F . Metric for comparison
We measure the quality of output prediction using the
Mean Squared Prediction Error (MSPE) for 150 step ahead
predictions on unseen test data:
MSPE = 1
150
T+150∑
i=T+1
(yi −ˆyi)2, (14)
where yi is the measured output and ˆyi is the output
prediction at time step i. A high quality perception algorithm
will have the least MSPE when compared to other methods.
G. Importance of generalized coordinates
The key difference between DEM and other classical
estimators is its capability to deal with colored noise using
the generalized coordinates (GC). In this section, we show
that the use of generalized coordinates improves the accuracy
of output prediction of a quadrotor ﬂying in wind. We
repeat the same procedure in Section V-E for two different
conditions: 1) output prediction with GC ( p = 2 ) and 2)
without GC ( p = 1 ). Fig. 8 demonstrates that the use of
Fig. 8: The output prediction of DEM on the test data improves
when GC is used during perception. The green curve follows the
trend of the red curve better than the yellow curve.
(a) Benchmarking output prediction.
 (b) The n-step ahead prediction error.
 (c) MSPE for ﬁve quadrotor experiments.
Fig. 9: The parameter learning using DEM is benchmarked against other system identiﬁcation methods - PEM, SS and EM. (a) The output
predictions of DEM (green curve) for experiment 2 on the unseen test data (grey background) best follows the trend of the measured
output (red curve) when compared to other methods. (b) The corresponding n-step ahead output prediction error is the lowest for DEM
(green curve) for most cases. (c) DEM outperforms other methods with the best quality output prediction by minimizing MSPE for all
ﬁve experiments, thereby demonstrating that DEM is a very competitive algorithm.
GC provides a better output prediction than when no GC
was used. MSPE was used to measure the quality of output
prediction for all ﬁve ﬂight experiments for both conditions
(with and without GC), and the results are tabulated in Table
II. The results show a lower MSPE for DEM with GC
when compared to DEM without using GC, revealing the
importance of using GC for output prediction.
TABLE II: INFLUENCE of GC on MSPE.
expt 1 expt 2 expt 3 expt 4 expt 5 total
DEM without GC 0.1197 0.0640 0.1647 0.0518 0.0951 0.4953
DEM with GC 0.0521 0.0133 0.0583 0.0458 0.1172 0.2867
H. Benchmarking
In this section, we will show that DEM outperforms
other classical estimators from control systems with the least
MSPE for ﬁve quadrotor ﬂight experiments in wind. The
estimators under consideration are Prediction Error Mini-
mization (PEM), Subspace method (SS) and Expectation
Maximization (EM). The System Identiﬁcation toolbox from
MATLAB was used for SS ( n4sid()) and PEM ( pem())
methods, whereas an EM algorithm implementation for state
space model was written based on [26]. PEM was initialized
using the solutions of SS. The data from experiment 2 was
used to learn the state space model of the quadrotor for
all methods. Fig. 9a shows the results of the n step ahead
output prediction on the unseen test data (grey background)
using the model learned by all methods. All predictions
tend to follow the trend of the measured output (red curve).
The prediction accuracy of different methods in Fig. 9a
is visualized in Fig. 9b using the n step ahead squared
prediction error. It can be observed that DEM outperforms
other methods with the least prediction error on unseen data.
MSPE was used as the evaluation metric to compare the
performance of DEM with other methods on all ﬁve ﬂight
data, and the results are shown in Fig. 9c. DEM outperforms
other methods for all ﬁve experiments with minimum MSPE
on unseen test data.
I. Extended DEM for black-box estimation
The previous sections use the known inputs, outputs and
model order for the output prediction, which differs from
the biological brain’s perception that do not have access to
the real inputs and model order. Therefore, in this section
we unleash the full capability of DEM with unknown inputs,
and then extend it by proposing a free energy objective based
scheme to evaluate the model order for black box estimation.
Since ¯F is the sum of prediction errors for ˜x, ˜v, θand λand
their entropies, it is intuitive for the correct model order (or
above) to maximize ¯F. In this section, we test this hypothesis
for quadrotor ﬂights.
We consider the linearlized model of the quadcopter
dynamics given in [25] to derive 4 different LTI systems as
given in Table I. All systems are observable and controllable,
and use motor pwm signals as the input. y, ˙y φ and ˙φ
were selected as states since they are the most inﬂuenced by
the wind in y direction, thereby generating colored process
noise in data. We use the same algorithm setup in Section
V-D except for an additional constraint for unknown input
(ηv = 0 with low precision Pv = e2), to run DEM for all ﬁve
experiments. The converged values of ¯F for all experiments
Fig. 10: The average ¯F of ﬁve experiments for different model
orders. ¯F saturates when the robot brain’s model order matches the
real system order (4 for blue, 3 for red, 2 for yellow and 1 for
violet).
were recorded by assuming a model order of 1,2,3 and 4 for
all systems. The average ¯F of ﬁve experiments with different
model orders for all four systems is shown in Fig. 10. ¯F
saturates when the model order matches the system order,
proving that ¯F is an indicator for model order selection.
We use this idea to extend the original DEM algorithm for
complete black box estimation as given in Algorithm 1. It
generates an internal model via free energy maximization to
estimate ˜x,˜v,θ,λ and nx that best explains the data.
Algorithm 1: Extended DEM - black box estimation
Initialize priors η= {ηv,Pv,ηθ,Pθ,ηλ,Pλ};
Initialize brain’s model order nx = 0 ;
while ¯Fb not converged do ⊿ model order
Initialize a← −1 and ¯Fa ← −−∞;
nx ← −nx + 1; ⊿ increment model order
while θ not converged do
for t = 0: ∆t:T do
˜x(t),˜v(t) ← −D STEP(˜y(t),θ,λ,n x,η);
end
while λ not converged do
λ← −M STEP(˜y,˜x,˜v,θ,λ,n x,η) ;
end
¯Fa ← −Equation (13) ⊿ ¯F at optimal precision
if ¯Fa > ¯Fa−1 then ⊿update θ if ¯F increased
θ← −E STEP(˜y,˜x,˜v,θ,λ,n x,η) ;
end
a← −a+ 1 ;
end
¯Fb = ¯Fa−1;
end
VI. CONCLUSIONS
Robust algorithms for robot perception is still an open
challenge, which could be solved by a brain-inspired algo-
rithm. We take a step towards applying one such method
(DEM) to real robots. We introduced a DEM based percep-
tion and system identiﬁcation scheme for accurate output
predictions during uncertainties (unmodelled dynamics), and
validated it through real experiments on a quadcopter. We
demonstrated its superior performance through its minimum
MSPE for 150 step ahead output prediction, when compared
to estimators like SS, PEM and EM. The usefulness of gener-
alized coordinates in providing additional (derivative) infor-
mation for estimation during unmodelled dynamics (wind)
was demonstrated through the decrease in MSPE. Based on
the results, the original DEM algorithm was extended for
model order selection during complete black box estimation.
The main disadvantage of DEM is it’s higher computational
complexity induced by generalized coordinates. Moreover,
the noise smoothness needs to be known apriori. The future
research will address these issues.
ACKNOWLEDGMENT
We would like to thank Dennis Benders for his involve-
ment in the data acquisition, as a part of his masters thesis.
REFERENCES
[1] K. Friston, “The free-energy principle: a uniﬁed brain theory?” Nature
reviews neuroscience, vol. 11, no. 2, pp. 127–138, 2010.
[2] K. Friston and S. Kiebel, “Predictive coding under the free-energy
principle,” Philosophical transactions of the Royal Society B: Biolog-
ical sciences, vol. 364, no. 1521, pp. 1211–1221, 2009.
[3] K. Friston, “Hierarchical models in the brain,” PLoS computational
biology, vol. 4, no. 11, p. e1000211, 2008.
[4] K. Friston, J. Mattout, and J. Kilner, “Action understanding and active
inference,” Biological cybernetics, vol. 104, no. 1, pp. 137–160, 2011.
[5] K. J. Friston, N. Trujillo-Barreto, and J. Daunizeau, “DEM: a varia-
tional treatment of dynamic systems,” Neuroimage, vol. 41, no. 3, pp.
849–885, 2008.
[6] K. Friston, “The free-energy principle: a rough guide to the brain?”
Trends in cognitive sciences , vol. 13, no. 7, pp. 293–301, 2009.
[7] K. J. Friston, J. Daunizeau, J. Kilner, and S. J. Kiebel, “Action and
behavior: a free-energy formulation,” Biological cybernetics, vol. 102,
no. 3, pp. 227–260, 2010.
[8] T. Parr, N. Sajid, L. Da Costa, M. B. Mirza, and K. J. Friston,
“Generative models for active vision,” Frontiers in Neurorobotics ,
vol. 15, p. 34, 2021.
[9] R. L. Carhart-Harris and K. J. Friston, “The default-mode, ego-
functions and free-energy: a neurobiological account of freudian
ideas,” Brain, vol. 133, no. 4, pp. 1265–1283, 2010.
[10] K. J. Friston, J. Daunizeau, and S. J. Kiebel, “Reinforcement learning
or active inference?” PloS one, vol. 4, no. 7, p. e6421, 2009.
[11] C. L. Buckley, C. S. Kim, S. McGregor, and A. K. Seth, “The free
energy principle for action and perception: A mathematical review,”
Journal of Mathematical Psychology , vol. 81, pp. 55–79, 2017.
[12] A. A. Meera and M. Wisse, “Free energy principle based state and
input observer design for linear systems with colored noise,” in 2020
American Control Conference (ACC) . IEEE, 2020, pp. 5052–5058.
[13] M. Baltieri and C. L. Buckley, “Pid control as a process of active
inference with linear generative models,” Entropy, vol. 21, no. 3, p.
257, 2019.
[14] G. Oliver, P. Lanillos, and G. Cheng, “Active inference body
perception and action for humanoid robots,” arXiv preprint
arXiv:1906.03022, 2019.
[15] C. Pezzato, R. Ferrari, and C. H. Corbato, “A novel adaptive controller
for robot manipulators based on active inference,” IEEE Robotics and
Automation Letters, vol. 5, no. 2, pp. 2973–2980, 2020.
[16] O. C ¸ atal, T. Verbelen, T. Van de Maele, B. Dhoedt, and A. Safron,
“Robot navigation as hierarchical active inference,” Neural Networks,
vol. 142, pp. 192–204, 2021.
[17] F. Bos, A. Anil Meera, D. Benders, and M. Wisse, “Free energy
principle for state and input estimation of a quadcopter ﬂying in wind,
Under review,” 2021.
[18] A. Anil Meera and M. Wisse, “Dynamic expectation maximiza-
tion algorithm for estimation of linear systems with colored noise
(Under review),” 2021.
[19] ——, “On the convergence of dem’s linear parameter estimator,
Accepted,” in International Workshop on Active Inference , 2021.
[20] L. Ljung, “System identiﬁcation,” in Signal analysis and prediction .
Springer, 1998, pp. 163–173.
[21] Y . Zhang, “Unbiased identiﬁcation of a class of multi-input single-
output systems with correlated disturbances using bias compensation
methods,” Mathematical and Computer Modelling , vol. 53, no. 9-10,
pp. 1810–1819, 2011.
[22] X. Liu and J. Lu, “Least squares based iterative identiﬁcation for a
class of multirate systems,” Automatica, vol. 46, no. 3, pp. 549–554,
2010.
[23] W. X. Zheng, “On a least-squares-based algorithm for identiﬁcation of
stochastic linear systems,” IEEE Transactions on Signal Processing ,
vol. 46, no. 6, pp. 1631–1638, 1998.
[24] Y . Zhang and G. Cui, “Bias compensation methods for stochastic
systems with colored noise,”Applied Mathematical Modelling, vol. 35,
no. 4, pp. 1709–1716, 2011.
[25] D. Benders, “Ar. drone 2.0 state estimation using dynamic expectation
maximization: Bringing brain perception theory to practice,” Master
thesis, TU Delft , 2020.
[26] F. J. Cara, J. Juan, and E. Alarc ´on, “Using the em algorithm to estimate
the state space model for omax,” In practice, vol. 1000, no. 1J, p. 3,
2014.