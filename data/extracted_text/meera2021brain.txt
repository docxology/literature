A Brain Inspired Learning Algorithm for the Perception of a
Quadrotor in Wind
Ajith Anil Meera1 and Martijn Wisse2
Abstract—Thequestforabrain-inspiredlearningalgorithm
for robots has culminated in the free energy principle from
neuroscience that models the brain’s perception and action
as an optimization over its free energy objectives. Based on
this idea, we propose an estimation algorithm for accurate
outputpredictionofaquadrotorflyingunderunmodelledwind
conditions. The key idea behind this work is the handling of
unmodelledwinddynamicsandthemodel’snon-linearityerrors
as coloured noise in the system, and leveraging it for accurate
output predictions. This paper provides the first experimental
validationfortheusefulnessofgeneralizedcoordinatesforrobot
perception using Dynamic Expectation Maximization (DEM).
Through real flight experiments, we show that the estimator
outperforms classical estimators with the least error in output
predictions. Based on the experimental results, we extend Fig. 1: The proposed DEM based perception scheme. The unmod-
the DEM algorithm for model order selection for complete elledwindandthenonlinearityerrorsintherobotbrain’sinternal
black box identification. With this paper, we provide the first modelmanifestsasthesensorysurprisal(outputpredictionerrors).
experimental validation of DEM applied to robot learning. The free energy principle (DEM) drives the robot brain to update
itsinternalmodeloftheworld(quadrotordynamics)foruncertainty
I. INTRODUCTION resolution, resulting in better output predictions.
The inferior uncertainty handling capabilities of modern
robot algorithms when compared to a human brain has been
inspiring roboticists to search for brain inspired algorithms 1) introduce a DEM based perception scheme for the
for robot perception. The recent advancements in compu- output prediction of a quadrotor hovering in wind,
tational neuroscience has culminated in the Free Energy 2) providethefirstexperimentalconfirmationfortheuse-
Principle(FEP)thatmodelsthebrain’sperceptionandaction fulnessofgeneralizedcoordinatesforrobotperception,
under one optimization scheme. Fundamentally rooted in 3) extend the DEM algorithm with model order estima-
Bayesian Inference, FEP emerges as a brain theory that can tion for the black-box identification of linear systems.
learn hierarchical causal dynamic models from limited data
under uncertainties. In light of these developments, we aim II. RELATEDWORK
to bridge the gap between FEP and robotics by providing
In this section, we capture the multidisciplinary nature of
the first experimental proof of concept for one of its variant
FEP literature, connecting neuroscience and robotics.
called Dynamic Expectation Maximization (DEM), applied
to robot model learning.
A. Cognitive neuroscience
With this work, we introduce the idea of leveraging the
information content from the unmodelled system dynamics FEPemergesfromneuroscienceasaunifyingbraintheory
foraccurateoutputpredictionsunderuncertainty.Wepropose [1]thatexplainsthebrainfunctionsunderasingleframework
a DEM based perception scheme that models this noise - free energy optimization. According to FEP, every self
(prediction error) as colored using generalized coordinates organisingsystemthatisinequilibriumwiththeenvironment
for accurate output predictions. Fig. 1 shows our proposed should minimize its free energy. This drives a biological
perception scheme applied to a quadrotor hovering under agent into minimizing its sensory surprisal for uncertainty
unmodelled wind conditions. The possible applications of resolution while interacting with the environment. This is
thisapproachiswideandincludethehandlingofunmodelled done in two ways - through perception (learning) and action
wind dynamics on a delivery drone, non-linearity errors of (active inference). Perception involves learning the gener-
an industrial manipulator robot, friction dynamics of a skid ative process in the environment for accurate predictions,
steer ground robot in unknown terrains like martian surface, whereas active inference involves acting on the environment
search and rescue environments etc. The core contributions to suppress sensory surprisal. Numerous methods have been
of the paper include: developed around these ideas to explain brain functions
includingpredictivecoding[2],hierarchicalbrainmodels[3],
1,2 are with Cognitive Robotics, Faculty of Mechanical Maritime and
active inference [4], DEM [5] etc. The biological plausiblity
Materials Engineering, Delft Institute of Technology, The Netherlands,
Correspondingauthor:ajitham1994@gmail.com of FEP rests in its capability to provide a mathematical
1202
peS
42
]OR.sc[
1v17911.9012:viXra
description of brain functions [6], to unify action and per- IV. PRELIMINARIES
ception[7],toconnectphysiologicalconstructslikememory, Tolaythe foundationsofourperceptionand systemiden-
attention, value, reinforcement and salience [6], to explain tification scheme, this section introduces the key concepts
active vision [8], while remaining consistent with Freudian behind DEM.
ideas[9]. Similarities of FEP with reinforcement learning
A. Generalized coordinates
[10], neural networks [11], [3], Kalman Filtering [12], PID
control [13] and active learning [7] further guides the quest The key concept that differentiates DEM from other
for a brain inspired robot learning algorithm towards FEP as methods is its use of Generalized Coordinates (GC). GC
the unified robot learning algorithm. is a relatively new concept in robotics and shouldn’t be
confused with the definition in multi-body dynamics. GC
B. Robotics enables the estimator to gracefully handle colored noise by
modellingthetrajectory(insteadofpointestimates)ofallthe
Recent applications of FEP in robotics include the body
time dependent components like states, inputs, outputs and
perception of humanoid robots [14], adaptive control for
noisesusingtheirhigherorderderivatives,therebyproviding
robot manipulators [15], robot navigation and mapping
additionalinformationforperception.Forexample,thestates
(SLAM) [16] etc. Simultaneous state and input observer
in GC is given by x˜ = [x x(cid:48) x(cid:48)(cid:48) ...]T. The variables in
designs for linear time invariant (LTI) systems with colored
generalized coordinates are denoted by a tilde, and their
noisewasdeveloped[12]andappliedtoquadrotors[17].On
components (higher derivatives) are denoted by primes. In
the learning side, DEM was developed into a system identi-
Section V-G we will demonstrate the usefulness of GC in
ficationmethod[18]withtheoreticalconvergenceguarantees
providing additional information for robot perception.
[19].InthispaperweprovidetheproofofconceptforDEM
by learning a quadrotor model for output prediction. B. Generative model
The generative model denotes the robot brain’s internal
C. System identification
model of the generative process in the environment that is
In control systems, output predictions can be done using responsible for data generation. Since the time dependent
system identification, which is a mature field [20] with components of the generative model are differentiable and
methodslikeSubspace(SS)method,ExpectationMaximiza- because the noises are coloured, the evolution of states of
tion (EM), Prediction Error Minimization (PEM). However, an LTI system (generative process) in Equation 1 can be
most of them consider the noises to be white, which is extended as:
often a wrong assumption in practice and results in biased x(cid:48) =Ax+Bv+w y =Cx+z
estimationforleastsquarebasedmethods[21]andinaccurate
x(cid:48)(cid:48) =Ax(cid:48)+Bv(cid:48)+w(cid:48) y(cid:48) =Cx(cid:48)+z(cid:48) (2)
convergencefortheiterativemethods[22].Althoughvarious
bias compensation methods have been proposed to solve ... ...
this problem [23], [24], none of them perform simultaneous which can be compactly written as:
state, input, parameter and noise hyperparameter estimation,
x˜(cid:48) =Dxx˜=A˜x˜+B˜v˜+w˜ y˜=C˜x˜+z˜ (3)
except for DEM. Therefore, DEM is of importance to the
(cid:34) (cid:35)
research community and requires experimental validation on 01
real robots. With this paper, we aim to fill this research gap. where Dx = 01 . . ⊗I n×n
01
0 (p+1)×(p+1)
III. PROBLEMSTATEMENT performs derivative operation, equivalent to shifting up all
components in generalized coordinates by one block. p and
ConsiderthelinearizedplantdynamicsgiveninEquation1
d are the order of generalized motion of states and inputs
whereA,BandCareconstantsystemmatrices,withhidden respectively. Here, A˜ = I ⊗ A, B˜ = I ⊗ B and
state x∈Rn, input v∈Rr and output y∈Rm. C˜ = I ⊗C, where ⊗ i p s + t 1 he Kronecker te p n + s 1 or product.
p+1
The generalized motion of output ˜y are computed from the
x˙ =Ax+Bv+w, y=Cx+z. (1)
discrete measurements y [12].
Here w ∈ Rn and z ∈ Rm represent the process and C. Colored noise modeling
measurement noise respectively. In this paper, we consider a
The colored noises are analytic such that the covari-
special case where the system is a hovering quadrotor. Vari-
ance of noise derivatives z˜ = [z,z(cid:48),z(cid:48)(cid:48),...]T and w˜ =
ablesoftheplantaredenotedinboldface,whileitsestimates
[w,w(cid:48),w(cid:48)(cid:48),...]T are well defined. The correlation between
are denoted in non-boldface. The noises are assumed to be
noisederivativesarerepresentedusingthetemporalprecision
colored such that it was generated by the convolution of
matrixS (inverseofcovariancematrix).Sincethecorrelation
whitenoisewithaGaussianfilter.Theunmodelledwinddy-
is assumed to be due to a Gaussian filter, S becomes [5]:
namics and the non-linearity errors enter the system through
w, making it colored. The problems considered in the paper  1 0 − 1 .. −1
2σ2
a y re fr : o 1 m ) l t e h a e rn in a p n uts LT v I , m an o d de 2 l ) t l o ea a rn cc t u h r e at o el r y de p r re o d f i t c h t e th s e ys o te u m tpu n t S(σ2)=   − 0 1 2 0 σ 1 2 0 3 . . . .    (4)
2σ2 4σ4
for black box identification. .. .. .. ..
(p+1)×(p+1)
where σ2 is the variance of Gaussian filter, with σ denoting G. Free energy objectives
the noise smoothness. While σ2 = 0 denotes white noise, Two types of free energy objectives are used by DEM
non-zero σ2 denotes colored noise. The generalized noise for perception: 1) free energy F for the estimation of
precision matrices are given by Π˜w = S(σ2) ⊗ Πw and (cid:20) x˜ (cid:21)
Π˜z =S(σ2)⊗Πz, where Πw and Πz are the inverse noise time varying components (X = v˜ ) and 2) free energy
covariances. action F¯ = (cid:82) Fdt for the estimation of time invariant
components (θ and λ). The free energy F emerges from
D. Parameters and noise hyperparameters Bayesianstatistics(VariationalInference)asanupperbound
on surprise [1], and can be written as the sum of its internal
TheparameterθiscomposedofvectorizedA,B,C matri-
ces defined as θ = (cid:2) vec(AT)T vec(BT)T vec(CT)T(cid:3)T , energy U, mean field term W and the entropy term H as:
and the noise hyperparameters λ = (cid:2) λz λw(cid:3)T models the F =U +W +H. (7)
noise precision:
After Laplace approximation and mean-field approximation,
Πw(λw)=eλw Ωw, Πz(λz)=eλz Ωz, (5) U,W andH foranLTIsystemcanbesimplifiedas[5],[18]:
1 1 1
U =− (cid:15)˜TΠ˜(cid:15)˜− (cid:15)θTPθ(cid:15)θ− (cid:15)λTPλ(cid:15)λ
whereΩw andΩz representconstantmatricesencodinghow 2 2 2
different noises are correlated. We use Ωw and Ωz as iden- 1 1 1
+ ln|Π˜|+ ln|Pθ|+ ln|Pλ|,
tity matrices for this work. Parameter and hyperparameter 2 2 2 (8)
estimation entails the estimation of θ and λ respectively. W = tr(Σx˜U +Σv˜U +ΣθU +ΣλU ),
x˜x˜ v˜v˜ θθ λλ
1 1 1 1
E. Priors of the brain H = ln|Σθ|+ ln|Σλ|+ ln|Σx˜|+ ln|Σv˜|,
2 2 2 2
DEM enables the transfer of prior knowledge through  ˜y−C˜x˜ 
Gaussian prior distributions for inputs, parameters and hy- where (cid:15)˜= v˜−η˜v , (cid:15)θ =θ−θ and (cid:15)λ =λ−λ
perparameters, centred around η as p(v˜) = N(ηv˜,Pv˜), Dxx˜−A˜x˜−B˜v˜
p(θ) = N(ηθ,Pθ) and p(λ) = N(ηλ,Pλ) respectively. are the prediction error for components in generalized co-
The mean η acts as the starting point for the perception on ordinates, parameters and hyperparameters respectively. The
newdataandtheprecisionP shapestheconfidenceonthese prediction errors are precision weighed with the generalized
priors. P controls the robot brain’s exploration-exploitation precision matrix Π˜ = diag(Π˜z,Pv˜,Π˜w), where diag(.) is
trade off during learning - lower P favours exploration, the block diagonal operation. Here Σx˜, Σv˜, Σθ and Σλ
whereas higher P favours exploitation. We will exhaustively are the covariance matrices denoting the uncertainty in the
usethisideatopassknowninformationtothealgorithm(for estimation of states, inputs, parameters and hyperparameters
example, known inputs ) through η with high P. respectively.ThefreeenergyactionF¯ canbewrittenas[18]:
F. Perception as Bayesian Inference F¯ =−
1
(cid:15)θTPθ(cid:15)θ−
1
(cid:15)λTPλ(cid:15)λ+
1(cid:88)(cid:88)
Wϑi
2 2 2
ϑi t
The biological brain’s perception is modelled as a
Bayesian Inference which involves the computation of the +
1(cid:88)(cid:16)
−(cid:15)˜TΠ˜(cid:15)˜+ln|Π˜|+ln|Σ˜x|+ln|Σ˜v|
(cid:17)
(9)
2
posteriorprobabilitydensityp(ϑ/y)ofparameterθ,giventhe t
1 1 1 1
sensorymeasurementy[5].Sinceitinvolvesthecomputation + ln|Pθ|+ ln|Pλ|+ ln|Σθ|+ ln|Σλ|,
of an intractable integral p(ϑ/y) = p(ϑ,y)/ (cid:82) p(ϑ,y)dϑ, 2 2 2 2
a variational density q(ϑ) called the recognition density where Wϑi = tr(ΣϑiU ) is the mean field term of ϑi ∈
ϑiϑi
is defined to closely approximate the posterior as q(ϑ) ≈ {x˜,v˜,θ,λ}. F¯ can be seen as a generalized objective for
p(ϑ/y). This approximation is achieved by minimizing the Expectation Maximization (EM) algorithm with additional
Kullback-Leibler (KL) divergence of the distributions given capabilities to handle colored noise. Removing generalized
by KL(q(ϑ)||p(ϑ/y)) = (cid:104)lnq(ϑ)(cid:105) q(ϑ) − (cid:104)lnp(ϑ/y)(cid:105) q(ϑ) , coordinates, brain’s priors and the mean-field terms equates
where (cid:104).(cid:105) q(ϑ) represents the expectation over q(ϑ). Upon the objective functions of EM and DEM.
simplificationusingp(ϑ/y)=p(ϑ,y)/p(y),itcanberewrit-
H. Perception as free energy optimization
ten as:
DEM models the brain’s inference process probabilis-
lnp(y)=(cid:104)lnp(ϑ,y)(cid:105) −(cid:104)lnq(ϑ)(cid:105) +KL(q(ϑ)||p(ϑ/y)),tically through the estimation of two main components:
q(ϑ) q(ϑ)
(cid:124) (cid:123)(cid:122) (cid:125) the mean estimate and the uncertainty (inverse precision)
freeenergy
(6) in estimation. The mean estimate is computed through a
where lnp(y) is called the log-evidence. Since lnp(y) is gradient ascend on the free energy manifold. Accordingly,
independent of ϑ, the minimization of KL divergence for the update equation at time t, ath parameter update and bth
inference results in the maximization of free energy. This hyperparameter update can be written as [5]:
is the core idea behind using free energy as a proxy for ∂X ∂F ∂θ ∂F¯ ∂λ ∂F¯
perception through Bayesian Inference. =DX+kX , =kθ , =kλ , (10)
∂t ∂X ∂a ∂θ ∂b ∂λ
(a)F¯o withrespecttoparametersAandB. (b)PerceptionasmaximizationofF¯o. (c)TopviewofFig.2b.
Fig. 2: (a) The shape of the free energy manifold F¯o with respect to parameters A and B (both chosen as scalars for vizualization)
changes with each E step iteration i, because of the interdependence between x˜ and θ. Gradient ascend over F¯o at each E step sharpens
the peak around the real parameters, where F¯o is the maximum. (b) Visualization of perception as a gradient ascend over free energy
objective. 50 randomly sampled ηθ (green dots) lying on a circle climb up the free energy curve to converge to the same parameters
(magenta dot) that coincides with the peak of one of the realizations of the free energy curve. (c) Top view of Fig. 2b.
where kX,kθ and kλ are the learning rates. F¯ is maximized NotethatU¯ andU areusedfortimeindependentandtime
with respect to the estimation uncertainty Σϑi when the first dependent ϑi respectively. Therefore, the mean estimates
gradient is zero and the second gradient is negative definite. and the uncertainty in their estimation can be obtained from
∂F¯ = 1 ∂ (cid:16) ln|Σϑi |+ (cid:88) tr(Σϑi U ) (cid:17) E of qu th a e tio e n n s er 1 g 0 y a t n e d rm 1 s 2, (F o , n F l ¯ y ,U by ,U¯ u ) s . in S g ub th s e titu fi t r i s n t g tw E o qu g a r t a io d n ien 1 t 2 s
∂Σϑi 2∂Σϑi
t
ϑiϑi
in 9 eliminates the mean field terms and simplifies F¯ for
= 1(cid:0) (Σϑi )−1+U¯ (cid:1) , (11) an LTI system at optimal precision as the sum of weighted
2 ϑiϑi prediction errors and entropy [18]:
∂2F¯ 1
(∂Σϑi)2 =− 2 (Σϑi )−2 ≺O. F¯o = 1 nt (cid:104) ln|Π˜z|+ln|P˜v|+ln|Π˜w| (cid:105)
2
(cid:124) (cid:123)(cid:122) (cid:125)
Forcingthefirstgradienttozeroyieldstheoptimalprecision noiseentropy
(inverse covariance) of estimates as: + 1 n ln|Σ˜X| + 1 ln|ΣθPθ| + 1 ln|ΣλPλ|
2 t 2 2
Πx˜ =−U , Πv˜ =−U , Πθ =−U¯ , Πλ =−U¯ (12) (cid:124) (cid:123)(cid:122) (cid:125) (cid:124) (cid:123)(cid:122) (cid:125) (cid:124) (cid:123)(cid:122) (cid:125)
x˜x˜ v˜v˜ θθ λλ
stateandinputentropy parameterentropy hyperparameterentropy
−
1(cid:88)(cid:104)
(˜y−C˜x˜)TΠ˜z(˜y−C˜x˜)+(v˜−η˜v)TP˜v(v˜−η˜v)
(cid:105)
2
(cid:124) (cid:123)(cid:122) (cid:125) (cid:124) (cid:123)(cid:122) (cid:125)
t
predictionerrorofoutputs predictionerrorofinputs
−
1(cid:88)(cid:104)
(Dxx˜−A˜x˜−B˜v˜)TΠ˜w(Dxx˜−A˜x˜−B˜v˜)
(cid:105)
2
(cid:124) (cid:123)(cid:122) (cid:125)
t
predictionerrorofstates
1 1
− (θ−ηθ)TPθ(θ−ηθ)− (λ−ηλ)TPλ(λ−ηλ)
2 2
(cid:124) (cid:123)(cid:122) (cid:125) (cid:124) (cid:123)(cid:122) (cid:125)
predictionerrorofparameters predictionerrorofhyperparameters
(13)
MaximizingF¯ forperceptionisequivalenttominimizingthe
predictionerror,whilemaximizingtheuncertaintyinestima-
tion through the entropy terms. This acts like regularization,
preventing the brain from overfitting the model to the data,
making it an ideal objective function for robot learning.
I. Dynamic Expectation Maximization
Fig. 3: Perception as the maximization of F¯o. The parameter
estimates(circles)startati=1withwrongpriors(ηA =−8,ηB = DEMpostulatesthebrain’sperceptionasagradientascend
8)andconvergestothecorrectparameters(yellowandvioletlines) of its free energy objectives using three steps [5]:
atA=−2andB =2.TheF¯o curves(redandblue)arethecross • D step - state (x˜) and input (v˜) estimation,
sectionsofthemanifoldsimilartotheoneinFig.2aatdifferentE
• E step - parameter (θ) estimation and
step iteration i. The peak of these curves rise and narrows around
the correct parameter until convergence. The increasing curvature • M step - hyperparameter (λ) estimation.
ofthesepeaksduringlearningisindicativeofincreasingconfidence DEM results in Gaussian probability distributions with its
in estimation Πθ as given in Equation 12. mean as the estimate and its standard deviation as the
uncertainty in estimation. The D steps follows the gradient
ascend over F given in Equation 7 to estimate x˜,v˜,Πx˜ and
Πv˜. The E and M steps follows the gradient ascend over F¯
giveninEquation9toestimateθ,Πθ andλ,Πλ respectively.
We use the reformulated version of DEM for LTI systems
from our previous work [18] for rest of the paper. Fig. 2
demonstrates DEM’s parameter learning procedure, whereas
Fig.3demonstratestheevolutionofthecrosssectionsofF¯o
manifold during perception.
Fig. 5: The histograms of process noise
wφ˙
for all five flight
experiments follow a Gaussian distribution.
different wind conditions might induce different levels of
noisecolor,itdoesn’tinfluenceourfinalresult.Wespliteach
time series data into two parts: training data (700 time steps
(cid:39) 80%) and test data (150 time steps (cid:39) 20%). The training
dataisusedtolearnthemodel,whereasthetestdata(unseen
Fig.4:Thequadcopterandthewindblowerinthelabenvironment.
data)isusedtotesttheperformanceofthelearnedmodelfor
output prediction. As a pre-processing step, the input pwm
V. EXPERIMENTALRESULTSANDANALYSIS signaltotherotorwasmeanshiftedtozero,andscaleddown
from high values using: v = v−mean(v) .
This section aims to provide a proof of concept for DEM max(v)−min(v)
through real quadrotor flights in wind conditions.
C. Noise color and Laplace approximation
A. Experimental setup We validate the two fundamental assumptions of DEM,
A Parrot AR drone 2.0 was used to hover in wind in a the Laplace approximation and the noise color assumption,
controlled lab environment as shown in Fig. 4. A simple by using noise histogram and noise autocorrelation graph
linear state space model (Equation 1) that maps four rotor respectively on all experiments. Fig. 5 demonstrates that the
PWM signals of the quadrotor to its roll angle φ and roll histogram of process noise
wφ˙
is Gaussian in nature, con-
angular velocity φ˙ is constructed (System 2 in Table I). firming DEM’s Laplace approximation. Fig. 7 demonstrates
We consider a simple system where the optitrack motion that the autocorrelation plot of
wφ˙
does not correspond
capture system directly observes the internal states (x) of to white noise where it should have been bounded within
the quadcopter through measurements y with a precision the confidence bounds for lags above 0. This confirms the
of measurement noise Πz. The model is derived from [25] presenceofstrongcolorinprocessnoise,whichwasinduced
after linearization around the equilibrium point. The key by unmodelled wind dynamics and linearization errors.
idea behind this experimental design is to introduce the
D. Algorithm settings for DEM
linearization error and the error from unmodelled wind
dynamics to the system as colored process noise w. The parameter priors ηθ were randomly selected from [-
1,1], and a moderate level of parameter precision (Pθ =e4)
B. Data preparation
was set to encourage exploration in the parameter space,
We consider five quadrotor flights under different wind starting from random priors ηθ. A high observation noise
conditions (wind speed and blower orientation), all for a hyperparameter (λz = 20) was used with high confidence
durationof850timestepseachwithdt=0.0083s.Although (Pλz =e25)torepresenttheaccuratemotioncapturesystem
TABLE I: LINEARIZED QUADCOPTER MODELS of DIFFERENT ORDER.
Order x A B C v
System1 1 φ˙ 0 (cid:2)0.3748 −0.3748 −0.3748 0.3748(cid:3) I1 (cid:2) pwm1 pwm2 pwm3 pwm4(cid:3)T
System2 2
(cid:20)φ
φ˙
(cid:21) (cid:20)
0 0 1 0
(cid:21) (cid:20)
0.3 0 748 −0. 0 3748 −0. 0 3748 0.3 0 748
(cid:21)
I2 (cid:2) pwm1 pwm2 pwm3 pwm4(cid:3)T
y˙ 
0 −9.81 0
 
0 0 0 0

System3 3 φ 0 0 1  0 0 0 0  I3 (cid:2) pwm1 pwm2 pwm3 pwm4(cid:3)T
φ˙ 0 0 0 0.3748 −0.3748 −0.3748 0.3748
y 0 1 0 0  0 0 0 0 
System4 4 
φ
y˙ 



0
0
0
0
−9
0
.81
1
0 



0
0
0
0
0
0
0
0


I4 (cid:2) pwm1 pwm2 pwm3 pwm4(cid:3)T
φ˙ 0 0 0 0 0.3748 −0.3748 −0.3748 0.3748
(a)Outputprediction. (b)Parameterestimation. (c)MaximizefreeenergyactionF¯(i)−F¯(0).
Fig.6:Therobotbrain’sperceptionasafreeenergyoptimizationscheme(DEM)fortheoutputpredictionofaquadcopterhoveringunder
wind conditions. (a) The coinciding blue and red curves demonstrate that DEM can accurately perform one step ahead output prediction
on the training data (white background). The green curve following the trend of the red curve demonstrates that DEM can perform 150
step ahead output predictions on unseen data (grey background) using the learned model. (b) The parameter estimation step (E step)
explorestheparameterspacetofinallyconvergetoasolutionforA,B andC matrices.(c)PerceptiondrivenbythemaximizationofF¯.
measurements (optitrack). A low process noise hyperparam- Fig. 6c shows the maximization of F¯ during perception.
eter(λw =3)wasusedwithhighconfidence(Pλw =e20)to
F. Metric for comparison
represent high process noise emerging from wind and non-
linearityerrors.ThenoiseswereassumedtohaveaGaussian We measure the quality of output prediction using the
temporal correlation with a noise smoothness of s = dt for Mean Squared Prediction Error (MSPE) for 150 step ahead
alltheexperiments.Tohandlecolorednoise,thegeneralized predictions on unseen test data:
coordinatewasusedwithanorderofgeneralizationforstates
T+150
1 (cid:88)
and inputs as p = 2 and d = 1 respectively. DEM used the MSPE = (y −yˆ)2, (14)
150 i i
same settings to process all data.
i=T+1
where y is the measured output and yˆ is the output
E. Output prediction using DEM i i
predictionattimestepi.Ahighqualityperceptionalgorithm
The robot brain’s perception of a quadrotor hovering in
will have the least MSPE when compared to other methods.
windwasemulatedusingtheDEMalgorithm.Thequadrotor
modelwaslearnedbymaximizingF¯ usingtheexperiment2
dataandtheresultisshowninFig.6.Theparameterestima- G. Importance of generalized coordinates
tion(Estep)explorestheparameterspaceandconvergestoa
The key difference between DEM and other classical
solutionwithinfewiterations(Fig.6b),despitestartingfrom
estimators is its capability to deal with colored noise using
wrong random priors (ηθ) in the range [-1,1]. The learned
the generalized coordinates (GC). In this section, we show
model is tested for one step ahead output prediction on the
thattheuseofgeneralizedcoordinatesimprovestheaccuracy
trainingdata,andforoutputpredictionsuntil150stepahead
of output prediction of a quadrotor flying in wind. We
on the test data. The coinciding predictions and measured
repeat the same procedure in Section V-E for two different
output in Fig. 6a demonstrates DEM’s successful model conditions: 1) output prediction with GC (p = 2) and 2)
learningforoutputprediction,bothonseenandunseendata. without GC (p = 1). Fig. 8 demonstrates that the use of
Fig. 7: The autocorrelation plot of process noise
(wφ˙
) for all five Fig. 8: The output prediction of DEM on the test data improves
experimentsdoesn’tdropwithintheconfidenceboundimmediately when GC is used during perception. The green curve follows the
after zero lag, confirming the presence of a range of noise color. trend of the red curve better than the yellow curve.
(a)Benchmarkingoutputprediction. (b)Then-stepaheadpredictionerror. (c)MSPEforfivequadrotorexperiments.
Fig.9:TheparameterlearningusingDEMisbenchmarkedagainstothersystemidentificationmethods-PEM,SSandEM.(a)Theoutput
predictions of DEM (green curve) for experiment 2 on the unseen test data (grey background) best follows the trend of the measured
output (red curve) when compared to other methods. (b) The corresponding n-step ahead output prediction error is the lowest for DEM
(green curve) for most cases. (c) DEM outperforms other methods with the best quality output prediction by minimizing MSPE for all
five experiments, thereby demonstrating that DEM is a very competitive algorithm.
GC provides a better output prediction than when no GC I. Extended DEM for black-box estimation
was used. MSPE was used to measure the quality of output
The previous sections use the known inputs, outputs and
prediction for all five flight experiments for both conditions
model order for the output prediction, which differs from
(withandwithoutGC),andtheresultsaretabulatedinTable
the biological brain’s perception that do not have access to
II. The results show a lower MSPE for DEM with GC
the real inputs and model order. Therefore, in this section
when compared to DEM without using GC, revealing the
weunleashthefullcapabilityofDEMwithunknowninputs,
importance of using GC for output prediction.
andthenextenditbyproposingafreeenergyobjectivebased
TABLE II: INFLUENCE of GC on MSPE. schemetoevaluatethemodelorderforblackboxestimation.
SinceF¯ isthesumofpredictionerrorsforx˜,v˜,θ andλand
expt1 expt2 expt3 expt4 expt5 total
their entropies, it is intuitive for the correct model order (or
DEMwithoutGC 0.1197 0.0640 0.1647 0.0518 0.0951 0.4953 above)tomaximizeF¯.Inthissection,wetestthishypothesis
DEMwithGC 0.0521 0.0133 0.0583 0.0458 0.1172 0.2867
for quadrotor flights.
We consider the linearlized model of the quadcopter
H. Benchmarking dynamics given in [25] to derive 4 different LTI systems as
In this section, we will show that DEM outperforms giveninTableI.Allsystemsareobservableandcontrollable,
otherclassicalestimatorsfromcontrolsystemswiththeleast and use motor pwm signals as the input. y, y˙ φ and φ˙
MSPE for five quadrotor flight experiments in wind. The were selected as states since they are the most influenced by
estimators under consideration are Prediction Error Mini- the wind in y direction, thereby generating colored process
mization (PEM), Subspace method (SS) and Expectation noise in data. We use the same algorithm setup in Section
Maximization(EM).TheSystemIdentificationtoolboxfrom V-D except for an additional constraint for unknown input
MATLAB was used for SS (n4sid()) and PEM (pem()) (ηv =0withlowprecisionPv =e2),torunDEMforallfive
methods,whereasanEMalgorithmimplementationforstate experiments. The converged values of F¯ for all experiments
spacemodelwaswrittenbasedon[26].PEMwasinitialized
using the solutions of SS. The data from experiment 2 was
used to learn the state space model of the quadrotor for
all methods. Fig. 9a shows the results of the n step ahead
output prediction on the unseen test data (grey background)
using the model learned by all methods. All predictions
tend to follow the trend of the measured output (red curve).
The prediction accuracy of different methods in Fig. 9a
is visualized in Fig. 9b using the n step ahead squared
prediction error. It can be observed that DEM outperforms
othermethodswiththeleastpredictionerroronunseendata.
MSPE was used as the evaluation metric to compare the
performance of DEM with other methods on all five flight Fig. 10: The average F¯ of five experiments for different model
data,andtheresultsareshowninFig.9c.DEMoutperforms orders.F¯ saturateswhentherobotbrain’smodelordermatchesthe
othermethodsforallfiveexperimentswithminimumMSPE real system order (4 for blue, 3 for red, 2 for yellow and 1 for
on unseen test data. violet).
were recorded by assuming a model order of 1,2,3 and 4 for REFERENCES
allsystems.TheaverageF¯ offiveexperimentswithdifferent
[1] K.Friston,“Thefree-energyprinciple:aunifiedbraintheory?”Nature
model orders for all four systems is shown in Fig. 10. F¯ reviewsneuroscience,vol.11,no.2,pp.127–138,2010.
saturates when the model order matches the system order, [2] K. Friston and S. Kiebel, “Predictive coding under the free-energy
proving that F¯ is an indicator for model order selection. principle,”PhilosophicaltransactionsoftheRoyalSocietyB:Biolog-
icalsciences,vol.364,no.1521,pp.1211–1221,2009.
We use this idea to extend the original DEM algorithm for [3] K. Friston, “Hierarchical models in the brain,” PLoS computational
complete black box estimation as given in Algorithm 1. It biology,vol.4,no.11,p.e1000211,2008.
[4] K.Friston,J.Mattout,andJ.Kilner,“Actionunderstandingandactive
generates an internal model via free energy maximization to
inference,”Biologicalcybernetics,vol.104,no.1,pp.137–160,2011.
estimate x˜,v˜,θ,λ and nx that best explains the data. [5] K. J. Friston, N. Trujillo-Barreto, and J. Daunizeau, “DEM: a varia-
tionaltreatmentofdynamicsystems,”Neuroimage,vol.41,no.3,pp.
849–885,2008.
Algorithm 1: Extended DEM - black box estimation [6] K. Friston, “The free-energy principle: a rough guide to the brain?”
Initialize priors η ={ηv,Pv,ηθ,Pθ,ηλ,Pλ}; Trendsincognitivesciences,vol.13,no.7,pp.293–301,2009.
[7] K. J. Friston, J. Daunizeau, J. Kilner, and S. J. Kiebel, “Action and
Initialize brain’s model order nx =0 ; behavior:afree-energyformulation,”Biologicalcybernetics,vol.102,
while F¯ not converged do (cid:46) model order no.3,pp.227–260,2010.
b
Initialize a←−1 and F¯ ←−−∞; [8] T. Parr, N. Sajid, L. Da Costa, M. B. Mirza, and K. J. Friston,
a “Generative models for active vision,” Frontiers in Neurorobotics,
nx ←−nx+1; (cid:46) increment model order vol.15,p.34,2021.
while θ not converged do [9] R. L. Carhart-Harris and K. J. Friston, “The default-mode, ego-
for t = 0:∆t:T do functions and free-energy: a neurobiological account of freudian
ideas,”Brain,vol.133,no.4,pp.1265–1283,2010.
x˜(t),v˜(t)←− D STEP(y˜(t),θ,λ,nx,η); [10] K.J.Friston,J.Daunizeau,andS.J.Kiebel,“Reinforcementlearning
end oractiveinference?”PloSone,vol.4,no.7,p.e6421,2009.
while λ not converged do [11] C. L. Buckley, C. S. Kim, S. McGregor, and A. K. Seth, “The free
energy principle for action and perception: A mathematical review,”
λ←− M STEP(y˜,x˜,v˜,θ,λ,nx,η) ; JournalofMathematicalPsychology,vol.81,pp.55–79,2017.
end [12] A. A. Meera and M. Wisse, “Free energy principle based state and
F¯ ←−Equation (13) (cid:46) F¯ at optimal precision inputobserverdesignforlinearsystemswithcolorednoise,”in2020
a AmericanControlConference(ACC). IEEE,2020,pp.5052–5058.
if F¯ a >F¯ a−1 then (cid:46) update θ if F¯ increased [13] M. Baltieri and C. L. Buckley, “Pid control as a process of active
θ ←− E STEP(y˜,x˜,v˜,θ,λ,nx,η) ; inference with linear generative models,” Entropy, vol. 21, no. 3, p.
257,2019.
end
[14] G. Oliver, P. Lanillos, and G. Cheng, “Active inference body
a←−a+1 ; perception and action for humanoid robots,” arXiv preprint
end arXiv:1906.03022,2019.
F¯ =F¯ ; [15] C.Pezzato,R.Ferrari,andC.H.Corbato,“Anoveladaptivecontroller
b a−1 forrobotmanipulatorsbasedonactiveinference,”IEEERoboticsand
end AutomationLetters,vol.5,no.2,pp.2973–2980,2020.
[16] O. C¸atal, T. Verbelen, T. Van de Maele, B. Dhoedt, and A. Safron,
“Robotnavigationashierarchicalactiveinference,”NeuralNetworks,
vol.142,pp.192–204,2021.
VI. CONCLUSIONS
[17] F. Bos, A. Anil Meera, D. Benders, and M. Wisse, “Free energy
Robust algorithms for robot perception is still an open principleforstateandinputestimationofaquadcopterflyinginwind,
Underreview,”2021.
challenge, which could be solved by a brain-inspired algo-
[18] A. Anil Meera and M. Wisse, “Dynamic expectation maximiza-
rithm. We take a step towards applying one such method tion algorithm for estimation of linear systems with colored noise
(DEM) to real robots. We introduced a DEM based percep- (Underreview),”2021.
[19] ——, “On the convergence of dem’s linear parameter estimator,
tion and system identification scheme for accurate output
Accepted,”inInternationalWorkshoponActiveInference,2021.
predictionsduringuncertainties(unmodelleddynamics),and [20] L. Ljung, “System identification,” in Signal analysis and prediction.
validated it through real experiments on a quadcopter. We Springer,1998,pp.163–173.
[21] Y. Zhang, “Unbiased identification of a class of multi-input single-
demonstrated its superior performance through its minimum
outputsystemswithcorrelateddisturbancesusingbiascompensation
MSPEfor150stepaheadoutputprediction,whencompared methods,”MathematicalandComputerModelling,vol.53,no.9-10,
toestimatorslikeSS,PEMandEM.Theusefulnessofgener- pp.1810–1819,2011.
[22] X. Liu and J. Lu, “Least squares based iterative identification for a
alized coordinates in providing additional (derivative) infor-
classofmultiratesystems,”Automatica,vol.46,no.3,pp.549–554,
mation for estimation during unmodelled dynamics (wind) 2010.
was demonstrated through the decrease in MSPE. Based on [23] W.X.Zheng,“Onaleast-squares-basedalgorithmforidentificationof
stochastic linear systems,” IEEE Transactions on Signal Processing,
the results, the original DEM algorithm was extended for
vol.46,no.6,pp.1631–1638,1998.
modelorderselectionduringcompleteblackboxestimation. [24] Y. Zhang and G. Cui, “Bias compensation methods for stochastic
The main disadvantage of DEM is it’s higher computational systemswithcolorednoise,”AppliedMathematicalModelling,vol.35,
no.4,pp.1709–1716,2011.
complexity induced by generalized coordinates. Moreover,
[25] D.Benders,“Ar.drone2.0stateestimationusingdynamicexpectation
the noise smoothness needs to be known apriori. The future maximization: Bringing brain perception theory to practice,” Master
research will address these issues. thesis,TUDelft,2020.
[26] F.J.Cara,J.Juan,andE.Alarco´n,“Usingtheemalgorithmtoestimate
ACKNOWLEDGMENT thestatespacemodelforomax,”Inpractice,vol.1000,no.1J,p.3,
2014.
We would like to thank Dennis Benders for his involve-
ment in the data acquisition, as a part of his masters thesis.