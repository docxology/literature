Markov Blanket Density and
Free Energy Minimization
Luca M. Possati
July 2025
Abstract
This paper introduces a novel geometrical framework for understanding the con-
ditions under which the Free Energy Principle (FEP) can be meaningfully applied.
Departing from formulations that treat the FEP as a universal variational imper-
ative governing all self-organizing systems, we define a spatially continuous field
called the Markov Blanket Densityρ(x) ∈ [0, 1]. This quantity measures, at each
point in a spatial domain Ω ⊂ Rn, the degree of conditional independence be-
tween internal and external states given a local blanket. Rather than assuming
the existence of a Markov blanket as a binary structural feature of the system, we
treat conditional independence as a graded and spatially variable property. We
show that the standard components of the FEP—including generative modeling,
variational inference, and action as free energy minimization—are only definable
in regions whereρ(x) < 1, i.e., where conditional independence fails and mutual
information across the internal-external divide remains non-zero. In regions where
ρ(x) = 1, no inferential coupling is possible, and the variational free energy becomes
ill-defined or vacuous. This implies that the FEP is not a general law but a locally
valid phenomenological regularity, contingent on the informational geometry of the
environment. The model introduces a differential-geometric structure on the infor-
mational fieldρ(x), defining an information-theoretic metric, a Laplacian curvature
operator, and a log-transformed free energy landscape. In this setting, epistemic
dynamics are reinterpreted as gradient flows onρ(x), and agent behavior becomes a
response to informational topography. This approach provides a new foundation for
the FEP as a situated, spatially constrained phenomenon, and offers a principled
framework for modeling inference in distributed, multi-agent, or weakly bounded
systems where classical blanket structures are unstable or undefined. The result is a
shift in the explanatory architecture of the FEP: from a foundational principle im-
posed on all systems, to an emergent regime of behavior permitted by the structure
of the environment. We argue that this reframing offers a more falsifiable, flexible,
and geometrically grounded interpretation of inference and self-organization, with
implications for formal epistemology, situated cognition, and the design of epistemic
systems in both natural and artificial contexts.
1 Introduction
The Free Energy Principle (FEP) provides a powerful framework to understand how
agents (i.e., self-organizing systems such as living systems) maintain their structure by
minimizing variational and expected free energy [1, 2, 3, 4, 9, 20, 31, 37]. Central to FEP
is the Markov blanket, traditionally viewed as a discrete boundary separating internal
states from external environmental states. However, this binary view limits our ability
to model nuanced interactions and spatial dynamics.
In this paper, we introduce "Markov blanket density" as a continuous scalar field
quantifying the degree of conditional independence between internal and external states
at every spatial point relative to an observer and their scale of observation. Blanket
strength is thus measured by how effectively bkanket states mediate interactions, struc-
turing space into continuous gradients of coupling. Preferred states become regions of
optimal coupling rather than purely internal homeostatic targets. Although the fun-
damental idea—that agents naturally move towards regions of lower Markov blanket
1
arXiv:2506.05794v5  [q-bio.NC]  8 Aug 2025
density (greater coupling)—is intuitive, the paper offers originality through: (a) Shifting
from discrete partitions to a continuous scalar field, allowing nuanced spatial modeling;
(b) Rigorous mathematical formalization capturing precise, verifiable dynamics through
spatial gradients; (c) Practical applicability, providing a robust framework for empirical
predictions and novel simulations.
We think that classic active inference fails to properly account for the spatial di-
mension, collapsing it into a notion of space as an empty, passive, and predictable “en-
vironment.” In doing so, active inference cannot fully grasp the concept of affordance,
reducing it to a set of predictions about the environment. Essentially, active inference
remains captive to a lab-based perspective, where space adapts to hypotheses rather than
hypotheses adapting to space. The point is that space is complex, as are affordances.
The very unity of perception and action depends on that complexity.
Through detailed mathematical analysis, this paper demonstrates how free energy
minimization dynamics depend on variations in Markov blanket (MB) density, including
scenarios that invert typical inference dynamics. By bridging ecological and embodied
perspectives with formal variational inference, this work advances our understanding of
the embodied mind as actively embedded within dynamically structured informational
environments. The purpose of this paper is to introduce an informational geometry of
inferential space: not only “what an agent does,” but “where it does it,” how much it can
infer, at what speed, and with what access to information. The central thesis is that
the FEP should not be treated as a universal law, but rather as an emergent regime of
behavior permitted by the geometry ofρ(x). We formalize this framework by construct-
ing an informational metric, a free energy landscape defined via log-transform ofρ(x),
and a dynamic formulation in which agent trajectories follow informational gradients.
This reinterpretation positions the FEP not as a principle to be imposeda priori, but as
a local affordance of the informational structure of the environment—one that may fail
to hold, shift over time, or vary across systems. In so doing, we aim at extendind the
explanatory power of the FEP to a broader class of systems, including weakly bounded
agents, distributed cognitive architectures, and informationally heterogeneous environ-
ments. Our aim is not to reject the FEP, but to recover it as a special case within a more
general geometric and epistemic framework—one that better accommodates the spatial,
graded, and context-sensitive nature of real-world inference. In other words, the FEP
emerges as a local property of regions with good informational permeability.
As regards the structure of this paper, Section 2 introduces some key concepts from
active inference and the notion of the Markov blanket. Section 3 introduces the central
thesis of the paper, connecting it to existing literature and offering several conceptual
clarifications. Beginning with Section 4, the mathematical framework is laid out. A clear
definition of Markov blanket density is provided, followed by an operational definition
in Section 4.4—namely, an algorithm for identifying and computing the Markov blanket
density at each point in a hypothetical space. Three theorems (Sections 5–9) follow,
illustrating the relationship between free energy minimization and Markov blanket den-
sity. Sections 10–11 present a fourth theorem, which demonstrates how the temporal
evolution of free energy minimization depends on and is continually modulated by the
Markov blanket density. Section 12 addresses the problem of how an active inference
agent learns the space and how Markov blanket density is incorporated into the agent’s
inferential dynamics. Section 13 offers a complete axiomatic derivation of the Markov
blanket density concept, showing how the FEP can be seen as a local emergent effect of
this density.
Throughout the paper, a series of figures illustrates the results of various simulations.
The appendices cover technical details.
2 The Free Energy Principle
2.1 A basic outline
The FEP is a mathematical framework rooted in statistical physics, information theory,
and variational inference techniques from machine learning [9, 22]. It provides a unifying
account of self-organizing systems by interpreting their dynamics in terms of the mini-
2
mization of variational free energy. In particular, consider a random dynamical system
that satisfies the following conditions:
• it exhibits a degree of ergodicity, allowing time-averaged behavior to approximate
ensemble statistics;
• it possesses a pullback attractor, that is, a set of states toward which the system
tends over time — its "preferred" or most frequently occupied states;
• it admits an ergodic density that probabilistically characterizes long-term state
occupancy; and
• it maintains a degree of separation from its environment, such that internal and
external states can be distinguished (e.g., via a Markov blanket structure).
Under these assumptions, the system’s behavior can be interpreted as performing approx-
imate Bayesian inference by minimizing a quantity known as variational free energy. In
this context, the flow of states (e.g., internal states, active states) follows a gradient de-
scent on variational free energy, which serves as an upper bound on the system’s surprisal
(or self-information, see Table 1) about its sensory states. That is, even in the absence
of an explicit model, the system behaves as if it were inferring the causes of its sensory
inputs and acting to maintain itself within a bounded set of preferred states — thereby
resisting disorder and preserving its structural and functional integrity. As mentioned,
Self-information I(x)
Surprise or informativeness of a specific outcomex. High for rare events, zero for certain
ones.
Formal definition: I(x) = −logb p(x), where p(x) ∈ (0, 1] and b is typically 2 (bits),e
(nats), or 10 (Hartleys).
EntropyH(X)
Expected uncertainty or average surprise over all outcomes of a random variableX.
Formal definition:H(X) = −P
x∈X p(x) logb p(x)
Kullback–Leibler divergenceDKL(P ∥ Q)
Information lost when using distributionQ to approximate the true distributionP.
Formal definition: DKL(P ∥ Q) = P
x∈X p(x) logb

p(x)
q(x)

, defined only if p(x) > 0
implies q(x) > 0.
Table 1:Essential definitions of self-information, entropy, and KL divergence used in the FEP
framework.
the FEP is a mathematical modeling framework. It is not a theory seeking empirical val-
idation, but rather a mathematical-physical formalism that can be used to generate new
hypotheses or analyze data. In itself, however, it remains a purely theoretical construct,
without predictive aims.
When applied to living systems (e.g., the brain), the FEP gives rise to what is known
as active inference [30, 9]. In this framework, a living system maintains its structural
and functional integrity by resisting the natural tendency toward disorder—that is, by
remaining within a bounded set of preferred states despite environmental volatility (i.e.,
any living system tends, on average, to move along the gradient that leads toward its
attracting set, i.e., the pullback attractor). To do so, the system must possess a hierar-
chical generative model of the hidden causes of its sensory inputs—a probabilistic model
that is continuously tested and updated through Bayesian inference, i.e., a generative
model. Since exact inference is generally intractable in realistic conditions, the system
performs approximate variational inference: it selects an approximate posterior distri-
bution and updates its parameters iteratively to minimize the divergence from the true
posterior. This optimization process is formally equivalent to maximizing the Evidence
3
Lower Bound (ELBO) in machine learning. The objective of this process is to minimize
a quantity known as variational free energy. Variational free energy serves as an upper
bound on surprisal, or the negative log model evidence, which quantifies how unexpected
sensory inputs are under the model. In formal terms, free energy is decomposed into the
sum of a Kullback–Leibler divergence (between the approximate and true posterior) and
a term representing log evidence (see Table 2). Minimizing free energy thus corresponds
to maximizing model evidence. This process of continuously updating beliefs and ac-
tions to reduce free energy enables the system to maintain coherence and adaptivity in a
changing environment. In this sense, self-organization is reframed as self-evidencing—the
system acts in ways that confirm its own model of the world. Finally, the FEP asserts
that "all biological systems maintain their integrity by actively reducing the disorder or
dispersion (i.e., entropy) of their sensory and physiological states by minimising their
variational free energy" [4].
1. Free energy as a bound on surprise
F(o) ≥ −log p(o)
Free energy upper-bounds the surprisal (negative log model evidence) of sensory input.
Minimizing it helps explain perception as evidence maximization.
2. Free energy as a variational bound
F(q) = KL(q(s) ∥p(s | o)) − log p(o)
Free energy is minimized when the approximate posteriorq(s) matches the true posterior
p(s | o). This is the essence of variational Bayesian inference.
3. Free energy as energy minus entropy
F(q) = Eq[−log p(o, s)] + Eq[log q(s)]
Free energy is the sum of expected prediction error and the complexity of the approximate
posterior. It balances accuracy and complexity.
Table 2:Three equivalent formulations of variational free energy.
It should be emphasized that the recent literature on the FEP and active infer-
ence—from essentially [1, 6, 7, 8, 40]—has introduced and developed a new formulation
of the FEP, shifting from a state-based formulation to a path-based one that no longer
requires the concept of a NESS. In some of the more advanced FEP formulations, it
is shown how the FEP can be derived simply from Jaynes’s principle of maximum en-
tropy or maximum caliber under the constraint that there are boundaries of certain kinds.
These formulations show that the FEP is just maximum caliber with explicit boundaries.
Whereas the classical formulations (Friston 2019) start from the equations of statistical
physics (the Langevin or Fokker–Planck equation) and arrive at an equivalent descrip-
tion of the system in information-theoretic terms (a gradient descent over a free-energy
functional), the more advanced approaches instead begin with maximum caliber to show
how, once boundaries are imposed, it becomes the FEP. This addresses criticisms that
the FEP depends on physical presuppositions (e.g., the NESS).
2.2 Markov blankets
The concept of Markov blanket is crucial in the formulation of the FEP. In fact, "we
assume that for something to exist it must possess (internal or intrinsic) states that can
be separated statistically from (external or extrinsic) states that do not constitute the
thing" [1]. The existence of things implies the existence of Markov blanket, namely, "a
set of states that render the internal and external states conditionally independent" [1].
But what does it mean "separation" here? If the space in which the active inference
agent moves is composed of nested Markov blankets, how the agent passes through these
blankets and their permeability? "States of things are constituted by their Markov
blanket, while the Markov blanket comprises the states of smaller things with Markov
blankets within them – and so on ad infinitum" [1].
A Markov blanket is “a statistical partitioning of a system into internal states and
external states, where the blanket itself consists of the states that separate the two” [7, 1].
The Markov blanket divides the system into three groups of statistical variables: internal
states, external states, and blanket states. As Friston claims, “the dependencies induced
4
by Markov blankets create a circular causality that is reminiscent of the action-perception
cycle” [1]. Circular causality here means that “external states cause changes in internal
states, via sensory states, while the internal states couple back to the external states
through active states, such that internal and external states influence each other in a
vicarious and reciprocal fashion” [1]. Consequently, the internal and external states tend
to synchronize over time (i.e., coupling), much like two pendulums attached to opposite
ends of a wooden beam gradually swinging in unison.
The Markov blanket thus allows a certain statistical boundary to be defined between
internal states and external states, which are mediated solely by active states and sensory
states [38]. This means that, given the Markov blanket—that is, the sensory and active
states—the internal and external states are conditionally independent. In other words,
once the blanket is known, knowing additional information about the external states does
not further constrain or inform the internal states. This structure ensures that internal
and external states remain independent while being connected only through the active
and sensory states. Active and sensory states “shield” the internal states by creating
a statistical boundary [2, 5, 6, 7]. Put simply, internal states cannot directly affect
external states but can do so indirectly by influencing active states. Likewise, external
states cannot directly impact internal states but can do so indirectly by affecting sensory
variables (see Table 3).
Free energy is a functional—that is, a function of a function—that quantifies the
probability distribution encoded by the internal states of the system. Importantly, this
differs from surprise, which is a function of the sensory and active states on the Markov
blanket itself. Put differently: free energy is a function of probabilistic beliefs (i.e.,
internal states) about external states—that is, expectations about the likely causes of
sensory input. When these beliefs match the true Bayesian posterior, variational free
energy becomes equal to surprise. Otherwise, it serves as a tractable upper bound on
surprise. This is why self-organizing systems can be characterized as minimizing varia-
tional free energy, and thereby minimizing surprise, through the continuous optimization
of their beliefs about what lies beyond their Markov blanket. Finally, the FEP tells us
"how the quantities that define Markov blankets change as the system moves towards its
variational free energy minimum" [4].
Element Symbol Description
Internal states I Hidden states of the system that encode beliefs about ex-
ternal causes; not directly influenced by external states.
External states E States in the environment that influence sensory states but
are not directly influenced by internal states.
Sensory states S States that receive input from external states and influence
internal states; part of the Markov blanket.
Active states A States influenced by internal states that act upon external
states; part of the Markov blanket.
Markov blanket B = S ∪ A The boundary of the system that mediates interactions
between internal and external states through sensory and
active channels.
Conditional independence — Given the blanketB, internal and external states are con-
ditionally independent: p(I, E| B) = p(I | B) p(E | B).
Table 3:Formal components of a Markov blanket in active inference.
3 The Space as a Continuous Gradient of Markov Blan-
ket Strengths
In this section we introduce the central philosophical thesis of this paper. In the following
one we develop a formal demonstration. It all stems from a rather naive and abstract
question: What would a space be like if every point were composed of internal and external
5
states, i.e. had a Markov blanket? And how would an agent with a blanket of their own
move in this space?
Free energy minimization is generally described in temporal terms: “Strictly speak-
ing, free energy is only ever minimized diachronically—that is, over some discrete time
span—as a process” [2]. What role does space play in this process? The space through
which an active inference agent moves is not an empty or uniform container—it is instead
a structure composed by nested Markov blankets: “[...] we should be able to describe
the universe in terms of Markov blankets of Markov blankets—and Markov blankets all
the way up, and all the way down” [2]. The key issue is how we conceptualize Markov
blankets and the statistical boundaries they define.
Classic works on active inference fails to properly account for the spatial dimension,
treating space as a passive and predictable “environment.” By doing so, it cannot fully
grasptheconceptofaffordance, reducingittoasetofpredictionsaboutthatenvironment.
In this view, affordances are not inherently part of the environment itself; they depend on
the predictions and knowledge of the agent interacting with it. In active inference, space
plays no active role in shaping the agent’s trajectories—and this is not compatible with
Gibson’s view of affordance [29]. In essence, active inference remains confined to a lab-
based perspective, where space adapts to hypotheses rather than hypotheses adapting to
space. The point is that space is complex, as are affordances—they cannot be reduced to
the agent’s predictions. Affordances “are not simply static features of the environment,
independent of the presence and engagement of an agent, nor are they states of the
cognitive agent alone” [28]. The very unity of perception and action depends on that
complexity. In a nutshell,space is not entirely predictable, and above all, space shapes
and distorts our predictions. As we hope to show, since the blanket-density factor directly
modulates how strongly sensory evidence can update internal beliefs (and therefore the
generative model), it does in effect “shape” the model the agent uses.
At this point, the next question becomes: How can we reconceptualize space indepen-
dently of an agent’s predictions, that is, its generative model? The hypothesis we want to
propose and test here is that the space inhabited by active inference agents is populated
with Markov blankets that can vary (along a spectrum) in their degree of permeability
or porosity—that is, Markov blankets that are more or less “strong,” exhibiting higher
or lower degrees of separation relative to an observer and their scale of observation. The
strength of a Markov blanket (i.e., how well the blanket insulates the inside) is the degree
to which it enforces conditional independence between internal and external states, via
the mediating sensory and active states. Therefore, the space is structured by a continu-
ous gradient of Markov blanket strengths. From this spatial perspective, preferred states
can be reinterpreted as configurations of optimal coupling—zones of dynamic synchro-
nization with other Markov blankets—rather than purely internal homeostatic targets.
Thus, from this perspective, every point in the space through which the active in-
ference agent moves is associated with a Markov blanket that separates internal and
external variables. Based on this, we define the Markov blanket density, which varies
continuously, like a spectrum, and quantifies the local degree of informational isolation
between those internal and external variables.
3.1 Connection to the Literature
This paper builds on some findings from previous literature and aims to unify and extend
them.
[7] advances the FEP by translating its abstract notions of conditional independence
and “things” into a concrete, unsupervised learning algorithm. Recognizing that any
identifiable object must correspond to a partition—internal, boundary, external—their
variational Bayesian expectation maximization framework treats each microscopic ele-
ment as governed by one of several low dimensional latent processes. During inference,
elements are dynamically assigned to roles by maximizing an ELBO, and a “Bayesian
attention” mechanism tracks how the inferred boundary can move, split, or merge over
time. Through case studies as diverse as Newton’s cradle, a propagating combustion
front, and the Lorenz attractor, they demonstrate that their method reliably uncovers
the intuitive interfaces that simplify a system’s macroscopic description. See also [5, 6].
6
[8] complements this algorithmic advance with a rigorous, asymptotic guarantee for
the existence of blankets in high-dimensional stochastic systems. By defining a “blan-
ket index” to measure the strength of cross-couplings between internal and external
variables, the paper models these interactions as independent, bounded random vari-
ables and employs large-deviation techniques to show that, as the system’s dimension
grows without bound, almost all such couplings vanish. This result proves that “weak”
Markov blankets—where conditional independence holds up to vanishingly small interac-
tions—emerge almost surely in the infinite-dimensional limit, thereby grounding Friston’s
sparse-coupling conjecture in a broad class of Itô stochastic differential equations. While
this theorem confirms that blankets are not an ad hoc or exceptional phenomenon but
a generic feature of complex systems, it remains silent on how to measure the varying
strengths of these blankets in finite, real-world settings or how they might steer an agent’s
behavior. On Bayesian mechanics, see also [26, 27].
The present paper is also related to [1]. Both works share the same foundational
insight: any system at a non-equilibrium steady state can be partitioned into internal,
sensory, active, and external components via a Markov blanket, and internal states ap-
pear to perform Bayesian inference by minimizing variational free energy. However, while
Friston treats this boundary as a sharply defined, discrete set of sensory and active vari-
ables that uniformly insulates internal states from external states—demonstrating how
this partition underlies phenomena from quantum dynamics through classical stochastic
processes to living systems—the present paper explicitly extends this approach by al-
lowing that “insulating” effect to vary continuously across space. In other words, where
Friston envisions a crisp frontier separating inside and outside, the present research pro-
poses a continuous scalar field that quantifies, at each location, how strongly internal
and external states are decoupled. This permits intermediate regions where external
influences partially penetrate, rather than assuming each point is either fully inside or
fully outside the Markov blanket.
However, the present research does not stop at proposing this shift in perspective;
it also provides a concrete algorithmic recipe—based on information-theoretic estima-
tors and nearest-neighbor sampling—to measure local blanket strength from observed
data. In contrast, Friston’s treatment, although highly ambitious and formally rich
across multiple scales, remains largely conceptual with regard to how one might detect
or manipulate the blanket in real systems. Specifically, Friston [1] illustrates his theory
with idealized “active soup” simulations and outlines the mathematical links between
free energy, steady-state densities, and inference, but he does not detail how to estimate
blanket strength in, for example, a spatially extended neural system or an agent navi-
gating a heterogeneous environment. By combining these two perspectives, the present
research neither contradicts nor undermines Friston’s core theorems regarding a discrete
Markov blanket. Rather, by embedding Friston’s boundary within a gradient of insulat-
ing strength, it shows how free-energy minimization can be modulated by local variations
in coupling between internal and external states. In this view, agents naturally gravitate
toward regions where coupling is strongest—where the blanket is weakest—because those
regions offer richer sensory information. However, this also means that the MB density
imposes limits on free energy minimization. In summary, the present paper takes Fris-
ton’s high-level, multiscale framework and gives it concrete spatial texture: showing how
blanket strength can ebb and flow across space and, in turn, shape an agent’s inferential
and behavioral trajectories.
3.2 Some clarifications
We use here the term "coupling" to describe the degree of statistical and causal in-
terdependence between an agent and its environment. This is formalized in terms of
conditional mutual information, but also interpreted dynamically: strong coupling im-
plies that the agent’s sensory states carry information about external causes, and that
its actions can affect those causes. In our model, low MB density corresponds to higher
potential for coupling, which in turn enables more effective free energy minimization.
This is perfectly in line with [1].
However, we acknowledge that this use of "density" introduces a metaphorical shift:
7
we are interpreting space not as geometrically partitioned, but as structured by the sta-
tistical architecture of interaction. This raises ontological and epistemological questions.
Is MB density a real property of physical space, or is it a modeling construct used to
represent the agent’s epistemic relation to its surroundings? In this paper, we remain
agnostic: we treat MB density as a tool for expressing how the spatial environment
constrains inferential dynamics, rather than making strong claims about its physical in-
stantiation. We steer clear of the more strictly philosophical debates on the ontological
implications of the concept of Markov blankets [38]—at least, from my point of view,
Markov blankets are good modelling tools, but at the same time, they are onlygood
heuristics. This doesn’t mean avoiding philosophical debates about the relationship be-
tween the map (Markov blankets) and the territory (reality) — quite the opposite, in
fact. It means recognizing the importance of the problem (beyond an armchair philos-
ophy approach), and therefore focusing first on the robustness of the map and what we
can do with it — a necessary condition for understanding its relationship to the territory,
especially since the map is itself part of the territory. And we are also convinced that
(unlike [40]) instrumentalism does not necessarily imply blind belief in the usefulness of
the model—quite the contrary, in fact.
Morover, MBdensityinitselfisnotaprobabilitydensity. MBdensityisaninformation-
theoretic measure (ranging from 0 to 1) of how effectively an agent’s boundary blocks
information flow between its internal and external states at a point x, estimated via con-
ditional and unconditional mutual informations. It is not normalized over the state space
and directly modulates the speed of gradient-descent on free energy (when MB density
= 1, updates freeze). By contrast, a probability density p(x) is a normalized function
(integrating to one) that assigns relative likelihoods to values of x, without any notion
of informational blocking or direct influence on free-energy descent.
The MB densityρ(x) is a modeling index of local informational shielding, not a prob-
ability density; it modulates dynamics via˙x = −(1 − ρ(x)) ∇F(x). Because conditional
mutual information can exceed mutual information in the presence of synergy, the raw
ratio
ρraw(x) = 1 − I(I; E | B)
I(I; E) + ε
may fall outside [0, 1]. Operationally, we adopt an ε > 0 for numerical stability and
clip estimates toρ(x) ∈ [δ, 1 − δ] during inference (Algorithm 1, Sec. 4.5), ensuring a
well-defined mobility factor while preserving the statistical meaning of the ratio. An
extended exploratory variant lifts the clipping and allowsρ >1, which flips the sign of
the prefactor and induces local ascent ofF (see Sec. 10).
Another important caveat. The paper never claims that the agent “tends toward a
point where MB density = 0” (i.e., complete elimination of any boundary). When it
says that free-energy minimization follows trajectories into regions of low MB density,
it really means cases where the MB density is reduced but not zero: in those regions,
the blanket is “thin” enough to allow faster information exchange between internal and
external states, speeding up the descent of free energy. That does not imply that the
agent is drifting toward entropy and dissipation. The agent’s skill is precisely in staying
in areas where MB density is high enough to maintain its internal structure, yet not
so high as to block necessary coupling. Consequently, there is no contradiction in the
paper’s thesis. Low MB density means the blanket is just enough to separate internal and
external states, but weak enough to permit rapid information flow such that free-energy
descent is effective; by contrast, MB density = 0 is a theoretical limit where the blanket
no longer exists, and at that point the model no longer describes adaptive behavior but
instead total informational extinction (i.e., the agent dissolves). Moving into regions of
low MB density does not automatically cause an overall increase in entropy. In the free-
energy minimization framework, “low MB density” simply means that the information
boundary between agent and environment is more “porous,” allowing the internal state
to update more quickly based on sensory data. That does not equate to a loss of internal
order or a slide into chaos. Again, this is perfectly in line with [1]. In fact, "nearly every
system encountered in the real world is self-organizingto a greater or lesser degree" [1].
8
4 Thesis
We aim to demonstrate the following claim:
Free energy minimization tends to follow trajectories leading toward regions of lower
MB density. These regions correspond to stronger agent-environment coupling and greater
synchronization potential.
4.1 Definitions and Assumptions
Let Ω ⊂ Rn denote a spatial domain.
For each point x ∈ Ω, assume the presence of a local Markov blanketB(x) that
mediates interactions between internal statesI, external statesE, and blanket statesB.
Define theMarkov blanket strengthat pointx as:
S(x) := 1 − I(I; E | B)
I(I; E) (1)
where I(I; E | B) is the conditional mutual information between internal and external
states given the blanket.
This yields:
• S(x) = 1: perfect conditional independence (strong MB).
• S(x) = 0: no conditional independence (no effective MB).
Informational separation is at its highest degree when
I(I; E | B) = 0,
that is, when, onceB is known, knowing further details aboutE does not help to inform
I.
Define theMarkov blanket (MB) densityρ(x) as the field of MB strengths over
Ω:
ρ(x) := S(x), ρ (x) ∈ [0, 1] (2)
This field quantifies how insulated each point in space is with respect to internal-external
separation.
4.2 Clarification on Continuous MB Density vs. Discrete Condi-
tional Independence
A potential concern is that our MB densityρ(x), defined as a continuous scalar field,
might be conflated with the classical, discrete property of conditional independence.
We resolve this by distinguishing carefully between thestructural and the quantitative
aspects, and by invoking precise measure-theoretic language and manifold geometry.
4.2.1 Measurability and Measure-Theoretic Foundations
Let (Ω, F, P) be a probability space and let I, E, Bbe random variables with joint
distribution absolutely continuous w.r.t. Lebesgue measure on a parameter manifoldX.
By the Radon–Nikodym theorem there exists a density
p(i, e, b| x) = dP
dλ (i, e, b| x) for almost everyx ∈ X.
Define thetotal and residual mutual informations atx by
Itot(x) =
ZZ
p(i, e| x) ln p(i, e| x)
p(i | x) p(e | x) di de,
Ires(x) =
ZZZ
p(i, e, b| x) ln p(i, e| b, x)
p(i | b, x) p(e | b, x) di de db.
9
Since each is an integral functional of measurable densities, bothItot(x) and Ires(x) are
themselves measurable functions ofx, defined for almost everyx ∈ X. We then introduce
ρ(x) = 1 − Ires(x)
Itot(x), 0 ≤ ρ(x) ≤ 1, (1)
with all equalities understood to holdalmost everywhere (i.e., off a P–null set where
Itot(x) = 0).
Importantly, the discrete Markov blanket remains the primary structural object
enforcing
I ⊥E | B ⇐⇒ p(I, E| B) = p(I | B) p(E | B).
Only after specifying that blanket and computing the integrals above do we obtain the
scalar summaryρ(x). In the limiting cases,
Ires(x) = 0 =⇒ ρ(x) = 1, I res(x) = Itot(x) =⇒ ρ(x) = 0,
recovering perfect separation or total coupling, respectively, but never conflating struc-
ture with measure.
4.2.2 Geometry of the Underlying State Space
We regardX as thestatistical manifoldof our generative model. Explicitly,
x ∈ X ⇐⇒ x parametrizes p(i, e, b| x).
Equipped with a Fisher–Rao metric (or any smooth atlas compatible with the densities),
ρ(x) becomes a smooth scalar field onX.
In applications wherex denotes a point inphysical space, one first constructs a local
kernel approximation
p(i, e, b| x) = 1
|B(x, r)|
Z
B(x,r)
p(i, e, b| y) dy,
and then applies the same definitions. Thusρ(x) may equally be viewed as a field on a
physical manifold, provided the generative kernel is smooth.
4.2.3 Key Takeaways
• ρ(x) is a measurable function on X (a.e.), derived from well-defined integrals
(Radon–Nikodym, Lebesgue differentiation).
• Itquantifiesthe degree of conditional independence enforced by a classical Markov
blanket; it doesnot redefine or replace that structural concept.
• Its domain is a statistical manifold of model parameters (or, via kernel lifts, a
physical manifold).
• In the discrete limitρ ∈ {0, 1}, one recovers the ordinary, binary Markov blanket.
4.3 Local vs Regional ρ(x) Interpretations
Two clarifications are in order regarding the apparent tension between the local definition
of blanket density and its regional or global usage in the simulations.
First, thediscrepancyisonlyconceptualandresultsfromthedualperspectiveadopted
in this work. On the one hand, the agent’s behavior is analyzed from the point of view
of the environment: here, the space (and the field ρ(x)) is taken as given — which
is standard in most dynamical models, where the landscape precedes the agent. On
the other hand, the model also addresses the subjective perspective of the agent, for
whom the structure of the space is initially unknown and must be inferred through
interaction. Thus, whileρ(x) appears as a pre-defined field in the simulations, it should
be understood as a representation that the agent progressively constructs through active
10
P(x) P(x)
P(x) P(x)
P(x)
MB 1
MB 2
MB 3
MB 4
MB 5
MB 6
Figure 1: Walking through Markov blankets.A schematic and intuitive representation
of the path of an active inference agent (orange line) in a space “filled” with Markov blankets
(MB) and touching points with different densities or porosities. Obviously, the agent also has
its own Markov blanket, and therefore its movement is conditioned by the coupling with the
other blankets and thus by the MB density.
inference. These two views are not contradictory, but complementary: one external, the
other internal. This point is explicitly addressed in Section 12.
Second, the supposed tension between local and regional definitions ofρ(x) dissolves
whenweassumethediscretenatureoftheagent’smovement. Ateachtimestep, theagent
is located at a single point in space and therefore interacts only with the local blanket
density ρ(x) at that point. This is precisely what the algorithm introduced in Section 4.4
formalizes: a local, data-driven estimation ofρ(x) based on a finite neighborhood. Hence,
although ρ(x) is conceptually related to spatial regions (via the mutual information over
internal, blanket, and external zones), its operative meaning remains pointwise. The
algorithm, by grounding this estimation in local data, resolves the apparent conflict
between locality and regionality.
Afinalclarificationconcernstheinterpretationoftheblanketdensityfield ρ(x). While
it assigns a value to every point in space, this does not imply that the underlying Markov
blanket is associated with the same system or agent across the entire domain. In fact,
a given point may be part of different Markov blankets under different conditions —
depending on the scale, temporal resolution, or inferential context adopted. For instance,
a location might fall within the blanket of one agent during a given interaction, and later
within that of a different system, or none at all. Whatρ(x) captures, then, is not a
fixed assignment of spatial regions to specific agents, but the local degree of conditional
coupling between internal and external states — regardless of which system is involved.
This perspective reinforces the interpretation ofρ(x) as a context-sensitive measure of
informational structure, rather than a mapping of fixed systemic boundaries.
4.4 Technical Assumptions on Space and Measures
Let X ⊆Rd be a nonempty, bounded, open set with Lipschitz boundary, equipped with
the Lebesgue measure dx. We assume the joint distribution of internal, external, and
blanket variables admits a strictly positive,C2 density
p(i, e, b| x) w.r.t. di de db dx,
where i ∈ I, e ∈ E, and b ∈ Brange over compact subsets of Euclidean spaces. Con-
cretely, we require:
(i) Uniform bounds: there exist constants0 < m≤ M <∞ such that
m ≤ p(i, e, b| x) ≤ M, ∀(i, e, b, x).
11
(ii) Smooth marginals and conditionals:all marginal and conditional densitiesp(i, e),
p(i, e| b), etc., depend in aC2-fashion onx.
(iii) Regularity of information maps:the mappings
x 7→ I(I; E) and x 7→ I(I; E | B(x))
are C1 on X, and henceρ(x) = 1 − I(I; E | B)
I(I; E) is C1 as well.
Under these hypotheses, all integrals, gradients, and continuity arguments in subsequent
sections are well-defined and satisfy the smoothness conditions required by the main
theorems.
4.5 Operational Definition of MB Density
To render the blanket density fieldρ(x) operational in continuous systems, we parti-
tion the state–space around each pointx using two radii, r1 < r2. Variables within
distance r1 of x form the internal setI(x); those at distances in[r1, r2) form the blan-
ket B(x); and the remainder form the external setE(x). We estimate the conditional
mutual informationI(I; E | B) and the marginal mutual informationI(I; E) using the
Kraskov–Stögbauer–Grassberger (KSG) k-nearest–neighbors estimator. To avoid divi-
sion by zero, we introduce a small regularizerε and constrain ρ(x) ∈ [δ, 1 − δ]. See
[21]. The computational cost scales asO(N log N) using KD-trees or similar structures;
Algorithm 1Estimation of Blanket Densityρ(x)
Require: Dataset D = {(yi, si)}N
i=1, radiir1, r2, neighbor countk, regularizerε, bound
δ.
Ensure: Blanket densityρ(x) for each samplex ∈ {yi}.
1: for each samplex ∈ {yi} do
2: I ← {si | ∥yi − x∥< r1}
3: B ← {si | r1 ≤ ∥yi − x∥< r2}
4: E ← {si | ∥yi − x∥≥ r2}
5: Estimate I(I; E | B) via KSG_conditional(k, I, E, B)
6: Estimate I(I; E) via KSG_mutual(k, I, E)
7: S(x) ← 1 − I(I; E | B)
I(I; E) + ε
8: ρ(x) ← min{max{S(x), δ}, 1 − δ}
9: end for
10: return {ρ(x)}x∈{yi}
further speedups are possible via grid-based subsampling. In our simulations we used
r1 = 0.1, r 2 = 0.2, k = 5, ε = 10−6, δ = 10−3, N = 104.
A Python implementation of the KSG estimator to compute MB density from sample
data can be found here: https://github.com/DesignAInf/MB-density. See also Appendix
B. On the project’s GitHub page, there are two separate repositories serving different
purposes. The first one ( mbdensity-sim) is a demonstrative sandbox — a minimal,
self-contained environment designed to showcase the core idea of modeling a spatially
varying Markov blanket densityρ(x). It uses a single synthetic field, a simplified mu-
tual information estimator, and a basic 2D gradient-descent dynamic, making it easy
to test and understand the concept without extra complexity. The second repository
(mbdensity-paper-sims) is a full reproduction of all simulations and visualizations from
the manuscript (Figures 2–8). It implements the exact scenarios described in the main
text and Appendix A. In short: the first repo is a stripped-down prototype for explo-
ration, while the second is a faithful, figure-by-figure replication of the paper’s experi-
ments.
12
5 Free Energy and Modulated Gradient Descent
Let the variational free energy fieldF(x) be defined over spaceΩ:
F(x) := Eqµ(s(x))[log qµ(s(x)) − log p(s(x), η(x))] (3)
where qµ is the internal (variational) distribution of the agent,s(x) are sensory states at
location x, andη(x) are environmental (hidden) states atx.
The agent minimizesF(x) via gradient descent, modulated by MB density:
˙x = −M(x)∇F(x) (4)
where M(x) := (1−ρ(x))I, andI is the identity matrix. Ifρ(x) = 1, inference is blocked
(no coupling), so ˙x = 0 ; if ρ(x) = 0 , there is full coupling and maximal inference is
possible [10, 11, 14, 15, 16].
6 FEP and MB Density
Theorem 1(Simultaneous Descent of Free Energy and Blanket Density under the Gra-
dient-Ratio Condition). Let Ω ⊂ Rn be a compact domain withC2 boundary, and let
F ∈ C2(Ω) be the free-energy function. An agent’s trajectoryx(t) evolves according to
the modulated gradient descent
˙x(t) = −[1 − ρN (x(t))] ∇F(x(t)),
where ρN (x) is the empirical blanket-density estimator derived from a dataset ofN sam-
ples.
Assume the following hold on an open setD ⊂ Ω where ∇F(x) ̸= 0:
(a) Smoothness of information functions.
The true unconditional mutual information
v(x) = Itrue(I(x); E(x)), u (x) = Itrue(I(x); E(x) | B(x))
are C1 functions ofx.
(b) Gradient alignment.
Define
A(x) = ∇u(x) · ∇F(x), B (x) = ∇v(x) · ∇F(x),
and assume A(x) > 0, B(x) > 0, i.e. moving down∇F decreases bothu(x) and
v(x).
(c) Gradient-Ratio Condition.
The proportional rate of decrease ofv(x) along ∇F strictly exceeds that ofu(x):
B(x)
v(x) > A(x)
u(x) .
Conclusion. Under these assumptions, with probability tending to 1 asN → ∞(so that
∇ρN → ∇ρ uniformly), the agent’s trajectory both descends the free-energy landscape and
moves toward regions of strictly decreasing blanket density. In particular, for everyt with
x(t) ∈ D,
d
dt ρN (x(t)) = ∇ρN (x(t)) · ∇F(x(t)) > 0.
Note. We choose the sign so that a positive directional derivative∇ρ · ∇F >0 implies ρ
decreases asF decreases.
13
From this point of view, free-energy minimization is fundamentally and universally
aligned with seeking regions of stronger informational coupling (lower MB density). The
former process naturally gives rise to the latter. The alignment between free-energy min-
imization and stronger informational coupling iscontingent on the local informational
geometry. It holdsonly when the Gradient-Ratio Condition is met—i.e. when the infor-
mational benefit of reducing total uncertainty outweighs the cost of residual uncertainty
along the current path. Thus, the agent’s dynamics emerge from a direct competition
between these two informational gradients.
This revised framework opens up a richer, more nuanced model of active inference.
Activeinferenceisnotasimple, guaranteeddescentdownasmoothhillbutthenavigation
of a complex “epistemic landscape,” determined by the interplay between the free-energy
gradient ∇F and the informational field ρ(x). The directional derivative of the true
blanket density
ρtrue(x) = 1 − u(x)
v(x)
along the agent’s path has sign proportional to
[v(x)]2 u(x) B(x) − v(x) A(x) u(x),
which is positive precisely when the Gradient-Ratio Condition holds, ensuring alignment
of free-energy descent with a decrease inρ(x). This immediately raises a critical question:
What happens when the condition is violated? This leads to the concept of an epistemic
trap: a region in the state space where the informational geometry is "perverse," causing
the Gradient-Ratio Condition to fail. In such a region:
If
B(x)
v(x) ≤ A(x)
u(x) ,
an epistemic traparises: despite following free-energy minimization, the agent may move
toward higher ρ(x), becoming more informationally isolated. Such traps offer a first-
principles model of maladaptive behaviors (e.g. social anxiety) and underscore the ne-
cessity of stochasticity or curiosity-driven exploration to escape basins that violate the
Gradient-Ratio Condition. This discussion of epistemic traps serves as a qualitative
bridge to Theorem 2, where these traps are rigorously defined and their dynamical prop-
erties analyzed.
There are at least two implications of this point:
• Modeling Maladaptive States.Epistemic traps formalize how an agent can get
stuck in high-ρ regions despite lower free-energy alternatives elsewhere.
• Justification for Exploration.Deterministic descent may fail; random pertur-
bations or explicit exploratory drives are normatively justified to overcome perverse
informational geometries.
6.1 Proof of the Gradient-Alignment Condition
Here we provide the complete technical details required to justify the claim
∇ρN (x) · ∇F(x) > 0 on D,
with high probability asN → ∞. Recall that
ρN (x) = 1 −
bI(I(x); E(x) | B(x)) + ε(N)
bI(I(x); E(x)) + ε(N)
, ε (N) = C0 N−α.
The proof proceeds in several steps:
14
Step 1: Consistency andC1 Convergence of the MI Estimators
Under the choice of radiir1(N), r2(N) satisfying
r2(N) → 0, r 1(N) = c r2(N), N Vol(Ball(x; r2(N))) → +∞,
the KSG–kNN estimators
bI(I(x); E(x)), bI(I(x); E(x) | B(x))
converge in probability to theirtrue values
Itrue(I(x); E(x)), I true(I(x); E(x) | B(x)),
uniformly on every compactK ⊂ D. Moreover, if the true mutual informations areC1
and the underlying noise is sub-Gaussian (or sub-Exponential), thenbI converges toItrue
in C1-norm on compacts:
sup
x∈K
|bI(I(x); E(x)) − Itrue(I(x); E(x))| = Op(N−α),
sup
x∈K
|∇x bI(I(x); E(x)) − ∇xItrue(I(x); E(x))| = Op(N−α).
and similarly forbI(I(x); E(x) | B(x)). The exponentα >0 depends on the data dimen-
sion d and the chosenk. In particular, for sufficiently largeN, with probability at least
1 − δ, one has
∥bI(I(·); E(·)) − Itrue(I(·); E(·))∥C1(K) < η(N),
∥bI(I(·); E(·) | B(·)) − Itrue(I(·); E(·) | B(·))∥C1(K) < η(N),
where η(N) → 0 as N → ∞.
Step 2: Definition of the “True” Blanket Densityρtrue(x)
Define
ρtrue(x) = 1 − Itrue(I(x); E(x) | B(x))
Itrue(I(x); E(x)) .
Since Itrue(I(x); E(x)) > 0 for allx ∈ D, ρtrue(x) is well-defined and lies strictly in(0, 1).
By hypothesis,Itrue(·; ·) and Itrue(·; · | ·) are C1, soρtrue(x) ∈ C1(Ω). A straightforward
differentiation yields
∇ρtrue(x) = − 1
Itrue(I(x); E(x)) ∇Itrue(I(x); E(x) | B(x)) + Itrue(I(x); E(x) | B(x))
[Itrue(I(x); E(x))]2 ∇Itrue(I(x); E(x)) .
Since, by the above assumptions, both
∇Itrue(I(x); E(x) | B(x)) · ∇F(x) > 0, ∇Itrue(I(x); E(x)) · ∇F(x) > 0 ∀x ∈ D,
and becauseItrue(I(x); E(x) | B(x)) < Itrue(I(x); E(x)), it follows that
∇ρtrue(x) · ∇F(x) = − ∇Itrue(I(x); E(x) | B(x)) · ∇F(x)
Itrue(I(x); E(x))
+ Itrue(I(x); E(x) | B(x)) [∇Itrue(I(x); E(x)) · ∇F(x)]
[Itrue(I(x); E(x))]2 < 0.
Hence
∇ρtrue(x) · ∇F(x) < 0 = ⇒ ∇ ρtrue(x) · ∇[−F(x)] > 0.
Equivalently,
∇ρtrue(x) · ∇F(x) > 0 ∀x ∈ D.
15
Step 3: UniformC1 Convergence Implies Gradient Alignment for
ρN
Since
∥bI(I(·); E(·)) − Itrue(I(·); E(·))∥C1(K) = Op(N−α),
∥bI(I(·); E(·) | B(·)) − Itrue(I(·); E(·) | B(·))∥C1(K) = Op(N−α).
and ε(N) = C0 N−α, one deduces thatρN (x) → ρtrue(x) uniformly inC1(K) over any
compact K ⊂ D. In particular, for sufficiently largeN, with probability at least1 − δ,
sup
x∈K
∥∇ρN (x) − ∇ρtrue(x)∥ < η(N), where η(N) → 0 as N → ∞.
Since ∇ρtrue(x) · ∇F(x) is strictly positive and bounded away from zero onK, there
exists N0 such that for allN ≥ N0,
∇ρN (x) · ∇F(x) = ∇ρtrue(x) · ∇F(x) + [ ∇ρN (x) − ∇ρtrue(x)] · ∇F(x) > 0,
∀x ∈ K,
with probability at least1 − δ. Covering D by a finite collection of such compact sets
yields the uniform positivity of∇ρN (x) · ∇F(x) on all ofD, with probability→ 1.
Step 4: Conclusion—Monotonic Decrease ofρN along the Trajec-
tory
Let x(t) solve
˙x(t) = −[ 1− ρN (x(t))] ∇F(x(t)), x (0) = x0 ∈ D.
Then, whereverx(t) ∈ D,
d
dt ρN (x(t)) = ∇ρN (x(t)) · ˙x(t) = −[ 1− ρN (x(t))] [∇ρN (x(t)) · ∇F(x(t))].
Since 0 < ρN (x) < 1 implies 1−ρN (x) > 0, and from Step 3 we have∇ρN (x)·∇F(x) > 0
for allx ∈ D with high probability, it follows that
d
dt ρN (x(t)) < 0, whenever x(t) ∈ D.
Hence ρN (x(t)) is strictly decreasing along the agent’s path so long asx(t) remains in
D. This completes the proof.
□
The agent is driven by free energy minimization to move toward regions of lower
Markov blanket density—i.e., where boundaries are weak, coupling is strong, and inter-
action with the environment is richer. This provides a formal justification for the thesis:
free energy minimization in space tends to deform toward topologies of low Markov blanket
density.
For more details, see Figure 2-8 and Appendix A. As said, you can find the full code
of the simulations, detailed parameter settings, and usage instructions in the GitHub
repository: https://github.com/DesignAInf/MB-density.
6.2 An Empirical Diagnostic for Gradient Alignment
We provide here an operational, local diagnostic to test whether the alignment assump-
tion
⟨∇ρ(x), ∇F(x)⟩ > 0
holds in data. The diagnostic is modular and comes in three complementary variants: (A)
directional differences, (B) local gradient estimation with bootstrap, and (C) a dynamic
test when trajectories are observed. For a reference Python implementation of the em-
pirical alignment diagnostic, including local gradient estimation, directional derivatives,
and bootstrap testing, see https://github.com/DesignAInf/MB-density.git.
16
6.2.1 Variant A: Directional Differences (fast and robust)
Let bρ be an estimator ofρ and d∇F(x) an estimate of the free-energy gradient (e.g., via
autodiff on the model or via SPSA/finite differences). Define the unit direction
uF (x) :=
d∇F(x)
∥d∇F(x)∥
,
provided∥d∇F(x)∥> 0. For a set of step sizesE = {ε1, ε2, ε3}, we compute the symmetric
directional derivative ofbρ along uF :
Dρ|F (x; ε) := bρ(x + εuF ) − bρ(x − εuF )
2ε .
Aggregate across scales via the median:
Dρ|F (x) := medianε∈E Dρ|F (x; ε).
Decision rule. For a toleranceτ >0 (set from noise, see Sec. 6.2.4): (i) ifDρ|F (x) >
τ, declare positive alignment (⟨∇ρ, ∇F⟩ > 0); (ii) if Dρ|F (x) < −τ, declare negative
alignment; (iii) otherwise,inconclusive.
Symmetriccross-check. Ifanestimate c∇ρ(x) isavailable, defineuρ(x) := c∇ρ(x)/∥c∇ρ(x)∥
and compute
DF|ρ(x; ε) :=
bF(x + εuρ) − bF(x − εuρ)
2ε .
Consistency between the signs ofDρ|F and the median ofDF|ρ strengthens the evidence.
6.2.2 Variant B: Local Gradient Estimation with Bootstrap (CIs and p-
values)
We estimate both gradients locally and assess uncertainty by resampling.
Local gradients. Within a ballBr(x) of radiusr centered atx, fit a first-order local
polynomial (local linear regression) forbρ and bF using a kernel weight (e.g., tricube or
Gaussian). This yields
bρ(z) ≈ aρ + b⊤
ρ (z − x), bF(z) ≈ aF + b⊤
F (z − x),
with c∇ρ(x) := bρ and d∇F(x) := bF . When model derivatives are inaccessible, SPSA
with two-point perturbations can be used to obtaind∇F(x) (and analogously c∇ρ(x)).
Test statistic.
T(x) := c∇ρ(x)⊤d∇F(x).
Optionally, consider the cosine similarityc(x) := T(x)/(∥c∇ρ(x)∥·∥d∇F(x)∥) to reduce
scale effects.
Bootstrapuncertainty. Resamplewithreplacementthepointsin Br(x) (block-bootstrap
if temporal dependence is present), re-estimate gradients, and recomputeT∗(b)(x) for
b = 1, . . . , B. Let
CI1−α(x) = [qα/2, q1−α/2]
be the empirical(1−α) confidence interval from bootstrap quantiles. A one-sided p-value
for H0 : ⟨∇ρ, ∇F⟩ ≤0 vs. H1 :> 0 is
p(x) = 1 + #{b : T∗(b)(x) ≤ 0}
B + 1 .
Decision rule.(i) IfCI1−α(x) lies entirely above0 (and p(x) < α), declarepositive
alignment. (ii) If it lies entirely below 0, declare negative alignment. (iii) Otherwise,
inconclusive.
17
6.2.3 Variant C: Dynamic Test Along Trajectories
Suppose we observe a trajectory xt evolving under ˙xt = −M(xt)∇F(xt) with M(x)
positive definite (e.g.,M ≈ I). Then
d
dtρ(xt) = ∇ρ(xt)⊤ ˙xt = −∇ρ(xt)⊤M(xt)∇F(xt).
If M ≈ I, the sign of⟨∇ρ, ∇F⟩ is the negative of the sign of˙ρ. In practice, filterxt (e.g.,
Savitzky–Golay), computebρ(xt) and its central finite-difference derivativeb˙ρt. Estimate
the fraction
π := 1
T
TX
t=1
⊮{b˙ρt < 0},
and form block-bootstrap confidence intervals forπ. If the CI is strictly above0.5, we
declarepositive alignment on averagealongtheobservedpath(adjustingfor M ifknown).
6.2.4 Hyperparameters, Quality Checks, and Practical Defaults
Neighborhood size. Choose r so that the local sample sizeNr ∈ [50, 200]; report
stability across two or three values ofr. Directional step sizes.Use E = {0.5, 1, 2}×
the median nearest-neighbor distance. Tolerance. Set τ to one or two MADs of the
bootstrapped Dρ|F (x; ε). Flat regions.If ∥d∇F(x)∥ or ∥c∇ρ(x)∥ fall below a threshold,
label the test uninformative. Cosine similarity. Report bootstrap CIs forc(x) as a
scale-invariant summary.
6.2.5 Limitations
The diagnostic is local and sensitive to neighborhood sizer and step sizesE. In high
dimension, gradient estimates and MI-basedbρ may be noisy; we therefore recommend
reporting sensitivity analyses and bootstrap CIs. In flat regions where∥∇F∥ or ∥∇ρ∥ is
small, the test is uninformative by design.
7 Implications
This result calls for a redefinition of active inference concepts in terms of spatially struc-
tured MB density. Markov blankets are no longer discrete boundaries, but a graded
field ρ(x) across space. Free energy becomes a spatial fieldF(x), whose minimization is
modulated by this field. Perception and action emerge as spatially constrained processes,
more effective in low-MB-density regions. Expected free energy can be redefined as a
trajectory-dependent integral:
G(π) =
Z
τ
(1 − ρ(xπ(t)))F(xπ(t)) dt (5)
This framework generalizes active inference beyond fixed, agent-centered models. It
accommodates proto-agents, emergent structures, and distributed cognition. It also
grounds the role of movement, curiosity, and exploration in the topology of inference:
agents seek regions where inference is possible and fruitful. It aligns naturally with eco-
logical and enactive theories of cognition, and opens the door to applications in swarm
robotics, architecture, and cognitive development.
8 MB Density and the Limits on the Free Energy Min-
imization
The next two theorems elaborate on the relationship between MB density and free energy
minimization. Theorem 2 formalizes that as MB density rises toward 1, agent’s mecha-
nisms by which it reduces free energy—namely, its movements and belief updates—slow
down without bound and, at full density, stop altogether, so that regions of high blanket-
density effectively lock the agent in place and prevent any further action or inference
[12, 13, 17].
18
Theorem 2. Let
1. F : Ω → R be a continuously differentiable (C1) function on an open setΩ ⊆ Rn.
2. ρ : Ω → [0, 1] be a continuous blanket-density field. At each pointx ∈ Ω, assume the
agent’s spatial (or parametric) coordinates evolve according to the continuous-time
dynamics
˙x = −(1 − ρ(x)) ∇F(x).
3. There exist two positive constants:
• G such that ∥∇F(x)∥ ≤G for all x ∈ Ω. In other words, F has a globally
bounded gradient onΩ.
• m such that
m = inf
x∈Ω
Ftarget ≤F(x) ≤F(x0)
∥∇F(x)∥2 > 0,
where x0 is the initial point (withF(x0) = F0) andFtarget < F0 is the desired
(strictly lower) “target” value of free energy.
Under these assumptions, the following statements hold:
1. Exact Blocking atρ = 1.
If, for some open neighborhoodU ⊆ Ω, ρ(x) = 1 for every x ∈ U, then for all
x ∈ U:
˙x = −(1 − ρ(x)) ∇F(x) = −(1 − 1) ∇F(x) = 0,
and therefore
d
dtF(x(t)) = ∇F(x) · ˙x = 0 .
In other words, wheneverρ(x) ≡ 1 on some region, the agent iscompletely immo-
bilized there: it cannot move (˙x = 0) and cannot reduce free energy (d
dtF = 0).
2. Quantitative Slowing Whenρ Is Close to 1.
Fix an arbitrary pointx ∈ Ω. Because
d
dtF(x(t)) = ∇F(x) · ˙x = −(1 − ρ(x)) ∥∇F(x)∥2,
one sees immediately that ifρ(x) ≥ 1 − δ for some0 < δ≪ 1, then
0 ≤ 1 − ρ(x) ≤ δ,
and hence
− d
dtF(x) = (1 − ρ(x)) ∥∇F(x)∥2 ≤ δ ∥∇F(x)∥2 ≤ δ G2.
Equivalently,
d
dtF(x) ≥ −δ G2.
Thus, at any point whereρ(x) ≥ 1 − δ, the instantaneous decrease ofF is at most
δ G2. In particular:
• If one demands that the rate of decrease of free energy be at least some positive
threshold α >0, i.e.
− d
dtF(x) ≥ α,
then it is necessary that
(1 − ρ(x)) ∥∇F(x)∥2 ≥ α ⇐⇒ 1 − ρ(x) ≥ α
∥∇F(x)∥2 ≤ α
G2 .
Hence
ρ(x) ≤ 1 − α
G2 .
In short,any pointx at whichρ(x) exceeds 1− α
G2 cannot decrease free energy
faster thanα.
19
• Conversely, ifρ(x) ≤ 1 − α
G2 , then
− d
dtF(x) = (1 − ρ(x)) ∥∇F(x)∥2 ≥ α
G2 ∥∇F(x)∥2 ≥ 0.
But to ensured
dtF(x) ≤ −α, one must also require∥∇F(x)∥2 not be too small.
The precise condition ford
dtF(x) ≤ −α is
(1 − ρ(x)) ∥∇F(x)∥2 ≥ α ⇐⇒ 1 − ρ(x) ≥ α
∥∇F(x)∥2 .
Since ∥∇F(x)∥2 ≤ G2, a sufficient condition is1 − ρ(x) ≥ α
G2 .
In summary, wheneverρ(x) lies in the interval
1 − α
G2 < ρ(x) ≤ 1,
the descent of free energy is eithervery slow(bounded byδ G2 with δ = 1 − ρ) or
completely blocked (ifρ = 1). As ρ(x) → 1, the instantaneous free-energy-descent
rate | d
dtF(x)| →0.
3. Lower Bound on the Time to DecreaseF by ∆.
Suppose we start atx(0) = x0, with F(x0) = F0, and we want to reach any point
x(t) such that F(x(t)) ≤ Ftarget = F0 − ∆ for some fixed∆ > 0. Assume that,
along the entire trajectoryx(t) from t = 0 until the first hitting timeT of {x :
F(x) ≤ F0 − ∆}, it holds that
1 − ρ(x(t)) ≥ δ for allt ∈ [0, T],
for someδ >0. Then
d
dtF(x(t)) = −(1 − ρ(x(t))) ∥∇F(x(t))∥2 ≤ −δ ∥∇F(x(t))∥2.
By hypothesis, on the level set{x : Ftarget ≤ F(x) ≤ F0}, we have∥∇F(x)∥2 ≥ m.
Hence d
dtF(x(t)) ≤ −δ m,
and integrating from0 to T gives
F(x(T)) − F(x0) ≤
Z T
0
[−δ m] dt = −δ m T.
Since F(x(T)) = F0 − ∆, we conclude
−∆ ≤ −δ m T =⇒ T ≥ ∆
δ m.
Thus, if the agent is “stuck” in regions where1 − ρ(x) ≥ δ (i.e. ρ(x) ≤ 1 − δ), then
it will take at leastT = ∆/(δ m) units of time to reduceF by ∆. As δ → 0, this
lower boundT → +∞.
4. Implication for Learning Rates of Internal Parametersθ.
Suppose the agent also has internal parameters (beliefs)θ ∈ Rp that evolve according
to
˙θ = −(1 − ρ(x)) ∂F (x, θ)
∂θ .
At anyx such thatρ(x) ≥ 1 − δ, the magnitude of the instantaneous updateof θ
is bounded by
∥ ˙θ∥ = (1 − ρ(x))
∂F
∂θ
 ≤ δ
∂F
∂θ
.
20
Therefore, if one demands a minimum learning rate ∥ ˙θ∥ ≥αθ > 0, then it is
necessary that
1 − ρ(x) ≥ αθ
∥∂F/∂θ ∥ ⇐⇒ ρ(x) ≤ 1 − αθ
∥∂F/∂θ ∥ .
Hence any locationx satisfying ρ(x) > 1 − αθ
∥∂F/∂θ ∥ will force∥ ˙θ∥ < αθ, meaning
that the agent’s ability to update its beliefs isdramatically reducedwhen ρ is close
to 1.
Proof Sketch. 1. Since F ∈ C1(Ω) and x(t) evolves via ˙x = −(1 − ρ(x)) ∇F(x), one
computes
d
dtF(x(t)) = ∇F(x(t))·˙x(t) = ∇F(x)·
h
−(1−ρ(x)) ∇F(x)
i
= −(1−ρ(x)) ∥∇F(x)∥2,
establishing the exact expression for the instantaneous change ofF.
2. If ρ(x) = 1, then ˙x = 0 and hencedF/dt = 0. This immediate calculation shows
that any region whereρ ≡ 1 blocks both motion and free-energy reduction.
3. If ρ(x) ≥ 1 − δ, then1 − ρ(x) ≤ δ. Therefore
− d
dtF(x) = (1 − ρ(x)) ∥∇F(x)∥2 ≤ δ ∥∇F(x)∥2 ≤ δ G2,
whichimplies d
dtF(x) ≥ −δ G2. Requiring−dF/dt ≥ α forces1−ρ(x) ≥ α/∥∇F(x)∥2,
and since ∥∇F(x)∥2 ≤ G2, a sufficient condition is1 − ρ(x) ≥ α/G2, so ρ(x) ≤
1 − α/G2.
4. Suppose along the trajectory1−ρ(x(t)) ≥ δ. Then d
dtF(x(t)) ≤ −δ ∥∇F(x(t))∥2 ≤
−δ m. Integrating fromt = 0 to t = T and usingF(x(T)) = F0 − ∆ yields
F(x(T)) − F0 ≤ −δ m T =⇒ T ≥ ∆
δ m.
Hence, to reduce by∆, at leastT = ∆/(δ m) time is needed.
5. Because ˙θ = −(1−ρ(x)) ∂F/∂θ , ifρ(x) ≥ 1−δ then∥ ˙θ∥ ≤δ ∥∂F/∂θ ∥. To guarantee
∥ ˙θ∥ ≥αθ, one needs1 − ρ(x) ≥ αθ/∥∂F/∂θ ∥, i.e.ρ(x) ≤ 1 − αθ/∥∂F/∂θ ∥.
8.1 Numerical Example (One-Dimensional Case)
Consider:
F(x) = x2, x ∈ R.
Then ∇F(x) = 2x, so∥∇F(x)∥2 = 4x2.
1. Let x0 = 1, soF0 = 1. Choose Ftarget = 0.04. Then ∆ = F0 − Ftarget = 0.96.
2. On the level set{x : 0.04 ≤ x2 ≤ 1}, one has|x| ≥0.2. Thus
∥∇F(x)∥2 = 4x2 ≥ 4(0.2)2 = 0.16,
so we can takem = 0.16. On |x| ≤1, ∥∇F(x)∥2 ≤ 4, henceG = 2.
3. If everywhere along the continuous trajectory we haveρ(x) ≤ 0.9 (so δ = 0 .1),
Theorem 2 says
T ≥ ∆
δ m = 0.96
0.1 × 0.16 = 60.
If insteadρ(x) ≤ 0.99 (δ = 0.01), then
T ≥ 0.96
0.01 × 0.16 = 600.
If ρ(x) ≤ 0.999, thenT ≥ 6000. As ρ → 1, T → ∞.
21
4. Instantaneous descent atx = 0.5: ∥∇F(0.5)∥2 = 4(0.5)2 = 1.
• If ρ(0.5) = 0.95 (δ = 0.05), then
−dF
dt

x=0.5
= (1 − 0.95) × 1 = 0.05.
• If ρ(0.5) = 0.99 (δ = 0.01), then
−dF
dt

x=0.5
= (1 − 0.99) × 1 = 0.01.
• If ρ(0.5) = 0.999 (δ = 0.001), then
−dF
dt

x=0.5
= 0.001.
Hence “ρ near 1” throttles the instantaneous descent.
5. Internal-parameterupdate: let F(x, θ) = x2+1
2 θ2. At(x, θ) = (0.5, 0.5),∥∂F/∂θ ∥ =
0.5.
• If ρ = 0.95, thenδ = 0.05, so∥ ˙θ∥ ≤0.05 × 0.5 = 0.025.
• If ρ = 0.99, then∥ ˙θ∥ ≤0.01 × 0.5 = 0.005.
Again, higherρ means slower learning.
8.2 Discrete-Time Corollary
Proof. Suppose we implement the gradient-descent-like update:
xk+1 = xk − ∆t (1 − ρ(xk)) ∇F(xk), k = 0, 1, 2, . . . ,
with a fixed time-step∆t >0. Assume:
• ∥∇F(x)∥ ≤G for allx ∈ Ω.
• On the level set{x : Ftarget ≤ F(x) ≤ F(x0)}, ∥∇F(x)∥2 ≥ m >0.
• 0 < ∆t ≤ 1
2G2 .
Then each iterate satisfies
F(xk+1) ≤ F(xk) − 1
2 ∆t (1 − ρ(xk)) G2.
If along all iterates1 − ρ(xk) ≥ δ, then
F(xk+1) ≤ F(xk) − 1
2 ∆t δ G2, k = 0, 1, . . .
To reduceF by at least∆ > 0, one needs at least
K ≥ 2 ∆
δ G2 ∆t
iterations. As δ = 1 − ρ(xk)→ 0, K → ∞, demonstrating that “almost-perfect blankets”
stall discrete-time descent as well.
The following theorem formalizes how the FEP remains operative in realistically
heterogeneous settings, where the informational “shielding” of an agent’s Markov blankets
varies randomly across space. By showing that the expected rate of free energy descent
is proportional to (1 − ¯ρ), it quantifies exactly how much average permeability of the
Markov blanket (¯ρ <1) is required to guarantee net minimization. In practice, this result
is essential: it tells us that—even if some regions are nearly opaque (ρ close to 1)—as long
as the overall environment provides enough “leakiness” or "porosity," the agent can still
reduce free energy. Without this balance theorem, we would lack a principled criterion
for when and where active inference can succeed in complex, non-uniform worlds [18].
22
Theorem 3. Let Ω ⊂ R3 be a compact domain with smooth boundary. Define a twice
continuously differentiable free-energy function
F : Ω −→ R,
satisfying
1. ∥∇F∥∞:= supx∈Ω∥∇F(x)∥ < +∞,
2. min
x∈Ω
∥∇F(x)∥2 = m ≥ 0,
3. G := 1
Vol(Ω)
Z
Ω
∥∇F(x)∥2 dx = Ex∼Uniform(Ω)[∥∇F(x)∥2].
Assume ∥D2F∥≤ LF everywhere onΩ, so thatF is Lipschitz with constant∥∇F∥∞ and
has Hessian bounded byLF .
Next, let
ρ : Ω × Θ −→ [0, 1]
be a random field on a probability space(Θ, F, P), satisfying:
(i) (Boundedness)
0 ≤ ρ(x, θ) ≤ 1, ∀x ∈ Ω, ∀θ ∈ Θ.
(ii) (Spatial Stationarity in the Weak Sense)For everyx ∈ Ω,
E[ρ(x)] = µ ∈ [0, 1), Var[ρ(x)] = σ2.
(iii) (Covariance with∥∇F∥2) For eachx ∈ Ω,
Cov (ρ(x), ∥∇F(x)∥2) = C,
a constant independent ofx. Equivalently,
E[ρ(x) ∥∇F(x)∥2] = µ G+ C.
(iv) (Exponential Decay of Spatial Correlations)There exists a correlation length
ℓ >0 such that, for allx, y∈ Ω,
|Cov(ρ(x), ρ(y))| ≤σ2 exp

−∥x − y∥
ℓ

.
Consider the stochastic dynamics
˙xt = −(1 − ρ(xt)) ∇F(xt), x (0) = x0 ∈ Ω.
Theorem 4(Free Energy Descent under a Stochasticρ Field [19]).
A. Free-Energy Descent in ExpectationDefine
ϕ(x) = (1 − ρ(x)) ∥∇F(x)∥2.
Taking expectation over both the random fieldρ and (ergodically) overxt in Ω, we
have d
dt E[F(xt)] = E[∇F(xt)· ˙xt] = −E
h
(1 − ρ(xt)) ∥∇F(xt)∥2
i
.
Since
E[ϕ(x)] = E[∥∇F(x)∥2] − E[ρ(x) ∥∇F(x)∥2] = G − (µ G+ C) = (1 − µ) G − C,
it follows that
If (1−µ) G−C > 0

⇔ µ <1−C
G

, then d
dt E[F(xt)] = −((1−µ) G−C) < 0, ∀t ≥ 0.
Consequently, for any finiteT >0,
E[F(xT )] ≤ E[F(x0)] − ((1 − µ) G − C) T.
23
B. Free-Energy Descent with High Probability (Pointwise Uniform Control)
Define
m0 := min
x∈Ω
((1 − µ) ∥∇F(x)∥2 − C).
Assume m0 > 2 ε for someε >0. Also fix a finite grid{x(1), x(2), . . . , x(N)} ⊂Ω
such that maxx∈Ω mini∥x − x(i)∥ ≤δ. Since each ϕ(x) = (1 − ρ(x)) ∥∇F(x)∥2 is
bounded in[0, K2], Hoeffding’s inequality implies, for each fixedi,
P

|ϕ(x(i)) − E[ϕ(x(i))]| ≥ε

≤ 2 exp

−2 ε2
K4

.
Taking a union bound over allN grid points,
P

∃i such that|ϕ(x(i)) − E[ϕ(x(i))]| ≥ε

≤ 2 N exp

−2 ε2
K4

.
Choose N (or refine the grid) so that
2 N exp

−2 ε2
K4

≤ δ,
for a prescribed smallδ >0. Moreover, by continuity ofϕ(x), the maximum oscil-
lation betweenϕ(x) and ϕ(x(i)) for any x within δ of x(i) can be made arbitrarily
small by choosingδ sufficiently small.
Therefore, with probability at least1 − δ,
sup
x∈Ω
|ϕ(x) − E[ϕ(x)]| < ε,
and sinceE[ϕ(x)] ≥ m0 for everyx, one obtains
ϕ(x) = (1−ρ(x)) ∥∇F(x)∥2 ≥ E[ϕ(x)]−ε ≥ m0−ε > 2 ε−ε = ε > 0, ∀x ∈ Ω.
Hence, with probability at least1 − δ, for everyt ≥ 0,
˙F(xt) = −ϕ(xt) < −ε < 0.
In other words, the free energyF(xt) decreases uniformly (at least at rateε) for
all t, with probability at least1 − δ.
C. Existence of a Deterministic Descent PathSuppose there exists a continuous,
connected curve
γ : [0, 1] −→ Ω, γ (0) = x0, γ (1) = x∗,
where x∗ is a global minimizer ofF, such that
1. sup
s∈[0,1]
ρ(γ(s)) ≤ ρmax < 1,
2. inf
s∈[0,1]
∥∇F(γ(s))∥2 = m′ > 0.
Define a deterministic “descent” velocity alongγ by
˙γ(s) = −(1 − ρmax) ∇F(γ(s)), 0 ≤ s ≤ 1,
with γ(0) = x0. Then for eachs ∈ [0, 1],
d
ds F(γ(s)) = ∇F(γ(s))· ˙γ(s) = −(1−ρmax) ∥∇F(γ(s))∥2 ≤ −(1−ρmax) m′ < 0.
Hence F(γ(s)) strictly decreases fromF(x0) down toF(x∗) as s ranges from0 to
1. In particular,γ does not “get stuck”: the factor1 − ρmax is strictly positive, and
∥∇F∥ remains bounded below bym′ > 0. Therefore,γ is a valid monotone descent
path forF.
24
D. Finite-Sample Estimates and Confidence IntervalsIn practice, one does not
knowµ, G, andC exactly. Instead, one draws a finite sample ofN pointsx1, x2, . . . , xN
(uniformly from Ω or according to the stationary distribution ofxt), and defines
the empirical estimates:
ˆµ = 1
N
NX
i=1
ρ(xi), ˆG = 1
N
NX
i=1
∥∇F(xi)∥2,
bC = 1
N
NX
i=1
ρ(xi) ∥∇F(xi)∥2 − ˆµ ˆG.
By Hoeffding’s or Bernstein’s inequality, for any confidence level1 − δ, there exist
error boundsε1, ε2, ε3 = O(
r
ln(1/δ)
N ) such that, with probability at least1 − δ,
|ˆµ − µ| ≤ε1, | ˆG − G| ≤ε2, | bC − C| ≤ε3.
Define conservative bounds:
µmax = ˆµ + ε1
9 Temporal Expected Free Energy and Its Dependence
on Spatial Fields
In this section we introduce another theorem showing that the temporal side of the
FEP depends on MB density. The theorem provides a mathematical foundation for
understanding free energy minimization as a spatiotemporal process. It embeds the
familiar temporal version of the FEP within a broader framework where both free energy
and Markov blanket strength vary continuously across space. This insight not only unifies
“beliefupdating” and“movement” underasingleinformationallensbutalsoopenstheway
to apply the FEP in settings where spatial coupling is partial, graded, or heterogeneous.
(Some redundancy with the previous sections is necessary for the completeness of the
argument).
9.1 Definitions and Setup
1. Spatial Free EnergyF(x). For each locationx ∈ Ω, define the variational free
energy
F(x) = Eqµ(s|x)
h
log qµ(s | x) − log p(s, η| x)
i
,
where
• qµ(s | x) is the agent’s approximate posterior density over sensory datas if it were
at x.
• p(s, η| x) is the generative model (joint likelihood) of sensory datas and hidden
external statesη at locationx.
• The expectationEqµ is taken with respect toqµ(s | x).
Intuitively,F(x) quantifies the discrepancy between what the agentexpects to see atx
andwhattheenvironment actually encodesat x. Inthisway, F(x) istheusualvariational
free energy functionalindexed by spatial location(cf. Eq. (3)).
2. MBDensity ρ(x). Insteadofahard, binaryMarkovblanket, wedefinea continuous
blanket-density
ρ(x) = 1 − I(I(x) ; E(x) | B(x))
I(I(x) ; E(x)) + ε ,
where
25
• I(x) denotes the agent’sinternal variables within a small radiusr1 around x.
• B(x) denotes the “blanket” (sensory/active) variables in the annulus between radii
r1 and r2.
• E(x) denotes theexternal (hidden) variables beyond radiusr2.
• I(·; ·) is the Shannon mutual information; ε > 0 is a small regularizer to avoid
division by zero.
Hence:
• If I(I; E | B) = 0 exactly (perfect shielding byB), thenρ(x) = 1 (a perfect Markov
blanket).
• If I(I; E | B) = I(I; E) (conditioning on B does not reduce dependence), then
ρ(x) = 0 (no blanket; maximal coupling).
• In general,ρ(x) ∈ [0, 1] measures how “porous” the local statistical boundary is (cf.
Eq. (2) and §5.4).
3. Spatial Dynamics. The agent’s positionx(t) ∈ Ω evolves according to thethrottled
gradient-descent:
˙x(t) = −[ 1− ρ(x(t))] ∇F(x(t)). (6)
Concretely:
˙x =



−∇F(x) , ρ (x) = 0,
0 , ρ (x) = 1,
and forρ(x) ∈ (0, 1) , ˙x = −(1 − ρ(x)) ∇F(x).
Thus:
• ρ(x) = 0: The blanket is fully transparent, so the agent performs ordinary gradient
descent onF.
• ρ(x) ≈ 1: The agent is nearly insulated and˙x ≈ 0; free-energy descentstalls.
• Intermediate values ofρ “throttle” the descent speed proportionally to(1 − ρ).
Equation (6) is precisely Eq. (4).
9.2 Expression for Temporal EFE
Theorem 5. Let π = {x(t)}τ
t=0 be any (piecewise-continuous) trajectory inΩ. Then
the temporal expected free energyalong π is
G(π) =
Z τ
0
[ 1− ρ(x(t))]| {z }
coupling factor
× F(x(t))| {z }
spatial free energy
dt. (7)
In other words, G(π) is exactly the time-integral of the “accessible” free energy(1 −
ρ(x)) F(x) at each locationx(t).
Proof of Theorem 5.At any instantt, if the agent is located atx = x(t), theaccessible
portion of the spatial free energy is
F(x)|{z}
total free energy
× [ 1− ρ(x)]| {z }
coupling factor
.
Indeed:
• If ρ(x) = 0 , the blanket is transparent and the agent can fully exploitF(x) to
update beliefs⇒ the accessible free energy isF(x).
26
• If ρ(x) = 1, the blanket is opaque⇒ the accessible free energy is0.
• For ρ(x) ∈ (0, 1), the fraction (1 − ρ(x)) measures how much of F(x) remains
available for reduction.
Hence, over an infinitesimal time interval[ t, t+ dt ], the agent can reduce at most
[ 1− ρ(x(t))] F(x(t)) dt.
Integrating fromt = 0 to t = τ yields exactly
G(π) =
Z τ
0
[ 1− ρ(x(t))] F(x(t)) dt,
which is Equation (7). This completes the proof.
Remark. Equation (7) recovers Eq. (5) verbatim and is exactly what is referred to as
Theorem 5.
9.3 Evolution of the Instantaneous IntegrandΓ(x)
Define the instantaneous integrand
Γ(x(t)) := [ 1 − ρ(x(t))] F(x(t)).
Since G(π) =
Rτ
0 Γ(x(t)) dt, understanding howG evolves is equivalent to computing the
time-derivative d
dt Γ(x(t)) along the agent’s trajectory.
4.1. Computing ∇Γ(x). Observe that
Γ(x) = (1 − ρ(x)) F(x).
Taking the spatial gradient:
∇Γ(x) = ∇[ (1− ρ(x)) F(x)] = −F(x) ∇ρ(x) + (1 − ρ(x)) ∇F(x). (8)
4.2. Agent’s Dynamics. By assumption (Equation (6)),
˙x(t) = −[ 1− ρ(x(t))] ∇F(x(t)).
Substituting ∇Γ(x) from (8) and˙x(t) yields
d
dt Γ(x(t)) = ∇Γ(x(t)) · ˙x(t)
=
h
−F(x(t)) ∇ρ(x(t)) + (1 − ρ(x(t))) ∇F(x(t))
i
·
h
−(1 − ρ(x(t))) ∇F(x(t))
i
= −(1 − ρ(x(t)))2 ∥∇F(x(t))∥2 − F(x(t)) (1− ρ(x(t))) [∇ρ(x(t)) · ∇F(x(t))].
Hence, for brevity dropping the(x(t)) arguments,
d
dt Γ(x) = −(1 − ρ)2 ∥∇F∥2 − F (1 − ρ) [∇ρ · ∇F]. (9)
Equation (9) displays two terms:
(A) Throttled Descent Term:
−(1 − ρ(x))2 ∥∇F(x)∥2.
• If ρ(x) < 1, this term is strictly negative (unless∇F(x) = 0), ensuringΓ(x)
(and thusG) decreases.
27
• As ρ(x) → 1, the factor(1 − ρ(x))2 → 0, so this negative term vanishes and
no descent occurs. In particular, ifρ(x) = 1 , then ˙x = 0 and Γ(x) = 0 , so
d
dtΓ = 0. This is precisely the “exact blocking” result (Theorem 2).
(B) Gradient-Alignment Correction:
−F(x) (1 − ρ(x)) [∇ρ(x) · ∇F(x)].
• If ∇ρ(x) · ∇F(x) > 0, then this term is strictly negative, further accelerating
Γ’s decrease.
• If ∇ρ · ∇F <0, it could partially oppose descent.
• The gradient-alignment assumptionrequires ∇ρ ·∇F >0 over an open setD.
Under that assumption, (9) impliesΓ decreases strictly, showing simultaneous
descent ofF and “leakage”1 − ρ. This recovers Theorem 1.
9.4 Corollaries: Theorems 1 and 2
Corollary 1 (Exact Blocking, Theorem 2).If ρ(x(t)) = 1 at some pointx(t), then
˙x(t) = −(1 − ρ) ∇F = 0, sox(t) remains fixed. Moreover,Γ(x(t)) = (1 − ρ) F = 0, and
from (9),
d
dt Γ(x(t)) = 0 .
Hence the agent is “frozen” and cannot reduce any free energy once it enters a perfect-
blanket region.
Corollary 2 (Gradient Alignment, Theorem 1).If, over an open setD ⊂ Ω, the
gradient-alignment condition
∇ρ(x) · ∇F(x) > 0 and ρ(x) < 1, F (x) > 0 for allx ∈ D
holds, then from (9), both terms on the right-hand side arestrictly negative, so
d
dt Γ(x(t)) < 0 whenever x(t) ∈ D.
Thus Γ (and therefore the accessible free energy) strictly decreases as long as the agent
remains inD. Consequently, the agent’s trajectory simultaneouslydescends F and de-
creasesρ, driving it toward regions of stronger coupling and lower free energy.
9.5 Interpretation
Taken together, Theorem 5 and its corollaries paint a vivid picture:
• The temporal EFE G(π) is not an independent objective; it is exactly the time-
integral of the spatial free energyF(x), gated by the local blanket densityρ(x).
• The agent’sspatiotemporal dynamics are determined by the interplay between the
shape ofF(x) and the “porosity”ρ(x).
• Exact blocking: Regions where ρ = 1 act as walls: the agent cannot traverse
them nor reduce any free energy within them.
• Gradient alignment:If spatial gradients ofρ and F align positively, the agent is
guaranteed to move to tiles of(F, ρ) that are simultaneously lower, thereby forging
a path of ever-stronger coupling and lower surprise.
This theorem makes “space” a first-class player in active inference. In this way, one
obtains a unified description of howmovement (spatial navigation) andbelief updating
(free energy minimization) are two sides of the same informational coin.
28
10 Inversion of Free Energy Minimization via Extended
MB Density
In the previous parts of this paper, the blanket-density fieldρ(x) is constrained to lie in
[0, 1], ensuring that the “throttled” gradient flow
˙x = −[ 1− ρ(x)] ∇F(x)
always points downhill on the free energy F. Consequently, an agent following these
dynamics strictly minimizes F. Here, we relax the requirement ρ(x) ≤ 1 and allow
ρ(x) to exceed unity in certain regions. In that case, the prefactor[ 1 − ρ(x)] becomes
negative, and the flow reverses direction—driving the systemuphill on F. Theorem 6
below formalizes this phenomenon.
Theorem 6(Inversion of Free Energy Flow underρ >1). Let Ω ⊂ Rn be an open set,
and letF: Ω → R be aC1 function. Suppose we define anextended blanket-density field
ρ: Ω −→ R
and an open subsetU ⊂ Ω such that
ρ(x) > 1 for allx ∈ U.
Consider the modified dynamics
˙x = −[ 1− ρ(x)] ∇F(x), x (0) ∈ U.
Then for everyx ∈ U, the following statements hold:
1. Original normalization ofρ. In the original framework,ρ(x) was defined by
ρ(x) = Itrue(I(x); E(x) | B(x)) + ε
Itrue(I(x); E(x)) + ε ∈ [0, 1],
because unconditional mutual information I(I; E) is always at least as large as
conditional mutual information I(I; E | B). Therefore 1 − ρ(x) ≥ 0 ensured ˙x
pointed downward onF.
2. Extended definition allowingρ >1. To permitρ(x) > 1, replace the normalized
ratio Itrue(I; E | B)
Itrue(I; E) by a more general mapping
ρ(x) = f

Itrue(I; E | B)(x), Itrue(I; E)(x)

,
where f: R+ × R+ → R is chosen so thatf(x) > 1 on U. Examples include:
• Shifted ratio:
ρ(x) = Itrue(I; E | B)(x) + ε
Itrue(I; E)(x) + ε + α, α > 0,
which lies in[α, 1 + α].
• Weighted excess information:
ρ(x) = Itrue(I; E | B)(x)
Itrue(I; E)(x) + β

1 − Itrue(I; E | B)(x)
Itrue(I; E)(x)

, β > 1,
which can exceedβ when Itrue(I; E | B) ≪ Itrue(I; E).
In either construction,ρ(x) may exceed 1 for allx ∈ U.
29
3. Gradient-ascent whenρ >1. Whenever ρ(x) > 1, the coefficient[ 1− ρ(x)] is
strictly negative. Thus forx ∈ U,
˙x = −[ 1− ρ(x)] ∇F(x) = [ρ(x) − 1] ∇F(x),
which is thegradient-ascent flow onF instead of gradient-descent.
4. Free-energy increase formula. Along any trajectory x(t) satisfying ˙x(t) =
(ρ(x(t)) − 1) ∇F(x(t)) with x(t) ∈ U, one obtains
d
dtF(x(t)) = ∇F(x(t)) · ˙x(t) = (ρ(x(t)) − 1) ∥∇F(x(t))∥2 > 0,
since ρ(x(t)) − 1 > 0 and ∥∇F(x(t))∥2> 0 except at critical points. Consequently,
F(x(t)) strictly increases as long asx(t) ∈ U.
5. Separatrix atρ = 1 and illustrative example.The level set{x : ρ(x) = 1} is
a hypersurface on which˙x = 0. It separates:
• {ρ(x) < 1}: descent onF.
• {ρ(x) > 1}: ascent onF.
For a concrete example, letρ(x) be aC1 function such that
ρ(x) =



0.8, ∥x∥≤ 1,
1.2, 1 < ∥x∥≤ 2,
0.5, ∥x∥> 2,
with smooth transitions at∥x∥= 1 and ∥x∥= 2. Then:
• For ∥x∥≤ 1, ρ(x) = 0.8 < 1: the agent followsgradient-descent on F.
• For 1 < ∥x∥≤ 2, ρ(x) = 1.2 > 1: the agent followsgradient-ascent on F.
• For ∥x∥> 2, ρ(x) = 0.5 < 1: gradient-descent on F resumes.
This construction can producelimit-cycle or oscillatory behavior: the agent de-
scends in ∥x∥≤ 1, then ascends in1 < ∥x∥≤ 2, and descends again for∥x∥> 2,
repeatedly.
If the blanket-density factorρ(x) stays between0 and 1, then
˙x = −[ 1− ρ(x)] ∇F(x)
always points in the direction of decreasing free energy. In contrast, wheneverρ(x) > 1,
the multiplier[ 1− ρ(x) ] becomes negative and
˙x = (ρ(x) − 1) ∇F(x)
points in the direction of increasing free energy. Thus, in regions whereρ(x) > 1, the
agent climbs up the free energy landscape instead of descending it. The level set
{x : ρ(x) = 1}
forms a boundary separating “descent” regions (ρ < 1) from “ascent” regions (ρ > 1).
Crossing this boundary reverses the agent’s objective from minimizing free energy to
maximizing it. In reality, this is not a simple abstract extension of the initial model.
The “shift” we have inserted to makeρ >1 can be interpreted as a perturbation. Or, for
example, interpreting the human brain as a blanket-density field, the “shift” can be seen
as a form of psychopathology.
30
11 Joint Inference of an Unknown MB Density
How can an active inference agent learn about and move around in space?In the earlier
sections, we assumed that the agent has prior knowledge—at least in statistical form—of
the MB densityρ(x) or its empirical approximationρN (x). In more realistic settings,
however, the agent does not knowρN (x) in advance. It must, instead, infer the blanket
density while simultaneously minimizing variational free energy. We now show how an
active inference agent can learn the spatial profile ofρ(x) on the fly and prove that its
estimate converges to the true field.
11.1 Belief Model and Coupled Dynamics
Let Ω ⊂ Rn be compact, and letρtrue(x) ∈ C1(Ω) denote the true blanket density. The
agent maintains a parametric family{ρθ(x)}, θ ∈ Θ ⊂ Rp, with Θ compact and each
ρθ(x) lying in[0, 1]. Initially, the agent possesses a prior densityp0(θ) > 0 on Θ.
As the agent moves, it collects sensory datas(x(t)) at positions x(t). From each
sample, it constructs a likelihoodL(s(x); ρθ(x)) that measures how wellρθ(x) explains
the observed coupling between internal and external states. Under standard regularity
(continuity ofρθ in both arguments, bounded likelihoods, and identifiability ofθtrue), the
posterior
pt(θ) ∝ p0(θ)
tY
τ=0
L(s(x(τ)); ρθ(x(τ)))
concentrates on the true parameterθtrue satisfying ρθtrue (x) = ρtrue(x).
Simultaneously, the agent uses the current point estimate
ˆρt(x) = ρˆθt
(x), ˆθt = arg max
θ
pt(θ),
to drive free-energy descent:
˙x(t) = −[ 1− ˆρt(x(t))] ∇F(x(t)).
Thus, the agent interleaves Bayesian updating ofˆθt and state evolution under a scaled
gradient flow.
11.2 Consistency of Blanket-Density Learning
Theorem 7(Convergence of Joint Inference and Descent). Assume:
1. Each ρθ(x) is C1 on Ω×Θ, takes values in[0, 1], and the mapθ 7→ ρθ(x) is injective
for everyx ∈ Ω.
2. The likelihoodL(s; ρθ(x)) is Lipschitz in boths and ρθ(x), and identifiesθtrue such
that ρθtrue = ρtrue.
3. The priorp0(θ) > 0 in a neighborhood ofθtrue.
4. The descent flow under the true blanket density,
˙x = −[ 1− ρtrue(x)]∇F(x),
is ergodic onΩ: it visits every open set infinitely often.
5. F ∈ C2(Ω) has ∥∇F(x)∥> 0 except at finitely many isolated minima.
Then ast → ∞, the agent’s point estimateˆρt(x) converges uniformly toρtrue(x) on every
compactK ⊂ Ω, almost surely:
sup
x∈K
|ˆρt(x) − ρtrue(x)|
t→∞
− − − →0.
31
Proof. Because the true descent flow visits every open neighborhood infinitely often, the
agent samples sensory data at arbitrarily many positions throughoutΩ. Under assump-
tions (1)–(3), classical consistency for input-driven parameter estimation guarantees that
pt(θ) concentrates onθtrue, so ˆθt → θtrue and hence ˆρt(x) → ρtrue(x) uniformly on com-
pacts.
We must ensure that using ˆρt in place of ρtrue does not break ergodicity. Since
ˆρt → ρtrue uniformly, for larget the perturbed vector field
−[ 1− ˆρt(x)]∇F(x)
differs from the true flow by at most a small uniform error. BecauseF has no plateaus,
this small perturbation leaves the trajectory qualitatively unchanged: it continues to visit
each open neighborhood infinitely often. Hence the learning process remains ergodic,
validating the consistency argument ad infinitum.
Theorem 7 shows that an active inference agent, without prior knowledge ofρ(x),
can learn the blanket density while descending free energy. Ergodicity ensures the agent
gathers enough data to identifyθtrue almost surely, and free energy minimization prevents
collapse into a zero-blanket state. Consequently,ρ(x) becomes unpredictable in advance:
the agent must discover its own coupling constraints by moving through and sampling
the environment. This extension embeds the blanket into the agent’s inference process,
yieldingafullyself-consistentactiveinferencemodelonanunknownstochasticlandscape.
12 MB Density: Axiomatization and Derivation of the
FEP
In this section we provide a rigorous, assumption-light derivation of free energy min-
imization as a necessary dynamical consequence of the information geometry induced
by the MB Densityρ(x). Our strategy is: (i) postulate minimal axioms on ρ (regu-
larity and informational meaning), plus symmetry/isotropy assumptions that rule out
dynamically uninformative tangential drifts; (ii) deduce that any admissible dynamics
must be colinear with∇ρ with magnitude depending only on the levelρ(x); (iii) show
that this structureforces the existence of a scalar potentialF such that the dynamics
is a gradient flow˙x = −∇F. Classical choices (e.g.F = −log(1 − ρ + ε)) then appear
as corollaries—monotone reparameterizations of the emergent potential—rather than ad
hoc postulates. We also prove that the FEP has operational content precisely on the
regime ρ <1, while it is informationally vacuous onρ = 1.
We work on an open domainΩ ⊂ Rn with the Euclidean metric;x ∈ Ω denotes the
agent’s state.
12.1 Setup and standing assumptions
For eachx ∈ Ω, let (I, B, E) be a measurable partition of the variables of a generative
model, inducing a local data distributionpx. Define
MI(x) := I(I; E)x, CMI(x) := I(I; E | B)x. (10)
Axiom 8(positivity of MI). There exists an open setU ⊆ Ω such thatMI(x) > 0 for
almost everyx ∈ U.
Axiom 9(regularity). The mapsx 7→ MI(x) and x 7→ CMI(x) are C1 on U.
Definition 12.1(MB Density). For x ∈ U define
ρ(x) := 1 − CMI(x)
MI(x) ∈ (0, 1]. (11)
Extend by continuity withρ = 1 where CMI = 0. Assume ρ ∈ C1(U).
Interpretation. ρ(x) = 1 iff the blanket perfectly screensI and E (I ⊥ E | B); ρ ↓ 0
corresponds to maximal conditional coupling.
32
12.2 Operability of inference
Theorem 10(Operability iffρ <1). For x ∈ U, ρ(x) = 1 ⇔ I(I; E | B)x = 0. In this
case, any variational free energy functional
F(x) = Eqx[ logqx(s) − log px(o, s)] (12)
has zero first variation with respect to external perturbations transmitted throughB: the
“outer” gradient vanishes and inference is informationally vacuous.
Proof. If ρ = 1 then CMI = 0, hencepx(i | e, b) = px(i | b) (conditional independence).
Therefore changes ine cannot affect F once b is fixed, and the outer gradient is zero.
The converse is by Definition 12.1.
12.3 Symmetry, isotropy, and the form of admissible dynamics
Let v : U → Rn be the dynamical field,˙x = v(x).
Axiom11 (level-setsymmetry). Foreverydiffeomorphism Φ preservingρ (i.e.ρ◦Φ = ρ),
the dynamics is equivariant:DΦ(x) v(x) = v(Φ(x)).
Axiom12 (notangentialpreference) . Oneachregularlevelset Lc := {x ∈ U : ρ(x) = c},
the tangential component ofv vanishes for a.e.x: v(x) is colinear with∇ρ(x) wherever
∇ρ ̸= 0.
Lemma 13 (colinearity). Under Axioms 11 and 12, there exists a scalar functionα :
U → R such thatv(x) = −α(x) ∇ρ(x) for a.e.x ∈ U.
Proof. By Axiom 12, v(x) has no tangential component onLc, hence it is normal to
Lc, i.e. colinear with∇ρ. The sign is chosen so that flow proceeds towards increasing
information accessibility (monotone decrease of screening).
Axiom 14(level invariance of magnitude). α is constant along each level set ofρ: there
exists a continuousf : [0, 1] → [0, ∞) with α(x) = f(ρ(x)).
Axiom 15(stall at perfect screening). f(1) = 0 and f(ρ) > 0 for ρ <1.
Combining Lemma 13, Axiom 14 and Axiom 15 we obtain theforced form of the
dynamics:
˙x = v(x) = −f(ρ(x)) ∇ρ(x). (13)
12.4 Integrability and the emergent Free Energy potential
Lemma 16(integrability). Define w(x) := 1
f(ρ(x)) ∇ρ(x) on the regular set{x : ∇ρ(x) ̸=
0}. Then w is irrotational; hence, there existsF ∈ C2 such that∇F = w.
Proof. Since w = ψ(ρ) ∇ρ with ψ(ρ) := 1 /f(ρ), choose any C2 primitive Ψ of ψ, i.e.
Ψ′ = ψ. Then w = ∇(Ψ ◦ ρ) is a gradient field.
Definition 12.2(Emergent Free Energy). Fix a constantC ∈ R and define
F(x) := Ψ(ρ(x)) + C =
Z ρ(x) 1
f(u) du + C. (14)
Theorem 17(Emergence of FEP). Under Axioms 8–15, the dynamics(13) is exactly
a gradient flow of the potentialF in (14):
˙x = −∇F(x). (15)
Moreover,F is a Lyapunov function:
d
dtF(x(t)) = ∇F · ˙x = −∥∇F∥2≤ 0, (16)
with equality iff∇ρ = 0 or ρ = 1.
33
Proof. ByLemma16, ∇F = 1
f(ρ) ∇ρ. Multiplyingbothsidesby −f(ρ) yields−f(ρ)∇F =
−∇ρ. Comparing with (13) gives ˙x = −∇F. The Lyapunov property follows from
standard gradient-flow calculus; vanishing occurs only at critical points ofF (i.e. ∇ρ = 0)
or wheref(1) = 0 (i.e. ρ = 1).
Corollary 18 (class of representatives and uniqueness up to reparameterization). If
˜F = ϕ ◦ F with ϕ strictly increasing, then ˙x = −∇ ˜F generates the same trajectories
up to time-rescaling. Conversely, any gradient potential producing the same trajectories
must be a strictly monotone reparameterization ofF. In particular, the classical choice
f(ρ) = 1 − ρ + ε (ε >0) yields
F(x) = −log(1 − ρ(x) + ε) + C, (17)
as a corollary of Theorem 17.
12.5 Link to standard variational free energy
Let F(x) denote a standard variational free energy (VFE) for the recognizerqx.
Axiom 19(informational alignment). There exists a continuousκ : [0, 1] → [0, ∞) with
κ(1) = 0 and κ(ρ) > 0 for ρ <1, such that
∇F(x) = κ(ρ(x)) ∇ρ(x). (18)
Proposition 12.1 (directional equivalence). Under Axiom 19, there exists a strictly
increasingϕ such that the gradient flow ofF coincides with that ofϕ◦F; hence, after time-
rescaling, the VFE-descent is dynamically equivalent to the emergent FEP of Theorem 17.
Proof. From∇F = κ(ρ)∇ρ and ∇F = (1/f(ρ))∇ρ, defineϕ′ ◦ F := κ(ρ)f(ρ). Since ρ is
a strictly monotone function ofF by (14) and Axiom 15,ϕ is well-defined and strictly
increasing. Then ∇(ϕ ◦ F) = ϕ′(F)∇F = κ(ρ)∇ρ = ∇F. A constant time-rescaling
aligns the flows.
12.6 Limits, regularity, completeness
• Critical points of ρ. Where ∇ρ = 0 , the flow stalls; F has stationary points
(minima, maxima, or saddles).
• Frontier ρ = 1. By Axiom 15,f(1) = 0; we may normalizeF|ρ=1= 0. At ρ = 1
the FEP is informationally vacuous by Theorem 10.
• Domain issues. The set whereMI = 0 has measure zero inU by Axiom 8; the
extension ρ = 1 is continuous there.
• Uniqueness (strong).Under Axioms 11–15, any admissible dynamics must take
the form (13); hence a potentialF exists necessarilyand the class of representatives
is exactly{ϕ ◦ F : ϕ ↑}.
Conclusion. The MBD ρ together with symmetry and isotropy axioms forces the
dynamics to be a gradient flow of an emergent Free Energy potential defined by (14).
Thus, the FEP is not primitive but aderivative structure prevailing on the informational
regime ρ <1 and becoming vacuous atρ = 1.
13 Limitations and the Risk of Circularity
In Theorem 1, it is assumed that the mutual information (both marginal and conditional)
is C1 and that their gradients align with∇F over an open setD. We recognize that
this requirement of “gradient alignment” is extremely strong and likely does not hold in
many real-world applications (biological or engineering), where∇F and ∇I may point
in very different directions.
34
In Theorems 3 and 4, the assumption of “constant covariance”
Cov(ρ(x), ∥∇F(x)∥2) = C
is an artificial simplification, which is difficult to justify in practical situations where
both ρ(x) and ∇F(x) can vary spatially in complex ways.
ThekNN–KSGestimator, onwhichtheestimationof ρN relies, requireshigh-dimensional
datasetsandsuffersfromthecurseofdimensionality. Ifthedata si havedimension d ≫ 1,
obtaining a sufficiently accurate mutual information estimate to guarantee convergence
in theC1 norm becomes practically infeasible.
All of these regularity and stationarity assumptions limit the practical applicability of
thesetheorems: ifonetrulywantstousethemtoexplainneuralorbehavioralphenomena,
itisnecessarytodemonstratethatthebasicassumptions(alignment, constantcovariance,
exponential decay of correlations) are at least approximately satisfied on real data.
Another limitation concerns the possible risk of circularity of the overall argument.
Saying “the agent moves to regions of lowp” can be read as “the agent moves where it
is already well coupled,” which is arguably just restating “the agent moves to reduce free
energy” in spatial terms. The apparent circularity dissolves once one recognizes that here
ρ(x) is defineda priorias an external field of conditional-information estimates—derived
from raw sensory-environment samples—rather than as a byproduct of an agent’s free-
energy descent. In other words, one first samples the joint statistics of internal, external,
and blanket variables to buildρ(x) independently of any inference process; only then does
the agent navigate according to∇F and the precomputedρ. Becauseρ(x) is not recom-
puted from the agent’s current beliefs but estimated from external data, minimizing free
energy does not “chase its own tail” but rather follows a fixed landscape of informational
permeability, rendering any notion of tautological self-reference illusory.
14 Conclusions
The core idea of this paper is to reconceptualize the FEP not merely as an internal
rule for belief updating but as genuine spatial navigation through a continuously varying
MB density field. Instead of treating the informational boundary between internal and
external states as a binary condition, we introduce a functionρ(x), defined at every point
x in a continuous domain, which quantifies how “insulated” that location is. Values of
ρ(x) near zero indicate that internal and external states are strongly coupled (minimal
insulation), whereas values close to one indicate that a location is almost entirely isolated
(maximal insulation).
To make this precise, the paper tiesρ(x) to an information-theoretic measure: it
is the ratio between conditional mutual informationI(I; E | B), which measures how
much information about external statesE remains once boundary statesB are known,
and unconditional mutual informationI(I; E), which captures overall coupling. Because
conditioning cannot increase mutual information, that ratio always lies between zero and
one. Consequently, whenρ(x) is near zero, most of the mutual information between inter-
nal and external states bypasses the boundary, and whenρ(x) is near one, conditioning
on the boundary removes almost all of the coupling. In other words,ρ(x) serves as a
continuous gauge of how effectively the environment can inform the agent at locationx.
The formulation of the FEP presented here, grounded in the concept of a spatially
distributed MB densityρ(x), offers several theoretical advances relative to traditional
approaches. In contrast to standard formulations that assume the FEP as a universal
law governing all systems equipped with a Markov blanket, our approach introduces
a continuous informational field that modulates the very applicability of the principle.
Specifically, the FEP becomes locally definable only in regions whereρ(x) < 1, that is,
where conditional dependence between internal and external states—mediated by the
blanket—is sufficiently high to permit inferential coupling. This perspective yields four
distinct advantages. First, it introduces a topological criterion of inferential viability,
replacing the binary presence or absence of a blanket with a scalar field that continu-
ously measures the strength of informational separation. This makes it possible to study
inference not as a global property, but as asituated phenomenon, dependent on the
35
agent’s position within an informational manifold. Second, it reorients the explanatory
architecture of the FEP: rather than positing inference as an intrinsic drive of the sys-
tem, it treats inference as anaffordance of the environment—possible only where the
topology of ρ(x) permits it. Third, this framework offers ageometrization of inference.
By defining informational gradients, curvature, and metric structure on the fieldρ(x),
we provide tools to analyze cognitive processes as forms of motion through an infor-
mational landscape. This opens new paths for modeling agent-environment interaction,
including multi-agent systems, distributed cognition, and ecological learning. Finally, the
concept of MB density allows us to extend the reach of the FEP to systems where the
blanket structure is ambiguous, dynamic, or absent—such as in decentralized networks,
social systems, or collective organisms. In such contexts,ρ(x) can serve as a measure of
inferential accessibility even in the absence of well-defined agent boundaries.
36
Figure 2: Agent trajectories shaped by Markov blanket density.This figure compares
two systems governed by the same free energy minimization equation˙x = −(1 − ρ(x))∇F(x),
where ρ(x) is the spatially distributed Markov blanket density.Left: In the case of an infant
engaged in social interaction, the MB density is low, allowing for strong coupling with the envi-
ronment. Theagentfollowsthefreeenergygradientefficiently, resultinginasmoothanddirected
trajectory. Right: In the bureaucratic system, high blanket density inhibits coupling. Despite
non-zero free energy gradients, the trajectory is shallow and constrained, demonstrating how
strong informational boundaries block adaptive inference. The color maps represent the local
coupling potential(1 − ρ), highlighting the spatial modulation of active inference. Parameters:
the Figure describes the trajectories of an agent on the free-energy landscapeF(x, y) = x2 + y2
under two different blanket densities. The agent starts at(0.8, 0.8) in the square[−1, 1]×[−1, 1]
and evolves for 100 explicit-Euler steps with time step∆t = 0 .02. Its velocity at each step
is given by ˙x = −(1 − ρ) ∇F(x), with ρ = 0 .2 (blue curve, “Infant”) orρ = 0 .8 (red curve,
“Bureaucracy”), plotted in 2D with equal aspect ratio to illustrate how lower blanket density
permits faster descent toward the origin.
Figure 3: MB density as an informational topology. This 3D surface plot visualizes
the spatial distribution of MB densityρ(x) in a high-density regime (e.g., a bureaucratic sys-
tem). Regions of highρ(x) indicate strong informational boundaries—zones of limited coupling
between internal and external states. Such topologies constrain active inference by inhibiting
access to meaningful sensory feedback. This figure illustrates how the geometry ofρ(x) can
serve as an inferential landscape that shapes the success or failure of free energy minimization.
37
Figure 4: When variational free energy minimization is obstructed by informational
structure. This figure illustrates a theoretical conflict central to the paper. An agent (red dot)
begins in a region of high MB density (dashed red contour, shaded red area). Although the agent
is embedded in a free energy landscape (blue gradient), and a global minimum of variational
free energy is present (black dot), the high local value ofρ(x) inhibits coupling between the
agent’s internal states and external causes. As a result, the agent cannot exploit the free energy
gradient: adaptive inference is blocked not by the absence of a minimization path, but by the
statistical opacity of the surrounding space. The figure demonstrates that the ability to minimize
free energy is contingent upon local informational accessibility. Parameters: Contour plot of the
free-energy landscape F(x, y) = x2 + y2 obstructed by a high-density barrier inρ(x, y). On
the same100 × 100 grid over[−1, 1]2, F is contoured at 20 levels using the “Blues” palette. A
circular region centered at(0.5, 0.5) with radius 0.2 is assignedρ = 0.95, while the remainder of
the grid hasρ = 0.05; theρ = 0.5 boundary is overlaid as a red dashed contour. The starting
point (0.2, 0.2) is marked with a red dot and the global minimum location(0.5, 0.5) with a black
dot.
38
Figure 5: Effect of Markov blanket density on agent movement across informational
landscapes. This two-panel 3D visualization illustrates how the spatial distribution of MB
density ρ(x) modulates an agent’s ability to perform gradient descent on free energy. In both
panels, an agent attempts to follow the same epistemic imperative—minimization of variational
free energy—by moving through a landscape shaped byρ(x). (A) In a region ofweak MB density
(low ρ(x)), the informational coupling between agent and environment is strong. The agent can
descend the surface efficiently, adapting its trajectory to the available gradient field. (B) In
contrast, in a region ofstrong MB density (high ρ(x)), the agent is epistemically insulated.
Coupling is weak and movement is suppressed: although gradients still exist, the agent cannot
access or respond to them effectively. These simulations demonstrate that the capacity to
minimize free energy is shaped not only by internal dynamics but also by the external topology
of informational boundaries. Parameters: Side-by-side 3D depictions of free-energy surfaces
modulated by low versus high blanket-density fields, with corresponding agent trajectories. In
each panel, F(x, y) = x2 + y2 is plotted over a 100 × 100 grid on [−1, 1]2 using an alpha
of 0.7 and stride 4. In panel A, ρ(x, y) = 0 .2 + 0.3x + 1
2 (range [0.2,0.5]) and in panel B,
ρ(x, y) = 0 .8 + 0.2x + 1
2 (range [0.8,1.0]). From the initial point (0.8, −0.8), each trajectory
is simulated for 80 explicit-Euler steps with∆t = 0.02 using ˙x = −(1 − ¯ρ) ∇F(x), where ¯ρ is
the mean density over the panel; trajectories are drawn as red lines with markers against the
translucent energy surface.
39
Figure 6: Algorithm Agent Navigation in a Dynamic 3D Blanket-Density Field
(Section 5.4). The agent (red during the noisy phase, blue during the deterministic phase)
navigates a 3D barrier field ρ(x, y, z, t) that evolves over time due to two moving Gaussian
coupling regions. In the first half of the simulation, strong noise allows the agent to penetrate
thick barriers; in the second half, without noise, the agent smoothly steers around high-ρ zones
and converges on its target at(2, 2, 2). For more details, see Appendix A.
40
Figure 7: Advanced Agent Navigation in Nonstationary 3D Environment. Snapshots
of the three-dimensional blanket densityρ(x, y, z, t) (displayed with a plasma heatmap) at three
horizontal slices z ≈ −1.5, 0.0, 1.5 for times t = 0 , 400, and 699. At each slice, the white,
black, and gray contour lines correspond toρ = 0.2, ρ = 0.5, and ρ = 0.8, indicating regions
of low, medium, and high barrier strength. Red dots (sized proportionally to instantaneous
speed) mark the agent’s visits during the noisy phase (t < 400), often penetrating even the
darkest, high-barrier contours, while blue dots show the agent’s path during the deterministic
phase (t ≥ 400), hugging just outside the strongest barriers despite occasional perception noise.
In the lower right, the full 3D trajectory is plotted: the red segment (t = 0 . . .400) wanders
through overlapping, rotating ellipsoidal obstacles due to colored movement noise, whereas the
blue segment (t = 400 . . .699) smoothly navigates around the gray isosurface clouds att = 400
(where ρ >0.8). Black and yellow markers denote the agent’s start at(−2.5, −2.5, −2.5) and
the final position of the moving helix target. This composite visualization demonstrates how
an inertial agent with AR(1) movement and perception noise first plows through dynamically
changing, anisotropic obstacles and then transitions to informed, barrier-avoiding navigation
toward a moving goal. For more details, see Appendix A.
41
Figure 8: Inertial Agent Navigation in Ultra-Complex 3D Barriers. Each panel in this
3×3 grid shows a horizontal slice of the ultra-complex, nonstationary barrier fieldρ(x, y, z, t)
(plotted with a plasma colormap) atz ≈ −1.5, 0.0, and +1.5 for timest = 0, 350, and 599. In
each slice, white contours markρ = 0.2 (low barriers), black contours markρ = 0.5 (medium
barriers), and gray contours markρ = 0.8 (strong barriers). Overlaid red dots—sized in propor-
tion to instantaneous speed—represent the agent’s visits during the noisy phase (t <350), often
penetrating even the highest-barrier (gray) regions because colored movement noise overwhelms
the barrier. Blue dots correspond to the deterministic phase (t ≥ 350), where the inertial agent,
subject to AR(1) perception noise, hugs just outside the strongest barrier contours and weaves
through lower-ρ corridors. In the lower right panel, the complete 3D trajectory is shown: the red
segment (t = 0 . . .350) meanders through overlapping, rotating ellipsoidal Gaussians, AR(1)-
drifting micro-obstacles, and a time-varying random Fourier field. When movement noise ceases
at t = 350, the blue segment (t = 350 . . .599) smoothly navigates around the layered isosurfaces
at t = 350, where0.5 < ρ≤ 0.8 (light gray) andρ >0.8 (dark gray). Black and yellow markers
denote the agent’s starting location(−2.5, −2.5, −2.5) and the final position of the moving helix
target, respectively. For more details, see Appendix A.
42
Appendix A: Detailed Objectives and Methodology of
Figures 6-7-8
Figure 6
The goal of Figure 6 is to construct and visualize a continuous three-dimensional blanket-
density field ρ(x, y, z, t), to demonstrate how high-noise perturbations enable an agent
to traverse thick Markov blankets, and then to show how, once the noise is removed, the
agent’s dynamics
˙x = −(1 − ρ(x, t)) ∇F(x), F (x) = ∥x − (2, 2, 2)∥2,
cause it to avoid high-ρ zones and find a low-resistance path toward a fixed target at
(2, 2, 2).
At each time stept = 0, 1, . . . ,399 on a uniform35 × 35 × 35 grid over[−3, 3]3, we
define two moving Gaussian coupling regions:
c1(t) = (1.5 cos(0.02 t), 1.5 sin(0.02 t), 0), σ 1 = 0.7,
c2(t) = (1 − 0.01 t, −1 + 0.01 t, 0.5 sin(0.015 t)), σ 2 = 0.5.
For each grid pointx = (x, y, z), the total couplinga(x, t) is the sum of the two Gaussian
values
a(x, t) = exp

−∥x − c1(t)∥2
2 σ2
1

+ exp

−∥x − c2(t)∥2
2 σ2
2

.
We then form
ρcorr(x, t) = a(x, t)2
a(x, t)2 + 0.92 , I (x, t) = −1
2 ln[ 1− ρcorr(x, t)2],
and normalizeI(x, t) over the entire grid to obtainρ(x, t) ∈ [0, 1].
The agent’s trajectory is computed in two phases:
• Noisy Phase(0 ≤ t <200): At each step,
x(t + ∆t) = x(t) + ∆ t v(t) + η(t), ∆t = 0.03,
where
v(t) = −(1 − ρ(x(t), t)) ∇F(x(t)), η(t) ∼ N(0, 0.92I3).
• Deterministic Phase(200 ≤ t <400): Noise is removed, and
x(t + ∆t) = x(t) + ∆ t
h
−(1 − ρ(x(t), t)) ∇F(x(t))
i
.
Figure6isdisplayedasa 3×3 gridoftwo-dimensionalheatmaps. Columnscorrespond
to t = 0, 200, 399, and rows correspond to slices atz ≈ −1.0, 0.0, 1.0. Each heatmap
uses a plasma colormap to showρ(x, y, z, t), with white and black contours atρ = 0.3
and ρ = 0.6 indicating moderate and strong barrier levels. Overlaid red dots show the
agent’s positions during the noisy phase (for each slice, points where|zagent −zslice|< 0.1
overt ±10), while blue dots show positions during the deterministic phase. In the lower-
right panel, the full 400-step trajectory is shown in three dimensions: a red segment
for 0 ≤ t ≤ 200 (noisy phase), which penetrates high-ρ regions, and a blue segment
for 200 ≤ t ≤ 399 (deterministic phase), which winds around gray points (grid cells at
t = 200 satisfying ρ >0.6). A black dot at(−2.5, −2.5, −2.5) marks the agent’s start,
and a yellow dot at(2, 2, 2) marks the target.
43
Figure 7
Figure 7 demonstrates an advanced agent navigating an even more nonstationary 3D
environment. The environment is a40 × 40 × 40 grid over[−3, 3]3 containing:
1. Four rotating, anisotropic ellipsoidal Gaussians with parameters
σblobs = {(0.7, 0.4, 0.3), (0.5, 0.5, 0.6), (0.6, 0.3, 0.7), (0.4, 0.6, 0.5)}.
• Blob1: Center (1.5 cos(0.02t), 1.5 sin(0.02t), 0), covariancediag(0.72, 0.42, 0.32)
rotated aboutz by 0.01t.
• Blob2: Center (1−0.01t, −1+0.01t, 0.5 sin(0.015t)), covariancediag(0.52, 0.52, 0.62)
rotated abouty by 0.015t.
• Blob3: Center (0.5 cos(0.03t), 0.5 sin(0.03t), cos(0.02t)), covariancediag(0.62, 0.32, 0.72)
rotated aboutx by 0.012t.
• Blob4: Center (2 cos(0.01t), 2 sin(0.01t), −1+0.005t), covariancediag(0.42, 0.62, 0.52)
rotated aboutz by 0.02t.
2. Ten micro-obstacles of widthσobs = 0 .3 whose centers {mi(t)} follow an AR(1)
process withϕmicro = 0.9. Each micro-obstacle contributes
0.3 exp

−∥x − mi(t)∥2
2 (0.3)2

to the total coupling fielda(x, t).
3. A spatio-temporal random Fourier field built as the sum of fifteen sinusoidal waves
15X
k=1
sin(wk · (x, y, z) + ωk t + ϕk),
withrandomwavevectors wk ∼ N(0, 1.52 I3), frequenciesωk ∼ Uniform(0.005, 0.02),
and random phasesϕk ∼ [0, 2π]. This field is normalized to[0, 1] and scaled by0.5
before adding toa(x, t).
Thus, at each time0 ≤ t <700,
a(x, t) =
4X
j=1
exp [−1
2(x−cj(t))⊤Σj(t)−1(x−cj(t))] + 0.3
10X
i=1
exp
h
−∥x − mi(t)∥2
2 (0.3)2
i
+ 0.5 fRF(x, t).
We compute
ρcorr(x, t) = a(x, t)2
a(x, t)2 + 1.02 , I (x, t) = −1
2 ln[ 1− ρcorr(x, t)2],
and normalizeI(x, t) across all grid points to obtainρ(x, t) ∈ [0, 1].
The agent pursues a moving helix target
g(t) = (2 cos(0.005 t), 2 sin(0.005 t), 2 − 0.002 t)
using second-order dynamics (massm = 1.2, damping γ = 0.8, time step∆t = 0.02).
Its perceived barrier strength is the average ofρ over the local neighborhood of radius
1.0 on the 403 grid, corrupted by AR(1) perception noise (ϕperc = 0.6, σperc = 0.15).
During 0 ≤ t <400 (the noisy phase), movement noise follows AR(1) withϕmove = 0.7
and σmove = 0.7; for 400 ≤ t <700 (deterministic phase), movement noise is removed
but perception noise remains.
44
Figure 8
This figure extends complexity by using a 30 × 30 × 30 grid over [−3, 3]3 and three
rotating, anisotropic ellipsoidal blobs:
σblobs = {(0.8, 0.5, 0.3), (0.6, 0.4, 0.7), (0.5, 0.6, 0.4)}.
• Blob1: Center (1.5 cos(0.015 t), 1.5 sin(0.015 t), 0.5 sin(0.01 t)), covariancediag(0.82, 0.52, 0.32)
rotated aboutz by 0.02 t.
• Blob2: Center (−1.2 cos(0.018 t), 1.2 sin(0.018 t), −0.5 cos(0.012 t)), covariancediag(0.62, 0.42, 0.72)
rotated aboutx by 0.017 t.
• Blob3: Center (0.5 cos(0.02 t), −0.5 sin(0.02 t), 1.5 sin(0.015 t)), covariancediag(0.52, 0.62, 0.42)
rotated abouty by 0.013 t.
Eight micro-obstacles of widthσobs = 0.3 drift via an AR(1) process withϕmicro =
0.85. A spatio-temporal random Fourier field (sum of 15 sinusoids with random wavevec-
tors k ∼ N(0, 1.52 I3), frequencies in[0.005, 0.02], and random phases) is normalized to
[0, 1] and scaled by0.5. At each0 ≤ t <600, the total couplinga(x, t) is the sum of the
three anisotropic Gaussians, eight micro-Gaussians (scaled by 0.25), and0.5×the random
Fourier field. We then compute
ρcorr(x, t) = a(x, t)2
a(x, t)2 + 1.02 , I (x, t) = −1
2 ln(1 − ρcorr(x, t)2),
normalize I(x, t) over the303 grid to obtainρ(x, t) ∈ [0, 1].
The agent uses second-order dynamics (massm = 1.0, damping γ = 0.6, time step
∆t = 0.02) to chase a moving helix target
g(t) = (2 cos(0.008 t), 2 sin(0.008 t), 2 − 0.0015 t).
Its perceived barrier strength is the average ofρ over a spherical neighborhood of radius
1.0 (via nearest-neighbor averaging on the303 grid) plus AR(1) perception noise (ϕperc =
0.65, σperc = 0.12). During 0 ≤ t <350 (noisy phase), movement noise is AR(1) with
ϕmove = 0.75, σmove = 0.7; for 350 ≤ t <600 (deterministic phase), movement noise is
removed.
Appendix B: Estimating MB Density via KSG Mutual
Information
This appendix explains how to estimate MB density from data using a practical method
based on nearest-neighbor statistics. The approach, based on the KSG estimator, lets us
compute mutual information directly from samples, without needing to guess the shape
of the underlying distributions [23, 24, 25, 32, 33, 34, 35, 36].
Motivation and Theoretical Framework
We define the MB densityρ(x) as the conditional mutual information:
ρ(x) := I(sint : sext | sblanket = x)
This quantity expresses the degree to which blanket states mediate information flow. A
lowρ(x) indicates strong coupling (porous blanket), while a highρ(x) indicates statistical
insulation. Estimating ρ(x) from samples requires non-parametric tools, for which we
adopt the KSG estimator.
45
The KSG Estimator
Given samples(xi, yi), the mutual information estimator is:
ˆIKSG(X; Y ) = ψ(k) + ψ(N) − 1
N
NX
i=1
[ψ(nx(i) + 1) +ψ(ny(i) + 1)]
where ψ(·) is the digamma function, k is the neighbor order, and nx(i), ny(i) count
neighbors in the marginal spaces within joint-space neighborhoods.
To estimate conditional mutual information:
I(X; Y | Z) ≈ I(X; [Y, Z]) − I(X; Z)
This can be computed by applying the KSG estimator to(X, [Y, Z]) and (X, Z).
Simulation Example
We simulate the following generative process:
sext ∼ U(0, 1)
sblanket = sin(2πsext) + η1, η 1 ∼ N(0, 0.05)
sint = cos(2πsblanket) + η2, η 2 ∼ N(0, 0.05)
This structure introduces nonlinear, noise-perturbed coupling between the variables. Us-
ing 300 samples andk = 5, the estimated mutual information values were:
I(sint; sext, sblanket) ≈ 1.88 nats, I (sint; sblanket) ≈ 0.44 nats
So the estimated Markov blanket density is:
ρ(x) = I(sint : sext | sblanket) ≈ 1.44 nats
By constructing empirical spatial maps ofρ(x) across agent-environment interfaces,
onecancomputegradientsandsimulateagentdynamicsbasedonvariationalflows. These
flows reflect movement toward regions of maximal information exchange and support the
main claim of this paper: that active inference policies emerge from navigating MB
density fields. Therefore, by developing a KSG-based algorithm to estimateρ(x) from
sampled data, we open a research path for applying active inference to real sensory
trajectories—where one must learn the blanket density from streaming measurements.
One can now ask questions such as: How does estimation error inρ(x) affect planning?
What are the optimal sampling strategies to reduce uncertainty in blanket density? How
does noisy or partial observation of state-variables bias inference ofρ(x)?
Error Propagation from KSG to Free-Energy Descent (withptrue)
In this subsections, we developed an active-inference framework in which an agent navi-
gatesacontinuousstatespacebydescendingthevariationalfreeenergy F(x) = −ln ptrue(s(x), η(x)).
Central to this dynamic is the MB densityρ(x), which the agent must estimate in real
time via a KSG mutual-information estimator, yieldingρN (x). BecauseρN (x) inevitably
differs from the true blanket densityρtrue(x), our goal here is to quantify precisely how
the resulting pointwise error∆ρN (x) slows the agent’s descent ofF(x). Concretely, we:
1. Bound ∆ρN (x) uniformly overΩ, showing it scales likeN−1/(d+1) with high prob-
ability.
2. Translatethaterrorintoaperturbationoftheagent’svelocity ˙x = −[1−ρ(x)]∇xF(x),
yielding a local slowdown proportional to∆ρN (x).
3. Integrate these local effects along a finite descent path to derive an asymptotic
bound on the total “convergence delay”TN − T, proving it isOp(N−1/(d+1)).
46
TheseresultsmakeexplicithowKSGestimationaccuracy, samplesize N, andambient
dimension d jointly determine the agent’s performance in minimizing free energy.
In this subsection, we incorporate the notation
ptrue(s(x), η(x)) = the true joint density of sensory signalss(x) and latent statesη(x),
which underlies the variational free energy
F(x) = −ln ptrue(s(x), η(x)),
evaluated at each positionx ∈ Ω. We also recall the notation
ρtrue(x) = 1 − Itrue(I(x); E(x) | B(x))
Itrue(I(x); E(x)) ,
which is the ground-truth MB density atx. Here:
• Itrue(I(x); E(x)) is the true mutual information between internal variablesI(x)
(within a ball of radiusr1 around x) and external variablesE(x) (outside a ball of
radius r2).
• Itrue(I(x); E(x) | B(x)) is the true conditional mutual information when condition-
ing on blanket variablesB(x) in the shellr1 ≤ ∥y − x∥ < r2.
We estimateρtrue(x) via the KSG-estimator fromN samples, defining
ρN (x) = 1 −
bI(I(x); E(x) | B(x))
bI(I(x); E(x))
.
Our goal is to quantify how the pointwise estimation error∆ρN (x) = ρN (x) − ρtrue(x)
propagates through the active-inference dynamics
˙x = −[ 1− ρ(x)] ∇xF(x),
and in particular how it delays the time to descend to a given free-energy level. Through-
out, we assume:
(i) Regularity ofF. F(x) = −ln ptrue(s(x), η(x)) is C2 on Ω, and there exist con-
stants 0 < m≤ LF such that
m ≤ ∥∇xF(x)∥ ≤LF for allx ∈ Ω
(away from any isolated critical points).
(ii) Regularity of ρtrue. ρtrue ∈ C1(Ω) with ∥∇ρtrue(x)∥ ≤Lρ uniformly, and0 ≤
ρtrue(x) ≤ 1 − δ on the regions traversed by the agent (for someδ >0).
(iii) KSG estimation error.For radiir1(N), r2(N) ∼ N−1/(d+1), the KSG estimator
of each mutual-information term satisfies, uniformly onΩ,
|bI(I; E)(x)−Itrue(I; E)(x)| = Op(N
−
1
d + 1), |bI(I; E | B)(x)−Itrue(I; E | B)(x)| = Op(N
−
1
d + 1).
Under these conditions, we prove:
Lemma 20 (Uniform Consistency of ρN ). If r1(N), r2(N) ≈ c N−1/(d+1), then there
exists a constantC1 > 0 such that, with probability tending to 1,
sup
x∈Ω
|ρN (x) − ρtrue(x)| ≤C1 N− 1
d+1 .
47
Proof Sketch.Write
ρN (x) = 1 −
bIc(x)
bIu(x)
, ρ true(x) = 1 − Ic(x)
Iu(x),
whereIu(x) = Itrue(I(x); E(x)), Ic(x) = Itrue(I(x); E(x) | B(x)), bIu(x) = bI(I(x); E(x)), bIc(x) =
bI(I(x); E(x) | B(x)). Then
ρN (x) − ρtrue(x) = Ic(x) [bIu(x) − Iu(x)]
Iu(x) bIu(x)
−
bIc(x) − Ic(x)
bIu(x)
.
Since Iu(x) ≥ cI > 0 and bIu(x) → Iu(x) uniformly, both denominators remain bounded
below. Hence
|ρN (x) − ρtrue(x)| ≤|Ic(x)|
c2
I
|bIu(x) − Iu(x)| + |bIc(x) − Ic(x)|
cI
+ op(N
−
1
d + 1 ).
By assumption each numerator is Op(N−1/(d+1)) uniformly on Ω, so supx|ρN (x) −
ρtrue(x)|= Op(N−1/(d+1)).
Lemma 21(Local Velocity Perturbation). Fix a pointx ∈ Ω with ∥∇xF(x)∥≥ m >0.
Define the “ideal” velocity
˙xtrue = −[ 1− ρtrue(x)] ∇xF(x),
and the “noisy” velocity
˙xN = −[ 1− ρN (x)] ∇xF(x).
Then
∥˙xN − ˙xtrue∥ = |ρN (x) − ρtrue(x)| ∥∇xF(x)∥.
In particular, ifsupx|ρN (x) − ρtrue(x)|≤ εN , then
∥˙xN − ˙xtrue∥ ≤LF εN , ∥˙xN − ˙xtrue∥ ≥m |ρN (x) − ρtrue(x)|.
Proof. Subtracting gives
˙xN − ˙xtrue = −[ 1−ρN (x)]∇xF(x)+[ 1 −ρtrue(x)]∇xF(x) = −[ρN (x)−ρtrue(x)]∇xF(x).
Taking norms yields the desired bounds.
Lemma 22(Convergence Delay over a Finite Curve). Let xtrue(t) solve
˙xtrue = −[ 1− ρtrue(x)] ∇xF(x), x true(0) = x0,
and letxN (t) solve
˙xN = −[ 1− ρN (x)] ∇xF(x), x N (0) = x0.
Suppose that, overt ∈ [0, T], the ideal trajectoryxtrue(t) travels a curve of lengthℓ and
satisfies ∥∇xF(x)∥≥ m >0. If
sup
x∈Ω
|ρN (x) − ρtrue(x)| ≤εN , ρ N (x) ≤ 1 − δ (δ >0) along that region,
then there existsC2 > 0, depending onm, LF , δ, ℓ, such that for sufficiently largeN,
|TN − T| ≤C2 εN .
Hence TN − T = Op(N
−
1
d + 1 ).
48
Proof Sketch. (1) Ideal descent rate.Fort ∈ [0, T],
d
dtF(xtrue(t)) = −[ 1− ρtrue(x)]∥∇xF(x)∥2 ≤ −β m2,
where β = infx∈Ω(1 − ρtrue(x)) > 0. ThusF(xtrue) decreases at least at rateβ m2.
(2) Noisy descent rate.Similarly,
d
dtF(xN (t)) = −[ 1−ρN (x)]∥∇xF(x)∥2= −[ 1−ρtrue(x)]∥∇xF(x)∥2−[ρN (x)−ρtrue(x)]∥∇xF(x)∥2.
Hence
 d
dtF(xN ) − d
dtF(xtrue)
 = |ρN (x) − ρtrue(x)| ∥∇xF(x)∥2 ≤ L2
F εN .
(3) Gap at timeT. Let α = F(xtrue(T)). Define
h(t) = F(xN (t)) − F(xtrue(t)), h (0) = 0.
Then dh
dt = d
dtF(xN ) − d
dtF(xtrue) ≤ L2
F εN .
Integrating from0 to T yields
F(xN (T)) − α = h(T) ≤ T L2
F εN .
Therefore F(xN (T)) ≤ α + T L2
F εN .
(4) Extra time to reachα. At t = T, F(xN (T)) exceeds α by at mostT L2
F εN . Since
along xN ,  d
dtF(xN )
 = [ 1− ρN (x)]∥∇xF(x)∥2 ≥ δ m2,
it takes at most
∆T ≤ T L2
F εN
δ m2 = C2 εN
additional time forF(xN ) to drop fromα+T L2
F εN to α. Hence|TN −T| ≤C2 εN .
(5) Scaling ofεN . From Lemma 20,εN = Op(N−1/(d+1)). Consequently,
TN − T = Op(N
−
1
d + 1 ).
Asymptotic Conclusion. From Lemmas 20–22, we obtain a high-probability bound
on the convergence delay:
|TN − T| = Op

N
−
1
d + 1

.
• Dependence ond. The rate N−1/(d+1) reflects the curse of dimensionality: more
samples are needed in higherd to achieve the sameεN and delayTN − T.
• Role of r1, r2. Choosing ri(N) ∝ N−1/(d+1) balances bias and variance in KSG
estimates; deviating worsensεN and lengthensTN − T.
• Uniformity on Ω. Since εN is uniform over Ω, no path can bypass this bound,
provided ∥∇xF∥≥ m >0 and ρN (x) ≤ 1 − δ along it.
• High-probability vs. expectation.All bounds hold with probability→ 1. With mild
moment conditions,E[|TN − T|] = O(N−1/(d+1)) follows.
49
In summary, any local estimation errorρN (x) − ρtrue(x) of orderεN induces a slow-
down in ˙x of order O(εN ), leading to a total convergence delay of orderO(εN ). Since
εN = Op(N−1/(d+1)), we conclude that an agent must collectN ∼ ϵ−(d+1) samples to
bound its convergence delay byϵ > 0. This quantifies precisely how KSG estimation
accuracy, sample size, and dimensionality jointly determine the agent’s performance in
free-energy minimization.
Figure 9: Simulation of Conditional Dependencies Mediated by a Markov Blanket.
Synthetic generative structure: (left) external input sext; (center) mediated blanket variable
sblanket; (right) internal response sint. This figure illustrates the informational structure of
a synthetic agent-environment system composed of three variables: an external statesext, a
blanket statesblanket, and an internal statesint. The left panel shows the mapping fromsext to
sblanket, which is generated by a sinusoidal function with added noise. The structured, curved
distribution reflects a strong but noisy dependence between external and blanket states. The
middle panel displays the relationship betweensblanket and sint, also nonlinear and structured,
indicating that internal states are tightly coupled to the blanket dynamics. The right panel
shows the direct relationship betweensext and sint, which appears more diffuse. Although some
dependency remains, the structure is significantly weaker, because the internal state is influenced
by the external state only indirectly through the blanket. Together, these plots demonstrate the
mediating role of the blanket state in shaping the flow of information from the external to the
internal system. This functional mediation is the defining property of a Markov blanket. The
figure supports the idea that this mediation can vary in strength across space, and that such
variation can be formally quantified as MB density. Using estimators such as the KSG method,
this density can be empirically estimated from data, allowing for simulation and validation of
the theoretical framework presented in the main text.
Appendix D: Mathematical Background
Overview
In this appendix, we collect and summarize the principal mathematical concepts, defi-
nitions, and results that underpin the main text. The goal is to provide a concise but
self-contained exposition of the background material required to follow the formal argu-
ments and proofs in this paper. We assume that the reader is familiar with basic real
analysis and elementary probability theory; we then introduce, in turn:
• The notions ofentropy, mutual information, and conditional mutual information
in both the discrete and continuous settings.
• ThenonparametricestimationofmutualinformationviatheKraskov–Stögbauer–Grassberger
(KSG) k-nearest-neighbors (kNN) estimator.
• The concept of convergence in the normC1(K) for functions defined on compact
subsets K ⊂ Rn.
• The theory of gradient flows and ordinary differential equations (ODEs) of the
form ˙x(t) = −g(x(t)) ∇F(x(t)), including existence, uniqueness, and basic stability
estimates.
• Lipschitz continuity, differentiability classes (Ck), and regularity properties for
functions on Euclidean spaces.
50
• Basic ideas from the theory of random fields or stochastic processes indexed by
space, including covariance functions, stationarity, and concentration inequalities
(in particular Hoeffding’s inequality).
• Notions from geometric measure theoryregarding compact domains with smooth
boundary, volume (Lebesgue measure), and ballsBall(x; r) in Rn.
Throughout, we adopt the following notational conventions:
• Rn denotes n–dimensional Euclidean space, with the standard Euclidean norm
∥x∥=
p
x2
1 + ··· + x2n.
• Ω ⊂ Rn will denote a compact set withC2 boundary, or more generally a domain
(open connected set) whose closureΩ is compact.
• Given a probability densityp(x) on Rn, H(p) denotes its (differential) entropy,
and I(X; Y ) denotes mutual information between random variablesX, Y(possibly
vector-valued).
• For an open setU ⊂ Rn, Ck(U) is the space ofk–times continuously differentiable
real-valued functions on U, and ∥f∥C1(K) denotes the C1—norm on a compact
K ⊂ U.
• For random variables indexed by points in space (a “random field”), we often write
ρ(x, θ) where θ is a point in some probability space(Θ, F, P).
Entropy and Mutual Information
Discrete Entropy
Let X be a discrete random variable taking values in a finite or countable setX, with
probability mass function (pmf)pX(x) = P(X = x). The Shannon entropyof X is
H(X) = −
X
x∈X
pX(x) ln pX(x) ,
where throughout ln denotes the natural logarithm. Entropy H(X) measures the ex-
pected “surprisal” ofX and satisfies0 ≤ H(X) ≤ ln|X| when |X|< ∞.
Differential Entropy
When X is a continuous random vector inRd with probability density function (pdf)
pX(x), itsdifferential entropyis defined as
h(X) = −
Z
Rd
pX(x) ln pX(x) dx,
provided the integral exists (i.e., pX is absolutely continuous and
R
pX |ln pX|< ∞).
Unlike discrete entropy, differential entropy can be negative and is not invariant under
change of variable.
Mutual Information
Given two random variables (or vectors)X and Y , with joint distributionpX,Y (x, y) and
marginals pX(x), pY (y), themutual information between X and Y is defined by
I(X; Y ) =
Z
Rd×Rd′
pX,Y (x, y) ln
 pX,Y (x, y)
pX(x) pY (y)

dx dy
in the continuous case, or the analogous sum in the discrete case. Equivalently, in the
discrete setting:
I(X; Y ) = H(X) + H(Y ) − H(X, Y),
51
and in the continuous setting:
I(X; Y ) = h(X) + h(Y ) − h(X, Y).
Mutual information is always nonnegative, i.e.I(X; Y ) ≥ 0, and vanishes precisely when
X and Y are independent. It can also be written as the Kullback–Leibler divergence
I(X; Y ) = DKL(pX,Y ∥ pX ⊗ pY ).
Conditional Mutual Information
For three random variables (vectors)X, Y , and Z, the conditional mutual information
of X and Y given Z is
I(X; Y | Z) = EZ
h
DKL(pX,Y |Z ∥pX|Z ⊗ pY |Z)
i
.
Equivalently, in terms of (differential) entropies:
I(X; Y | Z) = H(X | Z) + H(Y | Z) − H(X, Y| Z),
or in the continuous case
I(X; Y | Z) = h(X | Z) + h(Y | Z) − h(X, Y| Z).
An equivalent formula in continuous form is
I(X; Y | Z) =
Z Z Z
pX,Y,Z (x, y, z) ln pX,Y |Z(x, y|z)
pX|Z(x |z) pY |Z(y |z) dx dy dz.
Conditional mutual information measures the residual statistical dependence betweenX
and Y once Z is known. In our context,I (internal states),B (blanket) andE (external
states) play the roles ofX, Z, andY respectively.
Normalized “Blanket Strength”
In the paper, theMarkov blanket strengthis defined at a pointx by
S(x) = 1 − I(I; E | B)
I(I; E) ,
and the associated MB density byρ(x) = S(x). Here I(I; E) and I(I; E | B) denote the
marginal and conditional mutual information restricted to the subsetsI(x), B(x), and
E(x) around x. One must therefore be fluent in all of the foregoing definitions.
Nonparametric Estimation of Mutual Information via KSG–kNN
Nearest-Neighbor Distances and Entropy Estimation
Given a sample{zi }N
i=1 ⊂ Rd, consider the distance to thek-th nearest neighbor:
εk(i) = min {r >0 : |{j ̸= i : ∥zj − zi∥≤ r}|≥ k }.
The classicalKozachenko–Leonenko (KL) estimator for the (differential) entropyh(Z) is
ˆhKL(Z) = ψ(N) − ψ(k) + ln(cd) + d
N
NX
i=1
ln εk(i),
where ψ(·) is the digamma function,cd = πd/2/Γ(d
2 + 1) is the volume of the unit ball in
Rd, andεk(i) is half the distance to thek-th nearest neighbor when using the maximum
norm (or Euclidean norm if appropriate correction is made).
52
Kraskov–Stögbauer–Grassberger (KSG) Estimator
Kraskov, Stögbauer, and Grassberger (2004) generalized the KL estimator to estimate
mutual information between two continuous random vectorsX ∈ Rdx and Y ∈ Rdy .
Given samples{(xi, yi)}N
i=1, for eachi define
εk(i) = min{max{∥xj − xi∥∞, ∥yj − yi∥∞} : 1 ≤ j ≤ N, j ̸= i, rank(j) = k },
i.e. the distance (in the maximum norm) to thek-th nearest neighbor in the joint space
Rdx+dy . Then count
nx(i) = |{j ̸= i : ∥xj − xi∥∞≤ εk(i)}|, n y(i) = |{j ̸= i : ∥yj − yi∥∞≤ εk(i)}|.
The KSG estimator for mutual information is
ˆIKSG(X; Y ) = ψ(k) − 1
k + ψ(N) − 1
N
NX
i=1
[ψ(nx(i) + 1) +ψ(ny(i) + 1)],
where ψ is again the digamma function. Under mild regularity conditions on the joint
density pX,Y , this estimator is (asymptotically) unbiased and consistent for largeN. An
analogous procedure can be applied to estimate conditional mutual informationI(X; Y |
Z) by conditioning onZ in a similar nearest-neighbor scheme.
Convergence Properties and Conditions
To employ KSG–kNN estimation within a theoretical analysis, one often needs more than
mere pointwise consistencyˆI
p
−→Itrue. In the paper’s arguments, the key requirement is
convergence in the norm
∥ˆI(·) − Itrue(·)∥C1(K) = Op(N−α),
for someα >0 and any compactK in the domain. Convergence inC1(K) means:
1. supx∈K|ˆI(x) − Itrue(x)|= Op(N−α),
2. supx∈K∥∇ˆI(x) − ∇Itrue(x)∥ = Op(N−α),
where ∇ denotes the gradient with respect to the spatial coordinatex ∈ Rn. Establishing
such rates typically requires:
• Assumptions that the true densities are bounded away from zero and infinity on
K, with Lipschitz (or Hölder) continuous derivatives.
• Control of the bias and variance of the kNN–KSG estimator and uniformity over
x ∈ K.
• Strong concentration inequalities for the nearest-neighbor distances and counts
nx(i), ny(i).
Convergence in the NormC1(K)
Function Spaces of ClassC1
Let U ⊂ Rn be an open set andK ⊂ U a compact subset. We say a functionf : U → R
belongsto C1(U) ifitiscontinuouslydifferentiable, i.e., allfirstpartialderivatives ∂f/∂x i
exist and are continuous onU. The restrictionf|K is then inC1(K) in the sense thatf
and its gradient∇f are continuous on the compact setK.
Definition of theC1–Norm
Forf ∈ C1(U) and a compactK ⊂ U, define
∥f∥C1(K) = sup
x∈K
|f(x)| + sup
x∈K
∥∇f(x)∥.
If ∥f − g∥C1(K)→ 0 as some parameter (e.g., sample sizeN) grows, we sayf converges
to g in theC1(K) norm. This implies uniform convergence of bothf and ∇f on K.
53
Implications for Gradient-Based Dynamics
Convergence inC1(K) is crucial when one studies ODEs of the form
˙x(t) = −[ 1− ρN (x(t)) ]∇F(x(t)),
when ρN (x) → ρtrue(x) in C1(K). Under such convergence, one can pass to the limit
in the vector fields and deduce that solutions to the “estimated” flow approach those of
the “true” flow, provided standard conditions of Lipschitz continuity hold. In particular,
if ρN → ρtrue and ∇ρN → ∇ρtrue uniformly onK, then the direction of descent−[1 −
ρN ]∇F converges uniformly to−[1 − ρtrue]∇F. This is one of the stepping stones in the
proof of Theorem 1.
Gradient Flows and Ordinary Differential Equations
Gradient Descent inRn
Given a continuously differentiable functionF : Ω ⊂ Rn → R, the gradient flow is the
ODE
˙x(t) = −∇F(x(t)),
with initial conditionx(0) = x0 ∈ Ω. Under the standard assumption that∇F is globally
Lipschitz (or at least locally Lipschitz onΩ), the Picard–Lindelöf theorem guarantees
the existence and uniqueness of a solution defined on a maximal interval. Moreover, if
Ω is compact and ∇F is continuous, then the flow exists for allt ≥ 0 and F(x(t)) is
nonincreasing (since d
dtF(x(t)) = ∇F(x) · ˙x = −∥∇F(x)∥2≤ 0).
Modified Gradient Flow with Mobility Function
In the paper, the dynamics are modified as
˙x(t) = −M(x(t)) ∇F(x(t)),
where themobility (or “coupling”) function is
M(x) = 1 − ρ(x), 0 ≤ ρ(x) ≤ 1.
Hence,
˙F(x(t)) = ∇F(x) · ˙x = −[1 − ρ(x)] ∥∇F(x)∥2 ≤ 0.
This shows thatF(x(t)) is nonincreasing along trajectories. Ifρ(x) = 1 at somex, then
M(x) = 0 and ˙x = 0, so the flow isfrozen at that point.
Existence and Uniqueness under Lipschitz Conditions
Suppose F ∈ C2(Ω), so∇F is Lipschitz continuous on any compactK ⊂ Ω with Lipschitz
constant LF . If, in addition,ρ(x) is C1 on K, thenM(x) = 1 − ρ(x) is also Lipschitz on
K. Consequently, the vector fieldv(x) = −M(x) ∇F(x) satisfies
∥v(x)−v(y)∥ = ∥M(x) ∇F(x)−M(y) ∇F(y)∥ ≤ ∥M(x) (∇F(x)−∇F(y))∥+∥∇F(y)∥ |M(x)−M(y)|.
Since M and ∇F are each bounded and Lipschitz onK, v(x) is Lipschitz. Hence by the
Picard–Lindelöf theorem, for eachx0 ∈ K there is a unique solutionx(t) ∈ K for some
maximal interval of existence. If K = Ω is compact andv does not push trajectories
outside Ω (e.g., v is tangent at the boundary), the solution exists for allt ≥ 0 and remains
in Ω.
Lipschitz Continuity and Differentiability Classes
Ck Function Spaces
Let U ⊂ Rn be open. We denote byCk(U) the set of functionsf : U → R whose partial
derivatives up to orderk exist and are continuous onU. In particular:
54
• C0(U) is the set of continuous functions.
• C1(U) consists of continuously differentiable functions; i.e., all first partials exist
and are continuous.
• C2(U) consists of twice continuously differentiable functions, etc.
If Ω is compact withC2 boundary, andF ∈ C2(Ω), then∇F is Lipschitz onΩ (since a
continuously differentiable map on a compact set is automatically Lipschitz). Specifically,
there existsLF > 0 such that
∥∇F(x) − ∇F(y)∥ ≤LF ∥x − y∥ ∀x, y∈ Ω.
Lipschitz Continuity
A functionf : K → R defined on a metric space(K, d) is Lipschitz continuous if there
exists a constantL ≥ 0 such that
|f(x) − f(y)| ≤L d(x, y) ∀x, y∈ K.
If f ∈ C1(K) for a compactK ⊂ Rn, then the mean value theorem impliesf is Lipschitz
with Lipschitz constant
Lf = sup
x∈K
∥∇f(x)∥.
Analogously, a vector fieldv : K → Rn is Lipschitz ifsupx∈K∥Dv(x)∥< ∞, whereDv(x)
is the Jacobian matrix and∥·∥ is the operator norm.
Random Fields and Concentration Inequalities
Random Fields on a Compact Domain
A random fieldon a compact setΩ ⊂ Rn is a collection of real-valued random variables
{ρ(x)}x∈Ω defined on a common probability space(Θ, F, P). We denote ρ(x, θ) when
emphasizing the dependence on the random elementθ ∈ Θ. Conditions often imposed
on ρ(x, θ) in the paper include:
• Boundedness: 0 ≤ ρ(x, θ) ≤ 1 for allx, θ.
• Stationarity of mean:Eθ[ρ(x, θ)] = µ is constant for allx ∈ Ω.
• Constant covariance with a deterministic field:Cov(ρ(x), ∥∇F(x)∥2) = C is inde-
pendent ofx.
• Decay of spatial correlations:There exists a length-scaleℓ >0 such that
|Cov(ρ(x), ρ(y))| ≤σ2 exp(−∥x − y∥/ℓ) ∀x, y∈ Ω.
The latter condition is a form ofexponential mixingor exponential decay of correlations
and ensures that values ofρ at distant points become nearly independent.
Hoeffding’s Inequality for Bounded Random Variables
Suppose Z1, . . . , ZN are independent random variables withai ≤ Zi ≤ bi almost surely.
Then for anyε >0,
P

| 1
N
NX
i=1
Zi − E[Zi]| ≥ε

≤ 2 exp

− 2N2ε2
PN
i=1(bi − ai)2

.
In the paper, to derive auniform high-probability bound on
φ(x) = [1 − ρ(x)] ∥∇F(x)∥2
55
over all x ∈ Ω, one discretizes Ω by a finite grid {x(1), . . . , x(N)} of mesh δ. Then
Hoeffding’s inequality yields, for each grid pointx(j),
P

|φ(x(j)) − E[φ(x(j))]| ≥ε

≤ 2 exp(−C ε2 )
for some constantC >0 if φ is bounded (since0 ≤ φ ≤ ∥∇F∥2
∞). A union bound over
all grid points (and then controlling the remainder ofΩ by Lipschitz continuity) yields
P

sup
x∈Ω
|φ(x) − E[φ(x)]| ≥ε

≤ N · 2 exp(−C ε2),
so that with high probability the random fieldφ(x) is uniformly close to its expectation.
Compact Domains and Volume inRn
Compact Sets with Smooth Boundary
Let Ω ⊂ Rn be a bounded open set whose boundary∂Ω is aC2 hypersurface. Such an
Ω is said to be acompact domain withC2 boundary if Ω is compact and ∂Ω is a C2
manifold. In particular:
• There exist coordinate charts(Ui, ψi) covering∂Ω such thatψi(Ui) is open inRn−1
and ∂Ω is locally given byxn = ϕi(x1, . . . , xn−1) for someC2 function ϕi.
• Ω satisfies an interior sphere condition: every point on∂Ω has a ball of positive
radius contained inΩ tangent to∂Ω at that point.
These properties guarantee that standard PDE and ODE results (e.g., existence of flows
that remain inΩ with vector fields tangent at the boundary) apply.
Volume of Balls
The n-dimensional Lebesgue measure (volume) of a ball of radiusr >0 in Rn is
Vol(Ball(x; r)) = Vol(Ball(0;r)) = cn rn,
where
cn = πn/2
Γ(n
2 + 1).
InmanyconsistencyargumentsforkNNestimators, onerequiresthat N Vol(Ball(x; r2(N))) →
∞ as N → ∞, which ensures that, on average, there are infinitely many sample points in
an r2(N)-neighborhood of any givenx. Usually r2(N) is chosen so thatN r2(N)n → ∞
but r2(N) → 0.
Gradient Alignment and Monotonicity Conditions
Gradient Conditions for Theorem 1
In Theorem 1, one assumes that there exist continuous functions
Itrue(I(x); E(x)), I true(I(x); E(x) | B(x)) : D ⊂ Ω −→ R,
which areC1 on an open setD, and satisfy
∇[Itrue(I(x); E(x)_]()
Acknowledgements
I thank Kobus and Stefan Esterhuysen for their assistance in developing the technical
aspects of this paper.
56
References
[1] Friston, K., A Free energy Principle for a Particular Physics, arXiv preprint
arXiv:1906.10184, 2019.
[2] Friston, K., “The Free-energy Principle: A Rough Guide to the Brain?”Trends
in Cognitive Sciences13(7): 293–301. 2009.
[3] Friston, K., “Life as We Know It.”Journal of the Royal Society Interface10(86):
20130475. 2013.
[4] Ramstead, M., Badcock, P., Friston, K., “Answering Schrödinger’s Question: A
Free Energy Formulation.”Physics of Life Reviews(24):1–16. 2018.
[5] Kirchhoff, M., T. Parr, E. Palacios, K. Friston, Kiverstein, J., “The Markov
Blankets of Life.”Journal of the Royal Society Interface15:20170792. 2018.
[6] Ramstead, M., Sakthivadivel, D., Heins, C., Koudahl, M., Millidge, B., DaCosta,
L., Klein, B., Friston, K., “OnBayesianMechanics.”Interface Focus13:20220029.
2023.
[7] Beck, J., Ramstead, M. "Dynamic Markov Blanket Detection for Macroscopic
Physics Discovery"arXiv:2502.21217 [q-bio.NC] 2025.
[8] Sakthivadivel, D. “Weak Markov Blankets in High-Dimensional, Sparsely-
Coupled Random Dynamical Systems” arXiv:2207.07620 2025
[9] Parr, T., Pezzulo, G., Friston, K.Active Inference. The Free Energy Principle
in Mind, Brain, and Behavior, MIT Press. 2022.
[10] Amari, S.Information Geometry and Its Applications, Springer. 2016.
[11] Cover, T. M., Thomas, J. A.Elements of Information Theory (2nd ed.), Wiley.
2006.
[12] Fleming, W. H., Rishel, R. W.Deterministic and Stochastic Optimal Control,
Springer. 1975.
[13] Bertsekas, D. P.Nonlinear Programming (2nd ed.), Athena. 1999.
[14] Jaynes, E. T. "Information theory and statistical mechanics"Physical Review,
106(4), 620.
[15] Amari, S."Informationgeometryonhierarchyofprobabilitydistributions" IEEE
Transactions on Information Theory, 47(5), 1701–1711. 2001.
[16] Pearl, J.Causality: Models, Reasoning and Inference, Cambridge. 2009.
[17] Crroks, G. "Entropy production fluctuation theorem and the nonequilibrium
work relation for free energy differences"Physical Review E, 60(3), 2721. 1999.
[18] Amari, S. "Natural gradient works efficiently in learning"Neural Computation,
10(2), 251–276. 1998.
[19] Li, W., Montúfar, G. "Natural gradient via optimal transport"Information Ge-
ometry, 1(2), 181–214. 2018.
[20] Parr, T., Friston, K. "Generalised free energy and active inference."Biological
Cybernetics, 113(5), 495–513. 2019.
[21] Kraskov, A., Stögbauer, H., Grassberger, P. "Estimating mutual information."
Physical Review, 69(6), 066138. 2004.
[22] Smith, R., Friston, K., Whyte, C. “A Step-by-Step Tutorial on Active Inference
and Its Application to Empirical Data.”Journal of Mathematical Psychology,
107: 102632. 2022.
57
[23] Paninski, L. "Estimation of entropy and mutual information."Neural Computa-
tion, 15(6), 1191–1253. 2003.
[24] Gao, W., Oh, S., Viswanath, P. "Demystifying information-theoretic estima-
tors." arXiv:1708.00065. 2017.
[25] Lizier, J. T. "JIDT: An information-theoretic toolkit for studying the dynamics
of complex systems."Frontiers in Robotics and AI, 1, 11. 2014.
[26] Da Costa, L., Friston, K., Heins, C., Pavliotis, G.A. "Bayesian mechanics for
stationary processes."Proceedings Royal Society, A 477: 20210518. 2021.
[27] Parr, T., Da Costa, L., Friston, K. "Markov blankets, information geometry
and stochastic thermodynamics." Philosophical Transactions Royal Society A,
378:20190159. 2019.
[28] Veissière S., Constant A., Ramstead M., Friston K., Kirmayer L. “Thinking
through Other Minds.”Behavioral and Brain Sciences, (43): 1–75. 2020.
[29] Gibson, J. J.The ecological approach to visual perception(1st ed). Mifflin and
Company, 1979.
[30] Badcock, P., Davey, C., Whittle, S., Allen, N., Friston, K. "The Depressed Brain:
An Evolutionary Systems Theory."Trends in Cognitive Science, (21): 182-194.
2017.
[31] Friston K, FitzGerald T, Rigoli F, Schwartenbeck P, Pezzulo G. "Active Infer-
ence: A Process Theory."Neural Computations, 29(1):1-49. 2017.
[32] Frenzel, S., Pompe, B. “Partial mutual information for coupling analysis of mul-
tivariate time series.”Physical Review Letters, 99:204101. 2007.
[33] Gao, W., Kannan, S., Oh, S., Viswanath, P. “Estimating mutual information
for discrete–continuous mixtures.” Advances in Neural Information Processing
Systems, 30:—. 2017.
[34] Hahsler, M., Hornik, K. “TSP—Infrastructure for the traveling salesperson prob-
lem.” Journal of Statistical Software, 23:1–21. 2007.
[35] Darbellay, G. A., Vajda, I. “Estimation of the information by an adaptive par-
titioning of the observation space.”IEEE Transactions on Information Theory,
45:1315–1321. 1999.
[36] Singh, S., Poczos, B., Wasserman, L. “Exponential concentration of a den-
sity functional estimator.”Neural Information Processing Letters and Reviews,
9:123–132. 2016.
[37] Clark, A.Surfing Uncertainty: Prediction, Action, and the Embodied Mind, Ox-
ford University Press. 2016.
[38] Bruineberg J, Dołęga K, Dewhurst J, Baltieri M. "The Emperor’s New Markov
Blankets." Behavioral and Brain Sciences", 45:e183. 2022.
[39] Colombo, M. "Nothing but a useful tool? (F)utility and the free energy princi-
ple." In Bruineberg J, Dołęga K, Dewhurst J, Baltieri M. "The Emperor’s New
Markov Blankets."Behavioral and Brain Sciences", 45:e183. 2022.
[40] Friston, K, Da Costa, L., Sakthivadivel, D., Heins, C., Pavliotis, G., Ramstead,
M., Parr, T. "Path Integrals, Particular Kinds, and Strange Things."Physics of
Life Reviews", 47, 2023.
58