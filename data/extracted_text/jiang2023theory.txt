A Theory of Human-Like Few-Shot Learning
Zhiying Jiang1, Rui Wang2, Dongbo Bu2, Ming Li1∗
1David Cheriton School of Computer Science, University of Waterloo,
200 University Ave W, Waterloo, ON N2L 3G1, Canada
2Institute of Computing Technology, Chinese Academy of Science, Beijing, China
∗To whom correspondence should be addressed; E-mail: mli@uwaterloo.ca
We aim to bridge the gap between our common-sense few-sample human learn-
ing and large-data machine learning. We derive a theory of human-like few-
shot learning from von-Neuman-Landauer’s principle. Modelling human learn-
ing is difﬁcult as how people learn varies from one to another. Under com-
monly accepted deﬁnitions, we prove that all human or animal few-shot learn-
ing, and major models including Free Energy Principle and Bayesian Program
Learning that model such learning, approximate our theory, under Church-
Turing thesis. We ﬁnd that deep generative model like variational autoencoder
(V AE) can be used to approximate our theory and perform signiﬁcantly better
than baseline models including deep neural networks, for image recognition,
low resource language processing, and character recognition.
Introduction
During the past decade, fast progress in deep learning ( 1) has empowered computer speech
recognition, image processing, natural language processing, protein folding, game playing and
many other applications. However, these great progresses fell short when we try to understand
our own learning mechanism: How to model human learning (2), (3), (4)?
Species in nature learn quickly to survive. When a dragonﬂy is hatched, within hours it
ﬁrms up its wings and then ﬂies to catch mosquitoes; a newborn does not need tons of repeated
examples or transfer learning to identify an apple. Most human or animal learning exhibits a
mixture of inherited intelligence, few-shot learning without prior knowledge, as well as long
term many-shot learning. It is interesting to note that these learning programs are encoded in
our genomes but they are not all the same, even for individuals within the same species. The
diversity of these learning algorithms is vividly expressed by Spearman’s "g" factor (2).
Work in progress.
1
arXiv:2301.01047v1  [cs.LG]  3 Jan 2023
Unlike data-laden, model-heavy, and energy-hungry deep learning approaches, most human
learning appear to be simple and easy. Merely scaling up current deep learning approaches may
not be sufﬁcient for achieving human level intelligence. We miss certain major components
when modelling human or animal learning.
Diversity is one of the missing part when modelling human or animal few-shot learning.
There are eight billion people on earth, each with a unique few-shot learning model (5). Even if
we just want to model one person, a single person often uses different parameters, features, and
perhaps different algorithms to deal with different learning tasks. Ideally we want a framework
that can cover the diversity in human and animal few-shot learning. Facing such a seemingly
formidable task, traditional thinking in machine learning will only lead us to various traps. To
avoid such traps we need to go back to the very ﬁrst principles of physics.
Speciﬁcally, we start from an agreed-upon law in thermodynamics, to formally derive our
model for few-shot learning, and prove this is the optimal model within our framework in the
sense that all other models including human ones may be viewed as approximations to our
framework. We show a deep connection between our framework and the free energy principle (3)
and the Bayesian Program Learning model (4). By the end of this process, a component of data
compression during the inference phase of learning emerges as a key component of all few-shot
learning models.
First, we formalize our intuitive and commonly accepted concept of human-like few-shot
learning. For example, our deﬁnition below is consistent with what is used in ( 4), and in the
same spirit of (3).
Deﬁnition 1. Consider a universe Ω, partitioned into H disjoint concept classes: Ch, h =
1,2,...,H . Few-shot (k-shot) learning is described as follows:
1. nelements in or outside Ω are given as unlabelled samples y1,...,y n;
2. There are klabelled examples for each class Ch, for small k;
3. The learning program, using a computable metric M, few-shot learns Ch,h = 1,2,...H,
if it uses the nunlabelled samples and k labelled samples and minimizes the objective
function:
H∑
h=1
|Ch|∑
i=1
M(xi,coreh) |y1,...,y n,xi ∈Ch,
where coreh = ψ(ksamples of Ch) representing a transformed representation of the k
labelled samples from Ch.
This deﬁnition covers most of our common sense few-shot learning scenarios and other
studies. In particular, this is used in one-shot learning by (4). As each independent individual,
we do not all use a same metric, or even similar metric, to few-shot learning. For example,
MN Hebart et al (6) identiﬁed 49 highly reproducible dimensions to 1854 objects to measure
2
their similarity. Different people can be equipped to better observe some of these dimensional
features.
We explain the intuition behind Deﬁnition 1 via a simple example. A human toddler may
have already seen many unlabelled samples of fruits which, for example, contains two classes:
apples and pears. Then given a new labelled sample from each class, the toddler learns how to
differentiate between these two fruits. The number of labelled data required for one to classify
may vary as people have different learning algorithms.
Current deep learning based approaches for few-shot learning generally depend on 1) many
auxiliary labelled training samples or task-speciﬁc data augmentation for transfer learning or
meta learning (7); or 2) very large scale self-supervised pre-training (8). These approaches thus
fall short to model few-shot learning in nature by humans and animals as they can hardly account
for the diversity in learning algorithms and they either neglect the unsupervised scenario that
humans are mostly exposed to or use the scale of unlabelled data and training parameters that
are far beyond creatures need.
Many attempts have been made to understand human learning through cognitive, biological,
and behavior sciences. Some studies have established basic principles a human learning model
should obey. One theory is the two-factor theory of intelligence by Charles Spearman in 1904 (2),
where the “g” factor is an indicator of the overall cognitive ability, and the “s” factor stands for
the aptitude that a person possesses in speciﬁc areas. As “g” factor is genetically-related (9), it
indicates the necessity of a learning theory that can account for the diversity in creatures’ learning
ability. Another theory is the Free Energy Principle by Karl Friston ( 3) that human (and all
biological systems) learning tends to minimize the free energy between internal understanding in
the sense of Bayesian (under internal perceived distributionp) and that of the environmental event
(under distribution q), measured by KL-divergence (10). In a similar spirit, Lake, Salakhutdinov
and Tenenbaum (4) proposed a Bayesian program learning (BPL) model, learning a probabilistic
model for each concept and achieve human-level performance. Two articles by Schmidhuber (11)
and by Chater and Vitanyi (12) linked simplicity to human cognition and appreciation of arts.
Instead of exploring a biological basis for few-shot learning, we think it is possible to
mathematically derive an optimal framework that can unify the above theories. We further
demonstrate by experiments that our new model indeed works signiﬁcantly better than other
classical deep learning neural networks for few-shot learning. As a byproduct of our new model,
a new concept class of "interestingness" is learned; this class implies where our appreciation
of art, music, science and games comes from. Extending this observation, some aspects of
consciousness may be modelled as a set of few-shot learned concepts. Consequently, we
hypothesize the ability of labelling input data becomes a key step to acquiring some aspects of
consciousness.
3
A theory of few-shot learning
We mathematically derive an optimal few-shot learning model for Deﬁnition 1 that is effective
and is able to cover enormous diversities existed in different species. The task may appear to be
formidable because of conﬂicting and seemingly very general goals: each individual is allowed
to have a different learning model, yet our model has just one program to model everybody;
we do not yet exactly know the complete underlying biological mechanisms, yet we need to
implement the right functionality; there are inﬁnite number of models, yet we need to choose
one that is optimal; we are not really interested in "proposing models" out of blue, yet we wish
our model to be a mathematical consequence of some basic laws of physics; the model needs to
be theoretically sound, yet practically useful.
For simplicity and readability, we begin with one-shot learning, k= 1 in Deﬁnition 1. Thus,
coreh in Deﬁnition 1 is just the single labelled sample xh. For larger k, coreh can be some form
of average of the ksamples. As Deﬁnition 1 deﬁned, some unlabelled objects are assumed and
it’s also possible to extend the deﬁnition by adding distribution, learnt from either unlabelled or
labelled data, to Ω. Using metric Mthat is responsible for k-shot learning of an individual, the
learning system seeks to minimize the energy function
H∑
h=1
|Ch|∑
i=1
M(xi,xh|y1,...,y n),
or, assuming H(y1,...,y n) is a pre-trained model of y1,...,y n, or other labelled samples,
capturing the distribution.
H∑
h=1
|Ch|∑
i=1
M(xi,xh|H(y1,...,y n)),
Now the question is, what sort ofMshould we use? Indeed, this varies from person to person.
Can we unify all such measures, algorithms and inferences? Let’s go back to the fundamentals.
Principle 1 (von-Neuman-Landauer Principle). Irreversibly processing 1 bit of information costs
1kT; reversible computation is free.
Then for two objects x,y, the minimum energy needed to convert between xand yin our
brain is:
EU (x,y) = min{|p|: U(x,p) = y,U(y,p) = x},
where U is a universal Turing machine or our brain, assuming Church-Turing thesis. Since we
can prove a theorem showing all Universal Turing machines are equivalent modulo a constant and
efﬁciency, we will drop the index U (see (13)). To interpret, E(x,y) is the length of the shortest
program that reversibly converts between xand y. These bits used in the shortest program p
when they are erased will cost |p|kT of energy, according to the John von Neuman and Rolf
Landuaer’s law. This leads us to a fundamental theorem (14):
4
... 
... degree 
degree 
Figure 1: Bipartite Graph
Theorem 1. E(x,y) = max{K(x|y),K(y|x)}+ O(1).
K(x|y) is the Kolmogorov complexity of xgiven y, or informally, the length of the shortest
program that outputs xgiven input y(details are shown in (13)). As this theorem was proved
thirty years ago and it is vital in our theory, to help our readers, we will provide an intuitive but
less formal proof here.
Proof. By the deﬁnition of E(x,y), it follows E(x,y) ≥K(x|y) and E(x,y) ≥K(y|x), thus
we have E(x,y) ≥max{K(x|y),K(y|x)}.
To prove the other direction E(x,y) ≤ max{K(x|y),K(y|x)}, we need to construct a
program p such that p outputs y on input x and p outputs x on input y, and length of p is
bounded by max{K(x|y),K(y|x)}+ O(1).
Let k1 = K(x|y), and k2 = K(y|x). Without loss of generality, assume k1 ≤k2. We ﬁrst
deﬁne a bipartite graph {X,Y,E }, where X,Y = {0,1}∗, as shown in Figure 1 and Eis a ﬁnite
set of edges deﬁned between X and Y as follows:
E = {{u,v},u ∈X,v ∈Y,K(u|v) ≤k1,K(v|u) ≤k2}
Note that a particular edge (x,y) is in E. If we ﬁnd edge (x,y), then given x, p can output y,
and vice versa. So the idea of the proof is to partition Eproperly so that we can identify (x,y)
easily. Two edges are disjoint if they do not share nodes on either end. A matching in graph
theory is a set of disjoint edges in E.
Claim. Ecan be partitioned into at most 2k2+2 matchings.
Proof of Claim. Consider edge (u,v) ∈E. The degree of a node u∈X is bounded by 2k2+1
because there are at most 2k2+1 different strings vsuch that K(v|u) ≤k2, accumulating possible
strings from i = 1 to i = k2 gives us ∑i=k2
i=1 = 2k2+1 −2. Hence ubelongs to at most 2k2+1
matchings. Similarly, node v∈Y belongs to at most 2k1+1 matchings. We just need to put edge
(u,v) in an unused matching. (End of Proof of Claim)
Let Mi be the matching that contains edge(x,y) We now construct our programp. p operates
as follows:
• Generate Mi following the proof of Claim, i.e. enumerating the matchings. This uses
information k1, k2, and i. K(i) ≤k2 + O(1)
5
• Given x, p uses Mi to output y, and given y, p uses Mi to output x.
A conditional version of Theorem 1, using information in Deﬁnition 1, can be obtained
E(x,y|y1,...,y n) = max{K(x|y,y1,...,y n),K(y|x,y1,...,y n)}, conditioning on unlabelled
samples y1,...,y n. According to (14), this distance is universal, in the sense that E(x,y) is the
minimum among any other computable distances:
Theorem 2. For any computable metricD, there is a constant c, such that for all x,y, E(x,y) ≤
D(x,y) + c.
This theorem implies: if Dmetric ﬁnds some similarity between xand y, so will E. Thus,
the above theorem implies, up to some constant O(H)
H∑
h=1
|Ch|∑
i=1
E(xi ∈Ch,coreh|y1,...,y n) ≤
H∑
h=1
|Ch|∑
i=1
M(xi ∈Ch,coreh|y1,...,y n).
When unlabelled samples y1,...,y n plus other irrelevant historical labelled samples are modeled
by some model Hsuch as a generative model (e.g., V AE), then the above inequality can be
rewritten as:
H∑
h=1
|Ch|∑
i=1
E(xi ∈Ch,coreh|H) ≤
H∑
h=1
|Ch|∑
i=1
M(xi ∈Ch,coreh|H). (1)
Thus, Egives optimal metric for few-shot learning algorithm. Other algorithms satisﬁed
Deﬁnition 1 are the approximation to this optimal solution. 1
In addition, we show that our theory’s deep connection to two well-established principles
of learning in neuroscience and psychology. Friston’s Free Energy Principle (FEP) (3), derived
from Bayesian brain hypothesis (15), states that brain seeks to minimize surprises. Speciﬁcally,
it assumes the brain has its internal state (a.k.a. generative model) that implicitly models the
environment according to the sensory data. Hidden (latent) variables need to be deﬁned for
the internal state, which are drawn from prior beliefs. Ideally, these prior knowledge is also
modelled, which is made possible by hierarchical generative models. The free energy principle
(FEP) is often interpreted as Bayesian optimization, using the Evidence Lower Bound (ELBO)
as ELBO = log p(x; θ) −D(q(z)∥p(z|x; θ) optimization function. Here the evidence log p(x; θ)
is the encoding length of xunder probability p, and the Kullback-Leibler divergence term is the
p-expected encoding length difference. This is half of Theorem 1 and FEP is asymmetric if we
view it as a distance. However, the symmetry is important to few-shot learning. For example, a
scarlet king snake may look like a coral snake, but the latter certainly has more deadly features
the former lacks, one way compression K(ScarletKingSnake|CoralSnake) is not sufﬁcient to
1Note that Eis a metric: it is symmetric, and satisﬁes triangle inequality
6
Compressor
Unlabeled Data Distribution
Test Instance
Figure 2: Illustration of our framework, dashed line indicates optional component when learning.
distinguish the two. Despite of the fact H. inﬂunza with genome size 1.8 million and E. coli with
genome size 5 million they are sister species but E. coli would be much closer to a species with
zero genome G0 or just a covid-19 genome with this asymmetric measure (K(G0|E.coli) than
with H. inﬂunza (K(H.influnza |E.coli )). A symmetric interpretation of Friston’s FEP can be
derived by requiring minimum conversion energy as we show in Theorem 1.
Different individuals may use different compression algorithms to do data abstraction and
inference. It can be viewed that these algorithms all approximateE(x,y). Some are more efﬁcient
than others in different situations. The individuals with better compression algorithms have
bigger “g” factor. Diversiﬁed compression algorithms also guarantee better survival chances of a
community when facing a pandemic. As compression neural networks are genetically encoded,
the “g” factor is thus inheritable. This can be seen via Figure 2, compression algorithms vary
from one to another. The distribution of the data to be learnt is either implicitly or explicitly
captured by creatures. Those who can better utilize unlabelled data to capture distribution may
have a more efﬁcient compression algorithm.
Experimental Results
Image Experiments
To approximate our universal few-shot learning model, we use a hierarchical V AE as our
underlying model Hin Inequality 1 to model the unlabelled samplesy1,...,y n. This hierarchical
structure coincides with our visual cortex and brain structure ( 16). According to integrated
information theory ( 17), an input y may come from all sensing terminals: vision, hearing,
smell, taste, sensation. Often, creatures are exposed to an unsupervised environment where
objects are unknown and unlabelled. Revisiting the negative ELBO, we can see it can be
interpreted as changing perceptions to minimize discrepancy (minimize KL divergence) or
changing observations to maximize evidence, in the context of FEP. When the creatures are
7
exposed to a “tree” and they do not fully realize what it is, the sensory information of the
objects are internalized with hidden states (inner belief) that can describes how it believes the
generation process of a “tree”. This process of generation, helps the creatures to identify the
latent similarities among objects that belong to the same category, without the full awareness.
This process of "unconsciously" training to generate helps the creatures to better categorize in
future. When the identity of a “tree” is ﬁnally revealed, they can generalize quickly. This explains
our rationale of using a V AE to process unlabelled samples. Consequently, the Kolmogorov
complexity terms in Inequality 1 are naturally approximated by a V AE based compressor (18).
To test the hypothesis, we carry out the experiment on ﬁve datasets, MNIST, KMNIST,
FashionMNIST, STL-10 and CIFAR-10. We ﬁrst train a hierarchical V AE on unlabelled data
to learn to generate ˆx that’s as close to x as possible. This corresponds to the time when
creatures exposed to a environment without knowing the object, implicitly learning the latent
representation among objects. When the identity of objects are revealed, a V AE based universal
compressor can be used to identify the new objects. Speciﬁcally, after training a hierarchical
V AE unsupervisedly, we compare theEenergy function between a labelled image and a test
image, as in Deﬁnition 1. In our experiment, we use 5 labelled samples per class to test the
accuracy of classiﬁcation. The energy function Erelies on a compressor to approximate. We thus
use the bits-back argument to directly use our trained V AE for the compressor in (18). Our result
shows that using only 5 samples, our method outperforms traditional supervised models like
SVM, CNN, VGG and Vision Transformer (ViT) on all ﬁve datasets. These supervised methods
are chosen to represent different model complexity with wide range of number of parameters.
As we can see, when labelled data are scarce, supervised methods are not effective: complex
models like VGG cannot perform better than SVM and this tendency is more obvious on ViT
without pre-training. The improvement that our method brings is more obvious on more complex
datasets like STL-10 and CIFAR-10. Similar result is also obtained in the recent work, across
different shot settings (19).
We also compare with using latent representation directly with k-Nearest-Neighbor classiﬁer,
labelled as “Latent” in the table. The architecture and training procedure for “Latent” method
is exactly the same to our method — we train on unlabelled data to generate the sample and
then take the latent representation for classiﬁcation. We can see using latent representation
outperforms all supervised methods on four out of ﬁve datasets. But the accuracy is still way
lower than our method, indicating our method can better utilize the generative models.
Text Experiments
Our theory is generally applicable, even without pre-training on unlabelled data. Here, we
demonstrate signiﬁcant advantages of our approach with a simple compressor gzip over lower
resource languages.
Languages with Abundant Resources We ﬁrst test our method on datasets with abundant
resources. Speciﬁcally, we compare with three datasets — AG News, SogouNews and DBpedia.
8
MNIST KMNIST FashionMNIST STL-10 CIFAR-10
SVM 69.4±2.2 40.3±3.6 67.1±2.1 21.3±2.8 21.1±1.9
CNN 72.4±3.5 41.2±1.9 67.4±1.9 24.8±1.5 23.4±2.9
VGG 69.4±5.7 36.4±4.7 62.8±4.1 20.6±2.0 22.2±1.6
ViT (disc) 58.8±4.6 35.8±4.1 61.5±2.2 24.2±2.5 22.3±1.8
Latent 73.6±3.1 48.1±3.3 69.5±3.5 31.5±3.7 22.2±1.6
Ours 77.6±0.4 55.4±4.3 74.1±3.2 39.6±3.1 35.3±2.9
Table 1: 5-shot image classiﬁcation accuracy on ﬁve datasets.
AG News SogouNews DBpedia
fasttext 27.3±2.1 54.5±5.3 47.5±4.1
Bi-LSTM+Attn 26.9±2.2 53.4±4.2 50.6±4.1
HAN 27.4±2.4 42.5±7.2 35.0±1.2
W2V 38.8±18.6 14.4±0.5 32.5±11.3
BERT 80.3±2.6 22.1±4.1 96.4±4.1
Ours 58.7±4.8 64.9±6.1 62.2±2.2
Table 2: 5-shot text classiﬁcation accuracy on three datasets.
Similar to image classiﬁcation, we compare with both supervised methods, including fasttext (20),
BiLSTM (21) with attention mechanism (22) and Hierarchical Attention Network (HAN) (23),
and non-parametric methods that use Word2Vec (W2V) (24) as representation. We also compare
with pre-trained language models like BERT (25) We use ﬁve labelled data for each class (5-shot)
for all the methods.
Surprisingly, even without any pre-training and with a simple compressor like gzip, our
method outperforms all non-pretrained supervised methods and non-parametric methods in
low data regime. This indicates that compressor serves as an efﬁcient method to capture the
regularity and our information distance is effective in comparing the similarity based on the
essential information. When comparing with pre-trained models like BERT, we can see our
method is signiﬁcantly higher on SogouNews, a special dataset that includes Pinyin — a phonetic
romanization of Chinese, which can be viewed as an Out-Of-Distributed (OOD) dataset as it
uses the same alphabet as english corpus.
Low-Resource Languages Sufﬁciently pre-trained language models are exceptional few-shot
learners (8). However, when faced with low resource data or distributions that are signiﬁcantly
different from any pre-trained data, those pre-trained language models lose their advantages
to our method. We compare our method with BERT on four different low-resource language
datasets - Kinyarwanda, Kirundi, Swahili and Filipino. These datasets are curated
to have the Latin alphabets, same as english corpus. BERT has performed extremely well as
9
Kinnews Kirnews Swahili Filipino
BERT 24.0±6.0 38.6±10.0 39.6±9.6 40.9±5.8
mBERT 22.9±6.6 32.4±7.1 55.8±16.9 46.5±4.8
Ours 45.8±6.5 54.1±5.6 62.7±7.2 65.2±4.8
Table 3: 5-shot text classiﬁcation accuracy on low-resource datasets
shown in Table 2 due to pre-training on billions of tokens. However, when facing low-resource
datasets, BERT perform signiﬁcantly worse than our method only using gzip as we can see
in Table 3, no matter using multilingual pre-trained version or the original one. Note that mBERT
is pre-trained on 104 languages including Swahili and Tagalog (on which Filipino is based
on). As we can see on Swahili and Filipino, mBERT performs better than BERT, but still
signiﬁcantly lower than our method.
Omniglot one-shot-classiﬁcation dataset
Figure 3: Distance between two Bezier curves
In ( 4), a one-shot learning framework
Bayesian program learning (BPL) was pro-
posed. It learns a simple probabilistic model
for each concept. Taking a negative logarithm
converts a Bayesian formula to a description
length paradigm, hence BPL can be viewed
as one particular approximation to our theory.
Here we provide another simple approxima-
tion of our theory for the Omniglot one-shot-
classiﬁcation dataset of (4).
Our system ﬁrst decompose a given char-
acter into strokes, then compute E(a,b) be-
tween characters aand b, using all their possi-
ble stroke decomposition. We provide how to
calculate E(a,b) here and details of decompo-
sition program is given in Appendix A.
1. Fit a stroke by a Bezier curve;
2. Ensure the number of points on two curves are same. This algorithm utilize equally split
method to select certain same number of points on each curve Figure 3;
3. Ensure the area of the convex hull and the barycenter of the compared characters are the
same;
10
4. Use max Cartesian distance between parallel points on two Bezier curves to approximate
the minimum encoding distance between two Bezier curves, as shown in Figure 3;
5. Choose the character with minimum distance.
This simple implementation achieves 92.25% accuracy 20-way-1-shot on this dataset. The
point here is to demonstrate various approximations of our theory that work rather than com-
paring accuracy. At 96.75% (4) or at 92.25% might be two different individuals with different
compression algorithms.
Uniﬁcation
Our framework can unify other popular deep neural networks for few-shot learning.
Siamese Network: Siamese network uses twin subnetwork to rank the similarity between
two inputs in order to learn useful features. Mhere is often a contrastive loss. This framework
shows strong performance in one-shot image recognition (26).
Prototypical Network: Prototypical networks (27) propose to optimize the distance metric
Mdirectly by learning coreh in representation space. coreh are represented as the mean of
embedded support samples.
Bi-Encoder: In the context of natural language processing, one of the dominant structure
is the Bi-Encoder design with each encoder being a pre-trained language model. For example,
in information retrieval, Dense Passage Retrieval (DPR), with two encoders encoding query
and document respectively, has become the new state of the art. To capture semantic similarity,
sentenceBERT (28) also adopts the bi-encoder design and becoming one of the most prevalent
methods for semantic textual similarity. Min both cases can either be cosine similarity or
Euclidean distance between the representation learned through pre-trained models.
Information Distance based Methods: Hundreds of algorithms were published, before the
deep learning era, on parameter-free data mining, clustering, anomaly detection, classiﬁcation
using information distance E(29–34), with a comprehensive list in ( 13). Recently ( 19) have
discovered using information distance with deep neural networks and leverage the generalizability
of few-shot image classiﬁcation. This work shows that with the help of deep generative models,
unlabelled data can be better utilized for few-shot learning under our framework.
Conclusion and a discussion on consciousness
We have deﬁned human-like few-shot learning and derived an optimal form of such few-shot
learning. Note there is an interesting difference between our theory and classical learning
theory. In classical learning theory, it is well-known that if we compress training data to a
smaller consistent description, whether it is a classical Bayesian network or a deep neural
networks (13, 35), we would achieve learning. In this paper, we demonstrate that in the inference
11
stage, compression is also important, especially when there are not enough labelled data to
train a small model. On the biological side, compression circuits using predictive coding in
human cortex has been studied by (36). Experiments have also strongly supported our theory.
We expect to see more practical systems approximating our theory can be implemented to
solve commonplace few-shot learning problems when large amounts of labelled data for deep
learning is lacking. We now wish to explore two consequences of our few-shot learning model,
to consciousness.
A binary classiﬁer of interestingness
Our few-shot learning model has a by-product. We have proved compression is a universal goal
that few-shot learning algorithms approximate. Thus this implies immediately a (subconscious)
binary classiﬁer: if something is compressed, then something interesting happens, and attention
is given. It turns out that this "Interestingness" has been theoretically studied as logical depth ﬁrst
proposed by Charles Bennett (13). According to Bennett, a structure is deep if it is superﬁcially
random but subtly redundant. When few-shot learning happens, signiﬁcant compression happens,
and these deep objects gain attention. Such a binary classiﬁer might explain our appreciation
of arts, music, games, and science, since these all share a common feature of dealing with
non-trivially compressible objects: whether it is a shorter description of the data that gives rise
of Newton’s laws (13), or a piece of art or music that itself is compressible or that reminds us of
something we have experienced before, hence very compressible, we feel we understand it and
hence appreciate it. Science is nothing but compressing data into simpler descriptions of nature.
Consciousness and the ability of labelling data
Do other species have consciousness? It is difﬁcult to answer this question as consciousness is
not testable. Thomas Nagel ( 37) made a comment: We will never know if a bat is conscious
because we are not bats.
Consider an alternative data-driven approach by asking what a species can do instead of how
they feel. That is, if we treat some aspects of consciousness as a collection of learned concepts,
then given a compression network, the ability of acquiring the relevant concepts becomes a matter
of labelling relevant data. We know learning and consciousness are both located at posterior
cortex region (38). This is in agreement with some injured patients when they lost consciousness.
This is also in agreement with “bistable perception” training results with monkeys (39).
Varieties of consciousness are being pragmatically studied (40). These include: 1) the ability
of consciously perceive the environment; 2) the ability of evaluating conscious emotions; 3) the
ability of having a uniﬁed conscious experience; 4) the ability of integrating across time as a
continuous stream, one moment ﬂowing into the next; 5) the conscious awareness of oneself
as distinct from the world outside. Many of these abilities may be seen as a few-shot learnable
concepts, given properly labelled data.
12
Different animals have various levels of some of such consciousness by passing certain tests.
For example, chimpanzees, dolphins, Asian elephants, and magpies can recognize themselves
by passing some mirror-mark tests. The corvids display some emotions, and are able to plan
ahead. Octopus have powerful perceptual facilities obtaining and processing data independently
with each tentacle. Experimentally, awareness emerges when information travels back and forth
between brain areas (41) instead of a linear chain of command.
According to our theory, the brain really only needs to use a universal compressor to compress
information, regardless of one processor in the head or a few processors in the tentacle (in case
of Cephalopods). Thus we can conjecture that "consciousness” then is a matter of ability of
labelling the data from sensory terminals. Food or enemy in the environment are easy to label.
Emotional labelling requires some level of abstraction. Self-awareness of “me” and “others”
thus is just another binary classiﬁer trainable depending on if the species is able to do “displaced
reference” mental labelling. Other than the human beings, only orangutans are known to have
limited displaced reference ability (42).
Thus we have just reduced the non-testable question of whether an animal has consciousness
in some aspects to if it is able to label the corresponding data properly.
Acknowledgement
We thank Dr. Hang Li for suggestions and bringing (43) to our attention and Dr. Amy Sun for
bringing (44) to our attention. The work is supported in part by Canada’s NSERC operating grant
OGP0046506, Canada Research Chair Program, and the Leading Innovative and Entrepreneur
teams program of Zhejiang, number 2019R02002, and NSFC grant 61832019.
References and Notes
1. Y . LeCun, Y . Bengio, G. Hinton,Nature 521, 436 (2015).
2. C. Spearman (1961).
3. K. Friston, Nature Review Neuroscience 11, 21 (2010).
4. B. M. Lake, R. Salakhutdinov, J. B. Tenenbaum, Science 350, 1332 (2015).
5. E. Stern, npj Science of Learning 2, 1 (2017).
6. M. Hebart, C. Zheng, F. Pereira, C. Baker,Nature, Human Behaviour pp. 1173–1185 (2020).
7. C. Finn, P. Abbeel, S. Levine, International conference on machine learning (PMLR, 2017),
pp. 1126–1135.
8. T. Brown, et al., Advances in neural information processing systems 33, 1877 (2020).
13
9. T. J. Bouchard Jr, Annals of Human Biology 36, 527 (2009).
10. M. N. Bernstein, mbernste.github.io/posts/elbo/ .
11. J. Schmidhuber, arXiv:0812.4360v2 [cs.AI] (2009).
12. N. Chater, P. Vitányi, Trends in Cognitive Sciences 7, 19 (2003).
13. M. Li, P. Vitányi,An Introduction to Kolmogorov Complexity and Its Applications(Springer-
Verlag, 1993, 1997, 2008, 2019).
14. C. Bennett, P. Gács, M. Li, P. Vitányi, W. Zurek, IEEE Trans. Inform. Theory 44, 1407
(1998).
15. D. C. Knill, A. Pouget, TRENDS in Neurosciences 27, 712 (2004).
16. K. Friston, PLoS computational biology 4, e1000211 (2008).
17. C. Koch, G. Tononi, Scientiﬁc American 304 (2011).
18. J. Townsend, T. Bird, D. Barber, International Conference on Learning Representations
(2018).
19. Z. Jiang, Y . Dai, J. Xin, M. Li, J. Lin,Advances in Neural Information Processing Systems
(2022).
20. A. Joulin, E. Grave, P. B. T. Mikolov, EACL 2017 p. 427 (2017).
21. M. Schuster, K. K. Paliwal, IEEE transactions on Signal Processing 45, 2673 (1997).
22. Y . Wang, M. Huang, X. Zhu, L. Zhao,Proceedings of the 2016 conference on empirical
methods in natural language processing (2016), pp. 606–615.
23. Z. Yang, et al., Proceedings of the 2016 conference of the North American chapter of
the association for computational linguistics: human language technologies (2016), pp.
1480–1489.
24. T. Mikolov, K. Chen, G. Corrado, J. Dean, arXiv preprint arXiv:1301.3781 (2013).
25. J. Devlin, M.-W. Chang, K. Lee, K. Toutanova, Proceedings of the 2019 Conference of
the North American Chapter of the Association for Computational Linguistics: Human
Language Technologies, Volume 1 (Long and Short Papers)(2019), pp. 4171–4186.
26. G. Koch, R. Zemel, R. Salakhutdinov,et al., ICML deep learning workshop (Lille, 2015),
vol. 2, p. 0.
14
27. J. Snell, K. Swersky, R. Zemel, Advances in neural information processing systems 30
(2017).
28. N. Reimers, I. Gurevych, Proceedings of the 2019 Conference on Empirical Methods
in Natural Language Processing and the 9th International Joint Conference on Natural
Language Processing (EMNLP-IJCNLP) (2019), pp. 3982–3992.
29. M. Li, et al., Bioinformatics 17, 149 (2001).
30. E. Keogh, S. Lonardi, C. A. Ratanamahatana, Proceedings of the tenth ACM SIGKDD
international conference on Knowledge discovery and data mining (2004), pp. 206–215.
31. C. H. Bennett, M. Li, B. Ma, Scientiﬁc American 288, 76 (2003).
32. M. Nykter, et al., Physical review letters 100, 058702 (2008).
33. D. Benedetto, E. Caglioti, V . Loreto,Physical Review Letters 88, 048702 (2002).
34. M. Nykter, et al., Proceedings of the National Academy of Sciences 105, 1897 (2008).
35. Y . Bengio,et al., Foundations and trends® in Machine Learning2, 1 (2009).
36. R. P. Rao, D. H. Ballard, Nature neuroscience 2, 79 (1999).
37. T. Negel, Readings in philosophy of psychology (1974).
38. C. Koch, Scientiﬁc American. (2018).
39. G. Miller, Science 309, 79 (2005).
40. J. Birch, A. Schnell, N. Clayton, Trends in cognitive sciences (2020).
41. M. Boly, et al., Science 332 (May, 2011).
42. H. Lyn, et al., Animal Cognition 17 (2014).
43. Y . Ma, D. Tsao, H. Shum (2022).
44. F. Scherr, C. Stöckl, W. Maass, BioRxiv (2020).
15
A Algorithm for extracting strokes from a character
Repeat until all pixels of a character are marked, by depth-ﬁrst search:
(1) Extract its skeleton so that the stroke width is 1 pixel point. Then convert the image to
a graph and shrink adjacent cross points. (2) Randomly select an endpoint as starting point,
endpoint at top left has a greater chance of being selected. Walk until a cross point or endpoint.
If there is a circle then select a cross point of a top left point if there is no cross point. Record
this stroke and mark it on the character. Allow small number of marked pixel points to make
the decomposition more natural. (3) When meeting a cross point, then enumerate two situations
of pen-up and turning, randomly. Pen-up means end of a stroke, go to step (2) with the marked
graph. Turning means continuation hence repeat step (2). If walking to an endpoint, then attempt
to turn by going back to ﬁnd a new unmarked pixels within some small number of pixels or
directly end the stroke and repeat step (2) with marked graph.
16