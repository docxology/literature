1
Active Anomaly Detection in Heterogeneous
Processes
Boshuang Huang, Kobi Cohen, Qing Zhao
Abstract— An active inference problem of detecting anomalies
among heterogeneous processes is considered. At each time, a
subset of processes can be probed. The objective is to design a
sequential probing strategy that dynamically determines which
processes to observe at each time and when to terminate the
search so that the expected detection time is minimized under
a constraint on the probability of misclassifying any process.
This problem falls into the general setting of sequential design
of experiments pioneered by Chernoff in 1959, in which a
randomized strategy, referred to as the Chernoff test, was
proposed and shown to be asymptotically optimal as the error
probability approaches zero. For the problem considered in this
paper, a low-complexity deterministic test is shown to enjoy the
same asymptotic optimality while offering signiﬁcantly better
performance in the ﬁnite regime and faster convergence to the
optimal rate function, especially when the number of processes
is large. The computational complexity of the proposed test is
also of a signiﬁcantly lower order.
Index Terms— Active hypothesis testing, sequential design
of experiments, anomaly detection, dynamic search, target
whereabout.
I. I NTRODUCTION
We consider the problem of detecting an anomalous process
among M heterogeneous processes. Borrowing terminologies
from target search, we refer to these processes as cells and the
anomalous process as the target which can locate in any of the
M cells. At each time, K (1 ≤K <M) cells can be probed
simultaneously to search for the target. Each search of cell
i generates a noisy observation drawn i.i.d. over time from
two different distributions fi and gi, depending on whether
the target is absent or present. The objective is to design a
sequential search strategy that dynamically determines which
cells to probe at each time and when to terminate the search
so that the expected detection time is minimized under a
constraint on the probability of declaring a wrong location
of the target.
The above problem is prototypical of searching for rare
events in a large number of data streams or a large system. The
rare events could be opportunities (e.g., ﬁnancial trading op-
portunities or transmission opportunities in dynamic spectrum
Boshuang Huang and Qing Zhao are with the School of Electrical and
Computer Engineering, Cornell University, Ithaca, NY , 14853, USA. Email:
{bh467, qz16}@cornell.edu. Kobi Cohen is with the Department of Electrical
and Computer Engineering, Ben-Gurion University of the Negev, Beer-Sheva
84105, Israel. Email: yakovsec@bgu.ac.il.
This work was supported by the National Science Foundation under Grant
CCF-1815559 and by the Army Research Ofﬁce under Grant W911NF-17-1-
0464. The work of Kobi Cohen was supported by the Cyber Security Research
Center at Ben-Gurion University of the Negev, and the U.S.-Israel Binational
Science Foundation (BSF) under grant 2017723.
access [1]), unusual activities in surveillance feedings, frauds
in ﬁnancial transactions, attacks and intrusions in communica-
tion and computer networks, anomalies in infrastructures (such
as bridges, buildings, and the power grid) that may indicate
catastrophes. Depending on the application, a cell may refer
to an autonomous data stream with a continuous data ﬂow or
a system component that only generates data when probed.
A. Main Results
The anomaly detection problem considered in this paper
is a special case of active hypothesis testing originated from
Chernoff’s seminal work on sequential design of experiments
in 1959 [2]. Compared with the classic passive sequential
hypothesis testing pioneered by Wald [3], where the obser-
vation model under each hypothesis is predetermined, active
hypothesis testing has a control aspect that allows the de-
cision maker to choose the experiment to be conducted at
each time. Different experiments generate observations from
different distributions under each hypothesis. Intuitively, as
more observations are gathered, the decision maker becomes
more certain about the true hypothesis, which in turn leads to
better choices of experiments.
In [2], Chernoff proposed a randomized strategy, referred
to as the Chernoff test, and established its asymptotic (as the
error probability diminishes) optimality1. This randomized test
chooses, at each time, a probability distribution that governs
the selection of the experiment to be carried out at this time.
This distribution is obtained by solving a minimax problem so
that the next observation generated under the random action
can best differentiate the current maximum likelihood estimate
of the true hypothesis (using all past observations) from its
closest alternative, where the closeness is measured by the
Kullback-Liebler (KL) divergence. Due to the complexity in
solving this minimax problem at each time, the Chernoff test
can be expensive to compute and cumbersome to implement,
especially when the number of hypotheses or the number of
experiments is large.
It is not difﬁcult to see that the problem at hand is a special
case of the general active hypothesis testing problem. Specif-
ically, the available experiments are in the form of different
subsets of K cells to probe, and the number of experiments is(M
K
)
. Under each hypothesis that cell m (m = 1,...,M ) is
the target, the distribution of the next observation (a vector
of dimension K) depends on which K cells are chosen.
The Chernoff test thus directly applies. Unfortunately, with
1The asymptotic optimality of the Chernoff test was shown under the
assumption that the hypotheses are distinguishable under every experiment.
arXiv:1704.00766v3  [cs.IT]  28 Aug 2018
2
the large number of hypotheses and the large number of
experiments, it can be computationally prohibitive to obtain
the Chernoff test.
In this paper, we show that the anomaly detection prob-
lem considered here exhibits sufﬁcient structures to admit a
low-complexity deterministic policy with strong performance.
In particular, we develop a deterministic test that explicitly
speciﬁes which K cells to search at each given time and
show that this test enjoys the same asymptotic optimality as
the Chernoff test 2. Furthermore, extensive simulation exam-
ples have demonstrated signiﬁcant performance gain over the
Chernoff test in the ﬁnite regime and faster convergence to the
optimal rate function, especially when M is large. In contrast
to the Chernoff test, the proposed test requires little ofﬂine
or online computation. The test can also be extended to cases
with multiple targets as discussed in Section V. Its asymptotic
optimality is preserved for K = 1.
Often, when a solution is simpler, establishing its optimality
becomes harder. This is indeed the case here. In Chernoff test,
since the distribution of the random action depends only on
the current maximum likelihood estimate of the underlying
hypothesis which becomes time-invariant after an initial phase
with a bounded duration, the stochastic behaviors of the
test statistics, namely, the log-likelihood ratios (LLRs), are
independent over time. In contrast, the deterministic actions
under the proposed policy result in strong time and spacial
(across processes) dependencies in the dynamic evolutions
of the LLRs. Establishing the asymptotic optimality becomes
much more involved.
B. Related Work
Chernoff’s pioneering work on sequential design of exper-
iments focuses on binary composite hypothesis testing [2].
Variations and extensions have been studied in [4]–[9], where
the problem was referred to as controlled sensing for hypoth-
esis testing in [5]–[7] and active hypothesis testing in [8], [9].
As variants of the Chernoff test, the tests developed in [4]–[9]
are all randomized tests.
There is an extensive literature on dynamic search and target
whereabout problems under various scenarios. We discuss
here existing studies within the sequential inference setting,
which is the most relevant to this work. Two models on prior
information about the targets have been considered in the
literature: the exclusive model which assumes a ﬁxed number
of targets and the independent model which assumes each cell
may contain a target with a given prior probability independent
of other cells. These two models were juxtaposed in [10],
[11] under different objective functions. The studies in [12]–
[16] focus on the exclusive model. In particular, homogeneous
Poisson point processes with unknown rates was investigated
and an asymptotically optimal randomized test was developed
in [12]. In [13], the problem of tracking a target that moves as
a Markov Chain in a ﬁnite discrete environment is studied and
a search strategy that provides the most conﬁdent estimate is
developed. The studies in [17]–[20] focus on the independent
2The asymptotic optimality of the proposed test holds for all but at most
three singular values of K (see Theorem 3).
model. The problem of searching among Gaussian signals with
rare mean and variance values was studied and an adaptive
group sampling strategy was developed in [17]. In [18], the
problem of quickly detecting anomalous components under
the objective of minimizing system-wide cost incurred by all
anomalous components was studied. In [19], an important case
of multichannel sequential change detection is studied and an
asymptotic framework in which the number of sensors tends
to inﬁnity was proposed.
Asymptotically optimal search policies over homogeneous
processes were established in [21] under a non-parametric
setting with ﬁnite discrete distributions and in [22] under
a parametric composite hypothesis setting with continuous
distributions. The objective of minimizing operational cost
as opposed to detection delay led to a different problem
from the one considered in this paper. Other related work on
quickest search over multiple processes under various models
and formulations includes [10], [14], [20], [23] and references
therein. Sequential spectrum sensing within both the passive
and active hypothesis testing frameworks has also received
extensive attention in the application domain of cognitive radio
networks (see, for example, [24]–[27] and references therein).
The readers are also referred to [28] for a comprehensive
survey on the problem of detecting outlying sequences.
A prior study by Cohen and Zhao considered the problem
for homogeneous processes (i.e., fi ≡f and gi ≡g) [15]. This
work builds upon this prior work and addresses the problem
in heterogeneous systems where the absence distribution fi
and the presence distribution gi are different across processes.
Allowing heterogeneity signiﬁcantly complicates the design
of the test and the analysis of asymptotic optimality. Since
each process has different observation distributions, the rate
at which the state of a cell can be inferred is different across
processes. To achieve asymptotic optimality, the decision
maker must carefully balance the search time among the
observed processes, which makes both the algorithm design
and the performance analysis much more involved under the
heterogeneous case. Speciﬁcally, in terms of algorithm design,
when dealing with homogeneous processes, the search strategy
is often static in nature [10], [12], [15], [21]. In contrast,
the asymptotically optimal search strategy developed here for
heterogeneous processes dynamically changes based on the
current belief about the location of the target. In terms of per-
formance analysis, when dealing with homogeneous processes,
the resulting rate function (which is inversely proportional to
the search time) always obeys a certain averaging over the
KL divergences between normal and abnormal distributions of
all processes. This observation follows from the fact that the
decision maker completes gathering the required information
from all the processes at approximately the same time due
to the homogeneity. In contrast, when searching over hetero-
geneous processes, the overall rate function does not always
obey a simple averaging across the KL divergences of all
processes. In Section IV, we show that the search time can
be analyzed by considering two separate scenarios, referred
to as the balanced and the unbalanced cases. The balanced
case holds when a judicious allocation of probing resources
can ensure the information gathering from all the processes be
3
completed at approximately the same time, in which case the
rate function is a weighted average among the heterogeneous
processes. The unbalanced case occurs when there is a process
with a sufﬁciently small KL divergence that it dominates the
overall rate function of the search. This case is unique to
the heterogeneous processes considered here and needs to be
addressed with new analytical techniques.
Besides the active inference approach to anomaly detection
considered in this paper, there is a growing body of literature
on various approaches to the general problem of anomaly
detection. We refer the readers to [29], [30] for comprehensive
surveys on this topic.
II. P ROBLEM FORMULATION
We consider the problem of detecting a single target located
in one of M cells. If the target is in cell m, we say that
hypothesis Hm is true. The a priori probability that Hm is
true is denoted by πm, where ∑M
m=1 πm = 1. To avoid trivial
solutions, it is assumed that 0 <πm <1 for all m.
When cell m is observed at time n, an observation ym(n)
is drawn, independent of previous observations. If cell m
contains a target, ym(n) follows distribution gm(y). Oth-
erwise, ym(n) follows distribution fm(y). Let Pm be the
probability measure under hypothesis Hm and Em the operator
of expectation with respect to the measure Pm.
An active search strategy Γ consists of a stopping rule τ
governing when to terminate the search, a decision rule δ for
determining the location of the target at the time of stopping,
and a sequence of selection rules {φ(n)}n≥1 governing which
K cells to probed at each time n. Let y(n) be the set of all
cell selections and observations up to time n. A deterministic
selection rule φ(n) at time n is a mapping from y(n−1)
to {1,2,...,M }K. A randomized selection rule φ(n) is a
mapping from y(n−1) to probability mass functions over
{1,2,...,M }K.
We adopt a Bayesian approach as in Chernoff’s original
study [2] by assigning a cost of c for each observation and
a loss of 1 for a wrong declaration. Note that c represents
the ratio of the sampling cost to the cost of wrong detections.
The Bayes risk under strategy Γ when hypothesis Hm is true
is given by:
Rm(Γ) ≜ αm(Γ) + cEm(τ|Γ), (1)
where αm(Γ) = Pm(δ̸= m|Γ) is the probability of declaring
δ ̸= m under Hm and Em(τ|Γ) is the detection delay under
Hm. The average Bayes risk is given by:
R(Γ) =
M∑
m=1
πmRm(Γ) = Pe(Γ) + cE(τ|Γ), (2)
where Pe(Γ) and E(τ|Γ) are the error probability and detec-
tion delay averaged under the given prior {πm}. The objective
is to ﬁnd a strategy Γ that minimizes the Bayes risk R(Γ):
inf
Γ
R(Γ). (3)
A strategy Γ∗ is asymptotically optimal if
lim
c→0
R(Γ∗)
infΓ R(Γ) = 1, (4)
which is denoted as
R(Γ∗) ∼inf
Γ
R(Γ). (5)
III. T HE DETERMINISTIC DGF I POLICY
In this section we propose a deterministic policy, re-
ferred to as the DGFi policy, indicating the key quantities
{D(gi||fi), D(fi||gi)}M
i=1 that govern the selection rule of the
proposed policy.
A. DGFi under Single-Cell Probing
We ﬁrst consider the case of K = 1 . Let 1m(n) be the
indicator function, where 1m(n) = 1 if cell m is observed
at time n, and 1m(n) = 0 otherwise. This indicator function
clearly depends on the selection rule, which we omit in the
notation for simplicity. Let
ℓm(n) ≜ log gm(ym(n))
fm(ym(n)) , (6)
and
Sm(n) ≜
n∑
t=1
ℓm(t)1m(t) (7)
be the LLR and the observed sum LLRs of cell m at time n,
respectively. Let D(g||f) denote the KL divergence between
two distributions g and f which is given by 3
D(g||f) ≜
∫ ∞
−∞
log g(x)
f(x)g(x) dx. (8)
Fig. 1: Typical sample paths of sum LLRs.
Illustrated in Fig. 1 are typical sample paths of the sum
LLRs of M = 4 cells, where, without loss of generality, we as-
sume that cell 1 is the target. Note that the sum LLR of cell 1 is
a random walk with a positive expected increment D(g1||f1),
whereas the sum LLR of cell m (m = 2 ,3,4) is a random
walk with a negative expected increment −D(fm||gm). Thus,
when the gap between the largest sum LLR and the second
largest sum LLR is sufﬁciently large, we can declare with a
sufﬁcient accuracy that the cell with the largest sum LLR is
the target. This is the intuition behind the stopping rule and
the decision rule under DGFi. Speciﬁcally, we deﬁne m(i)(n)
3We assume that gi is absolutely continuous with respect to fi (i =
1,...,M ) and vise versa, which ensures that all KL divergences are ﬁnite.
4
as the index of the cell with the ith largest observed sum LLRs
at time n. Let
∆S(n) ≜ Sm(1)(n)(n) −Sm(2)(n)(n) (9)
denote the difference between the largest and the second
largest observed sum LLRs at time n. The stopping rule and
the decision rule under the DGFi policy are given by:
τ = inf {n : ∆ S(n) ≥−log c}, (10)
and
δ= m(1)(τ) . (11)
We now specify the selection rule of the DGFi policy. The
intuition behind the selection rule is to select a cell from which
the observation can increase ∆S(n) at the fastest rate. The
selection rule is thus given by comparing the rate at which
Sm(1)(n)(n) increases with the rate at which Sm(2)(n)(n)
decreases. If Sm(1)(n)(n) is expected to increase faster than
Sm(2)(n)(n) decreases, cell m(1)(n) is chosen. Otherwise, cell
m(2)(n) is chosen. This leads to the following selection rule:
φ(n) =
{ m(1)(n), if D(gm(1)(n)||fm(1)(n)) ≥ ¯Fm(1)(n)
m(2)(n), otherwise ,
(12)
where
¯Fm ≜ 1∑
j̸=m
1
D(fj||gj)
. (13)
The selection rule in (12) can be intuitively understood by
noticing that D(gm(1)(n)||fm(1)(n)) is the asymptotic increas-
ing rate of Sm(1) (n) when cell m(1) is probed at each time.
This is due to the fact that m(1)(n) is the true target after an
initial phase (deﬁned by the last passage time that m(1)(n)
is an empty cell) which can be shown to have a bounded
expected duration. Similarly, even though much more involved
to prove, ¯Fm(1)(n) is the asymptotic rate at which Sm(2)(n)(n)
decreases when cell m(2)(n) is probed at each time. To see
the expression of ¯Fm for any m as given in (13), consider
the following analogy. Consider M −1 cars being driven
by a single driver from 0 to −∞. Car j (j = 1 ,...,M ,
j ̸= m) has a constant speed of D(fj||gj). At each time,
the car closest to the origin is chosen by the driver and driven
by one unit of time. We are interested in the average moving
speed of the position of the closest car to the origin. It is not
difﬁcult to see that it is given by ¯Fm in (13). This analogy,
concerned with deterministic processes, only serves as an
intuitive explanation for the expression of ¯Fm. As detailed
in Sec. IV, proving ¯Fm(1)(n) to be the asymptotic decreasing
rate of Sm(2)(n)(n) requires analyzing the trajectories of the
M sum LLRs {Sm(n)}M
m=1, which are stochastic processes
with complex dependencies both in time and across processes.
B. DGFi under Multiple Simultaneous Observations
Now we consider the case of K > 1. The stopping rule
and the decision rule remains the same as given in (10), (11),
whereas the selection rule requires a signiﬁcant modiﬁcation.
The main reason is that when K cells can be observed
simultaneously, the asymptotic increasing rate of Sm(1)(n)(n)
and the asymptotic decreasing rate of Sm(2)(n)(n) are much
more involved to analyze.
The selection rule φ(n), at each time n, chooses either the
K cells with the top K largest sum LLRs or those with the
second to the (K+ 1)th largest sums LLRs as in (14) where
Fm(κ) ≜ min{κ¯Fm, min
j̸=m
D(fj||gj)}. (15)
Note that (15) reduces to (13) at K = 1 (i.e., Fm(1) = ¯Fm),
in which case the minimum is always attained at the ﬁrst
term. Similar to the case with K = 1, the intuition behind the
selection rule is to select K cells from which the observations
increase ∆S(n) at the fastest rate. Speciﬁcally, Fm(1)(n)(K)
is the asymptotic decreasing rate of Sm(2)(n)(n) when K cells
with the second largest to the (K+1)th largest sum LLRs are
probed each time. When the cell with the top K largest sum
LLRs are probed each time, the asymptotic increasing rate
of ∆S(n) is D(gm(1)(n)||fm(1)(n)) +Fm(1)(n)(K−1), where
D(gm(1)(n)||fm(1)(n)) is the asymptotic increasing rate of
Sm(1)(n)(n) and Fm(1)(n)(K−1) is the asymptotic decreasing
rate of Sm(2)(n)(n) with K−1 drivers. It is easy to see that
when K = 1 , the policy reduces to the one described in
section III-A.
Fig. 2: The piecewise linear property of Fm(κ).
The behavior of Fm(κ) as a function of κ (extending κ
to all positive real values) is crucial in understanding and
analyzing the asymptotic optimality of DGFi for K >1. It
is easy to see that the ﬁrst term in the right hand of (15) is
a linearly increasing function of κ and the second term is a
constant. This readily leads to the piecewise linear property of
Fm(κ) as illustrated in Fig. 2. Let ˜Km denote the switching
point between the increasing and constant regions, we have
φ(n) =
{(
m(1)(n),m(2)(n),...,m (K)(n)
)
if D(gm(1)(n)||fm(1)(n)) + Fm(1)(n)(K−1) ≥Fm(1)(n)(K)(
m(2)(n),m(3)(n),...,m (K+1)(n)
)
otherwise (14)
5
˜Km = minj̸=mD(fj||gj)
¯Fm
=
∑
j̸=m
minj̸=mD(fj||gj)
D(fj||gj) . (16)
The constant value of Fm(κ) for κ ≥ ˜Km can be
explained with the same car analogy. This constant value
minj̸=mD(fj||gj) is the speed of the slowest car among the
M −1 cars (excluding the mth car). When the speed of the
slowest car is sufﬁciently small, this car always lags behind
even with a dedicated driver. This car becomes the bottleneck
that caps the value of Fm(κ) even when the number κ of
drivers increases (note that each car can at most have one
driver assigned). We refer to this case as the unbalanced case,
which presents the most challenge in proving the asymptotic
optimality of DGFi. The linearly increasing region of κ< ˜Km
is referred to as the balanced case, where Fm(κ) is a weighted
average among the M −1 cars.
IV. P ERFORMANCE ANALYSIS
In this section, we establish the asymptotic optimality of the
DGFi policy. While the intuitive exposition of DGFi given in
Sec. III may make its asymptotic optimality seem expected,
constructing a proof is much more involved. In particular,
bounding the detection time of DGFi requires analyzing the
trajectories of the M stochastic processes {Sm(n)}M
m=1 which
exhibit complex dependencies both over time and across
processes as induced by the deterministic selection rule.
The asymptotic optimality of DGFi is established by com-
paring its Bayes risk (given in Theorem 1) with a lower
bound on achievable Bayes risk (given in Theorem 2). We
ﬁrst analyze the rate function of DGFi. Deﬁne
Im(ΓDGFi) ≜ max{D(gm||fm) + Fm(K−1),Fm(K)},
(17)
which is the increasing rate of ∆S(n) under hypothesis Hm
when DGFi is employed. For a given a priori distribution
{πm}M
m=1, deﬁne
I(ΓDGFi) ≜ 1∑M
m=1
πm
Im(ΓDGFi)
. (18)
As shown in Theorem 1 below, I(ΓDGFi) is the rate function
of the Bayes risk of the DGFi policy.
Theorem 1: The Bayes risk R(ΓDGFi) of the DGFi policy
is given by
R(ΓDGFi) ∼ −clog c
I(ΓDGFi). (19)
Proof: Here we provide a sketch of the proof. The detailed
proof can be found in Appendix A. First, we show that
when ∆S(τ) is large, the probability of error is small, i.e.
Pe = O(c). As a result, by the deﬁnition of the Bayes risk,
it sufﬁces to show that the detection time is upper bounded
by −log c/I(ΓDGFi). By the deﬁnition of I(ΓDGFi) in (18), it
sufﬁces to show that the detection time is upper bounded by
−log c/Im(ΓDGFi) under hypothesis Hm. Since the decision
maker might not complete to gather the required information
from all the cells at the same time, we carry out the analysis
by treating the balanced and the unbalanced cases separately.
Next we estabilsh a lower bound on the Bayes risk achiev-
able by any policy. Deﬁne
I∗
m ≜ max
u∈[0,1]
uD(gm||fm) + Fm(K−u). (20)
I∗ ≜ 1∑M
m=1
πm
I∗m
. (21)
Using the same car analogy, we can interpret I∗
m as the
maximum increasing rate of ∆S(n) under hypothesis Hm with
an optimal allocation of u∗ ∈[0,1] driver to the target car.
Comparing with the rate of DGFi under Hm in (17), we see
that the deterministic nature of DGFi forces the allocation of
drivers to the target to be either 0 or 1. As shown in Theorem 2
below, I∗is an upper bound on the rate function for any policy.
Theorem 2: Let R(Γ) be the Bayes risk under an arbitrary
policy Γ. We have
inf
Γ
R(Γ) ∼ −clog c
I∗ (22)
Proof: The outline of the proof is as follows. We ﬁrst
prove that if the Bayes risk is sufﬁciently small under strategy
Γ, i.e., R(Γ) = O(−clog c), the difference between the
largest sum LLRs and the second largest sum LLRs must
be sufﬁciently large when the test terminates, i.e. ∆S(τ) =
Ω(−log c). Otherwise, it is not possible to achieve a risk
O(−clog c) due to a large error probability. We then show
that in order to make ∆S(n) sufﬁciently large, the sample
size must be large enough, i.e., E[τ|Γ] ≥−log c
I∗ . Since each
sample costs c, the total risk will be lower bounded by −clog c
I∗
as desired. The detailed proof can be found in Appendix B.
Establishing the asymptotic optimality of DGFi rests on
comparing its rate function I(ΓDGFi) with the optimal rate
function I∗. The key thus lies in analyzing the optimizer u∗
m
in the right hand of (20) and showing whether and when it
assumes integer values of 0 and 1 as used in DGFi. This is
established in Lemma 1 that leads to the following necessary
and sufﬁcient condition for the asymptotic optimality of DGFi.
Theorem 3: A necessary and sufﬁcient condition for the
asymptotic optimality of the DGFi policy is that, for each
m= 1,...,M , at least one of the following three statements
is true
(a) D(gm||fm) ≥ ¯Fm.
(b) K ≤ ˜Km.
(c) K ≥ ˜Km + 1.
Proof: We ﬁrst establish the following lemma on the
maximizer u∗
m that attains I∗
m given in (20). The proof of
this lemma is in Appendix C.
Lemma 1: Deﬁne
u∗
m ≜ arg max
u∈[0,1]
uD(gm||fm) + Fm(K−u). (23)
6
Then,
u∗
m =
{
1, if D(gm||fm) ≥ ¯Fm
min{max{K−˜Km,0},1}, if D(gm||fm) < ¯Fm
.
(24)
From (24) in Lemma 1, u∗
m takes the integer value of 0 or
1 if and only if at least one of the Statements (a), (b), (c) is
true. Theorem 3 thus follows.
Corollary 1: The DGFi policy is asymptotically optimal
except for at most three values of K ∈ {2,3,...,M }
for every given problem instance speciﬁed by
{M,{D(gi||fi),D(fi||gi)}M
i=1}.
Proof: From Theorem 3, it is easy to see that for each m,
there is only one possible K = ⌈˜Km⌉, which is the least inte-
ger greater than or equal to ˜Km, that makes Im(ΓDGFi) <I ∗
m.
Let j′= arg minjD(fj||gj). Since there is only one possible
K = ⌈˜Kj′⌉that makes Ij′(ΓDGFi) < I∗
j′, it remains to show
that there are only two possible values of K = ⌈˜Km⌉that
makes Im(ΓDGFi) <I ∗
m when m̸= j′. Let
V ≜
M∑
j=1
D(fj′||gj′)
D(fj||gj) .
Since 0 ≤
D(fj′||gj′)
D(fm||gm) ≤1, we have
˜Km =
∑
j̸=m
minj̸=mD(fj||gj)
D(fj||gj) = V−D(fj′||gj′)
D(fm||gm) ∈[V−1,V ]
for all m̸= j′. This implies that ⌈˜Km⌉(m̸= j′) can only take
two possible integers as desired.
The above corollary also indicates that for K = 1, the DGFi
policy is always asymptotically optimal. This can be easily
seen since Statement (b) always holds for K = 1. To ﬁnd those
pathological values of Kfor which DGFi is not asymptotically
optimal, we can compute ⌈˜Km⌉deﬁned in (16) for each m=
1,2,...,M . Since for each m, ⌈˜Km⌉only requires O(M)
number of multiplication and summation, the computational
complexity of ﬁnding those pathological values is O(M2).
V. E XTENSION TO DETECTING MULTIPLE TARGETS
In this section we extend the DGFi policy to the case with
L> 1 targets. The number of hypotheses in this case is
(M
L
)
.
We consider ﬁrst K = 1. The stopping rule and decision rule
of DGFi for L >1 are given below, similar in principle to
those for L= 1 as described in Section III:
τ = inf {n : ∆ SL(n) ≥−log c}, (25)
δ= {m(1)(τ),m(2)(τ),...,m (L)(τ)}, (26)
where
∆SL(n) ≜ Sm(L)(n)(n) −Sm(L+1)(n)(n) (27)
denotes the difference between the Lth and the (L + 1)th
largest observed sum LLRs at time n.
For the selection rule, deﬁne, for a given set D ⊂
{1,2,...,M }with |D|= L,
¯FD≜ 1∑
j/∈D
1
D(fj||gj)
. (28)
Similar to ¯Fm deﬁned in (13), FD can be viewed as the
asymptotic increasing rate of ∆SL(n) when the L targets are
given by set Dand we probe the cell with the (L+1)th largest
sum LLR. We also deﬁne
¯GD≜ 1∑
j∈D
1
D(gj||fj)
, (29)
which can be viewed as the asymptotic increasing rate for
∆SL(n) when we probe the cell with the Lth largest sum
LLR.
The selection rule follows the same design principle of
maximizing the asymptotic increasing rate of ∆SL(n), and
is given by
φ(n) =
{
m(L)(n), if ¯GD(n) ≥ ¯FD(n)
m(L+1)(n), otherwise , (30)
where
D(n) = {m(1)(n),m(2)(n),...,m (L)(n)}. (31)
It is not difﬁcult to see that when L= 1, the policy reduces
to the one described in Section III.
Next, we establish the asymptotic optimality of the DGFi
policy for L> 1 and K = 1. Let Ddenote a subset of Lcells
and πDthe prior probability of hypothesis HD(i.e, the target
cells are given by D). Deﬁne
ID≜ max{¯FD, ¯GD},
I∗
L ≜ 1∑
D
πD
ID
, (32)
where I∗
L is again the optimal rate function of the Bayes risk
as shown in the theorem below, and reduces to the one deﬁned
in (20) when L= 1.
Theorem 4: Let RL(ΓDGFi) and RL(Γ) be the Bayes risks
under the DGFi policy and an arbitrary policy Γ, respectively.
For K = 1, we have,
RL(ΓDGFi) ∼ −clog c
I∗
L
∼ inf
Γ
R(Γ) . (33)
Proof: See Appendix D.
For K >1, the stopping rule and the decision rule remain
the same. For the selection rule, deﬁne
FD(κ) ≜ min{κ¯FD, min
j/∈D
D(fj||gj)}. (34)
Similar to Fm(κ) deﬁned in (15), FD(κ) can be viewed as
the asymptotic increasing rate of ∆SL(n) when the L targets
are given by set Dand we probe those κ cells with the (L+
1)th to the (L+ κ)th largest sum LLR. Similarly,
GD(κ) ≜ min{κ¯GD, min
j∈D
D(gj||fj)}, (35)
which can be viewed as the asymptotic increasing rate of
∆SL(n) when we probe the cells with the (L−κ+ 1)th
to the Lth largest sum LLR.
7
Let
k∗
D≜ arg max
k=0,1,...,K
FD(K−k) + GD(k), (36)
which can be interpreted as the optimal number of target
cells that should be probed at each time for maximizing the
asymptotic increasing rate of ∆SL(n). The selection rule of
DGFi is thus given by
φ(n) = {m(L−k∗
D(n)+1)(n),...,m (L−k∗
D(n)+K)(n)}, (37)
where
D(n) = {m(1)(n),m(2)(n),...,m (L)(n)}. (38)
The asymptotic optimality of DGFi for L >1 and K >1
remains open. Following the same insight in the single-
target case, however, we have strong belief of the following
conjecture.
Conjecture 1: The DGFi policy preserves its asymptotic
optimality if
u∗
D≜ arg max
u∈[0,K]
FD(K−u) + GD(u) (39)
is an integer for all D, where we allow the domain of FD(·)
and GD(·) to be real numbers.
VI. C OMPARISON WITH THE CHERNOFF TEST
In this section, we compare the performance of the proposed
DGFi policy and the Chernoff test in terms of both computa-
tional complexity and sample complexity.
A. The Chernoff Test
The Chernoff test has a randomized selection rule. Specif-
ically, let q be a probability mass function over a set of ω
available experiments {ui}ω
i=1 that the decision maker can
choose from. Note that in our case, ω =
(M
K
)
. For each
hypothesis m = 1 ,2,...,M , the optimal action distribution
is given by
q∗
m = arg max
q
min
j̸=m
∑
ui
quiD(pui
m||pui
j ) , (40)
where pui
j is the observation distribution under hypothesis
j when action ui is taken, and qui is the ith element of
q (i.e., the probability of choosing experiment ui under q).
The rationale behind (40) is a zero-sum game formulation of
the problem, and the optimal mixed strategy q∗
m leads to a
random observation that best differentiates Hm from its closest
alternative.
The action at time nunder the Chernoff test is drawn from
a distribution q∗
ˆi(n), where ˆi(n) is the ML estimate of the true
hypothesis at time n based on past actions and observations.
The stopping rule and the decision rule are the same as in
(10), (11).
The rate function of the Chernoff test ΓC under hypothesis
Hm is given by
Im(ΓC) = min
j̸=m
∑
ui
q∗ui
m D(pui
m||pui
j ), (41)
which is the increasing rate of ∆S(n) under hypothesis Hm
when the Chernoff test is employed. The rate function of the
Chernoff test under a given prior {πm}M
m=1 can be similary
obtained as in (18).
We point out that in [2], while proving Im(ΓC) equals
the optimal rate I∗
m, Chernoff did not provide an explicit
expression for I∗
m or Im(ΓC). Both were given, as in (41),
inexplicitly in terms of the optimizer q∗
m of the maximin
problem in (40). Even for the problem studied here, a special
case of that considered by Chernoff 4, solving for q∗
m numeri-
cally is computationally expensive (see a detailed analysis on
computational complexity in the next subsection). The explicit
characterization of I∗
m in (20), which equals to Im(ΓDGFi)
in (17) under the necessary and sufﬁcient condition given in
Theorem 3, is a contribution of this work.
B. Comparison in Computational Complexity
While both the Chernoff test and the DGFi policy are
asymptotically optimal, i.e., I(ΓDGFi) = I(ΓC) = I∗, they
differ drastically in computational complexity. Speciﬁcally,
the Chernoff test can be expensive to compute especially
when the number of hypotheses or the number of experiments
is large. Consider the case of a single target ( L = 1 ).
Computing the selection rule of the Chernoff test given in (40)
requires solving M minimax problems, each corresponding to
a particular value of the ML estimate ˆi(n) ∈{1,...,M }. One
efﬁcient way of solving minimax problems is through linear
programming, which takes polynomial time with respect to
the number of variables and constraints. For this problem,
the number of variables is
(M
K
)
, which can be exponential
in M in the worst case. Calculating the rate function given
in (41) requires the optimal selection distribution q∗
m for all m,
thus bears similar computational complexity. For multi-target
detection, the number of hypotheses is
(M
L
)
, further increasing
the complexity.
The only computation involved in the selection rule of DGFi
is (15), which requires M summations each with M −1
elements. As a result, the computational time is O(M2), which
is independent of K. Similarly, the computational complexity
for calculating the rate function I(ΓDGFi) is O(M2) as well.
C. Comparison in Sample Complexity
In this subsection, we compare the performance of DGFi
with that of the Chernoff test in the ﬁnite regime (i.e., when
the sample cost c is bounded away from 0).
Consider a uniform prior and exponentially distributed ob-
servations: fm ∼exp(λ(m)
f ) and gm ∼exp(λ(m)
g ). The KL
divergences can be easily computed as follows.
D(gm||fm) = log(λ(m)
g ) −log(λ(m)
f ) +
λ(m)
f
λ(m)
g
−1 ,
D(fm||gm) = log(λ(m)
f ) −log(λ(m)
g ) + λ(m)
g
λ(m)
f
−1 .
4Note that the asymptotic optimality of the Chernoff test requires the
assumption of positive KL diverence between every pair of hypotheses under
every experiment. This does not hold for the problem at hand. However, it
can be shown that the Chernoff test preserves its asymptotic optimality in this
case.
8
M
20 30 40 50 60 70 80 90 100
Detection Delay
0
100
200
300
400
500
600
DGFi policy
Chernoff test
M
20 30 40 50 60 70 80 90 100
Probability of Error
0
0.002
0.004
0.006
0.008
0.01
0.012
0.014
0.016
0.018
DGFi policy
Chernoff test
M
20 30 40 50 60 70 80 90 100
Bayes Risk
0
0.1
0.2
0.3
0.4
0.5
0.6
DGFi policy
Chernoff test
Fig. 3: Performance comparison ( K = 1 ,λ(m)
g = 9 +
m,λ(m)
f = 0.0188,c = 10−3).
Shown in Fig. 3 is the performance comparison between
DGFi policy and Chernoff test for L = 1 and K = 1 .
The ﬁgure clearly demonstrates the signiﬁcant reduction in
detection delay and Bayes risk offered by the DGFi policy
as compared with the Chernoff test. The performance gain
increases drastically as M increases. The probability of errors
for Chernoff test and DGFi policy are about the same order
as shown. A similar comparison is observed in Fig. 4 with
L = 1,K = 2. The performance comparison for a case with
multiple targets is shown in Fig. 5 with L= 2,K = 1.
Next, we provide an intuition argument for the superior
ﬁnite-time performance of DGFi. Consider a short horizon
scenario where the sampling cost c is sufﬁciently high such
that D(f||g) >−log c. This implies that each empty cell can
be distinguished from the target with, on the average, a single
probing to achieve the required accuracy as determined by
c. We can cast this as the coupon collection problem, where
each empty cell is a coupon and the goal is to collect all
M −1 coupons. Consider a special case where K = 1 and
all fi and gi are identical, i.e., fi ≡f and gi ≡g. Assume
that D(f||g) >(M−1)D(g||f). In this case, the DGFi policy
chooses, at each time, the cell with the second largest sum LLR
whereas the Chernoff test randomly and uniformly chooses a
cell from all but the one with the largest sum LLR at each
time (this can be shown by solving (40)). Since Chernoff test
chooses empty cells with equal probability, based on results
in coupon collectors problem, the expected probing time will
M
20 30 40 50 60 70 80 90 100
Detection Delay
0
50
100
150
200
250
300
350
DGFi policy
Chernoff test
M
20 30 40 50 60 70 80 90 100
Probability of Error
0
0.002
0.004
0.006
0.008
0.01
0.012
0.014
0.016
0.018
DGFi policy
Chernoff test
M
20 30 40 50 60 70 80 90 100
Bayes Risk
0
0.05
0.1
0.15
0.2
0.25
0.3
0.35
DGFi policy
Chernoff test
Fig. 4: Performance comparison ( K = 2 ,λ(m)
g = 9 +
m,λ(m)
f = 0.0188,c = 10−3).
be roughly Mlog M. The DGFi policy, on the other hand, is
deterministic and guaranteed to collect a new coupon at each
time. The expected probing time is thus M.
VII. C ONCLUSION
The problem of detecting anomalies among a large number
of heterogeneous processes was considered. A low-complexity
deterministic test was developed and shown to be asymptot-
ically optimal. Its ﬁnite-time performance and computational
complexity were shown to be superior to the classic Chernoff
test for active hypothesis testing, especially when the problem
size is large.
APPENDIX A: PROOF OF THEOREM 1
Throughout this section, we use the following notations. Let
Nj(n) ≜
n∑
t=1
1j(t) (42)
be the number of times that cell j has been observed up to
time n. Let
∆Sm,j(n) ≜ Sm(n) −Sj(n) (43)
be the difference between the observed sum of LLRs of cells
m and j. We also deﬁne
∆Sm(n) ≜ min
j̸=m
∆Sm,j(n) . (44)
9
M
20 30 40 50 60 70 80 90 100
Detection Delay
0
100
200
300
400
500
600
700
800
900
DGFi policy
Chernoff test
M
20 30 40 50 60 70 80 90 100
Probability of Error
0
0.002
0.004
0.006
0.008
0.01
0.012
DGFi policy
Chernoff test
M
20 30 40 50 60 70 80 90 100
Bayes Risk
0
0.1
0.2
0.3
0.4
0.5
0.6
0.7
0.8
0.9
DGFi policy
Chernoff test
Fig. 5: Performance comparison ( L= 2,K = 1,λ(m)
g = 9 +
m,λ(m)
f = 0.0188,c = 10−3).
As a result, we have:
∆S(n) = Sm(1)(n)(n) −Sm(2)(n)(n) = max
m
∆Sm(n) . (45)
Without loss of generality we prove the theorem under
hypothesis Hm. We deﬁne
˜ℓk(i) =



ℓk(i) −D(gk||fk) , if k= m,
ℓk(i) + D(fk||gk) , if k̸= m,
(46)
which is a zero-mean random variable under hypothesis Hm.
For the ease of presentation, we ﬁrst provide the proof for
the case of K = 1.
A. Proof for K = 1
We ﬁrst bound the error probability of DGFi as given below.
Lemma 2:If DGFi policy is used, then the error probability
is upper bounded by:
Pe ≤(M −1)c. (47)
Proof: Let αm,j = Pm(δ = j) for all j ̸= m. Thus,
αm = ∑
j̸=mαm,j. By the deﬁnition of the stopping rule
under DGFi (see (10)), accepting Hj is done when ∆Sj(n) ≥
−log cwhich implies ∆Sj,m ≥−log c. Hence, for all j ̸= m
we have:
αm,j = Pm(δ= j)
≤Pm(∆Sj,m(τ) ≥−log c)
≤cPj(∆Sj,m(τ) ≥−log c) ≤c,
(48)
where changing the measure in the second inequality follows
by the fact that ∆Sj,m(τ) ≥−log c. As a result,
αm =
∑
j̸=m
αm,j ≤(M −1)c
and (47) thus follows.
Next we show that the expected detection time of DGFi
is bounded by −log c/Im(ΓDGFi) under hypothesis Hm. To
show this, we partition the detection process into three stages,
all deﬁned by certain last passage times. The ﬁrst stage is
deﬁned by the last passage time, denoted by τ1, that the
maximum likelihood estimate is not the true hypothesis Hm.
The second stage deﬁned by a last passage time τ2, indicates
that the true hypothesis Hm can be distinguished from at least
one false hypothesis with sufﬁciently high accuracy. The third
stage deﬁned by last passage time τ3, indicates that Hm can
be distinguished from all the other M −1 hypotheses with
sufﬁcient accuracy. The formal deﬁnitions of τ1,τ2,τ3 are give
below:
τ1 ≜ min{t: ∀j ̸= m,∀n≥t,Sm(n) ≥Sj(n)}
τ2 ≜ min{t: ∃j ̸= m,∀n≥t,Sm(n) −Sj(n) ≥−log c}
τ3 ≜ min{t: ∀j ̸= m,∀n≥t,Sm(n) −Sj(n) ≥−log c}.
(49)
Here, we assume that the selection rule of DGFi policy is
implemented indeﬁnitely, which means we probe the cells
according to the selection rule of DGFi as given in (14)
indeﬁnitely, while the stopping rule is disregarded. Note that
τ1,τ2,τ3 are not stopping times since they depend on the
future.
Since τ ≤τ3 based on the stopping rule of DGFi, it sufﬁces
to show τ3 is bounded by −log c/Im(ΓDGFi) under hypothesis
Hm. Let n2 = τ2 −τ1 and n3 = τ3 −τ2. In Lemma 4
and Lemma 7, we show that τ1 and n3 are sufﬁciently
small with high probability. In Lemma 5 we show that the
probability that n2 is greater than n decays exponentially
with n when n is greater than −log c/Im(ΓDGFi). Since
n3 = τ1 + n2 + n3, the expected detection time of DGFi
is bounded by −log c/Im(ΓDGFi) under hypothesis Hm as
desired.
Lemma 3: There exist constants C >0 and γ >0 such
that for any ﬁxed 0 < q <1, under any arbitrary policy, the
following statements hold:
Pm(Sj(n) ≥Sm(n),Nj(n) ≥qn) ≤Ce−γn , (50)
and
Pm(Sj(n) ≥Sm(n),Nm(n) ≥qn) ≤Ce−γn , (51)
for m= 1,2,...,M and j ̸= m.
10
Proof: We start with proving (50). Note that
Nj(n),Nm(n) can take integer values Nj(n) =
⌈qn⌉,⌈qn⌉+ 1 ,...n, and Nm(n) = 0 ,...,n . Using the
i.i.d. property of the observations across time yield:
Pm(Sj(n) ≥Sm(n),Nj(n) ≥qn)
≤
n∑
r=⌈qn⌉
n∑
k=0
Pm
( r∑
i=1
ℓj(i) +
k∑
i=1
−ℓm(i) ≥0
)
≤
n∑
r=⌈qn⌉
n∑
k=0
[
Em
(
esℓj(1)
)]r[
Em
(
es(−ℓm(1))
)]k
(52)
where we have used the following generic Chernoff bound for
a random variable X:
P(X ≥a) ≤E[eλX]
eλa , (53)
where it is assume that the moment generating functionE[eλX]
exists locally in an interval around λ= 0. Since the moment
generating function is equal to one at s= 0 and Em(ℓj(1)) =
−D(fj||gj) < 0, Em(−ℓm(1)) = −D(gm||fm) < 0 are
strictly negative, differentiating the MGFs of ℓj(1),ℓm(1) with
respect to s yields strictly negative derivatives at s= 0. As a
result, there exist s >0 and γ1 > 0 such that Em
(
esℓj(1))
,
Em
(
es(−ℓm(1)))
are strictly less than e−γ1 <1. Hence, there
exist C >0 and γ = γ1q >0 such that
Pm(Sj(n) −Sm(n) ≥0,Nj(n) ≥qn)
≤
n∑
r=⌈qn⌉
e−γ1r
n∑
k=0
e−γ1k ≤Ce−γn . (54)
Note that (51) can be proved with minor modiﬁcations.
Lemma 4: If the selection rule of DGFi is implemented
indeﬁnitely, there exist C >0 and γ >0 such that
Pm(τ1 >n) ≤Ce−γn , (55)
for m= 1,2,...,M .
Proof: We focus on proving for M > 2. Proving for
M = 2 is straightforward. Note that the event τ1 >n implies
that there exists a time instant twith t≥nsuch that Sj(t) >
Sm(t) for some j ̸= m. Hence,
Pm(τ1 >n) ≤Pm
(
max
j̸=m
sup
t≥n
(Sj(t) −Sm(t)) ≥0
)
≤
∑
j̸=m
∞∑
t=n
Pm(Sj(t) ≥Sm(t)) .
(56)
Following (56), it sufﬁces to show that there exist C >0 and
γ >0 such that Pm(Sj(n) ≥Sm(n)) ≤Ce−γn.
We next establish the required exponential decay. Let
km = maxj̸=mD(fj||gj)
minj̸=mD(fj||gj) ,
jm = arg min
j̸=m
D(fj||gj),
ρm = 1
8(km + 1)(M −2).
(57)
Note that 0 <ρm ≤1/16. Thus, we can write
Pm(Sj(n) ≥Sm(n))
≤Pm(Sj(n) ≥Sm(n),Nj(n) <ρmn,Nm(n) <ρmn)
+Pm(Sj(n) ≥Sm(n),Nj(n) ≥ρmn)
+Pm(Sj(n) ≥Sm(n),Nm(n) ≥ρmn) .
(58)
The second and the third terms on the RHS of (58) decay
exponentially with n by Lemma 3. Thus, it remains to show
that the ﬁrst term decays exponentially with n as well. Note
that the event (Nj(n) <ρmn,Nm(n) <ρmn) implies that at
least ˜n= n−Nj(n)−Nm(n) ≥n(1 −2ρm) times cells j,m
are not probed. We deﬁne ˜Nr(n) as the number of times in
which cell r̸= j,m has been probed and cells j,m have not
been probed by time n. There exists a cell r̸= j,m such that
˜Nr(n) ≥ ˜n
M−2 = n(1−2ρm)
M−2 . Hence, we can upper bound (58)
as follows:
Pm(Sj(n) ≥Sm(n))
≤
∑
r̸=j,m
Pm
(
˜Nr(n) > n(1 −2ρm)
M −2 ,
Nj(n) <ρmn,Nm(n) <ρmn
)
+ 2De−γ1n,
(59)
where the second and third terms on the RHS of (58) are
upper bounded by De−γ1n (there exist such D >0,γ1 > 0
by Lemma 3), and the ﬁrst term on the RHS of (58) is upper
bounded by the ﬁrst term (i.e., the summation term) on the
RHS of (59). Next, we show that each term in the summation
decays exponentially with n to get the desired result.
Let ˜tr
1,˜tr
2,..., ˜tr
˜Nr(n) be the indices for the time instants in
which cell r̸= j,m has been probed and cells j,m have not
been probed by time n. Let
ζ ≜ 1 −2ρm
2(M −2). (60)
Note that the event Sj(˜tr
ζn) ≤Sr(˜tr
ζn) or Sm(˜tr
ζn) ≤Sr(˜tr
ζn)
must occur (otherwise, cell j or m will be probed). Hence 5,
Pm
(
˜Nr(n) > n(1−2ρm)
M−2 ,
Nj(n) <ρmn,Nm(n) <ρmn)
=
n−ζn∑
q=0
ρmn∑
n′=0
Pm


n′
∑
i=1
ℓj(i) ≤
ζn+q∑
i=1
ℓr(i)


+
n−ζn∑
q=0
ρmn∑
n′=0
Pm


n′
∑
i=1
ℓm(i) ≤
ζn+q∑
i=1
ℓr(i)

.
(61)
For upper bounding the ﬁrst term on the RHS of (61) we write
the sum LLRs as follows:
5For the ease of presentation, throughout the proof we assume that ζn, ρmn
are integers. This assumption does not affect the exponential decay but only
the exact value of C >0 in (55) (since αn−1 ≤⌊αn⌋≤⌈ αn⌉≤ αn+ 1
holds for all α≥0 for all n= 0,1,... ).
11
ζn+q∑
i=1
ℓr(i) +
n′
∑
i=1
−ℓj(i)
=
ζn+q∑
i=1
˜ℓr(i) +
n′
∑
i=1
˜ℓj(i)
−D(fr||gr) (ζn+ q) + D(fn′||gn′)n′
≤
ζn+q∑
i=1
˜ℓr(i) +
n′
∑
i=1
−˜ℓj(i) −D(fjm||gjm) (ζn+ q−kmn′) ,
(62)
and by the deﬁnitions of ζ,km,ρm in (57) and (60), we have
ζn+ q−kmn′≥ζn+ q−kmn′−(km + 1) (ρmn−n′)
= n(ζ−(km + 1)ρm) + q+ n′≥ 1
4(M −2)n+ q+ n′
≥ 1
4(M −2)(n+ q+ n′) ,
for all n′≤ρmn. Therefore,
ζn+q∑
i=1
ℓr(i) +
n′
∑
i=1
−ℓj(i) ≥0 (63)
implies
ζn+q∑
i=1
˜ℓr(i) +
n′
∑
i=1
−˜ℓj(i) ≥C1 (n+ q+ n′) , (64)
where
C1 =
D(fjm||gjm)
4(M −2) >0. (65)
Then we have
Pm


n′
∑
i=1
ℓj(i) ≤
ζn+q∑
i=1
ℓr(i)


≤Pm


ζn+q∑
i=1
˜ℓr(i) +
n′
∑
i=1
−˜ℓj(i) ≥C1 (n+ q+ n′)


≤
[
Em
(
es˜ℓr(1)
)]ζn+q[
Em
(
es(−˜ℓj(1))
)]n′
×e−sC1(n+q+n′)
=
[
Em
(
es(˜ℓr(1)−C1))]ζn+q[
Em
(
es(−˜ℓj(1)−C1))]n′
×e−sC1(n−ζn) .
(66)
for all s> 0.
Since Em(˜ℓr(1)−C1) = −C1 <0 and Em(−˜ℓj(1)−C1) =
−C1 <0 are strictly negative, by applying a similar argument
as at the end of the proof of Lemma 3, there exist s> 0 and
γ2 >0 such that Em
(
e(s˜ℓr(1)−C1)
)
, Em
(
es(−˜ℓj(1)−C1)
)
and
e−sC1 are strictly less than e−γ2 <1. Hence,
Pm


n′
∑
i=1
ℓj(i) ≤
ζn+q∑
i=1
ℓr(i)

≤e−γ2(n+q+n′), (67)
and
n−ζn∑
q=0
ρmn∑
n′=0
Pm


n′
∑
i=1
ℓj(i) ≤
ζn+q∑
i=1
ℓr(i)


≤e−γ2n
n−ζn∑
q=0
e−γ2q
ρmn∑
n′=0
e−γ2n′
≤C2e−γ2n ,
(68)
where C2 = (1 −e−γ2 )−2.
A similar technique can be applied to upper bound the
second term on the RHS of (61).
Lemma 5: If the selection rule of DGFi is implemented
indeﬁnitely, then for every ﬁxed ϵ> 0 there exist C >0 and
γ >0 such that
Pm(n2 >n) ≤Ce−γn ∀n> −(1 + ϵ) logc/Im(ΓDGFi) ,
(69)
for all m= 1,2,...,M .
Proof: First, we consider the case where Im(ΓDGFi) >
D(gm||fm). Note that cell mis not observed for all n≥τ1 in
this case. Deﬁne N′
j(τ1+t) = ∑τ1+t
i=τ1+1 1j(i) and j∗(τ1+t) =
arg maxjN′
j(τ1 + t)D(fj||gj). Thus,
Pm(n2 >n)
≤Pm
(
sup
t≥n
τ1+t∑
i=τ1+1
ℓj∗(τ1+t)(i)1j∗(τ1+t)(i) ≥log c
)
.
(70)
Since t is the total number of observation from τ1 to τ1 + t,
by the deﬁnition of j∗(t) we have
t=
∑
j̸=m
N′
j(τ1 + t) =
∑
j̸=m
N′
j(τ1 + t)D(fj||gj)
D(fj||gj)
≤
∑
j̸=m
N′
j∗(τ1+t)(τ1 + t)D(fj∗(τ1+t)||gj∗(τ1+t))
D(fj||gj) .
(71)
Let ϵ1 = Im(ΓDGFi)ϵ/(1 + ϵ). Since Im(ΓDGFi) =∑
j̸=m1/D(fj||gj), we have
ϵ1 = ϵ
(1 + ϵ) ∑
j̸=m1/D(fj||gj). (72)
12
Then,
τ1+t∑
i=τ1+1
ℓj∗(τ1+t)(i)1j∗(τ1+t)(i) −log c
=
τ1+t∑
i=τ1+1
˜ℓj∗(τ1+t)(i)1j∗(τ1+t)(i)
−N′
j∗(τ1+t)(τ1 + t)D(fj∗(τ1+t)||gj∗(τ1+t)) −log c
≤
τ1+t∑
i=τ1+1
˜ℓj∗(τ1+t)(i)1j∗(τ1+t)(i)
− t∑
j̸=m1/D(fj||gj) −log c
≤
τ1+t∑
i=τ1+1
˜ℓj∗(τ1+t)(i)1j∗(τ1+t)(i) −tIm(ΓDGFi)
+tIm(ΓDGFi)/(1 + ϵ)
≤
τ1+t∑
i=τ1+1
˜ℓj∗(τ1+t)(i)1j∗(τ1+t)(i) −tϵ1
(73)
for all t ≥n >−(1 + ϵ) logc/Im(ΓDGFi). By applying the
generic Chernoff bound given in (53), it can be shown that
there exists γ1 > 0 such that Pm(∑τ1+t
τ1+1 −˜ℓj∗(τ1+t)(i) ≥
tϵ1) < e−γ1t for all t ≥ n > −(1 + ϵ) logc/Im(ΓDGFi).
Hence, there exist C1 > 0 and γ1 > 0 such that Pm(n2 >
n) ≤C1e−γ1n for all n> −(1 +ϵ) logc/Im(ΓDGFi). A simi-
lar argument applies for case where Im(ΓDGFi) ≤D(gm||fm).
To show that n3 is sufﬁciently small, we deﬁne a random
variable Ψ(t) as the dynamic range between sum LLRs of
empty cells:
Ψ(t) ≜ max
j̸=m
Sj(t) −min
j̸=m
Sj(t). (74)
Note that the dynamic range at time τ2 can be viewed as
a measure of the amount of information remains to gather
in order to distinguish Hm from any other false hypothesis.
Lemma 6 below shows that the dynamic range at time τ2 is
sufﬁciently small.
Lemma 6: If the selection rule of DGFi is implemented
indeﬁnitely. Then, for every ﬁxed ϵ1 > 0,ϵ2 > 0 there exist
C >0 and γ >0 such that
Pm(Ψ(τ2) >ϵ1n) ≤Ce−γn,
∀n> −(1 + ϵ2) logc/Im(ΓDGFi)
(75)
for all m= 1,2,...,M .
Proof: Note that
Pm(Ψ(τ2) >ϵ1n)
≤Pm(τ2 >n) + Pm(Ψ(τ2) >ϵ1n,τ2 ≤n) (76)
Since τ2 = τ1 + n2, applying Lemmas 4, 5 implies that
the ﬁrst term on the RHS of (76) decreases exponentially
with n for all n > −(1 + ϵ2) logc/Im(ΓDGFi) for every
ﬁxed ϵ2 > 0. It remains to show that the second term
on the RHS of (76) decreases exponentially with n. Let
¯j = arg max j̸=mSj(τ2),j = arg min j̸=mSj(τ2). Let
t0 be the smallest integer such that Sj(t) ≤ S¯j(t) for all
t0 <t ≤τ2. As a result, Ψ(τ2) >ϵ1n implies
τ2∑
t=t0
ℓ¯j(t)1¯j(t) −
τ2∑
t=t0
ℓj(t)1j(t) >ϵ1n.
Note that the second term on the RHS of (76) can be rewritten
as:
Pm(Ψ(τ2) >ϵ1n,τ2 ≤n)
= Pm(Ψ(τ2) >ϵ1n,τ2 ≤n,t0 ≥τ1)
+Pm(Ψ(τ2) >ϵ1n,τ2 ≤n,t0 <τ1)
(77)
First, we upper bound the ﬁrst term on the RHS of (77).
Note that for all τ1 ≤t0 <t ≤τ2, we have 1j(t) = 0. Hence,
τ2∑
t=t0
ℓ¯j(t)1¯j(t) −
τ2∑
t=t0
ℓj(t)1j(t) =
τ2∑
t=t0
ℓ¯j(t)1¯j(t)
=
τ2∑
t=t0
˜ℓ¯j(t)1¯j(t) −D(f¯j||g¯j) ≤
τ2∑
t=t0
˜ℓ¯j(t)1¯j(t)
(78)
Then, applying the generic Chernoff bound given in (53)
completes the proof for this case.
Next, we upper bound the second term on the RHS of (77).
Let ϵ3 ≜ ϵ1
4 maxj D(fi||gi) >0. Note that
Pm(Ψ(τ2) >ϵ1n,τ2 ≤n,t0 <τ1)
≤Pm(τ1 >ϵ3n)
+Pm(Ψ(τ2) >ϵ1n,τ2 ≤n,t0 <τ1,τ1 ≤ϵ3n) .
(79)
The ﬁrst term on the RHS of (79) decreases exponen-
tially with n by Lemma 4. Thus, it remains to show
that the second term on the RHS of (79) decreases ex-
ponentially with n. Note that Ψ(τ2) > ϵ 1n implies∑τ1
t=t0 ℓ¯j1¯j(t) + ∑τ2
t=τ1+1 ℓ¯j1¯j(t) >ϵ1n. Therefore, the
second term on the RHS of (79) can be rewritten as:
Pm(Ψ(τ2) >ϵ1n,τ2 ≤n,t0 <τ1,τ1 ≤ϵ3n)
≤Pm
( τ1∑
t=t0
ℓ¯j(t)1¯j(t) > ϵ1n
2 ,τ2 ≤n,t0 <τ1,τ1 ≤ϵ3n
)
+Pm
( τ2∑
t=τ1+1
ℓ¯j(t)1¯j(t) > ϵ1n
2 ,τ2 ≤n,t0 <τ1,τ1 ≤ϵ3n
)
(80)
The second term on the RHS of (80) decreases exponentially
with n using a similar argument as in (78). Next, it remains
to show that the ﬁrst term on the RHS of (80) decreases
exponentially with n. Note that
τ1∑
t=t0
ℓ¯j(t)1¯j(t) −
τ1∑
t=t0
ℓj(t)1j(t)
≤
τ1∑
t=t0
˜ℓ¯j(t)1¯j(t) −
τ1∑
t=t0
˜ℓj(t)1j(t) + max
j
D(fj||gj)τ1
≤
τ1∑
t=t0
[
˜ℓ¯j(t)1¯j(t) −˜ℓj(t)1j(t)
]
+ ϵ1
4 n
(81)
13
for all τ1 ≤ϵ3n.
As a result,
τ1∑
t=t0
ℓ¯j(t)1¯j(t) −ℓj(t)1j(t) > ϵ1
2 n (82)
implies
τ1∑
t=t0
[
˜ℓ¯j(t)1¯j(t) −˜ℓj(t)1j(t)
]
> ϵ1
4 n (83)
for all τ1 ≤ϵ3n. Applying the generic Chernoff bound given
in (53), we arrive at the lemma.
Lemma 7: If the selection rule of DGFi is implemented
indeﬁnitely, then for every ﬁxed ϵ> 0 there exist C >0 and
γ >0 such that
Pm(n3 >n) ≤Ce−γn ∀n> −ϵlog c/Im(ΓDGFi) , (84)
for all m= 1,2,...,M .
Proof: To prove the Lemma, we ﬁrst deﬁne τj
3 ≜ max{t:
∀n≥t,Sm(n)−Sj(n) ≥−log c}and Nj
3 as the total number
of observations that the decision maker collected from cell j
between τ2 and τj
3 . Since n3 ≤∑
jNj
3 and τ3 = maxjτj
3 ,
we only need to show that Pm(Nj
3 >n) decays exponentially
with n. We can write Pm(Nj
3 >n) as follows:
Pm(Nj
3 >n) ≤Pm
(
Ψ(τ2) >n minjD(fj||gj)
2
)
+Pm
(
Nj
3 >n|Ψ(τ2) ≤nminjD(fj||gj)
2
) (85)
Lemma 6 provides the desired decay for the ﬁrst term on the
RHS. We next show the desired decay for the second term.
Let t1,t2,... denote the time indices when cell j is observed
between τ2 and τj
3 . We can write:
Pm
(
Nj
3 >n|Ψ(τ2) ≤nminjD(fj||gj)
2
)
≤Pm
(
inf
r>n
r∑
i=1
−ℓj(ti) <n minjD(fj||gj)
2
)
≤Pm
( r∑
i=1
˜ℓj(ti) >r minjD(fj||gj)
2
)
.
(86)
Using the i.i.d. property of ˜ℓj(ti) yields:
Pm
( n∑
i=1
˜ℓj(ti) >n minjD(fj||gj)
2
)
<C3e−γn (87)
for some C3,γ3 which completes the proof.
The following Lemma provides an upper bound on the
detection time when DGFi policy is implemented.
Lemma 8:If DGFi policy is implemented, then the expected
detection time τ is upper bounded by:
Em(τ) ≤−(1 + o(1)) log(c)
Im(ΓDGFi) , (88)
for m= 1,...,M .
Proof: Since the actual detection time under DGFi is
upper bounded by: τ ≤ τ3 = τ1 + n2 + n3, combining
Lemmas 4, 5 and 7 proves the statement.
Combining Lemma 2 and Lemma 8, Theorem 1 follows for
the case of K = 1.
B. Proof for K >1
We focus on the case where Fm(K) > D(gm||fm) +
Fm(K −1). The case where the inequality is reversed can
be proven with minor modiﬁcations.
We consider the balanced case and the unbalanced case
separately. For the balanced case, the proof in Subsection A
directly applies. For the unbalanced case, the proof has to
be constructed differently. This is because in the unbalanced
case, there is a process with a sufﬁciently small information
acquisition rate D(fj||gj) such that it becomes the bottleneck
of the detection process and determines the asymptotic in-
creasing rate of ∆S(n). Directly bounding the dynamic range
of all sum LLR trajectories is no longer tractable. Instead,
the proof is built upon the analysis of the trajectory of the
sum LLR with the smallest expected increment. In particular,
we recognize that the key in handling the imbalance in the
information acquisition rates among empty cells is to deﬁne
a last passage time as the last time at which the empty cell
with the smallest D(fj||gj) is not probed and then analyze,
separately, the detection process before and after this last
passage time.
The proof proceeds as follows. First, by directly applying
Lemma 2, the error probability under DGFi is O(c). Then, we
show that the expected detection time of DGFi is bounded.
Similar to the case of K = 1 , we partition the detection
process into three stages with minor modiﬁcations. The ﬁrst
and the third stage are deﬁned by the same last passage times
τ1 and τ3 given in (49). The second stage, however, is deﬁned
differently by ˜τ2, indicates that the sum LLR of the cell with
the smallest KL divergence is smaller than −log c. By directly
applying Lemmas 3 and 4, we show that τ1 is sufﬁciently small
with high probability.
Then, we prove the following Lemmas to show that τ3
is bounded by −log(c)
Im(ΓDGFi) . Lemma 9 states that the largest
observed sum LLR among the empty cells is sufﬁciently
large as required with high probability. Lemma 10 states that
the smallest observed sum LLR among the empty cells is
sufﬁciently small as required with high probability. Lemma 11
shows the difference between the (K+ 1)th largest sum LLR
and the Mth largest sum LLR is sufﬁciently small as required
with high probability. Lemma 12 states that the sum LLR of
the cell with the smallest KL divergence is sufﬁciently small
(which will determine the rate function function for the search
in this case) with high probability. Lemma 13 shows that the
sum LLR of other cells are smaller than that of the cell with the
smallest KL divergence at time when t> ˜τ2. Finally, Lemma
14 upper bounds the last passage time τ3.
Deﬁne
U(n) ≜ min
j̸=m
Sj(n), L(n) ≜ max
j̸=m
Sj(n), (89)
14
Ψj2
j1 (n) ≜ Sm(j2)(n)(n) −Sm(j1)(n)(n), (90)
j(t) ≜ arg min
j̸=m
Nj(t)D(fj||gj), (91)
¯j(t) ≜ arg max
j̸=m
Nj(t)D(fj||gj), (92)
j′= arg min
j̸=m
D(fj||gj). (93)
Lemma 9: For any selection rule, ∀t,∀ϵ >0, there exist
C,γ >0 such that
Pm(L(t) <−tK¯Fm −nϵ) <Ce −γn ∀n>t. (94)
Proof: Note that
Pm(L(t) <−tK¯Fm −nϵ) ≤P(Sj(t)(t) <−tK¯Fm −nϵ),
(95)
and
Sj(t)(t) = −Nj(t)(t)D(fj(t)||gj(t)) +
t∑
i=1
˜lj(t)(i)1j(t)(i).
(96)
Since Kt is the total number of observations by time t, by the
deﬁnition of j(t) we have
Kt =
∑
j
Nj(t) =
∑
j
Nj(t)D(fj||gj)
D(fj||gj)
≥
∑
j
Nj(t)(t)D(fj(t)||gj(t))
D(fj||gj) .
(97)
Hence,
Nj(t)(t)D(fj(t)||gj(t)) ≤Kt· 1∑
j1/D(fj||gj) = t·K¯Fm.
(98)
Therefore,
Sj(t)(t) <−tK¯Fm −nϵ (99)
implies
t∑
i=1
˜lj(t)(i)1j(t)(i) <−nϵ. (100)
Then, applying the generic Chernoff bound completes the
proof.
Lemma 10:For any selection rule, ∀t,∀ϵ, there exist C,γ >
0 such that
Pm(U(t) >−tK¯Fm + nϵ) <Ce −γn ∀n>t. (101)
Proof: The proof follows similarly with Lemma 9.
Lemma 11: If DGFi policy is implemented, ∀t,∀ϵ, there
exist C,γ >0 such that
Pm(ΨK+1
M (t) >max
j̸=m
D(fj||gj) + nϵ) <Ce −γn ∀n>t.
(102)
Proof: We prove by induction with respect to t. When t=
1, using the generic Chernoff bound completes the induction
base. If the statement is true for t−1, then for t we have
Pm(ΨK+1
M (t) >max
j̸=m
D(fj||gj) + nϵ)
= Pm(ΨK+1
M (t) >maxj̸=mD(fj||gj) + nϵ,
m(M)(t) = m(M)(t−1))
+Pm(ΨK+1
M (t) >maxj̸=mD(fj||gj) + nϵ,
m(M)(t) ̸= m(M)(t−1)).
(103)
For the ﬁrst term on the RHS, we have
Pm(ΨK+1
M (t) >max
j̸=m
D(fj||gj) + nϵ,
m(M)(t) = m(M)(t−1))
≤Pm(ΨK+1
M (t−1) >max
j̸=m
D(fj||gj) + nϵ
2 ,
m(M)(t) = m(M)(t−1) or lm(K+1)(t−1)(t) <−nϵ
2 ,
m(M)(t) = m(M)(t−1))
≤Pm(ΨK+1
M (t−1) >max
j̸=m
D(fj||gj) + nϵ
2 )
+Pm(lm(K+1)(t−1)(t) <−nϵ
2 )
≤C1e−γ1n,
(104)
where the ﬁrst term can be bounded using assumptions on
t−1 and the second term can be bounded using the generic
Chernoff bound.
For the second term on the RHS of (103), we have
Pm(ΨK+1
M (t) >max
j̸=m
D(fj||gj) + nϵ,r(M)(t) ̸= r(M)(t−1))
≤Pm(lm(M)(t)(t) >max
j̸=m
D(fj||gj) + nϵ)
≤Pm(˜lm(M)(t)(t) >nϵ) <C2e−γ2n.
(105)
Combining (103), (104), (105) completes the proof.
Lemma 12: If DGFi policy is implemented, ∀t > τ1,∀ϵ,
there exist C,γ >0 such that
Pm(Sj′(t) −Sj′(τ1) >−(t−τ1)D(fj′||gj′) + nϵ) <Ce −γn
∀n>t.
(106)
Proof: Deﬁne t0 as the smallest integer such that cell j′
is observed at time ifor all t0 <i ≤t. Then, by our selection
rule, cell j′ is the one of the top K sum LLRs at time t0.
Then, by applying t= t0 to Lemma 11 we have
Pm(U(t0) −Sj′(t0) <−nϵ) <C1e−γ1n ∀n>t 0, (107)
for some C1,γ1. Substituting t= t0 in Lemma 10 we have:
Pm(U(t0) >−t0K¯Fm + nϵ) <C2e−γ2n ∀n>t 0, (108)
for some C2,γ2. Hence,
Pm(Sj′(t0) >−t0K¯Fm+nϵ) <C3e−γ3n ∀n>t 0, (109)
15
for some C3,γ3. Then, by the deﬁnition of t0 and using the
generic Chernoff bound we have
Pm(Sj′(t) −Sj′(t0) >−(t−t0)D(fj′||gj′) + nϵ)
<C4e−γ4n ∀n> (t−t0).
(110)
Since K¯Fm >D(fj′||gj′), we have:
Pm(Sj′(t) −Sj′(τ1) >−(t−τ1)D(fj′||gj′) + nϵ)
<C5e−γ5n ∀n>t
(111)
as desired.
Deﬁne ˜τ2 = τ1 + −log c
D(fj′||gj′) . Next we show that the sum
LLRs of other cells are smaller than cell j′ at time ˜τ2.
Lemma 13: For every ﬁxed ϵ >0, there exists C >0 and
γ >0, such that for all j we have:
Pm(Sj′(˜τ2) −Sj(˜τ2) <−ϵn) ≤Ce−γn, ∀n> ˜τ2. (112)
Proof: For ﬁxed j, deﬁne tj
0 as the smallest integer
such that Sj′(n) < Sj(n) for all tj
0 < i ≤ ˜τ2. By def-
inition, Sj′(tj
0) ≥ Sj(tj
0). Then, by our selection rule, for
all tj
0 < i≤ ˜τ2, whenever cell j′ is observed, cell j must
be observed based on their ranking of sum LLRs. Note that
D(fj′||gj′) ≤D(fj||gj). Thus,
˜τ2∑
i=tj
0
lj(i)1j(i) −
˜τ2∑
i=tj
0
lj′(i)1j′(i)
=
˜τ2∑
i=tj
0
˜lj(i)1j(i) −
˜τ2∑
i=tj
0
˜lj′(i)1j′(i)
+D(fj||gj)
˜τ2∑
i=tj
0
1j(i) −D(fj′||gj′)
˜τ2∑
i=tj
0
1j′(i)
≥
˜τ2∑
i=tj
0
˜lj(i)1j(i) −
˜τ2∑
i=tj
0
˜lj′(i)1j′(i),
(113)
which indicates that the LHS has positive means. By applying
the generic Chernoff bound and using the i.i.d. property of
˜lj(ti) we have:
Pm(Sj′(˜τ2) −Sj′(tj
0) −(Sj(˜τ2) −Sj(tj
0)) <−ϵn) ≤Ce−γn,
(114)
for some C,γ. Since Sj′(tj
0) ≥Sj(tj
0), we have:
Pm(Sj′(˜τ2) −Sj(˜τ2) <−ϵn)
≤Pm(Sj′(˜τ2) −Sj′(tj
0) −(Sj(˜τ2) −Sj(tj
0)) <−ϵn)
≤Ce−γn, ∀n> ˜τ2
(115)
as desired.
Let ˜n3 ≜ τ3 −˜τ2 denotes the total amount of time between
˜τ2 and τ3.
Lemma 14: For every ﬁxed ϵ >0, there exists C >0 and
γ >0 such that
Pm(˜n3 >n) <Ce −γn, ∀n> −ϵlog c/D(fj′||gj′).
(116)
Proof: By substituting t= ˜τ2 in Lemma 12 we have:
Pm(Sj′(˜τ2) >log c+ nϵ) <C1e−γ1n ∀n> ˜τ2 (117)
for some C1,γ1. By applying Lemma 13, we have:
Pm(Sj(˜τ2) >log c+ nϵ) <C2e−γ2n
∀n> ˜τ2,j = 1,2,··· ,m
(118)
for some C2,γ2 >0.
Let ˜Nj
3 denote that total number of observations, taken from
cell j between ˜τ2 and τj
3 . Since ˜n3 ≤∑ ˜Nj
3 , it sufﬁces to
show that P( ˜Nj
3 >n) decays exponentially with n. Note that
Pm( ˜Nj
3 >n)
≤Pm
(
Sj(˜τ2) >log c+ nD(fj′||gj′)
2
)
+Pm
(
˜Nj
3 >n|Sj(˜τ2) ≤log c+ nD(fj′||gj′)
2
)
.
(119)
By (118) it remains to show that the second term decays
exponentially with n. Let t1,t2,··· denote the time indices
when cell j is observed between ˜τ2 and τj
3 . Then,
Pm( ˜Nj
3 >n|Sj(˜τ2) ≤log c+ nD(fj′||gj′)
2 )
≤Pm
(
inf
r>n
r∑
i=1
lj(ti) <n D(fj′||gj′)
2
)
≤Pm
( r∑
i=1
˜lj(ti) >r D(fj′||gj′)
2
)
.
Applying the generic Chernoff bound and using the i.i.d.
property of ˜lj(ti) across time we have
Pm
( r∑
i=1
˜lj(ti) >r D(fj′||gj′)
2
)
<C3e−γn (120)
for some C3,γ3 which completes the proof.
The following Lemma provides an upper bound on the
detection time for the unbalanced case.
Lemma 15: If DGFi policy is implemented, for the unbal-
anced case, the expected detection time τ is upper bounded
by:
Em(τ) ≤−(1 + o(1)) log(c)
Im(ΓDGFi) , (121)
for m= 1,...,M .
Proof: Since the actual detection time under DGFi is
upper bounded by: τ ≤τ3 = ˜τ2 + ˜n3 = τ1 + −log(c)
Im(ΓDGFi) + ˜n3,
combining Lemmas 4 and 14 proves the statement.
Combining Lemma 2 and Lemma 15, Theorem 1 follows
for the case of K >1.
APPENDIX B: P ROOF OF THEOREM 2
First we show that in order to achieve a small order of Bayes
Risk, ∆Sm(τ) deﬁned in (44) need to be sufﬁcient large.
16
Lemma 16: Assume that αj(Γ) = O(−clog c) for all j =
1,...,M . Let 0 <ϵ< 1. Then:
Pm(∆Sm(τ) <−(1 −ϵ) logc|Γ) = O(−cϵlog c) , (122)
for all m= 1,...,M .
Proof: Note that:
Pm(∆Sm(τ) <−(1 −ϵ) logc|Γ)
= Pm(∆Sm(τ) <−(1 −ϵ) logc, δ = m|Γ)
+Pm(∆Sm(τ) <−(1 −ϵ) logc, δ ̸= m|Γ)
≤Pm(∆Sm(τ) <−(1 −ϵ) logc, δ = m|Γ) + αm(Γ),
(123)
where αm(Γ) = O(−clog c) by assumption. In what follows,
we upper bound
Pm(∆Sm(τ) <−(1 −ϵ) logc, δ = m|Γ) .
Similar to [2, Lemma 4] we can show that for all j ̸= m
there exists G> 0 such that:
−Gclog c≥Pj(δ̸= j|Γ) ≥Pj(δ= m|Γ)
≥Pj(∆Sm,j(τ) ≤−(1 −ϵ) logc, δ = m|Γ)
≥c1−ϵPm(∆Sm,j(τ) <−(1 −ϵ) logc, δ = m|Γ) ,
(124)
where the last inequality holds by changing the measure as in
[2, Lemma 4]. Thus,
Pm(∆Sm,j(τ) <−(1 −ϵ) logc, δ = m|Γ)
= O(−cϵlog c) ∀j ̸= m. (125)
As a result,
Pm(∆Sm(τ) <−(1 −ϵ) logc, δ = m|Γ)
≤
∑
j̸=m
Pm(∆Sm,j(τ) <−(1 −ϵ) logc, δ = m|Γ)
= O(−cϵlog c) .
(126)
Finally,
Pm(∆Sm(τ) <−(1 −ϵ) logc|Γ) = O(−cϵlog c) .
(127)
Lemma 17: Assume that
D(gm||fm) ≥ 1∑
j̸=m
1
D(fj||gj)
. (128)
Then, the function:
d(t) ≜ t
[
D(gm||fm) +
n
t −1∑
j̸=m
1
D(fj||gj)
]
(129)
is monotonically increasing with t for 0 ≤t≤n.
Proof: Differentiation d(t) with respect to t yields:
∂d(t)
∂t = D(gm||fm) − 1∑
j̸=m
1
D(fj||gj)
≥0 ,
which completes the proof.
For the next lemma we deﬁne
j∗(t) ≜ arg min
j̸=m
Nj(t)D(fj||gj), (130)
and
W∗
m(t) ≜
t∑
i=1
˜ℓm(i)1m(i) −
t∑
i=1
˜ℓj∗(t)(i)1j∗(t)(i), (131)
which is a sum of zero-mean random variable
Lemma 18: For every ﬁxed ϵ >0 there exist C >0 and
γ >0 such that
Pm
(
max
1≤t≤n
W∗
m(t) ≥nϵ|Γ
)
≤Ce−γn (132)
for all m= 1,...,M and for any policy Γ.
Proof: We upper bound (132) by summing over any
possible values that Nm(t),Nj∗(t)(t) can take and using the
generic Chernoff bound given in (53):
Pm
(
max
1≤t≤n
W∗
m(t) ≥nϵ|Γ
)
=
n∑
t=1
t∑
i=0
t∑
j=0
Pm
( t∑
r=1
˜ℓm(r)1m(r)
+
t∑
r=1
−˜ℓj∗(t)(r)1j∗(t)(r) ≥nϵ,Nm(t) = i,Nj∗(t) = j|Γ
)
≤
n∑
t=1
t∑
i=0
t∑
j=0
[
Em
(
es(˜ℓm(1)−ϵ/2)
)]i
×
[
Em
(
es(−˜ℓj∗(t)(1)−ϵ/2)
)]j
×exp
{
−sϵ
2(2n−i−j)
}
,
(133)
for all s> 0.
Since Em(˜ℓm(1) −ϵ/2) = −ϵ/2 <0 and Em(−˜ℓj∗(t)(1) −
ϵ/2) = −ϵ/2 < 0 are strictly negative, using a similar
argument as at the end of the proof of Lemma 3, there
exist s > 0 and γ′ > 0 such that Em
(
es(˜ℓm(1)−ϵ/2)
)
,
Em
(
es(−˜ℓj∗(t)(1)−ϵ/2)
)
and e−sϵ/2 are strictly less than
e−γ′
< 1. Since 2n−i−j ≥ 0, there exist C > 0 and
γ >0, such that summing over t,i,j yields (132).
Lemma 19: For any ﬁxed ϵ> 0,
Pm
(
max
1≤t≤n
∆Sm(t) ≥n(I∗
m + ϵ) |Γ
)
→0 as n→∞ ,
(134)
for all m= 1,...,M and for any policy Γ.
Proof: We next show exponential decay of (134) (which
is stronger than the polynomial decay shown under the binary
composite hypothesis testing case in [2, Lemma 5]). Let
∆S∗
m(t) ≜ Sm(t) −Sj∗(t)(t).
17
Note that ∆Sm(t) ≤∆S∗
m(t) for all m and t. As a result,
Pm
(
max
1≤t≤n
∆Sm(t) ≥n(I∗
m + ϵ) |Γ
)
≤Pm
(
max
1≤t≤n
∆S∗
m(t) ≥n(I∗
m + ϵ) |Γ
)
.
(135)
We next prove the lemma for the case where I∗
m = Fm(K)
and u∗
m = 0. Proving the lemma for the cases where u∗
m >0
applies with minor modiﬁcations.
Note that:
∆S∗
m(t) = W∗
m(t) + Nm(t)D(gm||fm)
+Nj∗(t)(t)D(fj∗(t)||gj∗(t))
≤W∗
m(t) + Nm(t) · 1∑
j̸=m1/D(fj||gj)
+Nj∗(t)(t)D(fj∗(t)||gj∗(t)).
(136)
Since that j∗(t) = arg min j̸=mNj(t)D(fj||gj) and Kt −
Nm(t) is the total number of observations taken from M−1
cells j ̸= m, we have:
∑
j̸=m
Nj∗(t)D(fj∗(t)||gj∗(t))
D(fj||gj) ≤Kt−Nm(t) ≤Kn−Nm(t).
(137)
Hence,
∆S∗
m(t) ≤W∗
m(t) + Kn 1∑
j̸=m1/D(fj||gj)
= W∗
m(t) + nI∗
m .
(138)
Therefore,
∆S∗
m(t) ≥n(I∗
m + ϵ)
implies
W∗
m(t) ≥nϵ.
By Lemma 18 we have:
Pm
(
max
1≤t≤n
∆Sm(t) ≥n(I∗
m + ϵ)
)
≤Pm
(
max
1≤t≤n
W∗
m(t) ≥nϵ
)
≤Ce−γn →0 as n→∞.
(139)
Finally, we show that the Bayes risk cannot be made smaller
than −clog(c)
I∗m
:
Lemma 20:Any policy Γ that satisﬁes Rj(Γ) = O(−clog c)
for all j = 1,...,M must satisfy:
Rm(Γ) ≥−(1 + o(1)) clog(c)
I∗m
. (140)
for all m= 1,...,M .
Proof: For any ϵ> 0 let nc = −(1−ϵ) log c
I∗m + ϵ. Note that
Pm(τ ≤nc |Γ)
= Pm(τ ≤nc , ∆Sm(τ) ≥−(1 −ϵ) logc|Γ)
+Pm(τ ≤nc , ∆Sm(τ) <−(1 −ϵ) logc|Γ)
≤Pm
(
max
t≤nc
∆Sm(t) ≥−(1 −ϵ) logc|Γ
)
+Pm(∆Sm(τ) <−(1 −ϵ) logc|Γ) .
(141)
Both terms on the RHS approaches zero as c → 0 by
Lemmas 16, 19. Hence,
Em(τ|Γ) ≥
∞∑
n=nc+1
nPm(τ = n|Γ)
≥ncPm(τ ≥nc + 1|Γ) →nc as c→0
(142)
Since ϵ > 0 is arbitrarily small we have Em(τ|Γ) ≥
−(1 + o(1)) log(c)/I∗
m. As a result, Rm(Γ) ≥cEm(τ|Γ) ≥
−(1 + o(1)) clog(c)/I∗
m.
APPENDIX C: PROOF OF LEMMA 1
Deﬁne
hm(u) = uD(gm||fm) + Fm(K−u). (143)
By taking the derivative of hm(u), we have
h′
m(u) = D(gm||fm) −F′
m(K−u), (144)
where
F′
m(v) =



1∑
j̸=m
1
D(fj||gj)
, if v≤ ˜Km
0, if v >˜Km.
(145)
Since F′
m(v) is piecewise constant with a breakpoint ˜Km,
h′
m(u) is piecewise constant with a breakpoint K − ˜Km.
Therefore,
1) If D(gm||fm) ≥ ¯Fm, then h′
m(u) >0 and u∗
m = 1.
2) If K > ˜Km + 1, then h′
m(u) = D(fj||gj) > 0 is a
positive constant and u∗
m = 1
3) If D(gm||fm) < ¯Fm and K < ˜Km then h′
m(u) =
D(gm||fm) < ¯Fm <0 is a negative constant and u∗
m = 0
4) If none of the above is true, then h′
m(u) > 0 for u <
K− ˜Km and h′
m(u) > 0 for u < K− ˜Km. Therefore,
u∗
m = K−˜Km
APPENDIX D: PROOF OF THEOREM 4
We now focus on proving asymptotic optimality for L> 1,
and K = 1. For L >1, we deﬁne τ1 as the smallest integer
such that Sm(n) >Sj(n) for all m∈D, j ̸= D and n≥τ1.
Note that when K = 1 and n≥τ1 the decision maker always
probe the consistent cell (target or not depending on the order
of ¯GD and ¯FD) for making the difference between the Lth
and (L+ 1)th largest sum LLRs greater than the threshold
−log c. As a result, the decision maker can always balance
18
the detection time so that the difference between the largest
sum LLR and the sum LLRs of any other cell exceeds the
threshold −log c approximately at the same time as c →0.
Thus, proving the asymptotic optimality of DGFi for L >1
and K = 1 follows similar arguments as in the balanced case
in the proof of Theorem 1 given in Appendix B, and we focus
here only on the key modiﬁcations. Let
∆SD(n) ≜ min
m∈D,j/∈D
∆Sm,j(n), (146)
where ∆Sm,j(n) is deﬁned in (43). Without loss of generality
we prove the theorem when set Dcontains all the targets. We
deﬁne
˜ℓk(i) =



ℓk(i) −D(gk||fk) , if k∈D,
ℓk(i) + D(fk||gk) , if k /∈D,
(147)
which is a zero-mean random variable.
We start by showing the upper bound on the Bayes risk
obtained by DGFi. Similar to Lemma 2, we can show that
the error probability under DGFi is O(c). Speciﬁcally, we can
show that the error probability is upper bounded by:
Pe ≤(M −L)L·c. (148)
We can show this by letting αD= PD(δ̸= D) and αD,j =
PD(j ∈ δ) for all j /∈ D, where the subscript D denotes
the measure when set D contains all the targets. Thus, αD≤∑
j/∈DαD,j. By the stopping rule, accepting j ∈δ implies
∆Sj,m ≥−log c for some m∈D. Hence, for all j /∈D we
have:
αD,j = PD(j ∈D)
≤∑
m∈DPD(∆Sj,m(τ) ≥−log c)
≤
∑
m∈D
cPD∪j\m(∆Sj,m(τ) ≥−log c) ≤L·c,
(149)
where we changed the measure in the second inequality. As a
result,
αD≤
∑
j/∈D
αD,j ≤(M −L)L·c,
which yields (148).
Here we consider the case where ID= ¯GD, the case ID=
¯FD applies with minor modiﬁcations. For showing that τ1 is
sufﬁciently small we need to show ﬁrst the following Lemmas:
Lemma 21:For all j /∈D, ∀0 <q <1, there exist C,γ >0
such that
PD(Nj(n) >qn) <Ce −γn (150)
Proof: For each j, deﬁne tj(n) as the time when cell j
is observed for the nth time. By DGFi selection rule, if cell
j is observed at time t, then there exists m ∈D such that
Sj(t) ≥Sm(t). Hence,
PD(Nj(n) >qn)
≤
n∑
t=1
PD(Nj(t) >qn, ∃m∈D : Sj(t) >Sm(t))
×PD(tj(⌈qn⌉) = t).
(151)
It sufﬁces to show that there exist constants C,γ such that
PD(Nj(t) >qn, ∃m∈D : Sj(t) >Sm(t)) ≤Ce−γn (152)
for all t≤n.
First we have
PD(Nj(t) >qn, ∃m∈D : Sj(t) >Sm(t))
≤
∑
m∈D
PD(Nj(t) >qn,S j(t) >Sm(t)). (153)
Fix m, then we have
PD(Nj(t) >qn,S j(t) >Sm(t))
≤
n∑
r=⌈qn⌉
n∑
k=0
PD
( n∑
i=1
ℓj(i) +
k∑
k=1
−ℓm(i) ≥0
)
≤Cme−γmn.
(154)
The last inequality can be shown using the generic Chernoff
bound given in (53).
To show (152), we let C = ∑
mCm,γ = minmγm, which
completes the proof.
Lemma 22: For all m∈D, and ϵ> 0, there exist C,γ >0
such that
PD
(
Nm(n) >
¯GD
D(gm||fm) −ϵ ·n
)
≤Ce−γn (155)
Proof: For each m, deﬁne tm(n) as the time when cell
mis observed for the nth time. By DGFi selection rule, if cell
m is observed at time t, either there exists j /∈D such that
Sj(n) >Sm(n) or Sm′(n) >Sm(n) for all m′∈D. Similar
to (151), it sufﬁces to show that
PD
(
Nm(t) >
¯GD
D(gm||fm)−ϵ ·n,∃j /∈D : Sj(t) >Sm(t)
)
≤Ce−γn
(156)
and
PD
(
Nm(t) >
¯GD
D(gm||fm)−ϵ ·n,∀m′∈D : Sm′(t) >Sm(t)
)
≤Ce−γn
(157)
for all t<n .
Since (156) can be shown similarly as in (152), it remains to
show (157). By the deﬁnition of ¯GD, if Nm(t) >
¯GD
D(gm||fm)−ϵ·
n, there exists m′ ∈ D and ϵ′ > 0 such that Nm′(t) <
¯GD
D(g′m||f′m)+ϵ′ ·t. Hence,
PD
(
Nm(t) >
¯GD
D(gm||fm) −ϵ ·n,∀m′∈D:
Sm′(t) >Sm(t)
)
≤
∑
m′∈D
PD
(
Nm(t) >
¯GD
D(gm||fm) −ϵ ·n,Sm′(t) >Sm(t),
N′
m(t) <
¯GD
D(g′m||f′m) + ϵ′·t
)
.
(158)
19
Fix m′, and let s1 =
¯GD
D(gm||fm)−ϵ, s2 =
¯GD
D(gm′||fm′)+ϵ.
Then, we have
PD
(
Nm(t) >
¯GD
D(gm||fm) −ϵ ·n,Sm′(t) >Sm(t)
,N′
m(t) <
¯GD
D(gm′||fm′) + ϵ′·t
)
≤
n∑
r=⌈s1n⌉
⌊s2t⌋∑
k=0
PD
( r∑
i=1
−ℓm(i) +
k∑
i=1
ℓm′(i) ≥0
)
≤
n∑
r=⌈s1n⌉
⌊s2t⌋∑
k=0
PD
( r∑
i=1
D(gm||fm) −ϵ−ℓm(i)
+
k∑
i=1
ℓm′(i) −D(gm′||fm′) −ϵ′≥0
)
≤
n∑
r=⌈s1n⌉
⌊s2t⌋∑
k=0
[
ED
(
es(−˜ℓm(1)−ϵ)
)]r[
ED
(
es(ℓm′(1)−ϵ′)
)]k
≤Cm′e−γm′n
(159)
The last inequality can be shown using the generic Cher-
noff bound given in (53). To show (158), we let C =∑
m′Cm′,γ = minm′γm′, which completes the proof.
Lemma 23: For all m ∈D, ∀ϵ >0, there exist C,γ > 0
such that
PD
(
Nm(n) <(
¯GD
2D(gm||fm))n
)
≤Ce−γn. (160)
Proof: By choosing qj and ϵ′
m in Lemma 21 and
Lemma 22 such that ∑
jqj+ ∑′
mϵ′
m = ¯¯GD
2D(gm||fm) , we have
PD
(
Nm(n) <(
¯GD
2D(gm||fm))n
)
≤
∑
j/∈D
PD(Nj(n) >qjn)
+
∑
m′∈D
PD
(
N′
m(n) >(
¯GD
D(g′m||f′m) + ϵ′
m)n
)
≤Cm′e−γn
(161)
as desired.
Next, similar to Lemma 4, we can show that the probability
that τ1 is greater than n decreases exponentially with n. This
result is used when evaluating the asymptotic expected search
time to show that it is not affected by τ1. We can show this
by noting that
PD(τ1 >n) ≤PD
(
max
j/∈D,m∈D
sup
t≥n
(Sj(t) −Sm(t)) ≥0
)
≤
∑
j/∈D,m∈D
∞∑
t=n
PD(Sj(t) ≥Sm(t)) .
(162)
Following (162), it sufﬁces to show that PD(Sj(n) ≥Sm(n))
decays exponentially with n. Note that
PD(Sj(n) ≥Sm(n))
≤PD
(
Sj(n) ≥Sm(n),Nm(n) ≥(
¯GD
2D(gm||fm))n
)
+PD
(
Nm(n) <(
¯GD
2D(gm||fm))n
)
(163)
The ﬁrst term decays exponentially with nby Lemma 3 (with
minor modiﬁcations). The second term decays exponentially
with n by Lemma 23.
Note that we obtained that the expectation of τ1 is bounded,
and we can use similar arguments as in the balanced case of
Theorem 1 in Appendix B to obtain the detection rate ID
for n ≥τ1. Combining these results yields that the expected
detection time τ under the DGFi policy is upper bounded by:
ED(τ) ≤−(1 + o(1)) log(c)
ID
, (164)
for m= 1,...,M .
Finally, showing that the asymptotic Bayes risk is lower
bounded by −clog c/I∗
L follows a similar outline as in Ap-
pendix B. Speciﬁcally, similar to Lemma 16, if αD(Γ) =
O(−clog c) for all D, and we let 0 <ϵ< 1, then:
PD(∆Sm(τ) <−(1 −ϵ) logc|Γ) = O(−cϵlog c) , (165)
for all Dand m∈D. Then, we deﬁne:
j∗(t) ≜ arg min
j/∈D
Nj(t)D(fj||gj), (166)
m∗(t) ≜ arg min
m∈D
Nm∗(t)(t)D(gm||fm), (167)
and
W∗
D(t) ≜
t∑
i=1
˜ℓm∗(t)(i)1m∗(t)(i) −
t∑
i=1
˜ℓj∗(t)(i)1j∗(t)(i),
(168)
where W∗
D(t) is a sum of zero-mean random variable. Using
these deﬁnitions, similar to Lemma 18, we can show that for
every ﬁxed ϵ> 0 there exist C >0 and γ >0 such that
PD
(
max
1≤t≤n
W∗
D(t) ≥nϵ|Γ
)
≤Ce−γn (169)
for all Dand for any policy Γ.
Next, similar to Lemma 19 we can show that for any ﬁxed
ϵ> 0,
PD
(
max
1≤t≤n
∆SD(t) ≥n(ID+ ϵ) |Γ
)
→0
as n→∞ ,
(170)
for all Dand for any policy Γ.
Finally, similar to Lemma 20, we can show that any policy
Γ that satisﬁes RD(Γ) = O(−clog c) for all Dmust satisfy:
RD(Γ) ≥−(1 + o(1)) clog(c)
ID
. (171)
for all D.
20
REFERENCES
[1] Q. Zhao and B. M. Sadler, “A survey of dynamic spectrum access,”
IEEE signal processing magazine, vol. 24, no. 3, pp. 79–89, 2007.
[2] H. Chernoff, “Sequential design of experiments,” The Annals of Math-
ematical Statistics, vol. 30, no. 3, pp. 755–770, 1959.
[3] A. Wald, “Sequential analysis. 1947,” Zbl0029, vol. 15805, 1947.
[4] S. A. Bessler, “Theory and applications of the sequential design of
experiments, k-actions and inﬁnitely many experiments. part i. theory,”
tech. rep., DTIC Document, 1960.
[5] S. Nitinawarat, G. K. Atia, and V . V . Veeravalli, “Controlled sensing
for hypothesis testing,” in 2012 IEEE International Conference on
Acoustics, Speech and Signal Processing (ICASSP), pp. 5277–5280,
IEEE, 2012.
[6] S. Nitinawarat, G. K. Atia, and V . V . Veeravalli, “Controlled sensing
for multihypothesis testing,” IEEE Transactions on Automatic Control,
vol. 58, no. 10, pp. 2451–2464, 2013.
[7] S. Nitinawarat and V . V . Veeravalli, “Controlled sensing for sequential
multihypothesis testing with controlled markovian observations and non-
uniform control cost,” Sequential Analysis, vol. 34, no. 1, pp. 1–24,
2015.
[8] M. Naghshvar and T. Javidi, “Active sequential hypothesis testing,” The
Annals of Statistics, vol. 41, no. 6, pp. 2703–2738, 2013.
[9] M. Naghshvar and T. Javidi, “Sequentiality and adaptivity gains in
active hypothesis testing,” IEEE Journal of Selected Topics in Signal
Processing, vol. 7, no. 5, pp. 768–782, 2013.
[10] D. A. Castanon, “Optimal search strategies in dynamic hypothesis
testing,” IEEE transactions on systems, man, and cybernetics, vol. 25,
no. 7, pp. 1130–1138, 1995.
[11] K. Cohen, Q. Zhao, and A. Swami, “Optimal index policies for anomaly
localization in resource-constrained cyber systems,” IEEE Transactions
on Signal Processing, vol. 62, no. 16, pp. 4224–4236, 2014.
[12] N. K. Vaidhiyan and R. Sundaresan, “Learning to detect an oddball
target,” arXiv preprint arXiv:1508.05572, 2015.
[13] K. Leahy and M. Schwager, “Always choose second best: Tracking
a moving target on a graph with a noisy binary sensor,” in Control
Conference (ECC), 2016 European, pp. 1715–1721, IEEE, 2016.
[14] J. Heydari, A. Tajer, and H. V . Poor, “Quickest linear search over cor-
related sequences,” IEEE Transactions on Information Theory, vol. 62,
no. 10, pp. 5786–5808, 2016.
[15] K. Cohen and Q. Zhao, “Active hypothesis testing for anomaly de-
tection,” IEEE Transactions on Information Theory, vol. 61, no. 3,
pp. 1432–1450, 2015.
[16] K. S. Zigangirov, “On a problem in optimal scanning,” Theory of
Probability & Its Applications, vol. 11, no. 2, pp. 294–298, 1966.
[17] A. Tajer and H. V . Poor, “Quick search for rare events,” IEEE Transac-
tions on Information Theory, vol. 59, no. 7, pp. 4462–4481, 2013.
[18] K. Cohen and Q. Zhao, “Asymptotically optimal anomaly detection via
sequential testing,” IEEE Transactions on Signal Processing, vol. 63,
no. 11, pp. 2929–2941, 2015.
[19] G. Fellouris, G. V . Moustakides, and V . V . Veeravalli, “Multistream
quickest change detection: Asymptotic optimality under a sparse signal,”
in Acoustics, Speech and Signal Processing (ICASSP), 2017 IEEE
International Conference on, pp. 6444–6447, IEEE, 2017.
[20] L. Lai, H. V . Poor, Y . Xin, and G. Georgiadis, “Quickest search over
multiple sequences,” IEEE Transactions on Information Theory, vol. 57,
no. 8, pp. 5375–5386, 2011.
[21] S. Nitinawarat and V . V . Veeravalli, “Universal scheme for optimal
search and stop,” in Information Theory and Applications Workshop
(ITA), 2015, pp. 322–328, IEEE, 2015.
[22] B. Hemo, K. Cohen, and Q. Zhao, “Asymptotically optimal search of
unknown anomalies,” in Proc. of the 16th IEEE Symposium on Signal
Processing and Information Technology (ISSPIT), (Limassol, Cyprus),
Dec. 2016.
[23] M. L. Malloy, G. Tang, and R. D. Nowak, “Quickest search for a rare
distribution,” in Information Sciences and Systems (CISS), 2012 46th
Annual Conference on, pp. 1–6, IEEE, 2012.
[24] Y . Pei, Y .-C. Liang, K. C. Teh, and K. H. Li, “Energy-efﬁcient design of
sequential channel sensing in cognitive radio networks: optimal sensing
strategy, power allocation, and sensing order,” IEEE Journal on Selected
Areas in Communications, vol. 29, no. 8, pp. 1648–1659, 2011.
[25] R. Caromi, Y . Xin, and L. Lai, “Fast multiband spectrum scanning
for cognitive radio systems,” IEEE Transactions on Communications,
vol. 61, no. 1, pp. 63–75, 2013.
[26] L. Ferrari, Q. Zhao, and A. Scaglione, “Utility maximizing sequential
sensing over a ﬁnite horizon,” IEEE Transactions on Signal Processing,
vol. 65, no. 13, pp. 3430–3445, 2017.
[27] M. Egan, J.-M. Gorce, and L. Cardoso, “Fast initialization of cognitive
radio systems,” in IEEE International Workshop on Signal Processing
Advances in Wireless Communications, 2017.
[28] A. Tajer, V . V . Veeravalli, and H. V . Poor, “Outlying sequence detection
in large data sets: A data-driven approach,” IEEE Signal Processing
Magazine, vol. 31, no. 5, pp. 44–56, 2014.
[29] V . Chandola, A. Banerjee, and V . Kumar, “Anomaly detection: A survey,”
ACM computing surveys (CSUR), vol. 41, no. 3, p. 15, 2009.
[30] M. H. Bhuyan, D. K. Bhattacharyya, and J. K. Kalita, “Network anomaly
detection: methods, systems and tools,” IEEE Communications Surveys
& Tutorials, vol. 16, no. 1, pp. 303–336, 2014.
[31] B. Huang, K. Cohen, and Q. Zhao, “Sequential active detec-
tion of anomalies in heterogeneous processes,” arXiv preprint
arXiv:1704.00766, 2017.