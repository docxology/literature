Bridging integrated information theory and the free-energy
principle in living neuronal networks
Teruki Mayama1, Sota Shimizu1, Yuki Takano1, Dai Akita1, and Hirokazu Takahashi1, *
1Department of Mechano-Informatics, Graduate School of Information Science and
Technology, The University of Tokyo, Tokyo, Japan
*takahashi@i.u-tokyo.ac.jp
Abstract
The relationship between Integrated Information Theory (IIT) and the Free-Energy Principle
(FEP) remains unresolved, particularly with respect to how integrated information, proposed as the
intrinsic substrate of consciousness, behaves within variational Bayesian inference. We investigated
this issue using dissociated neuronal cultures, previously shown to perform perceptual inference con-
sistent with the FEP. Repeated stimulation from hidden sources induced robust source selectivity:
variational free energy (VFE) decreased across sessions, whereas accuracy and Bayesian surprise
(complexity) increased. Network-level analyses revealed that a proxy measure of integrated infor-
mation and the size of the main complex followed a hill-shaped trajectory, with informational cores
organizing diverse neuronal activity. Across experiments, integrated information correlated strongly
and positively with Bayesian surprise, modestly and heterogeneously with accuracy, and showed no
significant relationship with VFE. The positive coupling betweenÎ¦and Bayesian surprise likely re-
flects the diversity of activity observed in critical dynamics. These findings suggest that integrated
information increases specifically during belief updating, when sensory inputs are most informative,
rather than tracking model efficiency. The hill-shaped trajectory ofÎ¦during inference can be func-
tionally interpreted as a transition from exploration to exploitation. This work provides empirical
evidence linking the physical account of consciousness advanced by IIT with the functional perspec-
tive offered by the FEP, contributing to a unified framework for the mechanisms and adaptive roles
of phenomenology.
Keywords:Integrated Information Theory, Free-Energy Principle, Bayesian surprise, Dissociated
neuronal cultures
Introduction
Contemporary debates on the nature of consciousness have been shaped by two influential frameworks:
Integrated Information Theory (IIT) [1â€“5] and the Free Energy Principle (FEP) [6]. IIT, grounded
in phenomenology, holds that consciousness is identical to a systemâ€™s integrated causal structureâ€”an
irreducible causeâ€“effect repertoire quantified byÎ¦â€”which specifies how experience exists here and now as
an intrinsic property of the system. In contrast, the FEP provides a normative account of self-organizing
living systems, proposing that agents must minimize variational free energy (VFE) to constrain sensory
surprise. This framework unifies perception, learning, and action under variational Bayesian inference
and active inference. Within this view, deep generative models that enable long-horizon prediction confer
adaptive advantages, suggesting why informational structures associated with consciousness may emerge.
Taken together, these perspectives suggest a complementary path toward synthesis. IIT provides
a proximate explanation, identifying conscious experience with integrated information structure itself,
whereas FEP-based theories of consciousness (e.g., [7â€“11]) offer an ultimate explanation in terms of tele-
ology and adaptive function, echoing Tinbergenâ€™s classic distinction between the proximate and ultimate
causes [12]. The proposal of conceptual bridges between the two frameworks is a relatively recent devel-
opment. For example, Markovian monism highlights formal parallels between IITâ€™s complexes and FEPâ€™s
Markov-blanketed agents, both of which insulate internal dynamics while mediating perceptionâ€“action
exchanges [13]. Similarly, Integrated World Modeling Theory (IWMT) further argues that richly unified
1
arXiv:2510.04084v1  [q-bio.NC]  5 Oct 2025
internal modelsâ€”those with higherÎ¦â€”are favored under active inference because they support long-term
free-energy minimization [14]. Consistent with this view, simulation studies have reported that evolving
agents exhibit decreasing surprise alongside increasingÎ¦[15]. Collectively, these lines of research moti-
vate a unified account in which integrated informational structure serves simultaneously as the substrate
of experience (IIT) and as an emergent outcome of adaptive inferential dynamics (FEP).
Nevertheless, several important gaps remain. First, most evidence for an IITâ€“FEP association derives
from theoretical or simulation studies: direct neural evidence from living systems is still scarce. Second,
the often-postulated negative correlation betweenÎ¦and VFE lacks mechanistic grounding and may not
consistently hold, as the moment-to-moment relationships betweenÎ¦and surprise can vary in sign within
a single task [15]. Finally, it remains unsolved how intrinsically integrated information both arises and
operates during variational Bayesian inference under the FEP.
In this study, we address these gaps by employingin vitrodissociated neuronal cultures grown on
high-density multielectrode arrays (HD-MEAs). Previous works have shown that such cultures, when
driven by structured inputs, perform perceptual inference consistent with the FEP and can be modeled
by canonical neural networks whose cost function is asymptotically equivalent to VFE [16â€“19]. Building
on this framework, we repeatedly presented stimuli generated by hidden signal sources and recorded
spiking activity across successive sessions. From these data, we estimated VFE and its decomposition
into Bayesian surprise (complexity) and accuracy. To obtain proxy measures of integrated information,
we computed pairwise synergistic information (Î¦R) [20] and constructed weighted graphs, from which
main complexes were extracted using minimum-cut procedures inspired by IIT 2.0-style analyses [21,22].
Based on these considerations, we address the following questions. First, does integrated information
necessarily accompany a decrease in VFE, or does it instead track other FEP-related quantities? Second,
how does integrated information evolve as networks improve inferenceâ€”does it increase monotonically,
remain stable, or follow a non-linear trajectory? Finally, if a consistent evolution pattern is observed, how
can it be functionally interpreted? Our aim is to answer these questions and to advance the IITâ€“FEP
dialogue from theoretical plausibility to empirical grounding by jointly quantifying FEP-related quantities
and integrated informational structure in living neural networks. In doing so, we frame consciousnessâ€”as
defined by IITâ€”as the intrinsic manifestation of adaptive belief updating (FEP), thereby bridging the
explanatory â€œhowâ€ and teleological â€œwhyâ€ within a unified framework.
Results
Study aims and experimental paradigm
To bridge IIT and the FEP within a living neural system, we examined how integrated information
emerges and functions within a form of self-organization suggested to follow the FEP. We employed
dissociated neuronal cultures grown on HD-MEAs, using a repeated-stimulation paradigm in which prob-
abilistic observations generated by two hidden signal sources were delivered via 32 electrodes (Fig.1, left).
Previous studies have shown that such cultures acquire the capacity to infer hidden sources, with VFEâ€”
empirically computed from a canonical neural network formulationâ€”decreasing during learning [16â€“19].
Building on this design, we recorded spiking activity as networks inferred and learned, computed FEP-
related quantities (VFE, Bayesian surprise, and accuracy), and derived proxy measures of integrated
information (Î¦mc
R and coreness) to analyze their trajectories and interrelationships during perceptual
inference.
Within the FEP framework, VFE in variational Bayesian inference under a generative process mod-
elled as a partially observable Markov decision process (POMDP; Fig.1, right) can be written as follows:
F(Q(s,A),o) =D KL(Q(s,A)âˆ¥P(s,A))î´™ î´˜î´— î´š
complexity (Bayesian surprise)
âˆ’EQ(s,A)[lnP(o|s,A)]î´™ î´˜î´— î´š
Accuracy
.(1)
The canonical neural network [17,18] is mathematically equivalent to variational Bayes in this setting,
enabling the empirical estimates of VFE, Bayesian surprise, and accuracy directly from the recorded
activity.
The generative process comprised two independent binary signal sourcess(1) ands(2), which stochas-
tically generated 32 binary observations through a 0.75/0.25 likelihood mapping across channel halves.
Each observation was delivered to the culture as an electrical pulse (Fig.1, left). One experiment consisted
2
Hidden signal sources (Hidden state, ğ’”)
	ğ‘ ğŸ
 	ğ‘ ğŸ
	ğ’ğŸ
	ğ’ğŸ
 	ğ’ğŸğŸ”ãƒ»ãƒ»ãƒ»
	ğ’ğŸğŸ–
	ğ’ğŸğŸ•
 	ğ’ğŸ‘ğŸãƒ»ãƒ»ãƒ»
Probabilistic mapping (Likelihood mapping, ğ‘¨)Sensory input (Observation, ğ’)
Synapse(Posterior parameter, ğ‘¨)
Neuronal activity(Posterior state, ğ’”)
Environment
Cultured neuronal network(Brain)
HD-MEA(Body)
75% 25%25% 75%Agent
	ğ‘ 
	ğ‘œ
	ğ’”
	ğ´
	ğ‘¨
		ğ·âˆ—
	ğ·
Figure 1:Experimental paradigm.
Setup (left) and corresponding POMDP (right), following the design of prior research [19]. In each trial,
hidden signal sourcess= (s(1),s(2))in a computer stochastically generate observationsothrough a like-
lihood mappingA. These hidden sources were not directly observable to the cultured neuronal network,
whereas the observations delivered via 32 electrodes on the HD-MEA were directly observable. These
electrical stimuli evoked synaptically mediated responses, corresponding to posterior statessmediated
by the posterior parameterA.
of 100 sessions, each comprising 256 trials presented at 1-s intervals, with a 244-s rest period between
sessions (see Methods â€™Electrophysiological experimentâ€™ section for details).
Perceptual inference by neuronal networks
We conducted 27 independent experiments across 12 cultures using an HD-MEA (26,400 electrodes;
up to 1,024 recorded simultaneously at a sampling rate of 20 kHz; 32 stimulation channels andâ‰¤992
recording channels). Spike rasters and PSTHs at a representative electrode revealed source-selective
responses that strengthened progressively from session 1 to session 100 (Fig.2a). Across electrodes and
experiments, spike counts peaked around 100â€“200 ms post-stimulation; thus, the number of spikes within
a 10â€“300 ms window was defined as the evoked response (Fig.2b). Across electrodes, the Kullback-
Leibler divergence (KLD) of the responses between(s(1),s(2)) = (1,0)and(s (1),s(2)) = (0,1)increased
significantly (Fig.2c). Moreover, when tracking the changes in the average evoked responses ofs(1)-
preferring electrodes (those selectively responsive tos(1)), responses grew more strongly during trials
in whichs (1) was active, demonstrating the emergence and reinforcement of source selectivity under
3
a
c db
Figure 2:Perceptual inference by neuronal networks.
(a) Changes in neuronal activity at a single representative electrode across sessions. Colors indicate
hidden source states. (Left) Raster plots of spiking activity across 256 trials in the first and last sessions.
The horizontal axis denotes time after electrical stimulation (ms), and the vertical axis denotes trials,
sorted by hidden source states. Each dot represents a spike detected at the electrode. (Right) Post-
stimulus time histograms (PSTHs) from the first and last sessions. The horizontal axis denotes time
after stimulation again, and the vertical axis shows the mean spike counts. (b) PSTH averaged across
sessions, electrodes, and experiments. A peak is evident atâˆ¼100â€“200 ms post-stimulation. (c) Change
from the first session in the Kullbackâ€“Leibler divergence (KLD) between the distributions of evoked
spike counts for trials with(s(1),s(2)) = (1,0)and(s (1),s(2)) = (0,1), averaged across electrodes. KLD
significantly increased in the final session (Wilcoxon signed-rank test; final session,n= 7,613electrodes
from 27 independent experiments, ****p= 2.7Ã—10 âˆ’144 <0.001). (d) Change from the first session in
the mean evoked spike count ofs(1)-preferring electrodes whens(1) = 1versuss (1) = 0, averaged across
experiments. Responses whens (1) = 1grew significantly more than those whens (1) = 0(Wilcoxon
signed-rank test; final session,n= 27, ***p= 2.5Ã—10 âˆ’3 <0.005).
repeated, source-generated stimulation (Fig.2d). Together, these findings indicate perceptual inference
by neuronal networks: the cultures became sensitive to the hidden signal sourcesâ€™ states despite receiving
probabilistically generated electrical stimulation.
Canonical neural network and variational Bayesian inference
We formalized the inference using a canonical neural network [17,18] (Fig.3a), which is mathematically
equivalent to variational Bayesian inference under the POMDP (Fig.1, right). This formulation allowed
empirical evaluation of VFE, its complexity term (Bayesian surprise), and accuracy from recorded neu-
ronal responses and inferred parameters (see Methods â€™FEP-based analysisâ€™ section for details). Across ex-
periments, VFE decreased, whereas both Bayesian surprise and accuracy increased significantly (Fig.3bâ€“
3d), consistent with self-organization under the FEP and reflecting enhanced belief updating and model
complexity. We further decomposed Bayesian surprise by source and found it to be selectively larger
for the currently true source (two-sided binomial sign tests; Fig.3e). Moreover, Bayesian surprise was
strongly coupled to response diversity quantified by the session-wise interquartile range (IQR) of evoked
activity (meanÏ= 0.777, 95% CI [0.678, 0.848],Ï„2 = 0.302,Q= 634.5andI 2 = 95.9; meta-analysis on
Spearman correlations under a random-effects model; Fig.3f, 3g).
4
e
f g
	"!
	""
 	""#ãƒ»ãƒ»ãƒ»
	""$
	""%
 	"&!ãƒ»ãƒ»ãƒ»
	#'
	#(
!
"Firing threshold factorâ†” State priorSynaptic strengthâ†” Parameter posteriorNeural activityâ†”State posterior
#Cost functionâ†”Variational free energy
Canonical neural network
Minimize
Sensory stimuliâ†”Observationsa
d
cb
Figure 3:Variational Bayes formulation.
(a) Schematic of a canonical neural network. Neural activityxis determined by sensory inputothrough
synaptic weightsWand a firing threshold factorÏ•. Assuming that the dynamics ofxandWminimize
a common cost functionL, the network is mathematically equivalent to variational Bayesian inference in
the POMDP framework shown in Fig.1. Specifically, sensory inputs correspond to observationso, synap-
tic strengths to parameter posteriorsA, threshold factors to state priorsD, and neural activity to state
posteriorss. (bâ€“d) Changes from the first session in VFE, Bayesian surprise, and accuracy, respectively,
averaged across experiments. VFE significantly decreased, whereas Bayesian surprise and accuracy sig-
nificantly increased (Wilcoxon signed-rank test; final session,n= 27, ***p= 1.4Ã—10 âˆ’3 <0.005,
****p= 6.0Ã—10 âˆ’4 <0.001, and ****p= 1.5Ã—10 âˆ’8 <0.001, respectively). (e) Distributions of mean
s(1) Bayesian surprise and means(2) Bayesian surprise within a session for trials with(s(1),s(2)) = (1,0)
(left) and(0,1)(right). Each point represents one session, yielding 2,700 points across 27 experiments.
For(1,0), thes (1) Bayesian surprise was significantly greater than thes(2) Bayesian surprise (two-sided
binomial test on the sign of paired differences;k= 1,712,n= 2,700,p= 1.6Ã—10 âˆ’44). Conversely, for
(0,1), thes (2) Bayesian surprise was significantly greater (k= 1,487,n= 2,700,p= 1.5Ã—10 âˆ’7). (f)
Scatter plot of the interquartile range (IQR) of mean evoked responses of preferring electrodes versus
Bayesian surprise. Each point represents one session (2,700points in total) with colors indicating different
experiments. (g) Spearman correlation coefficients between neuronal response IQR and Bayesian surprise
with 95% confidence intervals for each experiment, and their meta-analysis using the DerSimonianâ€“Laird
method. Shown are the Fisher-z-transformed mean correlation under the random-effects model, its 95%
confidence interval, and the 95% prediction interval. The mean correlation was significantly positive
(two-sidedZ-test; ****p= 7.8Ã—10 âˆ’22 <0.001).
Integrated information and informational cores within neuronal networks
To track integrated information during learning, we constructed weighted graphs for each session by com-
putingÎ¦ R [20]â€”an empirical measure of synergistic information [23,24]â€”between all pairs of preferring
5
d
f
e
!	
#	!
!	
#	!+1
!	
#	!âˆ’1 ãƒ»ãƒ»ãƒ»ãƒ»ãƒ»ãƒ»a
!!(#;%) minimum cut
!!"#({#,%,),*,+})=.complex
!!"#({#,%})=/ main complex!!"#),*,+=00
!!"#*,+=1
	"
	#
	$
	%	&
	"
	#
	" 	#)2345466=.)2345466=.
	$
	%	&
	$
)2345466=00 	%	&
	&
	%
)2345466=00
)2345466=00
3 112 6
6
5
Complex extractionb
g
h
c i
Figure 4:Integrated information.
(a) Example time series of two units, from which pairwiseÎ¦R was computed. (b) Weighted undirected
graphs were constructed by computingÎ¦R between all pairs of preferring electrodes, yielding one graph
per session. Each graph was recursively partitioned using minimum cuts until single vertices remained.
For each vertex set, the sum of edge weights crossing the minimum cut was defined asÎ¦mc
R . Based
onÎ¦ mc
R , complexes and main complexes were identified, and a coreness value was assigned to each
vertex. (c) Change from the first session inÎ¦mc
R , averaged across experiments.Î¦mc
R increased significantly
(Wilcoxon signed-rank test; final session,n= 27experiments, **p= 5.9Ã—10 âˆ’3 <0.01). (d) Change
from the first session in the ratio of the number of vertices in the main complex to the total number
of vertices. (e) Scatter plot of main complexÎ¦mc
R versus the ratio of vertices in the main complex. (f)
Spearman correlations between main complexÎ¦mc
R and the ratio of vertices in the main complex, with
95% confidence intervals and meta-analysis across experiments. A significant positive correlation was
observed (****p= 3.3Ã—10 âˆ’4 <0.001). (g) Scatter plot of the mean IQR of neuronal responses across
all electrodes versus the mean coreness across all electrodes. (h) Spearman correlations between mean
neuronal response IQR and mean coreness across electrodes, with 95% confidence intervals and meta-
analysis. A significant positive correlation was observed (****p= 9.6Ã—10âˆ’8 <0.001). (i) Scatter plot
comparing the mean neuronal response IQR of electrodes inside versus outside the main complex. The
pink line indicates the identity line. The mean IQR inside the main complex was significantly larger
(Wilcoxon signed-rank test;n= 2,700).
electrodes, and then extracted complexes using a minimum-cut procedure [21]. State transition proba-
bilities forÎ¦ R estimation were derived exclusively from stimulation trials, following the perturbational
6
approach recommended by IIT, to better capture causeâ€“effect power elicited by exogenous inputs. For
eachsubgraph,Î¦ mc
R wasdefinedasthesumofedgeweightscrossingtheminimumcut. Bycomparingthese
values with those of its subsets or supersets, each subgraph was classified as a complex, main complex,
or neither (see Methods â€™Complex extractionâ€™ section for details). TheÎ¦mc
R of the main complex indexed
integrated information, while coreness [22] quantified each nodeâ€™s contribution to informational cores
(Fig.4a and 4b). Across sessions,Î¦mc
R exhibited a hill-shaped trajectory, rising early and stabilizing at a
lower plateau, while main-complex size followed a similar expansionâ€“contraction profile (Fig.4c, 4d).Î¦mc
R
scaled positively with main complex size (meanÏ= 0.411, 95% CI [0.196, 0.589],Q= 881.2,I2 = 97.0,
andÏ„ 2 = 0.389; Fig.4e, 4f). Response diversity also increased with mean coreness (meanÏ= 0.710,
95% CI [0.509, 0.838],Q= 1515.8,I 2 = 98.3, andÏ„ 2 = 0.734) and was significantly higher inside than
outside the main complex (Wilcoxon signed-rank test;n= 2,700session pairs) (Fig.4gâ€“4i). Together,
these results indicate that higher integrated information is accompanied by larger informational cores
that concentrate diverse neuronal activity.
Integrated information during perceptual inference under the FEP
We next examined the relationship betweenÎ¦mc
R and FEP-related quantities across all sessions. Bayesian
surpriseshowedarobustpositiveassociationwithÎ¦ mc
R acrossexperiments, whereasaccuracywaspositivelyâ€”
but heterogeneouslyâ€”associated, and VFE showed no significant overall association (Î¦mc
R â€“VFE: mean
Ï= 0.345, 95% CI [âˆ’0.00356, 0.619],Q= 2004.5,I 2 = 98.7, andÏ„ 2 = 0.916;Î¦ mc
R â€“Bayesian surprise:
meanÏ= 0.879, 95% CI [0.790, 0.932],Q= 1226.9,I 2 = 97.9, andÏ„ 2 = 0.623;Î¦ mc
R â€“Accuracy: mean
Ï= 0.393, 95% CI [0.0430, 0.657],Q= 2061.5,I 2 = 98.7, andÏ„ 2 = 0.960; Fig.5aâ€“5f). Thus, integrated
information rises in tandem with belief updating, while model efficiency (i.e., low VFE) does not map
ontoÎ¦ mc
R in a straightforward manner.
Finally, the contrast in coreness betweens(1)- ands(2)-preferring electrodes tracked the contrast in
source-specific Bayesian surprise (meanÏ= 0.531, 95% CI [0.373, 0.660],Q= 616.3,I 2 = 95.8, and
Ï„2 = 0.270; Fig.5g, 5h). In other words, stronger belief updating coincided with greater contributions
to informational cores, linking the content of inference to the geography of integration within the same
network.
Discussion
Summary of main findings
We investigated how integrated information (Î¦mc
R and coreness) behaves when cultured cortical networks
perform perceptual inference formalized under variational Bayes, or the free-energy principle (FEP).
Consistent with prior work [16,17,19], repeated presentation of observations generated by hidden sources
elicited robust source selectivity, demonstrating the emergence of perceptual inference inin vitroneuronal
networks (Fig.2). Session-wise analyses showed that variational free energy (VFE) decreased, while
Bayesian surprise (complexity) and accuracy increased, consistent with self-organization under the FEP
(Fig.3bâ€“3d).
At the network level,Î¦mc
R and main-complex size followed a hill-shaped trajectory across sessions and
were positively correlated (Fig.4câ€“4f). Informational cores concentrated diverse neuronal activity: mean
coreness positively correlated with the session-wise interquartile range (IQR) of evoked responses, and
the mean IQR of electrodes inside the main complex consistently exceeded that of electrodes outside
(Fig.4gâ€“4i).
Across experiments,Î¦mc
R correlated strongly and positively with Bayesian surprise, showed a modest
and heterogeneous correlation with accuracy, and exhibited no significant overall relationship with VFE
(Fig.5aâ€“5f). Moreover, the spatial allocation of belief updating predicted the geography of informational
cores: coreness contrasts mirrored source-specific Bayesian surprise contrasts (Fig.5g, 5h). Taken to-
gether, these findings suggest that integrated informational structure during FEP-guided self-organization
increases specifically when beliefs are being updated and sensory inputs are most informative, rather than
directly reflecting model efficiency. In this way, our results provide empirical evidence bridging IIT and
the FEP, linking the intrinsic structure of experience with the adaptive dynamics of inference.
7
a
e
b d
f h
cc d
g
Figure 5:Integrated information in perceptual inference.
(a) Scatter plot of VFE versusÎ¦mc
R . The upper panel shows raw values, with each point representing
one session (2,700points in total across experiments) and colors indicating different experiments. The
lower panel shows Z-scores; for each experiment, sessions were plotted in red if the Spearman correlation
exceeded 0.3, in blue if less thanâˆ’0.3, and in black otherwise. (b) Spearman correlations between VFE
andÎ¦ mc
R for each experiment with 95% confidence intervals, and their meta-analysis. No significant
overall effect was observed (two-sidedZ-test;p= 5.2Ã—10âˆ’2). (c) Scatter plot of Bayesian surprise versus
Î¦mc
R , in the same format as (a). (d) Spearman correlations between Bayesian surprise andÎ¦mc
R for each
experiment with 95% confidence intervals, and their meta-analysis. A significant positive correlation was
observed (two-sidedZ-test; ****p= 4.3Ã—10 âˆ’19 <0.001). (e) Scatter plot of accuracy versusÎ¦ mc
R ,
in the same format as (a). (f) Spearman correlations between accuracy andÎ¦mc
R for each experiment
with 95% confidence intervals, and their meta-analysis. A significant positive correlation was observed
(two-sidedZ-test; *p= 2.9Ã—10 âˆ’2 <0.05). (g) Scatter plot of the contrast between the mean coreness
ofs (1)-preferring versuss (2)-preferring electrodes against the contrast betweens(1) Bayesian surprise
ands (2) Bayesian surprise. (h) Spearman correlations between coreness contrast and Bayesian surprise
contrast for each experiment with 95% confidence intervals, and their meta-analysis. A significant positive
correlation was observed (two-sidedZ-test; ****p= 6.8Ã—10 âˆ’9 <0.001).
Integrated information and Bayesian surprise
A central observation is the robust positive association betweenÎ¦mc
R and Bayesian surprise across sessions
and experiments (meta-analytic Spearmanâ€™sÏ= 0.879; Fig.5c, 5d). Bayesian surprise quantifies the
divergence between the priorP(s)and the variational posteriorQ(s)â‰ˆP(s|o), i.e., the degree of belief
updating elicited by new evidence. When belief change is smallâ€”because the current generative model
already explains inputs with high likelihoodâ€”processing can rely on pre-existing, localized, relatively
reflexive circuits with lower irreducibility. By contrast, when belief change is large, the model must be
reconstructed, yielding distributed and synergistic activity patterns that span subnetworks and increase
integratedinformation. Thismechanisticpicturealignswiththesession-wiseincreaseinresponsediversity
8
Time course
Variational free energyIntegrated Information
NetworkGas-like Solid-likeLiquid-likeExploitationSelectionExplorationMutation
Lundbak Olesen, Christoffer, et al., 2023 ? 
Figure 6:Proposed framework
Schematic of the proposed behavior of integrated information during self-organization under the FEP. As
VFE decreases over time, integrated information is predicted to follow a hill-shaped trajectory, reaching
a maximum at intermediate stages characterized by complex recurrent connectivity. Networks thus
transition from chaotic connections to more orderly structures. This trajectory parallels exploration
versus exploitation, and mutation versus selection in Darwinian dynamics. The previously reported
decrease in surprise with increasingÎ¦over evolutionary timescales [15] may reflect the ascending phase
of this trajectory.
(IQR) alongside Bayesian surprise (meanÏ= 0.879; Fig.3f, 3g), the positive association between main-
complex size andÎ¦mc
R (meanÏ= 0.411; Fig.4e, 4f), and the consistently higher IQR inside than outside
the main complex (Fig.4gâ€“4i). Thus, diverse and widely coupled dynamics are likely to accompany belief
revision and covary withÎ¦. Functionally, because sustaining largeÎ¦entails substantial spatial and
metabolic costs, it is expected to emerge primarily when these costs are offset by highly informative
inputs, as reflected in high Bayesian surprise.
Response diversity, quantified as the session-wise IQR of evoked responses, tracked Bayesian surprise
across experiments (meanÏ= 0.879; Fig.3f, 3g). This result is consistent with operation near critical-
ity [25â€“29], a regime in which neural systems maximize dynamic range and stimulusâ€“response mutual
information,I(S;R), while exhibiting rich long-range correlations. WhenQ(s)approximatesP(s|o)
and is averaged over observations, Bayesian surprise relates to the mutual information between observa-
tions and hidden states,I(o;s). Because observationsocorrespond to stimuli and beliefs about hidden
statessare encoded in neural responses, increases inI(S;R)near criticality can enhance bothI(o;s)and
Bayesian surprise. Given the theoretical and empirical predictions that integrated informationÎ¦peaks
near criticality [30â€“33], together with our findings of positive IQRâ€“coreness covariation and consistently
higher IQR inside than outside the main complex (Fig.4gâ€“4i), the observed positive correlation between
Î¦and Bayesian surprise appears to share a common foundation in criticalityâ€”where diverse activity is
globally coordinated without loss of differentiation.
Importantly, Bayesian surprise accords with the intrinsicality emphasized by IIT. Integrated infor-
9
mation structure is fundamentally intrinsicâ€”as in dreamingâ€”but can be modulated by external stimuli.
Bayesian surprise is defined solely in terms of internal elements, the priorP(s)and the variational pos-
teriorQ(s), yet depends implicitly on external observationsothroughQ(s)â‰ˆP(s|o). This perspective
aligns with IITâ€™s claim that integrated information reflects meaningful intrinsic causeâ€“effect power, rather
than the extrinsic Shannon-style messages or codes [34].
Assuming thatÎ¦underlies consciousness, its coupling with Bayesian surprise offers a unifying account
of diverse experiential phenomena. In motor adaptation, such as learning to play an instrument, the early
stages involve awkward movements and vivid sensations (highÎ¦) because internal models fail to predict
inputs and require reorganization (high Bayesian surprise). With practice, performance becomes fluent;
prediction improves, belief updating diminishes, and phenomenological vividness decreases (lowÎ¦and
Bayesian surprise). A similar trajectory is seen in perceptual adaptation, as in glare adjustment or Troxler
fading. The framework also explains why most spontaneous neural activity remains unconscious: such
fluctuations yield no new knowledge, elicit little belief updating, and are not integrated. By the same
logic, pathological experiencesâ€”such as hallucinations and delusions in schizophrenia, associated with
aberrant salience [35]â€”may reflect abnormal assignment of Bayesian surprise, which is closely related
to salience [36]. In such cases, trivial inputs are treated as highly informative, driving excessive belief
updating and distortingÎ¦â€“structure. Thus, across normal learning, adaptation, spontaneous activity,
and pathology,Î¦appears to index the informativeness of sensory evidence through its dependence on
belief updating.
Integrated information and accuracy
Overall, accuracy showed a significant but heterogeneous positive relationship withÎ¦mc
R (meanÏ= 0.393;
Fig.5e, 5f). This suggests that greater integration often accompanies better inference performance, yet
high accuracy is not strictly contingent on largeÎ¦mc
R : 7/27 experiments exhibited negative correlations.
These results are consistent with the view that richÎ¦â€“structures confer functional advantages [37,38],
while also aligning with IITâ€™s prediction that functionally equivalent systems can differ in their integrated
causal structure [4,5]. This dovetails with our observation thatÎ¦is tightly coupled to belief updating
(complexity) rather than to performance per se. Three analogies illustrate this dissociation: Bayesian
surprise vs. accuracy, model parameter count vs. performance, and intrinsic integrated information vs.
extrinsic functionality. In each case, the former contributes to the latter but it is not strictly required.
Integrated information and variational free energy
Empirically, theÎ¦mc
R â€“VFE relationship was mixed across experiments and not significant overall (mean
Ï= 0.345; CI crosses zero; Fig.5a, 5b). To reconcile this with reports thatÎ¦increases as surprise falls over
longer (evolutionary) timescales [15] and with the theoretical accounts suggesting that minimizing VFE
may entail maximizingÎ¦[13,14], here we newly propose a hill-shaped trajectory: as VFE decreases,
Î¦initially rises, peaks, and then declines (conceptual Fig.6). This scheme accords with the observed
hill-shaped transitions ofÎ¦ mc
R and main-complex size (Fig.4c, 4d). Under such a trajectory,Î¦â€“VFE
correlations can be positive or negative, depending on whether the system resides on the ascending or
descending slope. This framework thus accommodates the variability observed across experiments while
situating the negative relations reported in theory [13,14] and in evolutionary simulations [15] within the
ascending phase, without contradicting our findings.
At a high VFE (a maladapted regime), the entropy of observations tends to be largeâ€”under ergodicity,
the long-term average of VFE serves as an upper bound on observation entropy [39]â€”so behavior becomes
weakly structured and elements act almost independently. Integrated information is presumably low
owingtotheabsenceofthecauseâ€“effectpoweremphasizedbyIITâ€”conceptually, ahigh-entropyâ€œgas-likeâ€
network. At a very low VFE (an idealized limit), the agentâ€™s generative model would predict perfectly and
processing would become reflexive and feedforward, with minimal belief updating. Integrated information
should again be low, both because of the spatial and metabolic cost of maintaining it and the absence
of recurrenceâ€”conceptually, a low-entropy â€œsolid-likeâ€ network. Between these extremes, the model is
competent yet uncertainty remains. Multiple competing hypotheses must be coordinated and revised
by ongoing input, fostering large recurrent causeâ€“effect structures and highÎ¦â€”conceptually, a medium-
entropy â€œliquid-likeâ€ network.
Functionally, this hill-shaped trajectory can be interpreted as a progression from the exploration
10
(mutation) phase to the exploitation (selection) phase. Early in training, because high-Î¦systems coincide
with information harvestingâ€”high Bayesian surprise, related to the mutual informationI(o;s)â€”where
substantial resources are invested to construct large integrated cores and explore models capable of
explainingtheinputswithsufficientlikelihood. Later, asthemodelcompressesandstabilizes, exploitation
dominates: Bayesian surprise andÎ¦subside while VFE continues to decline. A similar interpretation
applies to mutationâ€“selection metaphors in the neural Darwinism-like dynamics [40â€“42]: early training
expands the responsive area and diversifies neural responses (presumably higherÎ¦), whereas later training
contracts the area and stereotypes responses (lowerÎ¦) even as performance improves [42]. Together, these
analyses suggest thatÎ¦is not a direct proxy for model efficiency. Instead, it peaks during phases of belief
revision embedded within longer-term free-energy descent.
Limitations of the present study
First, the proposed hill-shaped trajectory ofÎ¦is an idealized principle whose full expression is constrained
in practice. Embodiment, bodily degrees of freedom, and environmental complexity often prolong devel-
opment, such that a post-developmental state with diminishedÎ¦may rarely be reached outside of simple
tasks. Ourin vitro, low-difficulty task with two binary hidden states likely enabled some cultures to
reach this exploitative regime. Because the preparation was disembodied and passively stimulated, the
exploratory stage was probably shorter than would occur in an embodied setting. In active inference,
agents minimize expected free energy, which includes the epistemic-value term (expected Bayesian sur-
prise) with a negative sign [43,44], thereby promoting exploration, sustaining higher Bayesian surprise,
and maintaining largerÎ¦during active sensing, as in daily active vision [45]. Second,Î¦was approxi-
mated usingÎ¦ R [20] and coreness with a minimum-cut-based method [21,22]. These are IIT-inspired
proxies rather than full IIT 3.0/4.0 quantifications. Our approaches emphasize synergistic coupling but
do not exhaustively assess state-dependent causeâ€“effect structures across spatiotemporal scales [5]. Third,
methodological constraints required us to fix the timescale (Ï„= 10ms), treat each electrode as a unit,
and to estimate transitions primarily from stimulation (perturbational) trials. While these approxima-
tions are likely reasonableâ€”given the emergence of integrated information at the macro timescale in
actual neural recordings [46] and the characteristic timescales of cultured neurons [47,48]â€”they remain
scale-dependent and warrant cautious interpretation. Finally, substantial between-experiment hetero-
geneity (highQ, highI2) in several meta-analyses cautions that culture-specific factors (e.g., maturation,
connectivity, excitability) may modulate the coupling betweenÎ¦, Bayesian surprise, and performance.
Conclusion
Ourresultsshowthat, inlivingneuronalnetworksperformingperceptualinference, integratedinformation
is tightly coupled to belief updatingâ€”indexed by Bayesian surpriseâ€”rather than directly to variational
free energy. Informational cores expand and concentrate diverse activity when belief revision is stronger,
and aÎ¦-proxy follows a hill-shaped trajectory across learning sessions, peaking within long-term free-
energy descent. These dynamics are consistent with operation near criticality, where response diversity,
belief updating, and integrated information co-peak. Conceptually,Î¦can be interpreted as the intrinsic
manifestation of system reorganization required to incorporate informative evidence; once the generative
model becomes sufficiently complete,Î¦is expected to decline. Functionally,Î¦does not directly enhance
inference performance but indirectly facilitates it by supporting model updates. By situating integrated
information within belief updating, our findings empirically link IITâ€™s mechanistic account with the FEPâ€™s
functional perspective, advancing a unified framework that bridges the proximate â€œhowâ€ and the ultimate
â€œwhyâ€ of consciousness.
Methods
Dissociated neuronal cultures
All procedures complied with the â€œGuiding Principles for the Care and Use of Animals in the Field of
Physiological Scienceâ€ published by the Japanese Physiological Society. The Committee on the Ethics of
11
Animal Experiments at the Graduate School of Information Science and Technology, the University of
Tokyo, approved the experimental protocol (A2024IST003).
High-density microelectrode arrays (HD-MEAs, MaxOne, MaxWell Biosystems) were covered with 1
mL of 1% Tergazyme (Sigma-Aldrich) and left at room temperature for 2 h. The detergent was removed
with an aspirator, and the chips were rinsed three times with sterilized water. Each chip was subsequently
soaked in ethanol for 30 min, rinsed three additional times, overlaid with 1 mL of pre-warmed plating
medium (Neurobasal Plus, Thermo Fisher Scientific), covered to prevent drying, and maintained in an
incubator for at least 2 days.
After this pretreatment, the chips were rinsed three times with sterile water. Polyethylenimine (Su-
pelco) was diluted to 0.07 % in borate buffer (Thermo Fisher Scientific), and 50ÂµL were applied to each
electrode surface. The chips were incubated overnight, washed three times and then coated with 50ÂµL
of laminin (20Âµg/mL; Sigma-Aldrich). After replacing the lids, the chips were incubated for 1 h.
Pregnant Wistar rats were anesthetized with inhaled isoflurane (Viatris) and euthanised by guillotine
decapitation. Following abdominal disinfection with ethanol, the uterus was removed and placed in
Hankâ€™s Balanced Salt Solution (Life Technologies). Three E18 fetuses were harvested, their brains were
removed, and pieces of cerebral cortex were excised for cell seeding.
The cortical tissue was transferred to 2 mL of 0.25 % Trypsin-EDTA (Thermo Fisher Scientific)
and incubated for 20 min, with the tube shaken every 5 min. The tissue was then transferred to plating
medium to stop the enzymatic reaction, gently shaken, and placed in fresh medium. Cells were dissociated
with trituration pipetting. One milliliter of the suspension was passed through a 40Âµm cell strainer
(Falcon). Plating medium was added to adjust the density to 38,000 cells per 5ÂµL.
The laminin solution was removed from the chip surface, and 50ÂµL of the cell suspension was applied
onto the electrodes. The chip was incubated for 120 min to allow cell attachment, after which 0.6 mL
of plating medium was added. The chip was then maintained in the incubator. To prevent evaporation,
the chip was covered with its lid, placed with a 35 mm dish of sterilized water inside a 90 mm dish, and
kept in an incubator at 36.5Â°C in 5 % CO2.
In this study, 12 independent cell cultures were used to conduct 27 independent experiments. The
average days in vitro (DIV) was18.4Â±6.96.
Electrophysiological experiments
HD-MEAs were used both to record the activity of cultured neuronal networks and to deliver electrical
stimulation. The HD-MEA employed in this study contained 26,400 electrodes arranged within an area
of 3.85 mmÃ—2.10 mm, with 17.5-Âµm spacing between electrodes, of which up to 1,024 could be recorded
simultaneously at a sampling rate of 20 kHz [49,50]. Prior to experiments, spontaneous activity was
recorded from all electrodes for 50 s. Based on the average spike amplitude during this period, up to
1,024 electrodes with the highest amplitudes were selected for subsequent recordings. From this set,
the 32 electrodes with the highest average spike amplitudes were designated as stimulation electrodes.
Among them, the 16 electrodes with odd-numbered amplitude ranks delivered stimulation corresponding
to observationso (1) âˆ’o(16), while the 16 electrodes with even-numbered ranks delivered stimulation
corresponding to observationso (17) âˆ’o(32). Because recordings from the stimulation electrodes were
prone to noise interference, subsequent recordings were obtained from up to 992 electrodes, excluding
these 32 stimulation electrodes. Electrical stimulation consisted of biphasic pulses with a positive-first
phase, an amplitude of 350 mV, and a pulse width of 200Âµs.
Data processing
For spike detection, the recorded potentials were band-pass filtered (300â€“3000 Hz, Butterworth filter). A
spike was detected when the measured potential at an electrode fell below a threshold set at five times
the standard deviation of the potential for that electrode.
In our samples, spike counts peaked within 100â€“200 ms after electrical stimulation (Fig.2b). Accord-
ingly, the evoked response strengthrti at an electrodeiin a trialtwas defined as the number of spikes
occurring within a 10â€“300 ms window post-stimulation.
This treatment of evoked responses closely followed that of previous studies [16,19]; readers are
referred to those works for further details. For trials in which the source state was(s(1),s(2)) = (1,0)
(approximately 6,400 trials (= 100sessionsÃ—256trials/session/4states)), the meanr ti was computed,
12
as well as for trials in which(s(1),s(2)) = (0,1)(âˆ¼6,400 trials). The difference between these two means
was then calculated for each electrode. Electrodes with differences>0were classified ass(1)-preferring,
those with differences<0ass (2)-preferring, and those with differences= 0as non-preferring/inactive.
The numbers ofs(1)-preferring,s(2)-preferring, and non-preferring/inactive electrodes were352.0Â±359.3,
353.1Â±347.5, and287.7Â±311.0, respectively (n= 27).
For each trial, the mean evoked response over thes(1)-preferring electrodes was computed asxt1, and
the mean over thes(2)-preferring asxt2. Bothx t1 andx t2 were then mean-subtracted, detrended, and
normalized to the range[0,1].
KLD of neuronal response
To evaluate the source selectivity of neuronal responses at each electrode, we used the Kullback-Leibler
divergence (KLD) method introduced in a previous study [16]. For electrodei, the distributions of
evoked spike counts in(s(1),s(2)) = (1,0)and(0,1)trials were each fitted with a Poisson distribution.
The empirical parametersÎ»1,0 andÎ» 0,1 were estimated, and the KLD was computed according to the
following equation:
DKL(P(ri |(1,0))âˆ¥P(r i |(0,1))) =Î» 1,0 ln Î»1,0
Î»0,1
+Î»0,1 âˆ’Î»1,0.
In the Results, we report analyses restricted to the 7,613 electrodes for which the computed KLD
values converged (i.e., did not diverge).
FEP-based analysis
For FEP-based analysis, we closely followed the methods described in previous studies [17â€“19], including
the generative process, variational Bayesian inference, the canonical neural network, and the reverse-
engineering framework. For mathematical details, readers are referred to those prior studies.
Generative process of observations
We assumed a partially observable Markov decision process (POMDP) in which two independent binary
hidden sourcess t = (s(1)
t ,s(2)
t )âˆˆ{0,1} 2, generated 32 binary sensory observations,ot âˆˆ{0,1} 32, via
a stochastic mixing matrixA. In the actual experiment, the state of each hidden source was drawn
independently from a Bernoulli distribution with probability 0.5. For each observation channel, the
observation was generated from the hidden sources with specific conditional probabilities. In particular,
o(1) âˆ’o(16) conveyed the value ofs(1) with probability 0.75 or that ofs(2) with probability 0.25; conversely,
o(17) âˆ’o(32) conveyed the value ofs(2) with probability 0.75 or that ofs(1) with probability 0.25. This
defined the categorical likelihoodP(o(i)
t |st,A)for each electrode, withP(A(i))assigned a Dirichlet prior.
Variational free energy
Under a mean-field approximationQ(s1:t,A) =Q(A) âˆt
Ï„=1 Q(sÏ„), the variational free energy (i.e., the
negative evidence lower bound) is given by
F=
tâˆ‘
Ï„=1
sÏ„ Â·
(
lnsÏ„ âˆ’lnAÂ·o Ï„ âˆ’lnD
)
+O(lnt),
whereDis the prior over hidden states. MinimizingFwith respect tos Ï„ and the Dirichlet parameters
ayields
sÏ„ =Ïƒ
(
lnAÂ·o Ï„ + lnD
)
, aâ†a+
tâˆ‘
Ï„=1
oÏ„ âŠ—sÏ„,
whereÏƒ(Â·)is the softmax function andâŠ—denotes the outer product.
13
Canonical neural network formulation
Neuronal responsesxt âˆˆ(0,1) 2 to sensory inputsot were modelled as a canonical neural network with
the following dynamics:
Ë™xt âˆâˆ’sig âˆ’1(xt) +Wot +h,
wheresig âˆ’1(Â·)is the elementwise logit function,Wis a2Ã—32synaptic strength matrix, andhis the
adaptive firing threshold vector. The matrixW=W1 âˆ’W0 is composed of excitatory (W1) and inhibitory
(W0) components.
Neural network cost functionL
Integrating the network dynamics with respect toxt yields a cost function
L=
tâˆ‘
Ï„=1
(xÏ„
Â¯xÏ„
)âŠ¤[
ln
(xÏ„
Â¯xÏ„
)
âˆ’ln
(
Ë†W1
Â¯Ë†W1
Ë†W0
Â¯Ë†W0
)(oÏ„
Â¯oÏ„
)
âˆ’
(Ï•1
Ï•0
)]
+C,
whereÂ¯x= 1âˆ’x,Â¯o= 1âˆ’o, Ë†Wâ„“ = sig(Wâ„“), and Â¯Ë†Wâ„“ = 1âˆ’sig(W â„“). The threshold factorsÏ•= (Ï• 1,Ï•0)âŠ¤
correspond tolnD. ThisLis asymptotically equivalent toF, withxâ†”s,Wâ†”A, andÏ•â†”lnD.
Reverse engineering from empirical neural activity
From experimental data, neuronal responsesxt were calculated for each trial. Given these responses, the
threshold factorÏ•was then estimated as:
Ï•=
(Ï•1
Ï•0
)
= ln
( âŸ¨xâŸ©
1âˆ’âŸ¨xâŸ©
)
,
whereâŸ¨Â·âŸ©indicates the average over time. The threshold factorÏ•was held constant within each session.
Following previous studies,Ï•for the first 10 sessions was computed as the average of the neuronal
responses during those sessions. For subsequent sessions,Ï•was computed as the average of the neuronal
responses in the immediately preceding session.
The effective synaptic connectivityWwas estimated from the outer products ofxt ando t according
to the fixed-point equations
W1 = logit
(âŸ¨xoâŠ¤âŸ©
âŸ¨x1âŠ¤âŸ©
)
, W 0 = logit
(âŸ¨(1âˆ’x)o âŠ¤âŸ©
âŸ¨(1âˆ’x)1 âŠ¤âŸ©
)
, W=W 1 âˆ’W0.
Substitutingx,W, andÏ•intoLyielded the empirical variational free energy for each session. At the
same time, we computed empirical Bayesian surprise
tâˆ‘
Ï„=1
(xÏ„
Â¯xÏ„
)âŠ¤[
ln
(xÏ„
Â¯xÏ„
)
âˆ’
(Ï•1
Ï•0
)]
and empirical accuracy
tâˆ‘
Ï„=1
(xÏ„
Â¯xÏ„
)âŠ¤
ln
(
Ë†W1
Â¯Ë†W1
Ë†W0
Â¯Ë†W0
)(oÏ„
Â¯oÏ„
)
.
Neuronal response IQR
To evaluate the variability of neuronal responses, we used the interquartile range (IQR). For each session,
the mean evoked responser(1) ofs (1)-preferring electrodes was grouped by hidden source state, and the
IQR was calculated within each group. These IQR values were then averaged. The same procedure was
applied tor(2) ofs(2)-preferring electrodes. The two resulting IQRs were then averaged to yield an overall
measure of response diversity for the network.
Similarly, to assess the variability of neuronal responses at a single electrode, trials were grouped by
hidden source state, and the IQR was calculated within each group and then averaged.
14
Transition probability
In IIT, the causeâ€“effect power is evaluated from the transition probabilities between system states. The
method used here corresponds to what has previously been referred to as the downsampling method [46].
Specifically, the time series was coarse-grained into states by segmenting it into windows of widthÏ„, and
the empirical distribution of state transitions between adjacent windows was computed. For a time series
of lengthT, there areTâˆ’Ï„+ 1such windows, each represented by the mean value of the observations
within that window. These representative values were binarized using their median as the threshold.
Adjacent pairs of windows yieldTâˆ’2Ï„+ 1transitions, which were used to compute state transition
probabilities. In each trial, evoked responses during 10â€“300 ms after stimulation were binned at 1-ms
resolution, resulting in a time series of length 290. For each session, a single state transition probabil-
ity matrix was computed using all trials in which electrical stimulation was delivered, i.e., those with
(s(1),s(2))Ì¸= (0,0), amounting to approximately 256Ã—3/4=192 trials. The use of only trials containing
stimulation followed the rationale of the perturbational approach.
Complex extraction
For each session, a weighted undirected graph was constructed in which each vertex represented a pre-
ferring electrode, and all vertices were fully connected. The weight of each edge was given byÎ¦R [20],
computed from the neuronal activity of the corresponding pair. The number of vertices occasionally
reachedâˆ¼900. Due to computational constraints,Ï„was fixed at 10 ms, and state transition probabilities
were calculated for all electrode pairs;Î¦R values were then derived from these transition probabilities.
The 10-ms window width was chosen based on the time step used in the previous studies of spatiotemporal
patterns in neuronal cultures [47,48]. TheÎ¦R between electrodesXandYwas expressed as:
Î¦R(X,Y) =I(X tâˆ’1,Ytâˆ’1;Xt,Yt)âˆ’I(X tâˆ’1;Xt)âˆ’I(Y tâˆ’1;Yt) + min
Z=X,Y,W=X,Y
I(Ztâˆ’1;Wt),
whereIis Shannonâ€™s mutual information, and the fourth term corresponds to the minimum mutual
information (MMI) [51] redundancy function, introduced as a corrective measure to avoid negative values.
The method of complex extraction followed that described in previous research [21], and mathematical
details are provided therein. The graph was recursively partitioned using the minimum cut (mc) until all
vertices were isolated. Given a vertex set, the minimum cut is defined as the bipartition of the set into
two non-empty, disjoint subsets that minimizes the sum of the edge weights crossing the partition. The
sum of these edge weights crossing the minimum cut of a vertex set was denotedÎ¦mc
R for that set. A
vertex set was defined as a complex if itsÎ¦mc
R was greater than that of any of its supersets, and, among
such complexes, was further defined as a main complex if itsÎ¦mc
R was not smaller than that of any of its
subsets. The maximumÎ¦mc
R among main complexes â€” analogous to the integrated information quantity
in IIT 2.0 â€” was taken as the index of integrated information in this study. This index was computed
once per session. Finally,Î¦ mc
R was normalized by the number of edges in the graph. This adjustment
was necessary because, for two graphs with comparable average edge weights but different numbers of
vertices, the graph with more vertices and edges would naturally yield a larger number of edges crossing
a cut, and thus a largerÎ¦mc
R . Normalization by edge count therefore enabled comparisons across graphs
of different sizes.
Additionally, we computed the coreness measure [22]. For a given graph, the coreness of a vertex is
defined as the maximumÎ¦mc
R among all complexes that include that vertex (noting that the set of all
vertices always constitutes at least one complex). In previous work [22], coreness was computed for the
mouse connectome and found to be high in regions such as the cerebral cortex, which are conducive to
large integrated information, and low in regions such as the cerebellum, which are less suited for inte-
grated information. Thus, coreness quantifies the contribution of each vertex to the systemâ€™s integrated
information.
Statistical tests
For comparisons between two paired groups, the Wilcoxon signed-rank test was used. For the meta-
analysis of Spearman correlation coefficientsÏi obtained from each experiment, values were first trans-
formed into the Fisher-zdomain:z i = 1
2 ln 1+Ïi
1âˆ’Ïi
.Sampling variances were approximated asVar(zi)â‰ˆ
15
(1+Ï2
i/2)/(nâˆ’3)[52], wherendenotes the number of paired observations (i.e., the number of data points
per experiment contributing to the correlation). Between-experiment heterogeneity was assessed using
Cochranâ€™sQstatistic and theI 2 statistic [53]. Given the presence of heterogeneity, we estimated pooled
effects using a random-effects model with DerSimonianâ€“Laird estimation [54] of the between-experiment
varianceÏ„ 2. Random-effects weights were defined aswi = 1/(Var(zi) +Ï„ 2), and the pooled effect size
was computed aszRE = âˆ‘
iwizi/âˆ‘
iwi. The corresponding standard error was SERE =
âˆš
1/âˆ‘
iwi
and p-values were obtained from the two-sidedZ-test. Finally,z RE and the 95% confidence interval
zRE Â±1.96SE RE were back-transformed to the correlation scale usingÏ= tanh(z). Random-effects
estimates, together with heterogeneity statistics (Q,I2, andÏ„2), are reported in the Results.
Data availability
Processed spike data and stimulation conditions (2 hidden source states and 32 observations per trial)
have been deposited in the DANDI Archivehttps://dandiarchive.org/dandiset/001611/draft.
Derivatives (neuronal responses, PSTH, response KLD, preferring electrodes, VFE, Bayesian surprise,
accuracy,Î¦ R adjacency matrices, main-complex membership, and coreness) and Source Data are available
at Zenodohttps://doi.org/10.5281/zenodo.17187550.
Code availability
All analysis code except for complex extraction is available at GitHubhttps://github.com/yunipok
e/Bridging_integrated_information_theory_and_the_free_energy_principle_in_living_neu
ronal_networks. For complex extraction, the original sourcehttps://github.com/JunKitazono/Bid
irectionallyConnectedCoreswas utilized. Code for the variational Bayesian metric was created with
significantreferencetotheoriginalsourcehttps://github.com/takuyaisomura/reverse_engineering.
Acknowledgments
We are deeply grateful to Drs. Naotsugu Tsuchiya, Masafumi Oizumi, Muneki Ikeda, Francesco Ellia,
Matteo Grasso, Shosuke Nishimoto and Takuya Isomura for valuable discussions and insightful comments.
This work was partially supported by JSPS KAKENHI (23H03465, 24H01544, 24K20854, 25H02600),
AMED (24wm0625401h0001), the Asahi Glass Foundation, and the Secom Science and Technology Foun-
dation.
Conflict of interest
The authors have no conflicts to disclose.
Author contributions
Teruki Mayama:Conceptualization(lead); Investigation(lead); Resources(supporting); Software(supporting);
Formal analysis (lead); Visualization (lead); Writing â€“ original draft (lead).Sota Shimizu:Software
(lead); Resources (supporting).Yuki Takano:Software (supporting); Resources (supporting).Dai
Akita:Formal analysis (supporting); Resources (lead); Funding acquisition (supporting); Project ad-
ministration (supporting); Supervision (supporting); Writing â€“ review & editing (supporting).Hirokazu
Takahashi:Funding acquisition (lead); Project administration (lead); Supervision (lead); Writing â€“ re-
view & editing (lead).
References
[1] Tononi G. An information integration theory of consciousness. BMC neuroscience. 2004;5:1-22.
16
[2] Tononi G. Consciousness as integrated information: a provisional manifesto. The Biological Bulletin.
2008;215(3):216-42.
[3] Balduzzi D, Tononi G. Integrated information in discrete dynamical systems: motivation and theo-
retical framework. PLoS computational biology. 2008;4(6):e1000091.
[4] Oizumi M, Albantakis L, Tononi G. From the phenomenology to the mechanisms of consciousness:
integrated information theory 3.0. PLoS computational biology. 2014;10(5):e1003588.
[5] Albantakis L, Barbosa L, Findlay G, Grasso M, Haun AM, Marshall W, et al. Integrated information
theory (IIT) 4.0: formulating the properties of phenomenal existence in physical terms. PLoS
computational biology. 2023;19(10):e1011465.
[6] Friston K. The free-energy principle: a unified brain theory? Nature reviews neuroscience.
2010;11(2):127-38.
[7] Solms M, Friston K. How and why consciousness arises: some considerations from physics and
physiology. Journal of Consciousness Studies. 2018;25(5-6):202-38.
[8] Solms M. The hard problem of consciousness and the free energy principle. Frontiers in psychology.
2019;9:2714.
[9] Rudrauf D, Bennequin D, Granic I, Landini G, Friston K, Williford K. A mathematical model of
embodied consciousness. Journal of theoretical biology. 2017;428:106-31.
[10] Williford K, Bennequin D, Friston K, Rudrauf D. The projective consciousness model and phenom-
enal selfhood. Frontiers in Psychology. 2018;9:2571.
[11] Whyte CJ, Smith R. The predictive global neuronal workspace: A formal active inference model of
visual consciousness. Progress in neurobiology. 2021;199:101918.
[12] Tinbergen N. On aims and methods of ethology. Animal Biology. 2005;55(4).
[13] Friston KJ, Wiese W, Hobson JA. Sentience and the origins of consciousness: From Cartesian duality
to Markovian monism. Entropy. 2020;22(5):516.
[14] Safron A. An Integrated World Modeling Theory (IWMT) of consciousness: combining integrated
informationandglobalneuronalworkspacetheorieswiththefreeenergyprincipleandactiveinference
framework; toward solving the hard problem and characterizing agentic causation. Frontiers in
artificial intelligence. 2020;3:520574.
[15] Lundbak Olesen C, Waade PT, Albantakis L, Mathys C. Phi fluctuates with surprisal: An empirical
pre-study for the synthesis of the free energy principle and integrated information theory. PLOS
Computational Biology. 2023;19(10):e1011346.
[16] Isomura T, Kotani K, Jimbo Y. Cultured cortical neurons can perform blind source separation
according to the free-energy principle. PLoS computational biology. 2015;11(12):e1004643.
[17] Isomura T, Friston K. Reverse-engineering neural networks to characterize their cost functions.
Neural computation. 2020;32(11):2085-121.
[18] Isomura T, Shimazaki H, Friston KJ. Canonical neural networks perform active inference. Commu-
nications Biology. 2022;5(1):55.
[19] Isomura T, Kotani K, Jimbo Y, Friston KJ. Experimental validation of the free-energy principle
with in vitro neural networks. Nature Communications. 2023;14(1):4547.
[20] Mediano PA, Rosas F, Carhart-Harris RL, Seth AK, Barrett AB. Beyond integrated information:
A taxonomy of information dynamics phenomena. arXiv preprint arXiv:190902297. 2019.
[21] Kitazono J, Kanai R, Oizumi M. Efficient search for informational cores in complex systems: Ap-
plication to brain networks. Neural Networks. 2020;132:232-44.
17
[22] Kitazono J, Aoki Y, Oizumi M. Bidirectionally connected cores in a mouse connectome: towards
extracting the brain subnetworks essential for consciousness. Cerebral Cortex. 2023;33(4):1383-402.
[23] Varley TF. Decomposing past and future: Integrated information decomposition based on shared
probability mass exclusions. PLOS ONE. 2023 03;18(3):1-31. Available from:https://doi.org/10
.1371/journal.pone.0282950.
[24] Luppi AI, Mediano PA, Rosas FE, Allanson J, Pickard J, Carhart-Harris RL, et al. A synergis-
tic workspace for human consciousness revealed by integrated information decomposition. Elife.
2024;12:RP88173.
[25] Beggs JM, Plenz D. Neuronal avalanches in neocortical circuits. Journal of neuroscience.
2003;23(35):11167-77.
[26] Pasquale V, Massobrio P, Bologna L, Chiappalone M, Martinoia S. Self-organization and neuronal
avalanches in networks of dissociated cortical neurons. Neuroscience. 2008;153(4):1354-69.
[27] Shew WL, Yang H, Yu S, Roy R, Plenz D. Information capacity and transmission are maximized in
balanced cortical networks with neuronal avalanches. Journal of neuroscience. 2011;31(1):55-63.
[28] Yada Y, Mita T, Sanada A, Yano R, Kanzaki R, Bakkum DJ, et al. Development of neural population
activity toward self-organized criticality. Neuroscience. 2017;343:55-65.
[29] Ikeda N, Akita D, Takahashi H. Noise and spike-time-dependent plasticity drive self-organized
criticality in spiking neural network: Toward neuromorphic computing. Applied Physics Letters.
2023;123(2).
[30] Aguilera M, Di Paolo EA. Integrated information in the thermodynamic limit. Neural Networks.
2019;114:136-46.
[31] Kim H, Lee U. Criticality as a determinant of integrated informationÎ¦in human brain networks.
Entropy. 2019;21(10):981.
[32] Popiel NJ, Khajehabdollahi S, Abeyasinghe PM, Riganello F, Nichols ES, Owen AM, et al.
The emergence of integrated information, complexity, and â€˜consciousnessâ€™ at criticality. Entropy.
2020;22(3):339.
[33] Mediano PA, Rosas FE, Farah JC, Shanahan M, Bor D, Barrett AB. Integrated information as a
common signature of dynamical and information-processing complexity. Chaos: An Interdisciplinary
Journal of Nonlinear Science. 2022;32(1).
[34] Zaeemzadeh A, Tononi G. Shannon information and integrated information: message and meaning.
arXiv preprint arXiv:241210626. 2024.
[35] Kapur S. Psychosis as a state of aberrant salience: a framework linking biology, phenomenology,
and pharmacology in schizophrenia. American journal of Psychiatry. 2003;160(1):13-23.
[36] Itti L, Baldi P. Bayesian surprise attracts human attention. Advances in neural information pro-
cessing systems. 2005;18.
[37] Albantakis L, Hintze A, Koch C, Adami C, Tononi G. Evolution of integrated causal struc-
tures in animats exposed to environments of increasing complexity. PLoS computational biology.
2014;10(12):e1003966.
[38] Grasso M, Albantakis L, Lang JP, Tononi G. Causal reductionism and causal structures. Nature
neuroscience. 2021;24(10):1348-55.
[39] Friston K. Life as we know it. Journal of the Royal Society Interface. 2013;10(86):20130475.
[40] Edelman GM. Neural Darwinism: selection and reentrant signaling in higher brain function. Neuron.
1993;10(2):115-25.
18
[41] Kilgard MP. Harnessing plasticity to understand learning and treat disease. Trends in neurosciences.
2012;35(12):715-22.
[42] Takahashi H, Yokota R, Kanzaki R. Response variance in functional maps: neural darwinism
revisited. PLoS One. 2013;8(7):e68705.
[43] Friston K, Rigoli F, Ognibene D, Mathys C, Fitzgerald T, Pezzulo G. Active inference and epistemic
value. Cognitive neuroscience. 2015;6(4):187-214.
[44] Parr T, Pezzulo G, Friston KJ. Active inference: the free energy principle in mind, brain, and
behavior; 2022.
[45] Parr T, Friston KJ. The active construction of the visual world. Neuropsychologia. 2017;104:92-101.
[46] Leung A, Tsuchiya N. Emergence of integrated information at macro timescales in real neural
recordings. Entropy. 2022;24(5):625.
[47] MadhavanR,ChaoZC,PotterSM. Plasticityofrecurringspatiotemporalactivitypatternsincortical
networks. Physical biology. 2007;4(3):181.
[48] Yada Y, Kanzaki R, Takahashi H. State-dependent propagation of neuronal sub-population in
spontaneous synchronized bursts. Frontiers in systems neuroscience. 2016;10:28.
[49] Ballini M, MÃ¼ller J, Livi P, Chen Y, Frey U, Stettler A, et al. A 1024-channel CMOS microelectrode
array with 26,400 electrodes for recording and stimulation of electrogenic cells in vitro. IEEE journal
of solid-state circuits. 2014;49(11):2705-19.
[50] MÃ¼ller J, Ballini M, Livi P, Chen Y, Radivojevic M, Shadmani A, et al. High-resolution CMOS
MEA platform to study neurons at subcellular, cellular, and network levels. Lab on a Chip.
2015;15(13):2767-80.
[51] Barrett AB. Exploration of synergistic and redundant information sharing in static and dynamical
Gaussian systems. Physical Review E. 2015;91(5):052802.
[52] Bonett DG, Wright TA. Sample size requirements for estimating Pearson, Kendall and Spearman
correlations. Psychometrika. 2000;65(1):23-8.
[53] Higgins JP, Thompson SG. Quantifying heterogeneity in a meta-analysis. Statistics in medicine.
2002;21(11):1539-58.
[54] DerSimonian R, Laird N. Meta-analysis in clinical trials. Controlled clinical trials. 1986;7(3):177-88.
19