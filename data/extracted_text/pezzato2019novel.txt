A Novel Adaptive Controller for Robot Manipulators
Based on Active Inference
Corrado Pezzato1, Riccardo Ferrari2 and Carlos Herna´ndez Corbato3
Abstract—More adaptive controllers for robot manipulators number of DOFs. In this paper, we present a novel adaptive
are needed, which can deal with large model uncertainties. controllerforrobotmanipulators,inspiredbyarecenttheory
This paper presents a novel active inference controller (AIC)
ofthebrain,whichdoesnotrequireaccurateplantdynamics,
as an adaptive control scheme for industrial robots. This
and that is less sensitive to large parameters variation.
scheme is easily scalable to high degrees-of-freedom, and it
maintains high performance even in the presence of large Theproposedcontrolschemeisbasedonthegeneralfree-
unmodeled dynamics. The proposed method is based on active energy principle proposed by Karl Friston [7], and redefined
inference,apromisingneuroscientifictheoryofthebrain,which in engineering terms [8], [9]. The main idea at the basis of
describes a biologically plausible algorithm for perception and
Friston’s neuroscientific theory, is that the brain’s cognition
action. In this work, we formulate active inference from a and motor control functions could be described in terms
control perspective, deriving a model-free control law which
is less sensitive to unmodeled dynamics. The performance and of energy minimization. It is supposed [10] that humans
the adaptive properties of the algorithm are compared to a have a set of sensory data and a specific internal model to
state-of-the-art model reference adaptive controller (MRAC) characterize how the sensory data could have possibly been
in an experimental setup with a real 7-DOF robot arm. The
generated. Then, given this generative model, the causes of
resultsshowedthattheAICoutperformedtheMRACinterms
sensory data are inferred. Usually, the environment acts on
of adaptability, providing a more general control law. This
confirmed the relevance of active inference for robot control. humans to produce sensory impression, and humans can act
Index Terms—Biologically-Inspired Robots, Adaptive Con- on the environment to change it. In this view, the motor
trol of Robotic Systems, Industrial Robots, Active Inference, control of human body can be considered as the fulfillment
Free-energy Principle of a prior expectation about proprioceptive sensations [11].
Although the general active inference framework is math-
I. INTRODUCTION
ematically well defined, its application to robotics remains
Traditional control approaches for industrial manipulators a challenge. Active inference has mainly been applied to
rely on an accurate model of the plant. However, there is neuronal simulations (for handwriting [7] for instance), sup-
an increasing demand in industry for robot controllers that posing to know the true dynamical process. However, this is
are more flexible and adaptive to run-time variability. Often, notthecaseinrobotics.Eveniftheneuronalsimulationsare
robot manipulators are placed in dynamically changing sur- a strong proof of concept for the neuroscientific theory, in
rounding, and they are subject to noisy sensory input and thepresentformtheirextensiontorealisticroboticscenarios
unexpectedevents.Inthesenewapplications,obtainingsuch [12], [13] does not provide advantages over other classical
a model is a major problem. For example, in pick and place controllers. The main problems are the computational load
tasks,thedynamicsoftherobotmanipulatorscanchangeun- andthedefinitionofmeaningfulgenerativemodels.Withour
predictablywhilehandlingunknownobjects.Recentresearch workweovercometheselimitations,usingactiveinferenceto
hasfocusedontheuseofmachinelearningmethodstoobtain deriveamodel-freecontrollaw.Insteadofmodelingthetrue
accurateinversedynamicmodels[1],[2].Ingeneral,learning unknown dynamical process, we define a reference model
models using Neural Networks (NN) requires experts for that active inference has to follow. The main contributions
definingthebesttopologyforaparticularproblem[3].Even of this paper are twofold:
thoughitispossibletoexploitthephysicalknowledgeofthe • Derivation of an online active inference control law for
system to simplify and improve the learning performance a generic n-DOF robot manipulator in joint space.
[4], the need of large amount of training data and several • Comparison of the adaptability of the AIC with a state-
iterations for learning, still remains a problem and hard to of-the-art model reference adaptive controller.
generalise[5],[6].Controllersthatcandynamicallyadaptare
The contributions have been experimentally validated in a
required,butexistingsolutionsinadaptivecontroleitherneed
7-DOF collaborative industrial manipulator.
anaccuratemodel,oraredifficulttotuneandscaletohigher
A. Related work
*ThisresearchwassupportedbyAholdDelhaize.Allcontentrepresents At present, the use of active inference for robot control
theopinionoftheauthor(s),whichisnotnecessarilysharedorendorsedby
is still limited. In [12], the authors simulated a PR2 robot
theirrespectiveemployersand/orsponsors.
1,3Corrado Pezzato and Carlos Herna´ndez Corbato are with the Cog- controlled in Cartesian space for a reaching task. The solu-
nitive Robotics Department, TU Delft, 2628 CD Delft, The Netherlands tion was offline, computationally expensive, open-loop, and
c.pezzato@tudelft.nl,andc.h.corbato@tudelft.nl
it relied on an additional position controller. This makes the
2Riccardo Ferrari is with the Department of Systems and Control, TU
Delft,2628CDDelft,TheNetherlandsr.ferrari@tudelft.nl approach not suitable for online tasks. A recent MSc thesis
1202
rpA
31
]OR.sc[
2v86721.9091:viXra
[13], based on [12], derived an offline closed-loop scheme B. Paper structure
of active inference. The feedforward torque commands for a The paper is organised as follows: In Sec. II we present
simulated 7-DOF manipulator are computed offline, relying the free-energy principle and active inference in control
on additional controllers for feedback control. The scheme engineering terms. In Sec. III we derive a novel AIC for a
failed to control the robot in presence of gravity since the 7-DOFrobotmanipulator,andweexplainthemodelassump-
feedforward torques did not include the gravitational effect. tions and simplifications. In Sec IV the MRAC is presented
Both [12] and [13] were based on the Statistical Parametric for comparison. In Sec. V we compare the adaptability of
Mapping (SPM) by Friston. This toolbox is suitable for the AIC and MRAC in a simulated pick and place task,
several offline applications, but it is too computationally validating the results in the real setup. We also discuss
heavyforonlinecontrol.In[13],eachiterationisreportedto the advantages of our AIC and the open questions. Finally,
take about one second. Another recent work [14] formalised Sec. VI provides a summary and directions for future work.
the use of the free-energy for static state estimation, using a
real UR5 robot arm equipped with proprioceptive and visual
II. THEACTIVEINFERENCEFRAMEWORK
sensors. Even though the results of the state estimation were In this section we report the free-energy principle and
promising, no control actions were included. The same au- active inference from [8], [10], rewriting only the necessary
thorspresentedin[15]thebodyestimationandcontrolinthe conceptsincontrolterms,tounderstandthederivationofour
joint space of a simulated 2-DOF robot arm through active novel AIC in Sec. III.
inference.Thissolutionincludedstate-of-theartregressorsto
A. The free-energy principle
estimate online the generative models. However, during the
The free-energy principle is formulated in terms of
simulations,theestimationoftheaccelerationwasunreliable
Bayesian inference [23]. In this view, body perception for
and substituted with the ground truth. Regardless of the
state estimation is framed using Bayes rule:
fact that only forward dynamics models had to be learned,
the authors pointed out how this approach is not simpler p(y|x)p(x)
p(x|y)= (1)
compared with classical inverse dynamics techniques. In a p(y)
parallel, related work on active inference [16], the authors wherep(x|y)istheprobabilityofbeinginthen-dimensional
successfully controlled a real 3-DOF robot arm using veloc- state x given the current m-dimensional sensory input y.
ity commands. In our approach we formulate an AIC for Instead of exactly inferring the posterior, which often in-
online closed loop control of industrial robots, using low- volves intractable integrals, an auxiliary probability distri-
level torque commands. We also provide a comparison with bution r (x), called recognition density, is introduced. By
d
a state-of-the-art adaptive controller, and insights for design minimizingtheKullback-Leiblerdivergence(D )between
KL
andtuning.Ontheotherhand,theadaptivecontrolbranchof the true posterior p(x|y) and r (x), the most probable state
d
controltheory[17],offerssolutionstodealwithmanipulators given a sensory input is inferred [8]. D is defined as:
KL
subject to parameters variation and abrupt changes in the
(cid:90) r (x)
dynamics. Within adaptive controllers, two main categories D (r (x)||p(x|y))= r (x)ln d dx=F+lnp(y)
KL d d p(x|y)
can be identified: the model reference adaptive systems, and
(2)
the self-tuning regulators [18]. The first technique being
In the equation above, the scalar F is the so called free-
studied for robot manipulators was the model reference
energy. By minimizing F, D is also minimized and the
KL
adaptive control (MRAC) [19]. The idea behind this tech-
recognition density approaches the true posterior. Accord-
nique is to derive a control signal to be applied to the
ing to the Laplace approximation [24], the controller only
robot actuators which will force the system to behave as
parametrisesthesufficientstatistics(e.g.meanandvariance)
specified by a chosen reference model. Furthermore, the
of the recognition density. r (x) is assumed Gaussian and
d
adaptation law is designed to guarantee stability using either
sharply peaked at its mean value µ. This approximation
Lyapunov theory or hyperstability theory [20]. The other
allows to simplify the expression for F which results:
most common approach for robot control is the self-tuning
adaptivecontrol[21],[22].Themaindifferencebetweenthis F ≈−lnp(µ,y) (3)
technique and the MRAC is that the self-tuning approach
The mean µ is the internal belief about the true states x.
represents the robot as a linear discrete-time model and it
Minimizing F, the controller is continuously adapting the
estimates online the unknown parameters, substituting them
internal belief µ about the states x based on the current
in the control law. Adaptive control of robot manipulators
sensory input y.
is required in presence of uncertain dynamics and varying
B. Free-energy equation
payloads, however, the complexity of the controller usually
increases with increasing number of DOFs. Among all the Equation (3) is still general and it has to be further
possible adaptive controllers, in this paper we choose the specified to numerically evaluate F. To do so, the joint
MRAC with hyperstability theory [20] for comparison. This probability p(µ,y) has to be defined. This is done by
approachprovidesadaptabilitytoabruptchangesintherobot introducingtwogenerativemodels,onetopredictthesensory
dynamics, and it does not require the kinematic or dynamic data y, according to the current belief µ, and another to
description of the manipulator, similarly to the AIC. describe the dynamics of the evolution of the belief µ.
1) Generative model of the sensory data: The sensory dynamical order. Similarly, for the state dynamics, the state
data is modeled using the following expression [8]: atacertaindynamicalorderarerelatedonlywiththosewhich
are one order below. Then, using the chain rule, it results:
y =g(µ)+z (4)
n (cid:89)d−1
where g(µ) represents the non-linear mapping between sen- p(µ˜,y˜)= p(y(i)|µ(i))p(µ(i+1)|µ(i)) (9)
sory data and states of the environment, and z is Gaussian
i=0
noisez ∼(0,Σ ).ThecovariancematrixΣ alsorepresents
y y Using the Laplace assumption, and thus considering Gaus-
the controller’s confidence about each sensory input.
sian distributed probability densities, we can write:
2) Generativemodelofthestatedynamics: Inpresenceof
(cid:110) (cid:111)
t g i e m n e er v a a ti r v y e in m g o st d a e te l s o x f , th th e e e c v o o n l t u r t o io ll n er µ ha (cid:48) s o t f o t e h n e co b d el e ie a f d µ yn . a T m h i i c s p(µ(i+1)|µ(i))= |Σ µ(i) 1 | √ n2π exp −1 2 ε( µ i)(cid:62)Σ− µ( 1 i) ε( µ i)
(cid:110) (cid:111)
generative model is defined as [8]: p(y(i)|µ(i))= |Σ y(i) 1 | √ n2π exp − 2 1ε( y i)(cid:62)Σ− y( 1 i) ε( y i) (10)
dµ
dt =µ(cid:48) =f(µ)+w (5) where ε y (i) =(y(i)−g(i)(µ)) and ε( µ i) =(µ(i+1)−f(i)(µ))
arerespectivelythesensoryandstatemodelpredictionerrors.
where f is a generative function dependant on the belief
Furthermore it holds:
about the states µ and w is Gaussian noise w ∼(0,Σ ).
µ
3) Generalised motions: To describe the dynamics of the ∂g ∂f
g(i) = µ(i), f(i) = µ(i), g(0) =g, f(0) =f
states, or better the belief about these dynamics, we have ∂µ ∂µ
(11)
tointroducetheconceptofgeneralisedmotions[25].Gener-
Substituting (9) in (8) leads to:
alisedmotionsareusedtorepresentthestatesofadynamical
system, using increasingly higher order derivatives of the n (cid:88)d−1
(cid:104) (cid:105)
states of the system itself. They apply to sensory inputs as F =− lnp(y(i)|µ(i))+lnp(µ(i+1)|µ(i)) (12)
well, meaning that the generalised motions of a position i=0
measurement, for example, correspond to its higher order
Finally, according to (10), F can be expressed up to a
temporal derivatives (velocity, acceleration, and so on). The
constant as a weighted sum of squared prediction errors:
use of generalised motions allows a more accurate descrip-
tion of the system’s states. More precisely, the generalised 1 n (cid:88)d−1 (cid:104) (cid:105)
F = ε(i)(cid:62)Σ−1 ε(i)+ε(i)(cid:62)Σ−1 ε(i) +K (13)
motions µ˜ of the belief under local linearity assumptions 2 y y(i) y µ µ(i) µ
[24] are, up to the second order: i=0
where n is the number of generalised motions chosen and
µ(cid:48) = µ(1) =f(µ)+w d
K is a constant term resulting from the substitution. The
∂f
µ(cid:48)(cid:48) = µ(2) = µ(cid:48)+w(cid:48) (6) minimisation of this expression can be done by refining the
∂µ internal belief, thus performing state estimation, but also
In general, we indicate the generalised motions of the states computingthecontrolactionstofulfillthepriorexpectations
up to order n
d
1 as µ˜ =[µ, µ(cid:48), µ(cid:48)(cid:48), µ(cid:48)(cid:48)(cid:48), ..., µ(nd)]. and achieve a desired motion. The constant term K is
Similarly, the generalised motions of the sensory input are: neglected in the sequel since it plays no role into the
minimisation problem. The next two subsections describe
y = y(0) =g(µ)+z the approach proposed by Friston [10], [27] to minimise F,
y(cid:48) = y(1) = ∂g µ(cid:48)+z(cid:48) (7) using gradient descent.
∂µ
C. Belief update for state estimation
We indicate the generalised motions of the sensory input up
to order n
d
as y˜=[y, y(cid:48), y(cid:48)(cid:48), y(cid:48)(cid:48)(cid:48), ..., y(nd)]. The belief update law for state estimation is determined
4) Generalfree-energyexpression: Withtheextratheoret- from the gradient of the free-energy, with respect to each
generalised motion [8], [25]:
icalknowledgeaboutthegeneralisedmotions,wecandefine
an expression for the free-energy for a multivariate case in d ∂F
µ˜˙ = µ˜−κ (14)
a dynamically changing environment: dt µ∂µ˜
F =−lnp(µ˜,y˜) (8) The learning rate κ , can be seen from a control perspective
µ
as a tuning parameter for the state update.
The joint probability p(µ˜,y˜) has to be specified. According
to [8] and to the definitions previously given, the noise D. Control actions
at each dynamical order is considered uncorrelated. Then,
In the free-energy principle the control actions play a
according to the generalised sensory input, the sensory data
fundamental role in the minimisation process. In fact, the
at a particular order relates only with the states at the same
control input u allows to steer the system to a desired state
while minimising the prediction errors in F. This is done
1Generalisedmotionscanextenduptoinfiniteorderbutthenoiseathigh
ordersispredominant,thuswecanlimitthechosenorderton d [26]. usinggradientdescent.Sincethefree-energyisnotafunction
ofthecontrolactionsdirectly,buttheactionsucaninfluence in such a way that they will reach the goal µ with the
d
F by modifying the sensory input, we can write [8]: dynamics of a first order system with unitary time constant:
∂F(µ˜,y˜(u)) ∂y˜(u)∂F(µ˜,y(u)) f(µ)=µ −µ (20)
= (15) d
∂u ∂u ∂y˜(u)
Thevalueµ isaconstant∈Rncorrespondingtothedesired
d
Droppingthedependenciesforamorecompactnotation,the set-point for the joints of the manipulator. Substituting (19)
dynamics of the control actions can be written as: and (20) in (7) and (6), it results:
∂y˜∂F (cid:40) (cid:40)
u˙ =−κ a∂u ∂y˜ (16) µ(cid:48) =µ d −µ+w y q =µ+z (21)
µ(cid:48)(cid:48) =−µ(cid:48)+w(cid:48) y =µ(cid:48)+z(cid:48)
q˙
where κ is the tuning parameter to be chosen.
a
According to (21) and (13), the free-energy expression for a
III. ROBOTARMCONTROLWITHACTIVEINFERENCE generic robot manipulator under the assumptions given is:
In this section we derive the first model-free, computa- 1
F = (y −µ)(cid:62)Σ−1 (y −µ)
tionally lightweight, online torque controller for joint space 2 q y(0) q
control using active inference. The established theory of + 1 (y −µ(cid:48))(cid:62)Σ−1 (y −µ(cid:48))
Sec. II is adapted to define a novel control scheme for a 2 q˙ y(1) q˙
generic n-DOF manipulator. The challenging problem of + 1 (µ(cid:48)+µ−µ )(cid:62)Σ−1 (µ(cid:48)+µ−µ )
finding suitable generative models f(·) and g(·), and the 2 d µ(0) d
1
relation ∂y˜/∂u in such a complex scenario is solved. + (µ(cid:48)(cid:48)+µ(cid:48))(cid:62)Σ−1 (µ(cid:48)(cid:48)+µ(cid:48)) (22)
Assumption 1: The robot manipulator is equipped with 2 µ(1)
positionandvelocitysensors,whichrespectivelyprovidethe B. Belief update and state estimation for a manipulator
two variables y , y ∈Rn.
q q˙ According to the free-energy principle, the states of the
Assumption 2: Since only the position and velocity mea- robot manipulator can be estimated using a gradient descent
surements are available, we will consider the generalised scheme. Applying (14), having defined F as in (22), leads
motions up to order two, so n d =2. to the following state update law:
Assumption 3: The Gaussian noise affecting the different
sensory channels is supposed uncorrelated [8], [24]. The µ˙ = µ(cid:48)+κ µ Σ− y( 1 0) (y q −µ)−κ µ Σ− µ( 1 0) (µ(cid:48)+µ−µ d )
covariance matrices for sensory input and state belief are: µ˙(cid:48) = µ(cid:48)(cid:48)+κ Σ−1 (y −µ(cid:48))−κ Σ−1 (µ(cid:48)+µ−µ )
µ y(1) q˙ µ µ(0) d
Σ =σ I , Σ =σ I , (17) − κ Σ−1 (µ(cid:48)(cid:48)+µ(cid:48))
y(0) q n y(1) q˙ n µ µ(1)
Σ µ(0) =σ µ I n , Σ µ(1) =σ µ(cid:48) I n (18) µ˙(cid:48)(cid:48) = −κ µ Σ− µ( 1 1) (µ(cid:48)(cid:48)+µ(cid:48)) (23)
where we supposed that the controller associates four differ- Note that κ is the tuning parameter for state estimation.
µ
ent variances to describe its confidence about sensory input
C. Control actions for a robot manipulator
and internal belief.
Assumption 4: The states of the environment x are set The final step in order to be able to steer the joints of a
as the joint positions of the robot arm. Doing so, we can robot manipulator to a desired value µ , is the definition of
d
control the robot arm in joint space through free-energy the control actions.
minimization, and simplify the equations for states update 1) General considerations: The general actions update is
and control actions. expressedby(16).Thepartialderivativesof(22)withrespect
to the generalised sensory input are given by:
A. Generative models and F for a robot manipulator
∂F ∂F
Inordertonumericallyevaluatethefree-energyasin(13), ∂y =Σ− y( 1 0) (y q −µ), ∂y =Σ− y( 1 1) (y q˙ −µ(cid:48)) (24)
the two functions g(µ) and f(µ) have to be chosen. q q˙
1) Generative model of the sensory data: g(µ) indicates Having said that, the actions update is expressed as:
the relation between the sensed values and the states. Since (cid:104) (cid:105)
u˙ =−κ ∂yqΣ−1 (y −µ)+ ∂yq˙Σ−1 (y −µ(cid:48)) (25)
we chose the states to be the joint positions and the sensory a ∂u y(0) q ∂u y(1) q˙
data provides directly the noisy values y and y , it holds:
q q˙ Active inference requires then to define the change in the
sensory input with respect to the control actions, namely
g (µ)=µ, ∂g /∂µ=1 (19)
q q
∂yq/∂u and ∂yq˙/∂u. This is usually a hard forward dynamic
2) Dynamic generative model of the world: Instead of problem, which constituted a major complication in past
modelling the true dynamics of the manipulator, we propose controlstrategies.Oneapproachtocomputetheserelationsis
to define a reference model to specify the desired behaviour throughonlinelearningusinghigh-dimensionalspaceregres-
oftherobot[8].Inparticular,theworlddynamicsarechosen sors. However, this increases the complexity of the overall
such that the robot is steered to a desired position µ . In scheme and can produce unreliable results, as shown by the
d
otherwords,thecontrollerbelievesthatthestateswillevolve authors in [15]. In this paper we propose to approximate
the partial derivatives relying on the high adaptability of the IV. MODELREFERENCEADAPTIVECONTROLLER
active inference controller against unmodeled dynamics, as The controller chosen for comparison is an MRAC. This
suggested in the conclusive remarks in [15]. adaptive controller allows to obtain decoupled joint dynam-
2) Approximation of the true relation between u and y˜:
ics, forcing every single joint i = 1,...,n to respond as a
Let us first analyse the structure of the partial derivative
second order linear system with transfer function:
matrices in (25). The control action is a vector of n torques
ω2
applied to the n joints of the robot manipulator. Each torque G (s)= i q (s) (28)
hasadirecteffectonlyonthecorrespondingjointtowhichit i s2+2ζω i s+ω i 2 ri
isapplied.Thisallowsustoconcludethat∂yq/∂uand∂yq˙/∂u Thecontrolarchitectureistakenfrom[20],wherethecontrol
are diagonal matrices. Furthermore, considering the second is specified in terms of feedforward and feedback adaptive
Newton’s law, the total torque applied to a rotational joint gainmatrices.Thesetime-varyinggainmatricesareadjusted
equals the moment of inertia times the angular acceleration. bymeansofadaptationlawstoguaranteeclosedloopstabil-
Thediagonaltermsofthepartialderivativesmatricesarethen ityincaseoflargeparametersperturbations.Supposingzero
time varying positive values which depend on the current initial conditions for the gains, and neglecting the derivative
robotconfiguration.Inotherwords,thismeansthatapositive terms as described in [20], it holds:
torque applied to a joint will always result in a positive (cid:90) T
contribution for both position and velocity of that specific K (t) = E q¯ (t)q(t)(cid:62)+E q¯ (τ)q(τ)dτ (29)
0 01 e 02 e
joint. In this control scheme we propose to approximate the 0
(cid:90) T
true positive time-varying relation with a positive constant, K (t) = E q¯ (t)q˙(t)(cid:62)+E q¯ (τ)q˙(τ)dτ (30)
1 11 e 12 e
making use of the learning rate κ as tuning parameter to
a 0
achieveasufficientlyfastactionsupdate.Thecontrolupdate (cid:90) T
Q (t) = F q¯ (t)q (t)(cid:62)+F q¯ (τ)q (τ)dτ (31)
law is finally given by: 0 01 e r 02 e r
0
u˙ =−κ a (cid:104) C q Σ− y( 1 0) (y q −µ)+C q˙ Σ− y( 1 1) (y q˙ −µ(cid:48)) (cid:105) (26) Q (t) = F q¯ (t)q˙ (t)(cid:62)+F (cid:90) T q¯ (τ)q˙ (τ)dτ (32)
1 11 e r 12 e r
∂y ∂y 0
q ≈C , q˙ ≈C (27) (cid:90) T
∂u q ∂u q˙ f(t) = α q¯ (t)+α q¯ (τ)dτ (33)
1 e 2 e
The positive definite diagonal constant matrices C , C are 0
q q˙
then set to the identity, meaning that we only encode the The variables q r and q˙ r are the desired references to track.
sign of the relation between u and the change in y˜. The diagonal matrices E jk and F jk ∈Rn×n, and the vector
3) TuningparametersAIC: Thetuningparametersforthe α k ∈ Rn with j = {0,1} and k = {1,2}, are the tuning
active inference controller are: parameters for the proportional-integral adaptation law. The
• σ q , σ q˙ , σ µ , σ µ(cid:48) : the standard deviations representing term q¯ e is called modified joint angle error vector [20]:
the confidence of the controller regarding its sensory
q¯ =P [q (t)−q(t)]+P3[q˙ (t)−q˙(t)] (34)
e 2 r r
input and internal belief about the states;
• κ µ , κ a : the learning rates for state update and control with P2 and P3 diagonal weighting matrices. The MRAC,
actions respectively. similarly to the AIC, does not need the dynamic description
of the robot manipulator, and it is scalable to high DOF.
Algorithm 1 reports the pseudo-code of our AIC. For state
However,thenumberofthetuningparametersincreaseswith
and actions update, first-order Euler integration is used.
the degrees of freedom, unlike for the AIC.
Algorithm 1 AIC for robot control
V. EXPERIMENTALEVALUATION
Initialization
The adaptive properties of AIC and MRAC are now
Par ←σ , σ , σ , σ , κ , κ (cid:46) Set AIC parameters
q q˙ µ µ(cid:48) µ a compared: The controllers are tuned in simulation using an
µ=y ∈Rn (cid:46) Initialise belief
q approximated model of the robot, and then transferred to
µ(cid:48) =y ∈Rn
q˙ the real system. The tests performed are based on a pick
µ(cid:48)(cid:48) =0∈Rn
and place cycle using the Franka Emika Panda 7-DOF robot
u=0∈Rn (cid:46) Initialise torque commands
manipulator, as in Fig. 1, with different payloads.
µ ∈Rn (cid:46) Set prior, desired goal
d
Control Loop (cid:46) At high frequency
y , y (cid:46) Retrieve sensory input
q q˙
µ˜˙ = dµ˜−κ ∂F (cid:46) Belief dynamics (14)
dt µ∂µ˜
µ˜ =µ˜+∆ µ˜˙ (cid:46) Belief update, integration
t
u˙ =−κ ∂y˜∂F (cid:46) Action dynamics (16)
a∂u ∂y˜
u=u+∆ u˙ (cid:46) Action update, integration
t
return u (cid:46) Commanded torque
Fig.1. Simulatedandrealrobotforpickandplacecycle.
A. Remarks about the tuning procedure for the controllers
Before presenting the simulations and experimental re-
sults, we provide some observations regarding the number
of parameters and the different tuning procedures for the
AIC and MRAC.
1) Number of tuning parameters: The number of tuning
parametersfortheMRACequalsthenumberofDOFstimes
the number of weighting terms. According to Sec. IV, this
resultsin17×nparameterstobetuned.RegardingtheAIC,
instead,thenumberoftuningparametersisindependentfrom
the DOFs and it equals 6, following the formulation pre-
sented in Sec. III. The lower number of parameters resulted
in an overall easier tuning procedure for the active inference
controller. As a final remark, to modify the behaviour of the
stepresponsefortheAIC,suchasrisetimeandsettlingtime,
oneshouldchangetheinternalreferencemodelf(µ)instead
of fine tuning the controller’s parameters.
2) AIC tuning procedure: To obtain a satisfactory re-
sponse for the AIC, we performed the following steps:
1) We set the controller confidence about sensory input and
internalbelieftoone;2)Wedisabledthecontrolactionsand
incrementedthelearningrateκ untilthestateestimationin
µ
astaticsituationwasfastenough;3)Weincludedthecontrol Fig.2. Responseandcontrolactionsforthe7-DOFrobotarmcontrolled
throughAICandMRACwithapproximateddynamics.
actionsandincreasedthelearningrateκ untiltherobotwas
a
steered to the desired position, showing significant oscilla-
tions; 4) We dampened the oscillatory behaviour decreasing Second, the AIC and MRAC are re-tuned in the real robot
the sensory confidence about the most noisy sensors and the and used to pick and place different objects. The real setup
internal belief about velocities. is controlled using a standard laptop running Ubuntu 16.04
with RT kernel, 8-cores Intel i7-4710MQ 2.50GHz.
B. Simulations with approximated model
1) Pickandplacecycleontherealrobot: Weappliedthe
The performance of AIC and MRAC in simulation are
MRAC and AIC from simulation to the real 7-DOF Franka
now presented. The task is a pick and place cycle where the
Emika Panda. It is important to notice that, besides having
desired joint values are chosen such that the arm simulates
differentphysicalparameters,therealsetupisalreadygravity
the pick and place of an object from one bin to the other,
compensated. The AIC and MRAC are simply applied on
positioning the end-effector in A, B or C, see Fig 1. This
top of this intrinsic controller. This is already a considerable
is achieved giving every 6 [s] a set-point in joint space
change in the system’s dynamics, but to further increase the
following the sequence: q , q , q , q , q , where:
A B C B A levelofuncertainties,anend-effectorisattachedtotherobot.
• q A =[1, 0.5, 0, −2, 0, 2.5, 0] [rad] From a modeling point of view, the system used for tuning
• q B =[0, 0.2, 0, −1, 0, 1.2, 0] [rad] the controllers in simulation is completely different from
• q C =[−1, 0.5, 0, −1.2, 0, 1.6, 0] [rad] the real one. Usually, a controller tuned in simulation will
The controllers have been tuned using a considerably inac- not directly work on a real setup, especially if the initial
curate model of the robot arm on purpose. The links have model was not accurate. This was indeed the case for the
been approximated as cuboids, and 20% random uncertainty MRAC which, when transferred to the real robot, could
in each link’s mass has been assumed. This will allow to not control the setup leading to an immediate safety stop.
evaluatelaterontheadaptabilityperformancewhileapplying Nonetheless, this was not the case for our novel AIC: its
the controllers to the real manipulator. The joint values and strongcapabilitiestocopewithunmodeleddynamicsallowed
controlactionsusingAICandMRAC,aredepictedinFig.2. totransferthecontrollerfromthesimulationtotherealsetup
Note that, for the MRAC, saturation of the control input at withoutre-tuning.Forclarity,weonlyreporttheresponseof
±85Nm is reached for some of the joints, after providing the AIC during the initial part of the pick and place cycle
the new goal position. (q →q →q ) in Fig. 3. Joint 7 is not reported to limit
B A B
redundantinformation,sincenomotionwasrequired.Ascan
C. Experiments on the real setup
be seen the AIC can successfully control the manipulator,
The same controllers tuned in simulation using the ap-
however, the effect of the large uncertainties introduced
proximated model of the 7-DOF robot arm are now applied
for the tuning, resulted in some initial jittering, especially
to control the real manipulator. Two tests are performed:
in joint 62. In other words, the AIC tuned in simulation
first, the pick and place cycle of the previous section is
repeated in the real robot, without re-tuning the controllers. 2https://youtu.be/Vsb0MzOpTY
Fig.3. AIConrealsetupwithoutre-tuningfromsimulation.Focusoninitialpartofthepickandplacecycle(qB →qA→qB)tohighlightjittering
Fig.4. (A)Liftandplaceofemptybottle.(B)Differenceoftrajectoriesbetweenemptyandfilledbottleduringlift,place,andrelease
resulted too aggressive for the real robot. This is because in in Fig. 4B we show the difference of the trajectories in
simulationtheAIChadtocompensatealsoforgravity,thusa joint space between the case with empty and full bottle,
fastertorqueupdatewasrequired.Thelearningrateκ isthe considering lifting, placing and releasing. Both controllers
a
same for every joint but the jittering effect is mostly visible adapt to the heavier payload, making the trajectory converge
in joint 6. This is because in the last part of the kinematic to the one with lightweight bottle. AIC behaves similarly
chain, the resulting inertia acting on a joint is lower, and so to the MRAC, yet it presents considerably less oscillations
it is its reluctance to changes in velocities. To completely which reflected in smoother placing of the heavy object.
remove the jittering, one can simply reduce the learning rate The bigger error appearing at around 16 [s] is due to the
κ to lower the torque update rate. The AIC and MRAC releasing of the heavy object. The effect is more visible in
a
have been tested against large external disturbances such as the AIC since the robot is more compliant. In a sense, the
ahumanpushingtherobotduringmotion.AICresultedmore AICbehavessimilarlytoahuman arm,whenanunexpected
compliantthanMRAC,showingatthesametimeafasterand weight is dropped. This is an additional evidence of the bio-
less oscillatory disturbance rejection. inspired character of the controller. The AIC can also be
2) Pick and place with different payloads: In order to tuned to be stiffer if this effect is not desired.
use the MRAC on the real robot, a severe re-tuning of 63
D. Discussion and implementation notes
parametershadtobeperformed,tostabilisetheresponsedue
to the large unmodeled dynamics. For the AIC, κ has been Our novel AIC showed high adaptability, allowing to
a
reduced to eliminate the jittering, as well as σ , σ to give transferfromsimulationtorealrobotwithoutre-tuning.Fur-
q q˙
more importance to the measurements and further reduce thermore,theAICshowedsuperiorperformancewithrespect
oscillations. The two controllers are used to perform a pick to the MRAC in pick and place scenarios. The AIC is com-
and place of an almost empty water bottle (≈0.1 [kg]) and pliant while allowing to compensate for large perturbations.
a full water bottle (≈0.7 [kg]), as in Fig. 1. In Fig. 4A we However, even though there is a strong evidence of stability
showtheresponsesofAICandMRACincaseofthealmost and robustness of the AIC for a complex non-linear system,
empty bottle, during lifting and placing. As can be seen, the finding a formal stability proof is still an open question.
AIC presents a faster convergence to the set-point, as well Similarly to a linear case, one should determine a set of
as smoother trajectories with less oscillations. To achieve a learning rates which guarantees convergence. Intuitively, ac-
satisfactory response, we had to increase the stiffness of the tiveinferenceisagradientdescentonaquadraticandconvex
MRAC,whiletheAICcouldbekeptcompliant.Furthermore, function thus, for some set of learning rates, the algorithm
should converge to the global minima. A possible approach working on active inference at the Cognitive Robotics de-
to a formal proof is to use Lyapunov theory as for the back- partment.
propagation algorithm in neural networks. Active inference
REFERENCES
is, in a sense, back-propagating the sensitivity of the control
inputwithrespecttothefree-energy,tominimiseF.Properly [1] S.VijayakumarandS.Shaal,“Locallyweightedprojectionregression:
Incrementalrealtimelearninginhighdimensionalspace,”inProc.of
addressing this proof mathematically would require a deep
Int.Conf.onMachineLearning(ICML),2000,pp.1079–1086.
analysis which is out of the scope of the current paper. [2] D.Nguyen-Tuong,J.Peters,andM.Seeger,“Localgaussianprocess
Another remark relates to the computational load of AIC. regression for real time online model learning,” in Proc of Neural
InformationProcessingSystems(NIPS2008),2008,pp.1193–1200.
According to Algorithm 1, our novel AIC has a computa-
[3] M.Matteucci,“Elearnt:Evolutionarylearningofrichneuralnetwork
tional complexity of O(n) where n is the number of DOFs. topologies,” Carnegie Mellon University, 2006, technical repository
Given the structure of the generative models and covariance No.CMU-CALD-02.
[4] F. Ledezma and S. Haddadin, “First-order-principles-based construc-
matrices chosen, the AIC reduces to 16 sums of vectors and
tivenetworktopologies:Anapplicationtorobotinversedynamics,”in
15 scalar-vector multiplications with n-dimensional vectors. IEEE-RAS17thInt.Conf.onHumanoidRobotics(Humanoids),2017.
On the other hand, the complexity of the MRAC is O(n3). [5] D. Keppler, F. Peters, N. Ratliff, and S. Shaal, “A new data source
for inverse dynamics learning,” in Proc of IEEE/RJS Conference on
Another optimised computed torque algorithm such as LGP
IntelligentRobotsandSystems,2017.
[28], which relies on learning dynamical models, has a cost [6] L.Jamone,B.Damas,andJ.Santos-Victor,“Incrementallearningof
of O(N2) for online learning, where N is the number of context-dependentdynamicinternalmodelsforrobotcontrol,”inProc.
oftheIEEEInt.SymposiumonIntelligentControl(ISIC),2014.
data points (i.e. N ≈300). Finally, the Franka Emika Panda
[7] K. J. Friston, J. Mattout, and J. Kilner, “Action understanding and
requires the control signals to be ready within 300 [µs] to activeinference,”Biologicalcybernetics,vol.104(1-2),2011.
guarantee a functioning frequency of 1 [kHz]: Our AIC can [8] C. Buckley, C. Kim, S. McGregor, and A. Seth, “The free energy
principleforactionandperception:Amathematicalreview,”Journal
performatsuchahighloopratewithoutanypackageloss;is
ofMathematicalPsychology,vol.81,pp.55–79,2017.
straightforward to implement; and extremely simple to tune. [9] R. Bogacz, “A tutorial on the free-energy framework for modelling
The source code for simulations3 and experiments4 is freely perceptionandlearning,”Journalofmathematicalpsychology,2015.
[10] K. J. Friston, “The free-energy principle: a unified brain theory?”
available on GitHub.
NatureReviewsNeuroscience,vol.11(2),pp.27–138,2010.
[11] K. J. Friston, J. Daunizeau, and S. Kiebel, “Action and behavior: a
VI. CONCLUSION
free-energyformulation,”Biologicalcybernetics,vol.102(3),2010.
In this paper we derived the first active inference torque [12] L.Pio-Lopez,A.Nizard,K.Friston,andG.Pezzulo,“Activeinference
and robot control: a case study,” Journal of The Royal Society
controller for online joint space control of robot manipula-
Interface,vol.13(122),2016.
tors. Our approach makes use of the alleged adaptability of [13] A.C.Mercade´,“Robotmanipulatorcontrolundertheactiveinference
active inference, to introduce simplifications for the gener- framework,”(UnpublishedMScthesis),TUDelft,2018.
[14] P.LanillosandG.Cheng,“Adaptiverobotbodylearningandestima-
ative models, obtaining a model-free scheme which is less
tionthroughpredictivecoding,”in(IROS),2018.
sensitive to unmodeled dynamics, is easily scalable to high [15] P. Lanillos and G.Cheng, “Active inference with function learning
DOF and is computationally inexpensive. With the proposed for robot body perception,” in International Workshop on Continual
UnsupervisedSensorimotorLearning(ICDL-Epirob),2018.
controller structure we overcame the complexity barrier of
[16] G.Oliver,P.Lanillos,andG.Cheng,“Activeinferencebodypercep-
previous approaches, making possible control loops at high tionandactionforhumanoidrobots,”arXiv:1906.03022v2,2019.
frequencywithactiveinference.Simulationsandexperiments [17] K.Astrom,“Theoryandapplicationsofadaptivecontrol-asurvey,”
Automatica,vol.Vol.19,No.5,pp.471–486,1983.
inarealsetupwitha7-DOFrobotarmshowedthatourAIC
[18] T.Hsia,“Adaptivecontrolofrobotmanipulators-areview,”inProc
issuitablefortasksinwhichthedynamicmodeloftheplant ofIEEEInt.conf.onroboticsandautomation(ICRA),1986.
is unknown or subject to large changes. The performance [19] D. D. Zhang and B. Wei, “A review on model reference adaptive
controlofroboticmanipulators,”AnnualReviewsinControl,vol.43,
of our novel AIC has been compared with that of a state-
2017.
of-the-art MRAC, in different pick and place scenarios. The [20] M. Tarokh, “Hyperstability approach to the synthesis of adaptive
AICshowsbetteradaptabilityproperties,allowingtotransfer controllers for robot manipulators,” in Proc of IEEE international
conferenceonroboticsandautomation(ICRA),1991.
from simulation to real setup without re-tuning. In addition,
[21] R. Walters and M. Bayoumi, “Application of a self-tuning pole-
the AIC resulted easier to tune and implement. With this placementregulatortoanindustrialmanipulator,”inProcof21stIEEE
work we confirmed the value of active inference to develop ConferenceonDecisionandControl,1991,pp.323–329.
[22] A. Koivo and T. Guo, “Adaptive linear controller for robotic manip-
more adaptive control of robot manipulators. This is only
ulators,” IEEE Transactions and Automatic Control, vol. AC-28, pp.
the first step in this direction, future work should proof the 162–171,1983.
closed-loop stability of active inference, define generative [23] D.Lindley,“Bayesianstatistics,areview,”SIAM,vol.2,1972.
[24] K.Friston,J.Mattout,N.Trujillo-Barreto,J.Ashburner,andW.Penny,
models to account for dynamic requirements and motion
“Variationalfreeenergyandthelaplaceapproximation,”Neuroimage,
constraints,andbeextendedtoothercontrolmodalities,such vol.34(1),pp.220–234,2007.
as control in Cartesian space or impedance control. [25] K. Friston, K. Stephan, B. Li, and J. Daunizeau, “Generalised filter-
ing,”MathematicalProblemsinEngineering,2010.
ACKNOWLEDGMENT [26] K. Friston, “Hierarchical models in the brain,” PLoS computational
biology,vol.4(11),e1000211,2008.
The authors would like to thank Prof. Dr. Martijn Wisse [27] K. Friston, J. Daunizeau, and S. Kiebel, “Reinforcement learning or
for the helpful discussions, together with the whole group activeinference?”PloSone,vol.4(7),e6421,2009.
[28] D. Nguyen-Tuong andJ. Peters, “Learning robotdynamics for com-
puted torque control using local gaussian processes regression,” in
3https://github.com/cpezzato/pandasimulation
Symp.onLearningandAdaptiveBehaviorsforRoboticSystems,2008.
4https://github.com/cpezzato/activeinference