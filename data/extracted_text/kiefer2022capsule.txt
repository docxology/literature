Capsule Networks as Generative Models
Alex B. Kiefer∗1,2, Beren Millidge∗1,3, Alexander Tschantz∗1, and
Christopher L Buckley1,4
1 VERSES Research Lab
2 Monash University
3 MRC Brain Network Dynamics Unit, University of Oxford
4 Sussex AI Group, Department of Informatics, University of Sussex
Abstract. Capsule networks are a neural network architecture special-
ized for visual scene recognition. Features and pose information are ex-
tracted from a scene and then dynamically routed through a hierarchy of
vector-valued nodes called ‘capsules’ to create an implicit scene graph,
with the ultimate aim of learning vision directly as inverse graphics. De-
spite these intuitions, however, capsule networks are not formulated as
explicit probabilistic generative models; moreover, the routing algorithms
typically used are ad-hoc and primarily motivated by algorithmic intu-
ition. In this paper, we derive an alternative capsule routing algorithm
utilizing iterative inference under sparsity constraints. We then introduce
an explicit probabilistic generative model for capsule networks based on
the self-attention operation in transformer networks and show how it is
related to a variant of predictive coding networks using Von-Mises-Fisher
(VMF) circular Gaussian distributions.
1 Introduction
Capsule networks are a neural network architecture designed to accurately cap-
ture and represent part-whole hierarchies, particularly in natural images [17,
18, 39], and have been shown to outperform comparable CNNs at visual object
classiﬁcation, adversarial robustness, and ability to segment highly overlapping
patterns [18, 39]. A capsule network comprises layers of ‘capsules’ where each
capsule represents both the identity and existence of a visual feature as well as
its current ‘pose’ (position, orientation, etc.) relative to a canonical baseline.
This approach is heavily inspired by the concept of a scene graph in computer
graphics, which represents the objects in a scene in precisely such a hierarchical
tree structure where lower-level objects are related to the higher-level nodes by
their pose. The capsule network aims to ﬂexibly parameterize such a scene graph
as its generative model and then perform visual object recognition by inverting
this generative model [16,17] to infer 3D scene structure from 2D appearances.
It is argued that the factoring of scene representations into transformation-
equivariant capsule activity vectors (i.e. vectors that change linearly with trans-
lation, rotation, etc.) and invariant pose transformation matrices is more ﬂexi-
ble and eﬃcient than the representation used in convolutional neural networks,
arXiv:2209.02567v2  [q-bio.NC]  6 Oct 2022
2 Kiefer, Millidge, Tschantz, et al
where activities in higher layers are merely invariant to changes in viewpoint. In
addition to arguably providing a better scene representation, capsule networks
can use agreement between higher-level poses and their predictions based on
lower-level poses to solve the binding problem of matching both the ‘what’ and
the ‘where’ of an object or feature together.
Capsule networks are in part motivated by the idea that ‘parse-trees’ of the
object hierarchy of a scene must be constructed at run-time, since they can
be diﬀerent for diﬀerent images. Crucially, it is assumed that this dynamically
constructed parse-tree must be sparse and almost singly connected - each low-
level capsule or feature can be matched to only one high-level parent. This is
because in natural scenes it is sensible to assume that each feature only belongs
to one object at a time – for instance, it is unlikely that one eye will belong to two
faces simultaneously. In [39], it is proposed to dynamically construct these parse-
trees by an algorithm called ‘routing by agreement’ whereby low-level capsules
are assigned to the high-level capsule whose pose matrix most closely matches
their pose matrix under certain transformations.
While capsule networks appear to be a highly eﬃcient architecture, invented
using deep insights into the nature of visual scenes, there are, nevertheless, many
elements of the construction that appear relatively ad-hoc. There is no construc-
tion of an explicit probabilistic generative model of the network. Moreover, it is
unclear why the routing algorithm works and how it is related to other frame-
works in machine learning. Indeed, some research [31, 36] suggests that typical
routing algorithms do not perform well which suggests that the goals of routing
are better attained in some other way.
In this paper we propose a probabilistic interpretation of capsules networks in
terms of Gaussian mixture models and VMF (circular Gaussian) distributions,
which applies the self-attention mechanism used in modern transformer net-
works [15,47]. We argue that fundamentally, the purpose of the original routing-
by-agreement algorithm of [39] is to approximate posterior inference under a
generative model with the particular sparsity structure discussed above. We
ﬁrst demonstrate in experiments that we can achieve routing-like behaviour us-
ing sparse iterative inference, and show in addition that even in the original
implementation of dynamic routing in capsules [39], sparsity of the top-level
capsules is enforced via the margin loss function alone when iterative routing is
turned oﬀ. This loss function can be interpreted as implementing a low-entropy
prior on digit classes. We then write down a principled top-down generative
model for capsules networks that provides a plausible description of the model
that routing attempts to approximately invert. Overall, our results aim to pro-
vide a clear and principled route toward understanding capsule networks, and
interpreting the idea of routing as fundamentally performing sparse iterative in-
ference to construct sparse hierarchical program trees at runtime – a method
that can be implemented in many distinct ways.
Capsule Networks as Generative Models 3
2 Capsule Networks
A capsule network comprises a hierarchical set of layers each of which consists of
a large number of parallel capsules. In practice, several non-capsule layers such
as convolutional layers are often used to provide input data preprocessing. We
do not consider non-capsule layers in this analysis.
Each capsule j in a layer receives an input vector sj consisting of a weighted
combination of the outputs of the capsules i in the layer below, multiplied by
their respective aﬃne transformation matrices Ti,j, which deﬁne the invariant
relationships between the poses represented by iand j. The input from capsule i
is denoted ˆuj|i = Ti,jvi, where vi is the output activity of capsuleiafter its input
has been passed through a ‘squash’ nonlinearity deﬁned as f(x) = ||x||2
1+||x||2 · x
||x||.
The higher-level capsule then weights the contributions from its low-level input
capsules by weighting coeﬃcients ci,j which are determined by iterative routing.
To obtain the output of the capsule, all its inputs are weighted and summed and
then the output is fed through the nonlinear activation function f. The forward
pass of a capsule layer can thus be written as,
v(l)j = f(
∑
i
ci,jTi,jv(l−1)i
) (1)
The core algorithm in the capsule network is the routing-by-agreement algo-
rithm which iteratively sets the agreement coeﬃcients ci,j:
bk
i,j = bk−1
i,j + (Ti,jv(l−1)i
)T vk−1
(l)j
ck
i = σ(bk−1
i )
(2)
where k is the iteration index of the routing algorithm, σ(x) is the softmax
function such that σ(x)i = exp(xi)∑
j exp(xj) , and bk
i are the logit inputs to the softmax
at iteration k, which act as log priors on the relevance of lower-level capsule i’s
output to all the higher-level capsules. These are initialized to 0 so all capsules
are initially weighted equally.
The routing algorithm weights the lower-level capsule’s contribution to de-
termining the activities at the next layer by the dot-product similarity between
the input from the low-level capsule and the higher-level capsule’s output at the
previous iteration. Intuitively, this procedure will match the pose of the higher-
level capsule and the ‘projected pose’ ˆ uj|i = Ti,jv(l−1)i
from the lower-level
capsule, so that each lower-level capsule will predominantly send its activity
to the higher-level capsule whose pose best ﬁts its prediction. In addition to
matching parts to wholes, this procedure should also ensure that only higher-
level capsules that receive suﬃciently accurate pose-congruent ‘votes’ from the
capsules below are activated, leading to the desired sparsity structure in the
inferred scene representation.
4 Kiefer, Millidge, Tschantz, et al
3 Sparse Capsule PCN
Intuitively, the goal of routing is to match the poses of higher- and lower-level
capsules and thus to construct a potential parse tree for a scene in terms of
relations between higher-level ‘objects’ and lower-level ’features’. Crucially, this
parse tree must be highly sparse such that, ideally, each lower-level feature is
bound to only a single high-level object. To represent uncertainty, some assign-
ment of probability to other high-level capsules may be allowed, but only to a
few alternatives.
We argue that all of this is naturally accommodated if we interpret routing
as implementing sparse iterative inference, where the sparsity constraints derive
from an implicit underlying generative model. This is because the fundamental
goal of routing is to obtain a ‘posterior’ over the capsule activations throughout
the network given the input as ‘data’. Unlike standard neural networks, this
posterior is not only over the classiﬁcation label at the output but over the
‘parse tree’ comprising activations at the intermediate layers. Taking inspiration
from Predictive Coding Networks (PCNs) [3,6,12,27], we can imagine the parse
tree posterior as being inferred in a principled way through iterative variational
inference [2, 48] applied to the activities at each layer during a single stimulus
presentation.
The idea of using variational inference to perform capsule routing is also
explored and shown to be very eﬀective in [38]. Most closely related to our aims
here, [42] propose a full generative model and variational inference procedure for
capsules networks, focusing instead on the E-M routing version of capsules [18] in
which existence is explicitly represented using a distinct random variable. They
show that performing iterative inference to further optimize solutions at test
time leads to improved digit reconstructions for rotated MNIST digits. [28] also
proposes a generative model that aims to capture the intuitions behind capsule
networks, and likewise derives a variational inference scheme for inverting this
model.
There are various ways to achieve sparsity. [36] investigated unsupervised
versions of capsules networks, and found that while routing in the CapsNet
architecture did not produce the intended eﬀects (i.e. sparse activations at each
capsule layer and feature equivariance) without supervision at the output layer,
these properties could be restored by adding a sparsity constraint adapted from
k-sparse autoencoders [24]. A ‘lifetime sparsity constraint’ that forces all capsules
to be active a small fraction of the time was also found to be necessary to
discourage solutions in which a small number of capsules are used to reconstruct
the input and the rest are ignored (which interferes with the ability to learn
the desired equivariances). We experiment with a simpler form of sparsity in
combination with iterative PC inference, using an L1 penalty, which is known to
encourage sparsity, as an additional regularizing term added to the free energy.
In Appendix B, we demonstrate this eﬀect on a toy two-layer network where
sparse iterative inference routs all inputs through a speciﬁc intermediate layer,
thus constructing a single preferred parse-tree.
Capsule Networks as Generative Models 5
3.1 Experiments
To test our interpretation of iterative routing-by-agreement as inference under
sparsity constraints, we investigated the role of routing in the canonical ‘Cap-
sNet’ capsules network proposed in [39]. This network, diagrammed in Fig. 1A,
consists of a preliminary conventional convolutional layer, followed by a convolu-
tional capsules layer, and a ﬁnal layer whose ten capsules are meant to represent
the presence of the digits 0-9 in input images. Three iterations of the routing-
by-agreement algorithm are used between the two capsules layers.
Fig. 1.A: CapsNet architecture. Input (left) is passed through Conv1, yielding 256
feature maps which provide the input to the ﬁrst (convolutional) capsules layer, Pri-
maryCaps. This yields 1152 (32 dimensions x 6 * 6 output) 8-dimensional capsules,
which are each connected to each of the 10 16-dimensional DigitCaps via their own
transformation matrices. The L2 norms of the digit capsules are then compared with a
one-hot encoding of the target. The auxiliary reconstruction network is not pictured.
Rows B-E: Samples of DigitCaps activity vectors for test set examples under varying
conditions. Red borders indicate correct digits and the number above each box is the
corresponding vector norm. B: DigitCaps activities using a network trained with three
iterations of dynamic routing. Sparsity is clearly enforced at the capsule level, though
it is more extreme in some cases than others. C: Two random activity vectors from
an otherwise identical network trained without routing. Note that the ambiguous im-
age on the left predictably leads to less decisive capsule outputs (note also that this
occurrence was not unique to the no-routing condition). D: Capsule network trained
without routing, with 500 iterations of iterative inference performed in place of routing
at inference time. E: Same as (D) but with an L1 regularization term on the capsule
activities (i.e. Σj ∥vj ∥) added to the standard predictive coding (squared prediction
error) loss function.
6 Kiefer, Millidge, Tschantz, et al
In the experiments reported in [39], the network is trained to classify MNIST
digits via backpropagation, using a separate ‘margin loss’ function for each digit:
Lk = Tk max (0,m+ −∥vk∥)2 + λ(1 −Tk) max (0,∥vk∥−m−)2 (3)
Here, Lk is the margin loss for digit k (0 through 9), Tk is a Boolean indicating
the presence of that digit in the input image, ∥vk∥is the L2 norm of capsule out-
put vk, and m+ and m−are thresholds used to encourage these vector norms to
be close to 1 or 0, in the digit-present or digit-absent conditions, respectively. λ
is an additional term used to down-weight the contribution of negative examples
to early learning. In the full CapsNet architecture, this loss is combined with a
downweighted reconstruction regularization term from an auxiliary reconstruc-
tion network used to encourage capsule activities to capture relevant features in
the input.
In our experiments, we ﬁrst trained a standard CapsNet on MNIST for 13
epochs, using the same hyperparameters and data preprocessing as in [39]. It is
worth noting that, as a baseline for comparison, CapsNet does indeed produce
sparse higher-level capsule activations (i.e. sparsity in the vector of L2 norms of
the activity vectors of each of the 10 capsules in the DigitCaps layer). However,
in Fig. 1C we show that training the same network architecture with 0 rout-
ing iterations (simply setting the higher-level capsule activities to the squashed
sum of the unweighted predictions from lower layers) produces sparsity as well,
suggesting that the transformation matrices learn to encode this sparsity struc-
ture based on the margin loss function alone. In addition to exhibiting simi-
lar higher-level capsule activities, the two networks also performed comparably
(with > 99% accuracy on the test set) after training, though the no-routing
network was initially slower to converge (see Appendix A).
To test whether the intuitions explored in the toy example in Appendix
B would play out in a larger-scale architecture, we also tried using iterative
inference in place of dynamic routing. In these experiments, we began with a
forward pass through a trained CapsNet, clamped the target (label) nodes, and
ran iterative inference for 500 iterations with a learning rate of 0 .01, either with
the standard squared-error predictive coding objective or with the standard PC
loss plus L1 regularization applied to the ﬁnal output vector of the CapsNet
(see Appendix C). We found that, as in the toy experiment, standard iterative
inference with an L1 penalty (in this case applied per-capsule) produced sparse
outputs, while without the L1 penalty activity was more evenly distributed over
the capsules, though the vector norms for the ‘correct’ capsules were still longest.
Overall, our ﬁndings on CapsNet are consistent with results reported in [36],
which suggest that the sparsity seen at the output layer of CapsNet is at-
tributable to its supervised learning objective alone and does not occur without
this objective. Further conﬁrming these results, we performed experiments on
a modiﬁcation of CapsNet with an intermediate capsule layer between Prima-
ryCaps and DigitCaps, and did not observe sparsity in the intermediate-layer
activities despite comparable performance. Despite our largely negative ﬁndings,
these experiments support our broader view that the main point of routing is to
Capsule Networks as Generative Models 7
induce sparsity in the capsule outputs, and that this objective can be achieved
by various means, including iterative inference in a predictive coding network. In
the following section we propose an explicit generative model for capsules that
produces the right kind of sparsity in a principled way.
4 A Generative Model for Capsules
To be fully consistent with the goal of learning vision as inverse computer graph-
ics, a capsules network should be formulated as a top-down model of how 2D
appearances are generated from a hierarchy of object and part representations,
whose inversion recovers a sensible parse-tree. We now develop an explicit prob-
abilistic generative model for the capsule network that achieves this which, in-
terestingly, involves the self-attention mechanism used in transformer networks.
4.1 Attention and the Part-Whole Hierarchy
In recent years it has become increasingly clear that neural attention [15, 47]
provides the basis for a more expressive class of artiﬁcial neural network that
incorporates interactions between activity vectors on short timescales. As noted
in [39], while conventional neural networks compute their feedforward pass by
taking the dot products of weight vectors with activity vectors, neural atten-
tion relies on the the dot product between two activity vectors, thus producing
representations that take short-term context into account. In particular, atten-
tion allows for the blending of vectors via a weighted sum, where the weights
depend on dot-product similarities between input and output vectors. The core
computation in neural attention can be written as,
Z = σ(QKT )V (4)
with Z being the output of the attention block,K,Q,V being the ‘Key’, ‘Query’,
and ‘Value’ matrices, and σ the softmax function, as above. Intuitively, the at-
tention operation can be thought of as ﬁrst computing ‘similarity scores’ between
the query and key matrices and then normalizing them with the softmax. The
similarity scores are then multiplied by the value matrix to get the output. In
the transformer architecture [1, 47], these matrices are typically produced from
a given input representation (e.g. a word embedding) via a learned linear trans-
formation.
There is a tempting analogy between the capsule layer update and neural
attention, since the output capsule activities are determined as a blend of func-
tions of the inputs, using weights determined by applying the softmax function
to dot-product similarity scores. A key diﬀerence, which seems to ruin the anal-
ogy, is that in routing-by-agreement, each of the weights that determine the
output mixture comes from a distinct softmax, over the outputs of one lower-
level capsule. Simply swapping out a neural attention module for the routing
8 Kiefer, Millidge, Tschantz, et al
algorithm gives the wrong result however, since this enforces a ‘single-child con-
straint’ where in the limit each higher-level object is connected to at most one
lower-level part in the parse-tree.
It turns out however that the attention mechanism is precisely what is needed
to naturally construct a top-down generative model of parse trees within a cap-
sules architecture. Firstly, we note that we can aggregate the small transforma-
tion matrices Ti,j connecting input capsule i to output capsule j into a large
tensor structure W =


T1,1 ... Tm,1
... ... ...
T1,n ... Tm,n

, for m lower-level and n higher-level
capsules. Similarly, the N individual d-dimensional capsule vectors in a layer
can be stacked to form an N ×d matrix with vector-valued entries, V(l) =
[v(l)1,v(l)2 ... v(l)N ]T , and the routing coeﬃcients cij collected into a matrix C
with the same shape as W. We can then write the forward pass through a vector
of capsules in a way that is analogous to a forward pass through a large ANN:
V(l) = f
[
(C ⊙W)V(l−1)
]
(5)
Here, ⊙denotes element-wise multiplication and the nonlinearity f is also ap-
plied element-wise. The expression WV(l−1) should be read as a higher-level
matrix-matrix multiplication in which matrix-vector multiplication is performed
in place of scalar multiplication per element, i.e. V(l)j = ∑m
i=1CjiWjiV(l−1)i
.
This term implements the sum of predictions ∑m
i=1ˆ uj|i from lower-level capsules
for the pose of each higher-level capsule j, where each transformation matrix is
ﬁrst scaled by the appropriate entry in the routing coeﬃcient matrix C.
We have argued that what the forward pass in equation 5 aims to implement
is in eﬀect posterior inference under a top-down generative model. To write down
such a model, we ﬁrst deﬁne ˜W as the transpose of the original weight tensor
W, i.e. an m×ncollection of transformations from nhigher-level capsules to m
lower-level capsules. Since each row of ˜W collects the transformations from all
higher-level capsules to the intrinsic coordinate frame of one lower-level capsule
v(l−1)i, we can then deﬁne a matrix ˆU(l−1) =


( ˜W1 ⊙V(l))T
...
( ˜Wm ⊙V(l))T

 that contains all
the predictions for the lower-level capsules, where matrix-vector multiplication
is applied element-wise to the submatrices.
Setting V = K = ˆU(l−1)i
and Q = V(l−1)i
, we can then frame the top-
down generation of one lower-level capsule vector within a capsules network as
an instance of neural attention, where Vk
(l) is the matrix of capsule activities at
layer l and iteration k, as above:
Vk
(l−1)i
= σ(Vk−1
(l−1)i
ˆUT
(l−1)i
) ˆU(l−1)i
(6)
These updates are independent for each lower-level capsule but can clearly be
vectorized by adding an extra leading dimension of size m to each matrix, so
that an entire attention update is carried out per row.
Capsule Networks as Generative Models 9
The above can be viewed as an inverted version of routing-by-agreement
in which the higher-level capsules cast ‘votes’ for the states of the lower-level
capsules, weighted by the terms in the softmax which play a role similar to
routing coeﬃcients. There is also a relation to associative memory models [21,
26, 35] since we can think of the capsule network as associating the previous
lower-level output (query) to ‘memories’ consisting of the predictions from the
layer above, and using the resulting similarity scores to update the outputs as a
blend of the predictions weighted by their accuracy.
Crucially, when used in this way for several recurrent iterations, neural at-
tention encourages each row of the output matrix to be dominated by whichever
input it is most similar to. Since the output in this case is the lower level in a
part-whole hierarchy (where rows correspond to capsule vectors), this precisely
enforces the single-parent constraint that routing-by-agreement aspires to.
In the routing-by-agreement algorithm, the routing logits bij are initially set
to 0 (or to their empirical prior value, if trained along with the weights) and
then accumulate the dot-product similarities during each iteration of routing.
It is clear that the application of attention alone without the accumulation of
log evidence over iterations should produce a routing-like eﬀect, since there is
a positive feedback loop between the similarities and the softmax weights. If
one wanted to emulate routing-by-agreement more closely, the above could be
supplemented with an additional recurrent state formed by the similarity scores
of the previous iteration.
While the single-parent constraint alone is not suﬃcient to ensure that only
lower-level capsules that are a good ﬁt with some active higher-level capsule are
activated, it is reasonable to expect that when no constant relationship between
a higher- and lower-level entity exists in the data, training would encourage the
weights of the corresponding transformation matrix to be close to 0, on pain of
inappropriately activating a lower-level capsule, which would lead to an increase
in the loss function (e.g. squared prediction error).
4.2 Probabilistic Generative Model
We now formulate the generative model sketched above explicitly in probabilis-
tic terms, which therefore also doubles as a generative model of transformer
attention (see Appendix D).
As remarked above, capsule networks can be seen as combining something
like a standard MLP forward pass with additional vector-level operations. In
particular, for a given lower-level capsule i, the attention mechanism can be
interpreted as mixing the MLPs deﬁned by each capsule pair ( i,j) with the
weights given by the attention softmax. If we interpret each MLP update in
terms of a Gaussian distribution, as in PCNs (that is, where the uncertainty
about the hidden state V(l−1) is Gaussian around a mean given by the sum of
weighted ‘predictions’), we arrive at a mixture of Gaussians distribution over
each lower-level capsule pose, whose mixing weights are determined by scaled
dot-product similarity scores.
10 Kiefer, Millidge, Tschantz, et al
These similarity scores must be interpreted diﬀerently from the MLP-like
part of the model, and we argue that these are correctly parametrized via a
von Mises-Fisher (VMF) distribution with a mean of the pose input. The VMF
implements the dot-product similarity score required by the routing coeﬃcient
in a probabilistic way, and can be thought of as parametrizing a distribution over
vector angles between the output and input poses, which is appropriate since the
purpose of the routing coeﬃcients is to reinforce predictions that match a higher-
level pose (where degree of match can be captured in terms of the angle between
the pose and prediction vectors). Importantly, since it parametrizes an angle
the distribution is circular since angles ‘wrap-around’. The VMF distribution
is a Gaussian deﬁned on the unit hypersphere and so correctly represents this
circular property.
Given the above, we can express the update in equation 6 above as a proba-
bilistic generative model as follows:
p(V(L)i
|ˆU(L)i
) =
∑
j
[
π(i)j
N(V(L)i
; ˆU(L)ij
,σij)
]
π(i) = Cat(n,p(i))
p(i) = σ
[
VMF (V(L)i
; ˆU(L)i1
,κi1) ... VMF (V(L)i
; ˆU(L)in
,κin)
]
(7)
where π(i) are the mixing weights, σij is the standard deviation of the Gaussian
distribution over capsule i conditioned on higher-level capsule j, and κij is the
‘concentration parameter’ of the corresponding VMF distribution, which deter-
mines how tightly probability mass is concentrated on the direction given by the
mean ˆU(L)ij
.
The generative model then deﬁnes the conditional probability of an entire
capsule layer given the predictions as the product of these per-capsule mixture
distributions, mirroring the conditional independence of neurons within a layer
in conventional MLPs:
p(V(L)|ˆU(L)) =
∏
i
p(V(L)i
|ˆU(L)i
) (8)
It would be simpler to use the attention softmax itself directly to determine the
mixing weights of each GMM, but using the probabilities returned by individual
VMF distributions instead aﬀords a fully probabilistic model of this part of the
generative process, where not only the vector angle match but also the variance
can be taken into account for each capsule pair i,j. It remains for future work
to write down a process for inverting this generative model using variational
inference.
Capsule Networks as Generative Models 11
5 Conclusion
In this paper, we have aimed to provide a principled mathematical interpre-
tation of capsule networks and link many of its properties and algorithms to
other better known ﬁelds. Speciﬁcally, we have provided a probabilistic genera-
tive model of the capsule network in terms of Gaussian and VMF distributions
which provides a principled mathematical interpretation of its core computa-
tions. Secondly, we have shown how the ad-hoc routing-by-agreement algorithm
described in [39] is related to self-attention. Moreover, we have demonstrated
both in a toy illustrative example and through large-scale simulation of capsule
networks how the desiderata of the routing algorithm can be achieved through
a general process of sparse iterative inference.
Acknowledgements
Alex Kiefer and Alexander Tschantz are supported by VERSES Research. Beren
Millidge is supported by the BBSRC grant BB/S006338/1 and by VERSES
Research. CLB is supported by BBRSC grant number BB/P022197/1 and by
Joint Research with the National Institutes of Natural Sciences (NINS), Japan,
program No. 0111200.
Code Availability
Code for the capsules network is adapted from
https://github.com/adambielski/CapsNet-pytorch
and can be found at: https://github.com/exilefaker/capsnet-experiments. Code
reproducing the toy model experiments and ﬁgure in Appendix B can be found
at: https://github.com/BerenMillidge/Sparse Routing.
References
1. Bahdanau, D., Cho, K., Bengio, Y.: Neural machine translation by jointly learning
to align and translate. arXiv preprint arXiv:1409.0473 (2014)
2. Beal, M.J.: Variational algorithms for approximate Bayesian inference. Tech. rep.
(2003)
3. Bogacz, R.: A tutorial on the free-energy framework for modelling perception and
learning. Journal of mathematical psychology 76, 198–211 (2017)
4. Bricken, T., Pehlevan, C.: Attention approximates sparse distributed memory.
arXiv preprint arXiv:2111.05498 (2021)
5. Brown, T.B., Mann, B., Ryder, N., Subbiah, M., Kaplan, J., Dhariwal, P., Nee-
lakantan, A., Shyam, P., Sastry, G., Askell, A., et al.: Language models are few-shot
learners. arXiv preprint arXiv:2005.14165 (2020)
6. Buckley, C.L., Kim, C.S., McGregor, S., Seth, A.K.: The free energy principle for
action and perception: A mathematical review. Journal of Mathematical Psychol-
ogy 81, 55–79 (2017)
12 Kiefer, Millidge, Tschantz, et al
7. Buzs´ aki, G., Mizuseki, K.: The log-dynamic brain: how skewed distributions aﬀect
network operations. Nature Reviews Neuroscience 15(4), 264–278 (2014)
8. Chen, L., Lu, K., Rajeswaran, A., Lee, K., Grover, A., Laskin, M., Abbeel, P., Srini-
vas, A., Mordatch, I.: Decision transformer: Reinforcement learning via sequence
modeling. Advances in neural information processing systems 34, 15084–15097
(2021)
9. De Zeeuw, C.I., Hoebeek, F.E., Bosman, L.W., Schonewille, M., Witter, L.,
Koekkoek, S.K.: Spatiotemporal ﬁring patterns in the cerebellum. Nature Reviews
Neuroscience 12(6), 327–344 (2011)
10. Demircigil, M., Heusel, J., L¨ owe, M., Upgang, S., Vermet, F.: On a model of asso-
ciative memory with huge storage capacity. Journal of Statistical Physics 168(2),
288–299 (2017)
11. Dosovitskiy, A., Beyer, L., Kolesnikov, A., Weissenborn, D., Zhai, X., Unterthiner,
T., Dehghani, M., Minderer, M., Heigold, G., Gelly, S., et al.: An image is
worth 16x16 words: Transformers for image recognition at scale. arXiv preprint
arXiv:2010.11929 (2020)
12. Friston, K.: A theory of cortical responses. Philosophical transactions of the Royal
Society B: Biological sciences 360(1456), 815–836 (2005)
13. Graham, D.J., Field, D.J.: Sparse coding in the neocortex. Evolution of nervous
systems 3, 181–187 (2006)
14. Greﬀ, K., Srivastava, R.K., Schmidhuber, J.: Highway and residual networks learn
unrolled iterative estimation. arXiv preprint arXiv:1612.07771 (2016)
15. Gregor, K., Danihelka, I., Graves, A., Rezende, D., Wierstra, D.: Draw: A recur-
rent neural network for image generation. In: International conference on machine
learning. pp. 1462–1471. PMLR (2015)
16. Hinton, G.: How to represent part-whole hierarchies in a neural network. arXiv
preprint arXiv:2102.12627 (2021)
17. Hinton, G.E., Krizhevsky, A., Wang, S.D.: Transforming auto-encoders. In: Inter-
national conference on artiﬁcial neural networks. pp. 44–51. Springer (2011)
18. Hinton, G.E., Sabour, S., Frosst, N.: Matrix capsules with em routing. In: Inter-
national conference on learning representations (2018)
19. Jastrzbski, S., Arpit, D., Ballas, N., Verma, V., Che, T., Bengio, Y.: Residual
connections encourage iterative inference. arXiv preprint arXiv:1710.04773 (2017)
20. Kanerva, P.: Sparse Distributed Memory. MIT Press (1988)
21. Krotov, D., Hopﬁeld, J.: Large associative memory problem in neurobiology and
machine learning. arXiv preprint arXiv:2008.06996 (2020)
22. Krotov, D., Hopﬁeld, J.J.: Dense associative memory for pattern recognition. Ad-
vances in Neural Information Processing Systems 29, 1172–1180 (2016)
23. Lamme, V.A., Roelfsema, P.R.: The distinct modes of vision oﬀered by feedforward
and recurrent processing. Trends in neurosciences 23(11), 571–579 (2000)
24. Makhzani, A., Frey, B.J.: k-sparse autoencoders. CoRR abs/1312.5663 (2014)
25. Melloni, L., van Leeuwen, S., Alink, A., M¨ uller, N.G.: Interaction between bottom-
up saliency and top-down control: how saliency maps are created in the human
brain. Cerebral cortex 22(12), 2943–2952 (2012)
26. Millidge, B., Salvatori, T., Song, Y., Lukasiewicz, T., Bogacz, R.: Universal hopﬁeld
networks: A general framework for single-shot associative memory models. arXiv
preprint arXiv:2202.04557 (2022)
27. Millidge, B., Seth, A., Buckley, C.L.: Predictive coding: a theoretical and experi-
mental review. arXiv preprint arXiv:2107.12979 (2021)
28. Naz´ abal, A., Williams, C.K.I.: Inference for generative capsule models. CoRR
abs/2103.06676 (2021), https://arxiv.org/abs/2103.06676
Capsule Networks as Generative Models 13
29. Olshausen, B.A., Field, D.J.: Emergence of simple-cell receptive ﬁeld properties by
learning a sparse code for natural images. Nature 381(6583), 607–609 (1996)
30. Olshausen, B.A., Field, D.J.: Sparse coding of sensory inputs. Current opinion in
neurobiology 14(4), 481–487 (2004)
31. Paik, I., Kwak, T., Kim, I.: Capsule networks need an improved routing algorithm.
ArXiv abs/1907.13327 (2019)
32. Parmar, N., Vaswani, A., Uszkoreit, J., Kaiser, L., Shazeer, N., Ku, A., Tran, D.:
Image transformer. In: International conference on machine learning. pp. 4055–
4064. PMLR (2018)
33. Pearl, J.: Probabilistic reasoning in intelligent systems: networks of plausible in-
ference. Morgan kaufmann (1988)
34. Radford, A., Wu, J., Child, R., Luan, D., Amodei, D., Sutskever, I., et al.: Language
models are unsupervised multitask learners. OpenAI Blog 1(8), 9 (2019)
35. Ramsauer, H., Sch¨ aﬂ, B., Lehner, J., Seidl, P., Widrich, M., Adler, T., Gruber, L.,
Holzleitner, M., Pavlovi´ c, M., Sandve, G.K., et al.: Hopﬁeld networks is all you
need. arXiv preprint arXiv:2008.02217 (2020)
36. Rawlinson, D., Ahmed, A., Kowadlo, G.: Sparse unsupervised capsules generalize
better. ArXiv abs/1804.06094 (2018)
37. Reed, S., Zolna, K., Parisotto, E., Colmenarejo, S.G., Novikov, A., Barth-Maron,
G., Gimenez, M., Sulsky, Y., Kay, J., Springenberg, J.T., et al.: A generalist agent.
arXiv preprint arXiv:2205.06175 (2022)
38. Ribeiro, F.D.S., Leontidis, G., Kollias, S.D.: Capsule routing via variational bayes.
In: AAAI. pp. 3749–3756 (2020)
39. Sabour, S., Frosst, N., Hinton, G.E.: Dynamic routing between capsules. Advances
in neural information processing systems 30 (2017)
40. Schweighofer, N., Doya, K., Lay, F.: Unsupervised learning of granule cell sparse
codes enhances cerebellar adaptive control. Neuroscience 103(1), 35–50 (2001)
41. Shepherd, G.M., Grillner, S.: Handbook of brain microcircuits. Oxford University
Press (2018)
42. Smith, L., Schut, L., Gal, Y., van der Wilk, M.: Capsule networks - A probabilis-
tic perspective. CoRR abs/2004.03553 (2020), https://arxiv.org/abs/2004.
03553
43. Sterling, P., Laughlin, S.: Principles of neural design. MIT press (2015)
44. Theeuwes, J.: Top–down and bottom–up control of visual selection. Acta psycho-
logica 135(2), 77–99 (2010)
45. Tschantz, A., Millidge, B., Seth, A.K., Buckley, C.L.: Hybrid predictive coding:
Inferring, fast and slow. arXiv preprint arXiv:2204.02169 (2022)
46. VanRullen, R.: The power of the feed-forward sweep. Advances in Cognitive Psy-
chology 3(1-2), 167 (2007)
47. Vaswani, A., Shazeer, N., Parmar, N., Uszkoreit, J., Jones, L., Gomez, A.N., Kaiser,
 L., Polosukhin, I.: Attention is all you need. In: Advances in Neural Information
Processing Systems. pp. 5998–6008 (2017)
48. Wainwright, M.J., Jordan, M.I., et al.: Graphical models, exponential families,
and variational inference. Foundations and Trends® in Machine Learning 1(1–2),
1–305 (2008)
49. Weidner, R., Krummenacher, J., Reimann, B., M¨ uller, H.J., Fink, G.R.: Sources
of top–down control in visual search. Journal of Cognitive Neuroscience 21(11),
2100–2113 (2009)
50. Willmore, B.D., Mazer, J.A., Gallant, J.L.: Sparse coding in striate and extrastriate
visual cortex. Journal of neurophysiology 105(6), 2907–2919 (2011)
51. Zheng, Q., Zhang, A., Grover, A.: Online decision transformer. arXiv preprint
arXiv:2202.05607 (2022)
14 Kiefer, Millidge, Tschantz, et al
Appendix A: Convergence of CapsNet with and without
routing
The following plots show the loss per epoch (plotted on a log scale for visibil-
ity) during training of a CapsNet architecture with 3 and 0 rounds of dynamic
routing-by-agreement and without an auxiliary reconstruction net. The ﬁgure
shows that after initially slower learning, CapsNet without routing converged to
nearly the same test set loss as with routing.
Fig. 2.Left: Training set loss during training of CapsNet under standard routing (3
iterations) and no-routing conditions. Middle: Test set loss. Right: Comparison of ﬁnal
losses across standard, no-routing, no-reconstruction, and no-routing no-reconstruction
conditions. Note that the loss functions diﬀer between the reconstruction and no-
reconstruction conditions.
Interestingly, although classiﬁcation performance was very similar across
these networks, the test set accuracy for the four conditions (standard, no rout-
ing, routing without reconstruction loss, and neither routing nor reconstruction
loss) were 99.23%, 99.34%, 99.32%, and 99.29% respectively. In this case at least,
dynamic routing appears not to have led to improved accuracy, although it does
lead to slightly lower values of the loss function both when using the full loss
(margin + reconstruction) and when using margin loss alone.
This is consistent with the ﬁndings in [31] that iterative routing does not
greatly improve the performance of capsules networks and can even lead to
worse performance, though it is also consistent with Sabour et al [39], who report
a roughly 0 .14% performance improvement using routing against a no-routing
baseline.
Appendix B: Toy Model of Routing as Sparse Iterative
Inference
Capsule networks assume that a sparse parse tree representation of a stimulus is
preferred and achieve this using the routing algorithm while an equivalent ANN
would typically produce dense representations. To gain intuition for why sparse
iterative inference may be able to achieve this result as well as capsule routing, we
Capsule Networks as Generative Models 15
provide a simple illustrative example of how iterative inference with a sparsity
penalty can result in routing-like behaviour. We consider a simple three-layer
neural network with a single hidden layer and visible input and output layers.
We ﬁx both the top and bottom layers to an input or a target respectively. We
can then infer the hidden layer activities which can both suﬃciently ‘explain’
the output given the input. If we imagine the input layer of the network as
representing features and the output as a classiﬁcation label, then in the hidden
layer we wish to uniquely assign the input features all to the best matching
‘object’. We construct such a network with input size 3, hidden size 3, and output
size 1, with input weights set to identity and the output weights set to a matrix
of all 1s. The network is linear although this is not necessary. Following the
Gaussian generative model proposed for the capsule network, we implemented
this network as a predictive coding network (PCN) and performed iterative
inference by updating activities to minimize the variational free energy which can
be expressed as a sum of squared prediction errors at each layer [6]. In additional
to the standard iterative free energy, we also experimented with adding either
a sparsity penalty (L1 regularisation) or L2 activity norm regularization to the
network. We investigated the extent to which iterative inference with the sparsity
penalty can reproduce the desired routing eﬀect with only a single high-level
feature being active, and found that it can (see Figure 3).
Fig. 3.A: Default behaviour of the outcome of iterative inference purely minimizing
squared prediction errors. Probability mass is distributed between all three potential
‘objects’ in the hidden layer. B: Outcome of sparse iterative inference using an L1
penalty term in the objective function. All probability mass is concentrated on a single
‘best’ object so that a singly connected scene parse tree is constructed. C: Outcome
of iterative inference with an L2 penalty term in the loss function which encourages
probability mass to spread out. All objects have approximately equal probability of
being selected.
Moreover, this sparsity penalty was necessary in this network in order for
inference to exhibit routing-like behaviour. Without any regularization, itera-
tive inference has a tendency to distribute probability mass between various
high-level objects. This tendency is exacerbated with L2 regularisation which
encourages the inference to spread probability mass as evenly as possible.
Interestingly, a similar intuition is applied in [18] where routing is explicitly
derived as part of an EM algorithm with a clear probabilistic interpretation and
16 Kiefer, Millidge, Tschantz, et al
where the MDL penalties derived for simply activating a capsule, which do not
depend on its degree of activation, can perhaps also be thought of as eﬀectively
implementing a similar sparsity penalty which encourages the EM algorithm
to assign capsule outputs to a single high-level capsule instead of spreading
probability mass between them.
Appendix C: Iterative inference process for CapsNet
Our implementation of sparse iterative inference in place of capsule routing is the
same in outline as that used for the toy model discussed in Appendix B, applied
to the CapsNet architecture. That is, we minimize the sum of squared prediction
errors per layer, which is equivalent to the variational free energy [27]. In this case
the prediction error for the output layer is given by the diﬀerence between the
prediction from the penultimate (PrimaryCaps) layer and the clamped target
values. For the sparsity condition, we also add the capsule-level L1 sparsity
penalty discussed in the caption of ﬁgure 1 at the output layer. Dynamic routing
was turned oﬀ for this experiment, both at inference time and during training.
Appendix D: Relationship between Capsule Routing and
Attention
As noted above, our generative model of the capsule network can also describe
the self-attention block in transformers, providing a fundamental building block
towards building a full transformer generative model. Explicitly writing down
such a generative model for the transformer architecture could enable a signiﬁ-
cantly greater understanding of the core mechanisms underlying the success of
transformers at modelling large-scale sequence data as well as potentially suggest
various improvements to current architectures.
This relationship to transformer attention is important because transformer
attention is well-understood and found to be highly eﬀective in natural language
processing tasks [5, 34] as well as recently in vision [11, 32] and reinforcement
learning [8, 37, 51]. Since capsule networks appear highly eﬀective at processing
natural scene statistics, this provides yet another example of the convergence
of machine learning architectures towards a universal basis of attention mecha-
nisms.
The basis of attention mechanisms can then be further understood in terms
of associative memory architectures based on Modern Hopﬁeld networks [21,35],
as brieﬂy discussed above. It has been found that sparsity of similarity scores
is necessary for eﬀective associative memory performance to prevent retrieved
memories from interfering with each other [20,22,26]. The softmax operation in
self-attention can be interpreted as a separation function with the goal of spar-
sifying the similarity scores by exponentially boosting the highest score above
the others. Indeed, it is a general result that the capacity of associative mem-
ory models can be increased dramatically by using highly sparsifying separation
Capsule Networks as Generative Models 17
functions such as high-order polynomials [10,22], softmaxes [35] and top-k acti-
vation functions [4].
An interesting aspect of our generative model is the use of VMF distributions
to represent the dot-product similarity scores. Intuitively, this arises because the
cosine similarity is ‘circular’ in that angles near 360 degrees are very similar to
angles near 0. In most transformer and associative memory models, the update
rules are derived from Gaussian assumptions which do not handle the wrap-
around correctly and hence may be subtly incorrect for angles near the wrap-
around point. By deriving update rules directly from our generative model, it is
possible to obtain updates which handle this correctly and which may therefore
perform better in practice. A second potential improvement relates to the VMF
variance parameter κ. In transformer networks this is typically treated as a
constant and set to 1√
d. In essence, this bakes in the assumption that the variance
of the distribution is inversely proportional to the data dimension. Future work
could also investigate dynamically learning values of κ from data which could
also improve performance.
One feature of routing-by-agreement not captured by iterative inference in
standard PCNs is the positive feedback loop, in which low prediction error en-
courages even closer agreement between activities and predictions. This is similar
to applying self-attention over time. A key distinction between attention as used
in transformers and the routing mechanism in capsule networks is that the lat-
ter is iterative and can be applied sequentially for many iterations (although
usually only 3-5), unlike in transformers where it is applied only once. Capsule
networks therefore could provide ideas for improving transformer models by en-
abling them to work iteratively and adding the recurrent state that arises from
the ‘bias’ term in the routing algorithm.
It has been proposed that highly deep networks with residual connections,
a set of architectures that includes transformers, are implicitly approximating
iterative inference using depth instead of time [14,19] which is a highly ineﬃcient
use of parameters. Instead, it is possible that similar performance may be ob-
tained with substantially smaller models which can explicitly perform iterative
inference similar to capsule networks. Some evidence for this conjecture comes
from the fact that empirically it appears that large language models such as
GPT2 [34] appear to perform most of their decisions as to their output tokens in
their ﬁrst few layers. These decisions are then simply reﬁned over the remaining
layers – a classic use-case for iterative inference.
The link between capsule routing and sparse iterative inference also has sig-
niﬁcant resonances in neuroscience. It is known that cortical connectivity and
activations are both highly sparse (approximately only 1-5% neurons active si-
multaneously) [7,13,50] with even higher levels of sparsity existing in other brain
regions such as the cerebellum [9, 40, 41]. Such a level of sparsity is highly en-
ergy eﬃcient [43] and may provide an important inductive bias for the eﬃcient
parsing and representation of many input signals which are generated by highly
sparse processes – i.e. dense pixel input is usually only generated by a relatively
small set of discrete objects. Secondly, iterative inference is a natural ﬁt for the
18 Kiefer, Millidge, Tschantz, et al
ubiquitous recurrent projections that exist in cortex [23,25,44,46,49] and many
properties of visual object recognition in the brain can be explained through a
hybrid model of a rapid amortized feedforward sweep followed by recurrent itera-
tive inference [45]. These considerations combine to provide a fair bit of evidence
towards a routing-like sparse iterative inference algorithm being an integral part
of cortical functioning. Moreover, it has been demonstrated many times in the
sparse-coding literature that adding sparse regularisation on a variety of recon-
struction and classiﬁcation objectives can result in networks developing receptive
ﬁelds and representations that resemble those found in the cortex [29,30,50].
Iterative inference is also important for enabling object discrimination and
disambiguation in highly cluttered and occluded scenes because it can model
the vital ‘explaining away’ [33] eﬀect where inferences about one object can
then inform parallel inferences about other objects. This is necessary in the
case of occlusion since by identifying the occluder and implicitly subtracting
out its visual features, it is often possible to make a much better inference
about the occluded object [17]. It is therefore noteworthy, and suggestive of
our hypothesis that routing can really be interpreted as iterative inference, that
capsule networks perform much better at parsing such occluded scenes than
purely feedforward models such as CNNs.