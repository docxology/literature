Brain2aiworkshopatICLR2021: howcanfindingsaboutthebrainimproveAIsystems
NEUROSCIENCE-INSPIRED PERCEPTION-ACTION IN ROBOTICS
APPLYINGACTIVEINFERENCEFORSTATEESTIMATION,CONTROLANDSELF-PERCEPTION
PabloLanillos
DondersInstituteforBrain,CognitionandBehaviour
DepartmentofArtificialIntelligence
RadboudUniversity
Nijmegen,theNetherlands
{p.lanillos}@donders.ru.nl
MarcelvanGerven
DondersInstituteforBrain,CognitionandBehaviour
DepartmentofArtificialIntelligence
RadboudUniversity
Nijmegen,theNetherlands
ABSTRACT
Unlikerobots, humanslearn, adaptandperceivetheirbodiesbyinteractingwith
theworld. Discoveringhowthebrainrepresentsthebodyandgeneratesactionsis
ofmajorimportanceforroboticsandartificialintelligence. Herewediscusshow
neuroscience findings open up opportunities to improve current estimation and
controlalgorithmsinrobotics. Inparticular,howactiveinference,amathematical
formulationofhowthebrainresistsanaturaltendencytodisorder,providesauni-
fiedrecipetopotentiallysolvesomeofthemajorchallengesinrobotics, suchas
adaptation,robustness,flexibility,generalizationandsafeinteraction. Thispaper
summarizessomeexperimentsandlessonslearnedfromdevelopingsuchacom-
putationalmodelonrealembodiedplatforms,i.e.,humanoidandindustrialrobots.
Finally,weshowcasethelimitationsandchallengesthatwearestillfacingtogive
robotshuman-likeperception1.
1 INTRODUCTION
Shewakesup,looksatthemirrorandreflects–isthisme?–whileopeningthetap
andleavingthewatertopourout–didIdoit?
Answering these two simple questions is the tip of the iceberg of body perception and action in
the brain (Tsakiris et al., 2007; Haselager, 2013; Haggard, 2017; Hinz et al., 2018). Underneath,
there are more than 500 million years of neural development that allow us to safely interact in a
world full of uncertainties. Unveiling how the brain integrates different sources of information to
perceivethebody, andgeneratesadaptiveactionsisofmajorimportanceforroboticsandartificial
intelligence(Todorov&Jordan,2002;Oliveretal.,2021).
According to (Helmholtz, 1867) perception is an unconscious mechanism that infers the state of
the world. Under this revolutionary view, the brain may learn an internal generative model of the
world and use it to reconstruct the perceived reality from partial sensory information. A perfect
exampleisvisualillusions,suchastheDallenbachillusion,wherepriorinformationdisambiguates
the meaning of an altered noisy image (Dallenbach, 1951). In other words, the brain works as a
predictivemachine(Clark,2013). Thispredictionpowerhasbeenproposedforseveralsegregated
brainregions,suchasthevisualcortex(Rao&Ballard,1999)orthecerebellum(Doya,1999). One
waytomodelapredictivemachineisthroughBayesianinference, wheretheagent’sbeliefsabout
thestateoftheenvironmentarebasedonitssensoryevidenceandpriorbeliefs. Thus,theinternal
1Accepted at ICLR 2021 Brain2AI workshop. Video presentation: https://youtu.be/
oW40kUGxu2s
1
1202
yaM
01
]OR.sc[
1v16240.5012:viXra
Brain2aiworkshopatICLR2021: howcanfindingsaboutthebrainimproveAIsystems
model is updated through the senses (Knill & Pouget, 2004; Friston, 2005). Accordingly, we can
answerthequestion‘Whereismybody?’byestimatingourbodyinspaceusinglearnedmodelsthat
have been acquired during our lifetime (Mori & Kuniyoshi, 2010) based on afferent multisensory
input(e.g.,visual,tactileandproprioceptivecues).
Analogously,thegenerationofadaptivebehaviorfromthepredictivebrainperspectivearisesfrom
theminimizationofsurprise(Friston,2010),thatis,thedifferencebetweenpredictedandobserved
sensations. Accordingtothispredictiveprocessinghypothesis—seeCiriaetal.(2021)forarecent
reviewincognitiverobotics—, thebrainmaintainsaninternalmodelthatpredictstheagent’ssen-
sations based on the causes of those sensations in the environment. If we condition sensation not
only on the environmental causes but also on the agent’s actions then we can integrate perception
and action. Adaptive behavior can then be viewed as an active inference (AIF) process in which
theagentselectsthoseactionsthatsupportthemaximizationofmodelevidence,orequivalently,the
minimizationofsurprise(DaCostaetal.,2020). Consequently,wecananswerthequestion‘How
should I move my body?’ by computing those actions that make the world better fit the learned
model. Thesearethefoundationsofthefreeenergyprinciple(FEP,Friston(2010)), whichpostu-
latesthatthebrainoptimizesthevariationalfreeenergy(VFE),whichisanupperboundonmodel
evidence. This approach allows us to infer and simultaneously adapt body posture to uncertain
situations(Kirchhoffetal.,2018);agoalthathasonlybeenpartiallysolvedinrobotics.
Recently,wehaveshownthatcombiningactiveinferencewithadvancesindeeplearningallowsus
togenerateadaptivebehaviorinhumanoidandindustrialrobots. Thesingleaimoftherobotisto
inferitsstate(unobservedvariable)bymeansofnoisysensoryinputs(observed). Forthatpurpose,
it can refine its state using the measurements or perform actions to fit the observed world to its
internal model. This is dually computed by optimizing the VFE. This work, depicted in Figure 1,
summarizessomeoftherecentproof-of-conceptexperimentswherewestudiedcoupledperception
(estimation)andaction(control)usingdeepAIFmodels(Lanillos&Cheng,2018b;Sancaktaretal.,
2020;Oliveretal.,2021;Lanillosetal.,2020a;Meo&Lanillos,2021).Furthermore,theapplication
of such a model in real-world settings provides an exciting avenue for mechanistically explaining
neuropsychologicalobservationsrelatedtobehaviorinbiologicalagents.
Figure 1: Neuroscience-inspired body perception and action for robotics. Answering these four
questions is crucial for embodied artificial intelligence and robotics. We cast estimation (where is
my body?) and control (how should I move?) as an inference process where the overall aim is to
perform state estimation. While we already approached a basic form of body-ownership (is this
me?) directlyfromthemodelevidence,agency(didIdoit?) isstillanevasivequestion.
ThefollowingsectionsareorganizedtoanswerthequestionsdescribedinFigure1fromtheactive
inferenceperspective.
2
Brain2aiworkshopatICLR2021: howcanfindingsaboutthebrainimproveAIsystems
2 WHERE IS MY BODY? GENERALIZED FILTERING
Knowing where our body is in space is central for safety and awareness. The brain keeps track
of a body posture or schema (Hoffmann et al., 2010; Lanillos et al., 2017) by fusing information
from all available sensory inputs. We cast body state estimation as generalized filtering (Friston
et al., 2010a). Defining the state of the system/body as z, the sensory inputs as x and the time-
derivative of the state vector Dz in generalized coordinates2, we describe the generative model of
thebody/worldwithtwofunctions:
x=g(z)+r sensoryinput(visual,proprioceptive,etc)
Dz=f(z)+w internalstatedynamics
Bodyestimationissolvedbyinferringthesystemstatewiththefollowingupdateequation:
z˙ =Dz−k ∇ F(z,x) (1)
z z
F istheVFEandundertheLaplaceandmean-fieldapproximations(Fristonetal.,2007;Buckley
etal.,2017;Oliveretal.,2021),hasclosedformandisdefinedas3:
F(z,x)(cid:39)−lnp(z,x)=−ln(p(x|z)p(z)) (2)
(cid:39)(x−g(x))TΣ−1(x−g(x))
x
+(Dz−f(z))TΣ−1(Dz−f(z))
z
1 1
+ ln|Σ |+ ln|Σ | (3)
2 x 2 z
NotethatEquation(1)iscorrectingthestategiventheweightedpredictionerrorencodedinF.
In(Lanillos&Cheng,2018b;Oliveretal.,2021),wedescribedhowtousethismethodtoestimate
the body pose of a humanoid robot. We showed how the algorithm provided robust multisensory
fusion(visual,proprioceptiveandtactilesources)wheninjectingstrongreadingsnoise,andadapt-
abilitytounexpectedsensorychanges,suchasvisuo-tactileperturbationsorbrokensensors.
2.1 LEARNINGTHEGENERATIVEMODELS
Usually,withintheAIFliterature,thegenerativemodelofthebodyisknownapriori(Fristonetal.,
2010b). However, in practice, the brain learns these models during interaction. We introduced
severalmethodstolearnthesensorygenerativemodelg(z), i.e., themappingbetweenthestateof
the system and the observed measurements (Lanillos & Cheng, 2018a), and to seamlessly include
themintheVFEoptimizationscheme. Althoughthesemethodsarenot(yet)biologicallyplausible,
we are currently mainly interested in the functional aspects of the model. For low-dimensional
inputs,i.e.,whenwecansegmentthelocationoftheend-effectorintheimageorinthetaskspace,
Gaussianprocessregression(Rasmussen&Williams,2005)ormixturedensitynetworks(Bishop,
1994) are suitable. In the former, we can compute in closed form the partial derivatives of the
generative functions with respect to the state (Lanillos & Cheng, 2018a). In the latter, we can
exploitthebackpropagationmethodtocomputeit(Lanillosetal.,2020b). Figure2describeshow
tolearnthevisualkinematicmappingthatisneededtosolveEq.(1).
Learning the internal state dynamical generative model f(z) is more complex (Lanillos & Cheng,
2018a). However,ifweknowthecharacteristicsofthesystemwecanuseasimplifiedstatemodel
and let the variational approximation to tackle the discrepancies (Friston et al., 2010b; Pio-Lopez
et al., 2016). In the extreme case, if we have access to the propriceptive desired state, we can use
alinearmodel(Oliveretal.,2021;Meo&Lanillos,2021). Theadaptivecontrollerwillabsorbthe
non-linearitiesbytrackingthedesiredjointpositionsandvelocitiesPezzatoetal.(2020b);Meo&
Lanillos(2021).
2Dz= d(z[0],z[1],...,z[n])=[z[1],z[2],...,z[n+1]];wherethesuperscriptindicatesthederivativeorder.
dt
3Otherapproximationsofthevariationaldensityarealsopossiblebutoutofthescopeofthispaper(Am-
brogionietal.,2021).
3
Brain2aiworkshopatICLR2021: howcanfindingsaboutthebrainimproveAIsystems
Figure2: Sensorygenerativemodellearning. (A)Mappingbetweenthelatentstateandtheobser-
vations. Mixture density network (MDN) or Gaussian process regression (GPR) used to learn the
kinematicmappingwithlow-dimensionalinputs. WhileinGPRthereisacloseformforcomputing
thepredictionandthepartialderivativewithrespecttothe state, inaneural networkapproachwe
exploittheforwardpassandthebackpropagationalgorithm. (X referstothetrainingdata,k(·)to
thesquaredexponentialkernelandαisanumericallystablecomputationoftheinversecovariance).
(B)Segmentedend-effectorpositioninthevisualspaceanditsassociatedgenerativemodelg (z).
v
2.2 SCALINGTOHIGH-DIMENSIONALINPUTS: PIXEL-AIF
Bymeansofdeepartificialneuralnetworks,wecanscalethestateestimationtohigh-dimensional
inputs. In(Sancaktaretal.,2020)weshowedhowtouseaconvolutionaldecodertoperformpixel
stateestimation. Figure3showsthePixel-AIFalgorithmworkingforestimationandcontrolinthe
NAO robot using only raw images as input. Figure 3A shows the evolution of the predicted arm
imageuntilthestateconvergestotherightstateestimation. Figure3Bshowstheaverageerrorsof
the state estimation from pixels in three different conditions: level 1, small deviations of the joint
angles from the prior belief; level 2, strong deviations from the prior belief; and level 3 a random
pose.
In(Meo&Lanillos,2021),weextendedthePixel-AIFframeworktomultimodalstaterepresentation
learning. Thisimpliestheinclusionofonedecoderpersensoryinput. Oneofthemainadvantages
ofourbrain-inspiredapproachisthattherobotonlyhastolearnthekinematicforwardmappingand
thenistheinferenceprocessthatperformstheBayesianinversionforestimationandproducesthe
righttorquesforachievingthegoal,eveninthepresenceofunmodeledsituationsorexternalforces.
3 HOW SHOULD I MOVE? ACTION AS INFERENCE
Inpredictivebrainmodels,suchasAIF,actiongenerationisrealizedinauniquemanner. Thebrain
infers actions in the light of anticipated sensory consequences. Thus, the system should encode
desired goals (or preferences) as (learned) priors. These desired goal states (imaginary goals) can
trigger corresponding, expected sensations which, in turn, initiate and control bodily movements
throughthereflexarcpathway. Thisisinlinewithideomotortheory,whichposesthattogeneratea
motorresponsewefirstcreatearepresentationofthegoal(James,1890).Wecastactionasacontrol
asinferenceproblemwheretheactionisupdatedthroughgradient-basedoptimization:
(cid:88)dx
a˙ =−k ·∇ F(x,z) (4)
a da x
x
4
Brain2aiworkshopatICLR2021: howcanfindingsaboutthebrainimproveAIsystems
Figure 3: Pixel-AIF algorithm. Image reproduced from (Sancaktar et al., 2020). (A) Pixel-based
bodyestimation. (B)Imageandjointanglesestimationaverageerrors. Weevaluatedthearmstate
estimation for three different levels of difficulty: small deviations (red), strong deviations (green)
and random pose (blue); computed over 2500 trials (i.e., 5× 500 random arm images). (C) Pixel-
AIFworkingintheNAOrobotusingtheheadbottomcamerainareachingtask. Thedesiredgoal
is defined as an image with the arm in a random position. (D) Image and joint angles estimation
averageerrorsinthereachingtaskevaluationusingthePixel-AIF.
3.1 EMERGENCEOFTHETASKBYOPERATIONALSPECIFICATION
The advantage of the AIF approach is that the task can be specified as a desired preference. This
impliesthatthepriorwillleadtothecorrespondingactions. Thedifficultybecomesfindingtheright
attractor set. For instance, we can set the goal as the sensory output that we would like to obtain
withintheinternaldynamicsasfollows:
∂g(z)
f(z,x )=T(z)(x −g(z))= (x −g(z)) (5)
d d ∂z d
whereT(z)isafunctionthatmapstheerrorinthesensoryspacetothelatentspaceandtheopera-
tionalspecificationdefines,forinstance,thedesiredoutcomeimageandjointanglesx ={I ,q }.
d d d
Figure3CshowstheNAOrobotgeneratingactionsusingthepixel-AIF(Sancaktaretal.,2020)until
reaching the desired goal. Here the operational specification is only the final image. Figure 3D
describes the statistical evaluation of the image and joint angle errors when enabling AIF control.
Whiledeviations(smallorlarge)fromthepriorbeliefhavegoodperformance,someoftherandom
images(level3)werenotfullysolved—SeethejointerrorslargevarianceofFig.3D.Thispointsout
theintrinsicnatureofthisbrain-inspiredmethod. Itissupposedtoworkforadaptivecorrectionsof
thebodyinthespacebutnotforcomplexsequentialgoal-driventasks. Tosolveplanningtheattrac-
torsetshouldbeencodedasapriororlearned(Tani,2003). Apromisingnewresearchdirectionis
touseanexplicitpolicyandcomputetheexpectedfreeenergy(Millidgeetal.,2021)approximating
thedensityfunctionsusingartificialneuralnetworks(vanderHimst&Lanillos,2020).
3.2 ADAPTATION: INVOLUNTARYACTIONSTOFITANEWWORLD
This neuroscience-inspired approach to control the robot body brings adaptation in two ways: it
counteractsexternalforcesandchangesinthebody/environmentwithoutneedingtorelearnandit
handlesthetrade-offbetweenpriorknowledge(acquiredthroughexperience)andpurereactivecon-
troldrivenbythesensoryinput. ThisisagreatadvantageoftheAIFmodelwithrespecttoclassical
control methods used in factories. The generalization to slightly different contexts is essential. In
Oliveretal.(2021),depictedinFig. 4,weshowedhowwhenchangingthevisualend-effectorloca-
tion,thealgorithmgeneratedmovementstoadjusttheend-effectortotherobotinternalmodel. This
occursbecausethealgorithmcomputesthecontrolactionsbyminimizingthevariationalfreeenergy.
Thus,ittriestoreducethedifferencebetweentheinternalmodelpredictionandtheend-effectorvi-
sualobservation.Recentexperimentshaveshownevidenceofsimilarbehaviourinhumans(Lanillos
5
Brain2aiworkshopatICLR2021: howcanfindingsaboutthebrainimproveAIsystems
0.14 0.12 0.y10 0.08 0.06-0.30 0.14 0.12 0.y10 0.08 0.06-0.30
-0.32 -0.32
-0.34x -0.34x
-0.36 -0.36
0.10 z0.050.00 vcaiatstlrucaauclltaostrveρdgv(μ) 0.10 z0.050.00 vcaiatstlrucaauclltaostrveρdgv(μ)
(a) Visualmarkerto (b) Visualmarkerto
theleft. theright.
0.20 0.15 0.y10 0.05 0.00-0.25 0.20 0.15 0.y10 0.05 0.00-0.20
-0. - 3 0 0 .35x vcaiatstlrucaauclltaostrveρdgv(μ) -0. - 2 0 5 .30x
0.100.0z50.0-00.0-50.10 vcaiatstlrucaauclltaostrveρdgv(μ) -0.40 0.200.1z50.100.050.00 -0.35
(c) Visualmarkeron (d) Visualmarkeron
(e) Jupiterexperiment.
finger. forearm.
Figure4: Adaptation: involuntaryactionstofitchangesintheworld. (Left)Inthisexperiment,we
modifiedonlinethevisuallocationofthearmend-effector(yellowmarker)forcingtherobottoadapt
to the induced model-world mismatch. Taken from (Oliver et al., 2021). The algorithm produces
counter-actingbehaviourstomaximizemodelevidence. Thus,itmovesthisnewend-effectortothe
desiredlocation. Onthetoprightofeachimage,thelefteyecameraisshown. Desiredend-effector
position is shown in blue, visual perception in red and estimated position in green. The resulting
directionofmotionobtainedfromthealgorithmisshownasanarrow. (Right)Jupiterexperiment,
taken from (Meo & Lanillos, 2021). AIF approaches successfully adapt to the change in gravity
whencomparingwiththebuilt-inPandacontroller(BPC).MultimodalAIF(MAIF)showsthebest
performance.
etal.,2020a).Thisinherentmechanismisusefultodealwithenvironmentalandbodychanges,such
asrobotcomplianceorgravitychanges. In(Meo&Lanillos,2021)wedescribedtheJupiterexper-
imentontheFrankaEmikaPandarobot,whichillustratestheadvantagesofanAIFmodelandthe
limitationsofclassicalcontrolmethodsusedinfactories. Figure4(e)showstheperformancecom-
parison between the Panda built-in controller and two AIF controllers. Our controller presented
equivalentaccuracywhenincreasingthegravitytog = 24.79m/s2. Furthermore,AIFapproaches
haveshownimprovedperformancewhencomparingtostate-of-the-artmodelpredictivecontroland
interestingpropertiesforfault-tolerantcontrol(Pezzatoetal.,2020a;b).
4 IS THIS ME? SELF-AWARENESS
Goingfromestimationandcontroltobeingawareofourbodyisabigleap. Abreakthroughexper-
iment, coined as the rubber-hand illusion (RHI, Botvinick & Cohen (1998)), showed how flexible
humansarewhenperceivingtheirbodies. Participantsfeltaplasticarmastheirarminlessthanone
minutebyvisuotactilestimulation. SeveralfMRIstudieshavelookedintotheneuralcorrelatesfor
these kinds of body-ownership illusions (Makin et al., 2008; Hinz et al., 2018). Three areas were
consistently found activated during the RHI: posterior parietal cortex (including the intra-parietal
cortex and temporo-parietal junction), premotor cortex and lateral cerebellum. The cerebellum is
assumed to compute the temporal relationship between visual and tactile signals, thus playing a
roleintheintegrationofvisual, tactileandproprioceptivebody-relatedsignals. Thepremotorand
intra-parietalcortexaremultisensoryareas,alsointegratingvisual,tactileandproprioceptivesignals
presentduringtherubberhandillusion.Hence,therightcrossmodalneuralactivationsduringsenso-
rimotorintegrationmaybethekeyforbody-ownership. Withinthepredictiveprocessingapproach,
wecananswerabasicnotionof‘Isthisme?’ byevaluatingwhetherthesensationsfittheinternal
model(Kahl&Kopp,2018;Lanillosetal.,2020b).
Cognitiveroboticshasalsotriedtoenlightenthemechanismsbehindbodyawareness(Lanillosetal.,
2017;Tani&White,2020). Whatwecanalreadyreplicateareperceptualeffectsobservedduring
the RHI (Hinz et al., 2018; Rood et al., 2020) due to the recalibration of the body posture when
mergingsensoryconflictinginformation. Precisely,therealhandismislocalizedtowardstheplastic
hand due to the illusion. Furthermore, we also showed evidence of an active component derived
6
Brain2aiworkshopatICLR2021: howcanfindingsaboutthebrainimproveAIsystems
from the AIF hypothesis (Lanillos et al., 2020a). Figure 5A describes the perceptual and active
effectsfromthepredictivebrainpointofviewwhenexposingapersontoavirtualbody.
Figure 5: Towards human-like perception. (A) Human body perception and action when exposed
to a virtual environment where the virtual body does not correspond to the actual body pose. (B)
Modellingmirrorself-recognitiononarobot.
Furthermore,in(Lanillosetal.,2020b),Fig.5B,weshowedhowtouseAIFtosolveasimpleform
ofartificialself-recognition(Hoffmannetal.,2021)byvisual-kinestheticmatchingusingmovement
cues. Inessence,therobotinfersthatitisitselfbyevaluatingagainthemodelevidencethroughthe
VFE.F isthereforeusedasaboundonhowmuchtheobservationsfittheinternalmodel. Inother
words,howmuchthesensationsarebeingproducedbyitsbody.
Finally, ‘Did I do it?’ (Haggard, 2017) is still an evasive question. Although it is already possi-
ble to empirically evaluate the experience of agency and some theoretical models have been pro-
posed(Blakemoreetal.,2000;Hommel,2015),yetnocomputationalmodelcanproperlyreplicate
the process. Unveiling the mechanism of being aware of the effects that we generate in the world
iscriticalforroboticsasitprovidessafeinteractionincomplexenvironmentsandveryrelevantfor
imitationandsocialinteraction(Wirkuttis&Tani,2021).
5 CONCLUSION
We discussed some relevant models and experiments in robotics based on neuroscientific theories
of how humans perceive their bodies. In particular, we have presented a low-level estimation and
adaptive control algorithm that takes inspiration from how the brain may process sensory infor-
mationandgeneratesactionsthroughtheminimizationofsurprise. Hence, wemakeaconnection
betweenpredictiveprocessingtheoryincognitive(neuro)scienceandoutstandingchallengesinthe
field of robotics. Body intelligence is one of the biggest challenges described by Moravec’s para-
doxthatisnotyetsolved(Moravec,1988). Thedescribedproof-of-conceptexperimentsshowhow
understanding the brain can revolutionize robotics and embodied artificial intelligence in terms of
adaptation,generalization,flexibilityandrobustness. Assuch,thisresearchmarriesideasinneuro-
scienceandartificialintelligencewiththeaimofdevelopinganewgenerationofnaturallyintelligent
systems(vanGerven,2017).
REFERENCES
Luca Ambrogioni, Kate Lin, Emily Fertig, Sharad Vikram, Max Hinne, Dave Moore, and Marcel
Gerven. Automatic structured variational inference. In International Conference on Artificial
IntelligenceandStatistics,pp.676–684.PMLR,2021.
ChrisBishop. Mixturedensitynetworks. TechnicalReportNCRG/94/004,1994.
Sarah-JayneBlakemore,DanielWolpert,andChrisFrith. Whycan’tyoutickleyourself? Neurore-
port,11(11):R11–R16,2000.
7
Brain2aiworkshopatICLR2021: howcanfindingsaboutthebrainimproveAIsystems
Matthew Botvinick and Jonathan Cohen. Rubber hands ‘feel’ touch that eyes see. Nature, 391
(6669):756,1998.
Christopher L Buckley, Chang Sub Kim, Simon McGregor, and Anil K Seth. The free energy
principleforactionandperception:Amathematicalreview.JournalofMathematicalPsychology,
81:55–79,2017.
AlejandraCiria,GuidoSchillaci,GiovanniPezzulo,VerenaVHafner,andBrunoLara. Predictive
processingincognitiverobotics: areview. NeuralComputation,33(5):1402–1432,2021.
AndyClark. Whatevernext? predictivebrains,situatedagents,andthefutureofcognitivescience.
BehavioralandBrainSciences,36(3):181–204,2013.
LancelotDaCosta,ThomasParr,NoorSajid,SebastijanVeselic,VictoritaNeacsu,andKarlFriston.
Activeinferenceondiscretestate-spaces: asynthesis. JournalofMathematicalPsychology,99:
102447,2020.
K.M.Dallenbach. Apuzzle-picturewithanewprincipleofconcealment. TheAmericanJournalof
Psychology,64(3):431–433,1951.
KenjiDoya.Whatarethecomputationsofthecerebellum,thebasalgangliaandthecerebralcortex?
NeuralNetworks,12(7-8):961–974,1999.
KarlFriston. Atheoryofcorticalresponses. PhilosTransRSocLondB:BiologicalSciences,360
(1456):815–836,2005.
KarlFriston,Je´re´mieMattout,NelsonTrujillo-Barreto,JohnAshburner,andWillPenny.Variational
freeenergyandtheLaplaceapproximation. Neuroimage,34(1):220–234,2007.
KarlFriston,KlaasStephan,BaojuanLi,andJeanDaunizeau. Generalisedfiltering. Mathematical
ProblemsinEngineering,2010,2010a.
KarlJ.Friston. Thefree-energyprinciple: aunifiedbraintheory? NatureReviews.Neuroscience,
11:127–138,022010. doi: 10.1038/nrn2787.
Karl J Friston, Jean Daunizeau, James Kilner, and Stefan J Kiebel. Action and behavior: a free-
energyformulation. BiologicalCybernetics,102(3):227–260,2010b.
Patrick Haggard. Sense of agency in the human brain. Nature Reviews Neuroscience, 18(4):196,
2017.
Pim Haselager. Did i do that? brain–computer interfacing and the sense of agency. Minds and
Machines,23(3):405–418,2013.
HermannvonHelmholtz. HandbuchderPhysiologischenOptik. L.Voss,1867.
Nina-AlisaHinz,PabloLanillos,HermannMueller,andGordonCheng.Driftingperceptualpatterns
suggestpredictionerrorsfusionratherthanhypothesisselection: replicatingtherubber-handillu-
siononarobot. In2018JointIEEE8thInternationalConferenceonDevelopmentandLearning
andEpigeneticRobotics(ICDL-EpiRob),pp.125–132.IEEE,2018.
Matej Hoffmann, Hugo Gravato Marques, Alejandro Hernandez Arieta, Hidenobu Sumioka, Max
Lungarella,andRolfPfeifer. Bodyschemainrobotics: areview. AutonomousMentalDevelop-
ment.,IEEETran.on,2(4):304–324,2010.
MatejHoffmann,ShengzhiWang,VojtechOutrata,ElisabetAlzueta,andPabloLanillos. Robotin
themirror: towardanembodiedcomputationalmodelofmirrorself-recognition. KI-Ku¨nstliche
Intelligenz,pp.1–15,2021.
BernhardHommel.Actioncontrolandthesenseofagency.Thesenseofagency,pp.307–326,2015.
WillliamJames. ThePrinciplesofPsychology. Dover,NewYork,1890.
SebastianKahlandStefanKopp. Apredictiveprocessingmodelofperceptionandactionforself-
otherdistinction. Frontiersinpsychology,9:2421,2018.
8
Brain2aiworkshopatICLR2021: howcanfindingsaboutthebrainimproveAIsystems
MichaelKirchhoff,ThomasParr,EnsorPalacios,KarlFriston,andJulianKiverstein. TheMarkov
blankets of life: autonomy, active inference and the free energy principle. Journal of the Royal
SocietyInterface,15(138):20170792,2018.
DavidCKnillandAlexandrePouget. TheBayesianbrain: theroleofuncertaintyinneuralcoding
andcomputation. TrendsinNeurosciences,27(12):712–719,2004.
PabloLanillosandGordonCheng. Activeinferencewithfunctionlearningforrobotbodypercep-
tion. InternationalWorkshoponContinualUnsupervisedSensorimotorLearning,ICDL-Epirob,
2018a.
PabloLanillosandGordonCheng. Adaptiverobotbodylearningandestimationthroughpredictive
coding. IntelligentRobotsandSystems(IROS),2018IEEE/RSJInt.Conf.on,2018b.
Pablo Lanillos, Emmanuel Dean-Leon, and Gordon Cheng. Enactive self: a study of engineering
perspectives to obtain the sensorimotor self through enaction. In Developmental Learning and
EpigeneticRobotics,JointIEEEInt.Conf.on,2017.
Pablo Lanillos, Sae Franklin, and David W Franklin. The predictive brain in action: Involuntary
actionsreducebodypredictionerrors. BioRxiv,2020a.
Pablo Lanillos, Jordi Pages, and Gordon Cheng. Robot self/other distinction: Active inference
meetsneuralnetworkslearninginamirror. InProceedingsofthe20thEuropeanConferenceon
ArtificialIntelligenceECAI12.Amsterdam: IOSPress,2020b.
TamarRMakin,NicholasPHolmes,andHHenrikEhrsson. Ontheotherhand: dummyhandsand
peripersonalspace. BehaviouralBrainResearch,191(1):1–10,2008.
Cristian Meo and Pablo Lanillos. Multimodal VAE active inference controller. arXiv preprint
arXiv:2103.04412,2021.
BerenMillidge,AlexanderTschantz,andChristopherLBuckley.Whencetheexpectedfreeenergy?
NeuralComputation,33(2):447–482,2021.
HansMoravec. MindChildren: TheFutureofRobotandHumanIntelligence. HarvardUniversity
Press,1988.
Hiroki Mori and Yasuo Kuniyoshi. A human fetus development simulation: Self-organization of
behaviorsthroughtactilesensation.InIEEE9thInt.Conf.onDevelopmentandLearning(ICDL),
pp.82–87,2010.
GuillermoOliver,PabloLanillos,andGordonCheng. Anempiricalstudyofactiveinferenceona
humanoidrobot. IEEETransactionsonCognitiveandDevelopmentalSystems,2021.
CorradoPezzato,MohamedBaioumy,CarlosHerna´ndezCorbato,NickHawes,MartijnWisse,and
Riccardo Ferrari. Active inference for fault tolerant control of robot manipulators with sensory
faults. InInternationalWorkshoponActiveInference,pp.20–27.Springer,2020a.
Corrado Pezzato, Riccardo Ferrari, and Carlos Herna´ndez Corbato. A novel adaptive controller
for robot manipulators based on active inference. IEEE Robotics and Automation Letters, 5(2):
2973–2980,2020b.
Le´o Pio-Lopez, Ange Nizard, Karl Friston, and Giovanni Pezzulo. Active inference and robot
control: acasestudy. JRSocInterface,13,2016.
RajeshPNRaoandDanaHBallard. Predictivecodinginthevisualcortex: afunctionalinterpreta-
tionofsomeextra-classicalreceptive-fieldeffects. NatureNeuroscience,2(1):79–87,1999.
CarlEdwardRasmussenandChristopherK.I.Williams. GaussianProcessesforMachineLearning
(AdaptiveComputationandMachineLearning). TheMITPress,2005. ISBN026218253X.
ThomasRood,MarcelvanGerven,andPabloLanillos.Adeepactiveinferencemodeloftherubber-
handillusion. InInternationalWorkshoponActiveInference,pp.84–91.Springer,2020.
9
Brain2aiworkshopatICLR2021: howcanfindingsaboutthebrainimproveAIsystems
CansuSancaktar,MarcelvanGerven,andPabloLanillos. End-to-endpixel-baseddeepactiveinfer-
enceforbodyperceptionandaction. arXivpreprintarXiv:2001.05847,2020.
JunTani. Learningtogeneratearticulatedbehaviorthroughthebottom-upandthetop-downinter-
actionprocesses. NeuralNetworks,16(1):11–23,2003.
JunTaniandJeffreyWhite. Cognitiveneuroroboticsandselfinthesharedworld,afocusedreview
ofongoingresearch. AdaptiveBehavior,pp.1059712320962158,2020.
EmanuelTodorovandMichaelIJordan.Optimalfeedbackcontrolasatheoryofmotorcoordination.
NatureNeuroscience,5(11):1226,2002.
Manos Tsakiris, Simone Schu¨tz-Bosbach, and Shaun Gallagher. On agency and body-ownership:
Phenomenologicalandneurocognitivereflections. ConsciousnessandCognition,16(3):645–660,
2007.
Otto van der Himst and Pablo Lanillos. Deep active inference for partially observable MDPs. In
InternationalWorkshoponActiveInference,pp.61–71.Springer,2020.
MarcelAJvanGerven. Computationalfoundationsofnaturalintelligence. FrontiersinComputa-
tionalNeuroscience,11:1–24,2017.
Nadine Wirkuttis and Jun Tani. Controlling the sense of agency in dyadic robot interaction: An
activeinferenceapproach. arXivpreprintarXiv:2103.02137,2021.
10