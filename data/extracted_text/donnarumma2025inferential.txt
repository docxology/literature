bioRxiv preprint doi: https://doi.org/10.1101/2025.11.26.690672; this version posted November 26, 2025. The copyright holder for this preprint
(which was not certified by peer review) is the author/funder, who has granted bioRxiv a license to display the preprint in perpetuity. It is made
available under aCC-BY 4.0 International license.
Inferential planning in the frontal cortex
Francesco Donnarumma1 Thomas Parr2 Karl Friston3,4 James Whittington5
Giovanni Pezzulo1,∗
1 Institute of Cognitive Sciences and Technologies, National Research Council, Rome, Italy
2 Nuffield Department of Clinical Neurosciences, University of Oxford, Oxford OX1 2JD, UK
3 Queen Square Institute of Neurology, University College London, London WC1E 6BT, UK
4 VERSES Research Lab, Los Angeles, CA 90016, USA
5 Department of Experimental Psychology, University of Oxford, Oxford, UK
∗ Corresponding author: giovanni.pezzulo@istc.cnr.it
November 26, 2025
Abstract
Howthebrainplansandmaintainssequencesoffutureactionsremainsacentralquestioninsystems
neuroscience. Recentstudiesinthefrontalcortexhaverevealedthatmultipleelementsofasequenceare
representedsimultaneouslyinseparableneuralsubspaces,challengingclassicalserialmodelsofsequential
planning. Here,weshowthattheserepresentationsemergenaturallyunderinferentialplanninginwhich
sequential actions are inferred from sensory evidence and goals. Using a hierarchical generative model,
we reproduce key neural phenomena observed in primate frontal cortex, including the simultaneous
activationofmultipleplanelements,theemergenceof(almost)orthogonal‘memory’subspaces,andtheir
reuseacrossforwardandbackwardsequencetasks. Ourapproachprovidesamechanisticaccountofhow
probabilisticinferenceovercontrolstatesgivesrisetodistributedanddynamicneuralrepresentationsof
plans. This framework not only unifies previously disparate findings on planning, working memory, and
motorpreparation,butalsogeneratesnovel,testablepredictionsaboutthedynamicsofactiveinference,
the role of sensory subspaces, and the impact of uncertainty on sequence processing.
Keywords: planning, probabilistic inference, frontal cortex.
1 Introduction
The ability to plan is central to intelligent behaviour. Planning involves sequencing a series of actions that
can later be enacted in the world. While we are beginning to understand sequence processing in the brain
mechanistically (Mattar & Lengyel, 2022; Miller et al., 2017; Pezzulo et al., 2019; Balaguer et al., 2016), our
understandingofhowplansareformed, andtheirrelationshiptosequenceprocessingmorebroadly, remains
incomplete.
The dominant view of planning states that elements of the plan are sequentially sampled one after
another, i.e., the plan is generated in series with the neural population representing just one action at
any time-point. This view is consistent with many existing models for sequence understanding, as well as
planning, such as recurrent neural networks (Elman, 1990; Botvinick & Plaut, 2006; Maass et al., 2002;
Ganguli et al., 2008; Jensen et al., 2024), probabilistic generative models (Parr et al., 2024; Pezzulo et al.,
1
bioRxiv preprint doi: https://doi.org/10.1101/2025.11.26.690672; this version posted November 26, 2025. The copyright holder for this preprint
(which was not certified by peer review) is the author/funder, who has granted bioRxiv a license to display the preprint in perpetuity. It is made
available under aCC-BY 4.0 International license.
2017, 2014; George et al., 2021), or heteroclinic channels (Rabinovich et al., 2014). Representing plans and
sequences sequentially has been able to account for a variety of different neural representations, from motor
sequences as dynamical systems (Mante et al., 2013; Sussillo et al., 2015) to hippocampal replay sampled
from a generative model (cognitive map) of the environment (Schwartenbeck et al., 2023; Stoianov et al.,
2022; Foster, 2017) and the mental planning of multiple tasks reported in the orbitofrontal cortex (Wilson
et al., 2014; Schuck et al., 2016; Van de Maele et al., 2024). Further, such formalisms have been combined
withreinforcementlearning(Stachenfeldetal.,2017;Behrensetal.,2018;Barametal.,2021),aswellasthe
probabilistic planning literature (George et al., 2021; Raju et al., 2024; Stoianov et al., 2018), to understand
goaldirectedbehaviourwithmodelspredictingavarietyofneuralphenomenaofthehippocampalformation.
Despitetheirdifferences,allthesemodelsgeneratesequentialtransitionsbetweenelements—whetherspatial
positions, memories, or actions. At the neural level, this implies that at any specific point in time, the brain
represents only one element of the sequence in ongoing neural activity.
Recently, however, a different type of representation has been uncovered in prefrontal cortex. Here,
all elements of a sequence are represented simultaneously in neural activity at any given time, from path
planningtasks(Mushiakeetal.,2006;Saitoetal.,2005;El-Gabyetal.,2024)tosequencememorytasks(Xie
et al., 2022; Panichello et al., 2024; Chen et al., 2024) to drawing (Averbeck et al., 2002) and visual working
memorytasks(Liuetal.,2024). Eachelementofthesequenceisrepresented,andordered,inadistinctsetof
neuralsubspaces—termed‘activationslots’(Whittingtonetal.,2025). Thisallowstheentiresequencetobe
representedsimultaneouslyacrossthedifferentslots. Whilethisisadifferentviewofsequencerepresentation,
it has been shown to have a mathematical equivalence to the sequential view described earlier (Whittington
et al., 2025). This raises the tantalising possibility that this new type of representations—slots—can also
serve as a neural substrate of planning more broadly.
In this paper, we formalise planning as inference over these ordered subspaces. We show that messages
are passed from slot to slot in order to infer the correct state and action held at each time-step of the plan.
Using this theory we able to explain a variety of neural findings from prefrontal cortex while animals plan:
1) single neurons coding for specific cursor movements at specific time-steps in the plan (Mushiake et al.,
2006);2)neuralsubspacesholdingarbitraryelementsinsequencememorytask(Xieetal.,2022);3)showing
that the same subspaces are reused in both forward and backward planning tasks (Chen et al., 2024); 4)
inferringplanswhenthenumberofsequenceelementsinaplandiffers(Chenetal.,2024). Ourtheoryshows
planning and sequence memory to be two sides of the same coin and offers a mechanistic understanding of
how an entire plan can be encoded—in neural activity—simultaneously in prefrontal cortex.
2 Results
We first introduce an inferential planning model (Section 2.1) used subsequently to reproduce the neural
dynamics observed empirically in three studies (Mushiake et al., 2006; Xie et al., 2022; Chen et al., 2024).
2.1 A prefrontal model to infer arbitrary plans
Westartbyconsideringwhatitwouldmeantorepresentanarbitraryplansimultaneouslyinasetofneurons
(or neuronal populations), and then construct a model that is able to infer such a plan representation.
Aplanisaproposedsequenceofactions(a )andstates(s ): {(s ,a )}. Actions,however,canbeabstract
t t t t
orhigher-levelsubgoals(e.g.,gotoA)thataresubsequentlyenactedbymotorcontrols(e.g.,movearmleft).
Toaccountforthis,weuseahierarchicalmodel,inwhichtheplanisrepresentedinvariablesabstractedfrom
motorcommands(inLevel2),whilethemotorcommandsthemselvesarerepresentedinLevel1(Figure1A).
For Level 2 neurons to represent arbitrary full plans (complete sequences of action and states), multiple
copiesofactionandstateneuronsarerequiredinwhicheachcopycorrespondstopotentialactionsandstates
at each time-point in the plan (Figure 1B). Correspondingly, this means the whole plan is simultaneously
encoded by neural activity. For example, if each planning problem involves a sequence of three joystick
movements—examplesequencesbeing{Up,Left,Left}or{Up,Right,Right}(withcorrespondingstatesat
2
bioRxiv preprint doi: https://doi.org/10.1101/2025.11.26.690672; this version posted November 26, 2025. The copyright holder for this preprint
(which was not certified by peer review) is the author/funder, who has granted bioRxiv a license to display the preprint in perpetuity. It is made
available under aCC-BY 4.0 International license.
each time-point)—there must be three pools of neurons each able to represent any state and any action at
their corresponding time-point (Figure 1C).
This simultaneous representation of all elements in the plan allows for arbitrary plans to be represented.
This is fundamentally different to formalisms where elements of a plan are represented sequentially, one
after another, in the same neuron or population. While that setup can represent specific sequences using
neuraldynamics(providedtheappropriatesynapticconnections),itdoesnothavetheflexibilitytorepresent
arbitrary plan sequences. Furthermore, the encoding of the first action cannot be revised or contextualised
by the last action, because the first action is encoded in the past, when the last action is represented.
Figure 1 Schematic illustration of the hierarchical inferential planning model. (A) The model
comprisestwointerconnectedlevels. Level2(planninglevel)encodesbeliefsaboutplans—abstractsequences
of actions (and states) over time. Level 1 (sensorimotor level) encodes beliefs about concrete motor com-
mands (and sensory states), which generate observable outcomes in the environment. Arrows indicate the
bidirectional exchange of information: top–down predictions from Level 2 guide action selection at Level 1,
while bottom–up sensory evidence updates beliefs at both levels. This architecture supports both forward
and backward inference over time, allowing the system to infer, maintain, and flexibly revise entire action
sequences. (B) Within Level 2, neural populations encode beliefs about abstract actions Up, Down, Left,
and Right joystick movements (and corresponding states, omitted for clarity) at multiple time points; for
example, U1 is Up at time point 1, U2 is Up at time point 2, etc. These are maintained and updated in
parallel through reciprocal message passing (Section 4). (C) Example of Level 2 neural representations of
two plans: {Up,Left,Left} and {Up,Right,Right}. See main text for further explanation. (D) Intuitive
understanding of the message passing process in which plans are inferred. First a start and goal state are
presented, and then through multiple iterations (boxes from left to right) the full plan is inferred. In this
schematic,weshowbothexampleactionneuronsandstateneuronsofLevel2(forasimplifiedtaskcompared
to the other panels). See the main text for further explanation.
The ensuing simultaneous sequence element setup bears a remarkable resemblance to the ‘activation
slots’ found in prefrontal cortex (Whittington et al., 2025). However, current models of ‘activation slots’ are
limitedtounderstandingjustsequentialmemorytasks. Inthispaper, weshowthatthesamecomputational
architecturecansolvearbitraryplanningtasks. Inordertoformaplan, however, inferenceisrequired. This
may involve inferring the path between a start and goal state, though more generally it is the process of
3
bioRxiv preprint doi: https://doi.org/10.1101/2025.11.26.690672; this version posted November 26, 2025. The copyright holder for this preprint
(which was not certified by peer review) is the author/funder, who has granted bioRxiv a license to display the preprint in perpetuity. It is made
available under aCC-BY 4.0 International license.
combining observations with task statistics to infer optimal behaviour (we provide examples of this later in
the paper). Regardless of the setting, we employ variational Bayes for planning as inference (Attias, 2003;
Botvinick&Toussaint,2012;Fristonetal.,2017a;Parretal.,2022). Thusthehigherlevel(Level2)encodes
beliefs about plans or policies, while the lower level (Level 1) encodes beliefs about concrete sensorimotor
actionsthatimplementtheseplans—bymovingtheagentfromonelocationtothenext—interactingdirectly
with the environment.
Information flows bidirectionally between the two levels and with the environment. Predictions about
plannedsequencesflowdownwardfromLevel2toLevel1, guidingtheselectionofsensorimotoractionsthat
areexecutedintheenvironment. Inturn, sensoryfeedbackandactionoutcomesgeneratebottom-upsignals
that update beliefs at Levels 1 and then 2. This bidirectional exchange allows the system to continuously
align planned sequences with sensory evidence, ensuring coherent behaviour across hierarchical levels of
control. Within each level, neural populations represent probabilistic beliefs about hidden states, and their
interactionsimplementprobabilisticbeliefupdatingviaamessagepassingmethod,calledbeliefpropagation
(Pearl, 2022; George & Hawkins, 2009; George et al., 2025; Friston et al., 2017a,b; Parr et al., 2019).
Insum,weconsidera(Level2)neuralpopulationwhichconsistsofcopies(subspaces)ofstateandaction
representations, each able to represent an arbitrary state and action. To infer what action and state should
goineachsubspace(i.e.,infertheplan),weuseaneuronallyplausiblemessagepassingalgorithm(seeFigure
1D for an intuitive illustration). Critically, the simultaneous representation of all time-steps in the plan is
essentialtosupportthereciprocalmessagepassing—i.e.,beliefpropagation—thatimplementsthissequential
planning. See Section 4 for a formal description of the model and implicit message passing.
Wenowshowaseriesofresults(Sections2.2,2.3,2.4)inwhichourmodelrecapitulatestheprefrontalneu-
ralactivityofseveralexperimentalstudies. Ineachcase,weshowneuralpopulationdynamicscorresponding
to the inference process of Level 2 abstract plans. Where specified, we also show dynamics corresponding to
inference of Level 1 specific actions.
2.2 Planning sequences of cursor movements
First we consider a planning task (Mushiake et al., 2006) in which monkeys were trained to control a cursor
to navigate a two-dimensional maze, moving from a central position to a cued goal location (Figure 2A-B).
Theirkeyfindingwasthat,duringthepreparatoryperiodprecedingmovement,simultaneousrepresentations
of multiple future cursor movements were recorded in distinct neuronal populations within the monkey
lateral prefrontal cortex, each selective for a specific movement at a specific time step, e.g., the Right cursor
movementatthe1sttimestep, theLeftcursormovementatthe2ndtimestep, ortheLeftcursormovement
atthe3rdtimestep(Figure2C).Incontrast,neuralactivityintheprimarymotorcortexprimarilyreflected
actual arm movements.
We simulated this task under our hierarchical model (Figure 1). The lower level (Level 1) controls
cursor movements, whereas the upper level (Level 2) plans the sequence of cursor movements. Level 2
comprised25hiddenstatesrepresentingmazelocations(fromS toS )and5controlstatescorresponding
11 55
to possible cursor movements: Up, Down, Left, Right, and Stay. The simulated neural activity reported
below corresponds to the inference of these 5 control states across the 3 time steps of the plan, which we
compare with the frontal cortical activity reported by (Mushiake et al., 2006).
We denote time-steps within the plan (but all still represented simultaneously) with parentheses; for
instance, the ‘Up’ action at the first, second, and third time steps is represented as U(1), U(2), and U(3),
respectively. We use 4 neurons to represent each hidden state, and thus 60 neurons (4×5×3) to represent
the 5 possible cursor movements across 3 time steps
4
bioRxiv preprint doi: https://doi.org/10.1101/2025.11.26.690672; this version posted November 26, 2025. The copyright holder for this preprint
(which was not certified by peer review) is the author/funder, who has granted bioRxiv a license to display the preprint in perpetuity. It is made
available under aCC-BY 4.0 International license.
(A) (B) (C)
(D) (E) (F)
(D)
(G) (H) (I)
Figure 2 Planning a sequence of three cursor movements in a maze. This simulation replicates
the experimental setup of (Mushiake et al., 2006). (A-B) Monkeys navigated a 5×5 ‘maze’ by controlling a
joystick. They could perform five possible cursor actions: Up, Down, Left, Right, and Stay. (C) Schematic
illustration of the results reported in (Mushiake et al., 2006, Figure 3), showing three neurons selective for
the Right cursor movement at 1st time step, the Left cursor movement at the 2nd time step, and the Left
cursor movement at the 3rd time step. These neurons correspond to R(1), L(2) and L(3) in our simulations.
(D-F)and(G-I):twoexamplemazenavigationproblems, consistinginmovingfromthestart(greensquare)
to the goal state (red circle). Each white cell represents a valid navigable state, whereas black cells indicate
blocked states. Walls are depicted as solid lines, and open lines (doors) represent allowed transitions. For
each configuration, the successful strategy (shortest policy) is highlighted with arrows. (D) In this example
maze, the planned policy is Up-Left-Left (ULL). (E) Raster plots showing simulated neural activity, with
fourneuronscodingforeachofthe5controlstates(Up,Down,Left,Right,Stay)atLevel2,ateacheachof
thethreetimesteps. Neuronscodingforactionsatthe3timestepsarecolorcodedinred,yellowandviolet,
respectively. At the end of the simulation, corresponding to the delay period before execution, the policy
ULL is coded by the simultaneous activation of three populations of neurons, U(1), L(2) and L(3). (F)
The same results, but plotted as simulated firing rates of neurons associated with different actions. Neurons
representing U, D, L and R are coded with circles, squares, diamonds, and triangles, respectively. The stay
action is not shown for simplicity. (E) In this example maze, the inferred policy is Up-Right-Right (URR).
(H-I) Simulated raster plots and firing rates for the policy URR, following the same format as Panels C-D.
See the main text for further explanation.
5
bioRxiv preprint doi: https://doi.org/10.1101/2025.11.26.690672; this version posted November 26, 2025. The copyright holder for this preprint
(which was not certified by peer review) is the author/funder, who has granted bioRxiv a license to display the preprint in perpetuity. It is made
available under aCC-BY 4.0 International license.
Figure 2D illustrates an example problem in which the agent plans a sequence of three cursor move-
ments to navigate from the start location (green; S ) to the goal location (red; S ). Figure 2D shows a
33 21
simulated raster plot representing the inferential process for the five possible cursor movements (Up, Down,
Left, Right, Stay) across the three time steps. The 15 horizontal lines represent the simulated firing of 15
neural populations (each comprising four neurons) encoding the five cursor movements at three time steps.
For instance, U(1) (first line), U(2) (sixth line), and U(3) (eleventh line) correspond to planning the ‘Up’
movement at the first, second, and third time steps, respectively. Cursor movements at different time steps
are color-coded: red, yellow, and violet correspond to the first, second, and third time steps, respectively.
Atthestartoftheplanningprocess(time0), theagentmaintainsarelativelyflatbeliefdistributionover
thefirst,second,andthirdplannedcursormovements. UponpresentationofthegoallocationS ,itupdates
21
its beliefs about all three movements. During the early stage of planning (approximately 0.2–0.6), parallel
competitionoccursamongthetwoavailablecursormovementsattimestep1(U(1)andD(1)),thetwomost
likely movements at time step 2 (L(2) and R(2)), and the three most likely movements at time step 3 (U(3),
L(3),andR(3)). Byaround0.6,planningiscompleted,andthethreeselectedcursormovements(U(1),L(2),
and L(3)) exhibit simultaneous, sustained activation, which can serve as a prospective working memory for
the plan. However, as time passes—and the plan is executed at the lower level—mnemonic representations
of early elements become postdictive.
ThedynamicsoftheinferentialprocesscanalsobeobservedinFigure2F,whichshowstheaveragefiring
rates of the 12 neural populations involved in cursor movement planning (with ‘Stay’ actions omitted). The
figure illustrates that the three selected cursor movements (U(1), L(2), and L(3)) gradually increase their
activation over time, with the first planned movement (U(1)) rising fastest, reflecting faster convergence
during inference. These dynamics resemble a competitive queuing mechanism, in which the first element
of a sequence is activated first, but here this pattern emerges spontaneously during inference. It is also
apparent that most of the non-selected cursor actions increase slightly before decreasing, as they lose the
competition with alternative plans. Unfeasible actions (e.g., L(1) and R(1)) instead show an immediate
decrease in activity.
Figures 2G–I illustrate another example problem, in which the agent plans a sequence of three cursor
movements from the start location (green; S ) tothe goal location(red; S ), along withthe corresponding
33 25
inferential dynamics, using the same format as Figures 2D–F.
In summary, these simulations demonstrate how inferential planning dynamics naturally reproduce the
simultaneous activation and updating of neural populations encoding cursor movements at different time
steps, as observed in the monkey lateral prefrontal cortex (Mushiake et al., 2006).
2.3 Inferring and holding in memory a sequence of saccades
Second, we consider a task (Xie et al., 2022) in which monkeys were first shown a sequence of three targets
(from six possible targets arranged in a hexagon) and then, after a delay, were required to saccade to the
same three targets in order (Figure 3A-D). Unlike the previous task, this requires inferring a plan from
observations and maintaining it in working memory. A key finding of this study was that, during the delay
period, the prefrontal representation decomposed into three distinct and near-orthogonal subspaces for each
element (referred to as ‘ranks’) in the sequence (Figure 3C).
Figure 3E–G shows the results of a simulation of the (Xie et al., 2022) experiment. The generative
model’s structure is the same as in the previous simulations, but the states at each level differ. Level 1
controls eye movements and is not the focus of our analysis. Level 2 comprises 6 targets for each of the 3
timesteps,correspondingto18neuralpopulationsinFigure3E.TargetsarelabelledA−F,andthenumber
inparenthesesdenotesthetimestep. Atthebeginningofanexampletrial(‘Pre’period),theagentmaintains
a relatively flat belief distribution over the next targets. During the observation periods ‘S1’, ‘S2’, and ‘S3’
the agent observes targets A, B, and C, respectively, and incrementally infers that the correct plan is ABC.
Notably, during ‘S1’ it infers A(1) with high probability while simultaneously decreasing the probabilities
of A(2) and A(3), since targets cannot be repeated. During ‘S2’ it maintains its belief about A(1) and
additionally infers B(2). Finally, at ‘S3’ it infers the complete ABC plan and maintains it throughout the
6
bioRxiv preprint doi: https://doi.org/10.1101/2025.11.26.690672; this version posted November 26, 2025. The copyright holder for this preprint
(which was not certified by peer review) is the author/funder, who has granted bioRxiv a license to display the preprint in perpetuity. It is made
available under aCC-BY 4.0 International license.
(A) (B) (C)
(D)
(G)
(E) (F)
Figure3Inferringandholdinginmemoryasequenceofthreesaccades. Thissimulationreproduces
the experimental setup of (Xie et al., 2022). (A–B) Monkeys were instructed to perform sequences of three
saccades toward six possible targets, denoted as {A–F}. (C) Schematic illustration of the results reported
in(Xieetal.,2022, Figure2). Thefigureshowsthedisentangledneuralstatespacerepresentationprojected
onto three near-orthogonal 2D, step-specific subspaces, one per panel. Within each panel, Black-connected
points indicate samples at the end of the delay arranged in a hexagonal geometry; central points correspond
tothebeginningofthedelay. (D)Exampleofatrial, inwhichmonkeysmaintainedacentralfixation(green
square) while they were shown three consecutive targets, A, B, and C, that they had to fixate in the same
order after a delay period. (E-F) Simulated firing rates and spike trains for an example trial, requiring
generate sequential saccades to the A, B, and C targets. (G) Simulated population responses for each
combination of step and target during the delay period, projected onto three 2D step-specific subspaces,
one per panel; note that these subspaces correspond to the rank-subspaces in (Xie et al., 2022), shown in
Panel C. The bottom-left plot shows that the three subspaces are oriented in a near-orthogonal manner in
neural state space, as indicated by the large principal angles between them. The bottom-right plot shows
the cumulative explained variance along the different steps in neural state space, reflecting the symmetric
partitioning of information across the three subspaces. See the main text for further explanation.
delay period. The corresponding average firing rates for this inferential process are shown in Figure 3F, in
the same format as the first simulation.
To test whether the neural coding in our simulation reproduces the near-orthogonal rank subspaces re-
portedby(Xieetal.,2022),weappliedthesameanalysisapproachastheoriginalempiricalstudy,projecting
population activity into three 2D step-specific ‘rank-subspaces’. Figure 3G shows the simulated population
responses for each target and time step projected onto these subspaces, with the six target locations colour-
coded. The results match very well the empirical data. The hexagonal shape of the subspaces is the same
as the empirical data (Figure 3C). Furthermore, the large principal angles between the three subspaces,
togetherwiththecumulativeexplainedvarianceacrossstepsinneuralstatespace,recapitulatetheempirical
findings of (Xie et al., 2022) and indicate that the subspaces are nearly orthogonal.
7
bioRxiv preprint doi: https://doi.org/10.1101/2025.11.26.690672; this version posted November 26, 2025. The copyright holder for this preprint
(which was not certified by peer review) is the author/funder, who has granted bioRxiv a license to display the preprint in perpetuity. It is made
available under aCC-BY 4.0 International license.
Insummary,thissimulationdemonstratesthatinferentialplanningdynamicsreproducetheneuralpopu-
lation(information)geometryobservedby(Xieetal.,2022)duringthedelayperiod,whenmonkeysmaintain
a sequential plan for three saccades in working memory.
2.4 Inferring and holding in memory a variable-length sequence of forward or
backward saccades
Third,weconsideranexperiment(Chenetal.,2024)withanidenticalsetuptotheprevioustaskbutextended
tothreenovelconditions(Figure4A-BandFigure5A-B).Inthefirst(Forward)condition,monkeysobserved
sequences of variable length—from one to three targets—and therefore had to infer the length of their plan.
In the second (Backward) condition, monkeys again observed sequences of variable length but were required
toreproducetheplaninthebackwarddirection, thatis,tomakesaccadestothetargetsinthereverseorder
of presentation. Finally, in the third (Mixed) condition, monkeys observed sequences of fixed length (two
targets) and then received a cue instructing them to reproduce the plan either in the forward direction (the
same order of presentation) or in the backward direction (the reverse order).
As in (Xie et al., 2022), the first, second, and third actions in the sequence were represented in separate
subspaces—herereferredtoas‘memory’subspaces. Additionally, thedynamicsofthesesubspacesexhibited
a gradual build-up of activity at the moment when the animal could infer its position within the sequence.
Forexample, iftheanimalknewthatthesequencehadtobeexecutedintheforwarddirectionandobserved
target A at ‘S1’ it could already infer A(1), even if the actual sequence length was still unknown. This was
reflected in a rapid build-up of activity corresponding to A at ‘S1’ (Figure 4C). Conversely, if the animal
knewthatthesequencewastobeexecutedinthebackwarddirectionandobservedtargetA,itcouldnotyet
inferwhetherthecorrectactionwasA(1),A(2),orA(3),resultinginnosuchbuild-upofactivity(Figure4E).
Furthermore, during observation of the three targets (S1, S2, S3), additional ‘sensory’ subspaces transiently
coded for the observed targets (Figure 4D). Finally, an analysis of the third (Mixed) condition revealed
thatmonkeysusedcommonsubspacesacrossbothforwardandbackwardtasks: thefirst‘memory’subspace
(‘memory-1’) in the forward condition could be generalized to the second ‘memory’ subspace (‘memory-2’)
inthebackwardcondition,andthesecond‘memory’subspace(‘memory-2’)inthebackwardconditioncould
be generalized to the first ‘memory’ subspace (‘memory-1’) in the forward condition (Figure 5C).
To model this task, we used the same hierarchical generative model as in the previous simulation, but
with an additional hidden state encoding the agent’s belief about whether the task required a ‘forward’ or
‘backward’ plan execution. In the first two conditions, this belief was known before the target sequence was
shown, whereas in the third condition it was inferred when the ‘forward’ or ‘backward’ cue appeared.
Figure4F-Nshowsthesimulationofthefirsttwo(ForwardandBackward)conditionsofthe(Chenetal.,
2024) study, in which the monkeys know from the start whether the plan will be executed in the forward or
backward direction but do not know the sequence length. Figure 4F-H shows the simulation of the Forward
condition. The gradual build-up of neural activity associated with the ABC sequence to be executed in the
forwarddirectioncanbeseenatthreedifferentlevels: inthesimulatedrasterplots(Figure4F),thesimulated
firing rates (Figure 4G), and the simulated ‘memory slots’, which simply correspond to 3D projections of
the principal components (PCs) of simulated neural activity during inference (Figure 4H). In all cases, the
build-upofthefirsttargetintheplan(A(1))isfasterthanthatofthesecond(B(2))andthird(C(3))targets,
consistent with the experimental data (Figure 4C).
Figure 4I-K presents the results of the simulation for the Backward condition. The sequence of target
presentations (A, B, and C) was identical to that in the Forward condition, but the temporal dynamics
of activity differed. Following the presentation of the first two targets (A and B), the model maintained
multipleconcurrenthypothesesabouttheirpossiblepositionsinthesequence(A(1),A(2),A(3),B(1),B(2),
B(3)), reflecting uncertainty about sequence length. This ambiguity persisted until the third target (C)
was observed, at which point its identity as the final element (C(3)) became unambiguous, enabling rapid
resolution of uncertainty and selective build-up of activity corresponding to the third step. This pattern
parallels the empirical findings (Figure 4E).
8
bioRxiv preprint doi: https://doi.org/10.1101/2025.11.26.690672; this version posted November 26, 2025. The copyright holder for this preprint
(which was not certified by peer review) is the author/funder, who has granted bioRxiv a license to display the preprint in perpetuity. It is made
available under aCC-BY 4.0 International license.
(A) (F) (I) (L)
(B)
(C) (G) (J) (M)
(D)
(H) (K) (N)
(E)
Figure 4 Inferring and holding in memory a variable-length sequence of saccades, to be ex-
ecuted in either the forward or the backward direction. This simulation reproduces the first two
conditions of the experimental setup of (Chen et al., 2024). In (A-B), sequences of variable length (one to
three elements) are drawn from six possible target {A−F} (e.g., ABC, AB, ABD, BCA, CB, A, B). For
each block of trials, the instruction is to later execute the trial in the forward or backward direction. The
targetsarepresentedatstagesS1,S2,andS3(butS2andS3targetscanbeomitted). Duringthesubsequent
delay period, the inferred sequence is maintained in working memory. (C-E) Schematic illustration of the
results reported in (Chen et al., 2024, Figure 3), showing neural state activities corresponding to forward
‘memory’ populations, ‘sensory’ populations, and ‘backward’ memory populations. (F-H) Simulation of the
ABC sequence in the Forward condition. (F) Raster plots showing simulated neural activity, with four neu-
rons coding for each of the 6 control states (Targets A−F) at Level 2, at each each of the three time steps.
Neurons coding for control states at the 3 time steps are colour coded in red, yellow and violet, respectively.
At the end of the simulation, corresponding to the delay period before execution, the policy ABC is coded
bythesimultaneousactivationofthreepopulationsofneurons,A(1),B(2),andC(3). (G)Thesameresults,
but plotted as simulated firing rates of neurons associated with different actions. (H) The same results, but
plotted as simulated dynamics of the first three principal components (PCs) summarizing the neural state
space shown in (C) and corresponding to the ‘memory’ subspaces in the forward case in (Chen et al., 2024).
(I-K) Simulation of the ABC sequence in the Backward condition, using the same format as (F-H). These
activations summarize neural state space shown in (E) and corresponding to the ‘memory’ subspaces in the
backward case in (Chen et al., 2024). (L-N) Simulation of Level 1 activations during the observation of the
ABC sequence in both the Forward and Backward conditions. This simulation follows the same format as
(F–H) but depicts the activity of hidden states at Level 1 rather than Level 2. These activations summarize
the neural state space shown in (D) and corresponding to the ‘sensory’ subspaces in (Chen et al., 2024). See
the main text for further explanation. 9
bioRxiv preprint doi: https://doi.org/10.1101/2025.11.26.690672; this version posted November 26, 2025. The copyright holder for this preprint
(which was not certified by peer review) is the author/funder, who has granted bioRxiv a license to display the preprint in perpetuity. It is made
available under aCC-BY 4.0 International license.
Additionally, Figure 4L-N illustrates the transient activation of Level 1 actions inferred during the ob-
servation of the three targets, corresponding to the ‘sensory subspaces’ illustrated in Figure 4D. Within the
hierarchicalmodel,theseLevel1activationsarisefrombottom–upinferenceofthecurrentlyobservedtargets
and provide evidence that updates higher-level (Level 2) beliefs about the sequence. Unlike the sustained
Level 2 representations, which encode abstract ‘memory’ subspaces, Level 1 activations are short-lived and
confined to the sensory epochs, reflecting the transient message passing required for hierarchical inference.
Figure 5D-L shows the simulation of the third condition of the study of (Chen et al., 2024), in which
monkeys know from the beginning that the plan consists of two targets but are informed about the forward
or backward direction only when the cue is presented. In this case, after observing the two targets, A and
B, the model maintains parallel, equally plausible, hypotheses, A(1), A(2), B(1), and B(2). After receiving
either a ‘forward’ or ‘backward’ cue, the model can correctly infer the AB (Figure 5D-F) or the BA plan
(Figure5G-I).Afterobservingthetwotargets,B andA,anda‘backward’cue,themodelcancorrectlyinfer
the AB plan (Figure 5J-L). This simulation also demonstrates the reuse of common ‘memory subspaces’ for
the first and second targets across both forward and backward tasks observed empirically (Figure 5C). For
example, the neural population encoding A(1) is the same whether the model has observed targets A and B
followed by a ‘forward’ cue (Figure 5A), or targets B and A followed by a ‘backward’ cue (Figure 5G).
Insummary,thissimulationillustrateshowinferentialplanningdynamicsreproducethenear-orthogonal,
hexagon-shaped subspaces for sequential targets, which are shared across forward and backward tasks, as
reported by (Chen et al., 2024).
3 Discussion
In this paper, we have shown that the recently discovered ‘activation slots’ are an effective neural substrate
for inferring arbitrary plans. Further, we showed the activity of model neurons during inference match
experimentallyrecordedneuronsinavarietyofplanningandsequencememorytasks(Mushiakeetal.,1991;
Xieetal.,2022;Chenetal.,2024). Weanticipateourplanningasactiveinferenceformulation,usingmessage
passingbetweenactivationslots,willserveasaframeworkforfuturefinegrainedmechanisticunderstanding
of planning in prefrontal cortex (and beyond) at the level of neuron and synapse.
Indeed, concurrent modelling work has shown that when RNNs are trained on spatial planning tasks,
theylearntoplanwithactivationslots—withplansasfixedpointsofattractordynamics—withthesynaptic
connections between slots mirroring the connectivity structure of the spatial environment (Jensen et al.,
2025). Thisbearsarelationtoourinferentialplanningviamessagepassingbetweenslots(where,technically,
the attractors are variational free energy minima). Our inferential planning approach, however, not only
provides a formalism for arbitrary planning tasks, but also provides a formal answer to a key question
about neural representation: why plan elements are coded simultaneously. In inferential planning (e.g.,
active inference, planning as inference, and related approaches (Attias, 2003; Botvinick & Toussaint, 2012;
L´azaro-Gredilla et al., 2024; Friston et al., 2017a; Parr et al., 2022; Ortega & Braun, 2013; Gershman &
Beck, 2017; Kappen et al., 2012; George et al., 2021; Pezzulo et al., 2018; Levine, 2018; Isomura et al., 2022;
Bastos et al., 2012)), a plan is generated by inferring the most likely sequence of actions (or policy) leading
from initial to goal states. Crucially, this inferential process entails reciprocal message passing among
representations of past, present, and future (expected) states, which must therefore be maintained and
updatedinparallel(George&Hawkins,2009;Georgeetal.,2025;Fristonetal.,2017a,b). Thesimultaneous
coding of plan elements is therefore not a nuance but a necessary prerequisite for the message passing that
underlies planning.
Other models (beyond the aforementioned RNNs (Whittington et al., 2025; Jensen et al., 2025)) also
represent all elements in a sequence simultaneously. Competitive queuing models (Bullock, 2004) generate
serial order via a competitive process in which the most active unit wins the competition and generates
the corresponding action; it then inhibits itself, allowing the next most active unit to drive the subsequent
action, and so forth. This differs from our framework which can endogenously generate a sequence of plan
element activations without requiring a predefined queuing mechanism. Indeed, in Figure 2F,I, the firing
rate of the first cursor movement increases faster than that of the second and third ones, reflecting a faster
10
bioRxiv preprint doi: https://doi.org/10.1101/2025.11.26.690672; this version posted November 26, 2025. The copyright holder for this preprint
(which was not certified by peer review) is the author/funder, who has granted bioRxiv a license to display the preprint in perpetuity. It is made
available under aCC-BY 4.0 International license.
(A) (D) (G) (J)
(B)
(C) (E) (H) (K)
(F) (I) (L)
Figure 5 Inferring and holding in memory a fixed-length sequence of saccades, to be executed
in either the forward or backward direction. This simulation reproduces the third condition of the
experimental setup of (Chen et al., 2024). (A-B) In this task, the sequence length is fixed to two targets,
selected from the set of six possible targets {A−F}. The two targets are presented sequentially during
epochsS1andS2,followedbyadelayperiodandaninstructioncueindicatingwhetherthesequenceshould
bereproducedintheforward orbackward direction. Duringthesubsequentdelayperiod,theinferredplanis
maintainedinworkingmemory. (C)Schematicillustrationoftheresultsreportedin(Chenetal.,2024,Figure
4), showing that the first ‘memory’ subspace (‘memory-1’) in the forward condition could be generalized to
the second ‘memory’ subspace (‘memory-2’) in the backward condition, and the second ‘memory’ subspace
(‘memory-2’)inthebackwardconditioncouldbegeneralizedtothefirst‘memory’subspace(‘memory-1’)in
theforwardcondition. Thehorizontalcolouredbarsindicatetimewindowswherethedecodingperformance
of an algorithm trained to generalize from forward to backward ‘memory’ subspaces (or vice versa) was
significantly higher than the chance level, indicating that the subspaces could be effectively generalized.
Training and test epochs for the algorithm are shown in green and orange, respectively. (D-F) An example
problem: inferring the AB sequence in the forward condition. (D-E) Raster plots showing simulated neural
activity and simulated firing rates associated with inferring the AB plan. (F) Simulated dynamics of the
two first principal components during the task. (G-I) Another example problem: inferring the AB sequence
in the backward condition. (J-L) Another example problem: BA sequence in the backward condition. See
the main text for further details.
resolution of uncertainty about what to do next. Other models represent multiple ordered elements of a
sequence simultaneously along a ‘mental line,’ enabling transitive inference (Jensen et al., 2015; Di Antonio
et al., 2024; Mannella & Pezzulo, 2025). This contrasts with our framework, which uses simultaneous
representations of actions and states to construct and update plans, rather than to encode relational order.
11
bioRxiv preprint doi: https://doi.org/10.1101/2025.11.26.690672; this version posted November 26, 2025. The copyright holder for this preprint
(which was not certified by peer review) is the author/funder, who has granted bioRxiv a license to display the preprint in perpetuity. It is made
available under aCC-BY 4.0 International license.
While building an understanding—using a probabilistic formalism—is one level abstracted from neuron
and synapse, it will not only be helpful when interpreting representations from tasks that manipulate tran-
sition probabilities between goals or those with cue uncertainty (Findling et al., 2025), but also provides
a formal account of any neural representation that corresponds to a variable in the underlying generative
model. Forexample,ourprobabilisticframingsuggeststhatthe‘sensorysubspaces’observedin(Chenetal.,
2024) correspond to Level 1 representations that play a central role in hierarchical inference, rather than
serving merely as temporary storage. This could be tested by perturbing these sensory subspaces (e.g., op-
togenetically), which should disrupt the animal’s ability to correctly infer targets, as shown in other studies
using hierarchical inference (Proietti et al., 2023; Van de Maele et al., 2024; Donnarumma et al., 2025).
Thereareseveral(addressable)limitationsofourmodel. First,wepredefinedseparateneuralpopulations
for each element of a plan, which differs from the frontal cortex observations in (Xie et al., 2022; Panichello
et al., 2024) in which subspaces are distributed across neurons. Such a distributed coding scheme could,
however, be readily recovered by assuming a different factorization of the generative model. Second, for
simplicity, we focused only on control states at Level 2 and actions at Level 1, ignoring the dynamics of
other latent states. Future work could ask whether incorporating these latent states provides additional
insights into sequence processing in the frontal cortex. Third, we only analysed the planning phase, rather
than the execution phase. Thus our neural subspaces correspond to distinct (and fixed) positions (e.g.,
1,2,3,...) of the plan. This is subtly different to the slots model (Whittington et al., 2025) in which slots
correspondtorelativepositions(e.g.,present,past,orfuture)withslotcontentsmovingbetweenslotssothat
the present slot always contains the present sequence element. This relative representation makes readout
(i.e., execution) extremely efficient as there only needs to be one set of readout weights. While we modelled
planningwithfixedslots,wepositthat,inprefrontalcortex,duringtheexecutionphasethecontentsofslots
will shuffle between one-another to take advantage of the simple readout mechanism. Indeed experimental
data suggests this, with planning phases using using fixed slots (Chen et al., 2024) (like our model), but
execution passing contents between slots (El-Gaby et al., 2024) (like the slots model).
Frontal cortex has long been known to be central to higher level cognitive functions including cognitive
control (Miller & Cohen, 2001; Duncan, 2001; Pezzulo et al., 2018; Koechlin et al., 2003; Barcel´o, 2021;
Proietti et al., 2025), cognitive map formation (Schuck et al., 2016; Wang & Hayden, 2021; Behrens et al.,
2018),workingmemory(Curtis&D’Esposito,2003)andplanning(Mattar&Lengyel,2022;Koechlin,2016;
Goel & Grafman, 1995; Duncan et al., 1996). In this work we provide a formalism of planning built from
recent experimental results for simultaneous sequence element coding in prefrontal cortex. In doing so we
provide explanations for several empirical observations, mechanistically link planning and working memory,
and generating testable predictions for future experiments.
4 Methods
In this section, we first provide a concise formal overview of the active inference framework that we adopt
in this study (Parr et al., 2022) (Section 4.1). Next, we describe the message-passing scheme that underlies
neural simulations in active inference (Section 4.2) and detail the specific hierarchical generative model
used to implement the simulations (Section 4.3). Finally, we outline the analytical procedures employed to
characterizelow-dimensionalneuralsubspacesinthesimulationofthestudyby(Xieetal.,2022;Chenetal.,
2024) (Section 4.4).
4.1 Brief introduction to Active Inference
ActiveInferenceprovidesanormativeaccountofperception–actionasvariationalBayesianinference undera
generativemodel,coupledwithpolicyselection thatminimizesexpectedfreeenergy(EFE)(Parretal.,2022).
Anagentmaintainsaprobabilisticmodeloverlatent(hidden)statesandobservations—typicallyrepresented
as a probabilistic graphical model (Bishop, 2006)—and acts to realize outcomes that jointly pursue utility
maximization (pragmatic value) and uncertainty minimization (epistemic value or information gain). In
12
bioRxiv preprint doi: https://doi.org/10.1101/2025.11.26.690672; this version posted November 26, 2025. The copyright holder for this preprint
(which was not certified by peer review) is the author/funder, who has granted bioRxiv a license to display the preprint in perpetuity. It is made
available under aCC-BY 4.0 International license.
the following, we summarize the key ingredients of active inference, from model formalization to the steps
required to perform inference by updating hidden states, policies, and precision.
Generative model. Let O =(O ,...,O ) denote a sequence of T observations, S a sequence of T
0:T 0 T 0:T
hidden states, π =(π ,...,π ) a policy (a sequence of control states, or more simply “actions”), γ ∈R a
1 T +
precisioncontrollingthesharpness(i.e.,inversetemperature)ofpolicyselection,andΘthemodelparameters.
A convenient factorization (here, dealing with a single hierarchical level) is:
T T−1
(cid:89) (cid:89)
p(O ,S ,π,γ |Θ)=p(γ |Θ)p(π |γ,Θ)p(S |Θ) p(O |S ,Θ) p(S |S ,π ,Θ). (1)
0:T 0:T 0 t t t+1 t t
t=0 t=0
Parameterization. We write Θ={A,B,C,D,E,β} with:
• Likelihood A: p(O |S ,Θ)=A. It maps hidden causes S to observations O (often categorical).
t t
• Transitions B: p(S |S ,π ,Θ)=B(π ), i.e., policy-conditioned dynamics.
t+1 t t t
• Preferences C: an a priori (log-)distribution over outcomes, encoding what the agent prefers to
observe, P(O )≡C.
τ
• Initial prior D: prior on hidden states p(S |Θ)=D.
0
• Policy prior E: habitual/structural prior over policies.
• Precision γ: sampled from a Gamma prior p(γ |Θ)∼Γ(1,β).
Intuitively,Atellstheagent‘whatsensationstoexpectfromeachstate’;Btellsit‘howhiddenstateschange
underachosenpolicy’;Cencodespreferences;Diswhatitbelievesbeforeseeinganything;Ecaptureshabits.
To move to a hierarchical specification, we would condition the D hidden state priors for one level on the
hidden states at the level above, such that a hidden state at any given level of the model predicts the initial
state of a short sequence at the level below.
Approximate posterior and mean-field form. A common implementation of active inference uses a
tractable variational posterior (see mean-field theory Parisi, 1988):
K
(cid:89)
Q(S ,π,γ)=Q(π)Q(γ) Q(S |π ). (2)
0:K t t
t=0
Withthisdistribution,wemaintainaposterioroverthepolicyQ(π)and,foreachtimestep,aposteriorover
hidden states conditional on the policy.
Variational free energy (VFE). Perceptual inference at time t minimizes
F =KL[Q(S |π )∥P(S |π )]−E [lnP(O |S )]. (3)
t t t t t Q(St|πt) t t
The first term is the Kullback-Leibler (KL) divergence representing the complexity cost (deviation from
prior), the second is the expected negative log-likelihood of the observation (negative accuracy, lack of fit to
data). Balancing the two yields predictive beliefs (Parr et al., 2022).
Under a standard categorical parameterization, a fixed-point update has the form
sπ ≈σ (cid:16) lnAT o + 1 ln (cid:2) B(π )sπ (cid:3) + 1 ln (cid:2) B(π )T sπ (cid:3)(cid:17) (4a)
t t 2 t−1 t−1 2 t t+1
(cid:16) (cid:17)
π =σ lnE−γ G(π )−F (π ) (4b)
t t t t
1
γ = (4c)
t β+E [−lnP(π )]
Qt(πt) t
13
bioRxiv preprint doi: https://doi.org/10.1101/2025.11.26.690672; this version posted November 26, 2025. The copyright holder for this preprint
(which was not certified by peer review) is the author/funder, who has granted bioRxiv a license to display the preprint in perpetuity. It is made
available under aCC-BY 4.0 International license.
Here σ(·) is the componentwise Softmax, s π =Q(S |π) denotes the posterior state marginals and o is the
t t t
one-hotencodingoftheobservedoutcomeattimet,Q(π)=Cat(π)istheposterioroverπ,whileQ (π )and
t t
(cid:16) (cid:16) (cid:17)(cid:17)
(cid:80)
P(π )=Cat σ ln E(π)−G(π ) are respectively the posterior and the prior over π . Intuitively,
t t t
π⊃πt
Eq. (4a): this combines current sensory evidence with predicted messages that depend upon predictions
based on beliefs about previous states and postdictions. Note that in Eq. (4a), B and BT are both assumed
to have normalized (sum-to-one) columns. from beliefs about subsequent states; Eq. (4b): prefer policies
that are habituated (large lnE) and have low EFE; Eq. (4c): increase precision when expected free energy
is low/consistent. The form of Eq. (4a) depends upon a marginal approximation to the prior for states in
Eq. (3)thataccountsforbeliefsaboutbothpastandfuturestates(c.f.,Bayesiansmoothing). Fortechnical
details of this scheme, please see (Parr et al., 2019) and the Appendices of (Parr et al., 2021; Friston et al.,
2017a).
Expected free energy (EFE) and action selection. Policies are scored by their EFE:
T
G(π )= (cid:88) (cid:16) KL (cid:2) Q(O |π)∥p(O ) (cid:3) +E [H[p(O |S )]] (cid:17) , (5)
t τ τ Q˜ τ τ
τ=t+1
where Q(O ,S | π) ≜ P(O | S )Q(S | π) is the predictive posterior distribution, Q(O | π) =
τ τ τ τ τ τ
(cid:80) Q(O ,s | π) is the predicted outcome, P(O ) ≡ C encodes preferences, and H[·] is Shannon en-
Sτ τ τ τ
tropy. Intuitively, the first term (expected cost/risk) favours policies that make preferred outcomes likely;
the second (expected ambiguity) favours policies that reduce uncertainty by seeking informative states.
In this model, action selection corresponds to the generation of predicted control signals, which are
sampled from the policy posterior in Eq. (4b). These samples represent planned actions, reflecting the
agent’s internal simulation of future behaviour under each candidate policy (Parr et al., 2022).
4.2 Message Passing and neural architecture
In this section, we briefly outline the way in which we can interpret the fixed point scheme outlined about
in terms of neuronal message passing, with a focus on Eq. (4a). The idea is relatively simple. If we assume
neuronal membrane potentials for a pool of neurons, on average, are represented by a vector Vπ, and firing
t
rates (again, on average) by Sπ, then treating the softmax function as a neuronal transfer function, such
t
that Sπ = σ(Vπ), we arrive at an interpretation (up to an additive constant) of Vπ = lnSπ. We can then
t t t t
expressthedynamicsofthemembranepotentialstoafirstorderapproximationasasimpleattractorsystem
whose fixed point corresponds to the solution of Eq. (4a):
V˙ π =lnAT O + 1 ln (cid:2) B(π )σ (cid:0) Vπ (cid:1)(cid:3) + 1 ln (cid:2) B(π )T σ (cid:0) Vπ (cid:1)(cid:3) −Vπ. (6)
t t 2 t−1 t−1 2 t t+1 t
Here,thekeypointstonotearethatthemembranepotentialsassociatedwithagivenpopulation(indexed
by time and policy) that represent beliefs about a particular time evolve such that they depend upon the
potentialsofpopulationsrepresentingbeliefsabouttheimmediatepastandfuture. Thisimpliesthatatany
giventime, weneedtosimultaneouslyholdbeliefsabout othertimestoinstantiatethesedynamics. Itisthis
distinctionbetweenthetimeatwhichbeliefsareheld,andthetimesthosebeliefsareabout thatunderwrites
the core ideas in this paper.
Beforewemoveon,itisworthhighlightingthatthispropertyisnotspecifictothemessagepassingscheme
outlinedhere,andwouldalsoapplytostrictbelief-propagationorvariationalmessagepassingschemes. The
reason for this is inherent in the structure of the generative model, rather than of the particular method of
solution. Specifically, the model used here relies in part upon a Markov chain, in which the Markov blanket
of any given state includes both its predecessor and successor. As such, beliefs about proximal time-points
will always be informative about the current time.
14
bioRxiv preprint doi: https://doi.org/10.1101/2025.11.26.690672; this version posted November 26, 2025. The copyright holder for this preprint
(which was not certified by peer review) is the author/funder, who has granted bioRxiv a license to display the preprint in perpetuity. It is made
available under aCC-BY 4.0 International license.
4.3 Hierarchical generative model for planning
The hierarchical Active Inference model employed in this study is designed to structure motor planning
acrosstwohierarchicallevels,denotedbyl. Ateachlevel,themodelencodeshiddenvariablesthatrepresent
distinct aspects of motor organization: low-level motor actions at Level 1 and structured sequences of these
actions at Level 2. The overall architecture of the model is illustrated in Figure 6.
To capture the structured dependencies among motor components, the hidden state space at each level
l is expressed as a tensor product:
S(l) =S(l)⊗S(l)⊗S(l),
1 2 3
whereeachfactor(subscriptsherebeingfactorindices, andnottime-pointsaspreviously)encodesaspecific
dimension of motor planning and control:
• Hidden Control States(S(l))–Thesevariablesspecifythemotorcontrolsoftheactionsthemselves.
1
At the lowest level (l = 1), they represent discrete atomic actions, while at the higher level (l = 2)
they encode sequences of actions composing a coherent motor strategy.
• Hidden Location States (S(l)) – This factor encodes the spatial component of the motor plan.
2
At Level 1, it corresponds to concrete movement execution in physical space, whereas at Level 2, it
represents the structural organization of sequence of action locations corresponding to the policy.
• Hidden Context States(S(l))–Thiscomponentdefinesthecontextualortemporalstructureofthe
3
motorsequence. Inoursimulations, atLevel2itspecifiestheorder inwhichactionsaretobeplanned
(e.g., forward vs. backward order relative to the presentation).
Observations. Each observation O = O ⊗O ⊗O is defined as the tensor product of the following
1 2 3
components:
• O : the observation of control actions.
1
• O : the observation of target locations.
2
• O : the cue indicating the execution order, which specifies the sequence in which actions should be
3
performed.
The cue O is used in Simulation (4) (see Table 1) and includes options such as ‘forward,’ ‘backward,’
3
other possible execution orders, and ‘idk’—a neutral cue indicating that execution does not depend on the
presentation order.
Transition mapping. The transition probability p(S(l)|S(l) ,π ) given control states is specified by the
t t−1 t
tensor:
B(l) =B(l)⊗B(l)
1 2
where:
• B(l) governs transitions among control states.
1
• B(l) defines transitions among spatial locations across time steps.
2
Transitionsarenearlydeterministic,butstochasticityisintroducedtomodelexecutionerrorsoruncertainty
in control signals.
(cid:40)
1−ϵ, if S(l) is the intended next location,
p(S(l)|S(l) ,π )= t
t t−1 t ϵ/(n−1), otherwise,
where ϵ is a small noise term and n is the number of allowable possible locations (where a transition is
actually possible).
bioRxiv preprint doi: https://doi.org/10.1101/2025.11.26.690672; this version posted November 26, 2025. The copyright holder for this preprint
(which was not certified by peer review) is the author/funder, who has granted bioRxiv a license to display the preprint in perpetuity. It is made
available under aCC-BY 4.0 International license.
C(2) E(2) C(2) E(2) Level 2
G(2) π(2) G(2) π(2)
t 1 t 1 t 2 t 2
D(2)
S(2)
B(2)
S(2)
B(2)
S(2)
t t t
1 2 3
A(2) A(2) A(2)
Level 1 Level 1 Level 1
S(1) S(1) S(1)
t t t
1 2 2
A(1) A(1) A(1)
Environment
O O O
t t t
1 2 3
Figure 6 The hierarchical (deep) Active Inference model for action planning. Themodelconsists
of two interacting layers, Level 1 and Level 2, organized within the Active Inference framework. Gray nodes
denote hidden states and policies, yellow nodes represent observations, and edges illustrate probabilistic
dependencies between variables. At the higher level, policies π encode sequences of control states (abstract
actions), whereas at the lower level, they correspond to single motor commands. Rectangular nodes depict
probabilistic distributions – the conditional dependencies defining the Hidden Markov Models – parameter-
ized by the matrices A, B, C, D, and E. The A matrix encodes the likelihood model (how hidden states S
t
generate observations O ); the B matrix parameterizes state transitions under each policy π; the C matrix
t
specifies preferred outcomes and contributes to the expected free energy G; the E matrix represents prior
preferences over policies (representing habits). Notably, the hidden states S(1) at Level 1 serve as observa-
t
tions for the higher-level process at Level 2, linking temporal inference across hierarchical timescales. See
the main text for further explanation.
bioRxiv preprint doi: https://doi.org/10.1101/2025.11.26.690672; this version posted November 26, 2025. The copyright holder for this preprint
(which was not certified by peer review) is the author/funder, who has granted bioRxiv a license to display the preprint in perpetuity. It is made
available under aCC-BY 4.0 International license.
Low-level generative model (Level 1). In simulations of tasks from (Mushiake et al., 2006), S(1)
1
represents the hidden controls of the cursor actions (i.e. Up, Down, Left, Right). In simulations of tasks
from(Xieetal.,2022)and(Chenetal.,2024),S(1) representsthehiddencontrolforthesaccadicmovements
1
towards the targets A,B,C,D,E,F. In both cases, S(1) represents the hidden locations of the target states.
2
Likelihood mapping at Level 1 Thelikelihoodp(O(1)|S(1))betweenhiddenstatesS(1) andobservations
O(1) is specified through the tensor:
A(1) =A(1)⊗A(1)
1 2
where:
• A(1) maps hidden control states S(1) to observations O (primitive control actions).
1 1 1
• A(1) maps hidden target states S(1) to observations O (target locations).
2 2 2
The mapping is almost deterministic but implements cosine tuning for sensory encoding:
p(O|S(1))∝cos(θ −θ ),
O S
where θ and θ represent preferred directions of observation and hidden state, respectively. Recognition
O S
accuracy is tuned in order to get approximately 85% with respect of the preferred direction, and misclassi-
fication occurs toward the closest state in angular space.
Higher-level generative model (Level 2). Level 2 comprises three hidden-state factors, analogous
to those in Level 1, representing beliefs about Controls (S(2)) and Locations (S(2)). The third factor,
1 2
Context (S(2)),encodesthesequenceexecutionorder(e.g.,‘forward’,‘backward’)oritsabsence(‘idk’). This
3
contextualfactormaybefixedpriortothetrial(asinsimulationsfrom(Xieetal.,2022))orrevealedduring
the trial through observation of the cue O .
3
Likelihood mapping at Level 2 Thelikelihoodp(S(1)|S(2))specifieshowhigher-levelhiddenstatesS(2)
predict lower-level hidden states S(1). It is represented by the tensor:
A(2) =A(2)⊗A(2)⊗A(2),
1 2 3
where:
• A(2): maps higher-level (sequence of) control states S(2) to lower-level controls S(1);
1 1 1
• A(2): maps higher-level (sequence of) target states S(2) to lower-level locations S(1);
2 2 2
• A(2): maps higher-level context states S(2) to the execution order cue O .
3 3 3
Here,higher-levelstatesaremappedontolower-levelstates(orcuesinthecaseofS(2) ,whicharetreated
3
as observations in the hierarchical model. Formally, the likelihood mappings are defined as p(S(1) | S(2)),
1 1
p(S(1) | S(2)), and p(O | S(2)), with each mapping being nearly deterministic while allowing for a small
2 2 3 3
degree of stochasticity (approximately 5% noise) in recognizing the correct correspondence.
Observations O (e.g., ‘Forward’ or ‘Backward’ cues) are included in tasks from (Chen et al., 2024) to
3
indicate execution order.
Preferences. The tensor C(2) =C(2)⊗C(2)⊗C(2) encodes prior preferences over observations:
1 2 3
• C(2): preferences over motor actions O(2) (goal-directed behaviour).
1 1
• C(2): preferences over spatial positions O(2) (preferred locations). In the simulations of tasks from
2 2
(Mushiake et al., 2006) this preference was used to setup target goal states.
• C(2): preferences over execution order cue O(2) (e.g., ‘Forward’ vs. ‘Backward’).
3 3
bioRxiv preprint doi: https://doi.org/10.1101/2025.11.26.690672; this version posted November 26, 2025. The copyright holder for this preprint
(which was not certified by peer review) is the author/funder, who has granted bioRxiv a license to display the preprint in perpetuity. It is made
available under aCC-BY 4.0 International license.
Prior beliefs. The tensor D(2) =D(2)⊗D(2)⊗D(2) encodes priors over hidden states:
1 2 3
• D(2): prior over Controls (initial policy or actions distribution).
1
• D(2): prior over Locations (starting position).
2
• D(2): prior over Context (execution order).
3
Additionally, E(2) encodes the prior distribution over policies. In line with the simulations from (Chen
et al., 2024), where sequences vary in length, we assign equal prior probability to policies of length 1, 2,
and 3. This compensates for the combinatorial bias favoring longer sequences (which are more numerous),
ensuringthat,forinstance,uponpresentationofthefirsttarget,thereremainsanequalpriorlikelihoodthat
thefullsequencewillbeoflength1,2,or3. Tab1showsasummaryofmainsettingsforthetaskssimulated
in the paper.
Notethat,forsimplicity,thegenerativemodelsusedinthisstudywerepredefined,reflectingthefactthat
monkeys had extensively practiced the tasks before neural recordings. However, in principle, such models
could also be learned through interaction with the environment, as demonstrated in previous work (Friston
et al., 2016, 2024; Van de Maele et al., 2024; George et al., 2021).
4.4 Subspace analysis
The procedures for generating the 2D plots follow the approach described in (Xie et al., 2022). Neural
responseswereobtainedbyperformingalinearregressionofspikecountsduringtheplanningperiodagainst
one-hot encoded task vectors (e.g., an 18-dimensional vector representing 6 directions across 3 steps). This
yielded, for each neuron, a set of regression coefficients β(r,l), where r denotes the step and l the direction.
For clarity, we focus on three time steps and six directions, although the procedure generalizes to other
configurations (e.g., 6 directions and 2 steps, see Fig. 5).
To capture variance in neural responses—attributable to item variation at each step—we applied prin-
cipal component analysis (PCA) to the regression coefficients grouped by step. This analysis produced a
reliable state-space representation that captures both the relationships among step-specific subspaces and
the geometry of spatial representations within each subspace.
A multivariable linear regression model was used to determine how task variables influence the average
neuralresponseduringthelatedelayperiod(1sbeforethegosignal). Forexample, alength-3sequencecan
be represented as an 18-dimensional three-hot vector. A sequence of targets ECA corresponds to indices [5,
3, 1] and can be encoded as:
(0,0,0,0,1,0, 0,0,1,0,0,0, 1,0,0,0,0,0).
We defined 18 one-hot vectors S as task variables, where r ∈ {1,2,3} and l ∈ {1,...,6}. The average
r,l
neural response of the ith neuron in one trial during the late delay was modeled as:
3 6
(cid:88)(cid:88)
y = β (r,l)S +ϵ ,
i i r,l i
r=1l=1
whereβ (r,l)areregressioncoefficientsandϵ istrial-by-trialnoise. Topreventoverfitting,weappliedLasso
i i
regularization and selected the regularization amplitude via maximum likelihood.
The regression coefficients β(r,l) were then used to identify low-dimensional subspaces capturing most
task-related variance. Specifically, with N neurons, an N-dimensional vector
β(r,l)=[β (r,l),...,β (r,l)]⊤
1 N
represents each rank–item combination (r,l) at the population level. To capture variance due to item
differences at each rank, the 18 vectors β(r,l) (r = 1,2,3; l = 1,...,6) were divided into three groups by
rank. For each group (fixed r), PCA was performed to extract the first two principal components, providing
a compact representation of spatial geometry within each step-specific subspace.
bioRxiv preprint doi: https://doi.org/10.1101/2025.11.26.690672; this version posted November 26, 2025. The copyright holder for this preprint
(which was not certified by peer review) is the author/funder, who has granted bioRxiv a license to display the preprint in perpetuity. It is made
available under aCC-BY 4.0 International license.
Task Settings Description
S 1 (2) ∈{Up,Down,Left,Right,Stay} 5 cursor controls
Simulation (1): S(2) ∈{S ,S ,...,S } 25 target locations
Planning sequences of 2 11 12 55
C(2) =Goal Preference on goal state
cursor movements 2
((Mushiake et al., 2006), C 3 (2) =∅ No contextual cue
Fig. 2) E(2) =p(π |Maze) Prior constrained by environment
Fixed-length sequences (3)
T(2) =3
Simulation (2): S(2) ∈{A,B,C,D,E,F,Stay} Six directions + no move
Inferring and holding 1
S(2) ∈ (cid:83)T {A(t),...,F(t),Empty(t)} targets + empty for each step
in memory a sequence of 2 t=1
Sequence Length = 3 Fixed-length sequences (3)
saccades ((Xie et al., 2022),
Fig. 3) C( 3 2) ∈{Forward} Contextual cue known from start
Simulation (3): S(2) ∈{A,B,C,D,E,F,Stay} Six directions + no move
Variable-length sequence 1
S(2) ∈ (cid:83)T {A(t),...,F(t),Empty(t)} targets + empty for each step
of forward/backward saccades 2 t=1
((Chen et al., 2024), C( 3 2) ∈{Forward,Backward} Contextual cue known from start
Variable-length sequences
Fig. 4) Sequence Length ∈{1,2,3}
Simulation (4):
S(2) ∈{A,B,C,D,E,F,Stay} Six directions + no move
Fixed-length sequence with 1
S(2) ∈ (cid:83)T {A(t),...,F(t),Empty(t)} targets + empty for each step
forward/backward execution 2 t=1
Sequence Length = 2 Fixed-length policies (2)
((Chen et al., 2024),
O (t )∈{Forward,Backward} Contextual cue observed
Fig. 5) 3 cue
Table 1 Schematics of the simulation parameters. ThetablesummarizeshierarchicalActiveInference
settings for four tasks: (1) planning sequences of cursor movements ((Mushiake et al., 2006), Fig. 2); (2)
inferring and holding in memory a sequence of saccades ((Xie et al., 2022), Fig. 3); (3) inferring and holding
in memory a variable-length sequence of forward or backward saccades ((Chen et al., 2024), Fig. 4); and
(4) inferring and holding in memory a fixed-length sequence of saccades executed in either forward or
backward order ((Chen et al., 2024), Fig. 5). For each task, the table reports hidden state configurations,
prior preferences, and policy constraints. Simulation (1) uses environment-constrained policies and goal
preferences. Simulation(2) expandstarget statesacross timesteps toencodetemporal information, with no
contextual cue. Simulation (3) introduces variable-length sequences with contextual cues known from the
start(ForwardorBackward). Simulation(4)usesfixed-lengthsequenceswithpreferencesforbothdirections,
where the cue is revealed at time step t .
cue
bioRxiv preprint doi: https://doi.org/10.1101/2025.11.26.690672; this version posted November 26, 2025. The copyright holder for this preprint
(which was not certified by peer review) is the author/funder, who has granted bioRxiv a license to display the preprint in perpetuity. It is made
available under aCC-BY 4.0 International license.
Acknowledgments
ThisresearchreceivedfundingfromtheEuropeanResearchCouncilundertheGrantAgreementNo. 820213
(ThinkAhead), the Italian National Recovery and Resilience Plan (NRRP), M4C2, funded by the Euro-
pean Union – NextGenerationEU (Project IR0000011, CUP B51E22000150006, ‘EBRAINS-Italy’; Project
PE0000013, ‘FAIR’; Project PE0000006, ‘MNESYS’), and the Ministry of University and Research, PRIN
PNRR P20224FESY and PRIN 20229Z7M8N. The GEFORCE Quadro RTX6000 and Titan GPU cards
used for this research were donated by the NVIDIA Corporation. T.P. is supported by an NIHR Aca-
demic Clinical Fellowship [ref: ACF-2023-13-013]. KF is supported by funding from the Wellcome Trust
(Ref: 226793/Z/22/Z). J.C.R.W is supported by European Research Council Starting Grant No. 101222868
(NARFB). We used a Generative AI model to correct typographical errors and edit language for clarity.
References
Attias, H. (2003). Planning by probabilistic inference. International workshop on artificial intelligence and
statistics, 9–16.
Averbeck, B. B., Chafee, M. V., Crowe, D. A., & Georgopoulos, A. P. (2002). Parallel processing of serial
movements in prefrontal cortex. Proceedings of the National Academy of Sciences, 99(20), 13172–13177.
Balaguer,J.,Spiers,H.,Hassabis,D.,&Summerfield,C.(2016). Neuralmechanismsofhierarchicalplanning
in a virtual subway network. Neuron, 90(4), 893–903.
Baram,A.B.,Muller,T.H.,Nili,H.,Garvert,M.M.,&Behrens,T.E.J.(2021). Entorhinalandventrome-
dial prefrontal cortices abstract and generalize the structure of reinforcement learning problems. Neuron,
109(4), 713–723.
Barcel´o, F. (2021). A predictive processing account of card sorting: Fast proactive and reactive fron-
toparietal cortical dynamics during inference and learning of perceptual categories. Journal of Cognitive
Neuroscience, 33(9), 1636–1656.
Bastos, A. M., Usrey, W. M., Adams, R. A., Mangun, G. R., Fries, P., & Friston, K. J. (2012). Canonical
microcircuits for predictive coding. Neuron, 76(4), 695–711.
Behrens, T. E., Muller, T. H., Whittington, J. C., Mark, S., Baram, A. B., Stachenfeld, K. L., & Kurth-
Nelson, Z. (2018). What is a cognitive map? organizing knowledge for flexible behavior. Neuron, 100(2),
490–509.
Bishop, C. M. (2006). Pattern recognition and machine learning. Springer.
Botvinick, M. & Toussaint, M. (2012). Planning as inference. Trends in cognitive sciences, 16(10), 485–488.
Botvinick, M. M. & Plaut, D. C. (2006). Short-term memory for serial order: a recurrent neural network
model. Psychological review, 113(2), 201.
Bullock, D. (2004). Adaptive neural models of queuing and timing in fluent action. Trends in cognitive
sciences, 8(9), 426–433.
Chen, J., Zhang, C., Hu, P., Min, B., & Wang, L. (2024). Flexible control of sequence working memory in
the macaque frontal cortex. Neuron, 112(20), 3502–3514.
Curtis, C. E. & D’Esposito, M. (2003). Persistent activity in the prefrontal cortex during working memory.
Trends in cognitive sciences, 7(9), 415–423.
Di Antonio, G., Raglio, S., & Mattia, M. (2024). A geometrical solution underlies general neural principle
for serial ordering. Nature Communications, 15(1), 8238.
bioRxiv preprint doi: https://doi.org/10.1101/2025.11.26.690672; this version posted November 26, 2025. The copyright holder for this preprint
(which was not certified by peer review) is the author/funder, who has granted bioRxiv a license to display the preprint in perpetuity. It is made
available under aCC-BY 4.0 International license.
Donnarumma,F.,Frosolone,M.,&Pezzulo,G.(2025).Integratinglargelanguagemodelsandactiveinference
to understand eye movements in reading and dyslexia. Physics of Life Reviews, 55, 61–78.
Duncan, J. (2001). An adaptive coding model of neural function in prefrontal cortex. Nature reviews
neuroscience, 2(11), 820–829.
Duncan, J., Emslie, H., Williams, P., Johnson, R., &Freer, C.(1996). Intelligenceandthefrontallobe: The
organization of goal-directed behavior. Cognitive psychology, 30(3), 257–303.
El-Gaby, M., Harris, A. L., Whittington, J. C., Dorrell, W., Bhomick, A., Walton, M. E., Akam, T., &
Behrens, T. E. (2024). A cellular basis for mapping behavioural structure. Nature, 1–10.
Elman, J. L. (1990). Finding structure in time. Cognitive science, 14(2), 179–211.
Findling, C., Hubert, F., Laboratory, I. B., Acerbi, L., Benson, B., Benson, J., Birman, D., Bonacchi, N.,
Buchanan, E. K., Bruijns, S., et al. (2025). Brain-wide representations of prior information in mouse
decision-making. Nature, 645(8079), 192–200.
Foster, D. J. (2017). Replay comes of age. Annual review of neuroscience, 40(1), 581–602.
Friston,K.,FitzGerald,T.,Rigoli,F.,Schwartenbeck,P.,&Pezzulo,G.(2017a). Activeinference: aprocess
theory. Neural computation, 29(1), 1–49.
Friston, K., FitzGerald, T., Rigoli, F., Schwartenbeck, P., Pezzulo, G., et al. (2016). Active inference and
learning. Neuroscience & Biobehavioral Reviews, 68, 862–879.
Friston, K. J., Da Costa, L., Tschantz, A., Kiefer, A., Salvatori, T., Neacsu, V., Koudahl, M., Heins, C.,
Sajid, N., Markovic, D., et al. (2024). Supervised structure learning. Biological Psychology, 193, 108891.
Friston,K.J.,Parr,T.,&deVries,B.(2017b). Thegraphicalbrain: Beliefpropagationandactiveinference.
Network neuroscience, 1(4), 381–414.
Ganguli, S., Huh, D., & Sompolinsky, H. (2008). Memory traces in dynamical systems. Proceedings of the
national academy of sciences, 105(48), 18970–18975.
George, D. & Hawkins, J. (2009). Towards a mathematical theory of cortical micro-circuits. PLoS compu-
tational biology, 5(10), e1000532.
George, D., L´azaro-Gredilla, M., Lehrach, W., Dedieu, A., Zhou, G., &Marino, J.(2025). Adetailedtheory
of thalamic and cortical microcircuits for predictive visual inference. Science Advances, 11(6), eadr6698.
George, D., Rikhye, R. V., Gothoskar, N., Guntupalli, J. S., Dedieu, A., & L´azaro-Gredilla, M. (2021).
Clone-structuredgraphrepresentationsenableflexiblelearningandvicariousevaluationofcognitivemaps.
Nature communications, 12(1), 2392.
Gershman, S. J. & Beck, J. M. (2017). Complex probabilistic inference: From cognition to neural computa-
tion. Computational models of brain and behavior, 453–466.
Goel, V. & Grafman, J. (1995). Are the frontal lobes implicated in “planning” functions? interpreting data
from the tower of hanoi. Neuropsychologia, 33(5), 623–642.
Isomura, T., Shimazaki, H., & Friston, K. J. (2022). Canonical neural networks perform active inference.
Communications Biology, 5(1), 55.
Jensen, G., Mun˜oz, F., Alkan, Y., Ferrera, V. P., & Terrace, H. S. (2015). Implicit value updating explains
transitive inference performance: The betasort model. PLoS computational biology, 11(9), e1004523.
Jensen, K. T., Doohan, P., Sabl´e-Meyer, M., Reinert, S., Baram, A., Akam, T., & Behrens, T. E. (2025). A
mechanistic theory of planning in prefrontal cortex. bioRxiv.
bioRxiv preprint doi: https://doi.org/10.1101/2025.11.26.690672; this version posted November 26, 2025. The copyright holder for this preprint
(which was not certified by peer review) is the author/funder, who has granted bioRxiv a license to display the preprint in perpetuity. It is made
available under aCC-BY 4.0 International license.
Jensen, K. T., Hennequin, G., & Mattar, M. G. (2024). A recurrent network model of planning explains
hippocampal replay and human behavior. Nature neuroscience, 27(7), 1340–1348.
Kappen, H. J., G´omez, V., & Opper, M. (2012). Optimal control as a graphical model inference problem.
Machine learning, 87(2), 159–182.
Koechlin, E. (2016). Prefrontal executive function and adaptive behavior in complex environments. Current
opinion in neurobiology, 37, 1–6.
Koechlin,E.,Ody,C.,&Kouneiher,F.(2003). Thearchitectureofcognitivecontrolinthehumanprefrontal
cortex. Science, 302(5648), 1181–1185.
L´azaro-Gredilla, M., Ku, L., Murphy, K. P., & George, D. (2024). What type of inference is planning?
Advances in Neural Information Processing Systems, 37, 116705–116742.
Levine, S. (2018). Reinforcement learning and control as probabilistic inference: Tutorial and review. arXiv
preprint arXiv:1805.00909.
Liu, B., Alexopoulou, Z.-S., & van Ede, F. (2024). Jointly looking to the past and the future in visual
working memory. Elife, 12, RP90874.
Maass, W., Natschl¨ager, T., & Markram, H. (2002). Real-time computing without stable states: A new
framework for neural computation based on perturbations. Neural computation, 14(11), 2531–2560.
Mannella, F. & Pezzulo, G. (2025). Transitive inference as probabilistic preference learning. Psychonomic
Bulletin & Review, 32(2), 674–689.
Mante, V., Sussillo, D., Shenoy, K. V., & Newsome, W. T. (2013). Context-dependent computation by
recurrent dynamics in prefrontal cortex. nature, 503(7474), 78–84.
Mattar, M. G. & Lengyel, M. (2022). Planning in the brain. Neuron, 110(6), 914–934.
Miller, E. K. & Cohen, J. D. (2001). An integrative theory of prefrontal cortex function. Annual review of
neuroscience, 24(1), 167–202.
Miller, K. J., Botvinick, M. M., & Brody, C. D. (2017). Dorsal hippocampus contributes to model-based
planning. Nature neuroscience, 20(9), 1269–1276.
Mushiake, H., Inase, M., & Tanji, J. (1991). Neuronal activity in the primate premotor, supplementary, and
precentral motor cortex during visually guided and internally determined sequential movements. Journal
of neurophysiology, 66(3), 705–718.
Mushiake, H., Saito, N., Sakamoto, K., Itoyama, Y., & Tanji, J. (2006). Activity in the lateral prefrontal
cortex reflects multiple steps of future events in action plans. Neuron, 50(4), 631–641.
Ortega, P. A. & Braun, D. A. (2013). Thermodynamics as a theory of decision-making with information-
processing costs. Proceedings of the Royal Society A: Mathematical, Physical and Engineering Sciences,
469(2153), 20120683.
Panichello, M. F., Jonikaitis, D., Oh, Y. J., Zhu, S., Trepka, E. B., & Moore, T. (2024). Intermittent rate
coding and cue-specific ensembles support working memory. Nature, 636(8042), 422–429.
Parisi, G. (1988). Statistical field theory. Frontiers in physics. Addison-Wesley.
Parr, T., Friston, K., & Pezzulo, G. (2024). Generative models for sequential dynamics in active inference.
Cognitive Neurodynamics, 18(6), 3259–3272.
Parr, T., Limanowski, J., Rawji, V., &Friston, K.(2021). Thecomputationalneurologyofmovementunder
active inference. Brain, 144(6), 1799–1818.
bioRxiv preprint doi: https://doi.org/10.1101/2025.11.26.690672; this version posted November 26, 2025. The copyright holder for this preprint
(which was not certified by peer review) is the author/funder, who has granted bioRxiv a license to display the preprint in perpetuity. It is made
available under aCC-BY 4.0 International license.
Parr, T., Markovi´c, D., Kiebel, S. J., & Friston, K. J. (2019). Neuronal message passing using mean-field,
bethe, and marginal approximations. Scientific Reports, 9(1), 1109.
Parr, T., Pezzulo, G., & Friston, K. J. (2022). Active inference: the free energy principle in mind, brain,
and behavior. MIT Press.
Pearl,J.(2022). Reverendbayesoninferenceengines: Adistributedhierarchicalapproach. Probabilistic and
causal inference: the works of Judea Pearl, 129–138.
Pezzulo, G., Donnarumma, F., Maisto, D., & Stoianov, I. (2019). Planning at decision time and in the
background during spatial navigation. Current opinion in behavioral sciences, 29, 69–76.
Pezzulo, G., Kemere, C., & Van Der Meer, M. A. (2017). Internally generated hippocampal sequences as a
vantage point to probe future-oriented cognition. Annals of the New York Academy of Sciences, 1396(1),
144–165.
Pezzulo, G., Rigoli, F., & Friston, K. J. (2018). Hierarchical active inference: a theory of motivated control.
Trends in cognitive sciences, 22(4), 294–306.
Pezzulo, G., VanderMeer, M.A., Lansink, C.S., &Pennartz, C.M.(2014). Internallygeneratedsequences
in learning and executing goal-directed behavior. Trends in cognitive sciences, 18(12), 647–657.
Proietti, R., Parr, T., Tessari, A., Friston, K., & Pezzulo, G. (2025). Active inference and cognitive control:
Balancing deliberation and habits through precision optimization. Physics of Life Reviews.
Proietti,R.,Pezzulo,G.,&Tessari,A.(2023).Anactiveinferencemodelofhierarchicalactionunderstanding,
learning and imitation. Physics of Life Reviews, 46, 92–118.
Rabinovich, M. I., Varona, P., Tristan, I., & Afraimovich, V. S. (2014). Chunking dynamics: heteroclinics
in mind. Frontiers in computational neuroscience, 8, 22.
Raju, R. V., Guntupalli, J. S., Zhou, G., Wendelken, C., L´azaro-Gredilla, M., & George, D. (2024). Space
is a latent sequence: A theory of the hippocampus. Science Advances, 10(31), eadm8470.
Saito, N., Mushiake, H., Sakamoto, K., Itoyama, Y., & Tanji, J. (2005). Representation of immediate and
final behavioral goals in the monkey prefrontal cortex during an instructed delay period. Cerebral Cortex,
15(10), 1535–1546.
Schuck, N. W., Cai, M. B., Wilson, R. C., & Niv, Y. (2016). Human orbitofrontal cortex represents a
cognitive map of state space. Neuron, 91(6), 1402–1412.
Schwartenbeck, P., Baram, A., Liu, Y., Mark, S., Muller, T., Dolan, R., Botvinick, M., Kurth-Nelson, Z.,
& Behrens, T. (2023). Generative replay underlies compositional inference in the hippocampal-prefrontal
circuit. Cell, 186(22), 4885–4897.
Stachenfeld, K. L., Botvinick, M. M., & Gershman, S. J. (2017). The hippocampus as a predictive map.
Nature neuroscience, 20(11), 1643–1653.
Stoianov, I., Maisto, D., & Pezzulo, G. (2022). The hippocampal formation as a hierarchical generative
model supporting generative replay and continual learning. Progress in Neurobiology, 217, 102329.
Stoianov, I. P., Pennartz, C. M., Lansink, C. S., & Pezzulo, G. (2018). Model-based spatial navigation in
the hippocampus-ventral striatum circuit: A computational analysis. PLoS computational biology, 14(9),
e1006316.
Sussillo, D., Churchland, M. M., Kaufman, M. T., & Shenoy, K. V. (2015). A neural network that finds a
naturalistic solution for the production of muscle activity. Nature neuroscience, 18(7), 1025–1033.
bioRxiv preprint doi: https://doi.org/10.1101/2025.11.26.690672; this version posted November 26, 2025. The copyright holder for this preprint
(which was not certified by peer review) is the author/funder, who has granted bioRxiv a license to display the preprint in perpetuity. It is made
available under aCC-BY 4.0 International license.
Van de Maele, T., Dhoedt, B., Verbelen, T., & Pezzulo, G. (2024). A hierarchical active inference model of
spatial alternation tasks and the hippocampal-prefrontal circuit. Nature Communications, 15(1), 9892.
Wang, M. Z. & Hayden, B. Y. (2021). Latent learning, cognitive maps, and curiosity. Current Opinion in
Behavioral Sciences, 38, 1–7.
Whittington,J.C.,Dorrell,W.,Behrens,T.E.,Ganguli,S.,&El-Gaby,M.(2025). Ataleoftwoalgorithms:
Structured slots explain prefrontal sequence memory and are unified with hippocampal cognitive maps.
Neuron, 113(2), 321–333.
Wilson, R. C., Takahashi, Y. K., Schoenbaum, G., & Niv, Y. (2014). Orbitofrontal cortex as a cognitive
map of task space. Neuron, 81(2), 267–279.
Xie, Y., Hu, P., Li, J., Chen, J., Song, W., Wang, X.-J., Yang, T., Dehaene, S., Tang, S., Min, B., et al.
(2022). Geometryofsequenceworkingmemoryinmacaqueprefrontalcortex. Science,375(6581),632–639.