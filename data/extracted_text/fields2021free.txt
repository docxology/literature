A free energy principle for generic quantum
systems
Chris Fieldsa∗, Karl Fristonb, James F. Glazebrook c,d and Michael Levine
a 23 Rue des Lavandi` eres, 11160 Caunes Minervois, FRANCE
b Wellcome Centre for Human Neuroimaging, University College London,
London, WC1N 3AR, UK
c Department of Mathematics and Computer Science,
Eastern Illinois University, Charleston, IL 61920 USA
d Adjunct Faculty, Department of Mathematics,
University of Illinois at Urbana-Champaign, Urbana, IL 61801 USA
e Allen Discovery Center at Tufts University, Medford, MA 02155 USA
January 3, 2022
Abstract
The Free Energy Principle (FEP) states that under suitable conditions of weak coupling,
random dynamical systems with suﬃcient degrees of freedom will behave so as to min-
imize an upper bound, formalized as a variational free energy, on surprisal (a.k.a., self-
information). This upper bound can be read as a Bayesian prediction error. Equivalently,
its negative is a lower bound on Bayesian model evidence (a.k.a., marginal likelihood). In
short, certain random dynamical systems evince a kind of self-evidencing. Here, we re-
formulate the FEP in the formal setting of spacetime-background free, scale-free quantum
information theory. We show how generic quantum systems can be regarded as observers,
which with the standard freedom of choice assumption become agents capable of assigning
semantics to observational outcomes. We show how such agents minimize Bayesian predic-
tion error in environments characterized by uncertainty, insuﬃcient learning, and quantum
contextuality. We show that in its quantum-theoretic formulation, the FEP is asymptot-
ically equivalent to the Principle of Unitarity. Based on these results, we suggest that
biological systems employ quantum coherence as a computational resource and – implicitly
– as a communication resource. We summarize a number of problems for future research,
∗Corresponding author at: 23 Rue des Lavandi` eres, 11160 Caunes Minervois, FRANCE;E-mail address:
ﬁeldsres@gmail.com
1
arXiv:2112.15242v1  [quant-ph]  30 Dec 2021
particularly involving the resources required for classical communication and for detecting
and responding to quantum context switches.
Contents
1 Introduction 3
2 Physical interaction as information exchange 5
2.1 What is “quantum”? . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 5
2.2 Unitarity . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 6
2.3 Separability and holographic encoding . . . . . . . . . . . . . . . . . . . . . 7
2.4 Reference frames . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 10
2.5 Symmetry breaking, decoherence, and agency . . . . . . . . . . . . . . . . . 12
2.6 Channel theory of QRFs . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 14
3 Repeated measurements and system identiﬁcation 20
3.1 Memory, time, and coarse-graining . . . . . . . . . . . . . . . . . . . . . . . 20
3.2 Learning and generative models . . . . . . . . . . . . . . . . . . . . . . . . . 24
3.3 Identifying and measuring systems embedded in E . . . . . . . . . . . . . . . 25
3.4 Noncommutativity and context-switching . . . . . . . . . . . . . . . . . . . . 28
4 FEP for generic quantum systems 30
4.1 Deﬁning VFE for quantum systems . . . . . . . . . . . . . . . . . . . . . . . 30
4.2 Sources of VFE for quantum systems . . . . . . . . . . . . . . . . . . . . . . 31
4.3 Asymptotic behavior of the FEP . . . . . . . . . . . . . . . . . . . . . . . . 34
5 Discussion 37
5.1 High-level overview . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 37
5.2 Summary of results . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 39
5.3 Applications to biological cognition . . . . . . . . . . . . . . . . . . . . . . . 40
5.4 Predictions and open questions . . . . . . . . . . . . . . . . . . . . . . . . . 42
2
1 Introduction
Since its introduction as a theory of brain function [1, 2, 3, 4], the variational Free Energy
Principle (FEP) has been extended into an explanatory framework for living systems at all
scales [5, 6, 7, 8, 9], and shown to characterize, in its most general form, all random dy-
namical systems that remain measurable, and hence identiﬁable as persistent and separable
entities, over macroscopic times [10]. To summarize, it is shown in [10] that any system that
has a non-equilibrium steady state (NESS) solution to its density dynamics i) possesses an
internal dynamics that is conditionally independent of the dynamics of its environment, and
ii) will continuously “self-evidence” by returning its state to (the vicinity of) its NESS. The
FEP is the statement that any measurable, i.e. bounded and macroscopically persistent,
system will behave so as to satisfy these requirements. Self-organization, the FEP tells
us, is not a rare, special case, but a ubiquitous feature of physical systems with suﬃcient
dynamical stability to be called “things.” All “things,” in particular, self-organize Markov
blankets (MBs; see [11] for an informal review) comprising “sensory” states that encode
incoming information and thus mediate the inﬂuence of external states on internal states,
and “active” states that encode outgoing information and thus mediate the inﬂuence of
internal states on external states. This partitioning of “things” into internal and MB states
means that every “thing” can be construed as a certain kind of “particle” – a particle that
is in open exchange with external states via its MB. In short, the MB of any such “particle”
underwrites conditional independence between its internal states and the external states of
its environment by localizing and thereby restricting information exchange; hence, the MB
can be viewed as separating internal from external states, while mediating their exchange.
As noted in [10], generalizing the FEP to characterize the behavior of all “things” substan-
tialy weakens the traditional distinction between “cognition” and merely “physical” dynam-
ics, and hence weakens the even deeper, pretheoretical [12] distinction between “agents” and
mere “objects” [13]. Treating physical interaction as information exchange – “observation”
of the environment followed by “action” upon it – redescribes the “mechanical” process
of returning to the NESS – as a random global (a.k.a., pullback) attractor – in terms of
inference. This can be read as “active inference” [4, 5, 6, 10] in which the existential in-
tegrity of the MB, and hence of the “self” – “world” distinction [14], can be maintained
in the face of environmental ﬂuctuations by changing internal states (via sensory states:
c.f., perception) or changing external states (via active states: c.f., action). It refocuses the
discussion, in other words, from abstract trajectories (or ﬂows) in state space to the MB
itself as a concrete locus of “identity” in the form of persistent measurability, and hence of
“self-evidencing” via active inference to maintain that identity.
The idea that all physical systems, including the environment at large, can be considered
“observers” that also act on their surroundings to “prepare” them for subsequent obser-
vations has become commonplace in quantum theory, largely replacing the “wave-function
collapse” postulate of traditional quantum mechanics [15] with interaction-induced deco-
herence (i.e., dissipation of quantum coherence) as the generator of classical information
3
[16, 17, 18, 19, 20]. 1 Indeed while quantum theory was originally developed – and is still
widely regarded – as a theory speciﬁcally applicable at the atomic scale and below, since
the pioneering work of Wheeler [24], Feynman [25], and Deutsch [26], it has, over the past
few decades, been reformulated as a scale-free information theory [27, 28, 29, 30, 31, 32] and
is increasingly viewed as a theory of the process of observation itself [33, 34, 35, 36, 37, 38].
This newer understanding of quantum theory ﬁts comfortably with the generalization of
the FEP, and hence of self-evidencing and active inference, to all “things” as outlined in
[10], and with the general view of observation under uncertainty as inference.
In what follows, we take the natural next step from [10], formulating the FEP as a generic
principle of quantum information theory. We show, in particular, that the FEP emerges
naturally in any setting in which an “agent” or “particle” deploys quantum reference frames
(QRFs), namely, physical systems that give observational outcomes an operational seman-
tics [39, 40], to identify and characterize the states of other systems in its environment.
This reformulation removes two central assumptions of the formulation in terms of random
dynamical systems employed in [10]: the assumption of a spacetime embedding (or “back-
ground” in quantum-theoretic language) and the assumption of “objective” or observer-
independent randomness. It further reveals a deep relationship between the ideas of local
ergodicity and system identiﬁability, and hence the idea of “thingness” highlighted in [10],
and the quantum-theoretic idea of separability, i.e., the absence of quantum entanglement,
between physical systems.
Any quantum system that can be distinguished from its environment over time can, there-
fore, be regarded as self-organizing and self-evidencing as described in [10]. We then show
that when the FEP is taken to an asymptotic limit, it drives systems away from separabil-
ity towards entanglement, and hence towards a supraclassical statistical coupling between
each “thing” and its environment – between the observer and the observed. In this, the
FEP reproduces the Principle of Unitary, i.e. the Principle of Conservation of Information,
which similarly drives all interacting systems asymptotically toward entanglement. Hence
the FEP is, in an important sense, an alternative statement of the Principle of Unitarity,
the most fundamental principle of quantum theory. It therefore applies to a much broader
array of systems than would fall under an intuitive idea of “thingness,” e.g. to quantum
ﬁelds, and applies in principle from the Planck scale to cosmological scales. Formulating
the FEP as a generic principle of quantum information theory thus substantially expands
the range of systems to which “cognitive” or information-processing concepts reasonably
apply.
We begin by reviewing in §2 the basic principles of quantum theory from an information-
1Variants of quantum theory that postulate a physical collapse mechanism also invoke interaction, e.g.
with gravity or a “noise” ﬁeld, to generate classicality; see [21] for review. We will not discuss here the
question of “interpretations” of quantum theory; see [22] for a thorough review and [23] for a more recent
taxonomy highlighting fundamental assumptions. Both decoherence and entanglement, in particular, have
diﬀerent physical meanings in diﬀerent interpretations, although their mathematical representations and
observable eﬀects are interpretation-independent. Our general approach can be viewed as replacing the
“measurement problem” – that such interpretations are designed to solve – with an explicit, quantum-
informational theory of measurement. This theory is, we show, just the theory of the FEP.
4
theoretic perspective, limiting the formalism to focus on the physical meaning of the theory.
Using the category-theoretic [41, 42] formalism of Channel Theory – developed by Barwise
and Seligman [43] to formalize the operational semantics of natural languages – we develop
a generic formal representation of QRFs and show how the noncommutativity of QRFs
induces quantum contextuality [44, 45], a nonclassical eﬀect demonstrating the presence of
entanglement between distinct physical degrees of freedom. We develop in §3 a generic,
formal description of how one quantum system identiﬁes another quantum system as a
persistent entity – a “thing” – and measures, records, and compares its states by deploying
speciﬁc sequences of QRFs. This identiﬁcation and measurement process depends critically
on breaking thermodynamic symmetries, and therefore on system-speciﬁc ﬂows of energy.
These sections together provide a representation of generic quantum systems as observers,
or in the language of Gell-Mann and Hartle [46] “information gathering and using systems”
(IGUSs), that is free of scale and spacetime embedding (i.e. “background”) dependent as-
sumptions. It also treats all probabilities as observer-relative. We then show in §4 how the
FEP emerges in this setting and analyze its asymptotic behavior; in particular, we consider
how the FEP addresses the fundamental problem posed by quantum context switches. We
conclude in §5 by discussing the relevance of these results to a scale-independent under-
standing of biological systems as “particles” that interact with other “particles,” whether
these are other organisms, “objects,” or an undiﬀerentiated environment. We consider in
particular the circumstances in which this “particle” nature can break down, and suggest
that well-designed experiments may be expected to detect quantum context switches or vio-
lations of the Bell [47] or Leggett-Garg [48] inequalities, any of which indicate entanglement,
by macroscopic biological systems under ordinary conditions.
2 Physical interaction as information exchange
2.1 What is “quantum”?
When physical interaction is viewed as information exchange, why it is “quantum” becomes
obvious: the fundamental quantum of information is one bit, one unit of entropy, that
one system exchanges with another. One bit, one quantum of information, is the answer
to one yes/no question. Planck’s quantum of action ℏ is then naturally regarded as the
action (energy ·time) required to obtain one bit via any physical interaction. The energy
required to irreversibly obtain one bit, i.e., to receive and irreversibly record one bit, is given
by Landauer’s Principle as ln 2 kBT, with kB Boltzmann’s constant and T temperature
[49, 50, 51]. The (minimum) time to irreversibly obtain one bit is then ℏ/ln 2 kBT, roughly
30 fs at 310 K. For comparison, the thermal dissipation time (in 3d space) due to time-
energy uncertainty is πℏ/2 ln 2 kBT [52], roughly 50 fs at 310 K. These values deﬁne a
minimal timescale for biologically-relevant, irreversible information processing, roughly the
timescale of molecular-bond vibrational modes [53] and an order of magnitude shorter than
photon-capture timescales [54].
5
Viewing all physical interaction as information exchange – and the bit as the fundamental
“quantum” of information – has the immediate consequence that interaction discretizes
the state spaces of all observable degrees of freedom. Given a set of mutually-commuting,
binary-valued observables, i.e., quantum operators implementing yes/no questions as de-
scribed below, a discrete state space for any observed system is constructed by assigning
a basis vector to each possible outcome (yes or no, +1 or -1) for each observable. These
are ﬁnite-dimensional Hilbert spaces. While Hilbert spaces with either ﬁnite or inﬁnite
dimension are introduced ad hoc in traditional quantum mechanics [15], ﬁnite-dimensional
Hilbert spaces emerge naturally from the process of observation in the information theory.
As Fuchs puts it, inﬁnite dimensional Hilbert spaces are, from an information perspective,
merely a “useful artiﬁce” permitting computation with diﬀerential equations [55]. Hence
in what follows, all Hilbert space dimensions will be ﬁnite dimensional.
2.2 Unitarity
The fundamental axiom of quantum theory is unitarity, again introduced ad hoc in tradi-
tional treatments. If U is an isolated system, its time propagator is a unitary operator:
PU = e−(ı/ℏ)HUt, (1)
where HU is the “internal” Hamiltonian (i.e. energy) operator satisfying the Schr¨ odinger
equation:
ıℏ(∂/∂t)|U(t)⟩= HU|U(t)⟩, (2)
where |U(t)⟩is the time-dependent state of U. When HU and hence PU are time-invariant,
solutions have the form:
|U(t)⟩= e−ıϕt|U(0)⟩, (3)
where |U(0)⟩is an initial ( t = 0) state. This Eq. (3) describes a phase rotation by ϕ
per unit time t in the Hilbert space HU; the initial state |U(0)⟩is preserved “up to” this
phase rotation. The dimension d= dim(HU) is the number of basis vectors ofHU and is, by
deﬁnition, the quantity (in bits) of observable information encoded by the state |U(0)⟩. The
number d is clearly invariant under the phase rotation given by Eq. (3); hence the phase
rotation is not an observable. Unitary evolution as deﬁned by Eq. (1) is, therefore, simply
evolution over time that conserves observable information. Hence, the fundamental axiom
of quantum theory is not ad hoc at all: it is the Principle that observable information, like
energy, is neither created nor destroyed by physical processes.
The appearance of the “imaginary” unit ı in Eq. (1) - (3) and the use of Hilbert spaces
over the complex ﬁeld C are standard in quantum theory but are often considered a mere
convenience; compelling arguments for their necessity have only been developed recently
[56, 57]. They can, however, be given a straightforward interpretation: they emphasize
6
that the phase rotation implemented by PU is not an observable dynamics and that the
“external” time t in these equations is not an observable, clock-referenced time. 2 Indeed,
no classical information – no observational outcome – has yet been obtained in the setting
deﬁned by Eq. (1) - (3). Characterizing observation as a process generating classical
outcomes as a result requires an additional assumption of separability as outlined below.
2.3 Separability and holographic encoding
Let U be an isolated system as above, and let U = AB be a bipartite decomposition of U,
i.e. the Hilbert space HU = HA⊗HB. At a ﬁxed time t, any such bipartite decomposition
can be characterized by an entanglement entropy:
S(|AB⟩) = −
∑
i
|αi|2 log2(|αi|2), (4)
where the coeﬃcients αi are the Schmidt coeﬃcients given by:
|AB⟩=
m∑
i
αi|ui⟩A|vi⟩B, (5)
where the label B is assigned so that m= dim(HB) ≤dim(HA) and the |ui⟩A and |vi⟩B are
orthonormal states of Aand Brespectively. The entanglement entropy S(|AB⟩) is a mutual
information measure that detects quantum correlation or “coherence” between A and B.
If S(|AB⟩) = 0, the joint state factors as |AB⟩= |A⟩|B⟩and hence is separable; otherwise
the joint state is entangled. Separable states are also called decoherent; entangled states are
coherent. Heuristically, a joint state |AB⟩is separable if the individual states |A⟩and |B⟩
can be determined by independent measurements. If |AB⟩is entangled, interactions with A
and B, including measurements, are no longer independent; this lack of independence can
be detected [47] and is the empirical basis for demonstrating entanglement [60] as discussed
in §5.4 below.
Extending Eq. (4) to all times and all bipartite decompositions of U gives a representation
of the time-dependent entanglement structure of U. As t →∞ the unitary dynamics of
Eq. (1) will drive U toward maximal entanglement, i.e. S(|AB⟩) →dim(HB) for every
bipartite decomposition U = AB; where, here again, Bis taken to be the smaller of the two
systems. At maximum entanglement, the joint-state evolution can be considered a simple
rotation as in Eq. (3).
Given a decomposition U = AB, the Hamiltonian can be decomposed as HU = HA +
HB+ HAB, where HAB represents the A-B interaction. Provided HAB is weak compared to
2Imagine, for an example, listening to a constant tone that has no beginning or end. Writing time as
ıt with t real allows Minkowski spacetime to be given a Galilean (++++) metric. See [58] for a discussion
of ı as a shorthand for converting classical to quantum observables, and [59] for a more intuitive view of
“rotation by ı” as a formal operation.
7
the internal interactions HA and HB and the time period of interest is short compared to
timescale in which PU drives the joint system to maximal entanglement, A and B can be
considered at least approximately separable, i.e. S(|AB⟩) ≈0 so |AB⟩≈| A⟩|B⟩. In this
case, |A⟩and |B⟩can be considered individually well-deﬁned, and bases can be chosen for
A and B so that:
HAB = βkkBTk
N∑
i
αk
iMk
i , (6)
where k = A or B, the Mk
i are N Hermitian operators with eigenvalues in {−1,1},
the αk
i ∈ [0,1] are such that ∑N
i αk
i = 1, and βk ≥ ln 2 is an inverse measure of k’s
thermodynamic eﬃciency that depends on the internal dynamics Hk [37, 38, 61, 62]. For
ﬁxed k, the operators Mk
i clearly must commute, i.e. [ Mk
i ,Mk
j ] = Mk
i Mk
j −Mk
j Mk
i = 0
for all i,j; hence HAB is swap-symmetric under the permutation group SN for each k. The
thermodynamic factor βkkBTk in Eq. (6) assures compliance with Landauer’s Principle,
i.e., assures that the per-bit free-energy cost of classical bit erasure is paid on each cycle
(see [37, 38] for discussion). As U = AB is by assumption isolated, conservation of energy
requires βATA = βBTB. As discussed in [13], Eq. (6) can be written in ordinary narrative
form as:
Physical Interaction = (Thermodynamics) ·(Yes/No questions).
This formulation emphasizes what quantum theory is about: the process of obtaining in-
formation. Obtaining information from B requires, in particular, that A acts on B by
asking questions. As Wheeler [63] puts it, “No question? No Answer!” All inference in this
framework is active inference; Eq. (6) does not allow “passive perception” to be a physical
process.
In contrast to classical theories of information transfer, in which physical tokens encoding
bits are transmitted between observers at diﬀerent locations, Eq. (6) involves no assump-
tions about spacetime, objects, or motions. It is strictly topological: given separability, it
identiﬁes a boundary B between A and B at which HAB is deﬁned. This boundary is the
“channel” via which Aand Bexchange strings of bits, ordered by the order of the operators
Mk
i in Eq. (6). Each of these bit strings encodes one eigenvalue of HAB; as HAB has units
of energy, these eigenvalues are measures of the energy βkkBTk exchanged between A and
B during each cycle of interaction. Any time variation of HAB is, therefore, time variation
of the energy exchanged and can be written:
HAB(t) = βk(t)kBTk
N∑
i
αk
i(t)Mk
i , (7)
where αk
i(t) and βk(t) are subject to the conditions on αk
i and βk given above. As noted for
Eq. (1) - (3) above, the time t in Eq. (7) is not an observable, clock-referenced time. We
8
will for simplicity considerHAB to be t-invariant; this is eﬀectively an adiabatic assumption.
An observer-speciﬁc, measurable time will be introduced in §3.1 below.
Boundaries such as B that function as information channels are, when embedded in space-
time and constrained by general covariance,3 holographic screens that limit communication
between the regions they separate to the bits that they encode [64, 65, 66, 67]. Interactions
between separable systems, i.e. interactions of the form given by Eq. (6) or (7) can, with-
out loss of generality, be regarded as deﬁned at such holographic screens [38, 62, 68]. The
operators Mk
i can, in this case, be regarded as “preparation” and “measurement” operators
that alternately write and read bit values encoded on B. The SN swap symmetry of the
Mk
i for each k means that the bits can be prepared, and then measured, in any order and
hence independently, provided preparation precedes measurement for each bit (such swaps
change the “zero point” of the energy scale and are undetectable). The screen B is, as
is any holographic screen, an ancillary construct, not “part of” either A or B. It can be
physically realized as an ancillary array of noninteracting qubits (quantum bits) with which
A and B interact as illustrated in Fig. 1.
3Eﬀectively, this is a requirement for consistency with both Special and General Relativity.
9
Figure 1: A holographic screen B separating systems A and B with an interaction HAB
given by Eq. (6) can be realized by an ancillary array of noninteracting qubits that are
alternately prepared by A(B) and then measured by B (A). Qubits are depicted as Bloch
spheres [27]. There is no requirement that A and B share preparation and measurement
bases, i.e. QRFs. Adapted from [38] Fig. 1, CC-BY license.
The holographic screen B has an obvious interpretation in the language of the FEP and
active inference: it implements the MB separating A from B [69]. “Active” and “sensory”
states of the MB correspond to preparation and measurement implemented by the Mk
i ; as
the interaction HAB is perfectly symmetrical, A’s actions are B’s sensations and vice-versa.
As bit strings on B encode energy eigenvalues, what either A or B “senses” is energy.
The assumption of separability plays, in this setting, the role played by the assumption
of measurability in [10]: it guarantees that systems A and B have well-deﬁned individual
states. These states are at informational equilibrium; A and B exchange bits one-for-one.
They are not, however, at thermal equilibrium, TA = TB unless their thermodynamic
eﬃciencies βA = βB. Hence, when sampled and averaged over macroscopic times, the pure
states |A⟩and |B⟩become (mixed) NESS densities ρA and ρB.
2.4 Reference frames
The isolation of U = ABassures that the A−Bchannel is free of classical, environmentally-
induced noise. The preparation and measurement operations MA
i and MB
i that A and B
10
use to communicate, however, are deﬁned with respect to and hence depend on the bases
|ui⟩and |vi⟩of the Hilbert spaces HA and HB respectively. In the qubit realization shown in
Fig. 1, the MA
i and MB
i are z-spin operators and so depend on the “choices” ofzaxis zA and
zB. Provided Aand B are separable, and assuming that there are no “superdeterminist” a
priori correlations, zA and zB are uncorrelated; this is the “free choice” assumption. Free
choice is often claimed to be essential to science as a practice [70, 71]; if it characterizes any
bounded system, consistency with quantum theory and special relativity together requires
that it must characterize all such systems [72]. Free choice of a basis introduces quantum
“noise” that is indistinguishable, observationally, from classical noise. Suppose B encodes
|↑⟩ on qubit q, using zB to deﬁne the “up” direction. If zA = zB, A’s measured state
|q⟩A = |↑⟩, i.e. A’s probability PA(|↑⟩) = 1. If, however, zA is chosen perpendicular to zB,
|q⟩A = (|↑⟩−|↓⟩ )/
√
2 and PA(|↑⟩) = PA(|↓⟩) = 0.5.
The z axis in Fig. 1 is a reference frame; free choice of the z axis generalizes to free choice
of the reference frame for encoding each qubit on B. While in classical physics, reference
frames are typically thought of as fully-speciﬁable abstractions, in quantum theory reference
frames must be considered physical systems – QRFs – that encode unmeasurable quantum
phase information. A QRF cannot, therefore, be fully speciﬁed by any ﬁnite bit string; it
is “nonfungible” in the terminology of [40]. In the setting of Fig. 1, the z axis deployed
by a A (B) determines how A (B) prepares and then measures the states of the qubits
composing B. We can, in particular, consider A to be isolated from B during the time
interval “between” preparation and measurement steps, an interval shorter than the natural
timescale of the interaction HAB. During such a short interval, we abuse the notation only
slightly by writing:
Pk : |B⟩meas ↦→|B⟩prep (8)
where k = A or B, i.e. by thinking of the internal propagators PA and PB, and hence
the dynamics HA and HB, as computing the next preparation of the qubits on B from
their most recent measured state. The idea of “computation” – or more properly, of the
physical system A (B) implementing a computation – is the standard notion, reviewed in
[73]: in brief, we can say a system A implements a computation of a function F if an
“interpretation” map IF exists such that the diagram:
⟨bits⟩i
F → → ⟨bits⟩i+1
|B⟩i
IF
↑ ↑ 
PA
→ → |B⟩i+1
IF
↑ ↑ 
(9)
commutes, i.e. F IF = IFPA for every “step” i →i+ 1, where here ⟨bits⟩is a ﬁnite bit
string and i→i+ 1 generalizes meas→ prep in Eq. (8). A QRF, e.g. a z axis as in Fig.
1, implemented by PA eﬀectively “chooses” the computational basis that renders the string
⟨bits⟩well-deﬁned. This is the same choice of basis that renders the MA
i well-deﬁned in
Eq. (6). Hence, we can identify the interpretation map IF with the QRF that renders the
11
function F well-deﬁned; to simplify the notation, we will use boldface F to label the QRF
itself. The choice of QRF F and hence of computational basis is functional or semantic, not
physical; both HA and HAB are invariant under changes of basis for HA. It is worth noting
explicitly that the choice of F is not encoded on B and is not observationally accessible to
B. Indeed, the general question of whether an arbitrary system A implements a QRF F is
Turing undecidable by Rice’s theorem [74]; see [38] for discussion.
As illustrated by the z axes in Fig. 1, the role of any QRF in a measurement setting is to
assure that measured values of some degree of freedom can be compared with each other
and hence given an operational meaning [75]. Meter sticks, clocks, gyroscopes, and the
Earth with its gravitational and magnetic ﬁelds serve this function, and are commonplace
laboratory QRFs. As described in detail in §3.3 below, recognizing an external object, such
as a meter stick, as a QRF and using it as such requires that the observer in question
already implements a QRF for the relevant degree of freedom: an observer with no “inter-
nal” ability to measure and compare lengths, for example, would ﬁnd a meter stick useless.
All QRFs can, therefore, be considered internal functional components of, or computations
implemented by, larger systems that allow measurements of, and assign operational seman-
tics to, one or more degrees of freedom external to the implementing system [61]. Shared
operational semantics across observers requires shared QRFs. The nonfungibility of QRFs
renders the question of QRF sharing in general Turing undecidable, again by Rice’s theorem
[38], a result consistent with the general undecidability of language sharing [76].
2.5 Symmetry breaking, decoherence, and agency
We will be interested in what follows in quantum systems, considered to be observers, that
deploy one or more distinct QRFs to measure particular subsets of the bits encoded on
their boundaries/MBs, and that record the values of these bits to a memory that persists
for at least one measurement cycle and hence allows comparisons of the values obtained in
at least two sequential measurements. Such systems eﬀectively decompose the holographic
screen B into three disjoint sectors that we will label E the observed environment , F
the unobserved environment, and Y the memory sector, respectively. Equivalently, they
eﬀectively decompose the set Mk
i of operators into three disjoint subsets (dropping the
redundant index k) ME
i , MF
j , and MY
l , respectively, with:
X =def dom({MX
i }) (10)
for each sector X. Assuming free choice of basis as above, this decomposition into sectors
can be regarded as freely chosen. Note that as B is the only locus of classical information in
the current formalism, any persistent classical memory must be a sector on B as discussed
in [13].
The assignment of operators to speciﬁc sectors breaks the SN swap symmetry of B [38].
As with choice of QRF, this is a functional or semantic symmetry breaking, not a physical
symmetry breaking; the assignment of bits on B to distinct sectors by HA has no eﬀect
12
on the deﬁnition of HAB given by Eq. (6). Holding HAB ﬁxed, we can vary the internal
interaction HA, and hence the implementation of QRFs as computations, so as to either
satisfy SN symmetry or break it. Note that varying HA in this way is equivalent to varying
HU −HB; such variation is undetectable at the boundary B. This insensitivity of B to
variation in the internal or joint dynamics of A and B is the core physical meaning of the
holographic principle [64, 65, 66, 67].
Breaking the SN swap symmetry on B renders the sector states |E⟩, |F⟩, and |Y⟩, each of
which corresponds to an encoded bit string, separable and hence mutually decoherent [38].
As emphasized in [77, 78, 79, 80, 81, 82] among others, decoherence is always observer-
relative, even when the “observer” is an ambient environment. Hence decoherence due to
swap-symmetry breaking is decoherence relative to A; the change-of-basis invariance ofHAB
renders A’s sector boundaries undetectable by B. Given free choice of QRFs, moreover,
B’s sector boundaries, if any, may be diﬀerent from A’s. Mismatched sector boundaries
between A and B generate apparent “hidden variables” and hence variational free energy
[4, 5, 6, 10] as discussed in §4.2 below. For the present purposes, what is important is that
deploying a QRF sensitive to only some degrees of freedom of B (i.e. sensitive to only some
bit values encoded on B) breaks the swap symmetry on B and creates a decoherent sector
as deﬁned by Eq. (10).
Breaking the swap symmetry on B allows diﬀerent sectors to have diﬀerent thermodynamic
eﬃciences, i.e. breaking swap symmetry allows breaking thermodynamic symmetry. This
can be made evident by rewriting Eq. (6) for A in terms of sectors X as:
HAB =
∑
X
βXkBTA
∑
i∈iX
αA
i MA
i , (11)
where iX is the set of indices of operators MA
i assigned to sector X. Note that this sym-
metry breaking does not change the total energy exchanged (i.e. the eigenvalue of HAB),
it only allocates the energy diﬀerently to diﬀerent sectors. This allows sectors to perform
diﬀerent thermodynamic roles; in particular, it allows the unobserved environment sector
F to serve as a source of free energy to – and a sink of waste heat from – the observed
environment sector E and the memory sector Y [37, 38]. The bits encoded on F are,
therefore, noninformative to Aand are traced (eﬀectively, marginalised and averaged) over
when deﬁning information-bearing states of A. Mathematically, this trace operation can
be viewed as implementing decoherence as discussed in [16, 17, 18, 19, 20], i.e., as imple-
menting the sector boundary of F. Assigning this thermodynamic function to F enables
thermodynamically-expensive classical information processing of bits encoded on E and Y,
including maintaining the stability of bit values written to Y as discussed in §3.1 below. It
therefore allows E and Y to have distinct semantics.
Free choice of a decomposition of B into sectors with diﬀerent QRF-induced semantics is
indicative of agency. Hence, we can deﬁne:
Deﬁnition 1. A (nontrivial) agent is a system Awith an internal dynamics HA that breaks
the SN swap symmetry of its boundary/MB B.
13
We can consider a system with a swap-symmetric boundary as shown in Fig. 1 a trivial
agent. Trivial agents correspond to “inert” systems with functionally-insigniﬁcant internal
states, and hence no internal information-processing capacity, as discussed in [10]. All
nontrivial agents are “cognitive” systems that engage in active inference.
Before proceeding to further characterize these sectors or to consider the imposition of ad-
ditional structure on E by further QRFs, we brieﬂy review below the speciﬁcation of QRFs
using the generic formalism of Channel Theory [43]. This formalism will enable characteri-
zation of the asymptotic behavior of the FEP and of context-switching as a mechanism for
minimizing FEP as discussed below in §4.3 below.
2.6 Channel theory of QRFs
Channel Theory [43] is an application of the category theory of Chu spaces, spaces of
semantic relations exempliﬁed by object – attribute tables [83, 84, 85]. Indeed Channel
Theory can be regarded as deﬁning a category Chan that is isomorphic to the category
Chu(Set,K) (for short, Chu) of Chu spaces. While conceptually simple, Channel Theory
is surprisingly rich, providing both a natural representation of conditional probabilities
and formal criteria for operator commutativity and quantum contextuality [86, 87] (for a
logico-philosophical perspective on the properties of semantic coherence in Chan, see e.g.
[88]). Furthermore, it provides an implementation-independent formal language for writing
functional speciﬁcations of QRFs as computations.
The central idea of Channel Theory is that of a “classiﬁer” that relates tokens in some
language to types in that language. We can deﬁne a classiﬁer as an object in Chan as
follows:
Deﬁnition 2. A classiﬁer Ais a triple ⟨Tok(A),Typ (A),|=A⟩where Tok(A) is a set of
“tokens”, Typ(A) is a set of “types”, and |=A is a “classiﬁcation” relating tokens to types.
The classiﬁcation |=A can, in general, be valued in any set K without assumed structure
(as is the case for Chu spaces); for simplicity, we will consider only binary classiﬁcations.
Morphisms in Chan, called “infomorphisms” between these objects are then given by the
following:
Deﬁnition 3. Given two classiﬁers A= ⟨Tok(A),Typ (A),|=A⟩and B= ⟨Tok(B),Typ (B),|=B
⟩, an infomorphism f : A→B is a pair of maps − →f : Tok(B) →Tok(A) and ← −f : Typ(A) →
Typ(B) such that ∀b∈Tok(B) and ∀a∈Typ(A), − →f(b) |=Aa if and only if b|=B
← −f(a).
This last deﬁnition can be represented schematically as the requirement that the following
diagram commutes:
Typ(A)
− →f → → Typ(B)
|=B
Tok(A)
|=A
Tok(B)
← −f← ← 
(12)
14
An infomorphism f : A→B is, eﬀectively, a map relating the semantic constraints imposed
by the classiﬁcation |=A to those imposed by |=B.
We are, in practice, interested in collections of infomorphisms than construct complex
semantic constraints out of simple ones; these will allow us to specify QRFs as hierarchies
of semantic constraints. Given a ﬁnite collection Ai of classiﬁers, we can represent this
construction process as a ﬁnite, commuting cocone diagram (CCD) depicting a ﬂow of
infomorphisms sending inputs to a core C′ that is the category-theoretic colimit of the
underlying classiﬁers, i.e., is the apex of the maximally general diagram of this form over
the Ai, if a unique such maximum exists:
C′
A1
f1
↗ ↗ 
g12
→ → A2
f2
↑ ↑ 
g23
→ → ... Ak
fk
← ← 
(13)
The cocone core C′ is itself a classiﬁer that encodes, via the incoming infomorphisms fi,
the conjunction of the semantic constraints imposed by the Ai.
There is a dual construction to this CCD, namely a commuting ﬁnite cone diagram (CD)
of infomorphisms on the same classiﬁers, where all arrows are reversed. In this case the
core of the (dual) channel is the category-theoretic limit of all possible downward-going
structure-preserving maps to the classiﬁers Ai. Hence, we can deﬁne the central idea of a
ﬁnite, commuting cone-cocone diagram (CCCD) as consisting of both a cone and a cocone
on a single ﬁnite set of classiﬁers Ai linked by infomorphisms as depicted below:
C′
A1
f1
→ → 
g12
g21 → → A2← ← 
f2
↑ ↑ 
g23
g32 → → ... Ak← ← 
fk
← ← 
D′
h1
← ← 
h2
↑ ↑ 
hk
→ → (14)
If the cores C′= D′, we can also represent the CCCD as:
A1 g12
g21 → → A2← ← 
g23
g32 → → ... Ak← ← 
C′
h1
← ← 
h2
↑ ↑ 
hk
→ → 
A1
f1
→ → 
g12
g21 → → A2← ← 
f2
↑ ↑ 
g23
g32 → → ... Ak← ← 
fk
← ← (15)
This diagram is naturally interpreted as reconstructing the semantics of the Ai via the
“combined” representation C′. Generalizing Diagram (15) by letting C′ be the limit of a
15
smaller set of classiﬁers A′
1,... A′
j, j <k, we can write:
A′
1 g′
12
g′
21 → → A′
2← ← 
g′
23
g′
32 → → ... A′
j← ← 
C′
h′
1
← ← 
h′
2
↑ ↑ 
h′
j
→ → 
A1
f1
→ → 
g12
g21 → → A2← ← 
f2
↑ ↑ 
g23
g32 → → ... Ak← ← 
fk
← ← (16)
Diagram (16) provides a natural representation of coarse-graining the semantics of Ai via
C′ into a compressed representation A′
i. We will employ this generalization in §3.1 below
to specify the writing of coarse-grained records of observational outcomes to the memory
sector Y.
Diagrams such as (13) – (16) can be generalized into hierarchical networks by adding
intermediate layers of classiﬁers and appropriate maps; when this is done, they clearly
resemble artiﬁcial neural networks (ANNs), and in the “bowtie” form of Diagrams (15)
and (16), variational autoencoders (VAEs) [86]. The core C′ in (15) and (16) can be
viewed as both an “answer” computed by the fi from inputs to the Ai and, dually, as an
“instruction” propagated by the hi (or in Diagram (16), the h′
i), to drive outputs from the
Ai (or in Diagram (16), the A′
i). Such dual input/output behavior is exactly the behavior
of a QRF. We can, therefore, represent any QRF as a CCCD “attached” to a subset of
measurement operators MA
k ,...M A
n by maps that identify the binary eigenvalues of the
MA
i with binary inputs to the Ai as illustrated in Fig. 2.
16
Figure 2: Attaching a CCCD to a subset of measurement operators MA
k ,...M A
n by iden-
tifying the binary eigenvalues of the MA
i with binary inputs to the Ai. Only the CCD
direction arrows are shown for simplicity; adding equivalent but reversed arrows completes
the CCCD. The CCCD speciﬁes a function computed by the internal dynamics PA, i.e. a
QRF deployed by A. Adapted from [38] Fig. 3; CC-BY license.
Thus far we have considered binary CCCDs, corresponding to Boolean ANNs or VAEs or to
QRFs imposing Boolean constraints. Mapping a CCCD to an arbitrary ANN or VAE that
computes some function of interest F just requires assigning probabilities, i.e. “weights”
to the infomorphisms in a way that respects the Kolmogorov axioms [86, 87]. We can then
treat the computed function F from network inputs to network outputs as an arbitrary
probabilistic QRF, or as suggested by Diagram (16), a pair of coupled QRFs that process
some “sensory” signal received by the Ai and write the result to a lower-dimensional and
17
hence coarse-grained “memory” via the A′
i. A QRF so deﬁned is naturally interpreted as
performing hierarchical Bayesian inference [86, 87]; see [89, 90] for applications to human
cognition.
To assign probabilities to infomorphisms, it is convenient to add the structure of a “local
logic” L(A) relating subsets of tokens and types to each classiﬁer A[43]. To do this, we
deﬁne an “implication” relation between subsets of types:
Deﬁnition 4. Two subsets M,N ⊆Typ(A) are related by a sequent M |=A N if ∀x ∈
Tok(A),x |=AM ⇒x|=AN.
Via the sequent relation, the local logic L(A) eﬀectively arranges the types of Ainto a
hierarchy; any classiﬁer can be extended to a local logic in this way by adding types as
needed. Considering all classiﬁers to be extended to local logics, Diagrams (13) – (16) can
be considered diagrams of local logics by requiring each of the infomorphisms to be a “logic
infomorphism” that preserves the sequent structure. In general, given an information ﬂow
channel:
−→Aα−1 −→Aα −→Aα+1 −→··· (17)
the semantic content can be extended by postulating local logics Lα = L(Aα) generated by
the corresponding classiﬁers Aα (assumed, in principle, to be in relationship to a (regular)
theory associated to the individual Aα, as speciﬁed in [43, Ch 9] (cf. [91]) and reviewed in
[87, Appendix A]), so to obtain a ﬂow of logic infomorphisms:
···−→L α−1 −→Lα −→Lα+1 −→··· (18)
which we can take to comprise comprise a CCD as in Eq. (13). Logic infomorphisms are,
eﬀectively, embeddings of type hierarchies; Diagrams (15) and (16) can be viewed as em-
beddings into a “top-level” type hierarchyC′that assigns an overall semantics to its inputs,
followed by encodings of this top-level hierarchy into some componential representation.
The local logic L(A) deﬁned above is Boolean. To extend the type hierarchy deﬁned
by L(A) to a hierarchical Bayesian inference, we extend L(A) to a probabilistic logic by
relaxing the sequent relation to require only that if x |=A M, there is some probability
P(N|M) that x|=AN. We can then write:
M |=P
AN =def P(M|N) (19)
and construct (extended, probabilistic) logic infomorphisms as above, requiring that they
preserve the conditional probabilities P(M|N) for all subsets M, N at each level of the
hierarchy.4 Traversing upwards in the hierarchy then imposes multiple conditioning on
each “low-level” probability distribution; traversing downwards sequentially unpacks this
conditioning. In fundamental Bayesian terms, M above can be regarded as a previous
event, whether observed or conjectured, and N as a currently observed datum, in which
4As pointed out in [93], it is instructive to see that Eq. (19) reveals how a conditional probability can
be used for interpreting the logical implication “ ⇒” as discussed in [96].
18
case P(M) becomes the prior, and P(N) the evidence, that together generate a prediction.
Given the likelihood P(N|M) as the conditional obtained from weakening the sequent via
Eq. (19), Bayes’ theorem speciﬁes this conditional as the posterior:
P(M|N) = P(N|M)P(M)
P(N) . (20)
A brief example illustrates these principles as follows: consider arbitrary classiﬁersA(a)
1 ,..., A(e)
5
in some part of an information channel where (as in [87]) the classiﬁers correspond to events
a,b,c,d,e , respectively, together with logic infomorphisms f13,...,f 45 between them, in
which the sequents are relaxed to conditional probabilities via Eq. (19):
A(a)
1
f13
↙ ↙ 
f14
↘ ↘ 
A(b)
2
f24
↙ ↙ 
A(c)
3 A(d)
4
f45
↓ ↓ 
A(e)
5
(21)
Following e.g. [92], this particular channel then generates a joint probability distribution
given by:
p(abcde) = p(a)p(b)p(c|a)p(d|ab)p(e|d). (22)
Putting these details within the framework of the above diagrams, a portion of a typical
CCD computing a hierarchical Bayesian inference from a set of (posterior) observations Ai
to an outcome C′ has the form:
C′
A1
p10(·|·)
↗ ↗ 
p12(·|·)
→ → A2
p20(·|·)
↑ ↑ 
p23(·|·)
→ → ... Ak
pk0(·|·)
← ← 
(23)
In this formal setting, the diagram commutativity of Diagrams (13) – (16), with probabilities
added as in Diagram (23) above, enforces Bayesian coherence: the probability associated
with any arrow U →Vmust equal the product of the probabilities associated with the
arrows on any other directed path from U to V.5 Any pair of subsets of the Ai have,
therefore, a well-deﬁned joint probability distribution. As shown in [87], the converse is
also true. Letting A1,A2 ... Band B,C1,... Ck be ﬁnite sets of classiﬁers, we can state the
following [87, Thm. 7.1]:
5Probability spaces and conditional distributions can also be deﬁned directly for Chu spaces as exhibited
in [87, Exs. 2.4, 2.5]. See [94] for an alternative representation of Bayesian inference and derivation of the
FEP using monodial categories and an operational formalism closely related to those employed in categorical
quantum theory [95].
19
Theorem 1. A well-deﬁned joint probability distribution exists over subsets A1,A2 ... B
and B,C1,... Ck of classiﬁers if and only if the following diagram commutes:
C
C1
φ
→ → 
C2
ψ
← ← 
A1
f1
↗ ↗ 
→ → A2
f2
↑ ↑ 
→ → ... B
fB
← ← 
gB
→ → 
→ → C1
g2
↑ ↑ 
→ → ... Ck
gk
← ← (24)
that is, if and only if there exist logic infomorphisms φ, ψ and a classiﬁer C such that the
above diagram is a CCD.
Proof. See [87]. The key observation is that φ and/or ψ can only fail to exist if the joint
probability distribution fails to exist.
The use of overlapping subsets of classiﬁers in Theorem 1 mirrors the use of mutually-
noncommuting subsets of mutually-commuting observables in the canonical deﬁnition of
quantum contextuality [44, 45] and its extension to a purely statistical criterion of incom-
patibility between measurement contexts [97, 98]. How the deployment of overlapping but
mutually-noncommuting subsets of QRFs implements context-switching between pairs of
complementary observables – such as position and momentum – is discussed in §3.4 be-
low. How the FEP can drive context-switching as a component of active inference is then
discussed in §4.3 below.
Viewing commutativity – and hence Bayesian coherence – as fundamental to the deﬁnition
of measurement, and hence also to the deﬁnition of preparation or action on the environment
generally, suggests that the Born rule, i.e. that if a state:
|X⟩=
∑
i
αi|xi⟩, (25)
the probability of obtaining |xi⟩as an observational outcome is:
P(|xi⟩= |αi|2, (26)
is a prescription for coherently assigning amplitudes αi to components |xi⟩, consistent with
the position advocated in [33, 35].
3 Repeated measurements and system identiﬁcation
3.1 Memory, time, and coarse-graining
The idea that a system must possess a (quasi-) NESS solution to its density dynamics – and
hence be restricted to trajectories in its classical conﬁguration space that do not diverge
20
exponentially over time – in order to be observable as a “thing”, immediately raises the
issues of time as measurable duration and of memory as persistent over measurable time.
As the simplest case, consider the NESS density ρE of the observed environment sector E
of some agent A. The agent A can only detect changes in ρE and employ them as bases
for inferences and actions if Acan write time-ordered records [ρE(tA)] to, and subsequently
read them from, the memory sector Y. Here tA is an A-speciﬁc time coordinate that must
be constructed. Persistence of the memory record [ ρE(tA)] between writing and reading
requires that it be “protected” from environmental noise, i.e. from ongoing events in E;
hence if |Y⟩is the state encoding [ρE(tA)], |Y⟩must vary only slowly under the action ofHB.
In the notation of Eq. (6), “protection” occurs if the coeﬃcients αB
i of operators MB
i acting
on qubits within Y all have small magnitudes. We can, therefore, distinguish two classes
of actions by A on its boundary/MB B. Actions on E are “questions” in Wheeler’s [63]
sense; they provoke informative responses from B that can be used to develop a generative
model of HB as discussed below. Actions on Y are recordings that must remain relatively
stable to be useful. Stability of the memory sector Y against HB is a critical resource for
any system A capable of responding to environmental state changes, and hence of any A
capable of active inference. Heuristically, this is clearly evinced in active vision, where we
actively palpate the world, every 250 ms or so, to update our working memory Y; i.e.,
update our (Bayesian) beliefs about the observed environment E.
The Second Law tells us that protecting any state against noise requires the expenditure
of free energy. Hence, any agent A is faced with a fundamental thermodynamic tradeoﬀ:
maintaining the stability ofY requires free energy sourced from the unobserved (traced over)
environmental sector F. For ﬁxed HAB, and hence ﬁxed B, expanding F to obtain more
free energy for Y requires shrinking E, i.e. “seeing” less of the environment. The alternative
is to coarse-grain Y either in time or in space, i.e. in bit-string length. Which horn of this
thermodynamic trilemma a given system takes is determined by the QRFs it implements.
Classical manifestation of this trade-oﬀ are seen in many guises. For example, the intimate
relationship between the eﬃciency of information transfer aﬀorded by compression – as
seen in minimum message length formulations of variational free energy [99, 100] – through
to the minimisation of statistical complexity aﬀorded by coarse-graining and quantisation
[101].
The simplest memory-write process is illustrated in cartoon form in Fig. 3. A state |E⟩, a
bit string of length dim( E), is constructed from one-bit operators ME
i by a QRF E. It is
then written to the memory Y by a QRF Y, with free energy sourced from the remainder
of B, i.e. from the unobserved sector F. In the simplest case, the memory capacity
dim(Y) = ndim(E) + log2 n where n is the number of distinguishable records. The log 2 n
labels that allow records to be distinguished can, without loss of generality, be considered
to be an integer sequence of clock ticks i→i+ 1, starting from i= 1. Hence, any memory
with more than one-record capacity deﬁnes a clock Gij, which we will see below must, in
general, be a groupoid operator [37]. 6 This clock is an internal time QRF that deﬁnes the
6Recall that a groupoid is a category in which the objects and arrows each comprise a set (as for a ‘small’
category), and every arrow is invertible [102, 103]. A groupoid generalizes the group concept in so far that
21
time coordinate tA.
Figure 3: Cartoon illustration of QRFs required to write a readable memory of an observed
environmental state |E⟩. The QRFs E and Y read the state from E and write it to Y
respectively. The clock Gij is a time QRF that deﬁnes the time coordinate tA.
The thermodynamic trade-oﬀ faced by A is between dim( E), dim( Y), and the sampling
time of states |E⟩, which determines the length of one clock tick and hence of one unit oftA.
As mentioned earlier, the minimum timescale for biological systems is set by the thermal
dissipation time to roughly 50 fs. Practical biological clocks run much more slowly; a clock
based on Gamma-band neural activity in mammalian cortex, for example, has a sampling
time of 10 – 20 ms. The recorded record, in this case, is a sample from or average over
a time ensemble < |E⟩ > of measured states, i.e., is a record [ ρE] of a coarse-grained
density. This record can be further compressed to achieve dim([ ρE]) < dim(E) and hence
dim(Y) <n ·dim(E) + log2 n.
With these QRFs, the memory read-compare-write cycle can be represented as in Fig. 4.
The classical record [ρE(i)] written in the previous cycle is read by Y at “external” (i.e. Eq.
(1) or (7)) time t. It is compared to the current measured state |E(t)⟩and a new record
[ρE(j)] is written by Y at t+∆t. This read-compare-write cycle advances the internal clock
Gij by one tick i→j. All QRFs together with the comparison function are implemented by
the former can admit “multiple identities” (the objects).
22
the internal dynamics PA. Formally, we can think of PA as a weighted sum of “all possible
paths” from the boundary state |B(t)⟩to the boundary state |B(t+ ∆t)⟩as in Eq. (8)
[104]; see [105] for discussion.
Figure 4: Cartoon illustration of one memory read-compare-write cycle deﬁning one tick
i→j of the internal clock Gij and requiring an interval ∆tof “external” time t. All QRFs
and the comparison function are implemented by the quantum dynamics PA (block arrow).
Fig. 4 explicitly illustrates an important distinction between classical and quantum repre-
sentations of dynamics and hence between classical and quantum formulations of the FEP.
Classical physics assumes a spacetime embedding; hence the MB of any topologically-
connected system can be associated with a spatial boundary that follows a smooth space-
time trajectory. “Internal” states of the system and the “internal” dynamics that operates
on those states to maintain a NESS are spatially localized inside this boundary, and are,
in particular, not exposed on the boundary. The current, quantum setting makes, in con-
trast, no assumptions about spacetime embedding as emphasized earlier. The boundary
B represents a Hilbert-space decomposition, not a “physical” spacetime decomposition.
As B is the only locus of classical information, “internal” classical states, including all
classical memory records, are exposed on B. The assumption that these exposed states
are “protected” from HB corresponds to the classical assumption of “self-evidencing”: that
maintaining the integrity of the MB as a spatial boundary enables the maintenance of the
NESS and vice-versa [10].
23
The true internal state of a quantum system Ais the state |A⟩that remains independently
well-deﬁned provided the joint state |AB⟩remains separable, i.e. provided the interaction
HAB can be written as Eq. (6). This internal state is “protected” from HB by deﬁni-
tion. Hence for quantum systems, “self-evidencing” is logically equivalent to separability.
Classical memories are at risk of environmental perturbation, unless suﬃcient free energy
is devoted to maintaining them. Quantum “memories” are encoded by the dynamics PA
and are at risk of environmental perturbation only if separability breaks down, i.e. if |AB⟩
becomes entangled.
With this non-spatial understanding of the “internal” states of a quantum system Awith a
classical memory, both the quantum|A(t)⟩→| A(t+∆t)⟩and the classical [ρE(i)] →[ρE(j)]
loops are internal to A. Hence, the (classical) integrated information Φ(A) >0 as deﬁned in
Integrated Information Theory (IIT) [106], rendering A “conscious” and hence an “agent”
in the framework of IIT. Hence the notion of agency in IIT is consistent with that of
Deﬁnition 1.
3.2 Learning and generative models
Learning a generative model allowing predictions of the future behavior of E is straightfor-
ward in this setting. The prediction problem can be represented as follows:
[ρE(1)],[ρE(2)],... [ρE(k−1)]  
Prior
,[ρE(k)]  
Posterior
→[ρE(k+ 1)],  
Prediction
(27)
where [ρE(1)],[ρE(2)],... [ρE(k−1)] are previous memory records, [ ρE(k)] is the current
record, and [ ρE(k + 1)] is the not-yet-obtained next record. The prior data can be re-
represented in three progressively more sophisticated ways:
1. As a probability distribution over the set of possible records, a discrete set of no more
than 2dim(E) elements.
2. As a probability distribution over the set of pairs ([ ρE(i)],[ρE(i+ 1)]) and hence as a
discrete Markov process.
3. As a map from probability distributions on records 1 ,2,...i to probability distribu-
tions on records 1 ,2,...i + 1 and hence as a discrete Markov kernel.
Representing the prior data by a discrete Markov kernel provides the greatest data com-
pression, at the cost of more sophisticated processing by PA.
The process of updating a Markov kernel MA
E(i) representing A’s prior data for E can be
formalized as:
L : (MA
E(i), [ρE(i)]) ↦→MA
E(i+ 1), (28)
24
where L is an operator of the form (function,data) → function′, i.e. a learning operator.
Hence any systemAthat stores prior information using a data structure more space-eﬃcient
than an explicit linked list can be considered to be learning.
As the records [ρE(i)] are just bit strings and Bayesian coherence is guaranteed by the com-
mutativity of the operators composing the QRF Y, the sequence [ρE(1)],[ρE(2)],... [ρE(k)]
can be represented by a “true” Markov kernelME(k) satisfying the following commutativity
constraint:
ρE(i)
ME → → ρE(i+ 1)
|B(t)⟩
E
↑ ↑ 
PU→ → |B(t+ ∆t)⟩
E
↑ ↑ 
(29)
where as before one “tick” oftA corresponds to ∆texternally and the notation |B⟩indicates
the state of the qubit array encoded on B. At step kin A’s acquisition of state information
about E, therefore, A’s prediction error ErE for E is:
ErE(k) = d(MA
E(k),ME(k)), (30)
where the d is the metric distance on Markov kernels. This deﬁnition is independent of L
and hence of the sources of A’s prediction errors.
3.3 Identifying and measuring systems embedded in E
We have so far considered only observers A that measure the states of their observed en-
vironments E without decomposing E into “systems” that have their own speciﬁc states.
Such undiﬀerentiated measurements of E plausibly characterize all biological systems that
interact with their environments primarily biochemically, instead of mechanically [107].
A bacterium measuring an ambient salt concentration, for example, does not assign the
concentration value to a speciﬁc object within the environment [13]. Animals as diverse
as arthropods, cephalopods, and vertebrates, however, detect and track the states of spe-
ciﬁc external “particles” or objects, often other animals. In terms of theoretical biology,
this ability is either ancient, arising at least by the Cambrian explosion, or results from
convergent evolution in multiple distinct lineages.
The question of how an observer A distinguishes a system S from the environment ˜E, in
which S is embedded, is central to classical cybernetics [108, 109] and, under the rubric of
object persistence, to cognitive and developmental psychology [110, 111]. Here, ˜E indicates
the remainder of E when S is removed, i.e. E = S˜E. While the question of how an
observer distinguishes an external system from its surrounding environment, prior to – and
as a precondition for – measuring some state of interest, is often neglected by physicists, it
imposes signiﬁcant thermodynamic and computational requirements on observers [112].
25
Distinguishing a system from its environment requires measurement, so it is naturally
formulated in the language of QRFs.
To set up some notation, we will consider any distinct, identiﬁed system S to comprise two
components, S = PR, where P is the “pointer” component that indicates some state |P⟩
(or density ρP of time-averaged samples of|P⟩) of interest and Ris a “reference” component
that by maintaining a constant state |R⟩(or constant density ρR of time-averaged samples
of |R⟩) allows S to be re-identiﬁed while |P⟩varies. Identifying a laboratory apparatus by
monitoring a time-invariant reference state provides an example; see Fig. 5.
Figure 5: Identifying a system S requires identifying some proper component Rthat main-
tains a constant state |R⟩(or density of time-averaged samples ρR) as the “pointer” state
|P⟩(or density of time-averaged samples ρP) of interest varies. Adapted from [37] Fig. 2,
CC-BY license.
Following the reasoning above, decomposing E into disjoint components E = PR ˜E is
deﬁning subsets of operators {ME
i }= {MP
j }⊔{ MR
k }⊔{ M˜E
l }where ⊔indicates disjoint
union. We can then deﬁne several QRFs:
26
P : P = dom({MP
j }) →|P⟩,
R : R= dom({MR
k }) →|R⟩,
˜E : ˜E = dom({M
˜E
l }) →| ˜E⟩,
(31)
with corresponding memory records [ ρP(i)], [ρR(i)], and [ρ˜E(i)]. As QRFs that prepare as
well as measure their assigned sectors of B, these QRFs P, R, and ˜E can be represented as
CCCDs with the symmetric form of Diagram (15). The processing pathway from a given
sector X to its associated memory record [ ρX] can, assuming a coarse-grained memory,
be represented as a CCCD with the asymmetric form of Diagram (16); the memory-read
to preparation of X pathway has the opposite asymmetry. Note that identiﬁability of S
requires [ρR(i)] = [ρR(j)] for all i,j. Forgetting what someone looks like, for example, can
lead to re-identiﬁcation failure.
Measurements of P, R, and ˜E are of no use unless they are recorded. As above, Markov
kernels provide the most eﬃcient data structure. The kernel MA
R must be constant to enable
system identiﬁcation. By analogy with Eq. (28), these kernels can be associated with a
learning operators LP, LR, and L˜E; where there is no requirement that these employ the
same learning algorithm. The “true” Markov kernel ME(i) can similarly be decomposed
into components, each of which must satisfy the commutativity constraint expressed by
Diagram (29):
ρP
MP (i)→ → ρP(i+ 1) ρR(i)
MR → → ρR(i+ 1) ρ˜E(i)
ME → → ρ˜E(i+ 1)
|B(t)⟩
P
↑ ↑ 
PU→ → |B(t+ ∆t)⟩
P
↑ ↑ 
|B(t)⟩
R
↑ ↑ 
PU→ → |B(t+ ∆t)⟩
R
↑ ↑ 
|B(t)⟩
˜E
↑ ↑ 
PU→ → |B(t+ ∆t)⟩
˜E
↑ ↑ 
(32)
Hence prediction errors for P, R, and ˜E can be deﬁned as in Eq. (30). Failing to correctly
predict ρR results in system-identiﬁcation failure and renders concurrent observations of ρP
meaningless.
The “systems” P, R, and ˜E are, clearly, just subsets of outcomes obtained by measuring
the qubits on A’s boundary/MB B; their states are, therefore, determined by the actions
of B’s encoding operators MB
i . As [ MB
i ,MB
j ] = 0 for all i,j by deﬁnition, R, P, and ˜E
must all be mutually separable and hence mutually decoherent; equivalently, R, P, and ˜E
must all mutually commute. Hence, A can regard R, P, and ˜E as “things” with distinct
identities and states as required by [10]. It bears emphasis, however, that no spacetime
background has been assumed in writing Eq. (6), in deﬁning B, or in deﬁning any of the
sectors R, P, or ˜E. The “things” R, P, and ˜E are not, therefore, observer-independent
in any sense, although observers deploying similar QRFs and able to communicate (i.e.
deploying QRFs that enable mutual recognition and communication) may agree as to their
27
states [35, 36]. The present formalism is, therefore, “system-free” in the sense of [34]
and hence represents measurements using external apparatus as fully device-independent.
While device independence is implied whenever an MB is invoked [11], classical formula-
tions of measurement interactions – indeed, of perception generally – tend nonetheless to
assume diﬀerentiated external objects a priori , as Einstein’s famous insistence that the
Moon is there when no one is looking exempliﬁes [113]; see [114, 115, 116] for examples
from perceptual psychophysics. Evolutionary considerations argue against any assumption
of a priori objects or even Galilean invariances of motion [117, 118], consistent with the
background-independent approach taken here.
3.4 Noncommutativity and context-switching
As emphasized by Bohr almost 100 years ago [119], a ﬁnite quantum of action ℏ partitions
the set of all possible quantum measurement operators into a set of “complementary” non-
commuting pairs, the most well-known being position ˆxand momentum ˆp. These operators,
as well as all other operators acting on “systems” with associated spacetime coordinates,
correspond in the current background-free framework to QRFs acting on sectors of B, i.e.,
on subsets of qubits as described above. Hence, noncommuting operators correspond to
noncommuting QRFs, as formalized by Theorem 1.
Two QRFs U and V can fail to commute only if the underlying measurement operators fail
to commute. However, as noted previously, any set of operators Mk
i appearing in Eq. (6)
must all mutually commute. Switching between noncommuting QRFs U and V, therefore,
entails switching between a mutually-commuting operator set MA
i , of which the MU
j are a
subset, and a complementary mutually-commuting operator set OA
i , of which the OV
j are a
subset, where for at least some i,j, [MU
i ,OV
j ] ̸= 0. This switch implements a basis rotation
on HAB, leaving its dimension N and its eigenvalues, the binary representations of which
are the bit strings encodable on B, both unchanged while replacing the amplitudes αA
i with
amplitudes λA
i so that Eq. (6) now reads, for A:
HAB = βAkBTA
N∑
i
λA
i OA
i . (33)
In practice, we will be primarily interested in partial basis rotations in which the MA
i and
the OA
i substantially overlap, e.g. maintaining ﬁxed sectors F, ˜E and R while switching
between complementary pointer sectors as discussed below. Note that such basis rotations
have no eﬀect on B or its operators, so are undetectable, in principle, by B.
An observer A capable of switching between noncommuting QRFs must, to maintain an
operable memory, implement a clock that is invariant under basis rotations on HAB. If
measurements made at clock ticks i and j do not commute, however, the corresponding
clock operations will not commute; in particular Gij ◦Gji ̸= Gji ◦Gij where ◦is operator
composition. It is for this reason that the Gij form a groupoid, and not a group [37]. From
a more practical perspective, noncommutativity forces tA to be unidirectional, and hence
28
memory records to be encoded irreversibly with an accompanying expenditure of free energy.
The internal clock Gij thus deﬁnes tA as an entropic time, consistent with the analysis in
[120]. Any observer A, therefore, observes a unidirectional ﬂow of information from B and
of dissipated heat to B; hence any observer A conﬁrms the Second Law with respect to
its internal time tA. As A and B are completely symmetric by Eq. (6), B also conﬁrms
the Second Law with respect to tB, showing that the Second Law is observer-relative and
independent of the “external” time t, consistent with the analysis in [121].
Switching between noncommuting QRFs while holding other QRFs constant, e.g., switch-
ing between interference (position) and which-path (momentum) measurements on an
interferometer identiﬁed by a ﬁxed reference sector R, is switching between mutually-
noncommuting but overlapping sets of mutually-commuting operators as described in The-
orem 1 and is a canonical quantum context switch [44, 45]. Pointer-state observables are,
in particular, observables in context as deﬁned in [87]: the state |P⟩of any pointer sector P
is measured in the context of the separable joint state |R⟩|˜E⟩|F⟩, where the component |F⟩
is unobserved by deﬁnition. By Theorem 1, two sets of pointer operators MU
j and OV
j as
above, that deﬁne alternative pointer sectorsU and V by Eq. (10), are mutually-commuting
and hence co-deployable if and only if maps φ and ψ exist such that the diagram:
C
C1
φ
→ → 
C2
ψ
← ← 
U
f1
↑ ↑ 
→ → R˜EF
g1
↖ ↖ 
g2
↗ ↗ 
→ → V
f2
↑ ↑ (34)
commutes. Here, we have replaced the explicit operators in Diagram (24) by their corre-
sponding sectors to simplify the notation. We can equally well interpret UF and VF as
contexts for the observation of sectors R and ˜E: in this case switching between U and
V—with the unobserved sector F held ﬁxed yields consistent probability distributions if
and only if Diagram (34) commutes.
If Diagram (34) fails to commute, then pointer-state observables are said to be non-co-
deployable. Non-commutativity of the CCD in (34) had been speciﬁed in [87, Th. 7.1] in
terms of non-existence of a consistently deﬁnable joint probability distribution of condi-
tionals, such as for Diagram (23). This non-co-deployability of observables thus amounts
to occurrence of intrinsic (quantum) contextuality in relationship to (34). 7
We will see in §4.2 below that context switching increases variational free energy (VFE)
by generating Bayesian“prediction errors”; hence context-switching makes minimizing VFE
7As recalled in e.g. [122, §3], ‘non-commutativity’ is at the very heart of contextuality, as ﬁrst formulated
by von Neumann in terms of non-commutativity of self-adjoint operators representing measurement, with
the impossibility of simultaneously measuring the eigenvalues corresponding to non-commuting operators.
In summarizing the principal results of ensuing hidden variables theory, Mermin [123] demonstrated the
impossibility of ﬁnding a joint probability distribution for all possible observables.
29
and hence complying with the FEP more diﬃcult. Deploying noncommuting QRFs against
a ﬁxed background can, however, lead to radically better generative models, as the history
of technological applications of quantum theory attests. Hence, context-switching poses
a fundamental challenge to any classical formulation of the FEP, and a fundamental ex-
planadum for a quantum formulation.
4 FEP for generic quantum systems
4.1 Deﬁning VFE for quantum systems
The FEP is a variational or least-action principle: it states that a system enclosed by an MB,
and therefore having internal states that are conditionally independent of its environment,
will evolve in a way that tends to minimize a VFE that is an upper bound on surprisal.
Formally, the VFE F(π), where π is a “particular” state π= (b,µ) comprising MB (b) and
internal (µ) components, can be written [10, Eq. 8.4],
F(π) ≜ I(π)
Surprisal
+ DKL[Qµ(η) ∥P(η|b)]  
Divergence
≥I(π). (35)
This functional as an upper bound on surprisal I(π) = −log P(π) because the Kullback-
Leibler divergence (DKL) term is always non-negative. This KL divergence is between the
density over external states η, given the MB state b, and a variational density Qµ(η) over
external states parameterised by the internal state µ. If we view the internal state µ as
encoding a posterior over the external state η, minimizing VFE is, eﬀectively, minimizing a
prediction error, under a generative model supplied by the NESS density. In this treatment,
the NESS density becomes a probabilistic speciﬁcation of the relationship between external
or environmental states and particular (i.e. “self”) states.
In the notation developed in §2 and 3 above, we can write the surprisal for a quantum
system A in its most general form as:
IA(t) = −P(|B(t)⟩|| A(t)⟩) (36)
and the corresponding evidence bound as:
DKL[Q|B(t)⟩(|B(t)⟩) ∥P(|B(t)⟩|| B(t)⟩]. (37)
In the current setting, however, these expressions have little direct utility, as our eﬀec-
tive starting point, Eq. (6), constrains neither |A(t)⟩nor |B(t)⟩. Indeed, from a strict
formal perspective, neither Eq. (36) nor Eq. (37) is well-deﬁned in the current setting.
The full boundary/MB state |B(t)⟩is, moreover, not an observable for A (or B), as the
thermodynamic-resource sector F remains unobservable by deﬁnition. We have, however,
30
already derived in §3.2 a representation of A’s prediction error, Eq. (30), which we repro-
duce here for reference:
ErE(k) = d(MA
E(k),ME(k)). (38)
In this expression, the timestep k counts A’s internal clock time tA and the kernels MA
E
and ME are derived from observables and therefore constrained by the theory. The kernel
ME(k) represents the observable behavior of B, as localized to the sector E, up to tA = k.
The kernel MA
E(k) is A’s generative model of the action of the unknown dynamics PB(t) on
B, also as localized to E. Hence ErE(k) represents A’s total reducible uncertainty about
B at tA = k. It is, therefore, an upper bound on surprisal analogous, in the current setting,
to F(π).
The operators ME
i referenced by Eq. (30), i.e. (38) must, clearly, all be co-deployable. In
practice, however, E is as discussed above subject to context switches of the form UR ˜E →
VR ˜E whenever Aswitches between noncommuting pointer QRFs U and V and hence non-
co-deployable operators MU
i and MV
i . Hence ErE is only well-deﬁned in the absence of
context switches; in the presence of context switches the generalized uncertainty relation:
∆u∆v≥ℏ/2 (39)
for pointer outcomes u and v can generate divergent uncertainties. Hence in practice, any
system A is faced with separately minimizing:
ErX(k) = d(MA
X(k),MX(k)). (40)
for each sector X deﬁned by a QRF X. We can, therefore, formulate the FEP for generic
quantum systems, taking context-switching into account, as:
FEP: A generic quantum system A will act so as to minimize ErX for each
deployable QRF X.
A trivial agent can be viewed as executing a trivial QRF, i.e. as only exercising choice of
basis for writing to and reading from B as a whole, and so satisﬁes the FEP trivially.
4.2 Sources of VFE for quantum systems
As noted in the Introduction, there is no source of objective randomness in the current
formalism. Indeed, an observer A can be regarded as certain of the states |˜E⟩, |R⟩, |P⟩,
and |Y⟩of the observable sectors ofB at every (external) timet. Uncertainty and prediction
error – and hence, VFE – is generated in the current formalism byA’s in-principle ignorance
of both the state |B⟩and the dynamics PB of its interaction partner B. As the bits Areads
from B are written by PB, A’s ability to predict the future states of its observable sectors,
31
and hence to minimize ErX for each sector X via Eq. (40), depends on its ability to predict
the behavior of PB locally on each observable sector. As the thermodynamic sector F is
not observed, direct predictions on F are not possible; the local behavior of PB on F can at
best be predicted from its local behavior elsewhere. An animal, for example, must employ
its available senses – hence its observable sectors – to predict the nutritional value of food.
The option space governing A’s ability to locally predict PB is summarized in Fig. 6. What
is important for A is not the dynamic complexity or even the dimension of PB, both of
which are unobservable in principle, but rather the dynamic complexity of the action of
PB on B (the dimension of this action is, clearly, just the dimension of B). Here, the
weak-interaction limit that allows separability between A and B is signiﬁcant: HAB (and
hence B) must have signiﬁcantly lower dimension that HB (and hence PB) if the weak
interaction limit to is hold. The simplest case is shown in Fig. 6, Panel a), in which the
system Bis a trivial agent deploying no QRFs other that the choice of basis for interactions
with B. The action of PB is, in this case, limited to choice of basis, e.g., to rotating the z
axis zB in Fig. 1. As discussed in §2.4, basis rotation by B generates quantum noise in the
communication channel deﬁned by HAB that is indistinguishable by Afrom classical noise.
Hence, the trivial agent B in Fig. 6, Panel a) “looks like” a noise source to A. Emission
of Hawking radiation from a black hole (BH) provides perhaps the most pure example of
such a noise source; while the dimension “inside” the BH can be arbitrarily large (see e.g.
[67, Fig. 19]), the internal dynamics are uncoupled from the classical information encoded
on the horizon and hence have no classical computational power. As will be discussed in
§4.3 below, a “small” trivial agent will be driven by the FEP toward entanglement with
the larger system A.
32
Figure 6: Four options for A’s ability to predict the local behavior of PB on an observable
sector XA. a) A trivial agent deploying no QRFs beyond choice of basis for interacting with
B appears as a noise source to A. b) B encodes a sector XB that contains XA; the bits on
XB but outside XA encode “nonlocal hidden variables” for A. c) The sectors XA and XB
overlap; the areas of non-overlap become noise sources. d) If XA = XB, VFE is generated
by insuﬃcient learning.
The more interesting parts of A’s option space for prediction are shown in Fig. 6, Panel
b), c), and d), in which B is nontrivial. If B is nontrivial, it deploys at least one QRF XB
acting on a sector XB. As discussed in §2.5, B’s sectors must be mutually decoherent, so
the action of PB on XB is independent of its action elsewhere; it is this independence that
makes prediction possible. If XB does not overlap any observable sector for A, however, B
will appear trivial, i.e. as a noise source, to A. Hence, the interesting cases are the ones in
which A’s and B’s observable sectors overlap; this is the case, intuitively, in which A and
B can “see each other” and hence interact in the ordinary, nontechnical sense of that term.
In Fig. 6, Panel b), B’s sector XB fully contains XA. As noted above in connection with Eq.
(31), all measure – prepare QRFs X are symmetric, i.e codom( X) = dom(X). Preparation
33
by B of the bits in XA will, therefore, in general depend on bits outside of XA but within
XB, i.e. on bits with the remainder XB\XA. The values of these bits are “nonlocal hidden
variables” [45] from A’s perspective; they aﬀect what is observed on sector XA without
being local to, i.e., contained within, XA. Indeed, such bits may be within F and hence
unobservable in principle by A. Changes in the values of these nonlocal hidden variables
are, eﬀectively, context changes as deﬁned in [97, 98]; probability distributions P(XA|ζ)
and P(XA|ξ) for distinct hidden-variable states ζ and ξ may be diﬀerent. The “context-
blind” distribution P(XA) can, in this case, fail to be well-deﬁned over time. Such failures
manifest as violations of Leggett-Garg inequalities [48], i.e. as “quantum hysteresis” eﬀects
due to nonlocal (i.e. outside of XA) and possibly unobservable causes. In the language of
artiﬁcial intelligence or robotics, they appear as failures to solve the Frame Problem [87],
the problem of predicting what will not change as the result of an action [124]. If XA is
a reference sector for A, Frame Problem solution failures on XA can result in failures of
object re-identiﬁcation [125].
A situation in which XA fully contains XB presents similar issues to that in Fig. 6, Panel b),
except here the “hidden variables” are in XA \XB and hence are accessible to A. The bits
in XA \XB nonetheless contribute VFE – eﬀectively, noise – to XA that is unconstrained
by XB. If XA and XB overlap with remainders, as in Fig. 6, Panel c), a similar noise
contribution to XA (or on B’s side, to XB) results. The ﬁnal possibility is, clearly, that
in which XA = XB as shown in Fig. 6, Panel d). Here, the source of VFE is not noise,
but rather diﬀerences in the computations implemented by the QRFs XA and XB. Such
diﬀerences correspond, in the notation of §2.6, to diﬀerences in the structures of the CCCDs
implementing XA and XB, e.g. diﬀerences in the “connection weights” if these are thought
of as ANNs or VAEs. They correspond, in other words, to learning failures, e.g. due to
insuﬃcient training-set representativeness, as Eq. (28) renders obvious. We can, therefore,
represent the overall situation for any observer A as:
VFE = Noise + Insuﬃcient Learning (41)
consistently with Eq. (35) above. Here “noise” includes VFE generated by unobserved
context changes (Leggett-Garg violations or Frame Problem solution failures) as well as
“classical” noise.
4.3 Asymptotic behavior of the FEP
Having seen how VFE is generated, we can now ask how it is minimized: how, in other
words, an agent acts in accordance with the FEP. As discussed in the Introduction, the FEP
in its classical form is eﬀectively the statement that any system with suﬃcient stability to
be a “thing” – i.e. a system with a [quasi-] NESS density – will act so as to preserve its
“thingness” by maintaining the integrity of its MB and hence the integrity of its “self” as
distinct from its surroundings. Comparing Eq. (35) and (41), it becomes clear what this
amounts to: a system “self evidences” by behaving in a way that minimizes noise while
improving learning. This, as is well known, induces a trade-oﬀ: learning requires seeking
34
uncertainty in order to minimize it. As emphasized in [126], successful learning requires
a focus on learnable tasks and avoidance of unlearnable tasks. Hence, minimizing VFE
is removing all removable noise. It does not, in practice, lead to perfect predictability of
future MB states, but to best feasible predictability of future MB states. In classical FEP
formulations, this becomes clearly evident in the form of a functional called expected free
energy (EFE); namely, VFE expected under a posterior predictive density that is condi-
tioned on action. In this setting, the most probable actions are those that minimise EFE
and thereby resolve uncertainty or maximise information gain (a.k.a., intrinsic motivation
or epistemic aﬀordance). In short, novelty-seeking is an emergent property of any“thing”,
under the FEP.
We can, however, ask in the current framework how the FEP behaves asymptotically, i.e.,
what are the consequences for A as, in the notation of Eq. (40), ErX(k) →0 as k →∞
for all observable sectors X. This clearly involves implementing a learning operator LX
for each sector X that is capable of asymptotically-perfect learning: let us assume this is
the case. What remains given Eq. (41) is noise, including noise due to observed context
switches. Only one mechanism for removing noise is available: that shown in Fig. 6, Panel
d). Hence we can conclude:
The FEP asymptotically drives alignment of QRFs across B.
It drives any observer A, in particular, to match any context switches by its interaction
partner B in order to maintain QRF alignment. Let us now consider, therefore, a situation
in which all QRFs deployed by Aand B are aligned as in Fig. 6 d), and in which all of A’s
QRFs have learned the local behavior of PB on their sectors perfectly. The local behavior
of PB on some shared sector X is determined by B’s QRF XB. This QRF XB is, however,
a quantum computation; as such, it encodes nonfungible – not ﬁnitely classically encodable
– information as shown in [40]. The future behavior of XB can, therefore, only be perfectly
predicted by XB itself, that is:
ErX →0 ⇒ XA = XB (42)
If Aand B are separable, the consequent in Eq. (42) violates the no-cloning theorem [127]:
it demands that the internal quantum state |B|X(t)⟩, the time (external t) evolution of
which implements XB, be replicated exactly in A. Hence, if Eq. (42) holds, A and B
cannot be separable. Therefore we have:
If AB is isolated, the FEP asymptotically drives the joint state |AB⟩to entan-
glement.
The claim that isolated systems are driven to entanglement is familiar from our initial
discussion of bipartite interactions in §2.3: all isolated systems are driven to entanglement
by unitary evolution. Separability is a special case, an approximation that holds only
under conditions of weak interactions and short observation times. Hence, we can, ﬁnally,
conclude:
35
The FEP is, asymptotically, the Principle of Unitarity.
The FEP is, in other words, asymptotically equivalent to the ﬁrst axiom of quantum theory.
Any quantum system, therefore, must behave in accord with the FEP; doing so is simply
approaching entanglement with its environment as required by the Principle of Unitarity.
The FEP is therefore, consistent with the results obtained in [10], a fundamental, generic
physical principle. Conversely, the Principle of Unitarity – the principle that observable
information is conserved – can now be seen as a fundamental principle of cognitive science.
As an example of the FEP in action, let us return to the situation in which a “small” trivial
system B interacts with a larger, nontrivial system A considered above. The only freedom
B has in this case is freedom of basis choice for reading and writing from B. From B’s
perspective, any basis choice that is misaligned with A’s basis choice generates noise. The
FEP will, therefore, drive B to align its choice of basis – z axis in Fig. 1 – with that of A.
This basis alignment, however, leaves B entangled with A. This is not surprising. When a
photon, for example, interacts with an atom, it is completely absorbed and loses its identity
as a “thing”; its state becomes irreversibly entangled with that of the atom with which it
interacts.
We can develop this result more formally as follows, noticing that a preparation operation
by BX followed by a measurement operation by AX can be described by a CCCD in the
form of Diagram (14), with the classiﬁers Ai identiﬁed with the bits comprising sector X
that are prepared and then measured. The question of asymptotic behavior is then the
question of whether this CCCD is symmetric, i.e. whether the cores C′ = D′ in Diagram
(14). We approach this by considering the Markov kernels MA
X and MX, the diﬀerence
between which deﬁnes the error ErX (via Eq. (40)) that the FEP asymptotically sends to
zero.
As shown in [128, p.17], following [129, §4], every category C whose arrows form a set
K embeds fully as a subcategory into Chu. There is, therefore, an induced mapping
F : C −→Chu realizing F(C) as an embedded subcategory of Chu that consists of some
objects of the latter, together with all of the arrows between them (for background on such
embeddings, see e.g. [41, 42]).
Now we recall the direct association between Markov kernels and conditional probabilities,
and apply the above embedding to the category P of conditional probabilities, following
mainly [130, 131] (cf. [132, 133]). Objects of P consist of countably generated measurable
spaces (X,ΣX), and arrows of P between two such objects, having the form:
M : (X,ΣX) −→(Y,ΣY). (43)
These arrows are Markov kernels assigning to eachx∈X, and each measurable set Q∈ΣY,
the probability of Qgiven x, denoted here by M(Q|x), whenever deﬁned. We can also write
this as pM(Q,|x), the (regular) conditional probability determined by the arrowM, ‘regular’
in so far that M is conditioned on points rather than on measurable sets in Σ X. As arrows
given by Eq. (43) specify a Markov process, they comprise a semigroup, and therefore a
36
set. Hence, we obtain a full embedding P −→Chu, where the (arrow) set K is identiﬁed
with a set of conditional probabilities K = {pM(S,|x)}⊆ [0,1].8 Using the fact that Chu
and the Channel Theory category Chan are isomorphic categories with respect to their
respective objects and arrows, we can summarize as follows:
Proposition 1. The category P embeds fully into Chan with classiﬁcation ⊩A realized by
the conditional probability pM(·|·) (the Chu space valuation/satisfaction relation) whenever
this is deﬁned.
Without loss of generality, we can assume the CCD in Diagram (23) to be a diagram in this
embedded subcategory (for a survey of probability spaces and Bayesian belief networks in
terms of the categories Chu and Chan, see [87, §2]).
We can now proceed to consider the asymptotic behavior of the FEP, in particular the
conditions under which |MX −MA
X|→ 0 for an arbitrary system A and sector X (with
QRF X), in the setting where A interacts with some B and the joint system AB is iso-
lated. To make sense of the formal diﬀerence MA −MB, that is, to make sense of the
diﬀerence between two arrows in P, we can use the metric distance on Markov kernels
as in Eq. (30). This distance is then manifestly the diﬀerence between the conditional
probabilities pMA(·|·) −pMB (·|·), in the way the corresponding Markov kernels determine
these as described above. As discussed previously, this is a diﬀerence in the (conditional)
probabilities of observable behavior in sectors. Thus, |MA −MB|→ 0 is interpreted as the
metric distance d(MA,MB) →0 in the asymptotic limit.
With the labeling by A,B, let us return to (23) which we adopt to provide two separate
CCDs as speciﬁed by (23) denoted by CCD A and CCDB. The asymptotic limit →0 of the
metric distance of the kernels determining the diﬀerence of the conditionals (hence →0 in
the asymptotic limit) provides the sense in which the diagrams CCD A and CCDB, along
with their respective colimits colim( C′
A) and colim(C′
B), can be identiﬁed in this limit (or
in the notation of Diagram (14), the cores C′ and D′ as required above become identical).
5 Discussion
5.1 High-level overview
While much of the foregoing has been technical, it is conceptually straightforward. To
brieﬂy review, the classical FEP as developed in [10] considers the joint environment-
agent system as a random dynamical system that possesses an attracting set. By placing
particular constraints on the coupling among systemic states (e.g., with sparse coupling
in ﬂow operators or stochastic diﬀerential equations), one can partition the joint state
space into external, internal and blanket (MB) states. In turn, the blanket states are
8In a similar way, Abramsky in [134] shows that the Dirac-von Neumann formulation of quantum
mechanics can be conveniently represented in the category Chu.
37
partitioned into sensory states that mediate the inﬂuence of external states on internal
states and active states that mediate the inﬂuence of internal states on external states.
Crucially, this particular partition imposes conditional independence between internal and
external states, given the blanket states. The ﬁnal move in the classical FEP is to induce a
variational density Qµ(η) over external states that is parameterised by internal states. It is
then fairly straightforward to show that the expected ﬂow of internal (and active) states can
be expressed as a gradient ﬂow on a variational free energy. This free energy is eﬀectively
the divergence between the variational density encoded by internal states and the density
over external states conditioned on the blanket states. This licences an interpretation of
internal and active states in terms of active inference, or a Bayesian mechanics, in which
their expected ﬂow can be read as perception and action, respectively. In other words, active
inference is a process of Bayesian belief updating that incorporates active exploration of
the environment.
Reformulating the FEP within quantum information theory allows us to drop the assump-
tion of an observer-independent spacetime background characterized by (continuous) frames
of reference that can be speciﬁed to inﬁnite precision, and also to drop the assumption of
randomness. In the quantum formulation, the blanket states are implemented by a holo-
graphic screen separating the interacting systems Aand B. The screen is the (topological)
locus of the interaction HAB; “sensory” and “active” states of the classical MB become
incoming and outgoing encodings of bits on the screen. The interaction is symmetrical
across the screen: the reciprocal exchange between “internal” Aand “external” B systems
takes the form of answers and questions (formulated as Hermitian operators Mk
i ), where
questions correspond to classical action (mediated by active states) and answers correspond
to classical perception (mediated by sensory states). There is, crucially, no assumption that
A and B share preparation and measurement bases; basis mismatches between A and B
generate quantum noise that is “perceived” as classical noise.
An “agent” in the quantum formalism is a system that deploys quantum reference frames
– eﬀectively, concepts that identify persistent objects and their time-varying states – when
interacting with its environment. Deploying distinct QRFs breaks the thermodynamic
symmetry of the screen for each agent, redirecting energy ﬂows within each agent to fund
processing and recording memory records of some bits while others – those in the “thermo-
dynamic” sector F – remain necessarily unobserved. Thus the quantum formalism explicitly
enforces a distinction that the classical formalism leaves implicit: that between observed
and unobserved parts of the environment. Mismatches between QRFs deployed by two
interacting agents generate noise and prediction errors, including incorrect Frame Problem
solutions and failures to correctly re-identify objects.
In the classical setting, agents “self-evidence” by maintaining their nonequilibrium steady-
states or, equivalently, the integrity of their MBs. From a mathematical point of view, this
is maintaining their identities (in the sense of being independently well-deﬁned) as systems.
In the quantum setting, being independently well-deﬁned is being separable from – not
entangled with – the environment; hence “self-evidencing” is maintaining separability. The
FEP identiﬁes self-evidencing with the minimization of Bayesian prediction error: to“be”
38
is to be capable of successful predictions; sometimes described as “predicting yourself into
existence”. Minimizing prediction error is, in the quantum setting, minimizing the diﬀerence
between two Markov kernels. As in the classical setting, noise and errors due to insuﬃcient
learning must both be minimized, a process that requires trade-oﬀs between the two.
The classical and quantum formulations of the FEP diﬀer in their asymptotic behavior,
i.e., as total prediction error is driven toward zero. A classical “perfect predictor” achieves
maximal classical correlation and hence maximal behavioral synchrony with its environ-
ment; it becomes a “perfect regulator” in the sense of the good regulator theorem [135].
In a quantum setting, perfect prediction entails shared QRFs between interaction partners
and hence entanglement; a quantum “perfect regulator” becomes indistinguishable from
the environment it is predicting. While this diﬀerence in asymptotic behaviors is a formal,
mathematical outcome, it can be traced to a diﬀerence in fundamental assumptions. The
classical formalism assumes a spacetime background, and hence can rely on separation in
space to distinguish between systems. The quantum formalism is background free: space
is simply an observable, represented by a QRF that a system may or may not deploy. It
can, therefore, play no “ontic” role in maintaining distinctions between systems. This re-
ﬂects the general role of (“physical” 3d) space in quantum ﬁeld theories: space is there to
enforce separability (see [68] for a general discussion of this point from a gauge-theoretic
perspective).
Both classical and quantum formulations of the FEP engender a fundamental form of
epistemic solipsism, in the sense that the coupling between internal and external systems
precludes the states of one from ever “knowing” the states of the other. While this seems
counter-intuitive, it is a straightforward consequence of the use of vector spaces to rep-
resent physical states. Vector-space product operators – the classical Cartesian product
or the Hilbert-space tensor product – are by deﬁnition associative (equivalently, dynamic
operators such as Hamiltonians are additive); product decompositions are, therefore, un-
detectable across decompositional boundaries in any vector space [136]. This sense of epis-
temic solipsism does not, as Fuchs emphasizes [55], in any way suggest ontic or metaphysical
solipsism. Both classical and quantum formulations of the FEP – indeed, any theory of
measurement or observation – requires two interacting systems, observer and observed. The
idea of a metaphysically solipsist theory of observation is self-contradictory.
5.2 Summary of results
We have obtained three results in this paper:
1. Given the standard free-choice assumption, the intuitive idea of an “agent” or IGUS
can be fully formulated within background-independent, scale-free quantum informa-
tion theory.
2. The FEP can be given a quantum-theoretic formulation that renders it applicable to
generic quantum systems.
39
3. When formulated as a generic principle of quantum information theory, the FEP is
asymptotically equivalent to the Principle of Unitarity.
Result 1) places the long-standing practice of treating generic quantum systems as “ob-
servers” on a ﬁrm theoretical foundation. It allows a formal speciﬁcation, in the language
of QRFs, of exactly what systems a given observer is capable of recognizing and what states
of those systems it is capable of measuring. Such speciﬁcations require no “ontic” assump-
tions of observer-independent systems; hence they are compliant with a device-independent
theoretical strategy. Result 1) also provides a formal deﬁnition of an “agent” in the con-
text of the free-choice assumption, and provides a generic language – the category-theoretic
language of Channel Theory – for specifying the semantics assigned by an agent to an
observational outcome. Finally, Result 1) shows how semantics arise from thermodynamic
symmetry breaking on a holographic screen, and provides a formal mechanism for quanti-
fying energy ﬂows that enable classical computation and classical memory encoding.
Result 2) extends the range of applicability of the FEP to generic quantum systems inde-
pendently of spacetime background or scale-dependent assumptions. Quantum ﬁelds, black
holes, and other spatially-distributed or topologically-deﬁned systems can, therefore, be
regarded as Bayesian observers and, if free choice is assumed, as Bayesian agents. Result
2) therefore makes clear the sense in which generic quantum systems can be regarded as
“users” of quantum information theory, as proposed under the rubric of QBism [33, 35, 55].
Indeed Result 2) renders QBism a consequence of quantum information theory, not an
interpretation.
Result 3) shows that the FEP is compliant with the Principle of Unitarity and, conversely,
that unitary evolution is compliant with the FEP. It allows us, in particular, to understand
quantum context-switching as both a source of prediction errors and a strategy for reducing
prediction errors. Result 3) also allows us to view separability as a resource for classical
communication and computation that is analogous to entanglement as a resource for quan-
tum communication and computation. Hence, it allows us to consider trade-oﬀs between
these resources by systems that maintain approximate separability while also employing
shared entanglement. Such systems have been studied in the abstract, and can potentially
exceed the computational power of Turing machines (e.g. can solve the Halting problem as
shown in [137]). Result 3) suggests that (some) biological systems may have this capability,
as discussed further in §5.4 below.
5.3 Applications to biological cognition
In addition to the results listed above, the current framework has a variety of more speciﬁ-
cally biological consequences, some of which have been discussed already in [13]. It predicts,
for example, that moving in ordinary 3d space does not require a QRF for Euclidean space
and hence, does not require an experience of space. From a classical perspective, this is
certainly true; as evidenced e.g. by place and grid cells in mammalian brains [138, 139, 140]
that appear to encode a coarse-grained representation of location, head-direction etc., in
40
various frames of reference. This coarse graining endorses another prediction; namely, that
actionable classical encodings are coarse-grained. Any system that encodes information
irreversibly is, therefore, faced with a choice that its computational architecture must re-
solve: the trade-oﬀ between preserving information in memory and losing information due
to coarse graining. On a classical FEP account, this coarse graining is mandated by the
minimization of VFE, which can be expressed as complexity minus accuracy. Classically,
complexity corresponds to the KL divergence between posterior and prior beliefs as in Eq.
(35). This relative entropy clearly depends upon the degree of discretisation or coarse
graining aﬀorded by the dimensionality of internal states. Eﬀectively, this KL divergence
scores the computational and thermodynamic cost of belief updating that is mitigated by
coarse graining or, in quantum terms, devoting memory resources to the results computed
by only some QRFs, possibly in a context-sensitive fashion [141].
The ubiquity of context-dependent eﬀects leads to another prediction: living systems in
complex environments will evolve context and attention switching systems. On a classical
view, this entails the identiﬁcation of context (cf. the role of pointers) in a hierarchical
generative model, where high level states contextualise the processing of lower level states.
This immediately introduces the notion of MBs or holographic screens in the joint space of
an agent’s internal states, i.e. a notion of modularity supported by shared memory. This
is gracefully accommodated by the channel theory of QRFs as developed in §2.6.9 Indeed,
much work in the classical ﬁeld of active inference rests upon optimising the hierarchical
structure of deep generative models, via various free energy minimizing processes [143,
144, 145, 146]. This is especially true for generative models of navigation and language
[147, 148, 149] that are almost universally based upon quantisation or discretisation of state
spaces. The attendant Boolean logic that arises from the imposition of Boolean constraints
by QRFs may have important practical applications, as demonstrated by recent work in
active vision and scene construction [150] that rests upon a generative model of the sensory
(visual) consequences of visually foraging a scene with multiple objects. Active inference
in this context can be seen as an inversion of a generative model that maps from causes
(external objects), to consequences (sensory states) (cf. [116]).
The inversion of generative models for active vision is extremely diﬃcult and ill-posed due to
its computational complexity. These models have to accommodate all the natural physical
laws of motion and optics (e.g., occlusion). The inversion of these models corresponds to
the measurement operators that mediate belief updating. In a classical setting, this can
be massively ﬁnessed by coarse graining the problem and applying Boolean operators. For
example, if one object is near and another object is far, an agent will see the near object.
Quantising or coarse graining the internal (i.e. generative) model along these lines reduces
the likelihood mapping to a set of relatively simple Boolean operators that could be cast as
measurement operators in a quantum-theoretic context. At present, when these operators
are encoded on standard classical computers for simulation, they are eﬀectively implemented
with enormous tensors. Reading and writing these tensors into working memory dwarfs
9See [90] for an explicit application to global-workspace theory and [142] for a more ambitious synthesis
of active inference, a global workspace, and IIT.
41
the actual compute time and renders active vision schemes of this sort computationally
and thermodynamically ineﬃcient. One might imagine that a combination of quantum
computing [25, 27] and neuromorphic engineering [151, 152] may be able to parallel the
eﬃciency of human vision.
There are, in addition, certain technical problems that are resolved in moving from a
classical to a quantum FEP formulation of active inference that go beyond a commitment
to unitary processes and binary measurement operators. These include problems entailed
by assuming reference frames that can be speciﬁed to inﬁnite precision. In formalising
the asymptotic behaviour of belief updating in the absence of random ﬂuctuations in the
classical formalism, for example, one has to deal with diﬀerential entropies that are ill-
deﬁned for very precise conditional densities, e.g. Dirac Delta functions. One workaround
is to use Jaynes’ limiting density of discrete points (LDDP) [153], which brings us back to
where we started, namely ﬁnite dimensional Hilbert spaces and discrete state spaces.
Finally, from a more philosophical perspective, the framework presented here is consistent
with [13, 14, 154] in supporting a panpsychist perspective on questions of agency, sentience,
and cognition. As our Deﬁnition 1 of agency illustrates, traditional binary categorizations
of entities into those having agency, sentience, and cognition and those lacking them are
replaced here by continua of “interestingness” along these dimensions. Deﬁnition 1 assumes
free choice, in particular of measurement basis. The Conway-Kochen theorem [72] states
that if any physical system is assumed to have free choice, then all physical systems must
be assumed to have free choice. “Free choice” in this case means behavior that is not
determined by (cannot be fully predicted given) the events in the system’s past lightcone.
Determination of behavior by events in the past lightcone is local determinism; such local
determinism is fundamentally inconsistent with the global determinism implied by unitarity
[155]. Hence what is interesting is the extent of choice. As emphasized in [10], interesting
choices are implemented by internal processes. An electron, for example, has internal
states – its charge and mass are not states of its MB – but they are invariant, and so
do not implement choices. The internal states of rocks are not invariants – changes in
water content or radioactive decay can occur – but they do not, in general, implement
interesting choices from our human perspective. Interesting choices require interesting
sensations and actions, and hence signiﬁcant internal energy ﬂows as discussed above. They
require diﬀerential use of thermodynamic resources to deploy multiple QRFs that probe the
observable environment in diﬀerent ways. Systems, including organisms, clearly do this to
diﬀerent extents; even among humans, the extent of variation is striking. Consonant with
a broadly-construed enactivism [156, 157, 158, 159], we view such active exploration of the
environment – hence, active inference – as indicating cognition and intelligence.
5.4 Predictions and open questions
The results obtained here suggest that the ﬁeld of quantum biology is far larger than has so
far been explored; indeed they suggest that all biological systems are properly considered
quantum systems and can be expected to employ quantum coherence as an information
42
processing resource. This suggestion is of course not novel, having been explored by many
authors from philosophical, theoretical, and increasingly over the past two decades, empiri-
cal perspectives [160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174]. We
have, however, shown here that it follows from general principles: quantum systems with
suﬃciently complex internal information ﬂows can be expected to exhibit active inference,
and hence to behave like organisms. Indeed, quantum systems that do not display evident
intelligence – quantum systems that are trivial agents – become an unusual special case.
Conversely, the results obtained here suggest that the concepts of active inference, agency,
Bayesian satisﬁcing, and cognition are applicable to generic quantum systems, and hence
to physical systems across the board. This turns the traditional question of the emergence
of intentionality [175, 176, 177] on its head: by making agency a generic expectation, it
makes the “merely physical” the special case demanding explanation. It thus suggests that
the traditional division between agency and mechanism is a hindrance, not a help, in the
task of understanding the natural world.
We make, in particular, the following predictions:
1. The internal, molecular-scale dynamics of both prokaryotic and eukaryotic cells im-
plement quantum information processing, i.e., make essential use of quantum coher-
ence as a computational and memory resource. This is consistent with recent results
showing that the free energy budgets of biological systems across known phylogeny are
orders of magnitude short of the resources required for purely classical computation
at the molecular scale [178].
2. Interacting biological systems trade oﬀ separability against entanglement and hence
classical against quantum communication. Interactions between biological systems
from the molecular scale upwards can be expected to display quantum contextuality
and violations of the Bell and Leggett-Garg inequalities.
These predictions remain largely untested, both for reasons of technical diﬃculty and due
to a still-pervasive traditional view of macroscopic systems as ontically classical. The mech-
anistic role of entanglement – even in relatively well-established systems such as light har-
vesting – remains subject to considerable debate [172, 173, 174]. Quantum context switch-
ing has been detected in human subjects [179, 180], but whether it is properly considered
“quantum” or merely “quantum-like” remains open to question [181]. 10 Neither Bell nor
Leggett-Garg inequality violations have been conclusively demonstrated with biological sys-
tems.
Setting technical diﬃculties aside, we suggest that coherence eﬀects in biological settings
may be systematically overlooked due to being dismissed as “noise” or “random coinci-
dence.” Thermal noise in biological settings is well characterized; general environmental
variation, including eﬀects of signaling by other cells or organisms, is less straightforwardly
10Such “quantum-like” contextuality is claimed for a certain case of gene expression in [182] where
conﬂicting probabilities (quantum vs. classical) do not give rise to a consistently deﬁnable joint distribution,
so suggesting a variant of Kolmogorov contextuality.
43
modeled or controlled. Experimental designs that explicitly test for coherence eﬀects will,
we expect, be required to test the above predictions. Focused theoretical support for such
designs is therefore necessary.
Interactions involving multiple agents remain an open theoretical as well as experimental-
design problem. In the bipartite setting employed for the technical analysis above, every
agent interacts with its entire surrounding, whether the bits transferred by this interaction
are observed and processed or not (i.e. whether they are included in sector E or F). This
does not change in a multi-party setting; each agent still interacts with its entire surround,
identifying other agents (or not) via speciﬁc QRFs. The ubiquitous assumption that inter-
agent communication is classical, made in domains as disparate as cell-cell interaction and
human natural language use, becomes problematic in this setting. As discussed in §4.3,
shared QRFs are required for fully-shared, counterfactual-supporting semantics, but they
induce entanglement (see also the discussion of this point in [38]). The extent of shared
semantics is not readily observable in living systems. In a fully classical setting, generalised
synchronisation (a.k.a., synchronisation of chaos) emerges when two free energy minimising
‘partners’ observe each other [183]. “Perfect prediction” of the partner’s behavior may
result, driven by classical learning of a shared generative model, implicitly resolving the
hermeneutics problem in the communication context [184, 185]. Recognizing a particular
communication partner, in this case, requires invoking a particular generative model, the
correct model to predict that partner’s behavior [186]. Such classical synchronization is not,
however, robust against perturbation; altering one agent’s model does not “automatically”
alter the other, as would be expected if the models, i.e. the QRFs implemented by the two
agents were entangled. Both theoretical and experimental characterization of relevant QRFs
will be required to assess the extent to which classical communication can be considered
purely classical, and detemine where and how quantum coherence contributes to in-practice
successful shared semantics.
Darwinian evolution can be viewed as a process of variation and selection of QRFs, and
hence as an instance of the multiple-agents problem in which semantics is only partially
shared. Evolution can be given a natural description in the framework of the classical FEP
[5, 187, 188, 189]. Variation and selection have been advanced as a model of decoherence
under the rubric of quantum Darwinism [18, 190]; see [191] for a discussion from the per-
spective of universal Darwinism. The selection mechanism invoked by quantum Darwinism,
however, assumes QRF sharing by multiple agents [192]; see [38, 62] for discussion. While
the present results allow any evolutionary system coupled to a larger environment to be
viewed as a Bayesian agent implementing active inference, a fully-satisfactory account of
variation and selection within a quantum framework remains to be developed.
Additional theoretical work is also needed to understand the relationships among the many
distinct models of quantum contextuality that have been put forward, often with the use
of quite diﬀerent formal tools (e.g. [193, 194, 195, 196]). The question of “context” is
deeply tied up with that of what is to be regarded as the “environment” or “surrounding”
of any given system. This is a particularly critical question at the cellular level, where
multiple signaling modalities with diﬀerent spatial ranges and temporal characteristics are
44
present. Models that explicitly characterize the “spaces” in which cells and multicellular
systems operate – e.g. the space of potential morphologies, or that of potential messages
from interaction partners – and that consider constraining eﬀects of one space on another
both within and between scales will be needed to understand the roles of context, and of
context switching, in biological systems.
In closing, we hope that we have shown to readers familiar with the FEP and the active
inference framework that quantum eﬀects are worth considering both theoretically and in
experimental design. For readers not familiar with the classical FEP but literate in quantum
theory (or vice versa), we hope this paper has gone some way to contextualizing your QRFs
in sense-making via Markov blankets and their underlying holographic screens.
Conﬂict of Interest Statement
The authors declare that the research was conducted in the absence of any commercial or
ﬁnancial relationships that could be construed as a potential conﬂict of interest.
Funding
The work of C.F. is supported in part by the Emerald Gate Foundation. K.J.F. is sup-
ported by funding for the Wellcome Centre for Human Neuroimaging (Ref: 205103/Z/16/Z)
and the Canada-UK Artiﬁcial Intelligence Initiative (Ref: ES/T01279X/1). M.L. gratefully
acknowledges support by the Guy Foundation Family Trust (103733-00001), the John Tem-
pleton Foundation (62212), and the Elisabeth Giauque Trust.
References
[1] Friston KJ. A theory of cortical responses. Philos Trans R Soc Lond B, Biol Sci
2005;360:815–36.
[2] Friston KJ, Kilner J, Harrison L. A free energy principle for the brain. J Physiol Paris
2006;100:70–87.
[3] Friston KJ, Stephan KE. Free-energy and the brain. Synthese 2007;159:417–58.
[4] Friston KJ. The free-energy principle: a uniﬁed brain theory? Nat Rev Neurosci
2010;11:127–38.
[5] Friston KJ. Life as we know it. J R Soc Interface 2013;10:20130475.
[6] Friston KJ, FitzGerald T, Rigoli F, Schwartenbeck P, Pezzulo G. Active inference: a
process theory. Neural Comput 2017;29:1–49.
45
[7] Ramstead MJ, Badcock PB, Friston KJ. Answering Schr¨ odinger’s question: a free-
energy formulation. Phys Life Rev 2018;24:1–16.
[8] Ramstead MJ, Constant A, Badcock PB, Friston KJ. Variational ecology and the physics
of sentient systems. Phys Life Rev 2019;31:188–205.
[9] Kuchling F, Friston K, Georgiev G, Levin M. Morphogenesis as Bayesian inference:
A variational approach to pattern formation and control in complex biological systems.
Phys Life Rev 2020;33:88–108
[10] Friston K. A free-energy principle for a particular physics. Preprint arXiv:1906.10184
(2019).
[11] Clark A. How to knit your own Markov blanket: Resisting the Second Law with meta-
morphic minds. In: Metzinger T, Wiese W (eds), Philosophy and Predictive Processing:
3. Frankfurt am Main: MIND Group, 2017.
[12] Scholl BJ, Tremoulet PD. Perceptual causality and animacy. Trends Cogn Sci
2000;4:299–309.
[13] Fields C, Glazebrook JF, Levin M. Minimal physicalism as a scale-free substrate for
cognition and consciousness. Neurosci Cons 2021;7:niab013.
[14] Levin M. Life, death, and self: fundamental questions of primitive cognition viewed
through the lens of body plasticity and synthetic organisms. Biochem Biophys Res Comm
2020;564:114–133.
[15] Von Neumann J. The Mathematical Foundations of Quantum Mechanics. Princeton,
NJ: Princeton University Press, 1955.
[16] Omn` es R. Consistent interpretations of quantum mechanics. Rev Mod Phys
1992;64:339–382.
[17] Zurek WH. Decoherence, einselection and the existential interpretation (the rough
guide). Phil Trans R Soc A 1998;356:1793–1821.
[18] Zurek WH. Decoherence, einselection, and the quantum origins of the classical. Rev
Mod Phys 2003;75;715–775.
[19] Schlosshauer M. Decoherence, the measurement problem, and interpretations of quan-
tum mechanics. Rev Mod Phys 2003;76:1267–1305.
[20] Schlosshauer M. Decohenece and the Quantum to Classical Transition. Springer,
Berlin, 2007.
[21] Bassi A, Lochan K, Satin S, Singh TJ, Ulbricht H. Models of wave-function collapse,
underlying theories, and experimental tests. Rev Mod Phys 2013;85:471–527.
46
[22] Landsman NP. Between classical and quantum. In: Butterﬁeld J, Earman J. (eds.),
HandBook of the Philosophy of Science: Philosophy of Physics. Elsevier, Amsterdam,
Netherlands, 2007, pp. 417–553.
[23] Cabello A. Interpretations of quantum theory: A map of madness. Preprint
arXiv:1509.04711v1, 2015.
[24] Wheeler JA. Law without law. In: Wheeler JA, Zurek W (eds), Quantum Theory and
Measurement. Princeton, NJ: Princeton University Press, 1983, pp. 182–213.
[25] Feynman RP. Simulating physics with computers. Int J Theor Phys 1982;21:467–488.
[26] Deutsch D. Quantum theory, the Church-Turing principle and the universal quantum
computer. Proc R Soc A 1985;400: 97–117.
[27] Nielsen MA, Chuang IL. Quantum Computation and Quantum Information. New York:
Cambridge University Press, 2000.
[28] Hardy L. Quantum theory from ﬁve reasonable axioms. Preprint arxiv:quant-
ph/0101012v4 (2001).
[29] Fuchs CA. Quantum mechanics as quantum information, mostly. J Mod Opt
2003;50:987–1023.
[30] Brassard G. Is information the key? Nat Phys 2005;1:2–4.
[31] Chiribella G, D’Ariano GM, Perinotti P. Informational derivation of quantum theory.
Phys Rev A 2011;84:012311.
[32] Masanes L, M¨ uller MP. A derivation of quantum theory from physical requirements.
New J Phys 2011:13;063001.
[33] Fuchs C, Schack R. Quantum Bayesian coherence. Rev Mod Phys 2013;85:1693–1715.
[34] Grinbaum A. How device-independent approaches change the meaning of physical the-
ory. Stud Hist Phil Mod Phys 2017;58:22–30.
[35] Mermin ND. Making better sense of quantum mechanics. Rep Prog Phys
2018;82:012002.
[36] M¨ uller MP. Law without law: from observer states to physics via algorithmic informa-
tion theory. Quantum 2020;4:301.
[37] Fields C, Glazebrook JF. Representing measurement as a thermodynamic symmetry
breaking. Symmetry 2020;12:810.
[38] Fields C, Glazebrook JF, Marcian` o A. Reference frame induced symmetry breaking on
holographic screens. Symmetry 2021;13:408.
47
[39] Aharonov Y, Kaufherr T. Quantum frames of reference. Phys Rev D 1984;30:368–385.
[40] Bartlett SD, Rudolph T, Spekkens RW. Reference frames, super-selection rules, and
quantum information. Rev Mod Phys 2007;79:555–609.
[41] Ad´ amek J, Herrlich H, Strecker GE. Abstract and Concrete Categories: The Joy of
Cats. New York: Wiley, 2004. Available at http://katmat.math.uni-bremen.de/acc (Ac-
cessed May 26, 2019)
[42] Awodey S. Category Theory. (Oxford Logic Guides, 62). Oxford, UK: Oxford Univer-
sity Press, 2010.
[43] Barwise J, Seligman J, Information Flow: The Logic of Distributed Systems (Cam-
bridge Tracts in Theoretical Computer Science, 44). Cambridge, UK: Cambridge Univer-
sity Press, 1997.
[44] Kochen S, Specker EP. The problem of hidden variables in quantum mechanics. J Math
Mech 1967;17:59–87.
[45] Mermin D. Hidden variables and the two theorems of John Bell. Rev Mod Phys
1993;65:803–815.
[46] Gell-Mann M, Hartle JB. Quantum mechanics in the light of quantum cosmology. In
Zurek W (ed) Complexity, Entropy, and the Physics of Information. Boca Raton, FL:
CRC Press, 1989; pp. 425–458.
[47] Bell JS. On the Einstein-Podolsky-Rosen paradox. Physics 1964;1:195–200
[48] Emary C, Lambert N, Nori F. Leggett-Garg inequalities. Rep Prog Phys
2013;77:016001.
[49] Landauer R. Irreversibility and heat generation in the computing process. IBM J Res
Devel 1961;5:183–195.
[50] Landauer R. Information is a physical entity. Physica A 1999;263:63–67.
[51] Bennett CH. The thermodynamics of computation. Int J Theor Phys 1982;21:905–940.
[52] Lloyd S. Ultimate physical limits to computation. Nature 2000;406:1047–1054.
[53] Zweir MC, Chong LT. Reaching biological timescales with all-atom molecular dynamics
simulations. Curr Opin Pharmacol 2010;10:745–752.
[54] Wang Q, Schoenlein RW, Peteanu LA, Mathies RA, Shank CV. Vibrationally coherent
photochemistry in the femtosecond primary event of vision. Science 1994;266:422–424.
[55] Fuchs C. QBism, the Perimeter of quantum Bayesianism. Preprint arXiv:1003.5209,
2010.
48
[56] Moretti V, Oppio M. Quantum theory in real Hilbert space: How the complex Hilbert
space structure emerges from Poincar´ e symmetry. Rev Math Phys 2017;29:17500021.
[57] Renou M-O, Trillo D, Weilenmann M, Thinh LP, Tavakoli A, Gisin N, Ac´ ın A,
Navascu´ es M. Quantum physics needs complex numbers. Preprint arXiv:2101.10873,
2021.
[58] Baez JC. Getting to the bottom of Noether’s theorem. Preprint arXiv:2006.14741,
2020.
[59] Kauﬀman LH. Eigenforms and quantum physics. Cybernet Human Knowing
2011;18:111–121.
[60] Aspect A, Grangier P, Roger G. Experimental realization of the Einstein-Posolsky-
Rosen gedankenexperiment: A new violation of Bell’s inequalities. Phys Rev Lett
1982;49:91–94.
[61] Fields C, Marcian` o A. Sharing nonfungible information requires shared nonfungible
information. Quant Rep 2019;1: 252–259.
[62] Fields C, Marcian` o A. Holographic screens are classical information channels. Quant
Rep 2019;2;326–336.
[63] Wheeler JA. Information, physics, quantum: The search for links. In Zurek W (ed)
Complexity, Entropy, and the Physics of Information. Boca Raton, FL: CRC Press, 1989;
pp. 3–28.
[64] ’t Hooft G. Dimensional reduction in quantum gravity. In Ali A, Ellis J, Randjbar-
Daemi S. (eds) Salamfestschrift. Singapore: World Scientiﬁc, 1993, pp. 284–296.
[65] Susskind L. The world as a hologram. J Math Phys 1995;36:6377–6396.
[66] Bousso R. The holographic principle. Rev Mod Phys 2002;74:825–874.
[67] Almheiri A, Hartman T, Maldacena J, Shaghoulian E, Tajdini A. The entropy of
Hawking radiation. Rev Mod Phys 2021;93:035002.
[68] Addazi A, Chen P, Fabrocini F, Fields C, Greco E, Lulli M, Marcian` o A, Pasechnik
R. Generalized holographic principle, gauge invariance and the emergence of gravity ` a la
Wilczek. Front Astron Space Sci 2021;8:563450.
[69] Fields C, Marcian` o A. Markov blankets are general physical interaction surfaces. Phys
Life Rev 2020;33:109–111.
[70] Bohr N. Atomic Physics and Human Knowledge. New York: Wiley, 1958.
[71] Gisin N. Non-realism: Deep thought or a soft option? Found Phys 2012;42:80–85.
[72] Conway JH, Kochen S. The strong free will theorem. Notices AMS 2009;56(2):226–232.
49
[73] Horsman C, Stepney S, Wagner RC, Kendon V. When does a physical system compute?
Proc R Soc A 2014;470:20140182.
[74] Rice HG. Classes of recursively enumerable sets and their decision problems. Trans
Am Math Soc 1953;74:358–366.
[75] Fields C, Levin M. How do living systems create meaning? Philosophies 2020;5:36.
[76] Quive WVO. Word and Object. Cambridge, MA: MIT Press, 1960.
[77] Zanardi, P. Virtual quantum subsystems. Phys Rev Lett 2001;87:077901.
[78] Zanardi P, Lidar DA, Lloyd S. Quantum tensor product structures are observable-
induced. Phys Rev Lett 2004;92:060402.
[79] Dugi´ c M, Jekni´ c J. What is “system”: Some decoherence-theory arguments. Int J
Theor Phys 2006;45:2249–2259.
[80] Dugi´ c M, Jekni´ c-Dugi´ c J. What is “system”: The information-theoretic arguments.
Int J Theor Phys 2008;47:805–813.
[81] De la Torre AC, Goyeneche D, Leitao L. Entanglement for all quantum states. Eur J
Phys 2010;31:325–332.
[82] Harshman NL, Ranade KS. Observables can be tailored to change the entanglement
of any pure state. Phys Rev A 2011;84:012303.
[83] Barr M. *-Autonomous Categories, with an Appendix by Po Hsiang Chu (Lecture
Notes in Mathematics 752). Springer: Berlin, Germany, 1979.
[84] Pratt V. Chu spaces. In School on Category Theory and Applications (Coimbra 1999);
Volume 21 of Textos Math. S´ er. B. University of Coimbra: Coimbra, Portugal, 1999, pp.
39–100.
[85] Pratt V. Chu spaces from the representational viewpoint. Ann Pure Appl Logic
1999;96:319–333.
[86] Fields C, Glazebrook JF. A mosaic of Chu spaces and Channel Theory I: Category-
theoretic concepts and tools. J Expt Theor Artif Intell 2019;31:177–213.
[87] Fields C, Glazebrook JF. Information ﬂow in context-dependent hierarchical Bayesian
inference. J Expt Theor Artif Intell 2021; in press (doi: 10.1080/0952813X.2020.1836034).
[88] Collier J. Information, causation and computation. In G. D. Crnkovic and M. Burgin
(eds.) Information and Computation: Essays on Scientiﬁc and Philosophical Foundations
of Information and Computation (World Scientiﬁc Series in Information Studies Vol 2).
World Scientiﬁc Press. Hackensack, NJ, 2011, pp. 89-105.
50
[89] Fields C, Glazebrook JF. A mosaic of Chu spaces and Channel Theory II: Appli-
cations to object identiﬁcation and mereological complexity. J Expt Theor Artif Intell
2019;31:237–265.
[90] Fields C, Glazebrook JF. Do Process-1 simulations generate the epistemic feelings that
drive Process-2 decision making? Cogn Proc 2020;21:533–553.
[91] Barwise J. Information and impossibilities. Notre Dame J Formal Logic
1997;38(4):488–515.
[92] Cherniak E. Bayesian networks without tears. AI Mag 1991;12(4):50–63.
[93] Allwein, G. A qualititative framework for Shannon Information theories. In NSPW
’04: Proceedings of 2004 Workshop on New Security Paradigms (Nova Scotia, Canada,
September 20-23, 2004). New York: ACM, 2004, pp. 23–31.
[94] St. Clere Smithe T. Compositional active inference I: Bayesian lenses, statistical games.
Preprint arXiv:2109.04461 [math.ST], 2021.
[95] Coecke B. Quantum picturalism. Contemp Phys 2010;51:59–83.
[96] Adams EW. A Primer of Probabilistic Logic. Chicago: University of Chicago Press,
1998.
[97] Dzhafarov EN, Cervantes VH, Kujala JV. Contextuality in canonical systems of ran-
dom variables. Phil Trans R Soc A 2017;375:20160389.
[98] Dzharfarov EN, Kon M. On universality of classical probability with contextually la-
beled random variables. J Math Psych 2018;85:17–24.
[99] MacKay DJC, Peto LCB. A hierarchical Dirichlet language model. Nat Lang Engin
1995;1,289–308.
[100] Wallace CS, Dowe, DL. Minimum message length and Kolmogorov complexity. Com-
puter J 1999;42:270–283.
[101] Smith R, Schwartenbeck P, Parr T, Friston KJ. An active inference approach to mod-
eling structure learning: Concept learning as an example case. Front Comput Neurosci
2020;14:41.
[102] Weinstein A. Groupoids: Unifying internal and external symmetry. Notices Am Math
Soc 1996;43:744–752.
[103] Brown R. Topology and Groupoids. www.groupoids.org.uk, Deganwy, UK, 2006.
[104] Deutsch D. The structure of the multiverse. Proc R Soc A 2002;458:2911–2923.
51
[105] Marcian` o, A.; Chen, D.; Fabrocini, F.; Fields, C.; Greco, E.; Gresnigt, N.; Jinklub,
K.; Lulli, M., Terzidis, K.; Zappala, E. Deep neural networks as the semi-classical limit
of quantum neural networks. Preprint arXiv:2007.00142v2 [cond-mat.diss-nn].
[106] Oizumi M, Albantakis L, Tononi G. From the phenomenology to the mechanisms of
consciousness: Integrated Information Theory 3.0. PLoS Comp Biol 2014;10:e1003588.
[107] Robbins RJ, Krishtalka L, Wooley JC. Advances in biodiversity: Metagenomics and
the unveiling of biological dark matter. Stand Genom Sci 2016:11:69.
[108] Ashby WR. Introduction to Cybernetics. Chapman and Hall, London, UK, 1956.
[109] Moore EF. Gedankenexperiments on sequential machines. In Shannon CW, McCarthy
J (eds) Autonoma Studies. Princeton University Press, Princeton, NJ, USA, 1956, pp.
129–155.
[110] Scholl BJ. Object persistence in philosophy and psychology. Mind Lang 2007;22:563–
591.
[111] Fields C. The very same thing: Extending the object token concept to incorporate
causal constraints on individual identity. Adv Cognit Psychol 2012;8:234–247.
[112] Fields C. Some consequences of the thermodynamic cost of system identiﬁcation.
Entropy 2018;20:797.
[113] Pais A. Einstein and the quantum theory. Rev Mod Phys 1979;51:863–914.
[114] Marr D. Vision. Freeman, San Francisco, CA, 1982.
[115] Palmer S. Vision Science: Photons to Phenomenology. MIT Press, Cambridge, MA,
1999.
[116] Pizlo Z. Perception viewed as an inverse problem. Vis Res 2001;41:3145–3161.
[117] Prakash C, Fields C, Hoﬀman DD, Prentner R, Singh M. Fact, ﬁction, and ﬁtness.
Entropy 2020;22:514.
[118] Prakash C, Stephens KD, Hoﬀman DD, Prentner R, Singh M, Fields C. Fitness beats
truth in the evolution of perception. Acta Biotheor 2021;69: 319–341.
[119] Bohr N. The quantum postulate and the recent development of atomic theory. Nature
1928;121:580–590.
[120] Di Biagio A, Don` a P, Rovelli C. The arrow of time in operational formulations of
quantum theory. Quantum 2021;5;520.
[121] Tegmark M. How unitary cosmology generalizes thermodynamics and solves the in-
ﬂationary entropy problem. Phys Rev D 2012;85:123517.
52
[122] Sulis W. Contextuality in neurobehavioural and collective intelligence systems. Quan-
tum Reports 2021;3: 592–614.
[123] Mermin D. Simpliﬁed uniﬁed form for the major no-hidden variables theorem. Phys
Rev Lett 1990; 65: 3373–3376.
[124] McCarthy J, Hayes PJ. Some philosophical problems from the standpoint of artiﬁcial
intelligence. In Michie D, Meltzer, B. (eds.) Machine intelligence, Vol. 4). Edinburgh
University Press, Edinburgh, 1969, pp. 463–502.
[125] Fields C. How humans solve the frame problem. J Expt Theor Artif Intell 2013;25:441–
456.
[126] Gottlieb J, Lopes M, Oudeyer P-Y. Motivated cognition: Neural and computational
mechanisms of curiosity, attention, and intrinsic motivation. In: Kim S-Y, Reeve J,
Bong M. (Eds) Recent Developments in Neuroscience Research on Human Motivation
(Advances in Motivation and Achievement, Vol. 19), Emerald Group Publishing Limited,
Bingley, UK, 2016, pp. 149–172.
[127] Wooters WK, Zurek WH. A single quantum cannot be cloned. Nature 1982;299:802–
803.
[128] Pratt V. Types as Processes, via Chu spaces. Elect Notes Theor Comp Sci 1997;7:227–
247.
[129] Pratt V. Broadening the denotational semantics of linear logic. Elect Notes Theor
Comp Sci 1996;3: 155–166.
[130] Culbertson J, Sturtz K. Bayesian machine learning via category theory. Preprint
arXiv:1312.1445v1[math.CT], 2013.
[131] Culbertson J, Sturtz K. A categorical foundation for Bayesian probability. Appl Cat-
egor Struct 2014;22(4): 647–662.
[132] Giry M. A categorical approach to probability theory. In: Banaschewski B. (ed)
Categorical Aspects of Topology and Analysis. (Lecture Notes in Mathematics, vol 915).
Springer, Berlin, 1982, pp. 68–85.
[133] Lawvere WF. The category of probabilistic mappings. Unpublished seminar notes,
(1962) available at https://ncatlab.org/nlab/ﬁles/lawvereprobability196.pdf (Accessed
10 Dec 2021).
[134] Abramsky S. Big toy models: Representing physical systems as Chu spaces. Synthese
2012;186:697–718.
[135] Conant RC, Ashby WR. Every good regulator of a system must be a model of that
system. Int J Syst Sci 1970;1(2):89–97.
53
[136] Fields C. Building the observer into the system: Toward a realistic description of
human interaction with the world. Systems 2016;4:32.
[137] Ji Z, Natarajan A, Vidick T, Wright J, Yuen H. MIP* = RE. Comms ACM
2021;64(11):131–138.
[138] Moser MB., Rowland DC, Moser EI. Place cells, grid cells, and memory. Cold Spring
Harbor Perspect Biol 2015;7:a021808.
[139] Stachenfeld KL, Botvinick MM, Gershman SJ. The hippocampus as a predictive map.
Nat Neurosci 2017;20:1643–1653.
[140] Whittington JC, Muller TH, Mark S, Chen G, Barry C, Burgess N, Behrens TE. The
Tolman-Eichenbaum Machine: Unifying space and relational memory through generali-
sation in the hippocampal formation. Preprint bioRxiv:770495, 2019.
[141] Lloyd K, Leslie DS. Context-dependent decision-making: A simple Bayesian model.
J R Soc Interface 2013;10:20130069.
[142] Safron A. An Integrated World Modeling Theory (IWMT) of consciousness: Combin-
ing integrated information and global neuronal workspace theories with the Free Energy
Principle and active inference framework; Toward solving the Hard Problem and charac-
terizing agentic causation. Front Artif Intell 2020;3:30.
[143] Davis MH, Johnsrude IS. Hierarchical processing in spoken language comprehension.
J Neurosci 2003;23:3423–3431.
[144] George D, Hawkins J. Towards a mathematical theory of cortical micro-circuits. PLoS
Comput Biol 2009;5:e1000532.
[145] Friston KJ, Lin M, Frith CD, Pezzulo G, Hobson JA, Ondobaka S. Active inference,
curiosity and insight. Neural Comput 2017;29:2633–2683.
[146] Friston KJ., Rosch, R, Parr T, Price C, Bowman H. Deep temporal models and active
inference. Neurosci Biobehav Rev 2017;77:388–402.
[147] MacKay DJ. Free-energy minimisation algorithm for decoding and cryptoanalysis.
Electron Lett 1995;31:445–447.
[148] Teh YW, Jordan MI, Beal MJ, Blei DM. Hierarchical Dirichlet processes. J Am Statist
Assoc2006;101:1566–1581.
[149] Friston KJ, Parr T, Yuﬁk Y, Sajid N, Price CJ, Holmes E. Generative models, lin-
guistic communication and active inference. Neurosci Biobehav Rev 2020;118:42–64.
[150] Parr T, Friston KJ. The active construction of the visual world. Neuropsychologia
2017;104:92–101.
54
[151] Mead C. Neuromorphic electronic systems. Proc IEEE 1990;78:1629–1636.
[152] Tang J, Yuan F, Shen X, Wang Z, Rao M, He Y, Sun Y, Li X, Zhang W, Li Y,
Gao B, Qian H, Bi G, Song S, Yang J, Wu H. Bridging biological and artiﬁcial neural
networks with emerging neuromorphic devices: Fundamentals, progress, and challenges.
Adv Mater 2019;31:1902761.
[153] Jaynes ET. Information Theory and Statistical Mechanics. Phys Rev (Series II)
1957;106:620–630.
[154] Friston KJ, Wiese W, Hobson JA. Sentience and the origins of consciousness: From
Cartesian duality to Markovian monism. Entropy 2020;22:516.
[155] Fields C. A whole box of Pandoras: Systems, boundaries and free will in quantum
theory. J Expt Theor Artif Intell 2013;25:291–302.
[156] Maturana H, Varela FJ. Autopoiesis and Cognition: The Realization of the Living.
Boston Stud Phil Sci 42. D. Reidel, Dordrecht, 1980.
[157] Varela F, Thompson E, Rosch, E. The Embodied Mind: Cognitive Science and Human
Experience. MIT Press, Cambridsge, MA, 1991.
[158] Anderson ML. Embodied cognition: A ﬁeld guide. Artif Intell 2003;149:91–130.
[159] Froese T, Ziemke T. Enactive artiﬁcial intelligence: Investigating the systemic orga-
nization of life and mind. Artif Intell 2009;173:466–500.
[160] Schr¨ odinger E. What Is Life?. Cambridge University Press, Cambridge, UK, 1944.
[161] Wigner EP. Remarks on the mind-body question. In: Good IJ (ed.), The Scientist
Speculates. London: Heinemann, 1961, pp. 284–302.
[162] Penrose R. The Emperor’s New Mind. Oxford University Press, Oxford, 1989.
[163] Hameroﬀ S, Penrose R. Orchestrated reduction of quantum coherence in brain mi-
crotubules: A model for consciousness. Math. Comput. Simul. 1996;40:453–480.
[164] Tegmark M. Importance of quantum decoherence in brain processes. Phys. Rev. E
2000;61:4194–4206.
[165] Davies PCW. Does quantum mechanics play a non-trivial role in life? BioSystems
2004;78:69–79.
[166] Hameroﬀ S, Tuszynski, J. Quantum states in proteins and protein assemblies: The
essence of life? In: Abbott D, Bezrukov SM, Der A, S´ anchez A. (eds) Fluctuations
and Noise in Biological, Biophysical, and Biomedical Systems II SPIE, Bellingham, WA,
2004, pp. 27–41.
55
[167] Arndt M, Juﬀmann T, Vedral V, Quantum physics meets biology. HFSP J 2009;3:386–
400.
[168] Lambert N, Chen Y-N, Cheng Y-C, Li C-M, Chen G-Y, Nori F. Quantum biology.
Nat. Phys. 2012;9:10–18.
[169] Melkikh AV, Khrennikov A. Nontrivial quantum and quantum-like eﬀects in biosys-
tems: Unsolved questions and paradoxes. Prog. Biophys. Mol. Biol. 2015;119:137–161.
[170] Brookes JC. Quantum eﬀects in biology: Golden rule in enzymes, olfaction, photo-
synthesis and magnetodetection. Proc. R. Soc. A 2017;473:20160822.
[171] McFadden J, Al-Khalili J. The origins of quantum biology. Proc. R. Soc. A
2018;474:20180674.
[172] Marais A, Adams B, Ringsmuth AK, Ferretti M, Gruber MJ, Hendrikx R, et al. The
future of quantum biology. J. R. Soc. Interface 2018;15:20180640.
[173] Cao J, Cogdell RJ, Coker DF, Duan H-G, Kleinekath¨ ofer U, Jansen TLC, et al.
Quantum biology revisited. Sci. Adv. 2020;6:eaaz4888.
[174] Kim Y, Bertagna F, D’Souza EM, Heyes DJ, Johannissen LO, Nery ET. Quantum
biology: An update and perspective. Quant Rep 2021;3:1–48.
[175] Polanyi M. Life’s irreducible structure. Science 1968;160:1308–1312.
[176] Rosen R. On information and complexity. In Casti JL, Karlqvist A. (eds) Complexity,
Language, and Life: Mathematical Approaches. Springer, Berlin, 1986; pp. 174–196.
[177] Ellis GFR. Physics, complexity, and causality. Nature 2005;435:743.
[178] Fields C, Levin M. Metabolic limits on classical information processing by biological
cells. BioSystems 2021;209:104513.
[179] Cervantes VH, Dzhafarov EN. Snow Queen is evil and beautiful: Experimental evi-
dence for probabilistic contextuality in human choices. Decision 2018;5(3):193–204.
[180] Basieva I, Cervantes VH, Dzhafarov EN, Khrennikov A. True contextuality beats
directs inﬂuences in human decision making. J Expt Psychol General 2019;148:1925–
1937.
[181] Khrennikov A. Quantum-like modeling of cognition. Front Phys 2015;3:77.
[182] Basieva I, Khrennikov A, Ohya M, Yamato O. Quantum-like interference eﬀect in
gene expression: glucose-lactose destructive interference. Syst Synth Biol 2011;5:59–68.
[183] Friston K, Frith C. A Duet for one. Conscious Cogn 2015;36:390–405.
56
[184] Frith C, Wentzer T. Neural Hermeneutics. In Kaldis B. (ed) Encyclopedia of Phi-
losophy and the Social Sciences. SAGE Publications, Thousand Oaks, CA, 2013, pp.
657–659.
[185] Friston KJ, Frith CD. Active inference, communication and hermeneutics. Cortex
2015;68:129–143.
[186] Isomura T, Parr T, Friston K. Bayesian ﬁltering with multiple internal models: To-
ward a theory of social intelligence. Neural Comput 2019;31:2390–2431.
[187] Campbell JO. Universal Darwinism as a process of Bayesian inference. Front Syst
Neurosci 2016;10:49.
[188] Fields C, Levin M. Integrating evolutionary and developmental thinking into a scale-
free biology. BioEssays 2020;42:1900228.
[189] Fields C, Levin M. Does evolution have a target morphology? Organisms 2020;4:57–
76.
[190] Zurek WH. Quantum Darwinism. Nature Physics 2009;5:181–188.
[191] Campbell JO. Quantum Darwinism as a Darwinian process. Preprint arXiv:1001.0745
[physics.gen-ph], 2010.
[192] Fields C. Quantum Darwinism requires an extra-theoretical assumption of encoding
redundancy. Int J Theor Phys 2010;49:2523–2527.
[193] Abramsky S, Brandenburger, A. The sheaf-theoretic structure of non-locality and
contextuality. New J Phys 2011;13:113036.
[194] Abramsky S, Hardy L. Logical Bell inequalities. Phys Rev A 2012; 85(6):062114.
[195] Popescu S. Non-locality beyond quantum mechanics. Nat Phys 2014;10:264–270.
[196] Adlam E. Contextuality, ﬁne-tuning and teleological explanation. Preprint
arXiv:2110.15898v1[quant-ph], 2021.
57