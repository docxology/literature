arXiv:2410.02972v1  [q-bio.NC]  3 Oct 2024
Bayesian Mechanics of Synaptic Learning under the
Free Energy Principle
Chang Sub Kim
Department of Physics, Chonnam National University, Gwangju 61 186, Republic of
Korea
E-mail: cskim@jnu.ac.kr
Abstract. The brain is a biological system comprising nerve cells and orchestrat es its
embodied agent’s perception, behavior, and learning in the dynamic e nvironment. The
free energy principle (FEP) advocated by Karl Friston explicates t he local, recurrent,
and self-supervised neurodynamics of the brain’s higher-order fu nctions. In this paper,
we continue to ﬁnesse the FEP through the physics-guided formula tion; speciﬁcally,
we apply our theory to synaptic learning by considering it an inferenc e problem under
the FEP and derive the governing equations, called Bayesian mechan ics. Our study
uncovers how the brain infers weight change and postsynaptic act ivity, conditioned
on the presynaptic input, by deploying the generative models of the likelihood and
prior belief. Consequently, we exemplify the synaptic plasticity in the brain with a
simple model: we illustrate that the brain organizes an optimal trajec tory in neural
phase space during synaptic learning in continuous time, which variat ionally minimizes
synaptic surprisal.
Keywords free energy principle; synaptic learning; Bayesian mechanics; cont inuous-
state formulation
Bayesian Mechanics of Synaptic Learning under the Free Energy Principle 2
1. Introduction
The brain’s perception, body movement, and learning are conjointly organized to
ensure the embodied agents’ homeostasis and adaptive ﬁtness in t he environment. It
is tempting to imagine a neural observer in the brain presiding over hig her animals’
cognitive control. Such a homunculus idea is untenable and must be dis carded in the
present-day brain theory [1]. However, there is still a much distanc e to the complete
scientiﬁc understanding of the emergent higher-order functions from the brain matter; it
demands a comprehension of the profound interplay between the s cientiﬁc reductionism
and teleological holism standpoints [2, 3].
The brain-inspired FEP is a purposive theory that bridges the gap be tween top-
down teleology and bottom-up scientiﬁc constructionism. Accordin g to the FEP [4, 5],
all living systems are self-organized to tend to avoid an atypical nich e in the environment
for existence. The FEP adopts the autopoietic hypothesis [6] and s cientiﬁcally formalizes
the abductive rationale of organisms’ making optimal predictions an d behavior from
incomplete sensory data. To be precise, the FEP suggests an infor mation-theoretic,
variational measure of environmental atypicality, termed free energy (FE). The FE
objective is technically deﬁned as a functional of the probabilistic ge nerative density
specifying the brain’s internal model of sensory-data generation and environmental
change and an online auxiliary density actuating variation. The Bayes ian brain
computes the posterior of the environmental causes of uncerta in sensory data by
minimizing the FE, whose detailed continuous-state description can b e found in [7]. For
discrete-state models of the FEP with discrete time, we recommend [8, 9] to readers.
When a Gaussian probability is employed for the variational density [1 0], the FE
becomes a L2 norm speciﬁed by the Gaussian means and variances and termed the
Laplace-encoded FE [7]. Thus, the Laplace-encoded FE provides a s cientiﬁc base of the
L2 objectives in a principled manner, which are widely used in machine learn ing and
artiﬁcial intelligence. For instance, the optimization function in the p redictive-coding
framework is proposed to be a sum of the squared prediction error s [11]. Also, the
loss function of a typical artiﬁcial neural network (ANN) is often w ritten as a sum of
squared diﬀerences between the ground truth and the predictive entries from the network
[12]. Furthermore, it is argued that the Gaussian suﬃcient statistic s are encoded by
the biophysical brain variables, which form the brain’s low-dimensiona l representations
of environmental states. This way the brain acquires access to th e encoded FE for
minimization as it becomes fully speciﬁed in terms of the brain’s internal states.
Our research over the years has been devoted to developing cont inuous-state
implementation of the FE minimization in a manner guided by physics laws a nd
principles [13, 14, 15]. We endeavored to advance the FEP to the poin t where it
coalesces into a uniﬁed principle of top-down architecture and mate rial base. Moreover,
to promote the FEP to nonstationary problems, we incorporated t he fact that the
physical brain is in a nonequilibrium (NEQ) stationary state and is gene rally continually
aroused by nonstationary sensory stimuli. The functional brain mu st perform the
Bayesian Mechanics of Synaptic Learning under the Free Energy Principle 3
variational Bayesian inversion of nonstationary sensory data to c ompute the posterior
mentioned above. Previously, we accounted for the brain behavior of perception and
motor control as described by attractor dynamics and termed th e governing equations
Bayesian mechanics (BM). The BM coordinates the brain’s sensory estimation and
motor prediction in neural phase space. In this paper, we make fur ther progress by
incorporating the brain’s synaptic learninginto the BM, which we did not accommodate
in our earlier studies. Learning constitutes the crucial brain funct ion of consolidating
memory, e.g., via Hebbian plasticity [16].
This paper aims to provide a simple but insightful model for synaptic le arning
in the brain. Our agendas are that the functional brain operates c ontinually using
continuous environmental representations and that synaptic lea rning is a cognitive
phenomenon that may very well be understood when statistical-ph ysical laws guide
it. The notion cognition throughout this paper is meant to be the brain’s higher-
order capability that involves a top-down, internal model. We consid er the NEQ brain
a problem-solving matter, cognitively interacting with the environme nt. To quantify
the synaptic cognition, we will specify the generative densities furn ishing the Laplace-
encoded FE in a manner to meet the NEQ stationarity and present th e FE minimization
scheme by practicing the principle of least action (Hamilton’s principle) [17]. The novel
contributions worked out in this paper are discussed in Section 7.
The rest of the paper is organized as follows. In Section 2, the single -synapse
structure of our interest is described. The essence of the FEP is r ecapitulated with
revision made for synaptic learning in Section 3. In Section 4, an NEQ f ormulation
is presented, which determines the likelihood and prior densities in the physical brain.
Next, Section 5 identiﬁes the FE objective as a classical action and d erives the governing
equations of synaptic dynamics by exercising the Hamilton principle. T he utility of our
theory is demonstrated in Section 6 using a simple model. After the dis cussion in
Section 7, a conclusion is given in Section 8.
2. Single Synapse Model
This work concerns the brain’s synaptic learning without considering how environmental
processes arouse stimuli at the sensory interface; as a parsimon ious model, we focus
on a single synapse within the brain’s internal environment. For insta nce, in the
hippocampus, the postsynaptic action potential in the dentate gy rus is evoked by a
presynaptic signal from the entorhinal cortex caused by a neura l signal from other
brain areas. Accordingly, the synaptic coupling between two pyram idal neurons in the
hippocampus constitutes a single synaptic assembly of interest.
We depict the single synaptic model in Figure 1, where the presynapt ic and
postsynaptic signals are denoted by s and µ, respectively; both are the brain’s
representations of noisy synaptic signals. In addition, the synapt ic plasticity is mediated
by the weight strength denoted by w. The synaptic structure considered is generic for
all neurons; accordingly, the ensuing formulation below applies to ot her brain regions.
Bayesian Mechanics of Synaptic Learning under the Free Energy Principle 4
Figure 1. Single synaptic assembly. The postsynaptic neural state µ is
neurophysically evoked by the presynaptic signal s, mediated by the weight change ∆ w
according to Hebb’s rule 9sµ. We adopt the Bayesian-inference perspective, suggesting
that the brain state µ infers the cause of the presynaptic input s, and the weight state
w makes up the synaptic input-output interface.
Note that we will handle the weight variable w as a neurophysical degree of freedom
like s and µ; this handling contrasts with ANN models, where the weights are tre ated
as a static parameter.
3. Free Energy Principle for Synaptic Learning
The brain-inspired FEP is built on three hypotheses: 1) surprisal hy pothesis, 2)
representation hypothesis, and 3) computability hypothesis, whic h we recapitulate here
with the revision applying to the synaptic learning problem.
3.1. Surprisal Hypothesis
We assume that the presynaptic signals s streaming into the synaptic interface are
prescribed and focus on the resulting synaptic dynamics. For conv enience, here we
introduce the notation ˜ϑ, by which we collectively denote the postsynaptic variable M
and the weight variable W:
˜ϑ “ t M, Wu.
The variables M and W are stochastic and unknown, so they are hidden from the
brain’s perspective.
The brain’s cognitive goal is to compute the posterior pp ˜ϑ|sq, which the FEP fulﬁlls
via variational Bayes in the following manner: First, we deﬁne the info rmation-theoretic
measure called the Kullback-Leibler (KL) divergence:
DKL
´
qp ˜ϑq}pp ˜ϑ|sq
¯
“
ż
d˜ϑqp ˜ϑq ln qp ˜ϑq
pp ˜ϑ|sq
, (1)
Bayesian Mechanics of Synaptic Learning under the Free Energy Principle 5
which is always positive [18], where d˜ϑ means dMdW. Some terminologies: qp ˜ϑq is
called R-density, which approximates the true posterior pp ˜ϑ|sq in the variational scheme.
The posterior makes up the so-called G-density pp ˜ϑ,s q “ pp ˜ϑ|sqppsq together with the
marginal density ppsq [7]. Second, using the preceding product rule, the above KL
divergence can be decomposed to
DKL
´
qp ˜ϑq}pp ˜ϑ|sq
¯
“ Frqp ˜ϑq,p p ˜ϑ,s qs ` ln ppsq.
The functional F on the right-hand side (RHS), which is identiﬁed to be
Frqp ˜ϑq,p p ˜ϑ,s qs ”
ż
d˜ϑ qp ˜ϑq ln qpϑq
pp ˜ϑ,s q
, (2)
is the informational free energy (FE). Third, the positivity of DKL leads to the inequality
´ ln ppsq ď Frqp ˜ϑq,p p ˜ϑ,s qs. (3)
Equation (3) is the mathematical statement of the brain-inspired F EP accounting
for life and cognitive phenomena in a universal manner, which compris es the surprisal
hypothesis. In the present context, the preceding inequality enunciates tha t synaptic
learning corresponds to the brain’s minimizing F, which is a proxy for synaptic surprisal,
´ ln ppsq, as an upper bound. In practice, it is intractable to determine the m arginal
density ppsq, which provides synaptic evidence to the brain. Note here that F is called
FE by mimicking thermodynamic FE in physics, which monotonically decre ases upon
spontaneous changes in a macroscopic open system, conforming t o the second law of
thermodynamics [15].
3.2. Representation Hypothesis
According to the inequality [Equation (3)], the brain variationally minimiz es F by means
of the R-density qp ˜ϑq: when the synaptic interface is elicited by the presynaptic stream
s, the brain launches qp ˜ϑq, an online approximation of the posterior; in the face of the
synaptic stream, the R-density probabilistically represents the un certain, hidden causes
˜ϑ “ t M, Wu, trying to match best with the posterior. Here, we adopt the Lapla ce
approximation for the R-density, which assumes a Gaussian form [19 ]:
qp ˜ϑq “ 1
?
2π˜σ2 expr´ 1
2˜σ2 p ˜ϑ´ ˜µq2s, (4)
where ˜µ and ˜σ are the suﬃcient statistics of the Gaussian density. In particular, we
intend that the means denoted by
˜µ “ t µ,w u
are the coarse-grained representations of high-dimensional ˜ϑ “ t M, Wu; they are the
latent brain variables in low dimensional neural space [20]. Also, the de pendence on
the variances ˜σ can be eliminated by further manipulation as elaborated in [7]. Then,
under the Laplace approximation, the FE functional reduces to
Frqp ˜ϑq,p p ˜ϑ,s qs “ ´ ln pp ˜µ,s q ` constants.
Bayesian Mechanics of Synaptic Learning under the Free Energy Principle 6
The nontrivial part in the reduced expression is the Laplace-encod ed FE denoted by F:
Fpµ,w,s q “ ´ ln ppµ,w,s q, (5)
which is a function of only the brain variables µ and w. In the present work, the
presynaptic input s is not a dynamical variable but is handled as an external time-
dependent input.
Here, the brain is assumed to be endowed with the generative densit y ppµ,w,s q
encoded over the evolutionary and developmental time scales. The FEP inequality
given in Equation (3) now becomes
´ ln ppsq ď Fpµ,w,s q; (6)
the brain has an access to Fpµ,w,s q by means of its internal variables µ and w. The
preceding expression comprises the representation hypothesis in the FEP; the brain
uses the coarse-grained representations µ and w in variationally minimizing synaptic
surprisal. Then, by applying the product rule ppµ,w,s q “ ppw|µ,s qppµ,s q, the Laplace-
encoded FE is completed as
Fpµ,w |sq “ ´ ln ppw|µ,s qppµ,s q, (7)
where ppw|µ,s q is the likelihood of the weight strength w given a postsynaptic signal µ,
and ppµ,s q is the prior about the postsynaptic dynamics, both subject to the presynaptic
input s.
Equation (7) is the objective function for synaptic learning under t he FEP, furnished
with only brain variables, which makes the brain-inspired FEP a biologica lly plausible
theory. Previously, we suggested that all the involved probabilities be speciﬁed as NEQ
stationary densities derived from the Fokker–Planck equation [15]. This work takes a
diﬀerent approach to determining the NEQ densities in Section 4.
3.3. Computability Hypothesis
The brain is endowed with the mechanism that actuates the FE minimiza tion, which
comprises the computability hypothesis in the FEP. The conventional continuous-state
implementation assumes that the brain employs gradient descent (G D) methods to
execute the FE minimization [5]. The GD schemes update the neural ac tivity µ downhill
on the FE landscape, which is woven by the generalized coordinates o f motion of all
dynamical orders surpassing the second order, namely, accelera tion [21, 22]. It is argued
that generalized motion can eﬀectively incorporate the temporal c orrelation of random
ﬂuctuations in stochastic dynamics beyond white noise. However, t he idea of generalized
motion transcends normative Newtonian physics; thus, its theore tical ground draws
critical attention in the literature [23, 14]. For the weight variable w, to incorporate its
slower change than the neural activity, a diﬀerent update rule is ap plied: for instance,
instead of the weight (parameters or hyper-parameters), its ra te may be updated under
the GD scheme [7]. Recently, researchers have extended the applic ability of FEP-based
GD algorithms to robotics and artiﬁcial intelligence problems, emphas izing colored-
noise modeling [24]. However, it is signiﬁcant to note that using GD meth ods is not
Bayesian Mechanics of Synaptic Learning under the Free Energy Principle 7
legitimate when the environmental inputs vary fast so that the FE la ndscape becomes
non-static (see, for further discussion, Section 7). Our formula tion aims at the general
time-dependent situation and, thus, avoids using a GD scheme; inst ead, we identify the
FE objective to be a classical action in mechanics and exercise Hamilto n’s principle
for the FE minimization according to the standard theory [17]. The de tails are given
in Section 5, where we derive the governing equations of motion for s ynaptic inference
regarding the canonical physical variables without invoking the gen eralized motion.
4. Nonequilibrium Generative Densities
We argued that the physical brain probabilistically encodes the repr esentations of the
internal and external hidden states (Section 3.2). The encoded p robabilities constitute
the generative densities that furnish the brain with FE objective fo r variational Bayesian
inference. Therefore, the generative densities must be speciﬁed in terms of the
biophysical brain variables in an NEQ stationary state. Here, we pre sent a stochastic
thermodynamic model for the NEQ densities, viewing the brain as a so ft material
consisting of neural constituents. This perspective brings us clos er to understanding
the brain’s NEQ states.
4.1. Prior for Postsynaptic Activity
For a simple description, we assume that the brain variable µ obeys an overdamped
Langevin dynamics on a mesoscopic scale:
dµ
dt “ fpµ,θ q ` ξ, (8)
where f and ξ on the RHS are the deterministic and random forces, respectively,
causing the neural change; θencapsulated in f denotes an input parameter aﬀecting the
system dynamics. The solution to Equation (8) describes a stochas tic path or trajectory
µ “ µptq in continuous state space. Recall that the neural variable µ is the mean of
the R-density probabilistically representing external environment al states online, which
may be viewed as a mean ﬁeld. Also, it is evident that the state transit ion between two
arbitrarily-close times described by Equation (8) is Markovian. Furt her assumptions
imposed are i) the noise ξ is Gaussian about zero mean, rendering xξy “ 0, and ii) the
noise is delta-correlated, a.k.a. white, through
xξpt1qξptqy “ σ2
µ δpt1 ´ tq, (9)
where σ2
µ is the noise strength. Strictly considering, the biological brain is in an
NEQ stationary state, whose temperature T is distinct from the environmental value;
however, here, we consider that the brain is locally in equilibrium chara cterized by its
body temperature. Also, we assume that the noise strength is give n, according to the
ﬂuctuation-dissipation theorem [25], as
σ2
µ “ 2γ´ 1
µ kBT, (10)
Bayesian Mechanics of Synaptic Learning under the Free Energy Principle 8
where γµ is the frictional coeﬃcient of the brain matter, and kB is the Boltzmann
constant.
Under the prescribed assumptions, we build the transition probabilit y along a
trajectory µ “ µptq as time t elapses. To proceed with the derivation, we ﬁrst note
a technical subtlety involved in the white noise ξptq: it is mathematically ill-deﬁned
because the variance is divergent [see Equation (9)]. To address th is, the Wiener process,
deﬁned through ∆ W ” ξ∆ t, is often conceived. This process introduces a form of coarse-
graining over a short time interval ∆ t, eﬀectively bypassing the singularity of the white
noise at an instant time. The Wiener process is also Gaussian about ze ro mean with
the well-deﬁned variance xp∆ Wq2y “ σ2
µ ∆ t. However, one must pay the price for the
Wiener recipe when the Riemann integral is performed for state fun ctions over a ﬁnite-
time elapse. In our derivation, we adopt the Ito convention that int erprets the integral
of Equation (8) over the time interval ∆ t“ tn` 1 ´ tn as
∆ µn “ fpµn,θ nq∆ t` ∆ Wn,
where the ﬁrst term on the RHS was approximated by choosing the v alue for fpµq at
the initial time tn; other terms are ∆ µn “ µn` 1 ´ µn and ∆ Wn “ Wn` 1 ´ Wn. Next,
using the Gussianity of ∆ Wn, we deﬁne the transition probability ppn` 1|nq from the
Wiener state Wn to the next Wn` 1 as [26]
ppn` 1|nq » exp
"
´ 1
2σ2µ ∆ t
´
∆ µn ´ fpµn,θ nq∆ t
¯2*
.
Then, the full Markovian transition over Np“ t{∆ tq time steps during the ﬁnite time
0 ď t1 ď t can be built as
N´ 1ź
n“ 0
ppn` 1|nq » exp
#
´ ∆ t
2σ2µ
ÿ
n
´ ∆ µn
∆ t ´ fpµn,θ nq
¯2
+
.
As a ﬁnal step, we take the continuous limit ∆ t Ñ 0 in the preceding expression and
obtain the path probability ppµ,θ q, up to a normalization constant, as
ppµ,θ q „ exp
#
´ 1
2σ2
µ
ż t
0
dt1
ˆ dµ
dt1 ´ fpµ,θ pt1qq
˙2+
, (11)
which is known as the Onsager-Machlup function [27].
The above Onsager–Machlup expression speciﬁes the transition pr obability of the
neural state µ, given initial condition µp0q, along the continuous path µ “ µptq.
When the parameter θ is replaced with s, it represents the prior density ppµ,s q in
Equation (7) accounting for the brain’s belief about or already-acq uired knowledge of
how the postsynaptic activity µ behaves.
4.2. Likelihood of Synaptic Change
Neurotransmitter transport at the synaptic interface mediates synaptic coupling
between two neurons, which is often eﬀectively described by the we ight variable w. We
assume that the brain is endowed with an internal model of weight dy namics leveraging
Bayesian Mechanics of Synaptic Learning under the Free Energy Principle 9
learning; learning constitutes the crucial brain function of consolid ating memory, e.g.,
via long-term potentiation.
We consider the synaptic weight w a time-dependent variable rather than a static
parameter, and the synaptic plasticity is described by its the rate 9w “ dw{dt. We
propose that similar to Equation (8), the synaptic plasticity is gover ned by the stochastic
equation:
dw
dt “ hpw,θ q ` χ, (12)
where h is the biophysical force causing the weight change, and χ is the additive
white noise associated with the synaptic process; again, θ is a time-dependent input
parameter. The noise is assumed to be Gaussian about zero mean an d delta-correlated:
xχptqχpt1qy “ σ2
wδpt´ t1q with σ2
w being the noise strength.
Next, to smooth the temporal singularity associated with the white noise χ, we
consider the Wiener process ∆ W “ χ∆ t, which is also Gaussian about zero mean
with the well-deﬁned variance, xp∆ Wq2y “ σ2
w∆ t. Then, we proceed with the same
formulation with Section 4.1 to specify the NEQ likelihood density ppw|θq. The result
is given as
ppw|θq „ exp
#
´ 1
2σ2w
ż t
0
dt1
ˆ dw
dt1 ´ hpw,θ pt1qq
˙2+
, (13)
which represents the Onsager–Machlup transition probability along the continuous path
w“ wptq, subject to initial condition wp0q.
In obtaining the above likelihood and prior densities, Equations (11) a nd (13),
respectively, we assumed that the random ﬂuctuations in the neur onal dynamics were
delta-correlated, i.e., white noises. The brain signals, by contrast, evidently reveal
the frequency spectrum reﬂecting color-correlated dynamics [28 ], which supports the
criticality idea in the brain [29]. In this work, we consider only the ideal w hite noise for
a practical illustration of determining the NEQ brain densities in a phys ics-grounded
manner. To obtain an analytic expression for the NEQ densities is intr actable under
general conditions even in the steady state [15]; they are usually as sumed to be an instant
Gaussian set by the Gaussian random noises imposed on the Langevin description [4, 5].
5. Bayesian Mechanics: Computability of Synaptic Learning
The FE landscape becomes nonstatic when the input parameter θ in the generative
densities [Equations (11) and (13)] is explicitly time-dependent. In t his case, it
is anticipated that the GD implementation on the FE landscape will fail. H ere,
we formulate the brain’s computability under nonstationary conditio ns, facilitating
nonautonomous neural computation.
In the synaptic learning problem, the presynaptic signal s acts as the input
parameter θ. Accordingly, we replace θ with s in the Onsager–Maclup representations
Bayesian Mechanics of Synaptic Learning under the Free Energy Principle 10
for the NEQ densities and substitute the results into Equation (7) t o obtain the Laplace-
encoded FE. The outcome is given as
F “
ż t
0
Lpµ,w ; 9µ, 9w; sqdt1, (14)
where the integrand L is expressed as
Lpµ,w ; 9µ, 9w; sq ” 1
2σ2µ
ˆ dµ
dt1 ´ fpµ,w ; spt1qq
˙2
` 1
2σ2w
ˆ dw
dt1 ´ hpµ,w,s pt1qq
˙2
.(15)
Note that in Equation (15), we concretely displayed the autonomou s dependence on
the variables µ and w and the nonautonomous dependence on the input s through the
generative functions f and h.
Equation (14) manifests a speciﬁc association of the FE objective F with the
mathematical object L; namely, F is given as a time integral of L. This observation
is reminiscent of the relation between the action and Lagrangian in cla ssical mechanics
[17]. Accordingly, by analogy, if we identify F as an eﬀective action S and the integrand
L as an eﬀective Lagrangian for the brain’s cognitive computation, the FE minimization,
which is mathematically performed by δF “ 0 under the FEP, is precisely mapped to
exercising Hamilton’s principle, δS “ 0. Then, the Euler-Lagrange equations of motion
for determining the optimal trajectories µptq and wptq will follow straightforwardly,
constituting the synaptic BM. Note the temperature dependence of the Lagrangian
[Equation (15)] via the noisy strengths σ2
µ and σ2
w, see Equation (10), which makes L a
thermal Lagrangian [27].
Here, working in the Hamiltonian description is more suitable for our pu rposes. To
this end, we carried out a Legendre transformation to derive an eﬀ ective Hamiltonian
H; the outcome is expressed as
H “ p2
µ
2mµ
` p2
w
2mw
` pµ fpµ,w ; sq ` pwhpw,µ ; sq. (16)
In the preceding expression of Hamiltonian, the new variables pµ and pw appear, which
are mechanically conjugate to the variables µ and w, respectively; they are determined
from the deﬁnitions:
pµ “ BL
B 9µ and pw “ BL
B 9w. (17)
Also, the constants, mµ and mw were deﬁned to be
mµ “ 1{σ2
µ and mw “ 1{σ2
w, (18)
which are a measure of respective precision of the probabilistic gene rative models,
Equations (11) and (13). Equation (10) suggests that the gener ative precisions are
a biophysical constant speciﬁed by the body temperature and the friction of the brain
matter. A few points about the Hamiltonian H are noteworthy: The variables ( µ, w)
and ( pµ , pw) correspond to positions and momenta, respectively, and the generative
precisions mµ and mw may be interpreted as a neural mass as a metaphor. The
Hamiltonian is not breakable into the kinetic and potential energies be cause the third
Bayesian Mechanics of Synaptic Learning under the Free Energy Principle 11
and fourth terms on the RHS in Equation (16) are given as a product of momentum
and position variables. The H function does not furnish a conservative-energy surface
because of its explicit time dependence through the presynaptic sig nal sptq, which makes
synaptic learning a nonautonomous problem.
The generative functions f and h for synaptic learning were introduced in
Equations (8) and (12) without specifying them; they are the bioph ysical forces driving
synaptic dynamics at the neuronal level. We now specify them by the following models:
fpµ,w ; sq “ ´ γµ pµ´ µdq ` ws, (19)
hpµ,w ; sq “ ´ γwpw´ wdq ` sµ. (20)
The ﬁrst terms on the RHSs, involving the damping coeﬃcients γµ and γw, prevent
an unlimited growth of µ and w [30]. The linear damping models may be replaced
with a nonlinear alternative; for instance, the modiﬁed ´γws2pw´ wdq may be used in
Equation (20) [31]. The second term ws on the RHS of Equation (19) describes the
presynaptic evoking weighted by w. Moreover, the term sµ in Equation (20) accounts
for Hebb’s rule; one can explore anti-Hebbian learning by inverting its sign. The extra
parameters µd and wd are the steady-state values of µ and w, respectively, without
driving terms wsand sµ. After substituting Equations (19) and (20) into Equation (15)
and by evaluating Equation (17), one can determine the neural rep resentations of the
momenta pµ and pw. The results are given as
pµ “ mµ p 9µ´ fq, (21)
pw “ mwp 9w´ hq. (22)
Note that momentum represents the discrepancy between the st ate rate and its
prediction from the generative model, modulated by precision, which corresponds to
prediction error in predictive coding theory (see discussion in Section 7).
Having speciﬁed the synaptic Hamiltonian given in Equation (16), we no w derive
Hamilton’s equations of motion by practicing the standard procedur e [17]. Here, we
present only the outcome without intermediate steps:
9µ “ 1
mµ
pµ ´ γµ pµ´ µdq ` ws, (23)
9w “ 1
mw
pw ´ γwpw´ wdq ` sµ, (24)
9pµ “ γµ pµ ´ spw, (25)
9pw “ γwpw ´ spµ . (26)
The resulting Equations (23)–(26) are a set of coupled diﬀerential equations for four
dynamical variables µ, w, pµ , and pw, subject to the time-dependent input source
s, which constitute the synaptic BM governing co-evolution of the state and weight
variables. In Figure 2, we show the neural circuitry implied by the der ived BM. We
argue that the functional behavior depicted in the circuitry is gene ric in every synapse
in the brain like every cortical column in the neocortex behaves as a s ensorimotor system
performing the same intrinsic function [32].
Bayesian Mechanics of Synaptic Learning under the Free Energy Principle 12
Figure 2. Schematic of the neural circuitry. The diagram manifests the work ings
of the synaptic BM: the presynaptic input sptq drives the interconnected, recurrent
dynamics among the state pw, µ q and momentum ppw, p µ q variables. The links depicted
by arrowheads indicate an excitatory coupling within a neural unit or between two
neural units, whereas the dot-head links indicate an inhibitory coup ling.
For a more compact description, we shall deﬁne the cognitive state Ψ as a column
vector in four-dimensional phase space:
Ψ T “ p µ,w,p µ ,p wq ” p ψ1,ψ 2,ψ 3,ψ 4q,
where T denotes a transpose operation. Then, the preceding Equations ( 23)–(26) can
be compactly expressed as
9Ψ “ RΨ ` I, (27)
where R is a 4 ˆ 4 matrix identiﬁed as
R “
¨
˚
˚
˚
˝
´γµ s 1{mµ 0
s ´γw 0 1 {mw
0 0 γµ ´s
0 0 ´s γ w
˛
‹
‹
‹
‚, (28)
and the inhomogeneous vector I is identiﬁed to be
IT “ p γµ µd,γ wwd, 0, 0q. (29)
Equation (27) can be formally integrated to bring about the solution :
Ψ ptq “ e
şt
0 Rpt1 qdt1
Ψ p0q `
ż t
0
dt1e
şt
t1 Rpτqdτ I, (30)
where the ﬁrst term on the RHS is a homogeneous solution, given the initial condition
Ψ p0q, and the second term is the inhomogeneous solution, driven by the s ource I.
The formal solution represents a continuous path in 4-dimensional phase space, which
Bayesian Mechanics of Synaptic Learning under the Free Energy Principle 13
variationally optimizes the FE objective [Equation (14)]. Note that th e trace of R
vanishes identically, i.e., TrpRq “ 0; accordingly, the sum of its eigenvalues must equal
zero, which we use as a consistency condition in the numerical calcula tion presented in
Section 6. In addition, when the presynaptic signal is constant or s aturates in time, the
ﬁxed point Ψ eq can be obtained analytically:
Ψ T
eq “ p µd ` s8wd{γµ
1 ´ s2
8{γµ γw
, wd ` s8 µd{γw
1 ´ s2
8{γµ γw
, 0, 0q, (31)
where we used the notation s8 “ sptÑ 8q .
6. Numerical Illustration
To exemplify the workings of the BM conducting synaptic inference, we numerically
integrated Equations (23)–(26). The results are presented belo w.
6.1. Free Parameters
Table 1. Parameter values we used to produce the data
mµ mw γµ γw µd wd
Solid 5 0.5 1 0.1 5 5
Dotted 5 0.5 1 0.1 10 0
Six free parameters appear in the BM and need to be ﬁxed for numer ical purposes,
of which values we choose as displayed in Table 1. The neural masses mµ and mw are a
measure of inferential precision deﬁned to be the inverse noise str engths [Equation (18)].
The frictional coeﬃcients denoted by γµ and γw appear in the generative functions
[Equations (19) and (20)], which we set γµ “ 10γw to account for the slower weight
dynamics compared to the neuronal activity. Also, the parameter s µd and wd in
the inhomogeneous vector [Equation (29)] represent the brain’s p rior belief about the
postsynaptic and weight values before the presynaptic input arriv es.
6.2. Static Presynaptic Input
We ﬁrst present the numerical outcome when the synapse delineat ed in Figure 1 is
evoked by a static presynaptic signal, which we set as s“ 5.
Figure 3 shows the synaptic response of w and µ to the prescribed input from two
diﬀerent parameter sets displayed in Table 1. Both cases exhibit tra nsient harmonic
behaviors: The ﬁgure manifests that in response to the static inpu t, the magnitude of
the output signals initially increases from the starting value 0; then, they approach the
corresponding ﬁxed points in a sinusoidal manner, pweq,µ eqq “ p´ 1.0, 0.1q for the solid
curve and pweq,µ eqq “ p´ 2.0, 0.0q for the dotted curve. The transient harmonic behavior
is attributed to imaginary eigenvalues of the matrix R for the chosen parameters. The
Bayesian Mechanics of Synaptic Learning under the Free Energy Principle 14
2 4 6 8 10 t
-3.5
-3.0
-2.5
-2.0
-1.5
-1.0
-0.5
0.0
w(t)
Weight Dynamics
2 4 6 8 10 t
-1.0
-0.5
0.0
0.5
1.0
1.5
µ(t)
Postsynaptic Activity
Figure 3. Synaptic dynamics evoked by the static presynaptic input s “ 5. The
parameter values that we used to produce the graphs are displaye d in Table 1; the
initial condition was chosen as µp0q “ 0 and wp0q “ 0 [All curves are in arbitrary
units].
-6 -4 -2 0 2 4 6
-6
-4
-2
0
2
4
6
w
µ
Figure 4. Continuous path driven by the static presynaptic input s “ 5: The initial
condition was chosen at pw, µ q “ p 5, 5q, marked by the blue dot; also, for illustrational
purposes, we set µd “ 0 and wd “ 0 while other parameter values are the same as in
Table 1.
plots for pµ and pw are not shown because we exploit dynamics near the ﬁxed points,
where their values are zero [see Equation (31)]. In general, the full synaptic dynamics
undergoes in 4-dimensional phase space.
In Figure 4, we illustrate a trajectory in the state space spanned b y pw,µ q; the
numerical conditions are described in the caption. One can observe the spiral approach
to the ﬁxed point p0, 0q, starting from the initial condition p5, 5q arbitrarily chosen for
the illustrational purpose. Again, the momentum representations are not drawn because
their values remain near the equilibrium point in the considered linear dy namics. Note
that the irregularity in the background streamlines is due to the nois e in the presynaptic
input, reﬂecting the fact that the brain deterministically predicts c ognitive outcomes
only on average. The trajectory we have illustrated is critical to un derstanding the
Bayesian Mechanics of Synaptic Learning under the Free Energy Principle 15
2 4 6 8 10 t
-5
0
5
w(t)
Weight Dynamics
2 4 6 8 10 t
-6
-4
-2
0
2
4
6
8
µ(t)
Postsynaptic Activity
Figure 5. Synaptic dynamics evoked by sptq “ 5 cos t` η, where η represents a random
ﬂuctuation: The blue solid and red dotted curves are the results fr om the parameter
values displayed in Table 1; in addition, we include the black dotted curv e from µd “ 0
and wd “ 0, while other parameter values remain the same. For all data, the in itial
condition was chosen at pw, µ q “ p 5, 5q [All curves are in arbitrary units].
unconscious cognition of weight change and postsynaptic output. The temporal course
is conditioned on the presynaptic input in the Bayesian brain, a crucia l context for our
research.
6.3. Nonstationary Presynaptic Inputs
Here, we present the numerical results of when the nonstationar y presynaptic inputs
drive the BM.
First, in Figure 5, we illustrate the weight dynamics and the postsyna ptic activity
resulting from the sinusoidally varying presynaptic input. In this cas e, the continual
harmonic driving causes the output signals to retain their oscillatory behavior and not
tend to a ﬁxed point. The output signals exhibit both positive and neg ative portions
because we considered the voltage-dependent plasticity, aiming at the continuous change,
which could induce the negative voltage response [33]. In contrast, only positive
signals would be produced if we considered the spike-timing-depende nt plasticity. The
momentum variables are not drawn because we follow dynamics near t he ﬁxed point
in neural phase space, where they remain nearly zero. Also, it need s to be understood
that the weight dynamics is ten times slower than the postsynaptic a ctivity because
we assumed the postsynaptic signal decays ten times faster (see Table 1). The same
interpretation applies to Figure 3.
Next, in Figure 6, we illustrate the neural trajectory in two-dimens ional state space
produced by the transient input signal that is shown as an inset. It discloses that the
brain’s synaptic computation follows a continuous approach to the o rigin, the ﬁxed
point in this case, starting from the chosen initial state pw,µ q “ p 5, 5q. In numerically
integrating the synaptic BM to obtain the trajectory, the parame ter values were chosen
from Table 1 except that, for illustrational purposes, the values f or µd and wd were
set to be both 0. Notice that we did not draw the streamlines in the ﬁg ure because
the presynaptic input is time-dependent, so the streamlines vary a t every moment
Bayesian Mechanics of Synaptic Learning under the Free Energy Principle 16
0 2 4 6 8 10
-6
-4
-2
0
2
4
6
Presynaptic input
-6 -4 -2 2 4 6 w
-4
-2
2
4
6
µ
Figure 6. Continuous trajectory in neural state space. The inset shows th e transient
input signal driving synaptic dynamics, sptq “ 5e´ t{5 cos t ` η, where η denotes a
noise. The initial values of the weight w and postsynaptic signal µ were chosen at
pw, µ q “ p 5, 5q, marked by a red dot; the neural trajectory manifests a continu ous
approach to the ﬁxed point p0, 0q [All curves are in arbitrary units].
in the trajectory’s course. In Figure 4, by contrast, the input wa s static so that we
could delineate the streamlines. Notably, our BM theory allowed us to handle the
nonautonomous problem induced by the nonstationary presynapt ic inputs. On the other
hand, the computability of the usual minimization scheme for the pre sent problem is
questionable because the FE landscape is non-static, not allowing a G D implementation,
as described in Section 3.3.
The neural paths we numerically illustrated in the current Section ar e an optimal
trajectory minimizing synaptic surprisal; the actual minimization was performed on the
variational FE objective [see Equation (14)] under the FEP [see Equ ation (6)]. Here, we
emphasize that the learned trajectories were self-organized, giv en the values of material
parameters of the brain matter. In essence, the brain’s learning p rocess is unsupervised
in the language of machine learning; this means that the brain does no t require any
external label to guide its learning, demonstrating its self-learning eﬃciency.
7. Discussion
The idea that the brain is a neural observer (reinforcer or problem -solving matter) is
implicit in the brain-inspired FEP, capable of perceiving, learning, and a cting on the
external and internal milieus; this renders the FEP a purposive the ory. On the other
hand, brain functions must emerge from the brain matter obeying p hysical laws and
principles; the neural substrates aﬀord the biological base for th e brain’s high-order
capability. Thus, it is signiﬁcant to recognize that the working FE obj ective is not a
single measure but an architecture hybridizing the teleological ratio nale and biophysical
realities.
Bayesian Mechanics of Synaptic Learning under the Free Energy Principle 17
In this paper, we continued our endeavor on the continuous-stat e implementation of
the promising FEP as a universal biological principle. Speciﬁcally, we ap plied our theory
to synaptic learning and exempliﬁed the learning dynamics as an infere nce problem
under the FEP. The noteworthy contributions from our eﬀort are discussed below:
(i) Equation (14) is the FE objective in our theory, which suggests t hat the FE
conducts itself as a classical action in Hamilton’s principle, i.e., S “ F. We obtained the
result by deriving the Onsager-Machlup representations for the N EQ generative densities
and inserting them into the Laplace-encoded FE. In our previous st udies [13, 14, 15],
by contrast, the action was identiﬁed as a time-integral of the FE, S “
ş
Fdt, under the
ergodic assumption. The ergodicity asserts that the ensemble ave rage of surprisal over
the sensory evidence equals the corresponding temporal averag e; however, it is diﬃcult
to justify the ergodicity idea in the brain. In the present work, we b ypassed the ergodic
assumption using the more physics-grounded NEQ densities and avo ided employing the
generalized coordinates of motion; this makes the FEP computability we proposed more
physics-grounded than the other conventional approach.
(ii) The weight variables change in time due to biophysical factors suc h as an
opening of channels at the synapse, through which neurotransmit ters transfer in a
complex time-dependent manner. Accordingly, we treated the syn aptic weights w as a
dynamical variable co-evolving with the state variables in completing t he synaptic BM.
In contrast, the weights are handled as a static parameter in the w idely exercised ANNs
in machine learning. Also, in the frameworks of ANNs, a nonlinear activ ation scheme,
e.g., the sigmoidal function or ReLU (rectiﬁed linear unit), rectiﬁes t he network output
value [12]. Our biophysics-informed treatment does not use enginee ring manipulation to
regulate the outcome; instead, the learning smoothly follows the co ntinuous BM. We add
that one may employ diﬀerent biophysical models from our Langevin d ynamics, such
as Izhikevich neurons [34] at the neuronal level or neural ﬁeld mo dels on a mesoscopic
scale [35], and apply our framework to derive a desired BM.
(iii) The momentum representations we unveiled [see Equations (21) a nd (22)]
match with the theoretical construct of prediction error in predic tive coding theory
[11, 36]. Recently, empirical evidence of error neurons was report ed, which encodes
prediction errors in the mouse auditory cortex [37]. Such a ﬁnding pr ovides a neural base
for our theory. However, the diﬀerentiation between the predict ive and error units within
a cortical column is still controversial, mainly because of insuﬃcient e lectrophysiological
recordings. Although there is no concrete agreement, the compa rtmental neuron
hypothesis seems to suit the neuronal scenario of functional dist inguishability [38, 39],
which argues that pyramidal neurons in the cortex are functionally organized such that
feedback and feed-forward signals are sent to outer layers (L1) and middle layers (L5),
respectively. In this case, our state representations correspo nd to feedback channels
via apical dendrites and momentum representations to feed-forw ard channels via basal
dendrites in somas. The Hebbian sign of Equation (20) can be either p ositive or negative;
one can implement spiking predictive coding with the former and the de ndrite predictive
coding with the latter.
Bayesian Mechanics of Synaptic Learning under the Free Energy Principle 18
(iv) Data learning via ANNs has become a formidable scientiﬁc tool [40], and much
attention is drawn to theoretical questions on how and why they wo rk [41]. This paper
suggested that the brain-inspired FEP underlies the widely used L2 objective in machine
learning algorithms. The L2 minimization is implemented using a GD with respect to
the weights connecting layer by layer, rendering back-propagatio n of the input-output
error reduction in a feed-forward architecture. However, stric tly speaking, the validity
of GD updating is limited to situations when the inputs are static or qua si-static. For
continuous nonstationary inputs such as a video stream, a bidirect ional, recurrent NN
(RNN) is employed [42]; RNN sends converted time-series inputs to a p re-structured
deep network and performs a GD by incorporating a feedback loop t o predict the
sequential outputs. Our BM formulation, in contrast, handles non stationary learning in
a genuinely continuous manner, oﬀering a fresh perspective. The b rain integrates the
BM to learn a continuous optimal trajectory in neural phase space by minimizing the FE
objective rather than estimating a sequential output. We hope th at our physics-guided
approach will provide further useful insight into the practice of AN N methodologies in
continuous time.
8. Conclusion
Within the continuous-state FEP framework, we cast synaptic lear ning into minimizing
the FE objective, the upper bound for synaptic surprisal in the br ain, and derived the
BM implementing the FE minimization in a physics-guided manner. Conseq uently, we
revealed that the brain conducts synaptic learning by integrating t he BM to ﬁnd an
optimal trajectory in the reduced-dimensional neural phase spa ce.
References
[1] Crick, F.; Koch, C. A framework for consciousness. Nat. Neurosci. 2003, 6, 119–126.
[2] Clark, A. Whatever next? Predictive brains, situated agents, a nd the future of cognitive science.
Behav. Brain Sci.2013, 36, 181–204.
[3] Buzs´ aki, G. The Brain from Inside Out; Oxford University Press: New York, U.S.A., 2019.
[4] Friston, K. The free-energy principle: a uniﬁed brain theory?. Nat. Rev. Neurosci. 2010, 11,
127–138.
[5] Friston, K.; Da Costa, L.; Sajid, N; Heins, C., Ueltzh¨ oﬀer, K.; Pav liotis, G.A.; Parr, T. The free
energy principle made simpler but not too simple. Physics Reports 2023, 1024, 1–29,
[6] Maturana, H.; Varela, F. Autopoiesis and cognition: The realization of the living ; Reidel:
Dordrecht, Holland, 1980.
[7] Buckley, C.L.; Kim, C.S.; McGregor, S.; Seth, A.K. The free energy p rinciple for action and
perception: A mathematical review. J. Math. Psychol.2017, 81, 55–79.
[8] Da Costa, L., Parr, T.; Sajid, N.; Veselic, S.; Neacsu, V.; Friston, K . Active inference on discrete
state-spaces: a synthesis. J. Math. Psychol.2020, 99, 102447.
[9] Smith, R.; Friston, K.J.; Whyte, C.J. A step-by-step tutorial on a ctive inference and its
application to empirical data, J. Math. Psychol.2022, 107, 102632.
[10] Friston, K.; Mattout, J.; Trujillo-Barreto, N,; Ashburner, J,; P enny, W. Variational free energy
and the Laplace approximation. Neuroimage 2007, 34, 220–234.
Bayesian Mechanics of Synaptic Learning under the Free Energy Principle 19
[11] Rao, R.; Ballard, D. Predictive coding in the visual cortex: a func tional interpretation of some
extra-classical receptive-ﬁeld eﬀects. Nat. Neurosci. 1999, 2, 79–87.
[12] LeCun, Y.; Bengio, Y.; Hinton, Deep learning, G. Nature 2015, 521, 436–444.
[13] Kim, C.S. Recognition dynamics in the brain under the free energy principle. Neural Comput.
2018, 30, 2616–2659.
[14] Kim, C.S. Bayesian mechanics of perceptual inference and moto r control in the brain. Biol Cybern.
2021, 115, 87–102.
[15] Kim, C.S. Free energy and inference in living systems. Interface Focus2023, 13, 20220041.
[16] Hebb, D.O. The organization of Behavior: A Neuropsychological Theory, 1st ed.; Psychology
Press: East Sussex, UK, 2002.
[17] Landau, L.P.; Lifshitz. E.M. Classical Mechanics, 3rd ed.; Elsevier Ltd.: Amsterdam, The
Netherlands, 1976.
[18] Cover, T.M.; Thomas, J.A. Elements of information theory, Wiley-Interscience: New York:
U.S.A., 1991.
[19] Tierney, L.; Kadane, J.B. Accurate approximations for poster ior moments and marginal densities.
J. Am. Stat, Assoc.1986, 81, 82–86.
[20] Chaudhuri, R.; Ger¸ cek, B.; Pandey, B. et al. The intrinsic attra ctor manifold and population
dynamics of a canonical cognitive circuit across waking and sleep. Nat. Neurosci. 2019, 22,
1512–1520.
[21] Friston, K.J.; Stephan, K. E. Free-energy and the brain. Synthese 2007, 159, 417–458.
[22] Friston, K.J.; Trujillo-Barreto, N.; Daunizeau, J. DEM: a variatio nal treatment of dynamic
systems. Neuroimage 2008, 41, 849–885.
[23] Aguilera, M,; Millidge, B.; Tschantz, A.; Buckley, C.L. How particular is the physics of the free
energy principle? Phys. Life Rev. 2021 40, 24–50.
[24] Anil Meera, A.; Wisse, M. Dynamic expectation maximization algorit hm for estimation of linear
Systems with colored noise. Entropy 2021, 23, 1306.
[25] Kubo, R.; Toda, M.; Hashitsume, N. Statistical Physics II. Nonequilibrium Statistical Mechanics,
2nd Edition, Springer-Verlag: Berlin: Germany, 1991.
[26] Adib, A.B. Stochastic actions for diﬀusive dynamics: reweighting , sampling, and minimization.
J. Phys. Chem. B2008, 112, 5910–5916.
[27] Hunt, K.L.C.; Ross, J. Path integral solutions of stochastic equ ations for nonlinear irreversible
processes: The uniqueness of the thermodynamic Lagrangian. J. Chem. Phys.1981, 75, 976–
984.
[28] Buzs´ aki, G.; Draguhn, A. Neuronal Oscillations in Cortical Netw orks. Science 2004, 304,1926–
1929.
[29] Beggs, J.M. The criticality hypothesis: how local cortical netwo rks might optimize information
processing. Phil. Trans. R. Soc. A2008, 366, 329–343.
[30] Miller, K.D.; MacKay, D.J.C. The role of constraints in Hebbian learnin g. Neural Comput.1994,
6, 100–126.
[31] Oja, E. Simpliﬁed neuron model as a principal component analyze r. J. Math. Biol. 1982, 15,
267–273.
[32] Hawkins, J.; Ahmad, S.; Cui, Y. A theory of how columns in the neoc ortex enable learning the
structure of the world. Front. Neural Circuits2017, 11, 81.
[33] Garg. N.; Balafrej, I.; Stewart, T.C.; Portal, J.-M.; Bocquet, M.; Querlioz, D.; Drouin, D.; Rouat,
J.; Beilliard, Y.; Alibart, F. Voltage-dependent synaptic plasticity: Un supervised probabilistic
Hebbian plasticity rule based on neurons membrane potential. Front. Neurosci. 2022, 16,
983950.
[34] Izhikevich, E.M. Dynamical Systems in Neuroscience: The Geometry of Excitability and Bursting,
The MIT Press: Cambridge, U.S.A., 2006.
[35] Deco, G.; Jirsa, V.K.; Robinson, P.A.; Breakspear, M.; Friston, K. The dynamic brain: from
spiking neurons to neural masses and cortical ﬁelds. PLoS Comput. Biol.2008, 4, e1000092.
Bayesian Mechanics of Synaptic Learning under the Free Energy Principle 20
[36] Shipp, S. Neural elements for predictive coding. Frontiers in Psychology2016, 7, 1792.
[37] Audette, N.J.; Schneider, D.M. Stimulusspeciﬁc prediction error neurons in mouse auditory
cortex. Journal of Neuroscience2023, 43, 7119–7129.
[38] Larkum, M.E. A cellular mechanism for cortical associations: An o rganizing principle for the
cerebral cortex. Trends Neurosci.2013, 36, 141–151.
[39] Gillon, C.; Pina, J.; Lecoq, J.; Ahmed, R. et al. Responses to Patte rn-Violating Visual Stimuli
Evolve Diﬀerently Over Days in Somata and Distal Apical Dendrites. J. Neurosci. 2024, 44,
e1009232023.
[40] Schmidhuber, J. Deep learning in neural networks: an overview , Neural Netw.2015, 61, 85–117.
[41] Zdeborov´ a, L. Understanding deep learning is also a job for ph ysicists. Nat. Phys. 2020, 16,
602–604.
[42] Sherstinsky, A. Fundamentals of recurrent neural network (RNN) and long short-term memory
(LSTM) network. Phys. D: Nonlinear Phenom.2020, 404, 132306.