Actively Inferring Optimal Measurement Sequences
Catherine F. Higham Catherine.Higham@glasgow.ac.uk
School of Computing Science
University of Glasgow, Glasgow, G12 8QQ, UK
Paul Henderson Paul.Henderson@glasgow.ac.uk
School of Computing Science
University of Glasgow, Glasgow, G12 8QQ, UK
Roderick Murray-Smith Roderick.Murray-Smith@glasgow.ac.uk
School of Computing Science
University of Glasgow, Glasgow, G12 8QQ, UK
Abstract
Measurement of a physical quantity such as light intensity is an integral part of many re-
construction and decision scenarios but can be costly in terms of acquisition time, invasion
of or damage to the environment and storage. Data minimisation and compliance with data
protection laws is also an important consideration. Where there are a range of measure-
ments that can be made, some may be more informative and compliant with the overall
measurement objective than others. We develop an active sequential inference algorithm
that uses the low dimensional representational latent space from a variational autoencoder
(VAE) to choose which measurement to make next. Our aim is to recover high dimensional
data by making as few measurements as possible. We adapt the VAE encoder to map par-
tial data measurements on to the latent space of the complete data. The algorithm draws
samples from this latent space and uses the VAE decoder to generate data conditional on
the partial measurements. Estimated measurements are made on the generated data and
fed back through the partial VAE encoder to the latent space where they can be evaluated
prior to making a measurement. Starting from no measurements and a normal prior on
the latent space, we consider alternative strategies for choosing the next measurement and
updating the predictive posterior prior for the next step. The algorithm is illustrated us-
ing the Fashion MNIST dataset and a novel convolutional Hadamard pattern measurement
basis. We see that useful patterns are chosen within 10 steps, leading to the convergence
of the guiding generative images. Compared with using stochastic variational inference to
infer the parameters of the posterior distribution for each generated data point individually,
the partial VAE framework can efficiently process batches of generated data and obtains
superior results with minimal measurements.
1 Introduction and overview
In many circumstances, data collection incurs a cost. This cost may be in terms of acquisition time, invasion
of or damage to the environment and storage. Identifying which, out of a range of data measurements,
to collect next is potentially a valuable cost saving activity. Importantly, it also facilitates fast decision
making (Horvitz & Barry, 1995). Data minimisation is an important consideration for compliance with data
protection laws worldwide1. In defense situations, the requirement for covert human intelligence means that
the act of taking measurements can also pose a security risk.2
1https://ico.org.uk/for-organisations/uk-gdpr-guidance-and-resources/
2https://www.gov.uk/government/publications/covert-human-intelligence-sources-code-of-practice-2022/covert-human-
intelligence-sources-revised-code-of-practice-accessible
1
arXiv:2502.18142v1  [cs.LG]  25 Feb 2025
In this work, our overall aim is to identify an optimal measurement sequence. We develop an active sequential
inference algorithm that uses a low dimensional data representation to infer its high dimensional state
conditional on partial measurement of that state. Reducing dimension allows for more efficient exploration
of the space of state possibilities. The state and types of tasks we are primarily interested in are image/scene
reconstruction and related classification tasks using photon based imaging and sensing technology such as a
single pixel camera (Higham et al., 2018). However, the method is applicable to a broader range of activities.
The overall aim is to customise a generative probabilistic model to provide the agent or user with different
reconstruction scenarios conditional on partial measurements. Given a suitably large dataset of task relevant
data, an appropriate generative model is the variational autoencoder (VAE) (Kingma & Welling, 2014). A
VAE learns to encode data in the convenient form of a low dimensional multivariate Gaussian and to decode
this representation back to data space. This provides a means to obtain different reconstructions through
manipulation of a low dimensional latent space. This neural network model is trained on relevant data to
learn the underlying distribution of the training data and used to generate new data. A VAE comprises an
encoder (a map from data space to a low dimensional latent representative space) and a decoder (a map
from the low dimensional space back to data space). To achieve this the VAE introduces latent variables
and the objective of a VAE is to understand the true posterior distribution of the latent variables. A VAE
accomplishes this by employing an encoder network to approximate the genuine posterior distribution with
a learned approximation. Once trained, samples from the prior on the latent space can be pushed through
the decoder in order to obtain new generated data. Similarly, samples from the posterior can be pushed
through the decoder in order to obtain data conditional on the input data. Here we adapt the encoder to map
partially measured data to the latent space. This necessitates creating a training set of partially measured
data. Once trained, the partial encoder and the original decoder are used by the algorithm to sequentially
reason about the full state and choose the next measurement. The probabilistic model we are inferring over
is capturing both the (approximate) data-generating process and the noisy measurement model.
The main idea of variational methods is to cast inference as an optimization problem (Blei et al., 2017).
Stochastic variational inference (SVI) (Hoffman et al., 2013) can be used to infer the posterior probability
distribution for specific data and a given set of measurements but requires multiple computation steps and
thus is prohibitively slow when required to estimate many possible measurement sets. We propose a hybrid
approach, in a similar spirit to Kim et al. (2018) but novel in our context, to combine the strengths of
VAE and SVI. We use the partial encoder to choose between patterns and integrate robust SVI when a
pattern has been selected for inferring the posterior distribution parameters based on actual measurements.
The algorithm is developed to actively select the next best measurement. It starts by pushing samples
from the prior distribution on the latent space through the decoder to obtain candidate images. Possible
measurements on these candidate images are estimated, forming an indexed set. The problem can be thought
of as choosing the next measurement index from a set of possible measurement indexes. The partial encoder
or SVI is used to characterise the posterior distribution and hence provide a score under that distribution for
each possible measurement index for each candidate image. There are different ways to define this score. We
consider two approaches. First, we choose the index with the highest average (over the candidate images)
likelihood score. Second, we choose the index with the least uncertainty score. The aim is to develop a
method that is flexible to the task context and measurement basis. In Section 3 we describe our method for
posterior inference given measurements. The active sequential measurement algorithm is outlined in Section
4. An overview of the algorithm is provided in Figure 1.
2 Related work
There is a large literature on data driven models for solving inverse problems (Arridge et al., 2019). In
particular, generative variational models have been developed for a range of inverse problems in imaging
(Habring & Holler, 2022). These include inpainting, denoising, deblurring, super resolution and JPEG
decompression. Here, we focus on acquiring data rather than how to utilise data once collected. Quantitative
methods for optimizing data acquisition have been explored in statistics and machine learning literature
(Rainforth et al., 2024). Bayesian experimental design is a powerful model-based framework for choosing
designs optimally using information-theoretic principles. This includes Bayesian active learning (MacKay,
1992a), sequential (Foster et al., 2021) and Bayesian optimization (Mockus, 1989; Garnett, 2023). Other
2
Figure 1: Active Learning. At stepk = 0, for each ofN starting points, samplezi from the prior for step
k = 0, push zi through the decoder to obtain a generated imageˆxi and estimate possible measurements
ˆyi for each pattern not yet measured (e.g. ˆy1, ˆy2 and ˆy3 illustrated above). Use the partial encoder
to approximate the posterior with probability distributions and estimate probability densitiesq1(z1|ˆy1),
q2(z1|ˆy2) and q3(z1|ˆy3) (illustrated above). Select the pattern which maximises the chosen expression and
take the measurement associated with this pattern. Update the measurement set and update the predictive
prior for the next step. By repeating these steps, we move towards the target distributionp(z|x).
related topics include active feature acquisition (Saar-Tsechansky et al., 2009), active multi-modal acquisition
(Kossenetal.,2023), activeperception(Bajcsyetal.,2018), Bayesianactivelearning(MacKay,1992b), active
reinforcement learning (Andreopoulos & Tsotsos, 2013) and active vision (Whitehead & Ballard, 1990).
A generative model-based approach to Bayesian inverse problems, such as image reconstruction from noisy
and incomplete images, is developed in Böhm et al. (2019). Their inference framework makes use of a
VAE to provide complex, data-driven priors that comprise all available information about the uncorrupted
data distribution and enables computationally tractable uncertainty quantification in the form of posterior
analysis in latent and data space. Our approach differs in how we extend the VAE to the data. Our focus is
identifying high value data points so we propose a different VAE to provide the prior and facilitate posterior
analysis in latent and data space. Similarly our approach can be adapted to different data systems without
retraining the core VAE. Our extended VAE can be used repeatedly for the sequence of measurements
whereas the method in Böhm et al. (2019) has as its focus corrupted or missing data and is designed to
tackle recovery of data for a given instance rather than exploring uncertainty in a sequential manner.
A partial variational autoencoder (Partial VAE) is introduced in Ma et al. (2019b) to predict problem specific
missing data entries given a subset of of the observed ones. The model is combined with an acquisition
function that maximises expected information gain on a set of target variables. The VAE based framework
is extended to a Bayesian treatment of the weights in Ma et al. (2019a). Our work overlaps in that we
develop a VAE and use it to identify high value data points. However it differs in that we are concerned
with measurements of data taken with respect to a basis. We adapt our encoder to the measurement basis
rather than the problem and hence extend the active learning application to image reconstruction using
3
Figure 2: Graphical representation of the VAE model. An imagex is generated by a random variablez
parameterized by a deep neural network with parametersθ, a). A variational distribution parameterized by
a deep neural network with parametersϕ is introduced to inferz given x, b). The encoder and decoder are
trained together usingN images. To train the partial encoder we simulateN×E measurements y[b] where
b is a subset of patterns, c). The partial encoder parameterized byϕp is trained with the original decoder,
d). The SVI method involves inferring the meanµ and varianceΣ for each image individually, e).
sensing technology. The workshop paper by Saar-Tsechansky et al. (2009) is also relevant to our work and
extends the work (Ma et al., 2019b) by adding transformer components to the partial VAE architecture.
One advantage of our partial encoder, over these works, is that given a full VAE on a domain, the partial
encoder can be trained on different measurement basis.
3 Method for posterior inference given measurements
We describe the underlying VAE, Section 3.1, the extension of this framework to sensor measurements,
Section 3.2, and the SVI method, Section 3.3. We then introduce the partial encoder, Section 3.4, and
training of the partial encoder, Section 3.5.
3.1 Underlying VAE model
We assume that an image,x, is generated by a latent random variable,z, in a complex non-linear manner,
parameterized by a deep neural network decoder,Dθ, with parameters θ. The structure of this model is
represented graphically in column (a) of Figure 2. To do inference in this model we introduce a variational
distribution to approximate the posterior distribution ofz given x. Through training the VAE learns a
function that maps eachx to the parameters of posterior densities. Typically this mapping encodes the mean,
µ, and variance,Σ, of a Gaussian distribution,N(µ,Σ), in latent space. This function is also parameterized
by a deep neural network with parametersϕ(encoder networkEϕ) and the variational distribution,qϕ(z|x),
is represented graphically in column (b) of Figure 2. The goal of training is to find optimal values forθ and
ϕso that the model,pθ(x|z), is a good fit to the data (log evidence is large) and the variational distribution
is a good approximation to the posterior,p(z|x).
Having learntθ and ϕ we can generate images by samplingz from the latent space according to the prior
p(z) and pushingz through the decoder map,Dθ(z) : z →x. We can also generate images,ˆx, conditioned
on testx, in three steps. First by using the encoder map,Eϕ(x) : x →µ,Σ, to characterise the posterior,
qϕ(z|x; µ,Σ). Second, by drawing samples from this distribution. And third, by using the decoder map
as before, Dθ(z|x) : z|x →ˆx. The full VAE is trained by maximising an evidence lower bound (ELBO),
L(θ,ϕ; x), which is equivalent to minimizing the KL divergence betweenp(z|x) and qϕ(z|x) (Kingma &
4
Welling, 2014), given by
p(x) = DKL(qϕ(z|x) ∥p(z|x)) + L(θ,ϕ; x)
p(x) ≥L(θ,ϕ; x) ≡Ez∼qϕ(z|x)[log qϕ(z|x) −log pθ(x|z) −log p(z)]. (1)
3.2 Extension of VAE framework to sensor measurements
We now consider the situation where we wish to determine a newx by taking optimal sequential measure-
ments on x with respect to a measurement basis withN indexes. At sequential step k the measurement
basis indexes chosen so far are denotedBk = {b1,b2,...,b k}. We obtain y[Bk] by taking a measurement
using these basis indices; for convenience we write
y[Bk] = f(x,Bk). (2)
We model these measurements using isotropic Gaussians with varianceσ2.
3.3 SVI method
Here inference is performed for one measurement instancey[Bk]. Marginalising x and applying Bayes’ rule,
we have
p(z|y) = p(z)p(y|z)
p(y) . (3)
The log of the posterior distribution of the latent variables for a given partial observationy[Bk] is therefore
log p(z|y[Bk]) = log p(z) + logp(y[Bk]|z) −log p(y[Bk]). (4)
This equation, as Equation (2), is intractable motivating the use of SVI. The aim of SVI is to approximate
the posterior with a multivariate Gaussian and infer the meanµk and varianceΣk of this distribution. As
the posterior,qk = q(z|y[Bk]; µk,Σk), evolves with the number and index of basis measurements, the mean
and variance are indexed byk. SVI is an iterative method. The variational parameters for each data input
are randomly initialized and then optimized to minimise the KL divergence
Lk ≡Ez∼qk(z|y[Bk])[log qk(z|y[Bk]) −log p(y[Bk]|z) −log p(z)]. (5)
3.4 Partial encoder
The aim of the partial encoder is to encode incomplete measurementsy[Bk] as defined in Equation (2). We
introduce a partial variational distribution,qϕp, to approximate the posterior distribution and train a partial
encoder, Eϕp, to infer µk and Σk for specific y[Bk], see Figure 1d). The partial encoder VAE is trained
by minimizing the KL divergence betweenp(z|x), established by the full VAE, and the partial posterior
distribution, qϕp(z|y[Bk]; µk,Σk), parameterised also by a neural network with parametersϕp.
Lpartial ≡Ez∼qϕp(z|y[Bk])[log qϕp(z|y[Bk]) −log p(x|z) −log p(z)]. (6)
As with the full VAE, once we have learntϕp we can generate images from a set of measurements by sampling
from the approximate posterior distributionqϕp(z|y[b]) and then pushing these samples through the decoder,
Dθ(z|y[Bk]) : z|y[Bk] →ˆx to generate the reconstructed imageˆx.
In summary, we have two approaches to approximate the posteriorp(z|y[Bk]). First using a partial encoder,
qϕp(z|y[Bk]), and second using SVI,qk(z|y[Bk]). We compare these approaches in Section 5.2.
5
3.5 Training the partial encoder
To train the partial encoder we assume that our measurement sensor can provide a series of J = Bk
observations, {y1,y2,...,y J}, each associated with an action (experiment or basis measurement resulting in
an observation) for an imagex, see Equation (2). We now simulate training data by randomly samplingN
experiments for every imagex, simulating observationsy[J] for each of them. This is repeatedE times for
each x giving N ×E experiments in total where the measurement vector,y[J], varies in terms of both the
number of measurements and the measurement index. This is achieved in an efficient manner by introducing
a mask layer into the encoder network that randomly masks a different number and index of measurements
with each training batch. Using this training set we learn a variational autoencoder which generates the
required mapping,Eϕp(y[J],j) :→µJ,ΣJ.
4 Method for active sequential inference
4.1 The algorithm
We now present our sequential algorithm to actively choose the next best measurement. Our proposed
active inference algorithm is illustrated in Figure 1 and pseudocode provided in Algorithm 1. The aim of the
algorithm is to identify, under some criteria (details in Section 4.2), the next best measurement to take. The
algorithm is designed to leverage the encoding and decoding properties of the VAE. The encoder provides a
means to map incomplete measurements onto a low dimensional space for exploration. The decoder provides
a means to project back to image space to assess future measurements.
At the first step,k = 0 , N samples are drawn from the prior on the latent space,p0 = N(0,1). These
samples, zi, are pushed through the decoder,Dθ(zi) : zi →ˆxi, to obtainN generated images,ˆxi. Simulated
measurements, ˆyi = f(ˆxi,j), are made under the chosen measurement basis for each basis element indexed
j. The simulated measurements are pushed through the encoder,Eϕp : ˆyi →: µj,Σj, and the output used to
characterise the conditional posterior,qj
i. The algorithm evaluates each measurement indicator and chooses
the measurement indicator which best satisfies the decision criteria. This indicator is added to the indicator
set, Bk+1. Actual measurements are taken on the test image,y[Bk+1] = f(x,Bk+1). SVI is used to infer the
posterior and predictive prior for the next step,pk+1 = qk+1. The algorithm continues forK−1 steps.
At stepk+ 1, N samples, z = {z1,...z N}, are drawn from the predictive prior,pk = N(µBk
,ΣBk
), where
µBk
and ΣBk
are the mean and variance predicted by the partial encoder conditional on the measurements,
y[Bk], made so far
encϕp(y[Bk]) : y[Bk] →µBk
,ΣBk
. (7)
These samples are then mapped by the decoder to generate images
decθ(z) : z →ˆx = {ˆx1 ... ˆxN}. (8)
For each remaining pattern indicator,j ∈B\Bk, we create a set of pattern indicatorsJ = {b1,...b k,bj}
and simulate measurements made on each generated image,{ˆy[J]
1 ,..., ˆy[J]
N }. We now use the partial encoder
to approximate the posterior distribution conditional on these simulated measurements for each generated
image denotedqJ
i = N(µJ
i ,ΣJ
i ).
4.2 Criteria for choosing next measurement
We consider three criteria for choosing the next pattern to measure. A good choice of measurement is one
that provides useful information to the agent.
6
4.2.1 Likelihood (QP)
Here, the criterion for choosing the next pattern,bk+1, corresponds to choosing the pattern,bj, with the
highest log likelihood with respect toqJ
i over allN images;
bk+1 = arg max
j
N∑
i=1
log(qJ
i (zi)). (9)
By using the likelihood we establish which measurements provide information that is consistent with the
predictive prior for that step. We investigate the ability of the algorithm to move towards the target
distribution.
4.2.2 Mutual Information (MI)
An alternative criterion based on the concept of conditional mutual information (Bishop, 2006) is to choose
the measurement which most reduces the posterior entropy or uncertainty. The mutual information,MI,
between zi and ˆy[J]
i is defined in terms of entropyHe as
MI(zi; ˆy[J]
i ) = He(zi) −He(z|ˆy[J]
i ). (10)
The entropy of random variablex from a multivariate Gaussian of dimensionD and varianceΣ is
He(x) = D
2 (1 + log (2π)) + 1
2 log |Σ|. (11)
Our criteria for choosing the next pattern is then
bk+1 = arg max
j
N∑
i=1
1
2(log |ΣJ
i |−log |ΣBk
|). (12)
High MI between measurement and posterior means that we learn as much as possible about the posterior
from the new measurement given what we already know.
4.2.3 Inference-free Hadamard optimisation (HO)
Some measurement bases, for example the Hadamard transform (Ahmed & Rao, 1975), permit patterns to be
prioritised according to the absolute value of the measurement instead of involving inference. High absolute
values (of the eigenvalues associated with each basis eigenvector) contribute more to the reconstructed image
which motivates the choice
bk+1 = arg max
j
N∑
i=1
|{ˆy[J]
i }|. (13)
5 Experimental Results
We illustrate the algorithm on Fashion MNIST (Xiao et al., 2017). The basic VAE is trained using the
60,000 training images from Fashion MNIST Xiao et al. (2017). The encoder/decoder architectures and
training details are provided in Appendix A. The partial encoder is trained on simulated measurements from
a novel 4×4 convolutional Hadamard measurement basis, details given in Section 5.1. The partial encoder
architecture is adapted and fitted with a random measurement layer so that experiments involving different
numbers and types of patterns can be efficiently simulated, in terms of computation and memory, during
training.
7
Algorithm 1Active Sequential Inference
B0 ←∅ ▷ pattern index set
for k= 0 ...K −1 do ▷ for each step
for i= 1 ...N do ▷ for each generated image
if k= 0 then
p0 = N(0,1) ▷ set prior for step 0
else ifk> 0 then
pk ←qk ▷ set predictive posterior prior for stepk
end if
zi ∼pk ▷ sample latent vector from current pdf
ˆxi ←decθ(zi) ▷ A. input to decoder to obtain generated imageˆxi
for each elementj ∈B\Bk do ▷ for each remaining pattern
J ←{b1,...,b k,j} ▷ add pattern indexj to measurement setJ
ˆyi ←f( ˆxi,J) ▷ B. estimate possible measurements
qj
i ←encϕp(ˆyi) ▷ C. use partial encoder to approximate pdfqj
end for
end for
Mij ←log(qj
i(zi)) −log(pk(zi)) ▷ D. store results in matrixM
{bk+1}←{ arg maxj
∑
iMij} ▷ E. find pattern index which maximises expression
Bk+1 ←Bk ∪{bk+1} ▷ add pattern index to pattern index set
y[Bk+1] ←f(x,Bk+1) ▷ take actual measurement onx
qk+1 ←SVI (y[Bk+1]) ▷ F. set predictive posterior prior for next step
end for
5.1 Convolutional Hadamard basis
In the context of single pixel imaging, the measurements,y, are made by projecting a series of spatial
patterns on to a scene and capturing the reflected light with a single pixel detector sensor Higham et al.
(2018). Mathematically, the measurement is the inner product between the patterns and the scene and
defines functionf from equation (2). Expressing an image in vector form,x, and the pattern basis in matrix
form, H, whereH ∈RD×D, we havey = Hx. Of particular interest is the Hadamard basis, an orthogonal
binary −1,1 basis (Ahmed & Rao, 1975). A Hadamard basis is suitable for experimental realization due to
the binary nature of patterns that can be projected using DMD (Digital Micromirror Device) technology as
spatial light modulator (Edgar et al., 2019). We takeH to be this basis though we emphasise our method
is not specific to the Hadamard basis and the approach could be generalised to another appropriate basis.
For an image with2n ×2n pixels wheren is a positive integer, the complete Hadamard basis, required for
perfect image reconstruction, comprisesN = 22n patterns.
In this work we develop a novel convolutional Hadamard basis inspired by convolutional layers. The convo-
lutional approach provides local spatial and resolution rather than global frequency information.
A Hadamard basis matrix with24 rows and columns is rearranged as a4 ×4 ×16 tensor which replaces the
filter of a standard convolutional mapping layer,fconv. The Hadamard basis has the property of being its
own inverse so the tensor can be used with transpose convolutional mapping layer,ftpconv, to recover the
input image from the feature image,fconv : x →y and ftconv : y →x.
An advantage of this convolutional Hadamard basis is that the resulting featuref ∈RN/4×N/4×16 has both
spatial (vertical and horizontal) and frequency or resolution dimension associated to each elementfj where
j = 1 ...N 2. We exploit this in our illustration to give further insights into the decision making process.
5.2 Comparison of pVAE and SVI
At each step of the algorithm, estimating the parameters of the approximate posterior,qJ, requires one
pass through the partial encoder but several iterations with the SVI method. We compare the performance
8
of pVAE (1 iteration) with SVI and a variable number of iterations{10,20,30,40,50,60,70}in terms of
reconstruction indexes: mean square error (MSE) and similarity structure (SSIM) Wang et al. (2004).
The performance scores are averaged over 100 samples from ten images (each from a different class) and
the algorithm is run for 100 steps, see Figure 3. The SVI method improves as the number of iterations
increases but only matches the pVAE method after 60 iterations. This makes the SVI method an order of
magnitude slower than pVAE. For our final algorithm, we therefore use pVAE to approximateqJ
i based on
simulated measurements (C in Algorithm 1) and SVI with 100 iterations to approximateqk+1 based on actual
measurements (F in Algorithm 1). This way we achieve a balance between performance and computation
time.
Figure 3: Comparison of pVAE and SVI. The performance scores (mseleft columnand ssimright column)
are averaged over 100 samples from ten images (each from a different class) and the algorithm is run for
100 steps. Here lower is better for mseleft and higher is better for ssimright. The performance of pVAE
(1 iteration) bold line with SVI and a variable number of iterations{10,20,30,40,50,60,70}mixed light
lines. The SVI method improves as the number of iterations increases. At 100 steps the results for pVAE
lie between the results for SVI with 60 (SVI60) and 70 (SVI70) iterations. In terms of timings, the pVAE
takes 9 ×10−4 seconds per step and the SVI method takes7.2 ×10−3 seconds per iteration. With many
iterations required for SVI, this makes the SVI method at least an order of magnitude slower than pVAE.
Time measurements were taken using a NVIDIA GeForce RTX 3090 GPU.
5.3 Comparison of choice criteria
The different criteria for choosing the next pattern (QP, MI and HO), equations (9), (12) and (13) respec-
tively, were evaluated using 10 test images, one from each class, andNs = {1,10,100,200}latent vector
samples over 100 steps. Performance measures, SSIM and MSE, were evaluated at each step and averaged
over the test images, see Figure 4 and, in Appendix B, Figure 6.
Our method (QP) outperforms Hadamard optimisation (HO) for the first 25 steps with 1, 10, 100 and
200 starting images in terms of MSE and SSIM. The methodsQP and HO differ in both the criteria for
choosing the next pattern and reconstruction whereas the methodsQP and MI differ only in the criteria for
9
Figure 4: Comparison of choice criteria in terms of the structural similarity index (SSIM). The different
criteria for choosing the next pattern (QP, MI and HO), equations (9), (12) and (13) respectively, were
evaluated (mean SSIM) using 10 test images, one from each class, and 1 (top left), 10 (top right), 100
(bottom left), 200 (bottom right) latent vector samples over 100 steps. Our method (QP) outperforms
Hadamard optimisation (HO) for the first 25 steps and both show superior performance toMI across all
the experiments. In terms of timings,HO took 0.7778 seconds,QP took 1.3583 seconds andMI took 1.4219
seconds to complete 50 steps. Time measurements were taken using a NVIDIA GeForce RTX 3090 GPU.
choosing the next pattern. After these first steps, the performance of both methods plateaus with a slightly
superior performance from the Hadamard reconstruction. Comparing QP with MI, QP shows superior
performance across all the experiments. Investigation of the patterns chosen suggest that usingMI early
in the process leads to the algorithm getting stuck in the latent space. This method relies on choosing the
next pattern to reduce uncertainty across several generated images whereasQP chooses the next pattern
to increase likelihood. TheMI strategy promotes larger initial steps in the latent space and consequently
a tendency to get stuck and miss patterns that are useful for reconstruction. TheQP strategy encourages
smaller steps in the latent space and moves more steadily to a convergence of generated images. TheQP
method is therefore the one that we recommend.
5.4 Visualisation of the active learning algorithm using UMAP
We now illustrate the active learning algorithm by exploring low dimensional image space using a two
dimensional representation of the latent space of 10,000 test images from Fashion MNIST created with
UMAP Meehan et al. (2022). UMAP is applied to the mean of the latent representations. The classes are
colour coded and the UMAP clusters within class and between similar classes (i.e. ankle boot, sneaker and
shoe) indicate that class structure has been retained by the latent representation and further dimension
reduction, see Figure 5.
A number,N, of latent variables are drawn from the prior. These are shown as black crosses projected on
to the two dimensional space along with the projected class colour coded test images. These variables are
then passed to the generator,pθ(xi|zi), to produce the generated images shown on the right. Also shown is
the image reconstruction from actual measurements made so far (top right box), none at step 0, 10 at step
10 and 30 at step 30, and the target image (bottom left box).
10
At steps 1 toK, the generated images from the previous step are used to estimate possible measurements
corresponding to the set of pattern indexes not yet taken. These possible measurements are individually
added to the actual measurements and passed to the encoder to obtain the posterior probability distribution.
The measurement index,j, which is considered most informative satisfies the following expression:
arg max
j
∑
i
log(qij(zi) −log(pk(zi)). (14)
At stepk our certainty, quantified by a probability distribution about our location in latent space, having
taken k−1 measurements, is denoted bypk−1(zi). If we were to take another measurement, our certainty
becomes qkij(zi). In the interest of increasing our certainty we choose the value which maximises the above
expression. This simple procedure allows us to move through latent space converging on a reconstruction
close to the target.
6 Discussion and Conclusion
We have shown that given a large dataset and a measurement basis the encoder of a VAE, trained on this
large dataset, can be adapted to map partial measurements on to a representative latent space. An sequential
measurement algorithm is developed to explore this latent space in order to optimise the next best measure-
ment. The algorithm is illustrated using the Fashion MNIST dataset and a novel convolutional Hadamard
measurement basis. We see that useful patterns are chosen within 10 steps leading to the convergence of the
guiding generative images. In situations where there is a cost attached to measurement, the ability to reduce
the number of measurements is a significant benefit. We believe that this algorithm is the first to address the
task of active sequential inference in this context, and we note that it has the potential to increase efficiency
dramatically in many high profile applications.
Acknowledgments
C.F.H and R.M-S. received funding from EP/T00097X/1, EP/R018634/1, and EP/T021020/1. R.M-S. also
received funding from the Designing Interaction Freedom via Active Inference (DIFAI) ERC Advanced Grant
(proposal 101097708, funded by the UK Horizon guarantee scheme as EPSRC project EP/Y029178/1).
References
Nasir Ahmed and Kamisetty Ramamohan Rao.Walsh-Hadamard Transform, pp. 99–152. Springer Berlin
Heidelberg, Berlin, Heidelberg, 1975. ISBN 978-3-642-45450-9. doi: 10.1007/978-3-642-45450-9_6. URL
https://doi.org/10.1007/978-3-642-45450-9_6 .
Alexander Andreopoulos and John K. Tsotsos. A computational learning theory of active object recognition
under uncertainty.Int. J. Comput. Vision, 101(1):95–142, January 2013. ISSN 0920-5691. doi: 10.1007/
s11263-012-0551-6. URL https://doi.org/10.1007/s11263-012-0551-6 .
Simon Arridge, Peter Maass, Ozan Öktem, and Carola-Bibiane Schönlieb. Solving inverse problems using
data-driven models. Acta Numerica, 28:1–174, 2019. doi: 10.1017/S0962492919000059.
R. Bajcsy, Y. Aloimonos, and J.K. Tsotsos. Revisiting active perception.Autonomous Robots, 42:177–196,
2018.
Christopher M. Bishop. Pattern Recognition and Machine Learning (Information Science and Statistics).
Springer-Verlag, Berlin, Heidelberg, 2006. ISBN 0387310738.
David M. Blei, Alp Kucukelbir, and Jon D. McAuliffe. Variational inference: A review for statisticians.
Journal of the American Statistical Association, 112(518):859–877, April 2017. ISSN 1537-274X. doi:
10.1080/01621459.2017.1285773. URL http://dx.doi.org/10.1080/01621459.2017.1285773.
11
Figure5: UMAPisusedtoreducethemeanofthelatentrepresentationsof10,000testimagesto2dimensions
(left hand column). The classes are colour coded and the UMAP clusters within class and between similar
classes (i.e. ankle boot, sneaker and shoe) indicate that the class structure has been retained by the latent
representation and further dimension reduction. The mean of 100 samples is similarly projected (black
crosses) on to the map at each step of the algorithm. The measurements made, the samples projected back
into image space and the image to be recovered are shown in the top left corner, centre and bottom right
corner of the (right hand column) respectively. We see the diversity of possible images in theright hand
column, and this decreases as uncertainty is reduced by more measurements.12
Vanessa Böhm, François Lanusse, and Uroš Seljak. Uncertainty Quantification with Generative Models. In
33rd Annual Conference on Neural Information Processing Systems, 10 2019.
M.P. Edgar, G.M. Gibson, and M.J. Padgett. Principles and prospects for single-pixel imaging. Nature
Photon, 13:13–20, 2019.
Adam Foster, Desi R Ivanova, Ilyas Malik, and Tom Rainforth. Deep adaptive design: Amortizing sequential
bayesian experimental design. In Marina Meila and Tong Zhang (eds.),Proceedings of the 38th Interna-
tional Conference on Machine Learning, volume 139 ofProceedings of Machine Learning Research, pp.
3384–3395. PMLR, 18–24 Jul 2021. URLhttps://proceedings.mlr.press/v139/foster21a.html.
Roman Garnett. Bayesian Optimization. Cambridge University Press, 2023.
Andreas Habring and Martin Holler. A generative variational model for inverse problems in imaging.SIAM
Journal on Mathematics of Data Science, 4(1):306–335, 2022. doi: 10.1137/21M1414978. URL https:
//doi.org/10.1137/21M1414978.
Irina Higgins, Loic Matthey, Arka Pal, Christopher Burgess, Xavier Glorot, Matthew Botvinick, Shakir Mo-
hamed, and Alexander Lerchner. beta-VAE: Learning basic visual concepts with a constrained variational
framework. InInternational Conference on Learning Representations, 2017.
C.F. Higham, R. Murray-Smith, M.J. M.J. Padgett, and M.P. Edgar. Deep learning for real-time single-pixel
video. Sci Rep, 8:2018, 2018.
Matthew D. Hoffman, David M. Blei, Chong Wang, and John Paisley. Stochastic variational inference.
Journal of Machine Learning Research, 14(40):1303–1347, 2013.
Eric Horvitz and Matthew Barry. Display of information for time-critical decision making. InProceedings
of the Eleventh Conference on Uncertainty in Artificial Intelligence, UAI’95, pp. 296–305, San Francisco,
CA, USA, 1995. Morgan Kaufmann Publishers Inc. ISBN 1558603859.
Yoon Kim, Sam Wiseman, Andrew Miller, David Sontag, and Alexander Rush. Semi-amortized variational
autoencoders. In Jennifer Dy and Andreas Krause (eds.),Proceedings of the 35th International Conference
on Machine Learning, volume 80 ofProceedings of Machine Learning Research, pp. 2678–2687. PMLR,
10–15 Jul 2018.
Diederik Kingma and Jimmy Ba. Adam: A method for stochastic optimization. InInternational Conference
on Learning Representations (ICLR), San Diega, CA, USA, 2015.
Diederik P. Kingma and Max Welling. Auto-encoding variational Bayes. In Yoshua Bengio and Yann LeCun
(eds.), 2nd International Conference on Learning Representations, ICLR 2014, Banff, AB, Canada, April
14-16, 2014, Conference Track Proceedings, 2014.
Jannik Kossen, Cătălina Cangea, Eszter Vértes, Andrew Jaegle, Viorica Patraucean, Ira Ktena, Ne-
nad Tomasev, and Danielle Belgrave. Active acquisition for multimodal temporal data: A challeng-
ing decision-making task. Transactions on Machine Learning Research, 2023. ISSN 2835-8856. URL
https://openreview.net/forum?id=Gbu1bHQhEL.
Chao Ma, Wenbo Gong, Sebastian Tschiatschek, Sebastian Nowozin, José Miguel Hernández-Lobato, and
Cheng Zhang. Bayesian EDDI: Sequential variable selection with Bayesian partial VAE.Workshop on
Real-World Sequential Decision Making: Reinforcement Learning and Beyond at NeurIPS, 2019a.
Chao Ma, Sebastian Tschiatschek, Konstantina Palla, Jose Miguel Hernandez-Lobato, Sebastian Nowozin,
and Cheng Zhang. EDDI: Efficient dynamic discovery of high-value information with partial VAE. In
Kamalika Chaudhuri and Ruslan Salakhutdinov (eds.),Proceedings of the 36th International Conference
on Machine Learning, volume 97 ofProceedings of Machine Learning Research, pp. 4234–4243. PMLR,
09–15 Jun 2019b.
13
David J. C. MacKay. Information-Based Objective Functions for Active Data Selection.Neural Computation,
4(4):590–604, 07 1992a. ISSN 0899-7667. doi: 10.1162/neco.1992.4.4.590. URL https://doi.org/10.
1162/neco.1992.4.4.590.
David J. C. MacKay. Information-based objective functions for active data selection.Neural Computation,
4(4):590–604, 1992b. doi: 10.1162/neco.1992.4.4.590.
Connor Meehan, Jonathan Ebrahimian, Wayne Moore, and Stephen Meehan. Uniform manifold approx-
imation and projection (UMAP). https://www.mathworks.com/matlabcentral/fileexchange/71902,
2022.
Jonas Mockus. Bayesian Approach to Global Optimization. Springer Dordrecht: Kluwer Academic, 1989.
Tom Rainforth, Adam Foster, Desi R. Ivanova, and Freddie Bickford Smith. Modern Bayesian Experimental
Design. Statistical Science, 39(1):100 – 114, 2024. doi: 10.1214/23-STS915. URLhttps://doi.org/10.
1214/23-STS915.
Maytal Saar-Tsechansky, Prem Melville, and Foster Provost. Active feature-value acquisition.Manage. Sci.,
55(4):664–684, April 2009. ISSN 0025-1909. doi: 10.1287/mnsc.1080.0952. URLhttps://doi.org/10.
1287/mnsc.1080.0952.
Zhou Wang, A.C. Bovik, H.R. Sheikh, and E.P. Simoncelli. Image quality assessment: from error visibility
to structural similarity.IEEE Transactions on Image Processing, 13(4):600–612, 2004.
Steven D. Whitehead and Dana H. Ballard. Active perception and reinforcement learning.Neural Compu-
tation, 2(4):409–419, 1990.
Han Xiao, Kashif Rasul, and Roland Vollgraf. Fashion-mnist: a novel image dataset for benchmarking
machine learning algorithms, 2017. URLhttp://arxiv.org/abs/1708.07747.
14
A VAE architecture and training
The encoder comprised an image input layer, two encoding blocks and a fully connected layer. Each encoding
block contained a convolutional layer, a batchnorm layer and a ReLU activation layer. The input image
(28 ×28) was downsized to (14 ×14 ×32) and (7 ×7 ×64) by the encoding blocks respectively. The output
of the fully connected layer,[µ,log Σ], is twice the size of the latent space (32 ×1).
The partial encoder was formed by replacing the first encoding block with a convolutional layer, modified
to use the convolutional Hadamard basis as fixed weights, resulting in a feature (7 ×7 ×64). This block
was followed by a random mask layer that randomly selects a number of patterns and pattern indexes. The
subsequent encoding block was adjusted to downsize to (4 ×4 ×64).
The decoder comprised an latent sample input layer (16×1), a project and reshape layer (7×7×64) and three
decoding blocks. The decoding blocks each contained a transposed convolutional layer and an activation
layer RELU for the first two blocks and sigmoid for the last block). The input feature was up sampled to
(14 ×14 ×64), (28 ×28 ×32) and (28 ×28 ×1) by the decoding blocks respectively.
The encoder and decoder were trained together using a custom training loop and 60,000 fashion MNIST
images Xiao et al. (2017) in mini-batches of 128 for 100 epochs. The parameters were updated using the
adaptive moment estimation (ADAM) algorithm (Kingma & Ba, 2015) with settings: learning rate = 0.001,
gradient decay = 0.9, squared gradient decay = 0.999 and epsilon = 1e-8) chosen using validation set
performance.
The partial encoder was trained using the previously trained decoder with fixed settings for 200 epochs. The
random mask layer was reset for each mini-batch iteration simulating200 ×450 different experiments.
We modify the KL divergence term in the loss functions to include an additional scaling factor,β, in front
of the KL divergence term. ThisβVAE approach was introduced in Higgins et al. (2017) to encourage a
more flexible latent space representation, while still ensuring that the learned distribution is close to the
prior distribution. The value ofβ is set to 0.1 for the VAE and the partial VAE.
B More results
The different criteria for choosing the next pattern (QP, MI and HO), equations (9), (12) and (13) respec-
tively, were evaluated using 10 test images, one from each class, andNs = {1,10,100,200}latent vector
samples over 100 steps. Performance measures, SSIM and MSE, were evaluated at each step and averaged
over the test images, see Figure 4 and, in Appendix B, Figure 6.
C Interpreting results
The patterns belonging to the convolutional Hadamard basis have two spatial and one resolution component.
A log likelihood map for each generated image can be formed by averaging the rowMi,: over the resolution
component
Mi,xy =
∑
r
Mi,xyr. (15)
Figure 7 shows resizedMxy overlaid on the generated imageˆxat step 0. This visualisation highlights regions
of interest. Namely the tops of the sleeves for T-shirt (a), the back and toe of the boot (b) and the waist
and lower legs for the trousers (c).
15
Figure 6: Comparison of choice criteria in terms of mean squared error (MSE). The different criteria for
choosing the next pattern (QP, MI and HO), equations (9), (12) and (13) respectively, were evaluated
(mean MSE) using 10 test images, one from each class, and 1 (top left), 10 (top right), 100 (bottom left),
200 (bottom right) latent vector samples over 100 steps. (QP) outperforms Hadamard optimisation (HO)
for the first 25 steps.
(a)
 (b)
 (c)
Figure 7: After step 0, we overlay Mi over ˆxi to indicate regions of high information (white) and low
information (black) within the active learning frame at this step. For the long sleeved top, regions of interest
are the tops of the sleeves (a). The back and toe of the boot are regions of interest (b). The waist and lower
legs are regions of interest for the trousers (c). Using expression in equation 14 the next measurement taken
is determined by averaging the information overN images.
16