bioRxiv preprint doi: https://doi.org/10.1101/2020.12.10.420547; this version posted December 11, 2020. The copyright holder for this
preprint (which was not certified by peer review) is the author/funder. All rights reserved. No reuse allowed without permission.
1 Canonical neural networks perform active inference
2
3 Takuya Isomura1*, Hideaki Shimazaki2, Karl Friston3
4 1 Brain Intelligence Theory Unit, RIKEN Center for Brain Science, Wako, Saitama, 351-0198, Japan
5 2 Center for Human Nature, Artificial Intelligence, and Neuroscience (CHAIN), Hokkaido University,
6 Sapporo, Hokkaido, 060-0812, Japan
7 3 Wellcome Centre for Human Neuroimaging, Institute of Neurology, University College London, 12
8 Queen Square, London, WC1N 3AR, UK
9 * Corresponding author email: takuya.isomura@riken.jp
10
11
1
bioRxiv preprint doi: https://doi.org/10.1101/2020.12.10.420547; this version posted December 11, 2020. The copyright holder for this
preprint (which was not certified by peer review) is the author/funder. All rights reserved. No reuse allowed without permission.
12 Abstract
13 This work considers a class of canonical neural networks comprising rate coding models, wherein
14 neural activity and plasticity minimise a common cost functionâ€”and plasticity is modulated with a
15 certain delay. We show that such neural networks implicitly perform active inference and learning
16 to minimise the risk associated with future outcomes. Mathematical analyses demonstrate that
17 this biological optimisation can be cast as maximisation of model evidence, or equivalently
18 minimisation of variational free energy, under the well-known form of a partially observed Markov
19 decision process model. This equivalence indicates that the delayed modulation of Hebbian
20 plasticityâ€”accompanied with adaptation of firing thresholdsâ€”is a sufficient neuronal substrate to
21 attain Bayes optimal control. We corroborated this proposition using numerical analyses of maze
22 tasks. This theory offers a universal characterisation of canonical neural networks in terms of
23 Bayesian belief updating and provides insight into the neuronal mechanisms underlying planning
24 and adaptive behavioural control.
25
26 INTRODUCTION
27 The sentient behaviour of biological organisms is characterised by optimisation. Biological
28 organisms recognise the state of their environment by optimising internal representations of the
29 external (i.e., environmental) dynamics generating sensory inputs. In addition, they optimise their
30 behaviour for adaptation to the environment, thereby increasing their probability of survival and
31 reproduction. This biological self-organisation is typically formulated as the minimisation of cost
32 functions [1â€“3], wherein a gradient descent on a cost function furnishes neural dynamics and
2
bioRxiv preprint doi: https://doi.org/10.1101/2020.12.10.420547; this version posted December 11, 2020. The copyright holder for this
preprint (which was not certified by peer review) is the author/funder. All rights reserved. No reuse allowed without permission.
33 synaptic plasticity. However, two fundamental issues remain to be establishedâ€”namely, the
34 characterisation of the dynamics of an arbitrary neural network as a generic optimisation
35 processâ€”and the correspondence between such neural dynamics and statistical inference [4]
36 found in applied mathematics and machine learning. The present work addresses these issues by
37 demonstrating that a class of canonical neural networks of rate coding models is functioning asâ€”
38 and thus universally characterised in terms ofâ€”variational Bayesian inference, under a particular
39 but generic form of generative model.
40 Variational Bayesian inference offers a unified explanation for inference, learning, prediction,
41 decision making, and the evolution of biological form [5,6]. This kind of inference rests upon a
42 generative model that expresses a hypothesis about the generation of sensory inputs. Perception
43 and behaviour can then be read as optimising the evidence for a â€˜generative modelâ€™, inherent in
44 sensory exchanges with the environment. The ensuing evidence lower bound (ELBO) [7], or
45 equivalently variational free energy, then plays the role of a cost function. Variational free energy is
46 the standard cost function in variational Bayesâ€”and provides an upper bound on surprise (i.e.,
47 improbability) of sensory inputs. Minimisation of variational free energy, with respect to internal
48 representations, then yields approximate posterior beliefs about external states. Similarly, the
49 minimisation of variational free energy with respect to action on external states maximises the
50 evidence or marginal likelihood of resulting sensory samples. This framework integrates perceptual
51 (unsupervised), reward-based (reinforcement), and motor (supervised) learning in a unified
52 formulation. In short, internal states of an autonomous system under a (possibly nonequilibrium)
53 steady state can be viewed as parameterising posterior beliefs of external states [8â€“10]. In
3
bioRxiv preprint doi: https://doi.org/10.1101/2020.12.10.420547; this version posted December 11, 2020. The copyright holder for this
preprint (which was not certified by peer review) is the author/funder. All rights reserved. No reuse allowed without permission.
54 particular, active inference aims to optimise behaviours of a biological organism to minimise a
55 certain kind of risk in the future [11â€“13], wherein risk is typically expressed in a form of expected
56 free energy (i.e., the variational free energy expected under posterior predictive beliefs about the
57 outcomes of a given course of action).
58 Crucially, as a corollary of the complete class theorem [14â€“16], any neural network minimising a
59 cost function can be viewed as performing variational Bayesian inference, under some prior
60 beliefs. We have previously introduced a reverse engineering approach that identifies a class of
61 biologically plausible cost functions for neural networks [17]. We identified a class of cost functions
62 for single-layer feedforward neural networks of rate coding models with a sigmoid (or logistic)
63 activation functionâ€”based on the assumption that the dynamics of neurons and synapses follow a
64 gradient descent on the same cost function. We subsequently demonstrated the mathematical
65 equivalence between the class of cost functions for such neural networks and variational free
66 energy under a particular form of generative model. This equivalence licenses variational Bayesian
67 inference, and the ensuing free-energy principle, as the fundamental optimisation process
68 underlying both dynamics and functions of such neural networks. Moreover, it enables one to
69 characterise any variables and constants in the network in terms of quantities that play a role in
70 variational Bayesian inference. However, it remains to be established whether active inference is
71 an apt explanation for any given neural network interacting with the surrounding environment.
72 In most formulations, active inference goes further than simply assuming action and perception
73 minimise variational free energyâ€”it also considers the consequences of action as minimising
74 expected free energy, i.e., planning as inference [18â€“22]. In what follows, we analytically and
4
bioRxiv preprint doi: https://doi.org/10.1101/2020.12.10.420547; this version posted December 11, 2020. The copyright holder for this
preprint (which was not certified by peer review) is the author/funder. All rights reserved. No reuse allowed without permission.
75 numerically demonstrate the implicit ability of neural networks to plan and minimise future risk,
76 when viewed through the lens of active inference.
77 In the present work, we identify a class of biologically plausible cost functions for two-layer
78 recurrent neural networks, under an assumption that neural activity and plasticity minimise a
79 common cost function (referred to as assumption 1). Namely, we suppose a network of rate coding
80 neurons with a sigmoid activation function, wherein the middle layer involves recurrent
81 connections and the output layer provides feedback responses to the environment (assumption 2).
82 In this work, such neural networks are referred to as canonical neural networks. Then, we
83 demonstrate that the class of cost functionsâ€”describing their dynamicsâ€”can be cast as variational
84 free energy under an implicit generative model, in the well-known form of a partially observable
85 Markov decision process (POMDP). The gradient descent on the ensuing cost function naturally
86 yields Hebbian plasticity [23â€“25] with an activity-dependent homeostatic term.
87 In particular, we consider the case where an arbitrary modulator [26â€“28] regulates synaptic
88 plasticity with a certain delay (assumption 3) and demonstrate that such a modulation is identical
89 to the update of a policy through a post-hoc evaluation of past decisions. The modulator renders
90 the implicit cost function a risk function, which in turn renders behavioural control Bayes
91 optimalâ€”to minimise future risk. The proposed analysis affirms that active inference is an inherent
92 property of canonical neural networks exhibiting delayed modulation of Hebbian plasticity. We
93 discuss possible neuronal substrates that realise this modulation.
94
95 RESULTS
5
bioRxiv preprint doi: https://doi.org/10.1101/2020.12.10.420547; this version posted December 11, 2020. The copyright holder for this
preprint (which was not certified by peer review) is the author/funder. All rights reserved. No reuse allowed without permission.
96 Overview of equivalence between neural networks and variational Bayes
97 First, we summarise the formal correspondence between neural networks and variational Bayes.
98 A biological agent is formulated here as an autonomous system comprising a network of rate
99 coding neurons. We presume that neural activity, action (decision), synaptic plasticity, and changes
100 in any other free parameters minimise a common cost function ğ¿ â‰” ğ¿(ğ‘œ ,ğœ‘) (c.f. assumption 1;
%:â€™
101 Fig. 1a). Here, ğ‘œ â‰” {ğ‘œ ,â€¦,ğ‘œ } is a sequence of observations and ğœ‘ â‰” {ğ‘¥ ,ğ‘¦ ,ğ‘Š,ğœ™} is a set
%:â€™ % â€™ %:â€™ %:â€™
102 of internal states comprising the middle-layer (ğ‘¥ ) and output-layer (ğ‘¦ ) neural activity, synaptic
2 2
103 strengths (ğ‘Š), and other free parameters (ğœ™) that characterise ğ¿ (e.g., firing threshold). Output-
104 layer activity ğ‘¦ determines the networkâ€™s actions or decisions ğ›¿ . Based on assumption 1, the
â€™ â€™
105 update rule for the i-th component of ğœ‘ is derived as the gradient descent on the cost function,
106 ğœ‘Ì‡ âˆ âˆ’ğœ•ğ¿/ğœ•ğœ‘ . This determines the dynamics of neural networks, including their activity and
5 5
107 plasticity.
108
109
110 Figure 1. Schematic of an external milieu and neural network, and the corresponding Bayesian
111 formation. (a) Interaction between the external milieu and autonomous system comprising a two-
6
bioRxiv preprint doi: https://doi.org/10.1101/2020.12.10.420547; this version posted December 11, 2020. The copyright holder for this
preprint (which was not certified by peer review) is the author/funder. All rights reserved. No reuse allowed without permission.
112 layer neural network. On receiving sensory inputs or observations ğ‘œ(ğ‘¡) that are generated from
113 hidden states ğ‘ (ğ‘¡), the network activity ğ‘¥(ğ‘¡) generates outputs ğ‘¦(ğ‘¡). The gradient descent on a
114 neural network cost function L determines the dynamics of neural activity and plasticity. Thus, L is
115 sufficient to characterise the neural network. The proposed theory affirms that the ensuing neural
116 dynamics are self-organised to encode the posterior beliefs about hidden states and decisions. (b)
117 Corresponding variational Bayesian formation. The interaction depicted in (a) is formulated in
118 terms of a POMDP model, which is parameterised by ğ´,ğµ,ğ¶ âˆˆ ğœƒ and ğ·,ğ¸ âˆˆ ğœ†. Variational free
119 energy minimisation allows an agent to self-organise to encode the hidden states of the external
120 milieuâ€”and to make decisions minimising future risk. Here, variational free energy F is sufficient to
121 characterise the inferences and behaviours of the agent.
122
123 In contrast, variational Bayesian inference depicts a process of updating the prior distribution of
124 external states ğ‘ƒ(ğœ—) to the corresponding posterior distribution ğ‘„(ğœ—) based on a sequence of
125 observations. Here, ğ‘„(ğœ—) approximates ğ‘ƒ(ğœ—|ğ‘œ ). This process is formulated as a minimisation
%:â€™
126 of the surprise of past-to-present observationsâ€”or equivalently maximisation of the model
127 evidenceâ€”which is attained by minimising variational free energy as a tractable proxy. We
128 suppose that the generative model ğ‘ƒ(ğ‘œ ,ğœ—) is characterised by a set of external states, ğœ— â‰”
%:â€™
129 {ğ‘  ,ğ›¿ ,ğœƒ,ğœ†}, comprising hidden states (ğ‘  ), decision (ğ›¿ ), model parameters (ğœƒ), and hyper
%:â€™ %:â€™ 2 2
130 parameters (ğœ†) (Fig. 1b). Based on the given generative model, variational free energy is defined as
131 a functional of ğ‘„(ğœ—) as follows: ğ¹Jğ‘œ ,ğ‘„(ğœ—)K â‰” E [âˆ’lnğ‘ƒ(ğ‘œ ,ğœ—)+lnğ‘„(ğœ—)]. Here,
%:â€™ M(N) %:â€™
132 E [âˆ™] â‰” âˆ«âˆ™ğ‘„(ğœ—)ğ‘‘ğœ— denotes the expectation over ğ‘„(ğœ—). In particular, we assume that ğ‘„(ğœ—) is
M(N)
7
bioRxiv preprint doi: https://doi.org/10.1101/2020.12.10.420547; this version posted December 11, 2020. The copyright holder for this
preprint (which was not certified by peer review) is the author/funder. All rights reserved. No reuse allowed without permission.
133 an exponential family and the posterior expectation of ğœ—, ğ› â‰” E [ğœ—], or its counterpart, are
M(N)
134 the sufficient statistics that parameterise (i.e., uniquely determine) ğ‘„(ğœ—). Under this condition, ğ¹
135 is reduced to a function of ğ›, ğ¹ = ğ¹(ğ‘œ ,ğ›). The variational update rule for the i-th component
%:â€™
136 of ğ› is given as the gradient descent on variational free energy, ğ›Ì‡ âˆ âˆ’ğœ•ğ¹/ğœ•ğ› .
5 5
137 Crucially, according to the complete class theorem, the dynamical system that minimises its cost
138 function can be viewed as performing Bayesian inference under some generative model and prior
139 beliefs. The complete class theorem [14â€“16] states that for any pair of admissible decision rules
140 and cost functions, there is some generative model with prior beliefs that renders the decisions
141 Bayes optimal. Thus, this theorem ensures the presence of a generative model that formally
142 corresponds to the above-defined neural network characterised by ğ¿. Hence, this speaks to the
143 equivalence between the class of neural network cost functions and variational free energy under
144 such a generative model:
145 ğ¿(ğ‘œ ,ğœ‘) â‰¡ ğ¹(ğ‘œ ,ğ›), (1)
%:â€™ %:â€™
146 wherein the internal states of a network ğœ‘ encode or parameterise the posterior expectation ğ›.
147 This mathematical equivalence means that an arbitrary neural network, in the class under
148 consideration, is implicitly performing active inference through variational free energy
149 minimisation. Minimisation of ğ¹ is achieved when and only when the posterior beliefs best match
150 the true conditional probability of the external states. Thus, the dynamics that minimise ğ¿ must
151 induce a recapitulation of the external states in the internal states of the neural network. This is a
152 fundamental aspect of optimisation in neural networks. This notion is essential to understand the
153 functional meaning of the dynamics evinced by an arbitrary neural network, which is otherwise
8
bioRxiv preprint doi: https://doi.org/10.1101/2020.12.10.420547; this version posted December 11, 2020. The copyright holder for this
preprint (which was not certified by peer review) is the author/funder. All rights reserved. No reuse allowed without permission.
154 unclear by simply observing the network dynamics.
155 Note that being able to characterise the neural network in terms of maximising model evidence
156 lends it an â€˜explainabilityâ€™, in the sense that the internal (neural network) states and parameters
157 encode Bayesian beliefs or expectations about the causes of observations. In other words, the
158 generative model explains how outcomes were generated. However, the complete class theorem
159 does not specify the form of generative model for any given neural network. To address this issue,
160 we formulate active inference using a particular form of POMDP models, whose states take binary
161 values. This facilitates identification of a class of generative models that corresponds to a class of
162 canonical neural networksâ€”comprising rate coding models with the sigmoid activation function.
163
164 Active inference formulated using a postdiction of past decisions
165 In this section, we define generative model and ensuing variational free energy that correspond
166 to a class of canonical neural networks that will be considered in the subsequent section. The
167 external milieu is expressed as a discrete state space in the form of a POMDP (Fig. 2). The
_
168 generation of observations ğ‘œ â‰” [ğ‘œ
(%)
,â€¦,ğ‘œ
(\] )
^ from external or hidden states milieu ğ‘  â‰”
â€™ â€™ â€™ â€™
_
169 [ğ‘  (%) ,â€¦,ğ‘  (\â€˜ ) ^ is expressed in the form of a categorical distribution, ğ‘ƒ(ğ‘œ |ğ‘  ,ğ´) = Cat(ğ´),
â€™ â€™ â€™ â€™
170 where ğ´ is referred to as the likelihood mapping. Our agent receives ğ‘œ , infers latent variables
â€™
_
171 (hidden states) ğ‘  , and provides a feedback decision ğ›¿ â‰” [ğ›¿ (%) ,â€¦,ğ›¿ (\ d ) ^ to the external
â€™ â€™ â€™ â€™
172 milieu. Thus, the state transition at time t depends on ğ›¿ , characterised by the state transition
â€™e%
173 matrix ğµf, ğ‘ƒ(ğ‘  |ğ‘  ,ğ›¿ ,ğµ) = CatJğµfK. Each element of ğ‘  , ğ‘œ , and ğ›¿ adopts a binary
â€™ â€™e% â€™e% â€™ â€™ â€™
174 value, which is suitable for characterising generative models implicit in canonical neural networks
9
bioRxiv preprint doi: https://doi.org/10.1101/2020.12.10.420547; this version posted December 11, 2020. The copyright holder for this
preprint (which was not certified by peer review) is the author/funder. All rights reserved. No reuse allowed without permission.
175 (see below). When dealing with external states that factorize (e.g., what and where), block
176 matrices ğ´ and ğµ (and ğ¶) are the outer products of sub matrices (please refer to Methods A for
177 further details); see also [17]. Hence, we define the generative model as follows:
â€™
178 ğ‘ƒ(ğ‘œ ,ğ›¿ ,ğ‘  ,ğ›¾ ,ğœƒ) = ğ‘ƒ(ğœƒ)ğ‘ƒ(ğ›¾ )hğ‘ƒ(ğ‘œ |ğ‘  ,ğ´)ğ‘ƒ(ğ‘  |ğ‘  ,ğ›¿ ,ğµ)ğ‘ƒ(ğ›¿ |ğ‘  ,ğ›¾ ,ğ¶), (2)
%:â€™ %:â€™ %:â€™ â€™ â€™ 2 2 2 2e% 2e% 2 2e% â€™
2i%
179 where 1 â‰¤ ğœ â‰¤ ğ‘¡ denotes an arbitrary time in the past, ğœƒ â‰” {ğ´,ğµ,ğ¶} constitute the set of
180 parameters, and ğ›¾ is the current risk (see below). Note that initial states and decisions are
â€™
181 characterised by prior distributions ğ‘ƒ(ğ‘  ) = Cat(ğ·) and ğ‘ƒ(ğ›¿ ) = Cat(ğ¸), where ğ· and ğ¸ are
% %
182 block vectors.
183
184
185 Figure 2. Factor graph depicting a fictive causality of factors that the generative model
186 hypothesises. The POMDP model is expressed as a Forney factor graph [48,49] based upon the
187 formulation in [50]. The arrow from the present risk ğ›¾ â€”sampled from Î“ â€”to a past decision ğ›¿
â€™ â€™ 2
10
bioRxiv preprint doi: https://doi.org/10.1101/2020.12.10.420547; this version posted December 11, 2020. The copyright holder for this
preprint (which was not certified by peer review) is the author/funder. All rights reserved. No reuse allowed without permission.
188 optimises the policy in a post-hoc manner, to minimise future risk. In reality, the current error ğ›¾
â€™
189 is determined based on past decisions (top). In contrast, decision making to minimise the future
190 risk implies a fictive causality from ğ›¾ to ğ›¿ (bottom). Inference and learning correspond to the
â€™ 2
191 inversion of this generative model. Postdiction of past decisions is formulated as the learning of
192 the policy mapping, conditioned by ğ›¾ . Here, ğ´, ğµ, and ğ¶ indicate matrices of the conditional
â€™
193 probability, and bold case variables are the corresponding posterior beliefs. Moreover, ğ·âˆ— and ğ¸âˆ—
194 indicate the true prior beliefs about hidden states and decisions, while ğ· and ğ¸ indicate the
195 priors that the network operates under. When and only when ğ· = ğ·âˆ— and ğ¸ = ğ¸âˆ—, inferences
196 and behaviours are optimal for a given task or set of environmental contingencies, and biased
197 otherwise.
198
199 The agent makes decisions to minimise a risk function Î“ â‰” Î“(ğ‘œ ,ğ¬ ,ğ›… ,ğ›‰) that it
â€™ %:â€™ %:â€™ %:â€™e%
200 employs (where 0 â‰¤ Î“ â‰¤ 1). Because the current risk Î“ is a consequence of past decisions, the
â€™ â€™
201 agent needs to select decisions that minimise the future risk. In this sense, Î“ corresponds to the
â€™
202 expected free energy in the usual formulation of active inference [12,13].
203 In our POMDP model, we formulate the operation to optimise decisions using a fictive causality
204 from the current risk Î“ to past decisions ğ›¿ ,â€¦,ğ›¿ (Fig. 2). Although this is not the true
â€™ % â€™e%
205 causality in the real generative process that generates sensory data, we intend to model the
206 manner that an agent subjectively evaluates its previous decisions after experiencing their
207 consequences. This fictive causality is expressed in the form of a categorical distribution,
208 ğ‘ƒ(ğ›¿ |ğ‘  ,ğ›¾ ,ğ¶) = Cat(ğ¶)stCatJğ¶u âŠ™ğ¶âŠ™e%K
st,
(3)
2 2e% â€™
11
bioRxiv preprint doi: https://doi.org/10.1101/2020.12.10.420547; this version posted December 11, 2020. The copyright holder for this
preprint (which was not certified by peer review) is the author/funder. All rights reserved. No reuse allowed without permission.
209 wherein policy mapping ğ¶ is switched by a binarized risk ğ›¾ âˆˆ {0,1}â€”sampled from ğ‘ƒ(ğ›¾ ) =
â€™ â€™
_
210 Cat[JÎ“,Î“ K ^â€”in a form of mixture model*. Note that ğ¶u denotes a normalisation factor that is
â€™ â€™
211 negligible in the following formulations, âŠ™ indicates the element-wise product operator, and
212 ğ¶âŠ™e% means the element-wise inverse of matrix ğ¶. Throughout the manuscript, the overline
213 variable indicates one minus the variable (e.g., ğ›¾ = 1âˆ’ğ›¾ ). This model presumes that a past
â€™ â€™
214 decision ğ›¿ (1 â‰¤ ğœ â‰¤ ğ‘¡âˆ’1) is determined based on a past state ğ‘  and the current risk ğ›¾ . In
2 2e% â€™
215 contrast, the current decision ğ›¿ is determined to minimise the future risk, ğ‘ƒ(ğ›¿ |ğ‘  ,ğ¶) =
â€™ â€™ â€™e%
216 Cat(ğ¶), because the agent has not yet observed the consequences of the current decision.
217 Importantly, the agent needs to keep selecting â€˜goodâ€™ decisions while avoiding â€˜badâ€™ decisions.
218 To this end, we suppose that the agent learns from the failure of decisions, by assuming that the
219 bad decisions were sampled from the opposite of the optimal policy mapping. In other words, the
220 agent is assumed to have the prior belief such that the decisionâ€”sampled from Cat(ğ¶)â€”should
221 result in ğ›¾ = 0, while sampling from CatJğ¶u âŠ™ğ¶âŠ™e%K should yield ğ›¾ = 1. This construction
â€™ â€™
222 enables the agent to conduct a postdiction of its past decisionsâ€”and thereby to update the policy
223 mapping to minimise future riskâ€”by associating the past decision rule (policy) with the current
224 risk. In the next section, we will explain the biological plausibility of this form of adaptive
225 behavioural control, wherein the update of the policy mapping turns out to be identical to a
* Although, by convention, active inference uses C to denote the prior preference, this work uses C
to denote a mapping to determine a decision depending on the previous state. Herein, the prior
preference is implicit in the risk function Î“ . Due to construction, ğ¶u does not explicitly appear in
â€™
the inference; thus, it is omitted in the following formulations.
12
bioRxiv preprint doi: https://doi.org/10.1101/2020.12.10.420547; this version posted December 11, 2020. The copyright holder for this
preprint (which was not certified by peer review) is the author/funder. All rights reserved. No reuse allowed without permission.
226 delayed modulation of Hebbian plasticity.
227 Variational Bayesian inference refers to the process that optimises the posterior belief ğ‘„(ğœ—).
228 Based on the mean-field approximation, ğ‘„(ğœ—) is expressed as
â€™
229 ğ‘„(ğœ—) = ğ‘„(ğ´)ğ‘„(ğµ)ğ‘„(ğ¶)hğ‘„(ğ‘  )ğ‘„(ğ›¿ ). (4)
2 2
2i%
230 Here, the posterior beliefs about states and decisions are categorical probability distributions,
231 ğ‘„(ğ‘  ) = Cat(ğ¬ ) and ğ‘„(ğ›¿ )= Cat(ğ›… ), whereas those about parameters are Dirichlet
2 2 2 2
232 distributions, ğ‘„(ğ´) = Dir(ğš), ğ‘„(ğµ) = Dir(ğ›), and ğ‘„(ğ¶) = Dir(ğœ). Throughout the manuscript,
233 bold case variables (e.g., ğ¬ ) denote the posterior expectations of the corresponding italic case
2
234 random variables (e.g., ğ‘  ). The agent samples a decision ğ›¿ at time t from the posterior
2 â€™
235 distribution ğ‘„(ğ›¿ ). In this paper, the posterior belief of transition mapping is averaged over all
â€™
236 possible decisions, ğ = E (cid:129)ğf(cid:130), to ensure the exact correspondence to canonical neural
M(f)
237 networks (see below). We use ğ›‰ â‰” {ğš,ğ›,ğœ} to denote the parameter posteriors. For simplicity,
238 here we suppose that state and decision priors (ğ·,ğ¸) are fixed.
239 Under the above-defined generative model and posterior beliefs, the ensuing variational free
240 energy is analytically expressed as follows:
â€™
241 ğ¹(ğ‘œ ,ğ¬ ,ğ›… ,ğ›‰) = (cid:131)ğ¬ â‹…(lnğ¬ âˆ’lnğ€â‹…ğ‘œ âˆ’lnğğ¬ )
%:â€™ %:â€™ %:â€™ 2 2 2 2e%
2i%
â€™
242 +(cid:131)ğ›… â‹…Jlnğ›… âˆ’J1âˆ’2Î“ Klnğ‚ğ¬ K+ğ’ª(lnğ‘¡). (5)
2 2 â€™,2 2e%
2i%
243 The derivation details are provided in Methods B. Note that Î“ = 0 for ğœ = ğ‘¡; otherwise, Î“ =
â€™,2 â€™,2
13
bioRxiv preprint doi: https://doi.org/10.1101/2020.12.10.420547; this version posted December 11, 2020. The copyright holder for this
preprint (which was not certified by peer review) is the author/funder. All rights reserved. No reuse allowed without permission.
244 Î“ . The order lnğ‘¡ term indicates the complexity of parameters, which is negligible when the
â€™
245 leading order term is large. The gradient descent on variational free energy updates the posterior
246 beliefs about hidden states (ğ¬ ), decisions (ğ›… ), and parameters (ğ›‰). The optimal posterior beliefs
â€™ â€™
247 that minimise variational free energy are obtained as the fixed point of the implicit gradient
248 descent, which ensures that ğœ•ğ¹/ğœ•ğ¬ = 0, ğœ•ğ¹/ğœ•ğ›… = 0, and ğœ•ğ¹/ğœ•ğ›‰ = ğ‘‚. The explicit forms of
â€™ â€™
249 the posterior beliefs are provided in Methods C.
250 To explicitly demonstrate the formal correspondence with the cost functions for neural networks
251 considered below, we further transform the variational free energy: based on Bayes theorem
252 ğ‘ƒJğ‘  |ğ‘  ,ğµfK âˆ ğ‘ƒJğ‘  |ğ‘  ,ğµfKğ‘ƒ(ğ‘  ), the inverse transition mapping is expressed as ğ(cid:138) =
2 2e% 2e% 2 2
253 ğ_diag[ğ·]e% using the state prior ğ‘ƒ(ğ‘  ) = Cat(ğ·) (where ğ‘ƒ(ğ‘  ) is supposed to be a flat
2 2e%
254 prior belief). Moreover, from ğ‘ƒ(ğ›¿ |ğ‘  ,ğ›¾ ,ğ¶) âˆ ğ‘ƒ(ğ‘  |ğ›¿ ,ğ›¾ ,ğ¶)ğ‘ƒ(ğ›¿ ), the inverse policy
2 2e% â€™ 2e% 2 â€™ 2
255 mapping is expressed as ğ‚(cid:138) = ğ‚_diag[ğ¸]e% using the decision prior ğ‘ƒ(ğ›¿ ) = Cat(ğ¸). Using
â€™
256 these relationships, equation (5) is transformed into the form shown in Fig. 3 (top). Please see
257 Methods B for further details. This specific form of variational free energy constitutes a class of
258 cost functions for canonical neural networks, as we will see below.
259 In summary, variational free energy minimisation underwrites optimisation of posterior beliefs.
260 In neurobiological formulations, it is usually assumed that neurons encode ğ¬ and ğ›… , while
â€™ â€™
261 synaptic strengths encode ğ›‰ [12,13]. In what follows, we demonstrate that the internal states of
262 canonical neural networks encode posterior beliefs.
263
14
bioRxiv preprint doi: https://doi.org/10.1101/2020.12.10.420547; this version posted December 11, 2020. The copyright holder for this
preprint (which was not certified by peer review) is the author/funder. All rights reserved. No reuse allowed without permission.
264
265 Figure 3. Mathematical equivalence between variational free energy and neural network cost
266 functions, depicted by one-by-one correspondence of their components. Top: variational free
267 energy transformed from equation (5) using the Bayes theorem. Here, ğ(cid:138) = ğ_diag[ğ·]e% and
268 ğ‚(cid:138) = ğ‚_diag[ğ¸]e% indicate the inverse mappings, and ğ· and ğ¸ are the state and decision
269 priors. Bottom: neural network cost function that is a counterpart to the aforementioned
270 variational free energy. In this equation, ğ‘Š(cid:141) â‰” sig(ğ‘Š), ğ¾(cid:141) â‰” sig(ğ¾), and ğ‘‰(cid:146) â‰” sig(ğ‘‰) (for ğ‘™ =
(cid:142) (cid:142) (cid:142) (cid:142) (cid:142) (cid:142)
271 0,1) indicate the sigmoid functions of synaptic strengths. Moreover, ğœ™ and ğœ“ are perturbation
(cid:142) (cid:142)
272 terms that characterise the bias in firing thresholds. Here, ğœ™ â‰” ğœ™ (ğ‘Š,ğ¾) = â„ âˆ’lnğ‘Š(cid:141) âˆ’lnğ¾(cid:141)
(cid:142) (cid:142) (cid:142) (cid:142) (cid:142) (cid:142) (cid:142)
273 is a function of ğ‘Š and ğ¾, while ğœ“ â‰” ğœ“ (ğ‘‰) = ğ‘š âˆ’lnğ‘‰(cid:146) is a function of ğ‘‰. When ğœ”(cid:152) â‰”
(cid:142) (cid:142) (cid:142) (cid:142) (cid:142) (cid:142) (cid:142) (cid:142) 5
274 sig(ğœ” ) is the sigmoid function of ğœ” , ğœ” â‰¡ lnğœ”(cid:152) âˆ’lnğœ”(cid:152) holds for an arbitrary ğœ” . Using this
5 5 5 5 5 5
275 relationship, equation (7) is transformed into the form presented at the bottom of this figure. This
276 form of cost functions formally corresponds to variational free energy expressed on the top of this
277 figure.
278
279 Canonical neural networks perform active inference
280 In this section, we identify the neuronal substrates that correspond to components of the active
15
bioRxiv preprint doi: https://doi.org/10.1101/2020.12.10.420547; this version posted December 11, 2020. The copyright holder for this
preprint (which was not certified by peer review) is the author/funder. All rights reserved. No reuse allowed without permission.
281 inference scheme defined above. We consider a class of two-layer neural networks with recurrent
282 connections in the middle layer (Fig. 1a). The modelling of the networks in this section (referred to
283 as canonical neural networks) is based on the following three assumptionsâ€”that reflect
284 physiological knowledge: (1) a gradient descent on a cost function L determines the updates of
285 neural activity and synaptic weights; (2) neural activity is updated by the weighted sum of inputs,
286 and its fixed point is expressed in a form of the sigmoid (or logistic) function; and (3) a modulatory
287 factor mediates synaptic plasticity in a post-hoc manner.
288 Based on assumption 2, we formulate neural activity in the middle layer (ğ‘¥) and output layer (ğ‘¦)
289 as follows:
â§ ğ‘¥Ì‡(ğ‘¡)âˆ âˆ’s(cid:156)ig(cid:157) e (cid:157) % (cid:158)Jğ‘¥(cid:157) ( (cid:157)ğ‘¡) (cid:159)K+((cid:156)ğ‘Š(cid:157) % (cid:157)âˆ’(cid:157)(cid:157)ğ‘Š(cid:157) ' (cid:157))(cid:157)ğ‘œ(cid:157)(ğ‘¡(cid:157))(cid:157)+(cid:157)(cid:158)(ğ¾(cid:157) % (cid:157)âˆ’(cid:157)(cid:157)ğ¾(cid:157) ' (cid:157))ğ‘¥(cid:157)((cid:157)ğ‘¡(cid:157)âˆ’(cid:157)(cid:157)Î”ğ‘¡(cid:159))+ â„(cid:156) % (cid:157)(cid:158)âˆ’(cid:157)â„(cid:159) '
290 (cid:160)Â¡Â¢Â£ â„Â¥Æ’Æ’Â¡Â§Â¤ Â«â€¹Â§Â¢â€ºÂ¤fiâ„ fiÂ§â€ºÂ¥Â¤ Â¤flÆ’Â¡Â«fl(cid:176)(cid:160)â€“ (6)
â¨ ğ‘¦Ì‡(ğ‘¡) âˆ âˆ’s(cid:156)ig(cid:157) e (cid:157) % (cid:158)Jğ‘¦(cid:157) ( (cid:157)ğ‘¡) (cid:159)K+((cid:156)ğ‘‰(cid:157) % (cid:157)âˆ’(cid:157)(cid:157)ğ‘‰(cid:157) ' )(cid:158)ğ‘¥(cid:157)((cid:157)ğ‘¡(cid:157)âˆ’(cid:157)(cid:157)Î”(cid:159)ğ‘¡)+ğ‘š(cid:156)(cid:157) % (cid:157)(cid:158)âˆ’(cid:157)(cid:157)ğ‘š(cid:159) '
â©
(cid:160)Â¡Â¢Â£ â„Â¥Æ’Æ’Â¡Â§Â¤ Â«â€¹Â§Â¢â€ºÂ¤fiâ„ fiÂ§â€ºÂ¥Â¤ Â¤flÆ’Â¡Â«fl(cid:176)(cid:160)â€“
_ _
291 Here, ğ‘¥(ğ‘¡) â‰” [ğ‘¥ (ğ‘¡),â€¦,ğ‘¥ (ğ‘¡)^ and ğ‘¦(ğ‘¡) â‰” Â·ğ‘¦ (ğ‘¡),â€¦,ğ‘¦ (ğ‘¡)Â¶ denote column vectors of
% \â€¡ % \(cid:181)
_
292 firing intensities; ğ‘œ(ğ‘¡) â‰” [ğ‘œ (ğ‘¡),â€¦,ğ‘œ (ğ‘¡)^ is a column vector of binary sensory inputs;
% \]
293 ğ‘Š ,ğ‘Š âˆˆ â„\â€¡Ã—\], ğ¾ ,ğ¾ âˆˆ â„\â€¡Ã—\â€¡, and ğ‘‰ ,ğ‘‰ âˆˆ â„\(cid:181)Ã—\â€¡ are synaptic strength matrices; and
% ' % ' % '
294 â„ â‰” â„ (ğ‘Š ,ğ¾ ), â„ â‰” â„ (ğ‘Š ,ğ¾ ), ğ‘š â‰” ğ‘š (ğ‘‰ ), and ğ‘š â‰” ğ‘š (ğ‘‰ ) are adaptive firing
% % % % ' ' ' ' % % % ' ' '
295 thresholds that depend on synaptic strengths.
296 One may think of ğ‘Š , ğ¾ , and ğ‘‰ as excitatory synapses, whereas ğ‘Š , ğ¾ , and ğ‘‰ can be
% % % ' ' '
297 regarded as inhibitory synapses. Here, (ğ‘Š âˆ’ğ‘Š )ğ‘œ(ğ‘¡) represents the total synaptic input from
% '
298 the sensory layer, and (ğ¾ âˆ’ğ¾ )ğ‘¥(ğ‘¡âˆ’Î”ğ‘¡) forms a recurrent circuit with a time delay Î”ğ‘¡ > 0.
% '
299 Receiving inputs from the middle layer ğ‘¥(ğ‘¡), the output-layer neural activity ğ‘¦(ğ‘¡) determines the
16
bioRxiv preprint doi: https://doi.org/10.1101/2020.12.10.420547; this version posted December 11, 2020. The copyright holder for this
preprint (which was not certified by peer review) is the author/funder. All rights reserved. No reuse allowed without permission.
_
300 decision ğ›¿(ğ‘¡) â‰” [ğ›¿ (ğ‘¡),â€¦,ğ›¿ (ğ‘¡)^ , i.e., Prob[ğ›¿ (ğ‘¡) = 1] = ğ‘¦ (ğ‘¡). We select the inverse
% \ 5 5
d
301 sigmoid (i.e., logit) leak current to ensure that the fixed point of equation (6) (i.e., ğ‘¥ and ğ‘¦ that
302 ensure ğ‘¥Ì‡ = 0 and ğ‘¦Ì‡ = 0) has the form of a sigmoid activation function (c.f. assumption 2). The
303 sigmoid activation function is also known as the neurometric function [29].
304 Without loss of generality, equation (6) can be cast as the gradient descent on cost function ğ¿.
305 Such a cost function can be identified by simply integrating the right-hand side of equation (6) with
306 respect to ğ‘¥ and ğ‘¦, consistent with previous treatments [17]. Moreover, we presume that
307 output-layer synapses (ğ‘‰ and ğ‘‰ ) are updated through synaptic plasticity mediated by the
% '
308 modulator Î“(ğ‘¡) (c.f. assumption 3; 0 â‰¤ Î“(ğ‘¡) â‰¤ 1), as a model of plasticity modulations that are
309 empirically observed [26â€“28]. Because neural activity and synaptic plasticity minimise the same
310 cost function ğ¿, the derivatives of ğ¿ must generate the modulated synaptic plasticity. Under
311 these constraints reflecting assumptions 1â€“3, a class of cost functions is identified as follows:
â€™ ğ‘¥(ğœ) _ ğ‘¥(ğœ) ğ‘Š ğ¾ â„
312 ğ¿ = â€° Â· Â¶ (cid:190)lnÂ· Â¶âˆ’Â· %Â¶ğ‘œ(ğœ)âˆ’Â· %Â¶ğ‘¥(ğœâˆ’Î”ğ‘¡)âˆ’Â· %Â¶Â¿ğ‘‘ğœ
ğ‘¥(ğœ) ğ‘¥(ğœ) ğ‘Š ğ¾ â„
' ' ' '
â€™ ğ‘¦(ğœ) _ ğ‘¦(ğœ) ğ‘‰ ğ‘š
313 +â€° Â· Â¶ (cid:190)lnÂ· Â¶âˆ’J1âˆ’2Î“(ğ‘¡,ğœ)KÂ· %Â¶ğ‘¥(ğœâˆ’Î”ğ‘¡)âˆ’[ % ^Â¿ğ‘‘ğœ+ğ’ª(1). (7)
'
ğ‘¦(ğœ) ğ‘¦(ğœ) ğ‘‰
'
ğ‘š
'
314 Here, ğ’ª(1)â€”that denotes a function of synaptic strengthsâ€”is of a smaller order than the other
315 terms that are of order t. Thus, ğ’ª(1) is negligible when t is large. We suppose Î“(ğ‘¡,ğœ) = 0 for
316 ğ‘¡âˆ’Î”ğ‘¡ < ğœ â‰¤ ğ‘¡ and Î“(ğ‘¡,ğœ) = Î“(ğ‘¡) for 0 â‰¤ ğœ â‰¤ ğ‘¡âˆ’Î”ğ‘¡, to satisfy assumptions 1â€“3. This means
317 that the optimisation of ğ¿ by associative plasticity is mediated by Î“(ğ‘¡). Note that a gradient
318 descent on ğ¿, i.e. ğ‘¥Ì‡ âˆ âˆ’d/dğ‘¡â‹…ğœ•ğ¿/ğœ•ğ‘¥ and ğ‘¦Ì‡ âˆ âˆ’d/dğ‘¡â‹…ğœ•ğ¿/ğœ•ğ‘¦, has the same functional form
319 (and solution) as equation (6).
17
bioRxiv preprint doi: https://doi.org/10.1101/2020.12.10.420547; this version posted December 11, 2020. The copyright holder for this
preprint (which was not certified by peer review) is the author/funder. All rights reserved. No reuse allowed without permission.
320 Synaptic plasticity rules conjugate to the above rate coding model can now be expressed as a
321 gradient descent on the same cost function ğ¿, according to assumption 1. To simplify notation, we
322 define synaptic strength matrix as ğœ” âˆˆ {ğ‘Š ,ğ‘Š ,ğ¾ ,ğ¾ ,ğ‘‰ ,ğ‘‰ }, pre-synaptic activity as ğ‘ğ‘Ÿğ‘’ (ğ‘¡) âˆˆ
5 % ' % ' % ' 5
323 {ğ‘œ(ğ‘¡),ğ‘œ(ğ‘¡),ğ‘¥(ğ‘¡âˆ’Î”ğ‘¡),ğ‘¥(ğ‘¡âˆ’Î”ğ‘¡),ğ‘¥(ğ‘¡âˆ’Î”ğ‘¡),ğ‘¥(ğ‘¡âˆ’Î”ğ‘¡)}, post-synaptic activity as ğ‘ğ‘œğ‘ ğ‘¡ (ğ‘¡) âˆˆ
5
324 {ğ‘¥(ğ‘¡),ğ‘¥(ğ‘¡),ğ‘¥(ğ‘¡),ğ‘¥(ğ‘¡),ğ‘¦(ğ‘¡),ğ‘¦(ğ‘¡)}, and firing thresholds as ğ‘› âˆˆ {â„ ,â„ ,â„ ,â„ ,ğ‘š ,ğ‘š }. Thus,
5 % ' % ' % '
325 synaptic plasticity in the first layer (ğ‘– = 1,â€¦,4) is derived as follows:
1 ğœ•ğ¿ ğœ•ğ‘›
ğœ”Ì‡ âˆ âˆ’ = âŸ¨(cid:156)ğ‘(cid:157)ğ‘œ(cid:157)ğ‘ (cid:157)ğ‘¡(cid:157)((cid:157)ğ‘¡(cid:158))ğ‘(cid:157)ğ‘Ÿ(cid:157)ğ‘’(cid:157)((cid:157)ğ‘¡(cid:157))_(cid:159)âŸ©+Â¸ğ‘ğ‘œğ‘ ğ‘¡ (ğ‘¡)1(cid:204)âƒ—_Ë›âŠ™ 5 , (8)
326 5 ğ‘¡ ğœ•ğœ” 5 5 (cid:156)(cid:157)(cid:157)(cid:157) 5 (cid:157)(cid:157)(cid:158)(cid:157)(cid:157)(cid:157)(cid:157)ğœ•(cid:157)ğœ”(cid:159)
5 5
(cid:201)Â¡ËšËšfiÂ¢Â§ â€º(cid:160)Â¢Â«Â¤fiâ„fiÂ¤â€¹
fl(cid:176)Ë‡Â¡(cid:176)Â«Â¤Â¢Â¤fiâ„ â€º(cid:160)Â¢Â«Â¤fiâ„fiÂ¤â€¹
327 Moreover, synaptic plasticity in the second layer (ğ‘– = 5,6) is derived as follows:
1 ğœ•ğ¿ ğœ•ğ‘›
328 ğœ”Ì‡ 5 âˆ âˆ’ ğ‘¡ ğœ•ğœ” = J(cid:156)1(cid:157)âˆ’(cid:157)(cid:157)2(cid:157)Î“(cid:157) ( (cid:157)ğ‘¡) (cid:157)K(cid:157) âŸ¨ (cid:157)ğ‘ğ‘œ(cid:158)ğ‘ (cid:157)ğ‘¡ 5(cid:157) ( (cid:157)ğ‘¡) (cid:157)ğ‘(cid:157)ğ‘Ÿ(cid:157)ğ‘’(cid:157)5 ( (cid:157)ğ‘¡(cid:157) )_ (cid:159) âŸ©+Â¸ (cid:156) ğ‘ (cid:157) ğ‘œ (cid:157) ğ‘  (cid:157) ğ‘¡ 5 (cid:157) (ğ‘¡ (cid:157) ) (cid:158) 1(cid:204)âƒ—_ (cid:157) Ë› (cid:157) âŠ™ (cid:157)(cid:157)ğœ•(cid:157)ğœ”(cid:159) 5 . (9)
5 5
Ë‡(cid:176)â€“Â¥(cid:160)Â¢Â¤Â¡â€“ (cid:201)Â¡ËšËšfiÂ¢Â§ â€º(cid:160)Â¢Â«Â¤fiâ„fiÂ¤â€¹
fl(cid:176)Ë‡Â¡(cid:176)Â«Â¤Â¢Â¤fiâ„ â€º(cid:160)Â¢Â«Â¤fiâ„fiÂ¤â€¹
329 Here, âŸ¨ğ‘ğ‘œğ‘ ğ‘¡ (ğ‘¡)ğ‘ğ‘Ÿğ‘’ (ğ‘¡)_âŸ© â‰” % âˆ« â€™ ğ‘ğ‘œğ‘ ğ‘¡ (ğœ)ğ‘ğ‘Ÿğ‘’ (ğœ)_ğ‘‘ğœ indicates the average over time and 1(cid:204)âƒ— =
5 5 â€™ ' 5 5
330 (1,â€¦,1)_ is a vector of ones.
331 These synaptic update rules are biologically plausible as they comprise Hebbian plasticityâ€”
332 determined by the outer product of pre- and post-synaptic activityâ€”accompanied by an activity-
333 dependent homeostatic term. In equation (9), the neuromodulator Î“(ğ‘¡)â€”that encodes an
334 arbitrary riskâ€”alters the form of Hebbian plasticity in a post-hoc manner. This can facilitate the
335 association between past decisions and the current risk, thus leading to the optimisation of the
336 decision rule to minimise future risk. In short, Î“(ğ‘¡) > 0.5 yields Hebbian plasticity, whereas
337 Î“(ğ‘¡) < 0.5 yields anti-Hebbian plasticity. Empirical observations suggest that some modulators
338 [26â€“28], such as dopamine neurons [30], are a possible neuronal substrate of Î“(ğ‘¡); please see
18
bioRxiv preprint doi: https://doi.org/10.1101/2020.12.10.420547; this version posted December 11, 2020. The copyright holder for this
preprint (which was not certified by peer review) is the author/funder. All rights reserved. No reuse allowed without permission.
339 Discussion for further details.
340 Based on the above considerations, we now establish the formal correspondence between the
341 neural network cost function and variational free energy. Under the aforementioned three minimal
342 assumptions, we identify the neural network cost function as equation (7). Equation (7) can be
343 transformed into the form shown in Fig. 3 (bottom) using sigmoid functions of synaptic strengths
344 (e.g., ğ‘Š(cid:141) â‰” sig(ğ‘Š) for ğ‘™ = 0,1). Here, the firing thresholds (â„ ,ğ‘š ) are replaced with the
(cid:142) (cid:142) (cid:142) (cid:142)
345 perturbation terms in the thresholds, ğœ™ â‰” â„ âˆ’lnğ‘Š(cid:141) âˆ’lnğ¾(cid:141) and ğœ“ â‰” ğ‘š âˆ’lnğ‘‰(cid:146) . Figure 3
(cid:142) (cid:142) (cid:142) (cid:142) (cid:142) (cid:142) (cid:142)
346 depicts the formal equivalence between the neural network cost function (Fig. 3, bottom) and
347 variational free energy (Fig. 3, top), visualised by one-by-one correspondence between their
348 components. The components of variational free energyâ€”including the log likelihood function and
349 complexities of states and decisionsâ€”re-emerge in the neural network cost function.
_
350 This means that when (ğ‘¥(ğœ)_,ğ‘¥(ğœ)_)_ = ğ¬ , (ğ‘¦(ğœ)_,ğ‘¦(ğœ)_)_ = ğ›… , ğ‘Š(cid:141) = ğ€_ , ğ¾(cid:141) = ğ(cid:138) , and
2 2 (cid:142) %(cid:142) (cid:142) %(cid:142)
_
351 ğ‘‰(cid:146) = ğ‚(cid:138) (for ğ‘™ = 0,1), the neural network cost function is identical to variational free energy, up
(cid:142) %(cid:142)
352 to the negligible lnğ‘¡ residual. This further endorses the asymptotic equivalence of equations (5)
353 and (7).
354 The neural network cost function is characterised by the perturbation terms implicit in firing
355 thresholds ğœ™ â‰” (ğœ™ ,ğœ™ ) and ğœ“ â‰” (ğœ“ ,ğœ“ ). These terms correspond to the state and decision
% ' % '
356 priors, lnğ‘ƒ(ğ‘  ) = lnğ· = ğœ™ and lnğ‘ƒ(ğ›¿ ) = lnğ¸ = ğœ“, respectively. Hence, this class of cost
â€™ â€™
357 functions for canonical neural networks is formally homologous to variational free energy, under
358 the particular form of POMDP generative model, defined in the previous section. In other words,
359 equations (2) and (5) express the class of generative modelsâ€”and ensuing variational free
19
bioRxiv preprint doi: https://doi.org/10.1101/2020.12.10.420547; this version posted December 11, 2020. The copyright holder for this
preprint (which was not certified by peer review) is the author/funder. All rights reserved. No reuse allowed without permission.
360 energyâ€”that ensure equation (1) is apt, for the class of canonical neural networks considered. This
361 in turn suggests that any canonical neural network in this class is implicitly performing active
362 inference. Table 1 summarises the correspondence between the quantities of the neural network
363 and their homologues in variational Bayes.
364 In summary, when a neural network minimises the cost function with respect to its activity and
365 plasticity, the network self-organises to furnish responses that minimise a risk implicit in the cost
366 function. This biological optimisation is identical to variational free energy minimisation under a
367 particular form of POMDP model. Hence, this equivalence indicates that minimising the expected
368 risk through variational free energy minimisation is an inherent property of canonical neural
369 networks featuring a delayed modulation of Hebbian plasticity.
370
371 Table 1. Correspondence of variables and functions.
Neural network formation Variational Bayes formation
Sensory inputs ğ‘œ(ğ‘¡) âŸº ğ‘œ Observations
â€™
ğ‘¥(ğ‘¡)
Middle-layer neural activity Â· Â¶ âŸº ğ¬ State posterior
ğ‘¥(ğ‘¡) â€™
ğ‘¦(ğ‘¡)
Output-layer neural activity Â· Â¶ âŸº ğ›… Decision posterior
ğ‘¦(ğ‘¡) â€™
Feedback response ğ›¿(ğ‘¡) âŸº ğ›¿ Decision
â€™
ğ‘Š âŸº sige%(ğ€ )
(cid:142) %(cid:142)
Synaptic strengths Parameter posterior
ğ¾ âŸº sige%Jğ(cid:138) K
(cid:142) %(cid:142)
20
bioRxiv preprint doi: https://doi.org/10.1101/2020.12.10.420547; this version posted December 11, 2020. The copyright holder for this
preprint (which was not certified by peer review) is the author/funder. All rights reserved. No reuse allowed without permission.
ğ‘‰ âŸº sige%Jğ‚(cid:138) K
(cid:142) %(cid:142)
ğœ™
ğœ™ â‰” Â· %Â¶ âŸº lnğ· State prior
ğœ™
'
Perturbation terms
ğœ“
ğœ“ â‰” Â· %Â¶ âŸº lnğ¸ Decision prior
ğœ“
'
â„ âŸº lnğ€ â‹…1(cid:204)âƒ—+lnğ(cid:138) â‹…1(cid:204)âƒ—+lnğ·
(cid:142) '(cid:142) '(cid:142) (cid:142)
Firing thresholds
ğ‘š âŸº lnğ‚(cid:138) â‹…1(cid:204)âƒ—+lnğ¸
(cid:142) '(cid:142) (cid:142)
ğœ†(cid:211) âŠ™ğ‘Š(cid:141)fiÂ§fiÂ¤ âŸº ğ‘
(cid:142) (cid:142) %(cid:142)
Initial synaptic strengths ğœ†(cid:212) âŠ™ğ¾(cid:141)fiÂ§fiÂ¤ âŸº ğ‘ Parameter prior
(cid:142) (cid:142) %(cid:142)
ğœ†(cid:213) âŠ™ğ‘‰(cid:146)fiÂ§fiÂ¤ âŸº ğ‘
(cid:142) (cid:142) %(cid:142)
372 Note that ğ‘ŠfiÂ§fiÂ¤,ğ¾fiÂ§fiÂ¤,ğ‘‰fiÂ§fiÂ¤ are initial values of ğ‘Š,ğ¾,ğ‘‰ (for ğ‘™ = 0,1) and ğœ†(cid:211),ğœ†(cid:212),ğœ†(cid:213) are
(cid:142) (cid:142) (cid:142) (cid:142) (cid:142) (cid:142) (cid:142) (cid:142) (cid:142)
373 inverse learning rate factors that express the insensitivity of synaptic strengths to plasticity. Please
374 refer to [17] for details.
375
376 Numerical simulations
377 Here, we demonstrate the performance of canonical neural networks using maze tasksâ€”as an
378 example of a delayed reward task. The agent comprised the aforementioned canonical neural
379 networks (Fig. 4a). Thus, it implicitly performs active inference by minimising variational free
380 energy. The maze affords a discrete state space (Fig. 4b). The agent received the states of the
381 neighbouring cells as sensory inputs, and its neural activity represented the hidden states (Fig. 4a,
382 panels on the right; See Methods E for further details). Although we denoted s as hidden states,
21
bioRxiv preprint doi: https://doi.org/10.1101/2020.12.10.420547; this version posted December 11, 2020. The copyright holder for this
preprint (which was not certified by peer review) is the author/funder. All rights reserved. No reuse allowed without permission.
383 the likelihood mapping A was a simple identity mapping in these simulations. When solving the
384 above equations (6), (8), and (9), the agentâ€™s neural network implicitly updates posterior beliefs
385 about its behaviour based on the policy mapping. It then selects an appropriate action to move
386 towards a neighbouring cell according to the inferred policy. The action was accepted if the
387 selected movement was allowed.
388 Before training, the agent moved to a random direction in each step, resulting in a failure to
389 reach the goal position (right end) within the time limit. During training, the neural network
390 updated synaptic strengths depending on its neural activity and ensuing outcomes (i.e., risk). The
391 training comprised a cycle of action and learning phases. In the action phase, the agent enacted a
392 sequence of decisions, until it reached the goal or ğ‘‡ = 2Ã—10(cid:218) time steps passed (Fig. 4c). In the
393 learning phase, the agent evaluated the risk associated with past decisions after a certain period:
394 the risk was minimum (i.e., Î“(ğ‘¡) = 0) if the agent moved rightwards with a certain distance during
395 the period; otherwise Î“(ğ‘¡) = 0.45 if the agent moved rightwards during the period, or Î“(ğ‘¡) =
396 0.55 if it did not. The synaptic strengths V (i.e., the policy mapping) were then potentiated if the
397 risk was low, or suppressed otherwise, based on equation (9). This mechanism made it possible to
398 optimise decision making. Other synapses (W, K) were also updated based on equation (8),
399 although we assumed a small learning rate to focus on the implicit policy learning. Through
400 training, the neural network of the agent self-organised its behaviour to efficiently secure its goal
401 (Fig. 4d).
402
22
bioRxiv preprint doi: https://doi.org/10.1101/2020.12.10.420547; this version posted December 11, 2020. The copyright holder for this
preprint (which was not certified by peer review) is the author/funder. All rights reserved. No reuse allowed without permission.
403
404 Figure 4. Simulations of neural networks solving maze tasks. (a) Neural network architecture. The
405 agent receives the states (pathway or wall) of the neighbouring 11 Ã— 11 cells as sensory inputs. A
406 policy decision represents a four-step sequence of actions (selected from up, down, left, or right),
407 resulting in 256 options in total. The panels on the right depict observations and posterior beliefs
408 about hidden states and decisions. (b) General view of the maze. The maze comprises a discrete
409 state space, wherein white and black cells indicate pathways and walls, respectively. A thick blue
410 cell indicates the current position of the agent, while the thin blue line is its trajectory. Starting
411 from the left, the agent needs to reach the right edge of the maze within ğ‘‡ = 2Ã—10(cid:218) time steps.
23
bioRxiv preprint doi: https://doi.org/10.1101/2020.12.10.420547; this version posted December 11, 2020. The copyright holder for this
preprint (which was not certified by peer review) is the author/funder. All rights reserved. No reuse allowed without permission.
412 (c) Trajectories of the agentâ€™s x-axis position in sessions before (black, session 1) and after (blue,
413 session 100) training. (d) Duration to reach the goal when the neural network operates under
414 uniform decision priors ğ¸ = ğ¸ = ğ¸ = ğ¸ = 1/256â‰ˆ 0.0039 (where ğ¸
Æ’fi(cid:219)flÂ¤ (cid:160)Â¡(cid:220)Â¤ Â¥â€º â€“(cid:176)(cid:221)Â§ Æ’fi(cid:219)flÂ¤
415 indicates the prior probability to select a decision involving the rightward motion in the next step).
416 Blue and red circles indicate succeeded and failed sessions, respectively. (e) Failure probability
417 (left) and duration to reach the goal (right) when the neural network operates under three
418 different prior conditions ğ¸ = 0.0023,0.0039,0.0055, where ğ¸ = 0.0078âˆ’ğ¸ and
Æ’fi(cid:219)flÂ¤ (cid:160)Â¡(cid:220)Â¤ Æ’fi(cid:219)flÂ¤
419 ğ¸ = ğ¸ = 0.0039 hold. The line indicates the average of 10 successive sessions. Although
Â¥â€º â€“(cid:176)(cid:221)Â§
420 the neural network with ğ¸ = 0.0055 exhibits better performance in the early stage, it turns
Æ’fi(cid:219)flÂ¤
421 out to overestimate a preference of the rightward motion in later stages, even when it approaches
422 the wall. (e) was obtained with 20 distinct, randomly generated mazes. Shaded areas indicate the
423 standard error. Refer to Methods E for further details.
424
425 With this set up in place, we numerically validated the dependency of performance on the
426 threshold factors (ğœ™,ğœ“). Consistent with our theoretical predictionâ€”that ğœ™ and ğœ“ encode prior
427 beliefs about hidden states (D) and decisions (E)â€”alternations of ğœ“ = lnğ¸ from the optimum to
428 a suboptimal value changed the landscape of the cost function (i.e., variational free energy),
429 thereby providing suboptimal inferences and decisions (in relation to the environment).
430 Subsequently, the suboptimal network firing thresholds led to a suboptimal behavioural strategy,
431 taking a longer time or failing to reach the goal (Fig. 4e). Thus, we could attribute the agentâ€™s
432 impaired performance to its suboptimal priors. This treatment renders neural activity and adaptive
24
bioRxiv preprint doi: https://doi.org/10.1101/2020.12.10.420547; this version posted December 11, 2020. The copyright holder for this
preprint (which was not certified by peer review) is the author/funder. All rights reserved. No reuse allowed without permission.
433 behaviours of the agent highly explainable and manipulatable in terms of the appropriate prior
434 beliefsâ€”implicit in firing thresholdsâ€”for a given task or environment. In other words, these results
435 suggest that firing thresholds are the neuronal substrates that encode state and decision priors, as
436 predicted mathematically.
437 Furthermore, when the updating of ğœ™ and ğœ“ is slow in relation to experimental observations,
438 ğœ™ and ğœ“ can be estimated through Bayesian inference based on empirically observed neuronal
439 responses (see Methods E for details). Using this approach, we estimated implicit prior ğ¸â€”which
440 is encoded by ğœ“â€”from sequences of neural activity generated from the synthetic neural networks
441 used in the simulations reported in Fig. 4. We confirmed that the estimator was a good
442 approximation to the true ğ¸ (Fig. 5a). The estimation of ğœ™ and ğœ“ based on empirical
443 observations offered the reconstruction of the cost function (i.e., variational free energy) that an
444 agent employs. The resulting cost function could predict subsequent learning of behaviours within
445 previously unexperienced, randomly generated mazesâ€”without observing neural activity and
446 subsequent behaviour (Fig. 5b). This is becauseâ€”given the canonical neural network at handâ€”the
447 learning self-organisation is based exclusively on state and decision priors, implicit in ğœ™ and ğœ“.
448 Therefore, the identification of these implicit priors is sufficient to asymptotically determine the
449 fixed point of synaptic strengths when ğ‘¡ is large (see Methods C, D for further details; see also
450 [17]). These results highlight the utility of the proposed equivalence to understand neuronal
451 mechanisms underlying adaptation of neural activity and behaviour through accumulation of past
452 experiences and ensuing outcomes.
453
25
bioRxiv preprint doi: https://doi.org/10.1101/2020.12.10.420547; this version posted December 11, 2020. The copyright holder for this
preprint (which was not certified by peer review) is the author/funder. All rights reserved. No reuse allowed without permission.
454
455 Figure 5. Estimation of implicit priors enables the prediction of subsequent learning. (a) Estimation
456 of implicit prior ğ¸ â€”encoded by threshold factor ğœ“â€”under three different prior conditions
Æ’fi(cid:219)flÂ¤
457 (black, blue, and cyan; c.f., Fig. 4). Here, ğœ“ was estimated through Bayesian inference based on
458 sequences of neural activity, obtained with 10 distinct mazes. Then, ğ¸ was computed by
Æ’fi(cid:219)flÂ¤
459 lnğ¸ = ğœ“ for each of 64 elements. The other 192 elements of ğ¸ (i.e., ğ¸ ,ğ¸ ,ğ¸ ) were also
(cid:160)Â¡(cid:220)Â¤ Â¥â€º â€“(cid:176)(cid:221)Â§
460 estimated. (b) Prediction of the learning process within previously unexperienced, randomly
461 generated mazes. Using the estimated ğ¸, we reconstructed the computational architecture (i.e.,
462 neural network) of the agent. Then, we simulated the adaptation process of the agentâ€™s behaviour
463 using the reconstructed neural network, and computed the trajectory of the probability of failure
464 to reach the goal within ğ‘‡ = 2Ã—10(cid:218) time steps. The resulting learning trajectories (solid lines)
465 predict the learning trajectories of the original agent (dashed lines) under three different prior
466 conditions, in the absence of observed neural responses and behaviours. Lines and shaded areas
467 indicate the mean and standard error, respectively. Inset panels depict comparisons between the
468 failure probability of the original and reconstructed agent after learning (average over session 51â€“
469 100), within 10 previously unexperienced mazes. Refer to Methods E for further details.
470
26
bioRxiv preprint doi: https://doi.org/10.1101/2020.12.10.420547; this version posted December 11, 2020. The copyright holder for this
preprint (which was not certified by peer review) is the author/funder. All rights reserved. No reuse allowed without permission.
471 DISCUSSION
472 Biological organisms formulate plans to minimise future risk. In this work, we captured this
473 characteristic in biologically plausible terms under minimal assumptions. We derived simple
474 differential equations that can be plausibly interpreted in terms of a neural network architecture
475 that entails degrees of freedom with respect to certain free parameters (e.g., firing threshold).
476 These free parameters play the role of prior beliefs in variational Bayesian formation. Thus, the
477 accuracies of inferences and decisions depend upon prior beliefs, implicit in neural networks.
478 Consequently, synaptic plasticity with false prior beliefs lead to suboptimal inferences and
479 decisions for any task under consideration.
480 A simple Hebbian plasticity strengthens synaptic wiring when pre- and post-synaptic neurons
481 fire together, which enhances the association between (pre-synaptic) causes and (post-synaptic)
482 consequences [23]. Hebbian plasticity depends on the activity level [24,25], spike timings [31,32],
483 or burst timings [33] of pre- and post-synaptic neurons. Furthermore, modulatory factors can
484 regulate the magnitude and parity of Hebbian plasticity, possibly with some delay in time, leading
485 to the emergence of various associative functions [26â€“28]. These modulations have been observed
486 empirically with various neuromodulators and neurotransmitters, such as dopamine [30,34,35],
487 noradrenaline [36,37], muscarine [38], and GABA [39,40], as well as glial factors [41].
488 In particular, a delayed modulation of synaptic plasticity is well-known with dopamine neurons
489 [30]. We mathematically demonstrated that such a plasticity enhances the association between
490 the pre-post mapping and the future value of the modulatory factor, where the latter is cast as a
491 risk function. This means that post-synaptic neurons self-organise to react in a manner that
27
bioRxiv preprint doi: https://doi.org/10.1101/2020.12.10.420547; this version posted December 11, 2020. The copyright holder for this
preprint (which was not certified by peer review) is the author/funder. All rights reserved. No reuse allowed without permission.
492 minimises future risk. Crucially, this computation corresponds formally to variational Bayesian
493 inference under a particular form of POMDP generative models, suggesting that the delayed
494 modulation of Hebbian plasticity is a realisation of active inference. Regionally specific projections
495 of neuromodulators may allow each brain region to optimise activity to minimise risk, and leverage
496 a hierarchical generative model implicit in cortical and subcortical hierarchies. This is reminiscent
497 of theories of neuromodulation and (meta-)learning developed previously [42]. Our work may be
498 potentially useful, when casting these theories in terms of generative models and variational free
499 energy minimisation.
500 It is remarkable that the proposed equivalence can be leveraged to identify a generative model
501 that an arbitrary neural network implicitly employs. This contrasts with naÃ¯ve neural network
502 models that address only the dynamics of neural activity and plasticity. If the generative model
503 differs from the true generative processâ€”that generates the sensory inputâ€”inferences and
504 decisions are biased (i.e., suboptimal), relative to Bayes optimal inferences and decisions based on
505 the right sort of prior beliefs. In general, the implicit priors may or may not be equal to the true
506 priors; thus, a generic neural network is typically suboptimal. Nevertheless, these implicit priors
507 can be optimised by updating free parameters (e.g., threshold factors ğœ™,ğœ“) based on the gradient
508 descent on cost function L. By updating the free parameters, the network will eventually, in
509 principle, becomes Bayes optimal for any given task. In essence, when the cost function is
510 minimised with respect to neural activity, synaptic strengths, and any other constants that
511 characterise the cost function, the cost function becomes equivalent to variational free energy
512 with the optimal prior beliefs. Simultaneously, the expected risk is minimised because variational
28
bioRxiv preprint doi: https://doi.org/10.1101/2020.12.10.420547; this version posted December 11, 2020. The copyright holder for this
preprint (which was not certified by peer review) is the author/funder. All rights reserved. No reuse allowed without permission.
513 free energy is minimised only when the precision of the risk (ğ›¾ ) is maximised (see Methods A for
â€™
514 further details).
515 When the rate coding activation function differs from the sigmoid function, it can be assumed
516 that neurons encode state posteriors under a generative model that differs from a typical POMDP
517 model considered in this work. Nevertheless, the complete class theorem guarantees the existence
518 of some pair of generative model (i.e., priors) and cost function that correspond to an arbitrary
519 activation function. The form or time-window of empirically observed plasticity rules can also be
520 used to identify the implicit cost and risk functionsâ€”and further to reverse engineer the task or
521 problem that the neural network is solving or learning: c.f., inverse reinforcement learning [43]. In
522 short, neural activity and plasticity can be interpreted, universally, in terms of Bayesian belief
523 updating.
524 The class of neural networks we consider can be viewed as a class of reservoir networks [44,45].
525 The proposed equivalence could render such reservoir networks explainableâ€”and may provide
526 the optimal plasticity rules for these networks to minimise future riskâ€”by using the formal
527 analogy to variational free energy minimisation (under the particular form of POMDP models). A
528 clear interpretation of reservoir networks remains an important open issue in computational
529 neuroscience and machine learning.
530 The equivalence between neural network dynamics and gradient flows on variational free
531 energy is empirically testable using electrophysiological recordings or functional imaging of brain
532 activity. We have previously shown that the self-organisation of in vitro neural networks minimises
533 empirically computed variational free energy in a manner consistent with variational free energy
29
bioRxiv preprint doi: https://doi.org/10.1101/2020.12.10.420547; this version posted December 11, 2020. The copyright holder for this
preprint (which was not certified by peer review) is the author/funder. All rights reserved. No reuse allowed without permission.
534 minimisation under a POMDP generative model [46,47]. Our analyses in the present work speak to
535 the predictive validity of the proposed formulation: when the threshold factors (ğœ™,ğœ“) can be
536 treated as constantsâ€”during a short experimentâ€”we obtain the analytical form of fixed points for
537 synaptic update rules (Methods D). Furthermore, ğœ™ and ğœ“ can be estimated using empirical
538 data (Methods E). This approach enables the reconstruction of the cost function and prediction of
539 subsequent learning process, as demonstrated in Fig. 5 using in silico data. Hence, it is possible to
540 examine the predictive validity of the proposed theory by comparing the predicted synaptic
541 trajectory with the actual trajectory. In future work, we hope to address these issues using in vitro
542 and in vivo data.
543 In summary, a class of cost functions for canonical neural networks can be cast as variational
544 free energy. Formal correspondences exist between priors, posteriors, and cost functions. This
545 means that canonical neural networks that optimise their cost functions implicitly perform active
546 inference. This approach enables identification of the implicit generative model and reconstruction
547 of variational free energy that neural networks employ. This means, in principle, neural activity,
548 behaviour, and learning through plasticity can be predicted under Bayes optimality assumptions.
549
550 Data Availability
551 All relevant data are within the paper. The MATLAB scripts are available at
552 https://github.com/takuyaisomura/reverse_engineering.
553
30
bioRxiv preprint doi: https://doi.org/10.1101/2020.12.10.420547; this version posted December 11, 2020. The copyright holder for this
preprint (which was not certified by peer review) is the author/funder. All rights reserved. No reuse allowed without permission.
554 Acknowledgements
555 This work was supported in part by the grant of Joint Research by the National Institutes of Natural
556 Sciences (NINS Program No. 01112005). T.I. is funded by RIKEN Center for Brain Science. H.S. is
557 funded by MEXT/JSPS KAKENHI Grant Number JP 20K11709. K.J.F. is funded by a Wellcome
558 Principal Research Fellowship (Ref: 088130/Z/09/Z). The funders had no role in study design, data
559 collection and analysis, decision to publish, or preparation of the manuscript.
560
561 Competing Interests
562 The authors have no competing interests to declare.
563
564 References
565 1. Linsker, R. Self-organization in a perceptual network. Computer 21, 105-117 (1988).
566 2. Dayan, P., Hinton, G. E., Neal, R. M. & Zemel, R. S. The Helmholtz machine. Neural Comput. 7,
567 889-904 (1995).
568 3. Sutton, R. S. & Barto, A. G. Reinforcement Learning. MIT Press, Cambridge, MA, USA (1998).
569 4. Bishop, C. M. Pattern recognition and machine learning. Springer (2006).
570 5. Friston, K., Kilner, J. & Harrison, L. A free energy principle for the brain. J. Physiol. Paris 100,
571 70-87 (2006).
572 6. Friston, K. The free-energy principle: a unified brain theory? Nat. Rev. Neurosci. 11, 127-138
31
bioRxiv preprint doi: https://doi.org/10.1101/2020.12.10.420547; this version posted December 11, 2020. The copyright holder for this
preprint (which was not certified by peer review) is the author/funder. All rights reserved. No reuse allowed without permission.
573 (2010).
574 7. Blei, D. M., Kucukelbir, A. & McAuliffe, J. D. Variational inference: A review for statisticians. J.
575 Am. Stat. Assoc. 112, 859-877 (2017).
576 8. Friston, K. Life as we know it. J. R. Soc. Interface 10, 20130475 (2013).
577 9. Friston, K. A free energy principle for a particular physics. arXiv preprint:1906.10184 (2019).
578 10. Parr, T., Da Costa, L. & Friston, K. Markov blankets, information geometry and stochastic
579 thermodynamics. Phil. Trans. R. Soc. A 378, 20190159 (2020).
580 11. Friston, K., Mattout, J. & Kilner, J. Action understanding and active inference. Biol. Cybern.
581 104, 137-160 (2011).
582 12. Friston, K., FitzGerald, T., Rigoli, F., Schwartenbeck, P. & Pezzulo, G. Active inference and
583 learning. Neurosci. Biobehav. Rev. 68, 862-879 (2016).
584 13. Friston, K., FitzGerald, T., Rigoli, F., Schwartenbeck, P. & Pezzulo, G. Active inference: A process
585 theory. Neural Comput. 29, 1-49 (2017).
586 14. Wald, A. An essentially complete class of admissible decision functions. Ann. Math. Stat. 18,
587 549-555 (1947).
588 15. Brown, L. D. A complete class theorem for statistical problems with finite-sample spaces. Ann.
589 Stat. 9, 1289-1300 (1981).
590 16. Berger, J. O. Statistical decision theory and Bayesian analysis. Springer Science & Business
591 Media (2013).
32
bioRxiv preprint doi: https://doi.org/10.1101/2020.12.10.420547; this version posted December 11, 2020. The copyright holder for this
preprint (which was not certified by peer review) is the author/funder. All rights reserved. No reuse allowed without permission.
592 17. Isomura, T. & Friston, K. Reverse-engineering neural networks to characterize their cost
593 functions. Neural Comput. 32, 2085-2121 (2020).
594 18. Attias, H. Planning by Probabilistic Inference. In Proc of the 9th Int Workshop on Artificial
595 Intelligence and Statistics (2003).
596 19. Botvinick, M. & Toussaint, M. Planning as inference. Trends Cogn. Sci. 16, 485-488 (2012).
597 20. Maisto, D., Donnarumma, F. & Pezzulo, G. Divide et impera: subgoaling reduces the
598 complexity of probabilistic inference and problem solving. J. R. Soc. Interface 12, 20141335
599 (2015).
600 21. Kaplan, R. & Friston, K. J. Planning and navigation as active inference. Biol. Cybern. 112, 323-
601 343 (2018).
602 22. Millidge, B. Deep active inference as variational policy gradients. J. Math. Psychol. 96, 102348
603 (2020).
604 23. Hebb, D. O. The Organization of Behavior: A Neuropsychological Theory. New York: Wiley
605 (1949).
606 24. Bliss, T. V. & LÃ¸mo, T. Long-lasting potentiation of synaptic transmission in the dentate area of
607 the anaesthetized rabbit following stimulation of the perforant path. J. Physiol. 232, 331-356
608 (1973).
609 25. Malenka, R.C. & Bear, M. F. LTP and LTD: an embarrassment of riches. Neuron 44, 5-21 (2004).
610 26. Pawlak, V., Wickens, J. R., Kirkwood, A. & Kerr, J. N. Timing is not everything: neuromodulation
33
bioRxiv preprint doi: https://doi.org/10.1101/2020.12.10.420547; this version posted December 11, 2020. The copyright holder for this
preprint (which was not certified by peer review) is the author/funder. All rights reserved. No reuse allowed without permission.
611 opens the STDP gate. Front. Syn. Neurosci. 2, 146 (2010).
612 27. FrÃ©maux, N. & Gerstner, W. Neuromodulated spike-timing-dependent plasticity, and theory of
613 three-factor learning rules. Front. Neural Circuits 9, 85 (2016).
614 28. KuÅ›mierz, Å., Isomura, T. & Toyoizumi, T. Learning with three factors: modulating Hebbian
615 plasticity with errors. Curr. Opin. Neurobiol. 46, 170-177 (2017).
616 29. Newsome, W. T., Britten, K. H. & Movshon, J. A. Neuronal correlates of a perceptual decision.
617 Nature 341, 52-54 (1989).
618 30. Yagishita, S. et al. A critical time window for dopamine actions on the structural plasticity of
619 dendritic spines. Science 345, 1616-1620 (2014).
620 31. Markram, H., LÃ¼bke, J., Frotscher, M. & Sakmann, B. Regulation of synaptic efficacy by
621 coincidence of postsynaptic APs and EPSPs. Science 275, 213-215 (1997).
622 32. Bi, G. Q. & Poo, M. M. Synaptic modifications in cultured hippocampal neurons: dependence
623 on spike timing, synaptic strength, and postsynaptic cell type. J. Neurosci. 18, 10464-10472
624 (1998).
625 33. Butts, D. A., Kanold, P. O. & Shatz, C. J. A burst-based â€œHebbianâ€ learning rule at
626 retinogeniculate synapses links retinal waves to activity-dependent refinement. PLoS Biol. 5,
627 e61 (2007).
628 34. Reynolds, J. N. J., Hyland, B. I. & Wickens, J. R. A cellular mechanism of reward-related
629 learning. Nature 413, 67-70 (2001).
34
bioRxiv preprint doi: https://doi.org/10.1101/2020.12.10.420547; this version posted December 11, 2020. The copyright holder for this
preprint (which was not certified by peer review) is the author/funder. All rights reserved. No reuse allowed without permission.
630 35. Zhang, J. C., Lau, P. M. & Bi, G. Q. Gain in sensitivity and loss in temporal contrast of STDP by
631 dopaminergic modulation at hippocampal synapses. Proc. Natl. Acad. Sci. USA 106, 13028-
632 13033 (2009).
633 36. Salgado, H., KÃ¶hr, G. & TreviÃ±o, M. Noradrenergic â€œtoneâ€ determines dichotomous control of
634 cortical spike-timing-dependent plasticity. Sci. Rep. 2, 417 (2012).
635 37. Johansen, J. P. et al. Hebbian and neuromodulatory mechanisms interact to trigger associative
636 memory formation. Proc. Natl. Acad. Sci. USA 111, E5584-92 (2014).
637 38. Seol, G. H. et al. Neuromodulators control the polarity of spike-timing-dependent synaptic
638 plasticity. Neuron 55, 919-929 (2007).
639 39. Paille, V. et al. GABAergic circuits control spike-timing-dependent plasticity. J. Neurosci. 33,
640 9353-9363 (2013).
641 40. Hayama, T. et al. GABA promotes the competitive selection of dendritic spines by controlling
642 local Ca2+ signaling. Nat. Neurosci. 16, 1409-1416 (2013).
643 41. Ben Achour, S. & Pascual, O. Glia: the many ways to modulate synaptic plasticity. Neurochem.
644 Int. 57, 440-445 (2010).
645 42. Doya, K. Metalearning and neuromodulation. Neural Netw. 15, 495-506 (2002).
646 43. Ng, A. Y. & Russell, S. J. Algorithms for inverse reinforcement learning. In ICML 2000 (Vol. 1, p.
647 2) San Francisco: Morgan Kaufmann (2000).
648 44. Sussillo, D. & Abbott, L. F. Generating coherent patterns of activity from chaotic neural
35
bioRxiv preprint doi: https://doi.org/10.1101/2020.12.10.420547; this version posted December 11, 2020. The copyright holder for this
preprint (which was not certified by peer review) is the author/funder. All rights reserved. No reuse allowed without permission.
649 networks. Neuron 63, 544-557 (2009).
650 45. Laje, R. & Buonomano, D. V. Robust timing and motor patterns by taming chaos in recurrent
651 neural networks. Nat. Neurosci. 16, 925-933 (2013).
652 46. Isomura, T., Kotani, K. & Jimbo, Y. Cultured cortical neurons can perform blind source
653 separation according to the free-energy principle. PLoS Comput. Biol. 11, e1004643 (2015).
654 47. Isomura, T. & Friston, K. In vitro neural networks minimise variational free energy. Sci. Rep. 8,
655 16926 (2018).
656 48. Forney, G. D. Codes on graphs: Normal realizations. IEEE Trans. Info. Theory 47, 520-548
657 (2001).
658 49. Dauwels, J. On variational message passing on factor graphs. Info. Theory, 2007. ISIT 2007.
659 IEEE Int. Sympo., IEEE (2007).
660 50. Friston, K. J., Parr, T. & de Vries, B. D. The graphical brain: belief propagation and active
661 inference. Netw. Neurosci. 1, 381-414 (2017).
662
663 METHODS
664 A. Generative model
665 The proposed POMDP model comprises ğ‘ -dimensional hidden states ğ‘  âˆˆ {0,1}\â€˜ that
(cid:224) â€™
666 depend on the previous states ğ‘  through a transition probability of ğµf, and a process of
â€™e%
667 generating ğ‘ -dimensional observations ğ‘œ âˆˆ {0,1}\] from those states through a likelihood
Ã† â€™
36
bioRxiv preprint doi: https://doi.org/10.1101/2020.12.10.420547; this version posted December 11, 2020. The copyright holder for this
preprint (which was not certified by peer review) is the author/funder. All rights reserved. No reuse allowed without permission.
668 mapping ğ´ (Fig. 2). Here, the transition probability ğµf is a function of ğ‘ -dimensional decisions
f
669 of an agent ğ›¿ âˆˆ {0,1}\ d, indicating that the agentâ€™s behaviour changes the subsequent states of
â€™
670 the external milieu. Each state, observation, and decision take the values 1 or 0. We use ğ‘œ =
%:â€™
671 {ğ‘œ ,â€¦,ğ‘œ } to denote a sequence of observations. Hereafter, i indicates the i-th observation, j
% â€™
672 indicates the j-th hidden state, and k indicates the k-th decision.
673 Due to the multi-dimensional (i.e., factorial) nature of the states, ğ´ and ğµ (and ğ¶) are usually
674 the outer products of sub matrices (i.e., tensors); see also [17]. The probability of an observation is
(5)
675 determined by the likelihood mapping, from ğ‘  to ğ‘œ , in terms of a categorical distribution:
â€™ â€™
676 ğ‘ƒ[ğ‘œ (5) |ğ‘  ,ğ´(5)^ = CatJğ´(5)K, where the elements of ğ´(5) are given by ğ´ (5) = ğ‘ƒ[ğ‘œ (5) = 1|ğ‘  =
â€™ â€™ %(cid:142)âƒ— â€™ â€™
677 ğ‘™âƒ—,ğ´(5)^ and ğ´ (5) = 1âˆ’ğ´ (5) = ğ‘ƒ[ğ‘œ (5) = 0|ğ‘  = ğ‘™âƒ—,ğ´(5)^. This encodes the probability of ğ‘œ (5) takes
'(cid:142)âƒ— %(cid:142)âƒ— â€™ â€™ â€™
678 1 or 0 when ğ‘  = ğ‘™âƒ—= (ğ‘™ ,â€¦,ğ‘™ ). The prior belief of ğ´ (5) is defined by Dirichlet distribution
â€™ % \ âˆ™(cid:142)âƒ—
(5) (5) (5)
679 ğ‘ƒ[ğ´ ^ = Dir[ğ‘ ^ with concentration parameter ğ‘ . The hidden states are determined by
âˆ™(cid:142)âƒ— âˆ™(cid:142)âƒ— âˆ™(cid:142)âƒ—
680 the transition probability, from ğ‘  to ğ‘  , depending on a given decision, in terms of a
â€™e% â€™
681 categorical distribution: ğ‘ƒ[ğ‘  ((cid:226)) |ğ‘  ,ğµf((cid:226))^ = CatJğµf((cid:226))K, where the elements of ğµf((cid:226)) are
â€™ â€™e%
682 given by ğµ f((cid:226)) = ğ‘ƒ[ğ‘  ((cid:226)) |ğ‘  = ğ‘™âƒ—,ğ›¿ ,ğµf^. The prior distribution of ğµ f((cid:226)) is defined by Dirichlet
â‹…(cid:142)âƒ— â€™ â€™e% â€™e% âˆ™(cid:142)âƒ—
f((cid:226)) f((cid:226)) f((cid:226))
683 distribution ğ‘ƒ[ğµ ^ = Dir[ğ‘ ^ with concentration parameter ğ‘ .
âˆ™(cid:142)âƒ— âˆ™(cid:142)âƒ— âˆ™(cid:142)âƒ—
684 The policy mapping is optimised based on a generative model of decisions ğ›¿ conditioned on
2
_
685 the current risk ğ›¾ âˆˆ {0,1} that obeys ğ‘ƒ(ğ›¾ ) = Cat[JÎ“,Î“ K ^, where Î“ = 1âˆ’Î“. This can be
â€™ â€™ â€™ â€™ â€™ â€™
(Âª)
686 viewed as a postdiction of past decisions. We express the conditional probability of ğ›¿ as a form
2
687 of a mixture model with respect to ğ›¾ : ğ‘ƒ[ğ›¿ (Âª) |ğ‘  ,ğ›¾ ,ğ¶(Âª)^ = ğ‘ƒ[ğ›¿ (Âª) |ğ‘  ,ğ¶(Âª),ğ›¾ =
â€™ 2 2e% â€™ 2 2e% â€™
688 0^
st
ğ‘ƒ[ğ›¿ (Âª) |ğ‘  ,ğ¶(Âª),ğ›¾ = 1^
st
. Namely, the agent assumes (i.e., postdicts) that ğ›¿ (Âª) was
2 2e% â€™ 2
37
bioRxiv preprint doi: https://doi.org/10.1101/2020.12.10.420547; this version posted December 11, 2020. The copyright holder for this
preprint (which was not certified by peer review) is the author/funder. All rights reserved. No reuse allowed without permission.
689 sampled by ğ‘ƒ[ğ›¿ (Âª) |ğ‘  ,ğ¶(Âª),ğ›¾ = 0^ = CatJğ¶(Âª)K after receiving ğ›¾ = 0, or sampled by
2 2e% â€™ â€™
690 ğ‘ƒ[ğ›¿ (Âª) |ğ‘  ,ğ¶(Âª),ğ›¾ = 1^ = Cat[ğ¶u(Âª) âŠ™Jğ¶(Âª)K âŠ™e% ^ after receiving ğ›¾ = 1. Because the agent
2 2e% â€™ â€™
691 does not yet observe the consequence of current decision ğ›¿ , ğ›¿ is sampled from
â€™ â€™
692 ğ‘ƒ[ğ›¿ (Âª) |ğ‘  ,ğ›¾ ,ğ¶(Âª)^ = ğ‘ƒ[ğ›¿ (Âª) |ğ‘  ,ğ¶(Âª)^ = CatJğ¶(Âª)K to minimise the future risk. The prior
â€™ â€™e% â€™ â€™ â€™e%
(Âª) (Âª) (Âª)
693 belief of ğ¶ is defined by Dirichlet distribution ğ‘ƒ[ğ¶ ^ = Dir[ğ‘ ^ with concentration
âˆ™(cid:142)âƒ— âˆ™(cid:142)âƒ— âˆ™(cid:142)âƒ—
(Âª)
694 parameter ğ‘ .
âˆ™(cid:142)âƒ—
695 Therefore, when observing ğ›¾ = 0, the agent regards that the past decisions were sampled
â€™
696 from the preferable policy mapping ğ¶ that minimises Î“ , and thereby updates the posterior
â€™
697 belief of ğ¶ to facilitate the association between ğ›¿ and ğ‘  . In contrast, when observing ğ›¾ =
2 2e% â€™
698 1, the agent hypothesises that this is because the past decisions were sampled from the
699 unpreferable policy mapping, and thereby updates the posterior belief of ğ¶ to reduce (forget) the
700 association. In short, this postdiction evaluates the past decisions after observing their
701 consequence. The posterior belief of ğ¶ is then updated by associating the past decision rule
702 (policy) and current risk, leading to the optimisation of decisions to minimise future risk.
703 An advantage of this generative modelâ€”based on counterfactual causalityâ€”is that the agent
704 does not need to explicitly compute the expected future risk based on the current states, because
705 it instead updates the policy mapping ğ¶, by associating the current risk with past decisions. Note
706 that this construction of risk corresponds to a simplification of expected free energy, that would
707 normally include risk and ambiguity, where risk corresponds to the Kullback-Leibler divergence
708 between the posterior predictive and prior distribution over outcomes [12,13]. However, by using
709 a precise likelihood mapping, ambiguity can be discounted and expected free energy reduces to
38
bioRxiv preprint doi: https://doi.org/10.1101/2020.12.10.420547; this version posted December 11, 2020. The copyright holder for this
preprint (which was not certified by peer review) is the author/funder. All rights reserved. No reuse allowed without permission.
710 the sort of decision risk considered in this work.
711 We can now define the generative model as equation (2), where ğ‘ƒ(ğ‘  |ğ‘  ,ğ›¿ ,ğµ) = ğ‘ƒ(ğ‘  ) =
% ' ' %
712 Cat(ğ·) and ğ‘ƒ(ğ›¿ |ğ‘  ,ğ›¾ ,ğ¶) = ğ‘ƒ(ğ›¿ ) = Cat(ğ¸) are assumed. We further suppose that ğ›¿ , given
% ' â€™ % 2
713 ğ‘  , is conditionally independent of {ğ‘œ ,ğ‘  }, and that only the generation of ğ›¿ depends on ğ›¾ ,
2e% 2 2 2 â€™
714 as visualised in the factor graph (Fig. 2). Equation (2) can be further expanded as follows:
\] \â€˜ \
d
715 ğ‘ƒ(ğ‘œ ,ğ‘  ,ğ›¿ ,ğ›¾ ,ğœƒ) = ğ‘ƒ(ğ›¾ )â‹…hğ‘ƒJğ´(5)Kâ‹…hğ‘ƒJğµf((cid:226))Kâ‹…hğ‘ƒJğ¶(Âª)K
%:â€™ %:â€™ %:â€™ â€™ â€™
5i% (cid:226)i% Âªi%
â€™ \] \â€˜ \ d
716 â‹…h(cid:228)hğ‘ƒ[ğ‘œ (5) |ğ‘  ,ğ´(5)^â‹…hğ‘ƒ[ğ‘  ((cid:226)) |ğ‘  ,ğ›¿ ,ğµf((cid:226))^â‹…hğ‘ƒ[ğ›¿ (Âª) |ğ‘  ,ğ›¾ ,ğ¶(Âª)^(cid:229). (10)
2 2 2 2e% 2e% 2 2e% â€™
2i% 5i% (cid:226)i% Âªi%
717 As described in the Results section, this form of generative model is suitable to characterise a class
718 of canonical neural networks defined by equation (6). This means that none of aforementioned
719 assumptions about the generative model limits the scope of the proposed equivalence between
720 neural networks and variational Bayesian inference, as long as neural networks satisfy assumptions
721 1â€“3.
722
723 B. Variational free energy
724 The agent aims to minimise surprise, or equivalently maximise the marginal likelihood of
725 outcomes, by minimising variational free energy as a tractable proxy. Thereby, they perform
726 approximate or variational Bayesian inference. From the above-defined generative model, we
727 motivate a mean-field approximation to the posterior distribution as follows:
39
bioRxiv preprint doi: https://doi.org/10.1101/2020.12.10.420547; this version posted December 11, 2020. The copyright holder for this
preprint (which was not certified by peer review) is the author/funder. All rights reserved. No reuse allowed without permission.
â€™
728 ğ‘„(ğ‘  ,ğ›¿ ,ğœƒ) = ğ‘„(ğœƒ)ğ‘„(ğ‘  )ğ‘„(ğ›¿ ) = ğ‘„(ğ´)ğ‘„(ğµ)ğ‘„(ğ¶)hğ‘„(ğ‘  )ğ‘„(ğ›¿ ). (11)
%:â€™ %:â€™ %:â€™ %:â€™ 2 2
2i%
729 Here, the posterior beliefs of ğ‘  and ğ›¿ are categorical distributions, ğ‘„(ğ‘  ) = Cat(ğ¬ ) and
2 2 2 2
730 ğ‘„(ğ›¿ ) = Cat(ğ›… ), respectively. Whereas, the posterior beliefs of ğ´, ğµ, and ğ¶ are Dirichlet
2 2
731 distributions, ğ‘„(ğ´) = Dir(ğš), ğ‘„(ğµ) = Dir(ğ›), and ğ‘„(ğ¶) = Dir(ğœ), respectively. In this
732 expression, ğ¬ and ğ›… represent the expectations between 0 and 1, and ğš, ğ›, and ğœ express
2 2
733 the (positive) concentration parameters.
734 In this paper, the posterior transition mapping is averaged over all possible decisions, ğ =
735 E (cid:129)ğf(cid:130), to ensure exact correspondence to canonical neural networks. Moreover, we suppose
M(f)
736 that ğ€ comprises the outer product of sub-matrices ğ€(5,(cid:226)) âˆˆ â„(cid:230)Ã—(cid:230) to simplify calculation of the
737 posterior beliefs, i.e., ğ€
(5)
= ğ€
(5,%)
âŠ—â‹¯âŠ—ğ€
(5,\â€˜ )
for ğ‘™ = 0,1. We also suppose that ğ and ğ‚
(cid:142)âˆ™ (cid:142)âˆ™ (cid:142)âˆ™
738 comprise the outer products of sub-matrices ğJ(cid:226),(cid:226)Ã˜K âˆˆ â„(cid:230)Ã—(cid:230) and ğ‚(Âª,(cid:226)) âˆˆ â„(cid:230)Ã—(cid:230), respectively. The
739 expectation over the parameter posterior ğ‘„(ğœƒ) = âˆ \] âˆ \â€˜ ğ‘„Jğ´(5,(cid:226))Kâ‹…âˆ \â€˜ âˆ \â€˜ ğ‘„JğµJ(cid:226),(cid:226)Ã˜KKâ‹…
5i% (cid:226)i% (cid:226)i% (cid:226)Ã˜i%
740 âˆ \ d âˆ \â€˜ ğ‘„Jğ¶(Âª,(cid:226))K is denoted as E [âˆ™] â‰” âˆ«âˆ™ğ‘„(ğœƒ)ğ‘‘ğœƒ. Using this, the posterior expectation of
Âªi% (cid:226)i% M(Âº)
741 a parameter Î˜ âˆˆ
(cid:237)ğ´(5,(cid:226)),ğµJ(cid:226),(cid:226)Ã˜K,ğ¶(Âª,(cid:226))(cid:238)
is expressed using the corresponding concentration
742 parameter ğ›‰ âˆˆ
(cid:237)ğš(5,(cid:226)),ğ›J(cid:226),(cid:226)Ã˜K,ğœ(Âª,(cid:226))(cid:238)
as follows:
ğ›‰
â‹…(cid:142)
â§ ğš¯ â‰” E [Î˜ ] =
â‹…(cid:142) M((cid:240) â‹…Ã¦ ) â‹…(cid:142) ğ›‰ +ğ›‰
743 %(cid:142) '(cid:142) (12)
ğ›‰
â¨ lnğš¯ â‰” E [lnÎ˜ ] = ğœ“(ğ›‰ )âˆ’ğœ“(ğ›‰ +ğ›‰ ) = ln â‹…(cid:142) +ğ’ª((ğ›‰ +ğ›‰ )e%)
â© â‹…(cid:142) M((cid:240) â‹…Ã¦ ) â‹…(cid:142) â‹…(cid:142) %(cid:142) '(cid:142) ğ›‰ +ğ›‰ %(cid:142) '(cid:142)
%(cid:142) '(cid:142)
744 for ğ‘™ = 0,1, where ğœ“(âˆ™) is the digamma function.
745 In terms of decisions, because ğ‘ƒ(ğ›¿ |ğ‘  ,ğ¶,ğ›¾ = 1) âˆ CatJğ¶âŠ™e%K in this setup, the complexity
2 2e% â€™
746 associated with past decision is given by ğ’Ÿ [ğ‘„(ğ›¿ )||ğ‘ƒ(ğ›¿ |ğ‘  ,ğ›¾ ,ğ¶)] =
(cid:243)(cid:244) 2 2 2e% â€™
40
bioRxiv preprint doi: https://doi.org/10.1101/2020.12.10.420547; this version posted December 11, 2020. The copyright holder for this
preprint (which was not certified by peer review) is the author/funder. All rights reserved. No reuse allowed without permission.
747 E [lnğ‘„(ğ›¿ )âˆ’lnğ‘ƒ(ğ›¿ |ğ‘  ,ğ›¾ ,ğ¶)] = ğ›… â‹…{lnğ›… âˆ’(1âˆ’Î“ )lnğ‚ğ¬ +
M(fÄ± )M((cid:224)Ä±(cid:246)(cid:247) )M(Å‚)Ã¸(st ) 2 2 2e% â€™ 2 2 â€™ 2e%
748 Î“ lnğ‚ğ¬ } for 1 â‰¤ ğœ â‰¤ ğ‘¡âˆ’1, up to the ğ¶u-dependent term which is negligible when
â€™ 2e%
749 computing the posterior beliefs. Whereas, the current decision is made to minimise the complexity
750 ğ’Ÿ [ğ‘„(ğ›¿ )||ğ‘ƒ(ğ›¿ |ğ‘  ,ğ¶)] = ğ›… â‹…(lnğ›… âˆ’lnğ‚ğ¬ ).
(cid:243)(cid:244) â€™ â€™ â€™e% 2 2 2e%
751 Variational free energy is defined as a functional of the posterior beliefs, given as:
752 ğ¹Jğ‘œ ,ğ‘„(ğ‘  ,ğ›¿ ,ğœƒ)K â‰” E [âˆ’lnğ‘ƒ(ğ‘œ ,ğ›¿ ,ğ‘  ,ğ›¾ ,ğœƒ)+lnğ‘„(ğ‘  ,ğ›¿ ,ğœƒ)]
%:â€™ %:â€™ %:â€™ M((cid:224)(cid:247):t,f(cid:247):t,Âº)Ã¸(st ) %:â€™ %:â€™ %:â€™ â€™ %:â€™ %:â€™
â€™
753 = (cid:131)E (cid:129)lnğ‘„(ğ‘  )âˆ’lnğ‘ƒ(ğ‘œ |ğ‘  ,ğ´)âˆ’lnğ‘ƒJğ‘  |ğ‘  ,ğ›¿ ,ğµfK(cid:130)
M((cid:224)Ä± )M((cid:224)Ä±(cid:246)(cid:247) )M(Å“)M(ÃŸ) 2 2 2 2 2e% 2e%
2i%
â€™
754 +(cid:131)E [lnğ‘„(ğ›¿ )âˆ’lnğ‘ƒ(ğ›¿ |ğ‘  ,ğ›¾ ,ğ¶)]
M(fÄ± )M((cid:224)Ä±(cid:246)(cid:247) )M(Å‚)Ã¸(st ) 2 2 2e% â€™
2i%
755 +ğ’Ÿ [ğ‘ƒ(ğ´)||ğ‘„(ğ´)]+ğ’Ÿ [ğ‘ƒ(ğµ)||ğ‘„(ğµ)]+ğ’Ÿ [ğ‘ƒ(ğ¶)||ğ‘„(ğ¶)]+ğ»[ğ›¾ ]. (13)
(cid:243)(cid:244) (cid:243)(cid:244) (cid:243)(cid:244) â€™
756 This provides an upper bound of sensory surprise âˆ’lnğ‘ƒ(ğ‘œ ). Here, ğ’Ÿ [âˆ™||âˆ™] is complexity of
%:â€™ (cid:243)(cid:244)
757 parameters scored by the Kullback-Leibler divergence. Minimisation of variational free energy is
758 attained when the entropy of the risk, ğ»[ğ›¾ ] â‰” E [âˆ’lnğ‘ƒ(ğ›¾ )] = âˆ’Î“ lnÎ“ âˆ’Î“ lnÎ“ , is
â€™ Ã¸(st ) â€™ â€™ â€™ â€™ â€™
759 minimised. This is achieved when Î“ shifts toward 0, meaning that the risk minimisation is a
â€™
760 corollary of variational free energy minimisation (the case where Î“ shifts toward 1 is negligible).
â€™
761 Under the MDP scheme, ğ¹ is expressed as a function of the posterior expectations, ğ¹ =
762 ğ¹(ğ‘œ ,ğ¬ ,ğ›… ,ğ›‰). Thus, using the vector expression, variational free energy under our POMDP
%:â€™ %:â€™ %:â€™
763 model is provided as follows:
â€™
764 ğ¹(ğ‘œ ,ğ¬ ,ğ›… ,ğ›‰) = (cid:131)ğ¬ âˆ™(lnğ¬ âˆ’lnğ€âˆ™ğ‘œ âˆ’lnğğ¬ )
%:â€™ %:â€™ %:â€™ 2 2 2 2e%
(cid:156)(cid:157)(cid:157)(cid:157)(cid:157)(cid:157)(cid:157)(cid:157)(cid:157)(cid:157)(cid:157)(cid:158)(cid:157)(cid:157)(cid:157)(cid:157)(cid:157)(cid:157)(cid:157)(cid:157)(cid:157)(cid:157)(cid:159)
2i%
Â¢â„â„Â¥Æ’Â¢â„â€¹(cid:253)Â«Â¤Â¢Â¤Â¡ â„(cid:176)Ë‡â€º(cid:160)Â¡(cid:254)fiÂ¤â€¹
41
bioRxiv preprint doi: https://doi.org/10.1101/2020.12.10.420547; this version posted December 11, 2020. The copyright holder for this
preprint (which was not certified by peer review) is the author/funder. All rights reserved. No reuse allowed without permission.
â€™
765 +(cid:131)ğ›… â‹…Jlnğ›… âˆ’J1âˆ’2Î“ Klnğ‚ğ‘  K
2 2 â€™,2 2e%
(cid:156)(cid:157)(cid:157)(cid:157)(cid:157)(cid:157)(cid:157)(cid:157)(cid:157)(cid:157)(cid:157)(cid:157)(cid:158)(cid:157)(cid:157)(cid:157)(cid:157)(cid:157)(cid:157)(cid:157)(cid:157)(cid:157)(cid:157)(cid:157)(cid:159)
2i%
â€“Â¡â„fiÂ«fi(cid:176)Â§ â„(cid:176)Ë‡â€º(cid:160)Â¡(cid:254)fiÂ¤â€¹
+((cid:156)ğš(cid:157)âˆ’(cid:157)(cid:157)ğ‘(cid:157))(cid:157)âˆ™l(cid:157)n(cid:157)ğ€(cid:157)âˆ’(cid:157)(cid:157)ln(cid:157)â„¬(cid:157)(cid:157)(ğš(cid:157))(cid:157)+(cid:157)(cid:157)(ğ›(cid:157)(cid:157)âˆ’(cid:157)ğ‘(cid:157))(cid:157)âˆ™(cid:157)ln(cid:158)ğ(cid:157)âˆ’(cid:157)(cid:157)ln(cid:157)(cid:157)â„¬(cid:157)(ğ›(cid:157))(cid:157)+(cid:157)(cid:157)((cid:157)ğœ(cid:157)âˆ’(cid:157)ğ‘(cid:157))(cid:157)âˆ™(cid:157)ln(cid:157)ğ‚(cid:157)âˆ’(cid:157)(cid:157)ln(cid:157)(cid:157)â„¬(cid:157)(ğœ(cid:159)). (14)
766
â€ºÂ¢Æ’Â¢Ë‡Â¡Â¤Â¡Æ’ â„(cid:176)Ë‡â€º(cid:160)Â¡(cid:254)fiÂ¤â€¹
767 Here, â„¬(ğš ) â‰¡ Î“(ğš )Î“(ğš )/Î“(ğš +ğš ) is the beta function. Here, lnğ€âˆ™ğ‘œ indicates the inner
5 5% 5' 5% 5' 2
768 product of lnğ€ and one-hot expressed ğ‘œ , which is a custom to express the sum of the product
2
_
769 of Jlnğ€(5,(cid:226))K _ âˆˆ â„(cid:230)Ã—(cid:230) and Â·ğ‘œ (5) ,ğ‘œ (5) Â¶ âˆˆ â„(cid:230) over all i.
2 2
770 The first and second terms of equation (14)â€”comprising accuracy and the complexity of state
771 and decisionâ€”increases in proportion to time t. Conversely, other termsâ€”the complexity of
772 parametersâ€”increases in the order of lnğ‘¡, which is thus negligible when t is large. Thus, we will
773 drop the parameter complexity by assuming that the scheme has experienced a sufficient number
774 of observations. Please see [17] for further details. The entropy of the risk is omitted as it is of
775 order 1.
776 Based on the Bayes theorem, ğ‘ƒJğ‘  |ğ‘  ,ğµfK âˆ ğ‘ƒJğ‘  |ğ‘  ,ğµfKğ‘ƒ(ğ‘  ) and ğ‘ƒ(ğ›¿ |ğ‘  ,ğ›¾ ,ğ¶) âˆ
2 2e% 2e% 2 2 2 2e% â€™
777 ğ‘ƒ(ğ‘  |ğ›¿ ,ğ›¾ ,ğœƒ)ğ‘ƒ(ğ›¿ ) hold, where ğ‘ƒ(ğ‘  ) is supposed to be a flat prior belief. Thus, the inverse
2e% 2 â€™ 2 2e%
778 transition and policy mappings are given as ğ(cid:138) = ğ_diag[ğ·]e% and ğ‚(cid:138) = ğ‚_diag[ğ¸]e%,
779 respectively. Thus, ğ¬ â‹…lnğğ¬ = ğ¬ â‹…(lnğ(cid:138) â‹…ğ¬ +lnğ·) and ğ›… â‹…lnğ‚ğ¬ = ğ›… â‹…
2 2e% 2 2e% 2 2e% 2
780 (lnğ‚(cid:138) â‹…ğ¬ +lnğ¸) hold. Accordingly, equation (14) becomes
2e%
â€™
781 ğ¹(ğ‘œ ,ğ¬ ,ğ›… ,ğ›‰) = (cid:131)ğ¬ â‹…(lnğ¬ âˆ’lnğ€â‹…ğ‘œ âˆ’lnğ(cid:138) â‹…ğ¬ âˆ’lnğ·)
%:â€™ %:â€™ %:â€™ 2 2 2 2e%
2i%
â€™
782 +(cid:131)ğ›… â‹…Jlnğ›… âˆ’J1âˆ’2Î“ Klnğ‚(cid:138) â‹…ğ¬ âˆ’lnğ¸K+ğ’ª(lnğ‘¡) (15)
2 2 â€™,2 2e%
2i%
42
bioRxiv preprint doi: https://doi.org/10.1101/2020.12.10.420547; this version posted December 11, 2020. The copyright holder for this
preprint (which was not certified by peer review) is the author/funder. All rights reserved. No reuse allowed without permission.
783 as expressed in Fig. 3 (top). Here, the prior beliefs about states and decisions, ğ‘ƒ(ğ‘  ) = Cat(ğ·)
2
784 and ğ‘ƒ(ğ›¿ )= Cat(ğ¸), alter the landscape of variational free energy. We will see below that this
2
785 specific form of variational free energy corresponds formally to a class of cost functions for
786 canonical neural networks.
787
788 C. Inference and learning
789 Inference optimises the posterior beliefs about the hidden states and decisions by minimising
790 variational free energy. The posterior beliefs are updated by the gradient descent on F, ğ¬Ì‡ âˆ
â€™
791 âˆ’ğœ•ğ¹/ğœ•ğ¬ and ğ›…Ì‡ âˆ âˆ’ğœ•ğ¹/ğœ•ğ›… . The fixed point of these updates furnishes the posterior beliefs,
â€™ â€™ â€™
792 which are analytically computed by solving ğœ•ğ¹/ğœ•ğ¬ = 0 and ğœ•ğ¹/ğœ•ğ›… = 0. Thus, from equation
â€™ â€™
793 (15), the posterior belief about the hidden states is provided as follows:
794 ğ¬ = ğœ(lnğ€â‹…ğ‘œ +lnğ(cid:138) â‹…ğ¬ +lnğ·). (16)
â€™ â€™ â€™e%
795 Moreover, the posterior belief about the decisions is provided as follows:
796 ğ›… = ğœ(lnğ‚(cid:138) â‹…ğ¬ +lnğ¸). (17)
â€™ â€™e%
797 Here, ğœ(âˆ™) denotes the softmax function; and ğ· and ğ¸ denote the prior beliefs about hidden
798 states and decisions, respectively, which we assume are fixed in this paper. Note that equations
799 (16) and (17) are equivalent to ğ¬ = ğœ(lnğ€â‹…ğ‘œ +lnğğ¬ ) and ğ›… = ğœ(lnğ‚ğ¬ ), respectively,
â€™ â€™ â€™e% â€™ â€™e%
800 as ğ(cid:138) = ğ_diag[ğ·]e% and ğ‚(cid:138) = ğ‚_diag[ğ¸]e%. Notably, ğ¬ = (ğ¬_ ,ğ¬_ )_ =
â€™ â€™% â€™'
_
801 [ğ¬
(%)
,â€¦,ğ¬
(\â€˜ )
,ğ¬
(%)
,â€¦,ğ¬
(\â€˜ )
^ indicates a block column vector of the state posterior under a
â€™% â€™% â€™' â€™'
(5) (5)
802 mean-field assumption, where ğ¬ is the posterior belief that ğ‘  takes a value of one. Since
â€™% â€™
43
bioRxiv preprint doi: https://doi.org/10.1101/2020.12.10.420547; this version posted December 11, 2020. The copyright holder for this
preprint (which was not certified by peer review) is the author/funder. All rights reserved. No reuse allowed without permission.
(5) (5)
803 ğ‘  takes either one or zero, a binary value, ğ¬ has the form of a sigmoid function. Here, we
â€™ â€™%
804 assume that only the state posterior ğ¬ at the latest time is updated at each time t; thus, no
â€™
805 message pass exists from ğ¬ to ğ¬ . The state posterior at time tâ€“1 is retained in the previous
â€™(cid:253)% â€™
806 value. This treatment corresponds to the Bayesian filter, as opposed to the smoother usually
807 considered in active inference schemes.
808 Equations (16) and (17) are analogue to a two-layer neural network that entails recurrent
809 connections in the middle layer. In this analogy, ğ¬ and ğ›… are viewed as the middle- and
â€™% â€™%
810 output-layer neural activity, respectively. Moreover, lnğ€â‹…ğ‘œ , lnğ(cid:138) â‹…ğ¬ , and lnğ‚(cid:138) â‹…ğ¬
â€™ â€™e% â€™e%
811 corresponds to synaptic inputs, and lnğ· and lnğ¸ relates to firing thresholds. These priors and
812 posteriors turn out to be identical to the components of canonical neural networks, as described in
813 the Results and Methods D.
814 Furthermore, learning optimises the posterior beliefs about the parameters ğ›‰ = {ğš,ğ›,ğœ} by
815 minimising variational free energy. The posterior beliefs are updated by the gradient descent on F,
816 ğ›‰Ì‡ âˆ âˆ’ğœ•ğ¹/ğœ•ğ›‰. By solving the fixed point ğœ•ğ¹/ğœ•ğ›‰ = ğ‘‚ of equation (14), the posterior beliefs about
817 parameters are provided as follows:
â€™
â§
ğš = ğ‘+(cid:131)ğ‘œ âŠ—ğ¬ = ğ‘¡âŸ¨ğ‘œ âŠ—ğ¬ âŸ©+ğ’ª(1)
âª 2 2 â€™ â€™
âª 2i%
âª â€™
818 ğ› = ğ‘+(cid:131)ğ¬ âŠ—ğ¬ = ğ‘¡âŸ¨ğ¬ âŠ—ğ¬ âŸ©+ğ’ª(1) (18)
2 2e% â€™ â€™e%
â¨
2i%
âª
â€™e%
âª
âªğœ = ğ‘+(cid:131)(1âˆ’2Î“ )ğ›… âŠ—ğ¬ +ğ›… âŠ—ğ¬ = ğ‘¡Â¸(1âˆ’2Î“ )âŸ¨ğ›… âŠ—ğ¬ âŸ©Ë›+ğ’ª(1)
â€™ 2 2e% 2 2e% â€™ â€™ â€™e%
â©
2i%
819 Note that â¨‚ denotes the outer product operator, and âŸ¨ğ‘œ âŠ—ğ¬ âŸ© â‰” % âˆ‘â€™ ğ‘œ â¨‚ğ¬ . Here, ğ‘,ğ‘,ğ‘
â€™ â€™ 2i% 2 2
â€™
820 are the prior beliefs, which are of order 1 and thus negligibly small relative to the leading order
44
bioRxiv preprint doi: https://doi.org/10.1101/2020.12.10.420547; this version posted December 11, 2020. The copyright holder for this
preprint (which was not certified by peer review) is the author/funder. All rights reserved. No reuse allowed without permission.
821 term when t is large. Thus, the posterior expectations of any parameters Î˜ (i.e., ğš¯ and lnğš¯) are
822 obtained using equations (12) and (18). These parameter posteriors turn out to correspond
823 formally to synaptic strengths (ğ‘Š,ğ¾,ğ‘‰) owing to the equivalence of variational free energy and
824 neural network cost function.
825
826 D. Neural networks
827 Updates of neural activity are defined by equation (6). When the time constant of neural activity
828 is smaller than that of sensory inputs, the fixed point of equation (6)â€”i.e., ğ‘¥ and ğ‘¦ that give
829 ğ‘¥Ì‡ = 0 and ğ‘¦Ì‡ = 0â€”is provided as follows:
ğ‘¥(ğ‘¡) = sigJ(ğ‘Š âˆ’ğ‘Š )ğ‘œ(ğ‘¡)+(ğ¾ âˆ’ğ¾ )ğ‘¥(ğ‘¡âˆ’Î”ğ‘¡)+â„ âˆ’â„ K
% ' % ' % '
830 % (19)
ğ‘¦(ğ‘¡) = sigJ(ğ‘‰ âˆ’ğ‘‰ )ğ‘¥(ğ‘¡âˆ’Î”ğ‘¡)+ğ‘š âˆ’ğ‘š K
% ' % '
831 The adaptive firing thresholds are given as functions of synaptic strengths, â„ = lnğ‘Š(cid:141) 1(cid:204)âƒ—+
(cid:142) (cid:142)
832 lnğ¾(cid:141) 1(cid:204)âƒ—+ğœ™ and ğ‘š = lnğ‘‰(cid:146) 1(cid:204)âƒ—+ğœ“ (for ğ‘™ = 0,1), where exp(ğœ™ )+exp(ğœ™ ) = 1 and
(cid:142) (cid:142) (cid:142) (cid:142) (cid:142) % '
833 exp(ğœ“ )+exp(ğœ“ ) = 1 hold. The form of equation (19) is identical to the state and decision
% '
834 posteriors in equations (16) and (17) of the variational Bayesian formation.
835 Considering that neural activity corresponds to the posterior beliefs about states and decisions,
836 one might consider the relationship between synaptic strengths and parameter posteriors. As we
837 mathematically demonstrated in the Results section, owing to the equivalence between variational
838 free energy F and the neural network cost function L, i.e., equation (5) versus equation (7),
839 synaptic strengths correspond formally to parameter posteriors. The ensuing synaptic update
840 rulesâ€”derived as the gradient descent on Lâ€”are expressed in equations (8) and (9). They have a
45
bioRxiv preprint doi: https://doi.org/10.1101/2020.12.10.420547; this version posted December 11, 2020. The copyright holder for this
preprint (which was not certified by peer review) is the author/funder. All rights reserved. No reuse allowed without permission.
841 biologically plausible form, comprising Hebbian plasticity accompanied with an activity-dependent
842 homeostatic term. The product of Î“(ğ‘¡) and the associated term modulates plasticity depending
843 on the quality of past decisions, after observing their consequences, leading to minimisation of the
844 future risk. In other words, the modulation by Î“(ğ‘¡) represents a postdiction that the agent
845 implicitly conducts, wherein the agent regards its past decisions as preferable when Î“(ğ‘¡) is low
846 and memorises the strategy. Conversely, it regards them as unpreferable when Î“(ğ‘¡) is high and
847 forgets the strategy.
848 In particular, when ğœ™ and ğœ“ are constants, the fixed point of synaptic strengths that minimise
849 L is expressed analytically as follows: for simplification, we employ the notation using ğœ” , ğ‘ğ‘Ÿğ‘’ ,
5 5
850 ğ‘ğ‘œğ‘ ğ‘¡ , and ğ‘› , as described in the Results section. The derivative of firing threshold ğ‘› with
5 5 5
851 respect to synaptic strength matrix ğœ” yields the sigmoid function of ğœ” , i.e., ğœ•ğ‘› /ğœ•ğœ” =
5 5 5 5
852 âˆ’Â¸ğ‘ğ‘œğ‘ ğ‘¡ 1(cid:204)âƒ—_Ë›âŠ™sig(ğœ” ). Here, âŠ™ indicates the element-wise product (Hadamard product). The
5 5
853 fixed point of synaptic strengths ensures ğœ•ğ¿/ğœ•ğœ” = ğ‘‚. Thus, from equations (8) and (9), it is
5
854 analytically expressed as
âŠ™e%
855 ğœ” = sige%[âŸ¨ğ‘ğ‘œğ‘ ğ‘¡ (ğ‘¡)ğ‘ğ‘Ÿğ‘’ (ğ‘¡)_âŸ©âŠ™Â¸ğ‘ğ‘œğ‘ ğ‘¡ (ğ‘¡)1(cid:204)âƒ—_Ë› ^ (20)
5 5 5 5
856 for ğ‘– = 1,â€¦,4, and
âŠ™e%
857 ğœ” = sige%[)J1âˆ’2Î“(ğ‘¡)KâŸ¨ğ‘ğ‘œğ‘ ğ‘¡ (ğ‘¡)ğ‘ğ‘Ÿğ‘’ (ğ‘¡)_âŸ©*âŠ™Â¸ğ‘ğ‘œğ‘ ğ‘¡ (ğ‘¡)1(cid:204)âƒ—_Ë› ^ (21)
5 5 5 5
858 for ğ‘– = 5,6. Equations (20) and (21) correspond to the posterior belief about parameters ğ´,ğµ,ğ¶,
859 which are shown in equation (18).
860
46
bioRxiv preprint doi: https://doi.org/10.1101/2020.12.10.420547; this version posted December 11, 2020. The copyright holder for this
preprint (which was not certified by peer review) is the author/funder. All rights reserved. No reuse allowed without permission.
861 E. Protocols for numerical simulations and data analyses
862 In Fig. 4, the neural network of the agent was characterised by a set of internal states ğœ‘ =
863 {ğ‘¥,ğ‘¦,ğ‘Š,ğ¾,ğ‘‰,ğœ™,ğœ“}. Neural activity (ğ‘¥,ğ‘¦) was updated by following equation (6), while synaptic
864 strengths (ğ‘Š,ğ¾,ğ‘‰) were updated by following equations (8) and (9). Here, we supposed that
865 neural activity converges quickly to the steady state relative to the change of observations. This
866 treatment allowed us to compute the network dynamics based on equations (19)â€“(21), which
867 could reduce the computational cost for numerical simulations. Synaptic strengths W were
868 initialised as a matrix sufficiently close to the identity matrix; whereas, synaptic strengths K and V
869 were initialised as matrices with uniform values. This treatment served to focus on the policy
870 learning implicit in the update of V. The threshold factors (ğœ™,ğœ“), which encoded the prior beliefs
871 about hidden states (D) and decisions (E), were pre-defined and fixed over the sessions. In Fig. 4e,
872 we varied E to show how performance depends on these priors. Namely, ğ¸ =
%
_
873 Jğ¸ ,â€¦,ğ¸ ,ğ¸ ,â€¦,ğ¸ ,ğ¸ ,â€¦,ğ¸ ,ğ¸ ,â€¦,ğ¸ K âˆˆ [0,1](cid:230)+, was characterised by
Æ’fi(cid:219)flÂ¤ Æ’fi(cid:219)flÂ¤ (cid:160)Â¡(cid:220)Â¤ (cid:160)Â¡(cid:220)Â¤ Â¥â€º Â¥â€º â€“(cid:176)(cid:221)Â§ â€“(cid:176)(cid:221)Â§
874 four values ğ¸ ,ğ¸ ,ğ¸ ,ğ¸ âˆˆ [0,1], where ğ¸ indicates the prior probability to select a
Æ’fi(cid:219)flÂ¤ (cid:160)Â¡(cid:220)Â¤ Â¥â€º â€“(cid:176)(cid:221)Â§ Æ’fi(cid:219)flÂ¤
875 decision involving the rightward motion in the next step.
876 When the belief updating of implicit priors (ğ·,ğ¸) is slow in relation to experimental
877 observations, ğ· and ğ¸â€”which are encoded by ğœ™ and ğœ“â€”can be viewed as being fixed over a
878 short period of time, as an analogy to a homeostatic plasticity over longer time scales [51]. In this
879 case, through variational free energy minimisation based on empirically observed neuronal
880 responses, the estimators of ğœ™ and ğœ“ are obtained as follows:
47
bioRxiv preprint doi: https://doi.org/10.1101/2020.12.10.420547; this version posted December 11, 2020. The copyright holder for this
preprint (which was not certified by peer review) is the author/funder. All rights reserved. No reuse allowed without permission.
â€™
1 ğ‘¥
â§ â€™
ğ›Ÿ = ln. (cid:131)[ ^/
âª ğ‘¡ ğ‘¥
â€™
881 2i% . (22)
â€™
â¨ 1 ğ‘¦
â€™
âªğ›™ = ln. (cid:131)[ ^/
ğ‘¡ ğ‘¦
â© â€™
2i%
882 Note that we suppose the constraints exp(ğœ™ )+exp(ğœ™ ) = 1(cid:204)âƒ— and exp(ğœ“ )+exp(ğœ“ ) = 1(cid:204)âƒ—.
% ' % '
883 This characterisation finessed the estimation of implicit priors (Fig. 5a) and the reconstruction of
884 variational free energy. Furthermore, the reconstructed variational free energy was used to predict
885 subsequent inference and learning, without observing neural activity (Fig. 5b). In Fig. 5, for
886 simplicity, the form of the risk function was supposed to be known when reconstructing the cost
887 function. Although we did not estimate ğœ™ in Fig. 5, the previous work showed that our approach
888 can estimate ğœ™ from simulated neural activity data [17].
889
890 References
891 51. Turrigiano, G. G. & Nelson, S. B. Homeostatic plasticity in the developing nervous system. Nat.
892 Rev. Neurosci. 5, 97-107 (2004).
893
48