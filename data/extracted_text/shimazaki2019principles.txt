9102
beF
82
]CN.oib-q[
1v33211.2091:viXra
The principles of adaptation in organisms and machines I:
machine learning, information theory, and thermodynamics
Hideaki Shimazaki
Graduate School of Informatics, Kyoto University
Abstract
How do organisms recognize their environment by acquiring knowledge about the world, and what ac-
tionsdotheytakebasedonthisknowledge? Thisarticleexamineshypothesesaboutorganisms’adaptation
to the environment from machine learning, information-theoretic, and thermodynamic perspectives. We
start with constructing a hierarchical model of the world as an internal model in the brain, and review
standard machine learning methods to infer causes by approximately learning the model under the maxi-
mum likelihood principle. This in turn provides an overview of the free energy principle for an organism,
a hypothesis to explain perception and action from the principle of least surprise. Treating this statistical
learning as communication between the world and brain, learning is interpreted as a process to maximize
information about the world. We investigate how the classical theories of perception such as the infomax
principle relates to learning the hierarchical model. We then present an approach to the recognition and
learning based on thermodynamics, showing that adaptation by causal learning results in the second law
of thermodynamics whereas inference dynamics that fuses observation with prior knowledge forms a ther-
modynamic process. These provide a unified view on the adaptation of organisms to the environment.
1 Introduction
stimuli such as the sounds of forests, coastal land-
scapesorflowingstreamsdeepens ourunderstanding
Howdoorganismsrecognizetheirenvironmentbyac- ofcodingmechanismsofthebrain[7,8]. Indeed,itis
quiring knowledge about the outside world for their knownthatthishypothesisexplainsresponsecharac-
survival,andwhatactionsdotheytakebasedonthis teristicsofearlysensoryneuronssuchasnonlinearity
knowledge? The purpose of this article is to gain a ofresponsesto stimuli, orsensitivityto the temporal
deeper understanding of this issue by explaining the and spatial arrangement of stimuli, called receptive
perception and behavior of organisms from multiple fields [7, 8, 9, 10, 11].
perspectives in different disciplines, namely machine Naturalstimulimustoriginatefromcertaincauses.
learning, information theory, statistical mechanics, Ifwefurtherconsidertheadaptivemechanismsofthe
and thermodynamics. brain, we arriveat the concept of the brain as an or-
Natural stimuli have characteristic statistical reg- ganthatinfersthecausesofinputstimuli. According
ularity that follows the rules of materials or life. As tothisview,thebrainisaninferenceorganequipped
a result of evolution and development, it is thought with an empirical model of what sorts of things in
that the nervous systems of living things adapt to the outside world cause the sensory data, and infers
the statistical regularity of natural stimuli, and effi- the causes of the current data based on this model.
ciently encode them in their activity [1, 2, 3, 4, 5, 6]. This view was proposed in the first half of the 20th
From an information theoretic point of view, Horace century by a German physicist and physician, Her-
Barlow proposed the efficient coding hypothesis, an mann von Helmholtz [12].1 He used the term un-
adaptiveprincipleofbrains,whichstatesthatredun- bewusster Schluss (unconscious conclusions) to refer
dancyofinformationintheenvironmentiseliminated to conclusions about the causes of sensory input, ar-
and represented as independent activity in the brain guing that these are dominated by inductive conclu-
[2,3]. Accordingtotheefficientcodinghypothesis,an sionsoriginatingfromexperiencesandanalogyrather
understanding of the statistical structure of natural than deductive logic.2 This concept is now known as
∗Address: Yoshida-honmachi, Sakyo-ku, Kyoto 606- 1Building on earlier work by Francis Bacon, Thomas
8501, Japan; Email: h.shimazaki@i.kyoto-u.ac.jp; URL: Hobbesandothers.
http://www.neuralengine.org 2Helmholtzhimselfconcludesthechapteronrecognitionin
1
1 INTRODUCTION
Helmholtz’sunconsciousinference. Statisticallyopti- into the model as prior knowledge through learning,
malreasoningisachievedbyconstructingaposterior and how this knowledge can act as a top-down mod-
distribution of causes from a Bayesian formula to- ulationsignal,fromperspectivesofmachinelearning,
gether with a hierarchical model (generative model) information-theory,and thermodynamics.
that describes the statistical structure of data gen- Thesemodelingapproaches,however,takeintoac-
eration. The hypothesis that organisms achieve op- count only passive aspects of the brain responding
timal or approximate Bayesian inference using their to presented stimuli. In real world, animals actively
nervoussystemsisgenerallycalledtheBayesianbrain explore the environment to acquire data of the out-
hypothesis[14]. Infact,intaskswheredecisionshave side world. Indeed, ashas been pointedout by many
to be made based on uncertain input stimuli, many scientists and philosophers including Merleau-Ponty
studieshavereportedthathumansandotheranimals and, more recently,Andy Clark,Rodney Brooksand
arrive at conclusions that are close to those from FranciscoValera,thebrainisfirstandforemostade-
the Bayesian statistical inference [15]. Many ideas vice for moving the body, and it is not possible to
have been proposed by theoretical groups regarding concludethetheoryofrecognitionandlearningwith-
mechanismsfor calculatingBayesianposteriordistri- outconsideringorganisms’activeinteractionwiththe
butions with neural systems [15, 16, 17, 18]. environment [37, 38].
Hinton and Dayan et al. proposed an optimiza- Friston’s theory builds on the static recognition
tion algorithm for a hierarchical model called the model to provide a unified view that also includes
Helmholtz machine, and introduced variational free actions [22, 39, 40, 36]. This hypothesis called active
energy as its objective function [19, 20]. Friston et inference assumes that actions are selected based on
al. argued that various related theories in recogni- the principle of least surprise. For example, consider
tion and learning can be handled in a unified way the task of recognizing the book you are holding. To
by the principle of minimizing variational free en- recognize a book using the static hierarchical mod-
ergy (free energy principle) [21, 22, 23, 24, 25, 26]. els (including deep neural networks), it is necessary
Thisprincipleisalsocalledsurpriseminimizationbe- to perform learning by using a large amount of data
cause data is no longer surprising after learning. In obtained by tilting the book, rotating it, examining
the literature of machine learning, the same frame- thecoverandsoon,sothatitispossibletorecognize
work for stochastic latent variable models is called an item as a “book” no matter what state it is in.
variational inference [27, 28]. This framework origi- But how do humans do this? If you do not under-
nates from Dempster et al.’s Expectation Maximiza- standwhatsomething is bylookingonly atthe spine
tion algorithm,and is established as an optimization of the book, you might try turning this object over.
framework of applied models including various hid- When you see the front, you will recognize that it is
den Markov models, latent dirichlet allocation used a book. In this example, the use of actions makes
in natural languageprocessing, and a variationalau- it easier to recognize that the object is a book, even
toencoder used in deep learning. whenusinganinternalmodelthatonly points to the
These models construct a generative model of the cover of the book. When data does not match our
externalworld,whichisahypothesisaboutdatagen- generative model of the world, it is more likely to
eration. Amongthem,predictivecodingtheoryofthe surpriseus(becausethegoodness-of-fitofthedatato
brain [29, 30, 31, 32, 33] hypothesizes that recursive the model is small). We can therefore make changes
hierarchical modules learn the statistical regularity. to the outside world in order to adapt the object to
These modules receive prediction from higher mod- our recognition capabilities and reduce the surprise.
ulesandsendpredictionerrorto the highermodules, This is a way of interpreting behavior based on the
which successfully explained contextual modulation generative model of the world in the brain, and at-
of early visual neurons by the feedback prediction tempts are being made to create a unified theory of
signals [31]. An extended framework called message recognitionand behavior by rewriting actions in this
passing algorithms (belief propagation) on graphical framework,includingthe selectionofactionsbyrein-
models is discussed as computational architecture of forcement learning [41, 40, 42].
the cortex [32,34], inparticularinthe contextofthe In this article, we first introduce the hierarchical
free energy principle [35, 23, 36]. In this article, we modeloftheenvironment,andexplainhowthemodel
will see how information about the data is absorbed is interpreted as a model of the brain. We review
an approximate inference method in machine learn-
his book [13] as follows: “it is the characteristic function of
ing, and explain how it is related to the free energy
theintellecttoformgeneralconceptions, thatis,tosearchfor
principle. Next, we present an overview of learn-
causes;andhenceitcanconceive(begreifen)oftheworldonly
asbeingcausalconnection.” inghierarchicalmodelsfromaninformationtheoretic
2
2 LEARNING HIERARCHICAL MODELS
environment organism
X hidden state, neural activity
measurement
data
W parameters, brain structure
Y
recognition model
q(x|Y) p(x|Y,W)
action
Figure 1: Interaction between organisms and the environment
viewpoint, andexplain how it relatesto the informa- from a distribution p¯(y).4 The symbol X repre-
tion maximization principle (infomax principle) and sents the causative factors behind the generation of
the efficient coding hypothesis, which are the clas- data. Furthermore, W represents the environmen-
sical theories of sensory perception. Finally, from tal factors or contexts that underlie these causative
the framework of statistical mechanics and thermo- factors and data. Assuming the distribution for the
dynamics for entropy maximization, we redefine free causes and environmental factors, the joint distribu-
energybyrevisitingthemodelofrecognition,anddis- tion p(y,x,w) that represents the dependency be-
cuss the formal relationship among statistical learn- tween the data and these factors is called a genera-
ing, minimization of free energy, and the second law tive model. The following hierarchical model is now
of thermodynamics. constructed as a generative model for data:
p(y,x,w)=p(y|x,w)p(x|w)p(w). (1)
2 Learning hierarchical models
In this article, the environmental factors w are
In this section, we introduce the hierarchical models treated as a parameter without assuming a distribu-
used in the fields of machine learning and statistics, tion.5 Inthiscase,p(y|x,w)iscalledtheobservation
and consider the meaning of introducing hierarchi- model, and p(x|w) is called the priordistribution. A
cal models as a model of the brain. Next, we define model of the data distribution can be derived by the
statistical learning and clarify difficulties of learning following equation,
the hierarchical models to motivate the need of ap-
proximate inference methods that will be described
p(y|w)= p(y,x|w)dx. (2)
in detail in the next section. Z
Thisoperationiscalledmarginalizationoflatentvari-
2.1 Hierarchical models
ables.
Organisms and machines can infer underlying causes A generative model is constructed based on an as-
fromtheobserveddata,andcanusethisknowledgein sumedhierarchicalstructure for the data generation,
performing their next actions(see Fig.1). It washy- andthisgenerativemodelcanbeusedtoestimateun-
pothesized that organisms achieve these recognition derlying causes from data according to the following
and behaviors by constructing a model on causal re- Bayes’theorem:
lationships in the outside world.3 Consider a model
p(Y|x,w)p(x|w)
that assumes the following hierarchical causal rela- p(x|Y,w)= . (3)
p(Y|w)
tionship. Let Y be the data obtained from the out-
side world, and assume that this data is sampled
Thisisthedistributionofcausativefactorsforagiven
3Here the ‘cause’ or ‘causative factor’ is the one assumed setofdata,andiscalledtheposteriordistribution. In
in the model or brain. To verify if the assumed causes in-
deed causally influence data, we need to intervene the world 4Inthisarticle,wewilluseuppercaseletterstodenoteran-
to control the causes. It is an act to test the causal model of domvariables,andlowercaseletterstodenote variables.
the world. We will touch upon action selection based on the 5x may be called the parameter of the observation model.
hierarchicalmodelinthenextsection. Inthiscase,w iscalledthehyper-parameter.
3
2 LEARNING HIERARCHICAL MODELS
thecaseofmachinelearning,estimationbasedonthe Symbols Descriptions
posterior distribution may be performed by using its Y, y data
analytical formula, or by using sampling techniques. sensory stimulus
Organisms are also able to act based on inference X,x cause, latent variable
and prediction, whereby sensory data is encoded in neural activity
the form of neural activity and the network struc- W,w parameter, context
ture that supports it; therefore it is likely that the brain structure
brain implements functions similar to the Bayesian φ parameter, basis function
inference [14]. Below we discuss how we consider the brain structure
hierarchical model as a model of the brain in this λ parameter in the prior
article.
As a model of the brain, the posterior distribution ω basis function, regularization
ofthelatentvariableXisinterpretedasneuralactiv- structure of spontaneous activity
ity caused by the stimulus Y. The prior distribution β regularization
of X is neuralactivity exposed to the variousstimuli feedback modulation
in natural environment. To explain this in detail, we p(Y|w) marginal likelihood, evidence
introduce the following simplified hierarchical struc-
ture as an internal model of the world in the brain: p(Y,X|w) complete data likelihood
p(y,x|w)=p(y|x,φ)p(x|λ), (4) p(y,x|w) generative model
where φ is a parameter of the observation model, λ
p(y|x,φ) observation model
is a parameter of the prior distribution, and w =
(φ,λ).6 The observation model p(y|x,φ) represents
p(x|λ) prior distribution
how data is expressed by combinations of neuronal
spontaneous or modulation activity
activity X. The parameter φ can be the basis func-
p(x|Y,w) posterior distribution
tionsforrepresentingthedata. Thepriordistribution
evoked activity
p(x|λ) represents constraints on the neural activity.
q(x|Y) approximate posterior distribution
Next, using this generative model, the posterior
recognition model, evoked activity
distribution of the latent variable is obtained as
L[q,p] lower bound, variational lower bound,
p(Y|x,φ)p(x|λ) evidence lower bound (ELBO)
p(x|Y,w)= . (5)
p(Y|w) Q[q,p] expected complete data
log-likelihood, Q-function
The posterior distribution of X represents the neu- H[q] entropy
ral activity in response to stimulus Y.7 It is formed
by combination of the observation model and prior
distribution. Thus we can interpret that the poste-
neural activity. For example, if X is assumed to be
rior is constructed by modulating the internalneural
the activity of an area in the early visual cortex, the
activity represented as the prior distribution by ob-
influence of the activity from other areas (such as
serving data. In this case, we identify the prior as
feedback input from lateral neurons or upper areas)
spontaneous activity of neurons [43]. Alternatively,
can be expressed by the prior distribution.
wemayconsiderthepriordistributionconstrainsthe
neural activity; therefore act as a bias signal on the The above provides a view to interpret the neu-
ral activity as dynamics to achieve inference of the
6From the original hierarchical model, this hierarchical
causative factors in the outside world. However, it
model is obtained as follows. First, the observation model is
obtainedasp(y|x,φ)undertheassumptionthatyiscondition- should be noted that the flow of information in our
ally independent of λ given x. Second, the prior distribution physiologicalsystems is opposite: external stimuli or
isobtainedasp(x|λ)giventhatxdoesnotdependonφ. Note causes make peripheral sensory receptors respond,
thatxisindependentfromφbecausethenodeythatconnects
which successively activate peripheral and central
thesetwoismarginalized.
7Alternatively, often inliteratureonpredictivecoding and nervous systems. How this forward direction of the
the free energy principle, activity rates (firing rates) of neu- informationprocessingcanbeframedintotheinverse
rons refers to maximum a posteriori (MAP) estimate of the
inference framework will be discussed in the section
posterior distributionas a proxy of the distribution. Here we
thatrelatestheinferenceframeworkwithinformation
take aview that neural activity represents a samplefromthe
posteriordistribution. theory.
4
2 LEARNING HIERARCHICAL MODELS
2.2 Learning Y
Learningrefers to the process ofadjusting the model
parameters so that the true data distribution and
the model distribution become as close as possible.
Here it is necessary to define the concept of close-
ness for distributions. We use the Kullback-Leibler
divergence,accordingto which the closeness ofa dis-
tribution to the true data distribution is defined as
follows:
p(Y|w)
p¯(y)
KL[p¯(y)||p(y|w)]≡ p¯(y)log dy
Z p(y|w)
=E logp¯(Y)−E logp(Y|w). (6)
Y Y
Throughout this article, E represents the expec-
Y
tation by the true data distribution p¯(y).8 We
want to reduce this KL divergence by modifying
Figure 2: Maximum likelihood estimation
the model through learning, and this can be done
by maximizing E logp(Y|w) in the second term.
Y
The true data distribution E Y is unknown, but this ical Bayes method:
term can be estimated by replacing it with the dis-
tribution of the observed data (empirical distribu- p(x|Y,W∗)=
p(Y|x,W∗)p(x|W∗)
. (8)
tion). When an independent sample has been ob- p(Y|W∗)
tained, the empirical distribution can be written as
p(y)=n−1 n δ(y−Y ). For the sake of simplic- This estimation method is a hybrid of the Bayesian
i=1 i
inferenceandmaximumlikelihoodestimation. Inthis
ity, we use YPto represent either a set of all samples
way, the empirical Bayes method that incorporates
{Y ,Y ,...,Y } or one sample Y (i = 1,...,n)
1 2 n i
the “experience” of data-based learning into prior
(see discussion below).
knowledge is an algorithm that realizes Helmholtz’s
Thus logp(Y|w) is the estimated value of the sec-
unconscious inference.
ond term in Eq. 6, and is a function of w since the
But unfortunately, this direct empirical Bayes
data point Y is given. p(Y|w) is called a marginal
method often runs into difficulties. To obtain the
likelihoodfunction,anditslogarithmiscalledthelog
marginal likelihood of Eq. 2, it is necessary to inte-
marginal likelihood function. The process of deter-
grateoverthecausativefactorsx,butitisdifficultto
mining parameters that maximize the marginal like-
performthisintegrationanalyticallyexceptwhenthe
lihoodfunctionis calledthe TypeII maximumlikeli-
observation model and prior distribution are normal
hood estimation. The resulting maximum likelihood
distributions orspecial distributions. If the marginal
estimate value is as follows:
likelihood and its gradient cannot be obtained, then
W∗ =argmaxlogp(Y|w). (7) itwillnotbepossibletoperformparameteroptimiza-
w tion. Also, since the marginal likelihood appears as
a normalizationtermin the Bayes’theoremofEq. 8,
Here the marginal likelihood function is given by
it will also be impossible to calculate the posterior
Eq.2. Themaximumlikelihoodestimationmethodis
distribution.
the process of choosing the model distribution clos-
In statistics and machine learning, methods were
est to sample data in terms of the KL divergence
therefore devised for approximately optimizing pa-
(Fig.2). It is a projectionofa sample froma higher-
rametersandconstructingthe posteriordistribution.
dimensional data distribution to a restricted model
The algorithm used for this approximate inference is
space.
described below. Since the inference processes in the
The method for constructing a posterior distribu-
brain’s neural network should be performed approx-
tion (Eq. 3) using the generative model with the pa-
imately, algorithms for learning approximate infer-
rameter W∗ that is empirically obtained by learning
ence model in the statistics and machine learning is
(maximumlikelihoodestimation)iscalledtheempir-
instructivewhenweconsidermodelsofthebrain[21].
8Notethatthisisnottheexpectedvalueofthedatagener- Finally, it is important to note that learning the
atedbythemodel. parameters can be performed using different sets of
5
3 APPROXIMATE INFERENCE
receive feedback/recurrent modulation via top-down
or lateral connections, which plays an essential role
  in perceptual experiences [44, 45], attention [46, 47],
and reward modulation [48] (see [49] for a review).
Thisfeedback/recurrentmodulationisinterpretedas
a prior signal that biases the observationmodel, and
 X construct the posterior (evoked activity of neurons).
Inmachinelearning,thesameapproachthatoptimize
priorparametersforeachsampleis knownasthe au-
tomaticrelevancedetermination(ARD)method[50],
and is often used to represent the data by imposing
Y sparsity to basis functions.
N
3 Approximate inference
Figure3: Graphicalrepresentationofthehierarchical Inthissection,wewillexplaintheapproximateinfer-
model. encemethodsthatplayanimportantroleinmachine
learning, known as the Expectation-Maximization
(EM) algorithm. This classical algorithm is a basis
data, namely either an entire set of data or each of variational methods which are standard tools to
sample. Although expressions in the above and fol- learn hierarchicalmodels under the principle of min-
lowing descriptions do not distinguish these differ- imizing variational free energy. Understanding the
ences for the sake of simplicity, it should be noted logic of fitting the model in the EM algorithm thus
that these different optimization strategies result in provides the basis of constructing advanced genera-
different learning dynamics that operate in distinct tive models, andis also instructive when we consider
time-scales, and have significant implications of the recognitionandlearning happening in the brain[21].
parametersasamodelofthebrain. Inthisarticle,we A detailed description of the EM algorithm can be
assumethattheparametersintheobservationmodel foundinstandardmachinelearningtextbooksaswell
φarelearnedfromanentiresetoftheobserveddata, [51, 50].
{Y ,Y ,...,Y }. The graphical representation of
1 2 n
the model is shown in Fig. 3. For example, the ba-
3.1 Recognition model and lower
sis functions to represent images are learned from a
bound
set of many visual scenes exposed to an animal. In
organisms, it is expected that learning with multi-
Instead of using an exact posterior distribution, the
ple samples are performed in an online manner that
approximateinference methodconsidersanotherdis-
marginallyupdates parametersaccordingto the con-
tribution that is easier to handle, and uses it to ap-
tribution by each sample in turn. Thus this learning
proximate the posterior distribution:
is gradual. The same approach, called the stochastic
gradientdescent (SGD) method, is taken in machine
q(x|Y)≈p(x|Y,w). (9)
learning to deal with a large number of samples.
In contrast, we can consider two types of param- This approximate posterior distribution is also re-
eters in the prior distribution λ = {β,ω}: one set ferred to as a recognition model. Using this recogni-
of parameters ω are optimized by using all samples, tion model, the logarithmic marginal likelihood can
and the others β are optimized for each sample of be decomposed as follows [52]:
thedata. Forexample,theparametersthatrepresent
spontaneousactivityofneuronsmaybe learnedfrom logp(Y|w)
manysamples[43],whereastheparametersthatmod-
= q(x|Y)logp(Y|w)dx
ulatesrepresentationbytheneuralactivityaccording
Z
to the current context needs to be learned from each
p(Y,x|w)
sample. Thislatterlearningisfasterthantheothers. = q(x|Y)log dx
Z p(x|Y,w)
Inthiscase,learningthepriorplaysanimportantrole
q(x|Y)p(Y,x|w)
in constructing a posterior distribution that is tai- = q(x|Y)log dx
loredforanindividualsample. Earlysensoryneurons Z q(x|Y)p(x|Y,w)
6
3 APPROXIMATE INFERENCE
p(Y,x|w)
The lower bound can be decomposed as follows:
= q(x|Y)log dx
Z q(x|Y)
L[q,p]= q(x|Y)logp(Y,x|w)dx
Lowerbound
Z
| {z q(x|Y)}
+ q(x|Y)log dx. (10)
Z p(x|Y,w) Q-function
| {z }
− q(x|Y)logq(x|Y)dx. (14)
KLdivergence Z
| {z }
In the first equation, the term q(x|Y)dx = 1 Entropy
| {z }
is inserted. The second equationRuses the relation
Here, the first term is called the expected complete
p(Y|w)=p(Y,x|w)/p(x|Y,w)basedontheformula
data log-likelihood function or Q-function:
of a posterior distribution (see Eq. 3). In the third
equation,arecognitionmodelisinsertedintothelog-
Q[q,p]≡ q(x|Y)logp(Y,x|w)dθ. (15)
arithm. Z
Here, the first term obtained by the last equation,
The second term is the entropy of the recognition
model.
p(Y,x|w)
L[q,p]≡ q(x|Y)log dx, (11)
Z q(x|Y)
H[q]≡− q(x|Y)logq(x|Y)dx (16)
Z
is called the evidence lower bound (ELBO) or vari-
ational lower bound, and plays a central role in this Using these equations, the EM algorithm alternates
article. We will simply refer to it as the lower bound betweenoptimizing the approximateposteriordistri-
inthisarticle. Thenegativevalueofthelowerbound bution and optimizing the parameters [53]. The ac-
is called the variational free energy, which is the ob- tual steps of the EM algorithm are described below.
jective function in the free energy principle. In gen-
eral, the lower bound L[q,p] is a functional of the 3.2 EM algorithm
recognition model q(x|Y) and the generative model
The EM algorithm alternates between two steps
p(Y,x|w). The second term is the KL divergence
called the E-step and the M-step. Figure 4 shows
between the recognitionmodel (an approximatepos-
a schematic representation of these steps.
terior distribution) and the exact posterior distribu-
E-step: In the E-step, the recognition model is
tion.9 In summary, the log marginallikelihood is de-
optimized to provide good approximation of the ex-
composed as follows:
act posterior distribution while the generative model
isfixed. Thepurposeofthisstepistoensurethatthe
logp(Y|w)=L[q,p]+KL[q(x|Y)||p(x|Y,w)]. (12)
lower bound provides a tight bound on the marginal
likelihood. First, note that the parameter w of the
Note that L[q,p] is called the lower bound because
generative model is fixed, so the marginal likelihood
KL divergence takes a non-negative value, so the log
logp(Y|w) is constant. In this case, according to
marginal likelihood function is bound by this func-
Eq. 12, when KL divergence is reduced by approxi-
tion.10
mating the recognition model to the exact posterior
distribution, the lower bound becomes correspond-
logp(Y|w)≥L[q,p]. (13)
ingly larger and approaches the log marginal likeli-
9Theexpectedvalueofthistermaccordingtop¯(y)iscalled hood function.
the conditional KL divergence. Thus the second term is an Many methods have been proposed for approxi-
estimateoftheconditionalKLdivergence. mating the posterior distributions, although this ar-
10The lower bound L[q,p] can also be obtained using
ticle will not go into the details of these methods.
Jensen’sinequalityas:
Forexample,stochasticmethodsincludeMonteCarlo
logp(Y|w)=log p(Y,x|w)dx methods, and deterministic methods include Laplace
Z
approximation (approximation by a Gaussian distri-
p(Y,x|w)
=log q(x|Y) dx bution), variational approximation (mean field ap-
Z q(x|Y)
proximation),andexpectationpropagationmethods.
p(Y,x|w)
≥ q(x|Y)log dx M-step: The aim of the M-step is to increase
Z q(x|Y)
the marginal likelihood by optimizing the parameter
≡L[q,p].
w. In this step, the recognition model is fixed. It
is presumed that optimization in the E-step results
7
3 APPROXIMATE INFERENCE
E-step M-step
0 0
l(w)
KL
logp(Y
fix
|w
ed
) logp(Y|w)
L[q,p]
KL
L[q,p]
KL
L[q,p]
KL
L[q,p]
fixed optimized
Inference L[q,p]=logp(Y|w) KL[q(x|Y)|p(x|Y,w)]
(E-step)
Lower bound marginal log-likelihood KL between approx. and exact posterior
p(Y,x|w)
L[q,p] q(x|Y)log dx
q(x|Y) optimized fixed
Learning L[q,p]= q(x|Y)logp(Y,x|w)dz+H[q(x|Y)]
(M-step)
expected complete data log-likelihood entropy
optimized optimized
L[q,p]= q(x|Y)logp(Y|x,w)dz KL[q(x|Y)|p(x|w)]
accuracy complexity
Figure 4: The EM algorithm
in the best approximation of the exact posterior dis- imize the Q-function. PerformingE-stepand M-step
tribution p(x|Y,w) within the range of the model alternately therefore causes the lower bound to in-
assumed for the recognition model q(x|Y), therefore crease monotonically, which is expected to increase
the KL divergence of these two distributions (second the marginal likelihood. This justifies changing the
termofEq.12)isminimized. Inthiscase,theKLdi- objectivefunctionfromthemarginallikelihoodtothe
vergenceis expected to increasedue to the changein lower bound L[q,p]. As in the studies by Friston et
the exact posterior distribution caused by change of al., we may construct a theory that starts from min-
the parameter w, which then contributes to increas- imization of the variational free energy that is the
ing the marginal likelihood. Therefore, the change negative lower bound.
of parameterscan be performedso as to increase the
first term of Eq. 12, i.e., the lower bound. Inciden-
tally, we have already seen that the lower bound can
be decomposed as follows:
3.3 Adaptation of the generative
L[q,p]=Q[q,p]+H[q]. (17)
model and behavior
Since therecognitionmodelisnowfixed,onlythe Q-
functionofthe firsttermis dependentonthe param-
eters. Therefore, in the M-step, we use parameters The above description shows how approximate infer-
that maximize the Q-function. ence is achieved by the EM algorithm. In the fol-
In summary, when using E-step to optimize the lowing, we will look into details of the learning step,
approximate posterior distribution, the lower bound considering cases where actions are included in this
increases because the KL-divergence decreases with reasoning. By rearranging the expressions discussed
constant marginal likelihood. In M-step, the lower above in terms of the lower bound L[q,p], we ob-
boundisincreasedbyselectingparametersthatmax- tain the following equations for E-step and M-step,
8
4 INFORMATION-THEORETIC APPROACHES TO ADAPTATION
respectively: Now let’s consider the complexity (the second
term). Complexityisminimizedbybringingtheprior
L[q,p]=logp(Y|w)−KL[q(x|Y)|p(x|Y,w)],
distribution closer to the posterior distribution. In
L[q,p]= q(x|Y)logp(Y,x|w)dx+H[q]. particular, when the approximate posterior distribu-
Z tion is an exact posterior distribution, we have the
(18) relation
Furthermore,the lowerbound canbe decomposedas p(x|Y,w)
p(x|Y,w)log dx
follows: Z p(x|w)
L[q,p]= q(x|Y)log
p(Y,x|w)
dx =KL[p(x|Y,w)||p(x|w)], (20)
Z q(x|Y)
which is called a Bayesian surprise [54]. This value
p(Y|x,w)p(x|w)
= q(x|Y)log dx quantifies how much the recognition model changes
Z q(x|Y)
whenthedataY isprovided,giventheparameterw.
= q(x|Y)logp(Y|x,w)dx The EM algorithm therefore performs approximate
Z minimization of the Bayesian surprise. This means
Accuracy thatsurprisesinthe dataareeliminatedby adapting
| {z q(x|Y}) a prior distribution as a result of learning.
− q(x|Y)log dx (19) This process can represent the adaptability of or-
Z p(x|w)
ganisms whereby the brain adapts to environmen-
Complexity tal factors or contexts, and incorporates them into
| {z }
Here,the firsttermontherightsideofthelastequa- its internal model. In particular, it was shown that
tion is an expectation of the log observation model the distance between the spontaneous firing activity
by the recognition model, which represents the aver- and stimulus response activity of the visual cortex
age goodness-of-fit of the observation model. This is of ferrets decreases during the first 5 months of life
sometimes referred to as the accuracy of the model. [43]. The sampling hypothesis suggests that this ob-
The secondterm is the KL divergenceof the approx- servation manifests that the prior distribution and
imate posterior distribution and prior distribution, posterior distribution become closer due to learning
which is sometimes referred to as the complexity of by identifying spontaneous activity as samples from
the model. We discuss these two terms below. thepriordistributionandstimulus-evokedactivityas
First, let us consider the accuracy(the first term). samples from the posterior distribution. The next
In M-step, the parameters of the observation model section explains the adaptation process more gener-
are optimized by maximizing the accuracy. For ex- ally from the viewpoint of information theory.
ample, parameters such as those of the basis func-
tions are optimized, thereby improving the explana-
4 Information-theoretic ap-
tory accuracy of the data. Not only that, Friston et
al. hypothesized that actions are also chosen as to proaches to adaptation
maximizetheaccuracy[22,39,40,36]. Theinference
problem in which action is involved is studied as an In this section, we treat the learning process as
active inference problem, and it often refers to the communicationthroughaninformationchannel, and
selectionofactionaccordingtomaximizingthelower lookatthe relationshipbetweenthe maximizationof
bound(orminimizingthevariationalfreeenergy). In marginallikelihood in the previous section and max-
this case, the behavior of an agent is generated ac- imization of information-theoretic quantities. Based
cording to its generative model [41, 40, 42]. Actions onthis,wewillexaminetherelationshipbetweenthe
selected by this principle are expected to alter the classical theory of perception [2, 5, 55] that is based
outside world so that it is more predictable for the on the information maximization principle (Infomax
agent. Notethatwhenweintroduceactionsasaway principle) and the approachwith a generative model
ofchangingthedatagenerationmechanism,thedata in the previous section. This can deepen the under-
distribution p¯(x) – which has so far remained fixed – standing of the relationship between the hypothesis
isforcedtochange. However,organismsoragentsare of the brain as a nonlinear computing machine and
not able to access the true data distribution. There- that of the brain as an inference machine. See also
fore,the onlywaytorespondisbyupdating thegen- [30, 20, 56, 26] for the relationship between the gen-
erative model, and it is necessary for the generative erative model and neural networks, and [23, 24, 57]
modeltoinclude statementsofhowthe generationof forthe relationshipbetweenthe free energyprinciple
data is affected by actions. and information theory.
9
4 INFORMATION-THEORETIC APPROACHESTO ADAPTATION
4.1 Maximization of mutual informa-
W
tion and optimization of the gen-
erative model
I(Y;W)
In this section, data Y is regarded as the input,
and the parameter W of the generative model is re-
garded as the output. Here, we want to maximize
the amount of mutual information between the ran-
dom variableY (data) andthe model parameterW.
Themutualinformationcanbe expressedintermsof Y X
entropy and conditional entropy as follows:
I(Y;W)=H(Y)−H(Y|W)
=H(Y)+E E logp(Y|W). (21)
Y W|Y
= -
The first term on the right side in Eq. 21 is the en- I(Y;W) I(Y;X,W) I(X;Y|W)
tropyofthedatadistributionH(Y)≡−E logp¯(Y),
Y
and is constant when the data distribution is fixed.
In this section, we will not consider changes to the
data distribution caused by actions. Let us consider
the second term on the right side. In the previous
section, we considered the reverse process from the
outputWtotheinputYasthedatagenerationpro-
cessintheinternalmodel. Usinglatentvariables,this
path was obtained as the marginal distribution:
p(y|w)= p(y|x,w)p(x|w)dx. (22) Figure5: Venndiagramanddecompositionofmutual
Z
information
The second term in Eq. 21 is the expectation of log
ofthisfunctionwithrespecttothejointdistribution, sensorydataY andthe parameterW canbe decom-
p(y,w)=p¯(y)p(w|y). The hierarchicalmodel ofthe posed into two factors: the mutual information rep-
previous section possesses the parameter w, which resenting the encoding of sensory data Y by latent
was learned from the data. This is a point estimate, variables X and parameters W (first term), and the
which means that the distribution of w for a given conditional mutual information between the latent
set of data is given by p(w|Y) = δ(w−W⋆), where variables X and data Y, given prerequisite knowl-
δ(·) is the Dirac delta function. Note that W⋆ is a edge acquired by the parameter W (second term).11
function of Y. In this way, the second term on the Below, we revisit the inference algorithm of the pre-
right side of Eq. 21 becomes E Y logp(Y|W⋆). Fur- vioussection,andclarifythattheyaimatoptimizing
ther, by replacing the expected value of Y with the these information-theoretic quantities.
empirical distribution, we can use the data Y to ob- Based on Eq. 19, the marginal likelihood can be
tain an estimate of the second term, which is the log expressed as
marginallikelihoodfunction. Thismeansthatwecan
expect the mutualinformationbetween Y andW to logp(Y|W⋆)=E logp(Y|X,W⋆)
X|Y,W⋆
be maximized by adopting the maximum likelihood −KL[p(x|Y,W⋆)kp(x|W⋆)],
estimate W∗ as a point estimation.
(24)
We note that, using a hidden state X, the mutual
information between Y and W is generally decom- where it is assumed that an exact posterior distribu-
posed as tion has been obtained. The first term represents
the accuracy, and the second term represents the
I(Y;W)=I(Y;X,W)−I(X;Y|W). (23)
11Inthiscase,onlythecostofencodingisconsidered. Tishby
et al.’s information bottleneck theory, which builds on Shan-
See the Venn diagram (Fig. 5) for the visualization
non’sratedistortiontheory,playsacomplementaryroleinthe
of this decomposition. From this decomposition, it
theoryofinformationmaximizationundertheconstraintthat
is foundthatthe mutualinformationI(Y;W) inthe thecostofdecodingisgivenforaparticulargenerationmodel.
10
4 INFORMATION-THEORETIC APPROACHES TO ADAPTATION
Bayesian surprise. We will confirm that maximiza- By adding the entropy of the data H(Y) on both
tionoftheaccuracyandminimizationoftheBayesian sides of Eq. 30, we obtain Eq. 23.13
surprisecorrespondtomaximizationofthe firstterm By comparing Eq. 24 with Eq. 23, we can clearly
and minimization of the second term in Eq. 23, re- understandobjectivesthatoptimizationofeachterm
spectively. in Eq. 24 aims at during the learning. First, while
First we note that E represents expecta- keepinginmindtheexistenceofanunknownconstant
W|Y
tion by the posterior distribution of W, namely H(Y), maximizing the first term on the right side of
p(w|Y) = δ(w−W⋆). Therefore, the log marginal Eq.24 (accuracy)maximizes the (estimated) mutual
likelihood can be expressed as logp(Y|W⋆) = informationrelatedtotheencodingfromYtoXand
E logp(Y|W). By taking the expectation by W. Second, minimization of complexity/Bayesian
W|Y
E Y , we can see that the left side of Eq. 24 corre- surprise in the second term of Eq. 24 minimizes the
sponds to (estimated) mutual information between the neural
activityXandthedataY,conditionalontheparam-
E Y E W|Y logp(Y|W)=−H(Y|W). (25) eterWofthegenerativemodel. Thismeansthatthe
information of the input data Y is absorbed during
Similarly, expectation of the first term on the right
the process of learning the parameter W, and as a
side by data distribution is
result, the neuralactivity X no longer has any infor-
mation about the input data Y other than what is
E Y E W|Y E X|Y,W logp(Y|X,W)=−H(Y|X,W). held by W.
(26)
4.2 Infomax principle for optimiza-
Second,theexpectationoftheBayesiansurprise(the
tion of nonlinear networks
second term on the right side) by the data distribu-
tion becomes the conditional mutual information:
In this subsection, we review the classical theory of
sensory perception. Based on this, we will consider
E E KL[p(x|Y,W)kp(x|W)]=I(X;Y|W).
Y W|Y its relation to the approach based on the generative
(27) model. Here we assume noiseless communication be-
tween the input Y and the output X, and that they
Note thatthe mutualinformationX andY available have the same dimension. For the noiseless channel,
under Z is computed from the KL divergence:12 we can representX as a nonlinear function of Y, us-
ing x = f(y;ϕ), for which a neural network can be
I(X;Y|Z)
used. Hereϕaretheparametersthatdefinethenon-
p(x,y|z) linear function (e.g., weights of a neural network),
= p(x,y,z)log dxdydz
ZZZ p(x|z)p(y|z) and comprise receptive fields of the neurons.
=E E KL[p(y|X,Z)||p(y|Z)] (29) The adaptationof the neural activity X to the ex-
X Z|X
ternalinputYbymaximizingthemutualinformation
Themutualinformationfordiscreterandomvariables I(Y;X) is known as the infomax principle [5]. This
can also be defined in the same way by replacing the mutual information is expressed in terms of entropy
integral with a summation. Eq. 27 is an extension as
of this formula to multivariate variables. In other
words,Bayesiansurpriseisanestimateofconditional I(Y;X)=H(X)−H(X|Y). (32)
mutual information. Taken together, expectation of
Eq. 24 by E is simplified to Inanoiselesschannel,thesecondtermofEq.32isnot
Y
dependentonthenonlinearfunctionf(y;ϕ),soitcan
−H(Y|W)=−H(Y|X,W)−I(X;Y|W). (30)
13 Giventhehierarchicalmodelofthebrain(Eq.4),Eq.23
12In general, the mutual information of continuous random canbefurtherwrittenas
variablesXandYisgivenby
I(Y;φ,λ)=I(Y;X,φ)−I(X;Y,φ|λ). (31)
p(x,y)
I(X;Y)= p(x,y)log dxdy This is obtained as follows. Under the assumption of the hi-
ZZ p(x)p(y)
erarchical model shown in Fig. 3, we obtain I(Y;X,φ,λ) =
p(y|x) I(Y;X,φ) since X is conditionally independent of λ. Using
= p(x)p(y|x)log dxdy
ZZ p(y) the general decomposition rule of Eq. 23 on the distributions
conditional on λ, we have I(Y;X|φ,λ) = I(X;Y,φ|λ) −
=EXKL[p(y|X)||p(y)] (28)
I(X;φ|λ) = I(X;Y,φ|λ). Here we used I(X;φ|λ) = 0 be-
causeXandφareindependent ifY ismarginalized.
11
4 INFORMATION-THEORETIC APPROACHESTO ADAPTATION
be ignored in optimization.14 Therefore, maximizing A nonlinear function
the mutual information is equivalent to maximizing
the entropy of the output X.
The method of optimizing parameter ϕ based on e
this principle is known as independent component
y
r
at Adaptation
analysis (ICA) used for blind signal separation[55]. vit
That is, the parameter ϕ is updated using the fol-
cti
A
lowing gradient,
∂I(Y;X) ∂H(X)
= . (33)
∂ϕ ∂ϕ Stimulus distribution
Here, the entropy of X due to the stochastic data Y
is given by
y
H(X)=H(Y)+E Y logdet
∂f(
∂
y
y
;ϕ)
(cid:12) , (34) e n
sit
(cid:12)y=Y D
(cid:12)
(cid:12)
because p(y) = p(x) ∂x , where ∂x = ∂f(y;ϕ) is a
∂y ∂y ∂y
(cid:12) (cid:12)
Jacobi matrix used fo(cid:12)r th(cid:12)e change of variables, and
(cid:12) (cid:12) Stimulus value
|·| =det· denotes a determinant. Using Eqs. 33 and
34,andreplacingtheexpectationofdatawithasam-
ple Y, the learning rule is obtained as
Figure 6: Nonlinear functions and adaptation
dϕ ∂ ∂f(y;ϕ)
∝ logdet . (35)
dt ∂ϕ ∂y (cid:12)
(cid:12)y=Y aggregates external signals and converts them into
(cid:12)
The mutual information ma(cid:12)ximization based on independentrepresentations,is sometimescalledfac-
maximizingtheoutputentropyfollowstheframework torial coding.
of the efficient coding hypothesis proposed by Ho- Next, from the second term, it can be seen that in
race Barlow [2, 3]. On the assumption of a noiseless ordertoincreasethemutualinformationbetweenthe
channel, Barlow proposed the principle of maximiz- input and output, the entropy of each random vari-
ing entropy of X (i.e., activity of neurons) as a goal able ofthe output shouldbe increased. Since the en-
of encoding sensory data such as tactile and vision. tropyismaximizedwhentherandomvariableshavea
The efficient coding hypothesis is also called the re- uniform distribution, the parameter ϕ should be ad-
dundancyreductionhypothesissinceitinvolveselim- justedsoastoobtainauniformoutputfromthenon-
inating redundancy from data as shown below. linear function X = f(Y;ϕ). For example, it is the
To explain this, let’s see that the multivariate en- mostappropriateiftheactivityofindividualneurons
tropy can be decomposed as follows. iscovereduniformlyoveritsdynamicrange. Consider
aone-dimensionalsensoryinputp¯(y)forsimplicity. If
d
we wish to construct a uniform distribution that has
H(X)=−I(X ;X ;...;X )+ H(X ). (36)
1 2 d i an upper limit as an output X =f(Y;ϕ), we should
Xi=1
use the nonlinear function f(y;ϕ)= y p¯(y′)dy′ or
−∞
Here,the firsttermonthe rightsideisthe multivari- a constant multiple thereof. This isRbecause substi-
ate mutual information, defined as I(X 1 ;...;X d ) = tutingarandomvariableY whosedistributionisp¯(y)
KL[p(X||Πd i=1 p(X i )]. Two conclusions can be de- to its own cumulative distribution function results
rived from this equation. From the first term, we in a uniform distribution of values over the range
cansee thatin orderto increasethe mutual informa- [0,1].15 This nonlinear transformation is sometimes
tion at the inputs and outputs, it is better to have a called histogram equalization.
smaller quantity of mutual information between the According to the efficient coding hypothesis, or-
outputs. That is, the parameter ϕ should be ad- ganismsarethoughttoadaptitsnonlinearactivation
justed so that the output variables become indepen-
dent random variables. This sort of encoding, which 15IfX isarandom variablefollowingtheprobabilitydistri-
x
butionfunctionFX(x)=
−∞
fX(s)ds, thenU =FX(X) has
14The conditional entropy is 0 for discrete distributions, or a uniform distribution. IRt is also used as a way of creating
negative infinity for continuous distributions if the channel is arbitrarysampledistributions fromuniform random numbers
−1
noiseless. (inversefunctionmethod): X =FX (U)
12
4 INFORMATION-THEORETIC APPROACHES TO ADAPTATION
functions of neurons to the distribution function of marginal likelihood function is written as17
the input data so they can use the output indepen-
dently anduniformlyoveritsdynamic range. Inpar- p(Y|w)= δ(Y−g(x;φ))π(x|λ)dx
ticular, horizontal movements or multiplications are Z
added to basic nonlinear input/output functions to ∂f(y;ϕ)
=π(X)·det . (38)
rapidly adapt to the environment. This process is ∂y (cid:12)
(cid:12)y=Y
called gain control (see Fig. 6). In insect retinal and (cid:12)
(cid:12)
olfactory nerve cells [7, 58] and mammalian visual Here the prior distribution for X is denoted by π(·)
neurons [59, 60, 61], the gain control is performed to avoid confusion. In the right hand side of this
to adapt to changes in the environment. Further- equation,thesensorydataY isprojectedtotheneu-
more,the gaincontrolexplains higher-levelcognitive ral activity X by the nonlinear function x=f(y;ϕ),
functions ofa brainsuchas attentionandcoordinate andthe likelihoodofthe sensorydata Y is now eval-
transformation of viewpoint [47, 62, 63, 64]. uated using the neural activity X with respect to its
prior distribution. Under the maximum likelihood
While the gain control allows fast adaptation to principle, learning of the nonlinear function is per-
changing environment, nonlinear functions them- formed so that the neural activity X fits to the prior
selves must be acquired from the data during learn- distribution. At the same time, the parameter λ of
ing processes in a longer time-scale. To capture the the prior distribution is optimized to fit the neural
non-Gaussian nature of sensory inputs, it is neces- activity. Theselearningprocessescorrespondtoopti-
saryto adaptivelygeneratea nonlinearfunctionthat mization of the observation model and the prior dis-
matchesupthehigherorderstatisticsofthedistribu- tribution discussed in the previous section, respec-
tion. For the distribution whose dimension is higher tively. Note that if we assume a flat prior, we obtain
than two, the higher-ordercorrelations (higher-order the same gradient in Eq. 35 for the infomax princi-
statistics among the variables) in the distribution plefromtheprincipleofmaximizingthelogmarginal
must be captured. In this way, it is hypothesized likelihood. This indicates that, in the approach with
that nonlinear functions that are expressed through the generativemodel, the optimal nonlinear function
the nonlinearity of neurons (nonlinear summation x = f(y;ϕ) is modulated by the prior distribution,
of synaptic inputs at dendrites, firing characteristics which can be interpreted as the gain modulation.
basedonthresholdmechanisms,andnetworkdynam- Onecanarriveatthegenerativemodelinvestigated
ics)areadaptedtothecharacteristicsofthedistribu- in the previous section by generalizing the above de-
tion of input data [65, 11]. terministic observation model to noisy observation
models togather with non-bijective nonlinear func-
Finally, we examine how the above arguments on tions. Often the mean µ of the observation model
the infomax principle can be generalized to the ap- is modeled as µ = g(Xφ), where φ plays the role
proach with the generative model. We investigated
of linear basis functions. Such a nonlinear function
optimization of the nonlinear function x = f(y;ϕ), g(·) is called a link function in statistics. Olshausen
assuming a noiseless channel and equal dimensions
& Filed introduced a sparse prior distribution to the
for y and x. For simplicity, here we assume that
latent variables of the Gaussian observation model
the nonlinear function is bijective functions (one-to-
with a linear link function, and make the basis func-
one functions), and define the inverse function as
tions of the observation model learned from natural
y = g(x;φ). The parameter φ represents how the
images. In this model, the dimension of latent vari-
data is constructed from the neural activity, and is ables Y and corresponding basis functions are much
calledthebasisfunctionorprojectionfield[56]. This larger than the number of pixels in Y (overcomplete
is in contrast to the parameter ϕ that comprises the
model). Theythenfoundthatthemodellearnshigh-
receptive field of neurons, which explains neural ac-
tivity in terms of the sensory inputs.16 17Here,withthechangeofavariabley=g(x;φ),wehave
p(Y|w)= δ(Y−g(x;φ))π(x|λ)dx
For the noiseless channel, the observation model Z
is written as p(Y|x,φ) = δ(Y−g(x;φ)). Then the = δ(Y−y)π(g−1 (y;φ)|λ) ∂x dy
Z (cid:12) (cid:12)∂y(cid:12)
(cid:12)
(cid:12) (cid:12)
=π(g−1 (Y;φ)|λ)det ∂x (cid:12) (cid:12)
∂y(cid:12)
(cid:12)y=Y
(cid:12)
∂f(y;(cid:12)ϕ)
=π(f(Y;ϕ)|λ)·det . (37)
16If the functions and parameters are linear (Y =Xϕ and ∂y (cid:12) (cid:12)y=Y
X=Yφ),weobtaintherelation,ϕφ=I. (cid:12)
(cid:12)
13
5 THERMODYNAMICS OF ADAPTATION
dimensional correlation structures such as lines and betweencausalstatisticallearningandthesecondlaw
edges that often appear in natural images [8, 9]. of thermodynamics. A similar treatment to the neu-
An alternative approach to augment the noiseless raldynamicspresentedinthissectioncanbefoundin
model to a noisy model is to directly construct the the thermodynamic analysisofneuralpopulationac-
approximateposteriordistributionq(x|Y) by adding tivity in Shimazaki 2015, 2018 [67, 68] to which the
noise to the nonlinear function x = f(y;ϕ). In reader is referred. Methods for calculating thermo-
the originalvariationalauto-encodermodel, notonly dynamicquantitiesofneuralpopulationsfromactual
the mean but variance of the approximated Gaus- recordings of time-series neural spike data, together
sian posterior distribution is learned by neural net- with the results of these methods, can be found in
works[52]. Contrarytothe overcompleterepresenta- Tkaˇciket al. 2015 [69], Donner et al. 2017and Gau-
tion,thedimensionofthelatentvariableXissmaller dreault et al. 2018 [70, 71].
than that of the observation Y; therefore the poste-
rior called encoder maps the data into latent vari- 5.1 Maximum entropy model
ables in a smaller subspace whereas the observation
modelcalleddecodermapsthelatentvariablestothe Before entering the discussion, we start with a de-
data, which has a largerdimension. A scheme differ- scription of the terminology. Based on Eq. 14, the
ent from the EM algorithm was developed to learn lower bound L[q,p] with a recognition model q(x|Y)
the posterior and the generative model simultane- can be expressed as follows:
ously using the neural networks. Common to all ap-
proaches,itisknownthatneitheroftheseapproaches L[q,p]=S− q(x|Y)[−logp(Y,x|w)]dx. (39)
Z
can fully eliminate redundancy in simple nonlinear
functions or non-Gaussian distributions [11, 10, 66],
In this section, the Shannon entropy of the recogni-
so efforts are being made to grasp the input correla-
tionmodelisrepresentedbyS (S ≡H[q(x|Y)]). The
tion structure with deeply hierarchical models.
second term is the negative of the Q-function (−Q),
which is as follows:
5 Thermodynamics of adapta-
q(x|Y)[−logp(Y,x|w)]dx=E. (40)
tion Z
Asshownlater,E isaquantitythatcanbereferredto
In Section 3, we introduced the EM algorithm as as the energy of the recognition model. These terms
a learning method for hierarchical models based on are used to bound the negative marginal likelihood
Helmholtz’s epistemology. This approach can be ex- function as
tended to variational inference using variational ap-
proximation methods. The variational inference is −logp(Y|w)≤E −S ≡F, (41)
a technique derived from mean field approximation
in statisticalphysicsthat providesapproximatesolu- where, in statistical physics, the left side is called
tions to physical models of materials involving com- free energy and the right side F = E −S is called
plex interactions among their elements (e.g., Ising the variational free energy. The variational free en-
model). Therefore its mathematical framework is ergyis the negative lowerbound (F =−L[q,p]), and
closely related to statistical physics and thermody- theproblemofmaximizingthe lowerboundthatwas
namics.18 However, it is not always clear how the discussedin the sectionofapproximateinference can
laws of thermodynamics relate to recognition and be substituted with the problem of minimizing the
learning. variationalfreeenergy. Inthefollowing,athermody-
Inthis section,we willlookatthe learningprocess namic approachto a recognitionmodel will be intro-
from a thermodynamic viewpoint based on the prin- duced to better understand dynamics of the entropy,
cipleofentropymaximization,andwewilldiscussdy- energy, and free energy (not variational free energy)
namicsoflearningbydefiningenergyandfreeenergy for a recognition model, induced by learning.
of a recognition model using an exponential family Forthisgoal,wewillconstructarecognitionmodel
distribution. Based on this, we explain the relation from the maximum entropy principle. Consider the
problem of maximizing the entropy of a recognition
18Asaphysiologist,Helmholtzhimselfdevelopedatheoryof model q(x|Y) given an expected value of a genera-
visualperception(theYoung–Helmholtztheoryoftrichromatic
tive model. This is an entropy maximization prob-
colorvision),andasaphysicist,hecontributedtoestablishing
lem with constraints, which can be solved by the
thefirstlawofthermodynamicsandthetheoryoffreeenergy
inchemicalreactions. method of Lagrange multipliers. In this method, the
14
5 THERMODYNAMICS OF ADAPTATION
constrained maximization problem is replaced with the entropy according to Eq. 44 becomes
maximizationofanewfunctionthatincludesthecon-
p(Y,x|w)
straints. Morespecifically,wemaximizethefollowing q (x|Y)= =p(x|Y,w), (46)
β=1 Z (Y)
Lagrange function (Lagrangian): β=1
which is an exact posterior distribution.
L˜ [q]=− q(x|Y)logq(x|Y)dx
β
Z
5.2 Law of conservation of entropy for
−β − q(x|Y)logp(Y,x|w)dx−E a recognition model
(cid:26) Z (cid:27)
Thegenerativemodelcanbedividedintoanobserva-
+a q(x|Y)dx−1 . (42)
(cid:26)Z (cid:27) tion model and a prior distribution. To manipulate
the entropy of the recognition model more precisely
where β, and a are Lagrange multipliers. The last
than in the above formula, we now consider a recog-
term is a constraint due to the fact that the recogni-
nition model, for which the constraints are stated in
tion model is a density or probability function. Ac-
more details. More specifically, we search for the
cordingtothevariationalprinciple,weneedtoobtain
recognitionmodelwhoseentropyismaximizedunder
thedistributionbymaximizingEq.42. Thevariation
the following constraints:
with respect to the distribution q(x|Y) is given by
h−logp(x|ω)i=U, (47)
δL˜ [q]
β = δq[−1−logq(x|Y) h−logp(Y|x,φ)i=V. (48)
δq Z
where h·i is the expected value of the recognition
+βlogp(Y,x|w)+a]dx. (43)
model. In this case, the Lagrangian can be written
Thus it is found that the distribution obeys the fol- as follows:
lowing exponential family distribution:
L˜ [q]=− q(x|Y)logq(x|Y)dx
β,α
1 Z
q(x|Y)= e−β{−logp(Y,x|w)}. (44)
Z (Y)
β −β − q(x|Y)logp(x|ω)dx−U
(cid:26) Z (cid:27)
The term Z (Y)(= ea−1) is called a normalization
β
term or partition function, and is given by −α − q(x|Y)logp(Y|x,φ)dx−V
(cid:26) Z (cid:27)
Z (Y)= e−β{−logp(Y,x|w)}dx. (45)
β +a q(x|Y)dx−1 , (49)
Z
(cid:26)Z (cid:27)
TheLagrangemultiplierβ isobtainedatthemaxima
where β, α, and a are Lagrange multipliers.19 By
of the Lagrangian ( ∂L˜ ∂ β β [q] = 0), which is given by examining variations in the recognition model in the
Eq.40. Thatis, β ischosento satisfythe constraints same way as before, we obtain
of Eq. 40. Note that in this section, we consider the
setofparametersasw={ϕ,ω}byexcludingβ,and δL˜ β,α [q] = δq[−1−logq(x|Y)
separately introduce β as a Lagrange multiplier that δq Z
is a parameter of the posterior distribution. +βlogp(x|ω)+αlogp(Y|x,φ)+a]dx. (50)
The maximum entropy method is a method that
maximizes the entropy of a distribution while apply- Consequently, the recognition model obeys the fol-
ing specific constraints. It can be used to obtain dis- lowing exponential family distribution:
tributions by eliminating statistical structures other 1
than constraints. As seen above, its distribution is q(x|Y)= eβlogp(x|ω)+αlogp(Y|x,φ). (51)
Z (Y)
β,α
expressedby anexponentialfamily distributionfrom
the definition of entropy. In statistical physics, this The partition function is given by
distribution is called the Gibbs or Boltzmann dis-
tribution, the exponent of the exponential function Z β,α (Y)= eβlogp(x|ω)+αlogp(Y|x,φ)dx. (52)
Z
H(x) ≡ −logp(Y,x|w) is called the Hamiltonian,
and the expected value of the Hamiltonian is called 19In the earlier equations, β was a Lagrange multiplier for
thegenerativemodel. However,itisnowaLagrangemultiplier
theenergyasgivenbyEq.40. Also,β iscalledthein-
forthepriordistribution. Therefore,βisnolongeraparameter
versetemperature,andT ≡1/β iscalledthetemper-
that controls energy. If we introduce α = βf, β controls the
ature. When β =1, the distribution that maximizes energy.
15
5 THERMODYNAMICS OF ADAPTATION
The Lagrange multipliers β and α are chosen to sat- and
isfy the constraints. When β = 1 and α = 1, the
∂S ∂S
recognition model becomes an exact posterior distri- =β, =α. (58)
∂U ∂V
bution.
The recognition model of Eq. 51 can be regarded This transformation converts the entropy S(U,V) (a
as an exponential family distribution where −β and function of U and V) into G(β,α) (a function of β
−α are canonical parameters, and −logp(x|ω) and and α). When β = 1 and α = 1, an exact posterior
−logp(Y|x,φ)arefeatures. We canthereforederive distribution is obtained, in which case the marginal
anumberofimportantrelations. First,thelogarithm likelihood and negative log partition function coin-
ofthepartitionfunctionformsacumulantgenerating cide: logp(Y|w)=−G(1,1).21
function. As a result, the first derivative of the log According to Eq. 58, the total derivative of the
partition function by the canonical parameter gives entropy of the recognition model,
the expected value of the feature by the recognition
model. That is, ∂S ∂S
dS = dU + dV, (60)
(cid:18)∂U(cid:19) (cid:18)∂V (cid:19)
V U
∂logZ (Y)
β,α =h−logp(x|ω)i
can be expressed as follows:
∂(−β)
∂logZ (Y)
β,α =h−logp(Y|x,φ)i. (53) dS =βdU +αdV. (61)
∂(−α)
This formula represents the contribution of the prior
Here, by defining a function distribution and the observation model (input stim-
uli)tothechangeofentropyintherecognitionmodel,
G(β,α)≡−logZ (Y), (54)
β,α and dictates the law of conservation of entropy. In
physics,Eq.61iscalledthefirstlawofthermodynam-
they can be simplified to
ics (law of conservation of energy).22 Since entropy
is a state variable that is determined for a particu-
∂G(β,α) ∂G(β,α)
=U, =V. (55) lar recognitionmodel, the entropy change on the left
∂β ∂α
side of Eq. 61 is expressed as a difference in state
Next, the entropy of the recognition model can be variables at two close recognition models. However,
calculated as the terms βdU and αdV on the right side depend on
theintegrationpathsinceβ andαarefunctions ofU
S(U,V)=h−logq(x|Y)i and V.
Theparametersβ andαoftheapproximateposte-
=βh−logp(x|ω)i+αh−logp(Y|x,φ)i
rior distribution represent contributions of the prior
+logZ (Y)
β,α distribution and the likelihood function when con-
=βU +αV −G(β,α). (56) structing the recognition model. This recognition
model becomes an exact posterior distribution when
ThecombinationofEq.55andEq.56formsaLegen- β = 1 and α = 1. It is expected that there ex-
dre transformation that transforms G(β,α) (a func- ists neural dynamics that progressively approaches
tion of β and α) into the entropy S(U,V) which is a the optimal state for the Bayesian inference. Thus
function of U and V.20 it is important to consider the dynamics of β and α
Since there is no loss of information by the Leg- when we hypothesize that the Bayesian inference is
endre transformation defined by Eqs. 55 and 56, it implemented by neural dynamics in the brain.
is always possible to return to the original function
by using the inverse Legendre transformation. The 21In general, the relationship with the lower bound is ex-
pressedas
inverse Legendre transformation is given by
L[q,p]=−G(β,α)+(β−1)U+(α−1)V. (59)
G(β,α)=βU +αV −S(U,V). (57)
22Thefirstlaw of thermodynamics TdS =dU+fdV isob-
20In general, when a smooth convex function f(x) is ex- tainedfromEq.61,usingthetemperature T =1/β andforce
pressedintermsofanewfunctionf∗(p)=maxx{px−f(x)}, f =α/β. In this case dU is called the internal energy, which
this is called a Legendre transformation. However, since the is a state variable. On the other hand, the terms d¯Q = TdS
derivativeiszeroatthemaximumvalue,p=f′(x),andthusp and d¯W = fdV, which are called heat and work, are repre-
representstheslopeofthefunctionf(x). Hence,strictlyspeak- sentedusingapath-dependent incompletederivatived¯. Using
ing,Eq.56multipledby−1representstheLegendretransfor- theseterms,thefirstlawofthermodynamicsisalsowrittenas
mationfrom−G(β,α)to−S(U,V) d¯Q=dU+d¯W.
16
5 THERMODYNAMICS OF ADAPTATION
For example, a likely scenario for the formation of for causal dynamics in which the forward and back-
a posteriordistributionby a neuralnetworkis as fol- wardprocessesaredifferent,fromthefluctuationthe-
lows: after nerve cells have fired in response to the orem[75,76,77]. Assumingsuchcausaldynamicsfor
presentationofastimulus,theneuralactivityismod- learning, it is expected that
ulated by feedback input (including information cor-
responding to the prior knowledge), whereby the ob- dS ≥βdU +αdV. (62)
servation and prior knowledge are fused. In [67, 68],
Thisisequivalenttothesecondlawofthermodynam-
the spontaneous firing of neurons corresponding to
ics inphysics,andit applies wheneveranirreversible
the prior distribution and the firing activity of neu-
process takes place. Here we examine how such a
rons induced by a stimulus are represented by expo-
causal learning rule relates to the optimization prin-
nential family distributions, to which we apply the
ciples introduced in previous sections.
thermodynamic formulation introduced in this sec-
Consider optimizing the parameters while keeping
tion. In particular, it was shown that, when stimu-
β and α fixed. The free energy is a convenient quan-
lus response is modulated with a time delay due to
tity that can be used instead of entropy under such
feedback/recurrent input, neural dynamics forms an
conditions. In fact, we will see that the quantity
information-theoretic cycle (an analogue of heat en-
G(β,α) is the free energy. The total derivative of
gine, termed neural engine).23 Many studies have
G(β,α) that is a function of β and α becomes
shown that the modulation of late components of
stimulus response is related to attention, perceptual
dG(β,α)=d(βU +αV)−dS
experience, short term memory, and subjective re-
=(Udβ+βdU)+(Vdα+αdV)−dS
wardvalue [72,73, 47,44,74, 45,48]. This approach
allows us to quantify higher-orderbrain functions by =Udβ+Vdα, (63)
measuring active portion of the computation as en-
wherethefirstlaw(Eq.61)isusedatthelastequality.
tropy emission related to the modulation of stimulus
Itcanalsobeobtaineddirectlyfromthe definitionof
response.
total derivative
5.3 Learning and the principle of in- ∂G ∂G
dG(β,α)= dβ+ dα, (64)
creasing entropy (cid:18)∂β(cid:19) (cid:18)∂α(cid:19)
α β
Severalthermodynamicequationsandthelawofcon- and from Eq. 55. G(β,α) is a thermodynamic quan-
servation of entropy have been concisely obtained by tity that takes β and α as natural independent vari-
adopting the maximum entropy model as a recogni- ables. Therefore it is particularly useful when these
tion model. Let’s see what happens in the learning independent variables are fixed. In this article we
process of this model. In the discussion so far, the call G(β,α) the Gibbs free energy.24 The reasonwhy
parameter w = {φ,ω} has been fixed without con- wederivethetotalderivativeusingEq.63insteadof
sideringlearning,althoughwe discusseddynamics to Eq.64isthatitbecomesclearthatthefollowingrela-
construct the optimal recognition model by chang- tionshipholds whenentropyis increasedbylearning:
ing β and α. Let us admit that parameter w is also
24In thermodynamics, the dual function based on the Leg-
optimized by learning, and assume that the learning
endretransformationofinternalenergyU iscalledthermody-
dynamics also follows the maximum entropy princi- namicpotential (freeenergy). Theinternalenergyisgivenby
ple. That is, the learning plays a role of another theformuladU =TdS+fdV, withS andV asnatural inde-
factor besides β andα (or U and V) that changethe pendent variables. For example, the Helmholtz freeenergy is
F = U −TS, and from the relationship dF = d(U −TS) =
entropy of the recognition model, and this factor al-
dU−(dTS+TdS)=fdV −SdT. Here we have V and S as
ways increase entropy. More specifically, the law of naturalindependentvariables. ThisisaLegendretransforma-
increasing entropy can be derived as a statistical law tion. At constant temperature, dF = fdV. Hence, the work
doneinanisothermalprocesscanbeexpressedasadifference
23Inthesearticles,thermodynamicanalysisofaneuralpop- of Helmholtz free energy. Similarly, the Gibbs free energy in
ulation was proposed by expressing spontaneous/background thermodynamicsisdefinedasG=F+fV. Thisisconvenient
activity and stimulus-related activity of neurons by an expo- expressiontouseinisothermalandisobaricprocessesbecause
nential family distribution. In particular, if the level of the dG=dF −(dfV +fdV)=−SdT +Vdf. However,theGibbs
backgroundactivityischangedwithatimedelayduetofeed- free energy G in this article is given by the relation G = βG.
backinputs,theresponseofneuronstoastimulusundergogain Whenconsideringtherecognitionmodelsofthebrainandma-
control. The dynamics of such a delayed gain-control of the chine, the concepts of heat and work may aid understanding,
stimulus response turns out to be analogous to a heat engine butitisnotclearwhethertheywillactuallybringdirectbene-
of thermodynamics. Thisresponse cycle preserve information fits. Sincethemainfocusofthisarticleisonentropy,wehave
aboutstimuliwiththepresenceofthedelayedfeedbacksignal, regardedtheLegendretransformationofentropy(ratherthan
thatwouldotherwisebelost. internalenergy)asfreeenergy.
17
6 SUMMARY AND PROSPECTS
temperature and constant pressure take place only
dG(β,α)≤Udβ+Vdα, (65) when some internal change such as a chemical re-
action takes place, and such reactions proceed in a
by applying Eq. 62 to Eq. 63. In particular, if causal
direction such that the Gibbs free energy decreases.
learning occurs while β and α are fixed, the Gibbs
Weexplainedhowlearningcanbetreatedinthesame
free energy decreases,
way in this section.
dG(β,α)≤0. (66)
That is, the following learning rule can be derived: 6 Summary and prospects
dw ∂G
=−ǫ , (67) In this article, we examined hypotheses on adaptive
dt ∂w
processes of organisms to their environments from
where w = {φ,ω}, and ǫ is a learning coefficient of multiple viewpoints: maximizing the marginal like-
the parameters.25 Alternatively to Eq.67, anunique lihood (maximizing the lower bound and minimizing
valueofthelearningcoefficientmaybeconsideredfor the variational free energy), maximizing the mutual
eachparametertoaccountforadaptationtoenviron- information, the law of increasing entropy (the sec-
mental dynamics with different time-scales. ondlawofthermodynamics),andminimizingthefree
Fromtheabove,whenβ andαarefixed,thelearn- energy.
ing process that decreases the Gibbs free energy of One important topic which was not systematically
the recognition model is equivalent to the learning coveredin this article is the adaptation of organisms
that maximizes the entropy of the recognitionmodel at different time scales. Data from the environment
(the second law of thermodynamics). In particular, hasa temporalhierarchyrangingfromthe formation
when β = 1 and α = 1, the Gibbs free energy be- of context over long timescales to short-term fluctu-
comes a negative marginal likelihood, and learning ations. Organisms are equipped with multiple adap-
according to the law of increasing entropy becomes tivemechanismsforsuchenvironmentalchanges. For
equivalenttolearningaccordingto themarginallike- example, the intensity of light experienced by an or-
lihood maximization. Therefore, if there is a mech- ganism changes with the cycle of day and night, but
anism for forming an optimal posterior distribution also undergoes sharp changes as the organismmoves
(β =1,α=1)asarecognitionmodelafterastimulus between light and shade. Animals perform multi-
is received, and if learning is performed at this time, ple adaptation processes to cope with the intensity
wecanexpecttheresultsobtainedbyminimizingthe changes, starting with constriction of pupils known
Gibbs free energy are the same as those obtained by as the pupillary light reflex, and including relatively
maximizing the marginal likelihood. One may also fast gain control performed in cells in retina [82, 59]
considerthe hypothesis that actionsarealso selected and primary visual cortex [61]. Furthermroe, it was
so as to reduce the Gibbs free energy, following the shown that visual attention of monkeys whereby the
assertions of Friston et al. animalschangesensitivitytolightcontrastaccording
In this section, we clarified the relationship be- to the context of tasks is also explained by the gain
tween learning according to the law of increasing controlmechanism[47]. The attentionalmechanisms
entropy, learning according to the minimization of in which organisms select data according to the con-
Gibbs free energy, and the maximization of marginal text may also be explained by the canonical adapta-
likelihood, by using a maximum entropy model to tion principle to the environment [47, 62, 63, 64, 83].
form a recognition model. In thermodynamics, free This implies that slower temporal dynamics is re-
energyisintroducedbyfindinganewthermodynamic quired for the neural dynamics to retain contextual
quantity having the same meaning as the law of in- information occuring in a long time-scale. Indeed,
creasing entropy under certain conditions when we it has been reported that the intrinsic time scale of
need to know in which direction a phenomenon will neural activity slows down along the way from the
occur as prescribed by the second law of thermody- primary visual cortex to the prefrontal cortex [84].
namics. Changes in gases and liquids at constant Finally, the adaptation of visual stimuli to spatial
25 Here we derived learning rules from the second law of structures is a process of adaptation to data distri-
thermodynamics or the minimization principle of free energy, butionsmoreslowlyonatime scalecorrespondingto
but it is possible to decide on a specific causal learning rule the organism’s own development. All of these adap-
and derive the law of increasing entropy (the second law of
tations are thought to be performed using biophysi-
thermodynamics)[78,79]. Thisapproachtothelearningpro-
calphenomena operatingondifferent time scales,in-
cess started to be discussed with the recent development of
stochasticthermodynamics [80,81]. cluding electrical responses and intracellular signal
18
REFERENCES
propagation(fromtensofmillisecondsto severalsec- adaptiveprocessesfrommultiple viewpoints,wewill
onds), and synaptic plasticity resulting from protein keep gaining deeper understanding about their prin-
synthesis (from tens of minutes to several hours). It ciples.
is necessary to clarify these hierarchical dynamics in
order to understand the adaptation of organisms to
acknowledgement
the environment.26
Wetoucheduponthesetopicsonthetemporalhier- I would like to thank Manuel Baltieri, Seyed-Amin
archyinadaptationandlearningateachsection,but Moosavi, Sousuke Ito, Ryota Kobayashi, Shashwat
not in a systematic manner. In Section 2 that intro- Shukla, Masanori Murayama, and Takuma Tanaka
duced learning, we mentioned different sample size for critical reading of the article and helpful discus-
for learning parameters of the models. In addition sions.
to learning the parameters in the generative model
from multiple samples for adaptation in a long time-
References
scale, we also introduced a process to learn the prior
distributionforeachsampletoaccountforthe short-
term adaptation. In the section of information the- [1] F. Attneave, “Some informational aspects of vi-
ory (Section 4), using a simple example of the noise- sual perception.,” Psychological review, vol. 61,
lesschannel,weconfirmedthatthenonlinearfunction no. 3, pp. 183–193,1954.
(neural network) should be adapted to the data dis- [2] H.B.Barlow,“Possibleprinciplesunderlyingthe
tribution under the informax principle in both long transformations of sensory messages,” in Sen-
andshorttime-scales. Further,wediscussedhowthis sory Communication (W. A. Rosenblith, ed.),
nonlinearfunctioncanbemappedintothegenerative ch. 13, pp. 217–234,MIT press, 1961.
model, and saw that the optimal nonlinear function [3] H.B.Barlow,“Singleunitsandsensation: aneu-
is modulated in the presence of the prior distribu- ron doctrine for perceptual psychology?,” Per-
tion. Finally, thermodynamic analysis in Section 5 ception, vol. 1, no. 4, pp. 371–394,1972.
formulated relative contributions of the observation [4] D. J. Field, “Relations between the statistics of
and prior to construct the recognition model, using natural images and the response properties of
the weight paramters β and α. In this framework, cortical cells,” Journal of the Optical Society of
learning parameters of the observation model and America A, vol. 4, no. 12, pp. 2379–2394,1987.
priordistributionin alongertime-scale wasachieved [5] R. Linsker, “Self-organization in a perceptual
by minimization of the Gibbs free energy. Short- network,”Computer,vol.21,no.3,pp.105–117,
term dynamics of the adaptation was discussed as 1988.
changesoftheparametersβandα,whichisdescribed [6] J. J. Atick and A. N. Redlich, “What does the
analogously to a thermodynamic process. Further, retinaknowaboutnaturalscenes?,”Neuralcom-
it was shown that this process works similarly to a putation, vol. 4, no. 2, pp. 196–210,1992.
heatenginewhenthestimulusresponse(observation) [7] S. Laughlin, “A simple coding procedure
is modulated by feedback inputs (prior information) enhances a neuron’s information capacity,”
via top-down or lateral connections [67, 68]. While Zeitschrift fu¨r Naturforschung c, vol. 36, no. 9-
the issues of adapting to different temporal scales 10, pp. 910–912,1981.
have been discussed in other articles, a unified the- [8] B. A. Olshausen and D. J. Field, “Emergence
ory that can be brought into practice remains to be of simple-cell receptive field properties by learn-
constructed. ing a sparse code for natural images,” Nature,
It can be stated that organisms are equipped with vol. 381, no. 6583,pp. 607–609,1996.
a number of adaptive mechanisms to environments [9] B.A.OlshausenandD.J.Field,“Sparsecoding
composed of spatial and temporal hierarchiesby uti- with an overcomplete basis set: A strategy em-
lizingtheirbiophysicalphenomenawithvarioustime- ployed by v1?,” Vision research, vol. 37, no. 23,
scales,inordertomaintaininformation-theoreticbal- pp. 3311–3325,1997.
ance with the environment. With active inference [10] E. P. Simoncelli and B. A. Olshausen, “Natu-
that includes behavior, this balance is stabilized be- ral image statistics and neural representation,”
cause the organisms build more predictable environ- Annual review of neuroscience, vol. 24, no. 1,
ments by use of the actions. By investigating these pp. 1193–1216,2001.
[11] O. Schwartz and E. P. Simoncelli, “Natural sig-
26Themethodofextracting featuresbasedondifferences in
nal statistics and sensory gain control,” Nature
time scales is called slow feature analysis, and has been pro-
posedasoneofthebrain’sguidingprinciples[85,86,87]. neuroscience, vol. 4, no. 8, p. 819, 2001.
19
REFERENCES
[12] H. von Helmholtz, Treatise on physiological op- [27] D. M. Blei, A. Kucukelbir, and J. D. McAuliffe,
tics, vol. 3. The Optical Society of America, “Variational inference: A review for statisti-
1925. cians,” Journal of the American Statistical As-
[13] H. von Helmholtz, Helmholtz’s treatise on phys- sociation, vol. 112, no. 518, pp. 859–877,2017.
iological optics, vol. 3. Dover Publication, Inc., [28] C. Zhang, J. Butepage, H. Kjellstrom, and
1962. S. Mandt, “Advances in variational inference,”
[14] K. Doya, Bayesian brain: Probabilistic ap- arXiv:1711.05597, 2017.
proaches to neural coding. MIT press, 2007. [29] D. Mumford, “On the computational architec-
[15] W. J. Ma, J. M. Beck, P. E. Latham, and ture of the neocortex,” Biological cybernetics,
A. Pouget, “Bayesian inference with proba- vol. 66, no. 3, pp. 241–251,1992.
bilistic population codes,” Nature neuroscience, [30] M. Kawato, H. Hayakawa, and T. Inui, “A
vol. 9, no. 11, pp. 1432–1438,2006. forward-inverse optics model of reciprocal con-
nectionsbetweenvisualcorticalareas,”Network:
[16] A. Pouget, J. M. Beck, W. J. Ma, and P. E.
Computation in Neural Systems, vol. 4, no. 4,
Latham, “Probabilistic brains: knowns and un-
pp. 415–422,1993.
knowns,” Nature neuroscience, vol. 16, no. 9,
[31] R. P. Rao and D. H. Ballard, “Predictive cod-
pp. 1170–1178,2013.
ing in the visual cortex: a functional interpre-
[17] J. M. Beck, P. E. Latham, and A. Pouget,
tation of some extra-classical receptive-field ef-
“Marginalization in neural circuits with divi-
fects,” Nature neuroscience, vol. 2, no. 1, p. 79,
sive normalization,” Journal of Neuroscience,
1999.
vol. 31, no. 43, pp. 15310–15319,2011.
[32] T. S. Lee and D. Mumford, “Hierarchical
[18] A. Funamizu, B. Kuhn, and K. Doya, “Neural
bayesian inference in the visual cortex,” Jour-
substrate of dynamic bayesian inference in the
nal of the Optical Society of America A, vol.20,
cerebral cortex,” Nature neuroscience, vol. 19,
no. 7, pp. 1434–1448,2003.
no. 12, pp. 1682–1689,2016.
[33] A. Clark, “Whatever next? predictive brains,
[19] G. E. Hinton and R. S. Zemel, “Autoencoders,
situated agents, and the future of cognitive sci-
minimum description length and helmholtz free
ence,” Behavioral and brain sciences, vol. 36,
energy,” in Advances in neural information pro-
no. 3, pp. 181–204,2013.
cessing systems, pp. 3–10, 1994.
[34] X. Pitkowand D. E.Angelaki,“Inference in the
[20] P. Dayan, G. E. Hinton, R. M. Neal, and R. S.
brain: statisticsflowinginredundantpopulation
Zemel, “The helmholtz machine,” Neural com-
codes,”Neuron,vol.94,no.5,pp.943–953,2017.
putation, vol. 7, no. 5, pp. 889–904,1995.
[35] K. Friston, “Hierarchical models in the brain,”
[21] K. Friston, “Learning and inference in the
PLoS computational biology, vol. 4, no. 11,
brain,” Neural Networks, vol. 16, no. 9,
p. e1000211,2008.
pp. 1325–1352,2003.
[36] K. Friston, R. Adams, L. Perrinet, and
[22] K. Friston, J. Kilner, and L. Harrison, “A
M.Breakspear,“Perceptionsashypotheses: sac-
free energy principle for the brain,” Journal of
cades as experiments,” Frontiers in psychology,
Physiology-Paris, vol. 100, no. 1-3, pp. 70–87,
vol. 3, p. 151, 2012.
2006.
[37] A. Clark, Being there: Putting brain, body, and
[23] K.Friston, “The free-energyprinciple: a unified world together again. MIT press, 1998.
brain theory?,” Nature reviews neuroscience, [38] F. J. Varela, E. Thompson, and E. Rosch, The
vol. 11, no. 2, p. 127, 2010. embodied mind: Cognitive science and human
[24] K. Friston, “A free energy principle for biologi- experience. MIT press, 1991.
calsystems,” Entropy, vol.14,no. 11,pp. 2100– [39] K. J. Friston, J. Daunizeau, J. Kilner, and S. J.
2121,2012. Kiebel, “Actionand behavior: a free-energyfor-
[25] C. L. Buckley, C. S. Kim, S. McGregor, and mulation,”Biological cybernetics,vol.102,no.3,
A.K.Seth, “Thefreeenergyprincipleforaction pp. 227–260,2010.
and perception: A mathematical review,” Jour- [40] K. Friston, S. Samothrakis, and R. Montague,
nal of Mathematical Psychology, vol.81,pp. 55– “Active inference and agency: optimal control
79, 2017. without cost functions,” Biological cybernetics,
[26] R.Bogacz,“Atutorialonthefree-energyframe- vol. 106, no. 8-9, pp. 523–541,2012.
work for modelling perception and learning,” [41] K. J. Friston, J. Daunizeau, and S. J. Kiebel,
Journal of mathematical psychology, vol. 76, “Reinforcement learning or active inference?,”
pp. 198–211,2017. PloS one, vol. 4, no. 7, p. e6421, 2009.
20
REFERENCES
[42] P.Schwartenbeck,T. FitzGerald,R. Dolan, and and blind deconvolution,” Neural computation,
K. Friston, “Exploration, novelty, surprise, and vol. 7, no. 6, pp. 1129–1159,1995.
free energy minimization,” Frontiers in psychol- [56] P. Dayan and L. F. Abbott, Theoretical neuro-
ogy, vol. 4, p. 710, 2013. science. Cambridge, MA: MIT Press, 2001.
[43] P. Berkes, G. Orb´an, M. Lengyel, and J. Fiser, [57] T.Isomura,“Ameasureofinformationavailable
“Spontaneouscorticalactivityrevealshallmarks for inference,” Entropy, vol. 20, no. 7, p. 512,
of an optimal internal model of the environ- 2018.
ment,” Science, vol. 331, no. 6013, pp. 83–87, [58] S. R. Olsen, V. Bhandawat, and R. I. Wilson,
2011. “Divisive normalization in olfactory population
[44] H. Super, H. Spekreijse, and V. A. Lamme, “A codes,” Neuron,vol.66,no.2,pp.287–99,2010.
neuralcorrelateof workingmemory in the mon- [59] R. M. Shapley and J. D. Victor, “The effect of
key primary visual cortex,” Science, vol. 293, contrast on the transfer properties of cat reti-
no. 5527, pp. 120–124,2001. nal ganglion cells.,” The Journal of physiology,
[45] S. Manita, T. Suzuki, C. Homma, T. Mat- vol. 285, no. 1, pp. 275–298,1978.
sumoto, M. Odagawa, K. Yamada, K. Ota, [60] S. B. Laughlin, “The role of sensory adaptation
C. Matsubara, A. Inutsuka, M. Sato, in the retina,” Journal of Experimental Biology,
M. Ohkura, A. Yamanaka, Y. Yanagawa, vol. 146, no. 1, pp. 39–62,1989.
J. Nakai, Y. Hayashi, M. E. Larkum, and [61] I.Ohzawa,G.Sclar,andR.Freeman,“Contrast
M. Murayama, “A top-down cortical circuit for gain control in the cat visual cortex,” Nature,
accurate sensory perception.,” Neuron, vol. 86, vol. 298, no. 5871,p. 266, 1982.
no. 5, pp. 1304–1316,2015. [62] E. Salinas and T. J. Sejnowski, “Gain modula-
tioninthecentralnervoussystem: wherebehav-
[46] P. R. Roelfsema, V. A. Lamme, and H. Spekrei-
ior, neurophysiology, and computation meet.,”
jse, “Object-based attention in the primary vi-
sual cortex of the macaque monkey,” Nature, The Neuroscientist, vol. 7, no. 5, pp. 430–440,
2001.
vol. 395, no. 6700, p. 376, 1998.
[63] J. H. Reynolds and D. J. Heeger, “The nor-
[47] J.H.Reynolds,T.Pasternak,andR.Desimone,
malizationmodel of attention,” Neuron, vol.61,
“Attention increases sensitivity of v4 neurons,”
no. 2, pp. 168–185,2009.
Neuron, vol. 26, no. 3, pp. 703–714,2000.
[64] M. Carandini and D. J. Heeger, “Normalization
[48] W. Schultz, “Dopamine reward prediction-error
as a canonical neural computation,” Nature re-
signalling: atwo-componentresponse.,”NatRev
views neuroscience, vol. 13, no. 1, pp. 51–62,
Neurosci, vol. 17, no. 3, pp. 183–195,2016.
2012.
[49] V. A. Lamme and P. R. Roelfsema, “The dis-
[65] J.-P.NadalandN.Parga,“Nonlinearneuronsin
tinctmodes ofvisionofferedbyfeedforwardand
the low-noise limit: a factorial code maximizes
recurrent processing,” Trends in neurosciences,
informationtransfer,”Network: Computation in
vol. 23, no. 11, pp. 571–579,2000.
neural systems, vol. 5, no. 4, pp. 565–581,1994.
[50] C.M.Bishop, Pattern Recognition and Machine
[66] H. MaBouDi, H. Shimazaki, S.-i. Amari, and
Learning. Springer, 2006.
H. Soltanian-Zadeh, “Representation of higher-
[51] D.J.MacKay,Informationtheory, inferenceand
order statistical structures in natural scenes via
learningalgorithms. Cambridgeuniversitypress,
spatial phase distributions,” Vision research,
2003.
vol. 120, pp. 61–73, 2016.
[52] D. P. Kingma, Variational inference & deep [67] H. Shimazaki, “Neurons as an information-
learning: A new synthesis. PhD thesis, the Uni- theoretic engine,” arXiv:1512.07855, 2015.
versity of Amsterdam, 2017.
[68] H. Shimazaki, Neural Engine Hypothesis,
[53] A. P. Dempster, N. M. Laird, and D. B. Rubin, pp.267–291.Cham: SpringerInternationalPub-
“Maximum likelihood from incomplete data via lishing, 2018.
the em algorithm,” Journal of the royal statis- [69] G.Tkaˇcik,T.Mora,O.Marre,D.Amodei,S.E.
tical society. Series B (methodological), vol. 39, Palmer, M. J. Berry, and W. Bialek, “Thermo-
no. 1, pp. 1–38, 1977. dynamics and signatures of criticality in a net-
[54] L. Itti and P. Baldi, “Bayesian surprise attracts work of neurons,” Proceedings of the National
human attention,” Vision research, vol. 49, AcademyofSciences,vol.112,no.37,pp.11508–
no. 10, pp. 1295–1306,2009. 11513,2015.
[55] A.J.BellandT.J.Sejnowski,“Aninformation- [70] C. Donner, K. Obermayer, and H. Shimazaki,
maximization approach to blind separation “Approximate inference for time-varying inter-
21
REFERENCES
actionsandmacroscopicdynamicsofneuralpop- [82] B. Sakmann and O. D. Creutzfeldt, “Sco-
ulations,” PLoS computational biology, vol. 13, topic and mesopic light adaptation in the cat’s
no. 1, p. e1005309,2017. retina.,” Pflugers Arch, vol. 313, no. 2, pp. 168–
[71] J. Gaudreault and H. Shimazaki, “State-space 185, 1969.
analysis of an ising model reveals contributions [83] E. Eldar, J. D. Cohen, and Y. Niv, “The effects
of pairwise interactions to sparseness, fluctua- ofneuralgainonattentionandlearning,”Nature
tion, and stimulus coding of monkey v1 neu- neuroscience, vol. 16, no. 8, p. 1146, 2013.
rons,” in International Conference on Artificial [84] J. D. Murray, A. Bernacchia, D. J. Freedman,
Neural Networks, pp. 641–651,Springer, 2018. R. Romo, J. D. Wallis, X. Cai, C. Padoa-
[72] B. Libet, W. Alberts, E. Wright, and B. Fein- Schioppa, T. Pasternak, H. Seo, D. Lee, et al.,
“A hierarchy of intrinsic timescales across pri-
stein, “Responses of human somatosensory cor-
mate cortex,” Nature neuroscience, vol. 17,
tex to stimuli below thresholdfor conscioussen-
sation,” Science, vol. 158, no. 3808, pp. 1597– no. 12, p. 1661, 2014.
[85] P. F¨oldi´ak, “Learning invariance from transfor-
1600,1967.
mation sequences,” Neural computation, vol. 3,
[73] L. J. Cauller and A. T. Kulics, “The neural ba-
no. 2, pp. 194–200,1991.
sis of the behaviorally relevant n1 component
[86] L. Wiskott and T. J. Sejnowski, “Slow feature
of the somatosensory-evokedpotential in si cor-
analysis: Unsupervised learning of invariances,”
tex of awake monkeys: evidence that backward
Neural computation, vol. 14, no. 4, pp. 715–770,
corticalprojectionssignalconscioustouchsensa-
2002.
tion,”Experimentalbrainresearch,vol.84,no.3,
[87] P.BerkesandL.Wiskott,“Slowfeatureanalysis
pp. 607–619,1991.
yields a rich repertoire of complex cell proper-
[74] S. Sachidhanandam, V. Sreenivasan, A. Kyri-
ties,” Journal of vision, vol. 5, no. 6, pp. 9–9,
akatos, Y. Kremer, and C. C. Petersen, “Mem-
2005.
brane potential correlates of sensory perception
in mouse barrel cortex,” Nature neuroscience,
vol. 16, no. 11, p. 1671, 2013.
[75] G. E. Crooks, “Entropy production fluctuation
theorem and the nonequilibrium work relation
for free energy differences,” Physical Review E,
vol. 60, no. 3, p. 2721,1999.
[76] U.Seifert,“Stochasticthermodynamics,fluctua-
tiontheoremsandmolecularmachines,”Reports
on progress in physics,vol.75,no.12,p.126001,
2012.
[77] S. Ito, “Unified framework for the second law
of thermodynamics and information thermody-
namics based on information geometry,” arXiv
preprint arXiv:1810.09545, 2018.
[78] S. Goldt and U. Seifert, “Stochastic thermo-
dynamics of learning,” Physical review letters,
vol. 118, no. 1, p. 010601,2017.
[79] D. S. Salazar, “Nonequilibrium thermodynam-
ics of restricted boltzmann machines,” Physical
Review E, vol. 96, no. 2, p. 022131,2017.
[80] S. Ito and T. Sagawa, “Information thermody-
namicsoncausalnetworks,”Physical review let-
ters, vol. 111, no. 18, p. 180603,2013.
[81] D. Hartich, A. C. Barato, and U. Seifert,
“Stochastic thermodynamics of bipartite sys-
tems: transfer entropy inequalities and a
maxwell’s demon interpretation,” Journal of
Statistical Mechanics: Theory and Experiment,
vol. 2014, no. 2, p. P02016,2014.
22