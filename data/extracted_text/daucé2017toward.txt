SubmittedtoICLR2018
TOWARD PREDICTIVE MACHINE LEARNING FOR AC-
TIVE VISION
EmmanuelDaucé
EcoleCentraledeMarseille,AixMarseilleUniv,Inserm
INS,InstitutdeNeurosciencesdesSystèmes
Marseille,France
emmanuel.dauce@centrale-marseille.fr
ABSTRACT
We develop a comprehensive description of the active inference framework, as
proposed by Friston (2010), under a machine-learning compliant perspective.
Stemming from a biological inspiration and the auto-encoding principles, the
sketch of a cognitive architecture is proposed that should provide ways to im-
plementestimation-oriented controlpolicies.Computersimulationsillustratethe
effectivenessoftheapproachthroughafoveatedinspectionoftheinputdata.The
pros and cons of the control policy are analyzed in detail, showing interesting
promisesintermsofprocessingcompression.Thoughoptimizingfutureposterior
entropy over the actions set is shown enough to attain locally optimal action se-
lection, offline calculation using class-specific saliency maps is shown better for
itsavesprocessingcoststhroughsaccadespathwayspre-processing,withanegli-
gibleeffectontherecognition/compressionrates.
1 MOTIVATION
The oculo-motor activity is an essential component of man and animal behavior, subserving most
of daily displacements and interactions with objects, devices or people. By moving the gaze with
theeyes,thecenterofsightisconstantlyandactivelymovingaroundduringallwakingtime.The
scanningofthevisualsceneisprincipallydonewithhigh-speedtargetedeyemovementscalledsac-
cades(Yarbus(1967)),thatsequentiallycapturelocalchunksofthevisualscene.Thoughubiquitous
in biology, object recognition through saccades is seldom considered in artificial vision. The rea-
sonsaremany,ofwhichtheexistenceofhigh-performancesensorsthatprovidemillionsofpixels
atlowcost.Increasinglypowerfulcomputingdevicesarethenassignedtocomputeinparallelthose
millionsofpixelstoperformrecognition,consumingresourcesinabrute-forcefashion.
Theexampleofanimalvisionencourageshoweveradifferentapproachtowardsmoreparsimonious
recognitionalgorithms.Asalientaspectofanimalvisionistheuseofactivesensingdevices,capable
of moving around under some degrees of freedom in order to choose a particular viewpoint. The
existenceofasetofpossiblesensormovementscallsforthedevelopmentofspecificalgorithmsthat
shouldsolvetheviewpointselectionproblem.Acomputervisionprogramshouldforinstancelook
back from past experience to see which viewpoint to use to provide the most useful information
about a scene. Optimizing the sensor displacements across time may then be a part of computer
visionalgorithms,incombinationwithtraditionalpixel-basedoperations.
Moregenerally,theideaofviewpointsselectionturnsouttoconsiderbeforehandthecomputations
thatneedtobedonetoachieveacertaintask.Avirtualsensingdeviceshouldforinstanceactlikea
filterthatwouldselectwhichpartofthesignalshouldbeworthconsidering,andwhichpartshould
bebypassed.Thismaybethecaseforrobotsanddronesthatneedtoreactfastwithlightandlow-
power sensing devices. Similarly, in computer vision, Mega-pixel high-resolution images appeals
for selective convolution over the images, in order to avoid unnecessary matrix products. Less in-
tuitively, the ever-growing learning databases used in machine learning also suggest an intelligent
scanning of the data, in a way that should retain only the critical examples or features, depending
onthecontext,beforeperforminglearningonit.Behindtheviewpointselectionproblemthusliesa
featureselectionproblem,whichshouldrelyonacontext.
1
8102
naJ
8
]EN.sc[
3v06401.0171:viXra
SubmittedtoICLR2018
Theconceptofactivevisionand/oractiveperceptionispresentinroboticliteratureunderdifferent
acceptances.InAloimonosetal.(1988),theauthorsaddressthecaseofmulti-viewimageprocessing
ofascene,i.e.showthatsomeill-posedobjectrecognitionproblemsbecomewell-posedassoonas
severalviewsonthesameobjectareconsidered.ThetermwasalsoproposedinBajcsy(1988)asa
roadmapforthedevelopmentofartificialvisionsystems,thatprovidesafirstinterpretationofactive
vision in the terms of sequential Bayesian estimation, further developed in Najemnik & Geisler
(2005);Butko&Movellan(2010);Ahmad&Angela(2013);Potthastetal.(2016).
The active inference paradigm was independently introduced in neuroscience through the work of
Friston (2010); Friston et al. (2012). The general setup proposed by Friston and colleagues is that
ofageneraltendencyofthebraintocounteractsurprisingandunpredictablesensoryeventsthrough
buildinggenerativemodelsthatimprovetheirpredictionsovertimeandrendertheworldmoreame-
nable.Thisimprovementismainlydonethroughsamplingtheenvironmentandextractingstatistical
invariants that are used in return to predict upcoming events. Building a model thus rests on ex-
tracting a repertoire of invariants and organizing them so as to process the incoming sensory data
efficientlythroughpredictivecoding(seeRao&Ballard(1999)).Thisproposition,gatheredunder
the “Variational Free Energy Minimization” umbrella, is reminiscent of the auto-encoding theory
proposed by Hinton & Zemel (1994), but introduces a new perspective on coding for it formally
links dictionary construction from data and (optimal) motor control. In particular, motor control
is here considered as a particular implementation of a sampling process, that is at the core of the
estimationofacomplexposteriordistribution.
2 ACTIVE INFERENCE
2.1 PERCEPTION-DRIVENCONTROL
Theactiveinferencereliesonalongstandinghistoryofprobabilisticmodellinginsignalprocessing
and control (see Kalman (1960); Baum & Petrie (1966); Friston et al. (1994)). Put formally, the
physicalworldtakestheformofagenerativeprocessthatisthecauseofthesensorystream.This
processisnotvisibleinitselfbutisonlysensedthroughanoisymeasureprocessthatprovidesan
observation vector x. The inference problem consists in estimating the underlying causes of the
observation,thatrestsonalatentstatevectorz andacontrolu.ThequestionaddressedbyFriston
etal.(2012)isthedesignacontroller thatoutputsacontrolufromthecurrentz estimatesoasto
maximize the accuracy of this state estimation process. This is the purpose of a perception-driven
controller.
Insteadofchoosinguatrandom,thegeneralobjectiveofanactiveinferenceframeworkistochoose
uinawaythatshouldminimizeatbestthecurrentuncertaintyaboutz.Theknowledgeaboutzcan
be reflected in a posterior distribution ρ(z). The better the knowledge (precision) about a sensory
scene,thelowertheentropyofρ,with:
H(ρ)=E [−logρ(z)] (1)
z∼ρ
ItisshowninFristonetal.(2012)thatminimizingtheentropyoftheposteriorthroughactioncan
be linked to minimizing the variational free energy attached to the sensory scene. The control u
is thus expected to reduce at best the entropy of ρ at each step. This optimal u is not known in
advance,becausexisonlyreadafteruhasbeencarriedout.Thencomesthepredictiveframework
thatidentifiestheeffectofuwithitsmostprobableoutcome,accordingtothegenerativemodel.
Ifwetakeastepback,thegeneralformulationofthegenerativemodelisthatofafeedbackcontrol
framework,underadiscreteBayesianinferenceformalism.Givenaninitialstatez ,theprediction
0
restsontwoconditionaldistributions,namelyP(Z|u,z )–thelinkdynamicsthatgeneratesz–and
0
P(X|z,u)–themeasureprocessthatgeneratesx–.Then,theforthcomingposteriordistributionis
(Bayesrule):
P(X,Z|u,z ) P(X|Z,u)P(Z|u,z )
P(Z|X,u,z )= 0 = 0 (2)
0 P(X|u,z ) (cid:80) P(X|z(cid:48),u)P(z(cid:48)|u,z )
0 z(cid:48) 0
sothattheforthcomingentropyexpectationis:
E [H(ρ)| ]=E [E [−logP(Z|X,u,z )]] (3)
X X,u,z0 X Z 0
2
SubmittedtoICLR2018
FIGURE1–Generativemodel(seetext)
andtheoptimaluis:
uˆ =argminE [H(ρ)| ] (4)
X X,u,z0
u∈U
Inpractice,theanalyticcalculationsareoutofreach(inparticularforpredictingthenextdistribu-
tion of x’s). One thus need to consider an estimate u˜ (cid:39) uˆ that should rely on sampling from the
generativeprocesstopredicttheeffectofu,i.e.
1 (cid:88)
u˜ =argmin −logP(z(i)|x(i),u,z ) (5)
N 0
u
i=1..N
x(i)∼P(X|u,z0)
z(i)∼P(Z|x(i),u,z0)
oronanevensharperdirectestimationthroughmaximumlikelihoodestimates(pointestimate):
x˜ =argmaxP(x|u,z ) (6)
u 0
x
z˜ =argmaxP(z|x˜ ,u,z ) (7)
u u 0
z
u˜ =argmin −logP(z˜ |x˜ ,u,z ) (8)
u u 0
u
Thisoperationcanberepeatedinasequence,wheretheactualcontrolu=u˜ isfollowedbyreading
theactualobservationx,whichinturnallowstoupdatetheactualposteriordistributionoverthez’s.
Thisupdatedposteriorbecomesthepriorofthenextdecisionstep,i.e.z ∼ P(Z|x,u,z )sothat
1 0
anewcontrolu canbecarriedout,etc.
1
IfwedenoteT thefinalstepoftheprocess,withu theactualsequenceofcontrolsandx
0:T−1 1:T
theactualsequenceofobservations,thefinalposteriorestimatebecomesP(Z |x ,u ,z ),
1:T 1:T 0:T−1 0
which complies with a Partially Observed Markov Decision Process (POMDP) estimation (see
fig.1),whosepolicywouldhavebeendefinedbytheentropyminimizationprinciplesdefinedabove,
preciselytofacilitatetheestimationprocess.Theactiveinferenceframeworkthusappearsasascene
understandingorientedpolicy(ithasnootherpurposethanfacilitateestimation).
2.2 ACTIVEVISION
The logic behind active vision is that of an external visual scene X that is never disclosed in full,
butonlysensedunderaparticularviewxundersensororientationu(likeitisthecaseinfoveated
vision).Knowingthatz isinvarianttochangingthesensorpositionu,uncoveringz shouldreston
collectingsensorypatchesx’sthroughchangingu(sensororientation)acrosstimeinordertorefine
z’s estimation. Considering now that a certain prior ρ (z) has been formed about z, choosing u
0
conductsthesightinaregionofthevisualscenethatprovidesx,whichinturnallowstorefinethe
estimationofz.Eachsaccadeshouldconsolidatearunningassumptionaboutthelatentstatez,that
mayberetainedandpropagatedfromsteptostep,untilenoughevidenceisgathered.
The active vision framework allows many relieving simplification from the general POMDP esti-
mationframework,firstinconsideringthatchanginguhasnoeffectonthesceneconstituents,i.e.
3
SubmittedtoICLR2018
P(Z |u,z ) = P(Z |z ).Then,usingthestaticassumption,thatconsidersthatnosignificant
t+1 t t+1 t
changeshouldtakeplaceinthesceneduringasaccadicexplorationprocess,i.e.∀t,t(cid:48),z =z =z.
t t(cid:48)
Thisfinallyentailsasimplifiedchainingoftheposteriorestimation:
P(x |Z,u )P(Z|x ,u ,z )
P(Z|x ,u ,z )= t+1 t 1:t 0:t−1 0 (9)
1:t+1 0:t 0 (cid:80) P(x |z(cid:48),u )P(z(cid:48)|x ,u ,z )
z(cid:48) t+1 t 1:t 0:t−1 0
issuingafinalestimateP(Z|x ,u ,z ).
1:T 0:T−1 0
Interpretation Theactiveinferenceframework,thatisrootedontheauto-encodingtheory(Free
Energy minimization) and predictive coding, provides a clear roadmap toward an effective imple-
mentationinartificialdevices.Itshouldrelyonthreeelements,namely:
— a generative model p that should predict the next view x under the current guess z and
0
viewpointu,
(cid:88)
p(.|u,z )(cid:39) P(X|z(cid:48),u)P(z(cid:48)|u,z )
0 0
z(cid:48)
— an inference model q that should predict the next posterior z under putative view x˜ and
viewpointu,i.e.
q(.|x˜,u,z )(cid:39)P(Z|x˜,u,z ) —seeeq.(2)—
0 0
(with the link dynamics P(Z|u,z ) implicitly embedded in both the generative and infe-
0
rencemodelsinthegeneralcase),
— andapolicyπthatshouldusea“two-stepsahead”prediction(nextviewpredictionfirstand
theninferenceonpredictedview)toissueanoptimalcontroluaccordingtoeithereq.(5)or
eqs.(6–8)
Under the computer vision perspective, and considering z = z (static scene assumption), each
0
different u corresponds to a different viewpoint over a static image, with a set of generative
{p (.|z)} andinference{q (.|x)} modelslearnedsystematicallyforeachdifferentview-
u u∈U u u∈U
pointu.Thoseplace-specificweakclassifierscontrastwiththeplace-invariantlow-levelfiltersused
in traditional image processing (see Viola et al. (2003)) and/or with the first layer of convolution
filtersusedinconvolutionalneuralnetworks.
3 IMPLEMENTATION
3.1 ALGORITHMS
As a preliminary step here, we suppose the predictive and generative models are trained apart for
wecanevaluatethepropertiesofthecontrolpolicysolely.Thismodel-basedapproachtosequential
viewselectionisprovidedinalgorithms1and2.
— Asignificantalgorithmicadd-onwhencomparedwithformulas(6–8)istheuseofadynamic
actionsset:U.Ateachturn,thenewselectedactionu˜isdrawnofffromU,sothatthenext
choice is made over fresh directions that have not yet been explored. This implements the
inhibitionofreturnprinciplestatedinItti&Koch(2001).
— AsecondalgorithmicaspectistheuseofathresholdH tostoptheevidenceaccumulation
ref
processwhenenoughevidencehasbeengathered.Thisthresholdisafreeparameterofthe
algorithmthatsetswhetherweprivilegeaconservative(tight)oroptimistic(loose)threshold.
Thestoppingcriterionneedstobeoptimizedtoarbitratebetweenresourcesavingandcoding
accuracy.
3.2 FOVEA-BASEDMODEL
Insuperiorvertebrates,twoprincipaltricksareusedtominimizesensoryresourceconsumptionin
scene exploration. The first trick is the foveated retina, that concentrates the photoreceptors at the
centeroftheretina,withamorescarcedistributionattheperiphery.Afoveatedretinaallowsboth
treating central high spatial frequencies, and peripheral low spatial frequencies at a single glance
(i.eprocessseveralscalesinparallel).Thesecondtrickisthesequentialsaccadicsceneexploration,
already mentioned, that allows to grab high spatial frequency information where it is necessary
(serialprocessing).
4
SubmittedtoICLR2018
Algorithm1Prediction-BasedPolicy
Require: p(generator),q(inference),ρ(prior),U (actionsset)
predictz ∼ρ
∀u∈U,generatex˜ ∼p(x|z,u)
u
return u˜=argmaxq(z|x˜ ,u)
u
u∈U
Algorithm2SceneExploration
Require: p(generator),q(inference),ρ (initialprior),U (actionsset)
0
ρ←ρ
0
whileH(ρ)>H do
ref
choose:u˜←Prediction-BasedPolicy(p,q,ρ,U)
read:x
u˜
update:∀z,odd[z]←logq(z|x ,u˜)+logρ(z)
u˜
ρ←softmax(odd){theposteriorbecomesthepriorofthenextturn}
U ←U \{u˜}
endwhile
return ρ
The baseline vision model we propose relies first on learning local foveated views on images.
ConsistentlywithKortum&Geisler(1996);Wangetal.(2003),werestrainherethefovealtrans-
formation to its core algorithmic elements, i.e. the local compression of an image according to a
particularfocus.Ourfovealimagecompressionthusrestsona"pyramid"of2DHaarwaveletcoef-
ficientsplacedatthecenterofsight.TakingtheexampleoftheMNISTdatabase,wefirsttransform
theoriginalimagesaccordingtoa5-levelswaveletdecomposition(seefigure2b).Wethendefinea
viewpointuasasetof3coordinates(i,j,h),withitherowindex,jthecolumnindexandhthespa-
tialscale.Eachumaycorrespondtoavisualfieldmadeofthreeofwaveletcoefficientsx ∈R3,
i,j,h
obtainedfromanhorizontal,averticalandanobliquefilteratlocation(i,j)andscaleh.Themultis-
calevisualinformationx ∈R15availableatcoordinates(i,j)correspondstoasetof5coefficient
i,j
triplets,namelyx = {x ,x ,x ,x ,x }(seefi-
i,j i,j,5 (cid:98)i/2(cid:99),(cid:98)j/2(cid:99),4 (cid:98)i/4(cid:99),(cid:98)j/4(cid:99),3 (cid:98)i/8(cid:99),(cid:98)j/8(cid:99),2 (cid:98)i/16(cid:99),(cid:98)j/16(cid:99),1
gure2c), sothat eachmultiscalevisual fieldowns 15coefficients(as opposedto784 pixelsin the
originalimage).Fig.2ddisplaysareconstructedimagefromthe4centralviewpointsatcoordinates
(7,7),(7,8)(8,7)and(8,8).
A weak generative model is learned for each u = (i,j,h) (making a total of 266 weak models)
over 55,000 examples of the MNIST database. For each category z and each gaze orientation u,
a generative model is built over parameter set Θ = (ρ ,µ ,Σ ), so that ∀z,u,x˜ ∼
z,u z,u z,u z,u z,u
B(ρ )×N(µ ,Σ )withBaBernouillidistributionandN amultivariateGaussian.TheBer-
z,u z,u z,u
nouilli reports the case where the coefficient triplet is null in the considered portion of the image
(whichisquitecommonintheperipheryoftheimage),whichresultsindiscardingthecorresponding
tripletfromtheGaussianmomentscalculation.Eachresultingweakgenerativemodelp(X|z,u)is
a b c d
FIGURE2–Foveatedimageconstruction.
5
SubmittedtoICLR2018
amixtureofBernouilli-gatedGaussiansoverthe10MNISTlabels.Fortheinferencemodel,apos-
teriorcanherebecalculatedexplicitlyusingBayesrule,i.e.q(Z|x,u)=softmaxlogp(x|Z,u).
Thesaccadeexplorationalgorithmisanadaptationofalgorithm2.Theprocessstartsfromaloose
assumptionbasedonreadingtherootwaveletcoefficientoftheimage,fromwhichaninitialguessρ
0
isformed.Then,eachfollow-upsaccadeiscalculatedonthebasisofthefinalcoordinates(i,j) ∈
[0,..,15]2, so that the posterior calculation is based on several coefficient triplets. After selecting
(i,j), all the corresponding coordinates (h,i,j) are discarded from U and can not be reused for
upcoming posterior estimation (for the final posterior estimate may be consistent with a uniform
scanoverthewaveletcoefficients).
Anexampleofsuchsaccadicimageexplorationispresentedinfigure3aoveroneMNISTsample.
The state of the recognition process after one saccade is shown on fig. 3b. The next saccade (fig.
3c)heads towarda regionof theimage thatis expectedto helpconfirm theguess. The continuing
saccade (fig. 3d) makes a close-by inspection and the final saccade (fig. 3e) allows to reach the
posterior entropy threshold, set at H = 1e−4 here. The second row shows the accumulation of
ref
evidenceoverthecoefficientstriplets,withfig.3fshowingtheposteriorsupdateofdifferentlabels
andfig.3gshowingtheposteriorentropyupdateaccordingtothecoefficientstripletsactuallyread.
Note that several triplets are read for each end-effector position (i,j) (see fig. 2c). There is for
instance a total of 5 triplets read out at the initial gaze orientation (b), and then 4 triplets read-out
foreachcontinuingsaccades.
The model provides apparently realistic saccades, for they cover the full range of the image and
tendtopointoverregionsthatcontainclass-characteristicpixels.Theimagereconstructionafter4
saccadesallowstovisuallyrecognizea"fuzzy"three,whileitwouldnotnecessarilybethecaseif
thesaccadeswerechosenatrandom.Theobservedtrajectoryillustratestheguessconfirmationlogic
that is behind the active vision framework. Every saccade heads toward a region that is supposed
toconfirmthecurrenthypothesis.Thisconfirmationbiasappearscounter-intuitiveatfirstsight,for
a b c d e
Read-outsteps Read-outsteps
f g
FIGURE 3–Sceneexplorationthroughsaccadesinthefoveatedvisionmodel.a.Saccadestra-
jectoryovertheoriginalimage(initialgazeorientationindicatedwithared"plus").b–e.Progressive
image reconstruction over the course of saccades, with b : 5 coefficients triplets + root coefficient
(initial gaze orientation), c : 9 coefficients triplets + root coefficient (first saccade), d : 13 coeffi-
cientstriplets+rootcoefficient(secondsaccade),e:17coefficientstriplets+rootcoefficient(third
saccade)f.Posteriorupdateinfunctionofthenumberofread-outsteps(notingthatstep1stemsfor
therootcoefficientandthenextstepsstemfor3Haarwaveletcoefficientsread-out),withonecolor
percategory(thenumbersoverthelinesprovidethecompetinglabels)g.Posteriorentropyupdate
infunctionofthenumberofread-outsteps.
6
SubmittedtoICLR2018
somewouldexpecttheeyetoheadtowardplacesthatmaydisprovetheassumption(tochallengethe
current hypothesis). This is actually not the case for the class-confirming regions are more scarce
thantheclass-disprovingregions,sothatheadingtowardaclass-confirmingregionmaybringmore
informationinthecaseitwould,bysurprise,invalidatetheinitialassumption.
3.3 SALIENCY-BASEDPOLICY
Thescalingofthemodelneedstobeaddressedwhenlargeimagesareconsidered.Thepolicyrelies
onatwo-stepsaheadprediction(eqs(6–8)andalgorithm1)thatscaleslikeO(|U|.|Z|)foritpredicts
thenextposteriordistributionoverthez’sforeachvisualpredictionx .Incomparison,parametrized
u
policiesaremorecomputationallyefficient,allowingforasingledrawovertheactionssetgivena
context. Luckily, such a parametrized policy is here straightforward to compute. Taking z as the
0
initial guess, and noting x˜ the visual generative prediction when z is assumed under visual
u,z0 0
orientation u, and assuming a uniform prior over the latent states, the process-independent look-
aheadposterioris:
p(x˜ |.,u)
ρ (.)= u,z0 (10)
u,z0 (cid:80) p(x˜ |z(cid:48),u)
z(cid:48) u,z0
providing at each (u,z ) an offline prediction, namely ρ (z ). Those offline computations pro-
0 u,z0 0
vide,foreachguessz ,asaliencymapovertheu’s.
0
Low-level features-based saliency maps date back from Itti & Koch (2001), with many follow-
ups and developments in image/video compression (see for instance Wang et al. (2003)). In our
case,asaliencymapisprocessedforeachguessz ,drivingtheviewpointselectionregardingz ’s
0 0
confirmation.Saliency-basedpoliciesthenallowtodefineanoptimalsaccadepathwaythroughthe
a b c d e f
Classification rate Mean / Median #saccades
95 # saccades distribution 45
predictive policy random policy (mean)
102 40 s p a re li d e i n c c t y iv - e b a p s o e l d ic y p o (m lic e y a ( n m ) ean)
90 101 35 r s a a n li d e o n m cy - p b o a l s ic e y d ( p m o e li d c i y a n (m ) edian)
predictive policy (median)
100 30
85 saliency-based
102 policy 25
101 20
80
100 15
75 p sa re li d e i n c c t y iv - e b a p s o e l d ic y policy 102 random policy 10
random policy
exhaustive scan 101 5
70 100 0
1e-1 1e-2 1e-3 1e-4 1e-5 1e-1 1e-2 1e-3 1e-4 1e-5 1e-1 1e-2 1e-3 1e-4 1e-5
Href Href Href
FIGURE4–Saliencybasedpolicy–Upperpanel:Saliencymapsinferredfromthemodelwith
correspondingsaccadestrajectoryprototypes.a.Saliencymapforlatentclass“1”.b.5-saccades
trajectoryprototypeforlatentclass“1”(initialpositionindicatedwithared“plus”)overclassave-
rage. c. Saliency map for latent class “2”. d. 5-saccades trajectory prototype for latent class “2”
overclassaverage.e.Saliencymapforlatentclass“3”.f.5-saccadestrajectoryprototypeforlatent
class “3” over class average. Lower panel : Policy comparison (left) Classification rate for the
predictivepolicy,thesaliencybasedpolicyandauniformrandompolicy,fordifferentrecognition
thresholds.Theexhaustivescan(baseline)recognitionrateisreddashed.(middle)Numberofsac-
cades distribution for the predictive policy, the saliency-based policy and the random policy. The
boxesindicatethefirstandthirdquartiles.(right)Meanandmediannumberofsaccadesinfunction
oftherecognitionthresholdforthedifferentconsideredpolicies.
7
SubmittedtoICLR2018
image that follow a sequence of “salient” viewpoints with decreasing saliency (according to the
inhibition of return). In our case, the viewpoint selected at step t depends on the current guess z ,
t
withon-the-flymapswitchiftheguessisrevisedacrossthecourseofsaccades.
Examplesofsuchsaliencymapsareprovidedintheupperpaneloffigure4,forcategories1to3.
The saliency maps allow to analyze in detail the class-specific locations (that appear brownish) as
opposed to the class-unspecific locations (pale orange to white). First to be noticed is the relative
scarcenessoftheclass-specificlocations.Those"evidenceproviding"locationsappear,asexpected,
mutually exclusive from class to class. A small set of saccades is expected to provide most of the
classification information while the rest of the image is putatively uninformative (or even counter
informative if whitish). A second aspect is that the class-relevant locations are all located in the
central part of the images, so there is very few chance for the saccades to explore the periphery
of the image where little information is expected to be found. This indicates that the model has
captured the essential concentration of class-relevant information in the central part of the images
forthatparticulartrainingset.
The lower part of figure 4 provides an overview of the model behavior in function of the recogni-
tionthresholdH .Theoriginalpredictivepolicyiscomparedto(i)thesaliency-basedpolicythat
ref
selects the saliency map in function of the current guess z and (ii) a uniform random exploration
t
(choose next viewpoint at random). The classification rates, shown in the leftmost figure, mono-
tonically increase with a decreasing recognition threshold. Considering a 92% recognition rate as
the upper bound here (corresponding to an exhaustive decoding made with 266 weak classifiers –
a close equivalent of a linear classifier), a near optimal recognition rate is obtained for both the
predictiveandsaliency-basedpoliciesforH approaching1e−5,whiletherandompolicyreveals
ref
clearly sub-optimal. Acomplementary effectis the monotonicincrease of thenumber of saccades
withdecreasingH showninthecentralandrightmostfigures.Thenumberofsaccadesisrepre-
ref
sentativeoftherecognitiondifficulty.Thedistributionofthenumberofsaccadesisveryskewedin
allcases(centralfigure),withfewsaccadesinmostcases,reflecting“peace-of-cake”recognitions,
andmanysaccadesmorerarelyreflectinga“hard-to-reach”recognition.Forboththepredictiveand
thesaliency-basedpolicies,lessthan5saccadesisenoughtoreachtherecognitionthresholdinmore
than50%ofthecases(versusabout15intherandomexplorationcase)forH =10−5.
ref
A strong aspect of the model is thus its capability to do efficient recognition with very few Haar
coefficients (and thus very few pixels) in most cases at low computational cost using using either
a full predictive policy or pre-processed maps and saccade trajectories. The number of saccades
reflectstheprocessinglengthofthescene.Forinstance,anaveragenumberofsaccadesbetween10
and15whenH = 1e−4 correspondstoanaveragecompressionof85-90%ofthedataactually
ref
processed to recognize a scene. It can be more if the threshold is more optimistic, and less if it is
moreconservative.
4 RELATED WORK AND PERSPECTIVES
Optimizing foveal multi-view image inspection with active vision has been addressed for quite a
while in computer vision. Direct policy learning from gradient descent was e.g. proposed in 1991
by Schmidhuber & Huber (1991) using BPTT through a pre-processed forward model. The em-
beddingofactivevisioninaBayesian/POMDPevidenceaccumulationframeworkdatesbackfrom
Bajcsy(1988),withamoreformalelaborationinNajemnik&Geisler(2005)andButko&Movellan
(2010).Itgloballycomplieswiththepredictivecodingframework(Rao&Ballard(1999))withthe
predictions from the actual posterior estimate used to evaluate the prediction error and update the
posterior. The "pyramidal" focal encoding of images is found in Kortum & Geisler (1996); Wang
et al. (2003), with Butko & Movellan (2010) providing a comprehensive overview of a foveated
POMDP-based active vision, with examples of visual search in static images using a bank of pre-
processedfeaturesdetectors.Finally,theideaofhavingmanymodelstoidentifyascenecomplies
withtheweakclassifiersevidenceaccumulationprinciple(seeViolaetal.(2003)andsequels),and
generalizestothemulti-viewselectioninobjectsearchandscenerecognitionPotthastetal.(2016).
Our contribution is twice, for it provides hints toward expressing the view-selection problem in
thetermsofprocessingcompressionundertheFreeEnergy/minimumdescriptionlengthsetup(see
Hinton&Zemel(1994)),allowingfuturedevelopmentsinoptimizingconvolutionalprocessing(see
also Louizos et al. (2017)). A second contribution is a clearer description of the active vision as a
8
SubmittedtoICLR2018
two-steps-aheadpredictionusingthegenerativemodeltodrivethepolicy(withoutpolicylearning).
Though optimizing future posterior entropy over the actions set is shown enough to attain locally
optimal action selection, offline calculation using class-specific saliency maps is way better for it
savesprocessingcostsbyseveralordersthroughsaccadespathwayspre-processing,withanegligible
effect on the recognition/compression rates. This may be used for developing active information
search in the case of high dimensionality input data (feature selection problem). The model thus
needstobetestedonmorechallengingcomputervisionsetups,inordertotesttheexactcounterpart
ofusingpre-processedsaliencymapswithrespecttothefullpredictivecase.
RÉFÉRENCES
SheerazAhmadandJYuAngela. Activesensingasbayes-optimalsequentialdecision-making. In
UncertaintyinArtificialIntelligence,pp. 12.Citeseer,2013.
John Aloimonos, Isaac Weiss, and Amit Bandyopadhyay. Active vision. International journal of
computervision,1(4):333–356,1988.
RuzenaBajcsy. Activeperception. ProceedingsoftheIEEE,76(8):966–1005,1988.
Leonard E Baum and Ted Petrie. Statistical inference for probabilistic functions of finite state
markovchains. Theannalsofmathematicalstatistics,pp.1554–1563,1966.
NicholasJButkoandJavierRMovellan. Infomaxcontrolofeyemovements. IEEETransactions
onAutonomousMentalDevelopment,2(2):91–107,2010.
KarlFriston. Thefree-energyprinciple:aunifiedbraintheory? NatureReviewsNeuroscience,11
(2):127–138,2010.
KarlFriston,RickAdams,LaurentPerrinet,andMichaelBreakspear. Perceptionsashypotheses:
saccadesasexperiments. Frontiersinpsychology,3:151,2012.
KarlJFriston,AndrewPHolmes,KeithJWorsley,J-PPoline,ChrisDFrith,andRichardSJFra-
ckowiak. Statisticalparametricmapsinfunctionalimaging:agenerallinearapproach. Human
brainmapping,2(4):189–210,1994.
GeoffreyEHintonandRichardSZemel.Autoencoders,minimumdescriptionlengthandhelmholtz
freeenergy. InAdvancesinneuralinformationprocessingsystems,pp.3–10,1994.
LaurentIttiandChristofKoch. Computationalmodellingofvisualattention. Naturereviewsneu-
roscience,2(3):194–203,2001.
Rudolph Emil Kalman. A new approach to linear filtering and prediction problems. Journal of
FluidsEngineering,82(1):35–45,1960.
PhilipKortumandWilsonSGeisler. Implementationofafoveatedimagecodingsystemforimage
bandwidthreduction.InHumanVisionandElectronicImaging,volume2657,pp.350–360,1996.
ChristosLouizos,KarenUllrich,andMaxWelling. Bayesiancompressionfordeeplearning. arXiv
preprintarXiv:1705.08665,2017.
JiriNajemnikandWilsonSGeisler. Optimaleyemovementstrategiesinvisualsearch. Nature,434
(7031):387–391,2005.
Christian Potthast, Andreas Breitenmoser, Fei Sha, and Gaurav S Sukhatme. Active multi-view
objectrecognition:Aunifyingviewononlinefeatureselectionandviewplanning. Roboticsand
AutonomousSystems,84:31–47,2016.
RajeshPNRaoandDanaHBallard. Predictivecodinginthevisualcortex:afunctionalinterpreta-
tionofsomeextra-classicalreceptive-fieldeffects. Natureneuroscience,2(1),1999.
JuergenSchmidhuberandRudolfHuber. Learningtogenerateartificialfoveatrajectoriesfortarget
detection. InternationalJournalofNeuralSystems,2(01n02):125–134,1991.
9
SubmittedtoICLR2018
M Viola, Michael J Jones, and Paul Viola. Fast multi-view face detection. In Proc. of Computer
VisionandPatternRecognition.Citeseer,2003.
ZhouWang,LigangLu,andAlanCBovik. Foveationscalablevideocodingwithautomaticfixation
selection. IEEETransactionsonImageProcessing,12(2):243–254,2003.
Alfred L Yarbus. Eye movements during perception of complex objects. In Eye movements and
vision,pp.171–211.Springer,1967.
10