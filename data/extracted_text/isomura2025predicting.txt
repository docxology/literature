bioRxiv preprint doi: https://doi.org/10.1101/2025.08.06.668947; this version posted August 7, 2025. The copyright holder for this preprint
(which was not certified by peer review) is the author/funder. All rights reserved. No reuse allowed without permission.
Predicting individual learning trajectories in zebrafish via
the free-energy principle
Takuya Isomura1*, Yuki Tanimoto2,3, Makio Torigoe2, Hitoshi Okamoto2,3,4, Hideaki Shimazaki5
1 Brain Intelligence Theory Unit, RIKEN Center for Brain Science, 2-1 Hirosawa, Wako, Saitama 351-
0198, Japan
2 RIKEN Center for Brain Science, 2-1 Hirosawa, Wako, Saitama 351-0198, Japan
3 Faculty of Science and Engineering, Waseda University, 2-2 Wakamatsu-cho, Shinjuku-ku, Tokyo
162-8489, Japan
4 Institute of Neuropsychiatry, 91 Bentencho, Shinjuku-ku, Tokyo 162-0851, Japan
5 Graduate School of Informatics, Kyoto University, 36-1 Yoshidahonmachi, Sakyo-ku, Kyoto 606-
8501, Japan
* Corresponding author email: takuya.isomura@riken.jp
1
bioRxiv preprint doi: https://doi.org/10.1101/2025.08.06.668947; this version posted August 7, 2025. The copyright holder for this preprint
(which was not certified by peer review) is the author/funder. All rights reserved. No reuse allowed without permission.
The free-energy principle has been proposed as a unified theory of brain function, and recent
evidence from in vitro experiments supports its validity. However, its empirical application to in
vivo neuronal dynamics during active decision-making remains limited. This work reverse-
engineered generative modelsâ€”cast as canonical neural networksâ€”from large-scale calcium
imaging data of zebrafish performing a visually guided go/no-go task in a virtual-reality
environment. Leveraging the formal equivalence between neural network dynamics and
variational Bayesian inference, we constructed biologically plausible synthetic agents capable of
active inference. These agents recapitulated individual variability in zebrafish neuronal dynamics
and behaviour by identifying subject-specific prior and posterior beliefs. Additionally, they enabled
quantitative predictions of long-term changes in neural activity, effective synaptic connectivity, and
behavioural performance, including task accuracy after training. Our results demonstrate a
powerful framework of active inference for modelling in vivo neuronal self-organisation and
highlight the predictive validity of the free-energy principle in behaving animals.
INTRODUCTION
Elucidating the computational principles underlying brain functions remains a central goal of
neuroscience [1â€“4]. A fundamental criterion for any such principle is predictive power, that is, the
ability to anticipate how brain function unfolds over time. Such predictions can deepen our
understanding of the emergence of cognitive function and the progression of neurodegenerative
and psychiatric disorders [5]. However, unlike recent successes in short-term predictions [6â€“9],
predicting the long-term self-organisation of neural circuitsâ€”including synaptic plasticity and
emergent network dynamicsâ€”remains challenging. This difficulty arises in part from the limited
resolution and coverage of empirical measurements, which constrain bottom-up approaches that
2
bioRxiv preprint doi: https://doi.org/10.1101/2025.08.06.668947; this version posted August 7, 2025. The copyright holder for this preprint
(which was not certified by peer review) is the author/funder. All rights reserved. No reuse allowed without permission.
attempt to model neuronal self-organisation purely from data. To overcome these limitations, this
work proposes the integration of empirically grounded inferences with normative computational
theories of brain function.
The free-energy principle has emerged as a comprehensive theory of the brain to account for
perception, learning, and action of all biological organisms [10,11]. The principle posits that the
brain performs variational Bayesian inference [12] of external milieu by minimising variational free
energy as a tractable proxy for minimising surprise. This entails the updates of posterior beliefs
about external milieu states encoded by neural activity and synaptic weights. Moreover, animals
can infer and then select actions that minimise expected risk associated with future outcomes, a
process termed active inference [13,14]. These types of inferences rest upon generative models,
that is, internal hypotheses or representations of the external milieu that express how external
states generate sensory input. Recent theoretical work has shown that canonical neural networks
can implement such generative models within their network architecture, thereby performing
active inference through neural activity and synaptic plasticity in a biologically plausible manner
[15â€“18]. In particular, delayed modulation of Hebbian plasticity [19â€“22] in the form of three-factor
learning [23â€“25] is a possible implementation of active inference, in which agents minimise future
risks by retrospectively updating behavioural strategies [16].
Despite numerous theoretical works, the free-energy principle has been criticised for its
apparent unfalsifiability owing to the broad generality of its claims. However, it becomes testable
when applied to specific systems with well-defined biological constraints [26]. To this end, previous
works have developed a reverse engineering scheme to identify generative models from empirical
neural data [15,16] and have demonstrated that this principle can accurately predict the self-
organisation of in vitro neural networks of rat cortical cells when assimilating sensory information
3
bioRxiv preprint doi: https://doi.org/10.1101/2025.08.06.668947; this version posted August 7, 2025. The copyright holder for this preprint
(which was not certified by peer review) is the author/funder. All rights reserved. No reuse allowed without permission.
[27]. However, extending this approach to behaving animals in vivo remains a critical step toward
validating the relevance of this principle to naturalistic cognitive function.
To pursue this type of validation, zebrafish are an ideal model animal owing to their genetic
tractability and amenability to large-scale calcium imaging [28,29]. Despite their simplicity
compared to mammals, zebrafish exhibit conserved neuroanatomical structures and behavioural
capabilities [30â€“32]. Previous work established a go/no-go decision-making paradigm in a virtual
reality environment, in which zebrafish engage in state inference and action selection by
associating colour cues and visual flow with punishment, consistent with active inference [33].
Their rapid learning within a few hours facilitates continuous tracking of large-scale neuronal
dynamics across learning phases, making them suited for comparing empirical changes with
theoretical predictions [34].
In the present work, we reverse engineered canonical neural network models from zebrafish
calcium imaging data during a decision-making task, yielding individual-specific generative models.
These models enabled the construction of â€˜synthetic fish agentsâ€™ that perform active inference,
recapitulating the inter-individual variability in behavioural performance and neural circuit
propertiesâ€”including differences in internal representation, effective synaptic connectivity, and
subjective risk between learners and non-learners. Subsequently, we demonstrated the
predictability of these agents for unseen data by reverse engineering generative models based only
on the initial empirical data before punishment was provided. These agents could predict long-
term changes in neural activity and behaviour over the training period, outperforming
conventional statistical and theory-based methods. Our results highlight active inference as a
mechanistic and predictive framework for modelling in vivo neuronal self-organisation.
4
bioRxiv preprint doi: https://doi.org/10.1101/2025.08.06.668947; this version posted August 7, 2025. The copyright holder for this preprint
(which was not certified by peer review) is the author/funder. All rights reserved. No reuse allowed without permission.
RESULTS
Zebrafish go/no-go decision-making paradigm
We began by outlining a zebrafish go/no-go decision-making task [33]. Head-fixed zebrafish
were immersed in a virtual reality environment created using visual displays (Fig. 1a). Tail motion,
captured by the camera, allowed the fish to navigate forward in the virtual space. Forward
movement was visualised as black stripes moving against a coloured background. After an interval
with a white background, the fish randomly engaged in either the go or no-go trial. In the go trial
(Fig. 1a, top), the fish began in the blue zone; remaining there for 10 s triggered an aversive weak
electric stimulus, whereas forward movement into the red zone prevented punishment.
Conversely, in the no-go trial (Fig. 1a, bottom), fish started in the red zone; remaining there for 10 s
prevented punishment, whereas moving forward into the blue zone was punished.
These randomly interleaved trials required the fish to infer the hidden environmental stateâ€”
that is, whether the environment is safe or dangerousâ€”based on sensory input and select their
actions accordingly. During the initial 20-trial adaptation phase, no punishment was delivered, and
the fish exhibited inherent (i.e., unconditioned) swimming behaviour irrespective of the conditions
(Fig. 1b, left). Training continued for 80 trials and was divided into early (21â€“60) and late (61â€“100)
phases. As the training progressed, the fish learned to swim selectively in the go trials and to
remain still in the no-go trials (Fig. 1b, right). Learners were defined as individuals with success
rates of at least 0.5 in both go and no-go trials and a marginal success rate of at least 0.6 during
the late training phase (Fig. 1c). Of the 45 fish, 30 met these criteria and were classified as
learners, whereas the remaining 15 were designated non-learners.
To investigate the neuronal basis of inference and decision-making in zebrafish, two-photon
calcium imaging was performed during the aforementioned go/no-go task (Fig. 1d). From each
5
bioRxiv preprint doi: https://doi.org/10.1101/2025.08.06.668947; this version posted August 7, 2025. The copyright holder for this preprint
(which was not certified by peer review) is the author/funder. All rights reserved. No reuse allowed without permission.
fish, 440 Â± 153 (mean Â± standard deviation (SD)) neurons were recorded across the telencephalon,
and they exhibited activity patterns indicative of internal representations of the external milieu.
We first quantified the extent to which neural activity could be explained by task-relevant
variables. Approximately 38% of the observed activity variance was accounted for by a set of nine
sensory and behavioural features, including four conditions determined by two task types and
colour cues (go&blue, go&red, no-go&red, and no-go&blue), inter-trial interval (white), optic
flows, weak electric stimuli, motor actions, and position (Fig. 1e). Notably, neural activity encoding
danger/safety states in response to colour cues (blue/red) occupied a substantial portion of the
task-related neural variance, and the amplitudes of their variances increased during the training
period (Fig. 1f). These results suggest that the zebrafish neurons formed internal representations
of task-relevant hidden states and determined their behaviour accordingly.
Fig. 1. Zebrafish go/no-go decision-making paradigm. a. Schematic of a go/no-go decision-making
task for zebrafish. Previous work developed a virtual reality-based experimental paradigm to train
zebrafish [33], where head-fixed zebrafish was placed in a chamber surrounded by monitors to
6
bioRxiv preprint doi: https://doi.org/10.1101/2025.08.06.668947; this version posted August 7, 2025. The copyright holder for this preprint
(which was not certified by peer review) is the author/funder. All rights reserved. No reuse allowed without permission.
provide a virtual reality environment. Zebrafish underwent a go/no-go decision making to swim in
response to blue cue (go, top) and remain in position in response to red cue (no-go, bottom) to
avoid weak electric stimuli. b. Zebrafish movements before (left) and after (right) training. Data
from a typical learner are shown. c. Task success rates before (left) and after (right) training. Data
from 30 learners and 15 non-learners are shown. d. Two-photon calcium imaging of head-fixed
zebrafish. Neural activity was measured during learning of the decision-making task across the
telencephalon [33]. e. Pie chart representing the ratio of variances of neural activity explained by
nine external information. The averaged contributions over 17,226 neurons from 39 fish are
shown. f. Changes in neural activity encoding blue and red states. Their increase during training
implies that these neurons self-organised to encode danger and safety states. Lines and error bars
represent mean values Â± SDs. In (dâ€“f), a deconvolution filter was applied to the region of interest
(ROI) signals, and 17,226 neurons from 39 fish that were properly detected activity were analysed.
However, as the deconvolution filter was unable to properly extract activity from some neurons
owing to noise, we used ROI signals without deconvolution in the subsequent analysis.
Reverse engineering generative models from neuronal data
The aforementioned observations were incorporated into the modelling as follows: in our task
design, the input generative process was defined by two latent environmental statesâ€”danger and
+
safetyâ€”represented as a two-dimensional hidden state vector ğ‘ (ğ‘¡) = &ğ‘  (ğ‘¡),ğ‘  (ğ‘¡)( ,
!"#$%& â€™"(%)*
and their transitions were determined by the fishâ€™s action ğ›¿(ğ‘¡) (Fig. 2a, top). These hidden states
+
generated four-dimensional sensory inputs ğ‘œ(ğ‘¡) = &ğ‘œ (ğ‘¡),ğ‘œ (ğ‘¡),ğ‘œ (ğ‘¡),ğ‘œ (ğ‘¡)( ,
,-.% &%! (-/0 â€™)12
expressing blue, red, and flow visual inputs, and weak electric stimuli (Fig. 2a, bottom).
Then, we modelled zebrafish neuronal networks using canonical neural networks that offer
7
bioRxiv preprint doi: https://doi.org/10.1101/2025.08.06.668947; this version posted August 7, 2025. The copyright holder for this preprint
(which was not certified by peer review) is the author/funder. All rights reserved. No reuse allowed without permission.
biologically plausible dynamics consistent with established realistic neuron models [16] (Fig. 2b,
+
left). The network comprises two middle-layer neuronal ensembles ğ‘¥(ğ‘¡) = ,ğ‘¥ (ğ‘¡),ğ‘¥ (ğ‘¡)- , which
3 4
receive sensory inputs ğ‘œ(ğ‘¡) and produce an output-layer activity ğ‘¦(ğ‘¡). The output activity ğ‘¦(ğ‘¡)
drives the agentâ€™s actions ğ›¿(ğ‘¡) (i.e., tail motions). These neural activities follow differential
equations for rate-coding models with sigmoidal activation functions derived as a gradient descent
on Helmholtz energy ğ’œ (Fig. 2c, top left; refer to the Methods section for equations). The
changes in synaptic weights (denoted as matrices ğ‘Š, ğ¾, and ğ‘‰) follow conjugate synaptic
plasticity rules derived as a gradient descent on the same ğ’œ with respect to these weights, thus
furnishing biologically grounded learning rules (Fig. 2c, bottom left). In particular, the update of the
output-layer synaptic weights ğ‘‰ = (ğ‘‰ ,ğ‘‰ ) takes the form of a three-factor learning rule [23â€“
33 34
25], which is mediated by risk-encoding neuromodulators ğ›¤ such as dopaminergic or
noradrenergic neurons [16].
Previous works have mathematically illustrated a formal equivalence between the Helmholtz
energy ğ’œ in canonical neural networks (Fig. 2c, middle left) and variational free energy â„± in the
free-energy principle (Fig. 2c, middle right) by showing one-to-one correspondences between their
components [15â€“18] (Table 1), that is, ğ’œ â‰¡ â„±. This mathematical equivalence indicates that the
neural activity and synaptic plasticity that minimise the shared Helmholtz energy can be
conceptualised as performing active inference, that is, Bayesian belief updating to infer latent
environmental states and actions (Fig. 2b, right). For instance, delayed modulation of Hebbian
plasticity [19â€“22] is shown to be a sufficient neuronal substrate for implementing active inference
that minimises risk associated with future outcomes [16]. This equivalence offers a unified
explanation for neuronal dynamics and computation, providing a normative and mechanistic
account that links physiological phenomena to cognitive functions.
8
bioRxiv preprint doi: https://doi.org/10.1101/2025.08.06.668947; this version posted August 7, 2025. The copyright holder for this preprint
(which was not certified by peer review) is the author/funder. All rights reserved. No reuse allowed without permission.
Building on this foundation, we propose a method to reverse-engineer generative models from
empirical brain activity data and test the predictive validity of active inference [26,27]. The
procedure begins by fitting experimentally recorded neural activity to a canonical neural network
(Fig. 2d, left), in which empirical neural activities were systematically allocated to the two
ensembles ğ‘¥(ğ‘¡) by minimising ğ’œ. This allocation is a projection of high-dimensional neuron-wise
data onto a two-dimensional subspace of ğ‘¥(ğ‘¡) that maximises predictability, thus facilitating the
extraction of task-relevant neural activity. From this, latent internal parametersâ€”including
effective synaptic connectivity, firing thresholds, and subjective risksâ€”were statistically estimated
by minimising the same ğ’œ (Fig. 2d, right). A complete description of the procedure is provided in
the Methods section â€œReverse engineering of generative modelsâ€.
Once the canonical neural network has been reconstructed, the associated Helmholtz energy ğ’œ
can be used to derive the corresponding variational free energy â„± and its generative model (Fig.
2c). This enables a formal, one-to-one mapping between neural network properties and those of
Bayesian inference under a certain generative model that embodies an animalâ€™s internal
hypotheses (Table 1). Under this framework, empirical properties of neural activity and synaptic
weights were made explainable in terms of posterior beliefs, enabling a formal characterisation of
the animalâ€™s perceptions and actions.
Subsequently, empirically derived generative models are used to construct synthetic agents
capable of prediction, learning, and action selection (Fig. 2e). The gradient descent on â„±
furnishes a synaptic plasticity rule for these synthetic agents. Crucially, this framework supports
forward inference (i.e., extrapolation): the free-energy principle posits that neural activity and
synaptic plasticity pursue the free energy gradient. Therefore, if active inference is applied, these
synthetic agents should be able to predict future latent variables and emulate an animalâ€™s
9
bioRxiv preprint doi: https://doi.org/10.1101/2025.08.06.668947; this version posted August 7, 2025. The copyright holder for this preprint
(which was not certified by peer review) is the author/funder. All rights reserved. No reuse allowed without permission.
behaviour and neuronal dynamics when exposed to the same task environment. This allows us to
test the predictive validity of the free-energy principle and active inference [26].
In the remainder of this paper, we applied this analytical paradigm to reverse engineer the
generative models underlying zebrafish decision-making. We then examined whether active
inference instantiated in a canonical neural network could quantitatively predict the behaviour,
brain activity, and learning dynamics of individual animals.
Fig. 2. Validation of active inference using reverse engineering. a. Generative process for the
10
bioRxiv preprint doi: https://doi.org/10.1101/2025.08.06.668947; this version posted August 7, 2025. The copyright holder for this preprint
(which was not certified by peer review) is the author/funder. All rights reserved. No reuse allowed without permission.
considered go/no-go task. b. Canonical neural network of zebrafish. Left: Canonical neural network
architecture. The middle and output-layer neural activities are expressed as ğ‘¥(ğ‘¡) and ğ‘¦(ğ‘¡). Right:
The network dynamics can be read as performing Bayesian inference under a partially observable
Markov decision process (POMDP) [52â€“54]. c. Mathematical equivalence between Helmholtz
energy and variational free energy [15â€“18]. First, the neural activity equations for canonical neural
networks are defined (top left). By computing the integral of these equations, biologically plausible
Helmholtz energy ğ’œ can be reconstructed (middle left). The derivative of ğ’œ with respect to
synaptic strengths yields equations of Hebbian plasticity (bottom left). Then, variational free
energy â„± is defined based on the generative model (middle right). Updating posterior beliefs
about hidden states and parameters to minimise â„± results in Bayesian inference (top right) and
learning (bottom right). As shown in the middle, ğ’œ and â„± have the identical functional form, as
depicted by one-to-one correspondences between their components [16] (see also Table 1 and the
Methods section). d. Procedures for reverse engineering generative models using empirical neural
activity data. Provided with empirical data ğ‘‘(6) for trials k = 1, â€¦, 100, unknown network
parametersâ€”including matrices for categorising neuronal ensembles, effective synaptic weights,
firing thresholds, and subjective risksâ€”are estimated by minimising ğ’œ. e. Procedures for applying
the reverse engineering method to predict learning trajectories. Unlike (d), here, reverse
engineering was conducted using only the initial empirical data to construct synthetic agents
employing individual-specific generative models. These agents can derive plausible synaptic
plasticity rules and perform active inference to make the quantitative prediction of subsequent
learning, enabling forward inference or extrapolation of neural activity, synaptic weights, and
actions throughout training. Further details are provided in the Methods section.
11
bioRxiv preprint doi: https://doi.org/10.1101/2025.08.06.668947; this version posted August 7, 2025. The copyright holder for this preprint
(which was not certified by peer review) is the author/funder. All rights reserved. No reuse allowed without permission.
Plausibility and individual variability in zebrafish generative models
Here, reverse-engineered generative models were analysed to verify some qualitative
predictions of the free-energy principle [10,11]. Ensemble ğ‘¥ received dominant sensory input
3
from the blue and flow cues and was highly active during the go trials, consistent with encoding a
danger-related hidden state (Fig. 3a, left; data from n = 30 learners). In contrast, ensemble ğ‘¥ was
4
excited by the red input and was more active in the no-go trials, suggesting its role in encoding the
safety state (Fig. 3a, centre). Upon receiving the inputs from these ensembles, larger motor
outputs were produced in the go trials (Fig. 3a, right). These functional specialisations emerged
during task acquisition, as evinced by the progressive increase in correlations between ensemble
activities and hidden states (danger/safety) during training (Fig. 3b). Crucially, ensemble ğ‘¥
3
integrated multimodal sensory information, not only colour but also optic flow (Fig. 3c),
highlighting their role in inferring hidden states through evidence accumulation. These dynamics
are consistent with in vitro empirical support of the free-energy principle [27,35,36] and in vivo
evidence of Bayesian inference [37,38] that show that neural activity self-organises to encode
hidden states or latent causes of sensory inputs.
These changes result from activity-dependent synaptic plasticity. Effective synaptic connectivity
analysis revealed distinct network properties between learners and non-learners (Fig. 3dâ€“f). In
particular, the effective synaptic weight from the flow input to ğ‘¥ (ğ‘Š ) increased selectively in
3 38
learners during training (Fig. 3d), suggesting that flow information is critical for decision-making in
successful fish. The network architecture in learners was also characterised by minimal recurrent
inter-ensemble connections (ğ¾ , ğ¾ ), which promoted the functional segregation of the two
34 43
ensembles (Fig. 3e). By contrast, non-learners formed stronger inhibitory inter-ensemble
connections during training, which reflected a disrupted representation of the task structure.
12
bioRxiv preprint doi: https://doi.org/10.1101/2025.08.06.668947; this version posted August 7, 2025. The copyright holder for this preprint
(which was not certified by peer review) is the author/funder. All rights reserved. No reuse allowed without permission.
Learner networks further exhibited strengthened positive connections from ğ‘¥ to the output
3
(ğ‘‰ ), which facilitated action initiation in the go trials, whereas minimal connections from ğ‘¥
33 4
(ğ‘‰ ) suppressed actions in the no-go trials (Fig. 3f). This asymmetry created a positive feedback
34
loop linking blue-and-flow perception to action, enabling continuous movement during the go
trials.
The learner network architecture became increasingly closer to that of the optimal generative
model to minimise future risks in the given task setting, as predicted by the free-energy principle
(Fig. 3g). Learners also developed more differentiated and richer internal representations of
hidden environmental states, which were reflected in the higher effective dimensionality [39] of
the ensemble activity that was close to two dimensions (Fig. 3h). The learning inability in non-
learners can be attributed to reduced representational dimensionality (Fig. 3h) and considerable
inhibitory coupling (negative correlation) between neural ensembles (Fig. 3e), which might be
caused by strong initial inhibitory inputs from minor colour cues such as ğ‘Š and ğ‘Š (Fig. 3d).
34 43
These features are associated with strong prior beliefs, which are consistent with previous
theoretical [15] and in vitro findings [27,35]. These results suggest that learners placed importance
on sensory evidence, whereas non-learners placed more importance on their prior beliefs.
Moreover, we assessed individual differences in punishment-related learning by estimating the
subjective risk ğ›¤ for each fish (Fig. 3i). Learners exhibited higher perceived risk (mostly close to
one) in response to punishment, which enhanced the learning of output-layer weights (ğ‘‰) to avoid
adverse outcomes, enabling sharper behavioural discrimination. Conversely, non-learners
exhibited low subjective risk (approximately 0.5) and weak behavioural contrast between trial
types, implying insufficient internal modelling of the task structure. These differences highlight the
intrinsic difference in their behavioural optimisation criteria.
13
bioRxiv preprint doi: https://doi.org/10.1101/2025.08.06.668947; this version posted August 7, 2025. The copyright holder for this preprint
(which was not certified by peer review) is the author/funder. All rights reserved. No reuse allowed without permission.
These correlations between the network properties and task success can be used for the
diagnosis of learners and non-learners (Fig. 3j). The differences in mean actions within the go and
no-go trials, subjective risks, and synaptic weights were highly predictive of task success. A subset
of fish showed high representational entropy but poor task performance, suggesting a two-stage
failure mode, that is, inadequate internal modelling or impaired action selection. Both can be
attributed to differences in prior beliefs that deviate the generative model from the Bayes-optimal
form.
Furthermore, we confirmed the reduction of variational free energy â„± over training for
learners (Fig. 3k). Learners exhibited a larger reduction in â„± than non-learners, indicating better
alignment of their generative models with the task environment. These results directly support the
notion that learning in zebrafish conforms to the free-energy principle.
In essence, individual differences in zebrafish learning were attributed to variations in the
generative model structure implicit in canonical neural networks. The ability to infer and act upon
hidden states relies on how sensory evidence and prior beliefs are integrated, which determines
the self-organisation of internal representations over time. These findings provide a mechanistic
foundation for understanding cognitive variability and predictive processing in vertebrate brains
and a basis for developing long-term prediction models.
14
bioRxiv preprint doi: https://doi.org/10.1101/2025.08.06.668947; this version posted August 7, 2025. The copyright holder for this preprint
(which was not certified by peer review) is the author/funder. All rights reserved. No reuse allowed without permission.
Fig. 3. Reverse-engineered zebrafish generative models. a. Neuronal ensemble activities in the go
(blue) and no-go (red) trials during the late training period. In (aâ€“c), data obtained from n = 30
learners were used. b. Changes in correlations between ensemble activity ğ‘¥ ,ğ‘¥ and hidden
3 4
danger/safety states over trials. c. Changes in correlations between ğ‘¥ ,ğ‘¥ and optic flow input. dâ€“
3 4
f. Changes in the effective synaptic connectivities in the middle (W, K) and output (V) layers.
Comparisons between trajectories of learners (coloured, n = 30) and non-learners (black, n = 15)
are shown. Here, ğ‘Š , ğ‘Š , ğ‘Š , and ğ‘Š denote forward effective connections from blue, red,
13 14 18 19
flow visual cues and weak electric stimuli to ensemble ğ‘¥ , respectively; ğ¾ denotes a recurrent
1 1:
connection from ensemble ğ‘¥ to ğ‘¥ ; and ğ‘‰ denotes a connection to the output (ğ‘–,ğ‘— = 1,2). g.
1 : 31
Reduced difference between the empirical network architecture and the optimal generative
model. The mean squared errors between parameter posteriors in the empirical generative model
15
bioRxiv preprint doi: https://doi.org/10.1101/2025.08.06.668947; this version posted August 7, 2025. The copyright holder for this preprint
(which was not certified by peer review) is the author/funder. All rights reserved. No reuse allowed without permission.
and theoretical values of A, B, and C matrices are plotted (see the Methods section for definitions
of A, B, and C). h. Significant differences in the representational dimensionality of neuronal
ensemble activity between learners and non-learners. High representational dimensionality
indicates functional segregation of the two ensembles. i. Correlation between estimated subjective
risk (ğ›¤) and behavioural difference between go and no-go trials (i.e., ğ›¿ âˆ’ğ›¿ ) during the late
$/ #/$/
training period. The subjective risks for receiving punishment were estimated using Bayesian
model selection. j. Diagnosis of learners and non-learners using network properties. k. Variational
free energy computed from data decreasing with trials. Changes from the first training trial (trial
21) are shown. In (dâ€“k), data from n = 30 learners and n = 15 non-learners are compared. Lines and
shaded areas in (aâ€“h, k) represent mean values Â± SDs. NS, p â‰¥ 0.05; *, p < 0.05; **, p < 0.01; ***, p
< 0.001; ****, p < 0.0001. Grey areas in (bâ€“h, k) indicate the initial 20-trial adaptation period, in
which no punishment was delivered. Further details are provided in the Methods section.
Quantitative prediction of zebrafish learning using synthetic agents
Next, we examined the predictive validity of active inference by asking whether synthetic
agentsâ€”characterised by initial neural data from individual zebrafishâ€”could predict both learning-
related changes in neuronal dynamics and behavioural performance (Fig. 4a). Despite the inherent
difficulty of long-term prediction in biological systems, our analyses revealed that key differences
between learners and non-learners could be traced back to the initial network parameters (Fig.
3dâ€“f). In particular, individuals with strong red-inhibitory (ğ‘Š ) and weak flow-excitatory (ğ‘Š )
34 38
initial weights resulted in a failure to acquire task-relevant representations, identifying these
individuals as non-learners (Fig. 3d). These observations imply that learning trajectories can be
predicted from neural activity measured during the initial adaptation period.
16
bioRxiv preprint doi: https://doi.org/10.1101/2025.08.06.668947; this version posted August 7, 2025. The copyright holder for this preprint
(which was not certified by peer review) is the author/funder. All rights reserved. No reuse allowed without permission.
To enable data-driven reverse engineering that incorporates individual fish properties, we
developed a pretrained initialisation function designed to estimate the initial network parameters
(Fig. 2e; refer to the Methods section â€œPrediction of learning trajectoriesâ€ for details). Trained on
an activity dataset of the other fish, this function estimates the initial internal variables for each
fishâ€”including the initial synaptic weights and subjective risksâ€”based on the neural activity data
during the initial 20-trial adaptation period (Fig. 2e, left). Throughout all predictive analyses, we
employed a leave-one-out cross-validation approach [40] at the individual fish level: for each test
fish, hyper parameters of the initialisation function were optimised using the entire dataset from
all other fish. Then, the test fishâ€™s learning trajectory was predicted based only on initial 20-trial
data of the fish using the pretrained function and canonical neural network simulations (Fig. 2e,
right), ensuring that no information from future trials was used during predictions.
Consistent with the free-energy principle [10,11], the plasticity in the estimated synaptic
weights occurred in the direction of minimising the variational free energy â„± along its gradient,
as illustrated in the (ğ‘Š ,ğ‘Š ) trajectories (Fig. 4b, left). This provided direct evidence that
38 48
synaptic plasticity in zebrafish neural circuits conforms to the normative Bayesian belief updating
rules. Based on these observations, we constructed synthetic zebrafish agents whose canonical
neural networks performed active inference. They employed generative models estimated from
neural activity data during the initial 20-trial adaptation period. We then exposed these agents to
the same go/no-go task environment as biological fish for training. These synthetic agentsâ€”
identical to ideal Bayesian observers [15,16]â€”learned by pursuing a gradient descent on â„±,
forming posterior beliefs about latent danger/safety states and selecting actions accordingly. We
confirmed that the predicted synaptic weight trajectories matched those estimated from empirical
data (Fig. 4b, right), demonstrating that the free-energy gradient was a key aspect to characterise
17
bioRxiv preprint doi: https://doi.org/10.1101/2025.08.06.668947; this version posted August 7, 2025. The copyright holder for this preprint
(which was not certified by peer review) is the author/funder. All rights reserved. No reuse allowed without permission.
the plasticity direction.
We then quantitatively assessed the accuracy of these predictions. The predicted synaptic
connectivity changes in both the middle and output layers aligned well with the experimentally
estimated values (Fig. 4c). Across fish, the synaptic weights predicted after training deviated by
approximately 5%, 10%, and 20% from the empirical measurements for W, K, and V, respectively,
confirming the precision of the model in capturing learning trajectories (Fig. 4d). In particular, the
risk-modulated synaptic plasticity in the output layer (ğ‘‰) could recapitulate empirical observations
of task-dependent plasticity in zebrafish. Therefore, the synthetic active inference agents
successfully recapitulated zebrafish learning.
Moreover, the synthetic agents could predict neural activity patterns over training (Fig. 4eâ€“h).
Importantly, this constitutes a highly nontrivial prediction, as synaptic efficacy is dynamically
modulated by activity, and neuronal responses are themselves contingent upon synaptic weights.
Although activity predictions were more variable than synaptic weightsâ€”owing to intrinsic noise in
the neural dataâ€”the overall structure of the inferred representations was preserved (Fig. 4e). The
predicted activity patterns (Fig. 4f) were homologous to empirical activity (Fig. 3a), and these
activities were correlated at each trial (Fig. 4g; Pearson correlation coefficient r = 0.76), even
during the late training period. The error in predicting ensemble activities remained approximately
35% during the late training period (Fig. 4h), indicating that despite noise and variability, the model
successfully captured core features of the learning process.
Additionally, behavioural metrics such as moving distance and success rate were predicted
based solely on the initial neural activity. Based on the initial synaptic weights, we derived the
predicted values of subjective risk ğ›¤ before fish has received punishment (refer to the Methods
section for details) and confirmed the matching between empirical and predicted risks (Fig. 4i; r =
18
bioRxiv preprint doi: https://doi.org/10.1101/2025.08.06.668947; this version posted August 7, 2025. The copyright holder for this preprint
(which was not certified by peer review) is the author/funder. All rights reserved. No reuse allowed without permission.
0.66), enabling us to simulate individual-specific punishment-related learning. The predicted
behaviours (i.e., moving distances) in go and no-go trials were homologous to empirical ones (Fig.
4j) and correlated at each trial (Fig. 4k; r = 0.63). Interestingly, the errors in predicting positions
tended to decrease as fish learned the task as behaviours of learned fish were more consistent
with Bayes-optimal synthetic agents (Fig. 4l). Consequently, synthetic agents successfully predicted
task success rates of biological fish over the training period (Fig. 4m; r = 0.77 during the late
phase), and the prediction errors exhibited a decreasing trend during training (Fig. 4n). These
results demonstrated that individual learning outcomesâ€”including success rate and distance
travelledâ€”could be predicted from initial neural states using active inference.
We further benchmarked our reverse engineering framework with pretrained initialisation
against existing approaches (Fig. 4o). Conventional statistical methods driven by empirical data
lack mechanistic grounding, whereas theory-based Bayesian modelsâ€”while offering qualitative
insightsâ€”typically assume idealised parameters that limit individual-level predictions, both of
which exhibited poor long-term predictions of task success rates (Fig. 4o, the centre two). The
performance of reverse engineering without pretrained initialisation was also poor owing to the
failure of capturing individual initial states (Fig. 4o, right). By contrast, the present method with
pretrained initialisation explicitly incorporated biological variability by estimating individual-
specific generative models, enabling more accurate long-term forecasts (Fig. 4o, left).
Taken together, our findings demonstrate that reverse-engineered synthetic agents can
quantitatively predict individual zebrafish learning trajectories, highlighting the predictive validity
of active inference in a biologically realistic setting. These agents quantitatively predicted key
features of learning, including synaptic plasticity, neural activity pattern, and behavioural
outcomes, based solely on initial empirical data. These results support the biological plausibility of
19
bioRxiv preprint doi: https://doi.org/10.1101/2025.08.06.668947; this version posted August 7, 2025. The copyright holder for this preprint
(which was not certified by peer review) is the author/funder. All rights reserved. No reuse allowed without permission.
the free-energy principle as a normative theory of brain function, providing a mechanistically
explainable foundation for long-term predictions of brain self-organisation.
Fig. 4. Quantitative predictions of zebrafish self-organisation. a. Schematic for long-term
prediction. The synthetic agents reverse engineered based on empirical data in the initial 20-trial
20
bioRxiv preprint doi: https://doi.org/10.1101/2025.08.06.668947; this version posted August 7, 2025. The copyright holder for this preprint
(which was not certified by peer review) is the author/funder. All rights reserved. No reuse allowed without permission.
adaptation period are used to predict individual learning trajectories in biological fish during early
and late training phases up to trial 100. b. Comparison of empirical results and theoretical
predictions. Left: Effective synaptic weights (ğ‘Š ,ğ‘Š ) estimated from the data of a
38 48
representative learner. Black and blue lines are trajectories during trials 1â€“20 and 21â€“100,
respectively. Right: Predicted weights in the absence of data (red). c. Comparison of the estimated
and predicted effective synaptic weights at trial 100. d. Errors in predicting effective synaptic
weights. The errors are assessed based on the mean squared error between estimated and
predicted weights, divided by the squared amplitude of weights. (c, d) are obtained from n = 360,
180, and 90 connections for W, K, and V, respectively. e. Empirical and predicted activities of
ensemble ğ‘¥ . Concatenated activity trajectories during trials 61â€“80 after excluding parts of rest
3
period data are shown. f. Predicted ensemble activities obtained in the go (blue) and no-go (red)
trials during the late training phase. g. Correlations between empirical and predicted activities
during the late phase. h. Error in predicting ensemble activity. The ratio of squared prediction error
and squared amplitude is plotted. i. Predicted subjective risks estimated using the pretrained
initialisation function. j. Empirical and predicted moving distance in trials 61â€“80. k. Correlations
between empirical and predicted moving distances (positions). l. Error in predicting moving
distance. m. Trajectories of empirical and predicted success rates (left) and their correlations
during the late phase (right). n. Error in predicting task success in each trial, measured based on
the absolute error. o. Comparison of task-success-rate prediction errors between reverse
engineering with pretrained initialisation (RE with PTI) and three conventional methods: naive
statistical method using single-layer perceptrons, theory-based method using canonical neural
networks, and reverse engineering without pretrained initialisation (RE w/o PTI). In (c, d, i, mâ€“o),
data from n = 30 learners and n = 15 non-learners were used. In (fâ€“h, k, l), data from n = 30
learners were used. (b, e, j) are data from representative learners. Lines and shaded areas in (d, fâ€“
21
bioRxiv preprint doi: https://doi.org/10.1101/2025.08.06.668947; this version posted August 7, 2025. The copyright holder for this preprint
(which was not certified by peer review) is the author/funder. All rights reserved. No reuse allowed without permission.
h, kâ€“n) represent mean values Â± SDs. Grey areas in (d, h, lâ€“n) indicate the initial 20 trials. *, p <
0.05; **, p < 0.01; ***, p < 0.001. Further details are provided in the Methods section.
Generalising predictions to novel task environments
So far, we demonstrated that our synthetic agentsâ€”reverse engineered from zebrafish neural
activityâ€”can quantitatively predict long-term learning trajectories in task settings identical to
training settings. However, it remains unclear whether these agents can generalise their predictive
capacities to unfamiliar environments that differ from the original training context. To address this,
we evaluated model generalisation under two untrained conditions: an open-loop setting and a
reversal learning paradigm (Fig. 5). Synthetic agents that had been trained under standard task
contingencies were exposed to these conditions and compared with empirical data from zebrafish.
In the open-loop condition, the fish tail movements no longer induced forward movement
within the virtual environment (Fig. 5a). In this scenario, fish that had previously learned to escape
from the danger state continued to attempt escape via tail beating, without success. Consistent
with our previous work that reported elevated optic-flow prediction errors in mismatched
sensorimotor contingencies [33], ensemble ğ‘¥ displayed a persistent increased activity in the
4
open-loop go trials, compared to the activity in the closed-loop go trials during the late training
phase (Fig. 5b). These persistent activities associated with prediction errors were highest when the
fish encountered the open-loop condition for the first time, then gradually decreased over the
subsequent 15 trialsâ€”a pattern consistent with the free-energy principle (Fig. 5c). We also
confirmed that learners with large increases in ğ‘¥ during the open-loop conditions exhibited
4
more efficient behaviours during the closed-loop conditions (Fig. 5d), consistent with our previous
findings [33]. In addition to confirming these neural signatures, the synthetic agents could
22
bioRxiv preprint doi: https://doi.org/10.1101/2025.08.06.668947; this version posted August 7, 2025. The copyright holder for this preprint
(which was not certified by peer review) is the author/funder. All rights reserved. No reuse allowed without permission.
reproduce the deviated activities in the open-loop conditions (Fig. 5e) and forecast a gradual
decline in these activities over time (Fig. 5f) and circuit-behaviour relationships (Fig. 5g), even in
unfamiliar scenarios.
Next, we examined reversal learning, wherein the previously learned stimulusâ€“response
contingencies were inverted; that is, fish that had learned to swim when presented with a blue
background now had to learn to swim in response to red (Fig. 5h). Initially, the fish failed to adapt,
consistent with their prior beliefs. However, with repeated exposure, they gradually learned the
reversed contingency by changing neural activity (Fig. 5i), as evinced by a gradual re-increase of
task success rate (Fig. 5j). These reversed neural activity patterns in the reversal learning
corroborated that ensembles ğ‘¥ and ğ‘¥ encoded the danger and safety states. The synthetic
3 4
agents could reproduce these changes in neural activity (Fig. 5k). As expected, the behavioural
trajectories predicted by the model closely matched the empirical reversal learning dynamics of
biological fish (Fig. 5l). These results demonstrated that the reverse-engineered generative
modelâ€”trained in a specific task environmentâ€”retained the capacity to generalise its predictions
to novel conditions that were not used during training.
Therefore, our findings show that the inferred generative models are capable of recapitulating
zebrafish learning and behaviour even under unfamiliar task variations. The resulting synthetic
agents can effectively generalise predictions to new, untrained conditions, indicating that they
capture core learning mechanisms of zebrafish. This generalisation capacity supports the
robustness of the free-energy principle and active inference as an explanatory framework for
adaptive behaviour in biological systems.
23
bioRxiv preprint doi: https://doi.org/10.1101/2025.08.06.668947; this version posted August 7, 2025. The copyright holder for this preprint
(which was not certified by peer review) is the author/funder. All rights reserved. No reuse allowed without permission.
Fig. 5. Generalising predictions to different task conditions. a. Schematic of open-loop conditions,
in which neural outputs do not induce forward movement. b. Empirically observed activity during
the closed-loop (trials 61â€“100 in the late phase) and open-loop (additional trials 1â€“15) conditions.
The mean activities when observing blue (or red) cues in the go (or no-go) trials are plotted. In (bâ€“
d), data from n = 20 learners exposed to the open-loop condition are used. c. Changes in early
response of ğ‘¥ in the go trials when observing blue cues. d. Comparison of behavioural
4
differences between learners with large ğ‘¥ in the open-loop condition (n = 7, top 33%) and those
4
with small ğ‘¥ (n = 13). Behavioural differences are defined as the gap between mean actions in go
4
and no-go trials during the late phase. e. Predicted activities of synthetic agents. Agents derived
24
bioRxiv preprint doi: https://doi.org/10.1101/2025.08.06.668947; this version posted August 7, 2025. The copyright holder for this preprint
(which was not certified by peer review) is the author/funder. All rights reserved. No reuse allowed without permission.
from n = 30 learners are used for simulations. The networkâ€™s plasticity insensitivity was reduced by
half following initial task learning to facilitate plasticity. f. Predicted changes in early response of
ğ‘¥ . g. Comparison of predicted behavioural differences between learners with large and small ğ‘¥
4 4
during the open-loop condition. Results from 20 agents corresponding to the fish in (g) are shown.
h. Schematic of reversal learning paradigm, in which the contingency between the color cues and
punishment is inverted. i. Empirically observed activity during forward (trials 61â€“100 in the late
phase) and reversal (additional trials 1â€“60) learning phases. The mean activities in go and no-go
trials are plotted. In (i, j), data from n = 3 learners exposed to the reversal learning condition are
used. j. Changes in task success rate during forward and reversal learning conditions. k. Predicted
activities of synthetic agents. Agents derived from n = 30 learners are used for simulations. The
networkâ€™s plasticity insensitivity was reduced following initial task learning and the three-factor
learning rule mediated by risk ğ›¤ was applied to ğ‘Š during the reversal condition to facilitate
plasticity. l. Predicted changes in task success rate. Lines and shaded areas (or error bars) in (bâ€“g,
iâ€“l) represent mean values Â± SDs. Grey areas in (j, l) indicate the initial 20 trials. NS, p â‰¥ 0.05; *, p <
0.05; **, p < 0.01; ***, p < 0.001.
DISCUSSION
Predicting whether an individual will successfully learn a taskâ€”or more broadly, whether they
will develop into high-performing individualsâ€”is of central interest in the practical applications of
neuroscience. This challenge lies at the heart of our efforts to understand the neuronal
mechanisms of learning and behaviour, with implications for psychiatry, education, and
neuromorphic engineering. While such predictions are often intractable in complex systems, this
work demonstrates that under well-defined conditions, it is possible to predict whether a zebrafish
25
bioRxiv preprint doi: https://doi.org/10.1101/2025.08.06.668947; this version posted August 7, 2025. The copyright holder for this preprint
(which was not certified by peer review) is the author/funder. All rights reserved. No reuse allowed without permission.
will become an effective learner or remain a non-learner solely based on its initial neuronal states.
The key innovation for this achievement is the incorporation of a normative theory of brain
functionâ€”the free-energy principle [10,11]â€”into data-driven predictions. By applying the free-
energy principle to in vivo neural recordings, we confirmed the predictive validity of this
theoretical framework in behaving animals. We specifically demonstrated that active inferenceâ€”
when grounded in empirical dataâ€”can generate long-term predictions of individual learning
trajectories. While previous works have largely focused on short-term predictions of brain activity,
such as subsecond-scale electrophysiological signals [6â€“9], our approach enables forecasting of
learning outcomes and neural self-organisation over training periods. This is also complementary
to previous work that have predicted behavioural outcomes using machine learning approaches
[41].
A central contribution of this work is the reverse engineering of generative models from
empirical neural activity. In contrast to conventional statistical and machine learning approaches
that primarily estimate static network architectures [42,43], our method reconstructs the
underlying generative models that shape both neural dynamics and plasticity. Moreover, this
framework enables data-driven identification of individual generative models, instead of explicitly
assuming specific Bayesian models a priori, thereby allowing quantitative predictions of long-term
self-organisation in individual animals. This enables the synthesis of artificial agents that explicitly
recapitulate brain-like learning. By doing so, we provide a formal demonstration of the predictive
power of active inference, extending beyond descriptive accounts to predict changes in the
internal hypotheses underlying individual behaviour. Having said this, the present work is limited
to neural data recorded from the telencephalon. Future studies incorporating activity from other
brain regions, such as the basal ganglia, may yield more biologically realistic circuit models and
26
bioRxiv preprint doi: https://doi.org/10.1101/2025.08.06.668947; this version posted August 7, 2025. The copyright holder for this preprint
(which was not certified by peer review) is the author/funder. All rights reserved. No reuse allowed without permission.
improve predictive accuracy.
The reverse engineering framework can be generalised beyond zebrafish and is broadly
applicable to diverse animal models, brain regions, tasks, and measurement modalities. The
resulting agent can generate theoretical predictions, whose consistency with data serves as a test
of the underlying principle. Canonical neural networks can also in principle be extended to
hierarchical active inference [44,45], implying potential applications of our method to more
complicated tasks. In future work, we plan to apply this framework to mammalian systems and
integrate multimodal datasets to investigate whether shared generative structures exist across
species, thereby potentially revealing the conserved principles of neural computation.
Moreover, this approach enables a data-driven phenotyping of individual animals based on
deviations from Bayes-optimal generative models [46]. Agents dominated by rigid, suboptimal
prior beliefs failed to learn the task. As we demonstrated, such individual differences in learning
outcomes could be traced back to the initial circuit structure. This enables us to capture the
intrinsic mechanistic distinctions between learners and non-learners and the likelihood of task
acquisition only from the initial network properties. This may have profound implications for our
understanding of how initial conditions and subjective risks mediate the plasticity of neural
circuits. Combining mathematical analysis and empirical observation indicates that prior beliefs
encoded at the circuit level such as initial synaptic weights are crucial for learning. The notion that
differences in prior beliefs can predict subsequent inference and learning may provide insight into
the mechanisms underlying inference attenuations and learning disabilities caused by psychiatric
disorders [5,47].
In summary, we demonstrated that reverse engineering generative models from neural activity
data enables long-term prediction of learning and neuronal self-organisation in zebrafish. These
27
bioRxiv preprint doi: https://doi.org/10.1101/2025.08.06.668947; this version posted August 7, 2025. The copyright holder for this preprint
(which was not certified by peer review) is the author/funder. All rights reserved. No reuse allowed without permission.
observations provide empirical support for the free-energy principle and active inference as
predictive theories of brain function. More broadly, these outcomes highlight the potential of
reverse engineering to forecast flexible, individual-specific responses, even in untrained scenarios,
which is a key requirement for translational applications in neuroscience and neurotechnology. Our
approach offers a powerful tool for uncovering the computational principles of brain function, with
potential implications for predicting progression of neurodegenerative and psychiatric disorders
and efficiency of education, and for the design of neuromorphic artificial interference that can
learn and adapt as the biological brain does.
METHODS
Data curation
In this work, previously published data of zebrafish engaging in a go/no-go decision-making task
[33] were analysed using the reverse engineering method described in the subsequent sections.
The zebrafish were head-fixed under a two-photon microscope for calcium imaging and
surrounded by monitors on their front, left, right, and bottom sides, creating a virtual reality
environment. Tail movement was tracked using a camera, which allowed the fish to move forward
in the virtual space in response to the detected motion. To indicate forward movement, black
stripes were displayed on the coloured background, which moved backwards as the fish advanced.
A trial continued 10 s, followed by a 15-s rest period. Further details on the preparation of animals,
virtual reality settings, two-photon calcium imaging, data acquisition, and preprocessing of data
are provided in the previous paper [33].
28
bioRxiv preprint doi: https://doi.org/10.1101/2025.08.06.668947; this version posted August 7, 2025. The copyright holder for this preprint
(which was not certified by peer review) is the author/funder. All rights reserved. No reuse allowed without permission.
Data preprocessing
For analysis of neural activity data measured using two-photon calcium imaging, regions of
interest (ROI) were detected as described previously [33]. The dF/F signals after removing low-
frequency components using a digital high-pass filter were used for subsequent analyses. Neural
+
activity with this preprocessing is denoted as ğ‘Ÿ(ğ‘¡) = &ğ‘Ÿ (ğ‘¡),â€¦,ğ‘Ÿ (ğ‘¡)( , where ğ‘ denotes the
3 ;! &
number of neurons.
For behavioural analysis, the distance between the start and goal positions was defined as one
unit, and the position of the fish was limited in the range of 0 and 2.
Covariance analysis
Covariance analysis was conducted to investigate the amount of external information encoded
by the measured neural activity. To this end, a deconvolutional filter [48] was applied to the ROI
data to remove background noise and obtain the estimated spike time-series.
In this setting, the environmental system was characterised by nine state variables: go&blue,
go&red, no-go&red, no-go&blue, interval (white), optic flow, electrical stimuli, actions, and
position. We assumed that neural activity could be expressed as a weighted sum of these nine
state variables and one constant. Some of these variables were not inherently encoded in the
circuit initially, but were encoded subsequently through learning, and therefore, their amplitudes
changed during the task. Hence, by using a discrete cosine transform (DCT), we considered basis
functions that represent changes during a task. Here, a low-dimensional DCT with up to a fifth-
order basis was considered, yielding a total of 60 dimensional bases.
Further, we employed a general linear model and optimised the transformation matrix by
29
bioRxiv preprint doi: https://doi.org/10.1101/2025.08.06.668947; this version posted August 7, 2025. The copyright holder for this preprint
(which was not certified by peer review) is the author/funder. All rights reserved. No reuse allowed without permission.
minimising the mean squared prediction error with least absolute shrinkage and selection operator
(LASSO) regression. Then, the amplitudes of the neural activity variances explained by external
information were computed. The residuals were treated as noise.
Statistical tests
The two-sided Wilcoxon signed-rank test was used for the paired comparisons. The two-sided
Mannâ€“Whitney U test was used for unpaired comparisons.
Canonical neural networks
We modelled zebrafish neuronal networks (i.e., synthetic agents) using canonical neural
networks of rate-coding models comprising two middle-layer and one output-layer neurons [15â€“
+
18] (Fig. 2b, left). The middle layer neurons ğ‘¥(ğ‘¡) = ,ğ‘¥ (ğ‘¡),ğ‘¥ (ğ‘¡)- involve a recurrent circuit, and
3 4
the output layer neuron ğ‘¦(ğ‘¡) forms a feedforward network that receives inputs from the middle
layer to generate a feedback response to the external milieu. Elements of ğ‘¥(ğ‘¡) and ğ‘¦(ğ‘¡) take
values within the range of 0 and 1.
Synthetic fish agents received four-dimensional sensory inputs: blue, red, and flow visual inputs,
+
and electric stimuli, expressed as ğ‘œ(ğ‘¡) = &ğ‘œ (ğ‘¡),ğ‘œ (ğ‘¡),ğ‘œ (ğ‘¡),ğ‘œ (ğ‘¡)( . Upon receiving
,-.% &%! (-/0 â€™)12
ğ‘œ(ğ‘¡), the neural activity is expressed as follows [16]:
ğ‘¥Ì‡(ğ‘¡) âˆ âˆ’sig<3,ğ‘¥(ğ‘¡)-+ğ‘Šğ‘œ(ğ‘¡)+ğ¾ğ‘¥(ğ‘¡âˆ’Î”ğ‘¡)+â„=
@ (1)
ğ‘¦Ì‡(ğ‘¡) âˆ âˆ’sig<3,ğ‘¦(ğ‘¡)-+ğ‘‰ğ‘¥(ğ‘¡âˆ’Î”ğ‘¡)+â„*
where sig<3(âˆ™) denotes the leak current in the form of the inverse sigmoid (a.k.a., logit) function;
ğ‘Š â‰” ğ‘Š âˆ’ğ‘Š âˆˆ â„4Ã—9, ğ¾ â‰” ğ¾ âˆ’ğ¾ âˆˆ â„4Ã—4, and ğ‘‰ â‰” ğ‘‰ âˆ’ğ‘‰ âˆˆ â„3Ã—4 are synaptic weight
3 > 3 > 3 >
30
bioRxiv preprint doi: https://doi.org/10.1101/2025.08.06.668947; this version posted August 7, 2025. The copyright holder for this preprint
(which was not certified by peer review) is the author/funder. All rights reserved. No reuse allowed without permission.
matrices for feedforward and recurrent connections in the middle layer and feedforward
connections in the output layer, respectively; â„= = â„= âˆ’â„= âˆˆ â„4 and â„* = â„ * âˆ’â„ * âˆˆ â„ are
3 > 3 >
adaptive firing thresholds in the middle and output layers, respectively; and Î”ğ‘¡ > 0 is a delay in
signal propagation. This model is biologically plausible, as it can be derived from the Hodgkinâ€“
Huxley equations [49] and FitzHughâ€“Nagumo model [50,51] through some approximations [16].
The ğ‘Š ,ğ¾ ,ğ‘‰ and ğ‘Š ,ğ¾ ,ğ‘‰ matrices can be associated with excitatory and inhibitory
3 3 3 > > >
synapses, respectively. The adaptive firing thresholds satisfy â„= = lnsig(âˆ’ğ‘Š)Q1âƒ—+
- -
lnsig(âˆ’ğ¾)1Qâƒ—+ğœ™= and â„ * = lnsig(âˆ’ğ‘‰)1Qâƒ—+ğœ™ * for ğ‘™ = 1,0. For simplicity, sets of synaptic
- - - - -
weights and firing thresholds are defined as ğœ” = {ğ‘Š ,ğ‘Š ,ğ¾ ,ğ¾ ,ğ‘‰ ,ğ‘‰ } and ğœ™ =
3 > 3 > 3 >
Xğœ™=,ğœ™=,ğœ™ * ,ğœ™ * Y, respectively. Throughout the manuscript, ğœ™ is fixed over the training period,
3 > 3 >
whereas ğœ” exhibits synaptic plasticity for each trial.
Without loss of generality, equation (1) can be derived as a gradient descent on a Helmholtz
energy (Fig. 2c, top left). Following the treatment in the previous work [15,16], the Helmholtz
energy for canonical neural networks can be reverse engineered by computing the integral of the
right-hand side of equation (1) as follows:
) ğ‘¥(ğœ) + ğ‘¥(ğœ) ğ‘Š ğ¾ â„=
ğ’œ = Z [ ] ^ln[ ]âˆ’[ 3]ğ‘œ(ğœ)âˆ’[ 3]ğ‘¥(ğœâˆ’Î”ğ‘¡)âˆ’[ 3]_ğ‘‘ğ‘¡
ğ‘¥(ğœ) ğ‘¥(ğœ) ğ‘Š ğ¾ â„=
> > > >
) ğ‘¦(ğœ) + ğ‘¦(ğœ) ğ‘‰ â„ *
+Z [ ] @ln[ ]âˆ’,1âˆ’2ğ›¤(ğ‘¡,ğœ)-[ 3]ğ‘¥(ğœâˆ’Î”ğ‘¡)âˆ’â€˜ 3abğ‘‘ğ‘¡+ğ’ (2)
ğ‘¦(ğœ) ğ‘¦(ğœ) ğ‘‰ â„ *
> > >
where ğ‘¥(ğœ) = Q1âƒ—âˆ’ğ‘¥(ğœ) denotes the sign-flipped ğ‘¥(ğœ) centred on 1/2, 1Qâƒ— = (1,â€¦,1)+ is a
vector of ones, and the integration constant ğ’ is in the order less than ğ‘¡. Risk-encoding
neuromodulator ğ›¤(ğ‘¡,ğœ) that takes the value in the range of 0â€“1 was added to incorporate the
effect of aversive neuromodulations on synaptic plasticity [23â€“25]. In this work, the risk was
determined by the ON or OFF status of punishment (i.e., weak electric stimuli): ğ›¤(ğ‘¡,ğœ) = 0 for
31
bioRxiv preprint doi: https://doi.org/10.1101/2025.08.06.668947; this version posted August 7, 2025. The copyright holder for this preprint
(which was not certified by peer review) is the author/funder. All rights reserved. No reuse allowed without permission.
successful trials in which fish avoids punishment or ğœ is sufficiently close to ğ‘¡; otherwise,
ğ›¤(ğ‘¡,ğœ) = ğ›¤ > 0. The value of ğ›¤ varies with individuals. For simplicity, we denote ğ›¤ simply as
3 3 3
ğ›¤ in the remainder of the manuscript, except where explicitly stated otherwise. Based on
! @ğ’œ
equation (2), equation (1) can be expressed as the gradient descent on ğ’œ, i.e., ğ‘¥Ì‡ âˆ âˆ’ and
!) @=
! @ğ’œ
ğ‘¦Ì‡ âˆ âˆ’ .
!) @*
Then, the synaptic plasticity rules can be derived as a gradient descent on ğ’œ (Fig. 2c, bottom
left). By computing the derivatives of ğ’œ with respect to synaptic connections, we obtain the
following equations for conjugate synaptic plasticity:
1 ğœ•ğ’œ
â§ ğ‘ŠÌ‡ âˆ âˆ’ = âŸ¨ğ‘¥(ğ‘¡)ğ‘œ(ğ‘¡)+âŸ©âˆ’kğ‘¥(ğ‘¡)Q1âƒ—+lâŠ™sig(ğ‘Š )
3 ğ‘¡ ğœ•ğ‘Š 3
âª 3
1 ğœ•ğ’œ
âª
ğ‘ŠÌ‡ âˆ âˆ’ = âŸ¨ğ‘¥(ğ‘¡)ğ‘œ(ğ‘¡)+âŸ©âˆ’kğ‘¥(ğ‘¡)1Qâƒ—+lâŠ™sig(ğ‘Š )
âª > ğ‘¡ ğœ•ğ‘Š >
>
âª
1ğœ•ğ’œ
âª ğ¾Ì‡ âˆ âˆ’ = âŸ¨ğ‘¥(ğ‘¡)ğ‘¥(ğ‘¡âˆ’Î”ğ‘¡)+âŸ©âˆ’kğ‘¥(ğ‘¡)1Qâƒ—+lâŠ™sig(ğ¾ )
3 ğ‘¡ ğœ•ğ¾ 3
3 (3)
1ğœ•ğ’œ
â¨
ğ¾Ì‡ âˆ âˆ’ = âŸ¨ğ‘¥(ğ‘¡)ğ‘¥(ğ‘¡âˆ’Î”ğ‘¡)+âŸ©âˆ’kğ‘¥(ğ‘¡)Q1âƒ—+lâŠ™sig(ğ¾ )
âª > ğ‘¡ ğœ•ğ¾ >
>
âª 1ğœ•ğ’œ
âªğ‘‰Ì‡ âˆ âˆ’ = ,1âˆ’2ğ›¤(ğ‘¡)-âŸ¨ğ‘¦(ğ‘¡)ğ‘¥(ğ‘¡âˆ’Î”ğ‘¡)+âŸ©âˆ’kğ‘¦(ğ‘¡)Q1âƒ—+lâŠ™sig(ğ‘‰ )
3 ğ‘¡ ğœ•ğ‘‰ 3
âª 3
1ğœ•ğ’œ
âª
ğ‘‰Ì‡ âˆ âˆ’ = ,1âˆ’2ğ›¤(ğ‘¡)-âŸ¨ğ‘¦(ğ‘¡)ğ‘¥(ğ‘¡âˆ’Î”ğ‘¡)+âŸ©âˆ’kğ‘¦(ğ‘¡)1Qâƒ—+lâŠ™sig(ğ‘‰ )
â© > ğ‘¡ ğœ•ğ‘‰ >
>
3
where âŠ™ denotes the elementwise (i.e., Hadamard) product operator, âŸ¨âˆ™âŸ© = âˆ«âˆ™ğ‘‘ğ‘¡ indicates the
)
average over time, and ğ›¤(ğ‘¡) = âŸ¨ğ›¤(ğ‘¡,ğœ)âŸ© denotes the risk for each trial (ğ›¤(ğ‘¡) = 0 for successful
trials and ğ›¤(ğ‘¡) = ğ›¤ for failed trials). In detail, by incorporating the initial synaptic weights ğ‘Š (>)
3
implicit in the integral constant ğ’, the expectations in equation (3) are computed as
âŸ¨ğ‘¥(ğ‘¡)ğ‘œ(ğ‘¡)+âŸ© = 3 &âˆ« ) ğ‘¥(ğœ)ğ‘œ(ğœ)+ğ‘‘ğœ+sig&ğ‘Š (>) (âŠ™ğœ† (>) ( and kğ‘¥(ğ‘¡)Q1âƒ—+l = 3 &âˆ« ) ğ‘¥(ğœ)Q1âƒ—+ğ‘‘ğœ+ğœ† (>) (,
) > 3 B" ) > B"
where ğœ† = âˆ« ) ğ‘¥(ğœ)Q1âƒ—+ğ‘‘ğœ+ğœ† (>) denotes the insensitivity to plasticity (inverse learning rate) and
B" > B"
(>)
ğœ† indicates its initial value [15]. The forms of equation (3) are biologically plausible as they
B"
comprise Hebbian and homeostatic plasticity, which indicates the biological plausibility of ğ’œ as
32
bioRxiv preprint doi: https://doi.org/10.1101/2025.08.06.668947; this version posted August 7, 2025. The copyright holder for this preprint
(which was not certified by peer review) is the author/funder. All rights reserved. No reuse allowed without permission.
the energy function that governs canonical neural networks. Synaptic plasticity in ğ‘‰ and ğ‘‰ is
3 >
altered by a modulatory factor that encodes the risk ğ›¤(ğ‘¡), which enables canonical neural
networks to optimise actions ğ›¿(ğ‘¡) for avoiding punishment [16]. Further details are provided in
previous works [15,16].
Variational Bayesian inference
Variational Bayesian inference [12] is a process that updates prior beliefs ğ‘ƒ(ğœ—) about external
milieu states ğœ— to the corresponding approximate posteriors ğ‘„(ğœ—), based on a sequence of
observations ğ‘œ = {ğ‘œ ,â€¦,ğ‘œ } (Fig. 2b, right). This inference rests upon a generative model
3:) 3 )
expressed as ğ‘ƒ(ğ‘œ ,ğœ—) = ğ‘ƒ(ğ‘œ |ğœ—)ğ‘ƒ(ğœ—). Here, a partially observable Markov decision process
3:) 3:)
(POMDP) is employed as a generative model to express a discrete spaceâ€“time environment [52â€“
54].
Observations ğ‘œ are generated from hidden states ğ‘  through likelihood matrix ğ´ in terms of
D D
a categorical distribution ğ‘ƒ(ğ‘œ |ğ‘  ,ğ´) = Cat(ğ´ğ‘  ) (Fig. 2a). The dynamics of hidden states ğ‘  are
D D D D
determined by transition matrix ğµ as ğ‘ƒ(ğ‘  |ğ‘  ,ğµ) = Cat(ğµğ‘  ). On receiving observations,
D D<3 D<3
the agent infers external states and generates actions ğ›¿ following policy matrix ğ¶ as
D
ğ‘ƒ(ğ›¿ |ğ‘  ,ğ¶) = Cat(ğ¶ğ‘  ). The evaluation of past decisions are conducted based on
D D<3 D<3
ğ‘ƒ(ğ›¿ |ğ‘  ,ğ¶,ğ›¾ ) = Cat(ğ¶ğ‘  )E#Cat,(ğ¶F âŠ˜ğ¶)ğ‘  -
E#
using binarized risk ğ›¾ âˆˆ {0,1}; that is,
D D<3 ) D<3 D<3 )
ğ‘ƒ(ğ›¿ |ğ‘  ,ğ¶,ğ›¾ ) = Cat(ğ¶ğ‘  ) for ğ›¾ = 0 and ğ‘ƒ(ğ›¿ |ğ‘  ,ğ¶,ğ›¾ ) = Cat,(ğ¶F âŠ˜ğ¶)ğ‘  - for ğ›¾ =
D D<3 ) D<3 ) D D<3 ) D<3 )
1, where âŠ˜ denotes the element-wise division and ğ¶F is a normalisation factor [16]. The
+
binarized risk ğ›¾ is sampled from a categorical distribution ğ‘ƒ(ğ›¾ ) = Cat&,ğ›¤,ğ›¤- (; thus, ğ›¤ is
) ) ) ) )
viewed as the risk intensity. Here, ğ‘  and ğ›¿ take binary (0,1) values, and parameters ğ´, ğµ, and
D D
ğ¶ take continuous values between 0 and 1. Thus, the generative model is expressed as
33
bioRxiv preprint doi: https://doi.org/10.1101/2025.08.06.668947; this version posted August 7, 2025. The copyright holder for this preprint
(which was not certified by peer review) is the author/funder. All rights reserved. No reuse allowed without permission.
)
ğ‘ƒ(ğ‘œ ,ğœ—) = ğ‘ƒ(ğ´)ğ‘ƒ(ğµ)ğ‘ƒ(ğ¶)ğ‘ƒ(ğ›¾ )}ğ‘ƒ(ğ‘œ |ğ‘  ,ğ´)ğ‘ƒ(ğ‘  |ğ‘  ,ğµ)ğ‘ƒ(ğ›¿ |ğ‘  ,ğ¶,ğ›¾ ) (4)
3:) ) D D D D<3 D D<3 )
DG3
where ğœ— = {ğ‘  ,ğ›¿ ,ğ´,ğµ,ğ¶} denotes a set of latent (external) variables.
3:) 3:)
Variational Bayesian inference minimises variational free energy â„±[ğ‘„(ğœ—),ğ‘œ ] =
3:)
E [âˆ’lnğ‘ƒ(ğ‘œ ,ğœ—)+lnğ‘„(ğœ—)] defined as a functional of approximate posterior belief ğ‘„(ğœ—) as
H(I) 3:)
a tractable proxy for minimising surprise âˆ’lnğ‘ƒ(ğ‘œ ) of sensory inputs, where ğ‘ƒ(ğ‘œ ) =
3:) 3:)
âˆ«ğ‘ƒ(ğ‘œ |ğœ—)ğ‘ƒ(ğœ—)ğ‘‘ğœ— denotes the model evidence [13,14]. In POMDP, the approximate posterior
3:)
belief is given as
)
ğ‘„(ğ‘  ,ğ›¿ ,ğœƒ) = ğ‘„(ğ´)ğ‘„(ğµ)ğ‘„(ğ¶)}ğ‘„(ğ‘  )ğ‘„(ğ›¿ ) (5)
3:) 3:) D D
DG3
where ğ‘„(ğ‘  ) = Cat(ğ¬ ) and ğ‘„(ğ›¿ ) = Cat(ğ›… ) are categorical distributions and ğ‘„(ğ´) = Dir(ğš),
D D D D
ğ‘„(ğµ) = Dir(ğ›), and ğ‘„(ğ¶) = Dir(ğœ) are Dirichlet distributions parameterised by concentration
parameters (Dirichlet counts) ğš, ğ›, and ğœ. Based on them, ğ‘„(ğœ—) is characterised by the
posterior expectation or its counterpart ğ› = {ğ¬ ,ğ›… ,ğš,ğ›,ğœ}. Hence, the variational free energy
3:) 3:)
â„± can be analytically expressed as a function of ğ› as follows:
) )
â„± = (cid:140)ğ¬ â‹…{lnğ¬ âˆ’lnğ€â‹…ğ‘œ âˆ’lnğğ¬ }+(cid:140)ğ›… â‹…Xlnğ›… âˆ’,1âˆ’2ğ›¤ -lnğ‚ğ¬ Y
D D D D<3 D D ),D D<3
DG3 DG3
+(ğšâˆ’ğ‘)â‹…lnğ€âˆ’lnâ„¬(ğš)+(ğ›âˆ’ğ‘)â‹…lnğâˆ’lnâ„¬(ğ›)+(ğœâˆ’ğ‘)â‹…lnğ‚âˆ’lnâ„¬(ğœ)+ğ»[ğ‘ƒ(ğ›¾)] (6)
where ğ‘ƒ(ğ´) = Dir(ğ‘), ğ‘ƒ(ğµ) = Dir(ğ‘), and ğ‘ƒ(ğ¶) = Dir(ğ‘) are prior Dirichlet distributions,
ğ’Ÿ [ğ‘„(ğ´)||ğ‘ƒ(ğ´)] = lnğ€â‹…(ğšâˆ’ğ‘)âˆ’â„¬(ğš) up to a constant, â„¬(ğš) denotes the beta function,
KL
and ğ»[ğ‘ƒ(ğ›¾)] is the entropy of the risk [16]. Here, ğ›¤ = 0 for successful trials or ğœ = ğ‘¡;
),D
otherwise, ğ›¤ = ğ›¤.
D,)
Minimising â„± yields an approximate posterior belief ğ‘„(ğœ—) that approximates the solution of
34
bioRxiv preprint doi: https://doi.org/10.1101/2025.08.06.668947; this version posted August 7, 2025. The copyright holder for this preprint
(which was not certified by peer review) is the author/funder. All rights reserved. No reuse allowed without permission.
Bayesâ€™ theorem (Fig. 2c, right). Implicit variational update rules are presented as a derivative of â„±
with respect to ğ›, and their fixed points provide the posterior expectations. By solving the fixed
points ğœ•â„±/ğœ•ğ¬ = 0 and ğœ•â„±/ğœ•ğ›… = 0, the posterior expectations about hidden states and actions
) )
are obtained as follows (Fig. 2c, top right):
ğ¬ = ğœ(lnğ€â‹…ğ‘œ +lnğğ¬ )
^ ) ) )<3 (7)
ğ›… = ğœ(lnğ‚ğ¬ )
) )<3
Minimisation of â„± with respect to parameters, by solving ğœ•â„±/ğœ•ğš = ğ‘‚, ğœ•â„±/ğœ•ğ› = ğ‘‚, and
ğœ•â„±/ğœ•ğœ = ğ‘‚, entails the following update rules (Fig. 2c, bottom right):
)
â§
ğš âŸµ ğš+(cid:140)ğ‘œ âŠ—ğ¬
âª D D
âª DG3
âª )
ğ› âŸµ ğ›+(cid:140)ğ¬ âŠ—ğ¬ (8)
D D<3
â¨
DG3
âª
)
âª
âªğœ âŸµ ğœ+(1âˆ’2ğ›¤)(cid:140)ğ›… âŠ—ğ¬
) D D<3
â©
DG3
where âŠ— denotes the Kronecker product operator. Parameter posteriors are computed as
lnğ€ = Ïˆ(ğš )âˆ’Ïˆ(ğš +ğš ) â‰ˆ ln,ğš âŠ˜(ğš +ğš )- using the digamma function Ïˆ(âˆ™). An
âˆ™- âˆ™- 3- >- âˆ™- 3- >-
analogous calculation is used for the other parameter posteriors, ğ and ğ‚.
Previous work established a mathematical equivalence between the class of factorial POMDP
considered here and canonical neural networks (equations (1) and (3)) by showing a one-to-one
correspondence between the components of the networkâ€™s Helmholtz energy (equation (2)) and
the variational free energy (equation (6)) [15,16]; that is, ğ’œ â‰¡ â„±, where internal states ğœ‘
encodes posterior beliefs ğ› (Fig. 2c). For instance, neural activity ğ‘¥(ğ‘¡) corresponds to the state
ğ‘¥(ğ‘¡)
priors ğ¬ â‰¡ [ ] and synaptic weights ğ‘Š and plasticity insensitivities ğœ† are linked with
) ğ‘¥Ì…(ğ‘¡) 3 B"
the parameter posteriors as ğ€ â‰¡ sig(ğ‘Š ) and ğš â‰¡ ğœ† âŠ™sig(ğ‘Š ) (refer to previous work
3 3 3 B" 3
[15,16] for details). Table 1 summarises these correspondences. Because all components of
35
bioRxiv preprint doi: https://doi.org/10.1101/2025.08.06.668947; this version posted August 7, 2025. The copyright holder for this preprint
(which was not certified by peer review) is the author/funder. All rights reserved. No reuse allowed without permission.
canonical neural networks can be mapped into those in variational Bayesian inference under
POMDPs, one can reverse engineer the generative models (i.e., internal hypotheses about external
milieu) under which fish operate. Through lens of this equivalence, their neural activity and
synaptic plasticity are read as performing active inference by minimising variational free energy
[15â€“18].
In particular, delayed modification of synaptic plasticity [19â€“22] in the form of a three-factor
learning rule [23â€“25] forms optimal behaviour that minimises future risks through the post-hoc
evaluation of past decisions. The three-factor learning mediates switching of Hebbian and anti-
Hebbian plasticity, which facilitates active inference to acquire risk-minimising behaviour [16].
Reverse engineering of generative models
This section elaborates an extension of reverse engineering method [26,27] for identifying the
generative models of behaving animals (Fig. 2d). Crucially, the present scheme estimates the
values of the unknown variablesâ€”including neural ensemble activity ğ‘¥(ğ‘¡), effective synaptic
weights ğ‘Š,ğ¾,ğ‘‰, firing threshold factors ğœ™=,ğœ™*, and subjective risk ğ›¤â€”by minimising the shared
Helmholtz energy ğ’œ defined in equation (2). Because ğ’œ can be read as the variational free
energy, such estimates are identical to posterior expectations of the variational Bayesian inference
[26,27], enabling the extraction of a low-dimensional sub-space of ensemble activity ğ‘¥(ğ‘¡) that
maximises the predictability.
Here, the dF/F signals ğ‘Ÿ(ğ‘¡), sensory inputs ğ‘œ(ğ‘¡), and actions ğ›¿(ğ‘¡) are the empirically
observable variables. A set of these data are denoted as
ğ‘‘(6) = Â£ğ‘Ÿ (6) ,ğ‘œ (6) ,ğ›¿ (6) â„ (9)
3:) 3:) 3:)
36
bioRxiv preprint doi: https://doi.org/10.1101/2025.08.06.668947; this version posted August 7, 2025. The copyright holder for this preprint
(which was not certified by peer review) is the author/funder. All rights reserved. No reuse allowed without permission.
for trial k, where ğ‘Ÿ = {ğ‘Ÿ(1),ğ‘Ÿ(2),â€¦,ğ‘Ÿ(ğ‘¡)} expresses a sequence of neural activities (i.e., df/f
3:)
signals) recorded with a time resolution of 0.1 s. The output layer activity ğ‘¦(ğ‘¡) is supposed to
generate the tail movement of fish ğ›¿(ğ‘¡) through a categorical distribution ğ‘ƒ,ğ›¿(ğ‘¡)- =
+
Cat&,ğ‘¦(ğ‘¡),ğ‘¦(ğ‘¡)- (. As ğ‘¦(ğ‘¡) represents the magnitude of the tail movement, ğ‘¦(ğ‘¡) = ğ›¿(ğ‘¡) is
substituted in the following analysis.
Empirical neural activity data are assigned to canonical neural network models, and the
corresponding generative models are identified through the established equivalence. This process
is begun by classifying large-scale neural activity data into two-dimensional neuronal ensembles.
The neuronal ensemble activity ğ‘¥(ğ‘¡) is characterised by the mapping from individual neural
ğ‘Ÿ(ğ‘¡)
activity to ensemble activity, expressed as ğ‘¥(ğ‘¡) = sigâ€˜ğ‘€ & (a with the values in the range
3 1
between 0 and 1. A reconstruction mapping from ğ‘¥(ğ‘¡) to individual neural activity is also defined
ğ‘¥(ğ‘¡)
as ğ‘ŸÌ‚(ğ‘¡) = ğ‘€ & (, where ğ‘€ = {ğ‘€ ,ğ‘€ } denotes encoding and decoding matrices for
4 1 3 4
classification. Moreover, the characterisation of the network architecture requires to specify
unobservable network parameters such as synaptic weights (ğœ”) and firing thresholds (ğœ™). Thus, the
internal states of canonical neural networks for trial ğ‘˜ are provided as follows:
ğœ‘(6) = Â£ğ‘¥ (6) ,ğ‘¦ (6) ,ğœ”(6),ğœ†(6),ğœ™,ğ›¤,ğ‘€â„ (10)
3:) 3:)
where ğœ”(6) = Â£ğ‘Š (6) ,ğ‘Š (6) ,ğ¾ (6) ,ğ¾ (6) ,ğ‘‰ (6) ,ğ‘‰ (6) â„ denotes effective synaptic weights, ğœ†(6) =
3 > 3 > 3 >
(6) (6) (6) (6) (6) (6)
Â£ğœ† ,ğœ† ,ğœ† ,ğœ† ,ğœ† ,ğœ† â„ denotes plasticity insensitivity (stability of synaptic weights), ğœ™ =
B" B$ N" B$ O" O$
Xğœ™=,ğœ™=,ğœ™ * ,ğœ™ * Y denotes firing threshold factors, and ğ›¤ is the subjective risk for receiving weak
3 > 3 >
electric stimuli. Here, ğœ™, ğ›¤, and ğ‘€ are fixed over trials. The magnitude of plasticity is controlled
by plasticity insensitivity ğœ†.
The allocation into neuronal ensembles makes the neural activity suitable for analysis. This is
37
bioRxiv preprint doi: https://doi.org/10.1101/2025.08.06.668947; this version posted August 7, 2025. The copyright holder for this preprint
(which was not certified by peer review) is the author/funder. All rights reserved. No reuse allowed without permission.
conducted by optimising classification matrices ğ‘€ = {ğ‘€ ,ğ‘€ } to minimise ğ’œ, following the
3 4
gradient descent:
1 ğœ•
ğ‘€Ì‡ âˆ âˆ’ (ğ’œ +ğ¸ )
ğ‘¡ ğœ•ğ‘€ &%P/#
1 ) ğ¾ + ğ‘¥(ğ‘¡+Î”ğ‘¡) ğ‘‰ + ğ‘¦(ğ‘¡+Î”ğ‘¡) ğ‘Ÿ + 1ğœ•ğ¸
= Z â€œÂ«ğ‘“ +[ 3] [ ]+[ 3] [ ]â€ºâŠ™ğ‘¥ âŠ™ğ‘¥fi& ( ğ‘‘ğ‘¡âˆ’ &%P/# (11)
ğ‘¡ ğ¾ ğ‘¥(ğ‘¡+Î”ğ‘¡) ğ‘‰ ğ‘¦(ğ‘¡+Î”ğ‘¡) 1 ğ‘¡ ğœ•ğ‘€
> > >
where ğ‘“ = âˆ’sig<3,ğ‘¥(ğ‘¡)-+ğ‘Šğ‘œ(ğ‘¡)+ğ¾ğ‘¥(ğ‘¡âˆ’Î”ğ‘¡)+â„= is the right-hand side of equation (1). To
) ğ‘¥(ğ‘¡) 4
preclude pseudo-solutions, a reconstruction error term ğ¸ = 0.1âˆ« (cid:176)ğ‘Ÿ(ğ‘¡)âˆ’ğ‘€ & ((cid:176) ğ‘‘ğ‘¡+
&%P/# > 4 1
0.5ğ‘¡ğ’Ÿ [ğ‘(ğ‘¥)||ğ‘ (ğ‘¥)] was added to ensure the efficient extraction of major features in neural
KL >
activity data. The Kullbackâ€“Leibler divergence with an independent uniform prior distribution
ğ‘ (ğ‘¥) prevents ensembles ğ‘¥ from mutually correlating too strongly.
>
Projecting empirical neural data onto the manifold of ğ‘¥ enables interpretable, mechanistically
grounded predictions of learning trajectories. When estimating the generative model (Fig. 2d and
Fig. 3), the allocation was conducted using data in all 100 trials, ğ‘‘(3),â€¦,ğ‘‘(3>>). Conversely, when
predicting learning trajectories (Fig. 2e and Fig. 4), this was conducted using test data in the initial
20-trial adaptation period, ğ‘‘(3),â€¦,ğ‘‘(4>), to avoid double-dipping.
For the firing threshold factors, we considered that ğœ™ğ’™ and ğœ™ğ’š were constant during the short
experimental period and derived their posterior expectations as follows:
ğœ™ğ’™ âŸ¨ğ‘¥(ğ‘¡)âŸ©
â§ğœ™ğ’™ = [ 3] = ln[ ]
âª ğœ™ğ’™ âŸ¨ğ‘¥(ğ‘¡)âŸ©
>
ğ’š
(12)
ğœ™ âŸ¨ğ‘¦(ğ‘¡)âŸ©
â¨ ğœ™ğ’š = â€˜ 3a = ln[ ]
âª ğœ™ ğ’š âŸ¨ğ‘¦(ğ‘¡)âŸ©
â© >
where âŸ¨âˆ™âŸ© denotes the average (i.e., the mean value) over the data during the initial 20-trial
adaptation period.
Effective synaptic connectivities (ğ‘Š,ğ¾,ğ‘‰) were altered through activity dependent plasticity.
38
bioRxiv preprint doi: https://doi.org/10.1101/2025.08.06.668947; this version posted August 7, 2025. The copyright holder for this preprint
(which was not certified by peer review) is the author/funder. All rights reserved. No reuse allowed without permission.
Thus, these weights were estimated for each trial by minimising ğ’œ. Solving the fixed point of
equation (3) entails the following synaptic weights that minimise ğ’œ:
ğ‘Š = sig<3,âŸ¨ğ‘¥(ğ‘¡)ğ‘œ(ğ‘¡)+âŸ©âŠ˜kğ‘¥(ğ‘¡)1Qâƒ—+l-
â§ 3
âª ğ‘Š = sig<3,âŸ¨ğ‘¥(ğ‘¡)ğ‘œ(ğ‘¡)+âŸ©âŠ˜kğ‘¥(ğ‘¡)Q1âƒ—+l-
>
âª
ğ¾ = sig<3,âŸ¨ğ‘¥(ğ‘¡)ğ‘¥(ğ‘¡âˆ’Î”ğ‘¡)+âŸ©âŠ˜kğ‘¥(ğ‘¡)1Qâƒ—+l-
3
(13)
â¨ğ¾ = sig<3,âŸ¨ğ‘¥(ğ‘¡)ğ‘¥(ğ‘¡âˆ’Î”ğ‘¡)+âŸ©âŠ˜kğ‘¥(ğ‘¡)1Qâƒ—+l-
>
âª
ğ‘‰ = sig<3,âŸ¨ğ‘¦(ğ‘¡)ğ‘¥(ğ‘¡âˆ’Î”ğ‘¡)+âŸ©âŠ˜kğ‘¦(ğ‘¡)1Qâƒ—+l-
âª 3
â©ğ‘‰ = sig<3,âŸ¨ğ‘¦(ğ‘¡)ğ‘¥(ğ‘¡âˆ’Î”ğ‘¡)+âŸ©âŠ˜kğ‘¦(ğ‘¡)Q1âƒ—+l-
>
where âŠ˜ denotes the element-wise division and âŸ¨âˆ™âŸ© indicates the average over data sequences
up to the current trial. Substituting empirical data sequence up to trial k, ğ‘‘(3),â€¦,ğ‘‘(6), into
equation (13) yields the effective synaptic connectivity for trial k.
The subjective risk was estimated using Bayesian model selection. Here, the variational free
energy â„± (equivalent to ğ’œ) was computed with varying ğ›¤ for receiving aversive electric stimuli
between 0 and 1, and the value of ğ›¤ that minimise â„± over training period was selected.
ğ›¤ = argminâ„±(ğ›¤F) (14)
>ST%S3
This enables the characterisation of individual differences in punishment-related learning.
In summary, the initial network states ğœ‘(>) = Xğœ”(>),ğœ†(>),ğœ™,ğ›¤,ğ‘€Y at trial 0 comprise the
classification matrix ğ‘€, initial synaptic weights ğœ”(>), insensitivity to plasticity ğœ†(>), firing
threshold factors ğœ™, and subjective risk ğ›¤. Firing threshold factors ğœ™, initial synaptic weights
ğœ”(>), and initial plasticity insensitivity ğœ†(>) were determined as values that minimise ğ’œ by using
the empirical data in the initial 20 trials, ğ‘‘(3),â€¦,ğ‘‘(4>), whereas ğ›¤ and ğ‘€ were determined
using data during the entire training period, ğ‘‘(3),â€¦,ğ‘‘(3>>). These variables are computed by
executing the naive initialisation function that involves equations (11)â€“(14) (refer to
reverse_engineering.m and phi_init.m in Code [55]):
39
bioRxiv preprint doi: https://doi.org/10.1101/2025.08.06.668947; this version posted August 7, 2025. The copyright holder for this preprint
(which was not certified by peer review) is the author/funder. All rights reserved. No reuse allowed without permission.
ğœ‘(>) = Î¦ ,ğ‘‘(3),â€¦,ğ‘‘(3>>)- (15)
UVWXY_WUW[
Moreover, the estimation of internal variables in trial ğ‘˜ (1 â‰¤ ğ‘˜ â‰¤ 100) was defined as a
mapping from ğœ‘(6<3) to ğœ‘(6) given observable data ğ‘‘(6) and performed by executing the
following estimation function that computes equation (13) (see phi_estimate.m in Code [55]):
ğœ‘(6) = Î¦ ,ğ‘‘(6),ğœ‘(6<3)- (16)
Y\[W]V[Y
By recursively computing this function, ensemble activity ğ‘¥ (6) ,ğ‘¦ (6) , synaptic weights ğœ”(6), and
3:) 3:)
plasticity insensitivity ğœ†(6) were updated for each trial, whereas ğœ™, ğ›¤, and ğ‘€ remained fixed
throughout the training period. Owing to the established equivalence between canonical neural
networks and variational Bayesian inference [15â€“18], the internal states ğœ‘(6) can be
conceptualised in terms of posterior beliefs about external states ğ›(6) (Table 1).
Prediction of learning trajectories
This section establishes long-term prediction of internal states based on the free-energy
principle (Fig. 2e). When the free-energy principle is applied to a particular system, its predictive
validity can be examined by asking whether it can predict the system response [26]. On this
reading, a key challenge lies in forecasting long-term learning and self-organisation at the level of
individual brains. Such predictions are particularly challenging under closed-loop conditions
considered herein, because external inputs change depending on the actions of the fish, and this
generally yields largely different data sequences. The reverse engineered generative model can
help us overcome this by integrating bottom-up statistical inferences with theoretical predictions.
The predicted neural activities ğ‘¥(cid:181)(ğ‘¡) and ğ‘¦(cid:181)(ğ‘¡) were provided by substituting predicted
variables (ğ‘ŠÂ¶, ğ¾Â¶, ğ‘‰â€¢, â„â€¢=, and â„â€¢*) into equation (1), as follows:
40
bioRxiv preprint doi: https://doi.org/10.1101/2025.08.06.668947; this version posted August 7, 2025. The copyright holder for this preprint
(which was not certified by peer review) is the author/funder. All rights reserved. No reuse allowed without permission.
ğ‘¥(cid:181)Ì‡(ğ‘¡) âˆ âˆ’sig<3,ğ‘¥(cid:181)(ğ‘¡)-+ğ‘ŠÂ¶ğ‘œ(cid:181)(ğ‘¡)+ğ¾Â¶ğ‘¥(cid:181)(ğ‘¡âˆ’Î”ğ‘¡)+â„â€¢=
@ (17)
ğ‘¦(cid:181)Ì‡(ğ‘¡) âˆ âˆ’sig<3,ğ‘¦(cid:181)(ğ‘¡)-+ğ‘‰â€¢ğ‘¥(cid:181)(ğ‘¡âˆ’Î”ğ‘¡)+â„â€¢*
where ğ‘ŠÂ¶ â‰” ğ‘ŠÂ¶ âˆ’ğ‘ŠÂ¶ , ğ¾Â¶ â‰” ğ¾Â¶ âˆ’ğ¾Â¶ , and ğ‘‰â€¢ â‰” ğ›½ ,ğ‘‰â€¢ âˆ’ğ‘‰â€¢ - denote predicted synaptic weight
3 > 3 > * 3 >
matrices, â„â€¢= â‰” â„â€¢= âˆ’â„â€¢= and â„â€¢* â‰” â„â€¢= âˆ’â„â€¢= denote predicted firing thresholds that satisfy
3 > 3 >
â„â€¢= = lnsig,âˆ’ğ‘ŠÂ¶ -1Qâƒ—+lnsig,âˆ’ğ¾Â¶-Q1âƒ—+ğœ™â€¢= and â„â€¢* = ğ›½ lnsig,âˆ’ğ‘‰â€¢ -Q1âƒ—+ğœ™â€¢* (for ğ‘™ = 1,0), and
- - - - - * - -
ğ›½ = 3 represents a gain parameter introduced to align predicted activity more closely with
*
empirical activity. Here, unlike parameter estimation in the previous section, both the neural
activity and synaptic weights are determined to minimise ğ’œ in the absence of empirical data.
Moreover, owing to the closed-loop condition, predicted inputs ğ‘œ(cid:181)(ğ‘¡) differ from empirical data
ğ‘œ(ğ‘¡) as the agentâ€™s action changes the environmental states. Given these, the updates of synaptic
strengths were determined as follows:
ğ‘ŠÂ¶ = sig<3,âŸ¨ğ‘¥(cid:181)(ğ‘¡)ğ‘œ(cid:181)(ğ‘¡)+âŸ©âŠ˜kğ‘¥(cid:181)(ğ‘¡)1Qâƒ—+l-
â§ 3
âª ğ‘ŠÂ¶ = sig<3,kğ‘¥(cid:181)(ğ‘¡)ğ‘œ(cid:181)(ğ‘¡)+lâŠ˜kğ‘¥(cid:181)(ğ‘¡)Q1âƒ—+l-
>
âª
âª ğ¾Â¶ = sig<3,âŸ¨ğ‘¥(cid:181)(ğ‘¡)ğ‘¥(cid:181)(ğ‘¡âˆ’Î”ğ‘¡)+âŸ©âŠ˜kğ‘¥(cid:181)(ğ‘¡)1Qâƒ—+l-
3
ğ¾Â¶ = sig<3,kğ‘¥(cid:181)(ğ‘¡)ğ‘¥(cid:181)(ğ‘¡âˆ’Î”ğ‘¡)+lâŠ˜kğ‘¥(cid:181)(ğ‘¡)1Qâƒ—+l- (18)
â¨ >
âªğ‘‰â€¢ = sig<3&â€&1âˆ’2ğ›¤â€¢(ğ‘¡)(âŸ¨ğ‘¦(cid:181)(ğ‘¡)ğ‘¥(cid:181)(ğ‘¡âˆ’Î”ğ‘¡)+âŸ©â€âŠ˜kğ‘¦(cid:181)(ğ‘¡)1Qâƒ—+l(
3
âª
âª
ğ‘‰â€¢ = sig<3&â€&1âˆ’2ğ›¤â€¢(ğ‘¡)(kğ‘¦(cid:181)(ğ‘¡)ğ‘¥(cid:181)(ğ‘¡âˆ’Î”ğ‘¡)+lâ€âŠ˜kğ‘¦(cid:181)(ğ‘¡)1Qâƒ—+l(
â© >
Using equations (17) and (18), the predicted neural activity and synaptic strengths were computed
for each trial to obtain the sequences of neural activity and synaptic strengths.
To achieve accurate predictions, precise characterisation of the initial network states is crucial.
However, this is not straightforward because equation (15) relies on the empirical data from the
entire training period; thus, simply applying equation (15) to predictions would constitute double
dipping. To overcome this, we developed a pretrained initialisation function that predicts the initial
parameters of canonical neural networks based only on the initial empirical data, which is defined
41
bioRxiv preprint doi: https://doi.org/10.1101/2025.08.06.668947; this version posted August 7, 2025. The copyright holder for this preprint
(which was not certified by peer review) is the author/funder. All rights reserved. No reuse allowed without permission.
as follows (phi_pretrained_init.m in Code [55]):
Xğœ‘(cid:181)(3),â€¦,ğœ‘(cid:181)(4>)Y = Î¦ ,ğ‘‘(3),â€¦,ğ‘‘(4>),ğ›¬- (19)
^_Y[_VWUYâ€˜_WUW[
where ğ›¬ denotes a set of hyper-parameters. Here, predicted initial states ğœ‘(cid:181)(6) =
Â£ğ‘¥(cid:181) (6) ,ğ‘¦(cid:181) (6) ,ğœ”â€¦(6),ğœ†â€°(6),ğœ™â€¢,ğ›¤â€¢,ğ‘€Â¶â„ include neural activity ğ‘¥(cid:181) (6) ,ğ‘¦(cid:181) (6) , classification matrix ğ‘€Â¶, initial
3:) 3:) 3:) 3:)
synaptic weights ğœ”â€¦(6), initial plasticity insensitivity ğœ†â€°(6), firing thresholds ğœ™â€¢, and subjective risk
ğ›¤â€¢. This function outputs the predicted initial states ğœ‘(cid:181)(3),â€¦,ğœ‘(cid:181)(4>) based on observable data in the
initial 20-trial adaptation period, ğ‘‘(3),â€¦,ğ‘‘(4>). First, ğ‘€Â¶, ğœ™â€¢, ğœ”â€¦(3),â€¦,ğœ”â€¦(4>), and ğœ†â€°(3),â€¦,ğœ†â€°(4>)
were estimated using equations (11)â€“(13) based on the initial data ğ‘‘(3),â€¦,ğ‘‘(4>) of a fish. Then,
ğ›¤â€¢ was estimated and ğœ”â€¦(3),â€¦,ğœ”â€¦(4>) and ğœ™â€¢ were modified using a function
Xğ›¤â€¢,ğœ”â€¦(3),â€¦,ğœ”â€¦(4>),ğœ™â€¢Y = ğ‘“ ,ğœ”â€¦(3),â€¦,ğœ”â€¦(4>),ğœ™â€¢,ğ›¬-.
a+b
Hyper parameters ğ›¬ were optimised to maximise the predictability of the states up to trial 100
using the training dataset, which was conducted by minimising errors between empirical and
predicted variables over training dataset. The prediction analysis throughout this paper was
conducted based on leave-one-out cross-validation method [40]. To avoid double-dipping data
when making predictions, ğ›¬ was trained using data from trials 1 to 100 in the 44-fish training
dataset. Then, the predicted initial values ğœ‘(cid:181)(3),â€¦,ğœ‘(cid:181)(4>) for the test data were estimated using
only data from the initial 20 trials of the test fish.
Trained on an activity dataset of other fish, this function estimates the initial internal variables
for each fish based on the neural activity during the initial adaptation phase. Hence, while a part of
parameters such as subjective risk ğ›¤ cannot be computed directly from the initial observable data
as fish had not yet received punishment, the pretrained initialisation allow to characterise the
initial states of the test data. This method automates the identification of neural ensembles and
the selection of initial parameter values, which were previously performed heuristically [27], and
42
bioRxiv preprint doi: https://doi.org/10.1101/2025.08.06.668947; this version posted August 7, 2025. The copyright holder for this preprint
(which was not certified by peer review) is the author/funder. All rights reserved. No reuse allowed without permission.
improves model initialisation.
After the initial states ğœ‘(cid:181)(3),â€¦,ğœ‘(cid:181)(4>) are determined, the canonical neural network model
simulates the subsequent activity and plasticity according to the free energy minimisation, which
yields a series of internal states ğœ‘(cid:181)(43),â€¦,ğœ‘(cid:181)(3>>) and external states ğœ‘(cid:181) (43) ,â€¦,ğœ‘(cid:181) (3>>) . These
%#c %#c
predictions were performed by executing the prediction function that involves equations (17) and
(18) (see phi_predict.m in Code [55]):
Â£ğœ‘(cid:181)(6),ğœ‘(cid:181) (6) â„ = Î¦ ,ğœ‘(cid:181)(6<3),â„°- (20)
%#c ^_Yâ€˜Wd[
where â„° = {ğ´,ğµ,ğ¶,ğ·,ğ¸} denotes a set of parameters that determine the POMDP environmental
settings and ğœ‘(cid:181)(6) = Â£ğ‘¥(cid:181) (6) ,ğ‘¦(cid:181) (6) ,ğœ”â€¦(6),ğœ†â€°(6),ğœ™â€¢,ğ›¤â€¢,ğ‘€Â¶â„ and ğœ‘(cid:181) (6) = Â£ğ‘œ(cid:181) (6) ,ğ›¿â€°(6) ,ğ‘ Ì‚ (6) â„ are predicted
3:) 3:) %#c 3:) 3:) 3:)
internal and external states at trial k, respectively. These predicted internal states ğœ‘(cid:181)(6) were then
compared with the sequences of empirical internal states ğœ‘(6) to assess the prediction accuracy
(Fig. 4).
Data Availability
Example raw data analysed in this work are available in the repository
(https://doi.org/10.5281/zenodo.5195611). Full raw data are available from the corresponding
author of previous work [33] upon request. Source data are provided with this paper.
Code Availability
The simulations and analyses were conducted using MATLAB version R2020a. The scripts are
available at GitHub https://github.com/takuyaisomura/reverse_engineering [55]. The scripts are
43
bioRxiv preprint doi: https://doi.org/10.1101/2025.08.06.668947; this version posted August 7, 2025. The copyright holder for this preprint
(which was not certified by peer review) is the author/funder. All rights reserved. No reuse allowed without permission.
covered under the GNU General Public License v3.0.
References
1. George, D. & Hawkins, J. Towards a mathematical theory of cortical micro-circuits. PLoS
Comput. Biol. 5, e1000532 (2009).
2. Bastos, A. M., Usrey, W. M., Adams, R. A., Mangun, G. R., Fries, P. & Friston, K. J. Canonical
microcircuits for predictive coding. Neuron 76, 695â€“711 (2012).
3. Song, Y., Millidge, B., Salvatori, T., Lukasiewicz, T., Xu, Z. & Bogacz, R. Inferring neural activity
before plasticity as a foundation for learning beyond backpropagation. Nat. Neurosci. 27,
348â€“358 (2024).
4. Hassabis, D., Kumaran, D., Summerfield, C. & Botvinick, M. Neuroscience-inspired artificial
intelligence. Neuron 95, 245â€“258 (2017).
5. Friston, K. J., Stephan, K. E., Montague, R. & Dolan, R. J. Computational psychiatry: the brain
as a phantastic organ. Lancet Psychiatry 1 148â€“158 (2014).
6. Auksztulewicz, R. & Friston, K. J. Attentional enhancement of auditory mismatch responses: a
DCM/MEG study. Cereb. Cortex 25, 4273â€“4283 (2015).
7. Singh, M. F., Braver, T. S., Cole, M. & Ching, S. Precision data-driven modeling of cortical
dynamics reveals person-specific mechanisms underpinning brain electrophysiology. Proc.
Natl. Acad. Sci. U.S.A. 122, e2409577121 (2025).
8. Takahashi, Y., Idei, H., Komatsu, M., Tani, J., Tomita, H. & Yamashita, Y. Digital twin brain
simulator for real-time consciousness monitoring and virtual intervention using primate
44
bioRxiv preprint doi: https://doi.org/10.1101/2025.08.06.668947; this version posted August 7, 2025. The copyright holder for this preprint
(which was not certified by peer review) is the author/funder. All rights reserved. No reuse allowed without permission.
electrocorticogram data. NPJ Digit. Med. 8, 80 (2025).
9. Wang, E.Y., Fahey, P.G., Ding, Z. et al. Foundation model of neural activity predicts response to
new stimulus types. Nature 640, 470â€“477 (2025).
10. Friston, K. J., Kilner, J. & Harrison, L. A free energy principle for the brain. J. Physiol. Paris 100,
70â€“87 (2006).
11. Friston, K. J. The free-energy principle: a unified brain theory? Nat. Rev. Neurosci. 11, 127â€“138
(2010).
12. Blei, D. M., Kucukelbir, A. & McAuliffe, J. D. Variational inference: A review for statisticians. J.
Am. Stat. Assoc. 112, 859â€“877 (2017).
13. Friston, K. J., FitzGerald, T., Rigoli, F., Schwartenbeck, P. & Pezzulo, G. Active inference: a
process theory. Neural Comput. 29, 1â€“49 (2017).
14. Parr, T., Pezzulo, G. & Friston, K. J. Active inference: the free energy principle in mind, brain,
and behavior. (MIT Press, Cambridge, MA, USA, 2022).
15. Isomura, T. & Friston, K. J. Reverse-engineering neural networks to characterize their cost
functions. Neural Comput. 32, 2085â€“2121 (2020).
16. Isomura, T., Shimazaki, H. & Friston, K. J. Canonical neural networks perform active inference.
Commun. Biol. 5, 55 (2022).
17. Isomura, T. Bayesian mechanics of self-organising systems. arXiv:2311.10216 (2023).
18. Isomura, T. Triple equivalence for the emergence of biological intelligence. Commun. Phys. 8,
160 (2025).
19. Yagishita, S., Hayashi-Takagi, A., Ellis-Davies, G. C., Urakubo, H., Ishii, S. & Kasai, H. A critical
45
bioRxiv preprint doi: https://doi.org/10.1101/2025.08.06.668947; this version posted August 7, 2025. The copyright holder for this preprint
(which was not certified by peer review) is the author/funder. All rights reserved. No reuse allowed without permission.
time window for dopamine actions on the structural plasticity of dendritic spines. Science
345, 1616â€“1620 (2014).
20. He, K., Huertas, M., Hong, S. Z., Tie, X., Hell, J. W., Shouval, H. & Kirkwood, A. Distinct eligibility
traces for LTP and LTD in cortical synapses. Neuron 88, 528â€“538 (2015).
21. Wieland, S., Schindler, S., Huber, C., KÃ¶hr, G., Oswald, M. J. & Kelsch, W. Phasic dopamine
modifies sensory-driven output of striatal neurons through synaptic plasticity. J. Neurosci. 35,
9946â€“9956 (2015).
22. Brzosko, Z., Zannone, S., Schultz, W., Clopath, C. & Paulsen, O. Sequential neuromodulation of
Hebbian plasticity offers mechanism for effective reward-based navigation. eLife 6, e27756
(2017).
23. Pawlak, V., Wickens, J. R., Kirkwood, A. & Kerr, J. N. Timing is not everything: neuromodulation
opens the STDP gate. Front. Syn. Neurosci. 2, 146 (2010).
24. FrÃ©maux, N. & Gerstner, W. Neuromodulated spike-timing-dependent plasticity, and theory of
three-factor learning rules. Front. Neural Circuits 9, 85 (2016).
25. KuÅ›mierz, Å., Isomura, T. & Toyoizumi, T. Learning with three factors: modulating Hebbian
plasticity with errors. Curr. Opin. Neurobiol. 46, 170â€“177 (2017).
26. Isomura T. Active inference leads to Bayesian neurophysiology. Neurosci Res. 175:38-45
(2022).
27. Isomura, T., Kotani, K., Jimbo, Y. & Friston, K. J. Experimental validation of the free-energy
principle with in vitro neural networks. Nat. Commun. 14, 4547 (2023).
28. Friedrich, R. W., Jacobson, G. A. & Zhu, P. Circuit neuroscience in zebrafish. Curr. Biol. 20,
46
bioRxiv preprint doi: https://doi.org/10.1101/2025.08.06.668947; this version posted August 7, 2025. The copyright holder for this preprint
(which was not certified by peer review) is the author/funder. All rights reserved. No reuse allowed without permission.
R371â€“R381 (2010).
29. Ahrens, M. B. & Engert, F. Large-scale imaging in small brains. Curr. Opin. Neurobiol. 32, 78â€“86
(2015).
30. Aoki, T., Kinoshita, M., Aoki, R. et al. Imaging of neural ensemble for the retrieval of a learned
behavioral program. Neuron 78, 881â€“894 (2013).
31. Tanimoto, Y., Kakinuma, H., Aoki, R., Shiraki, T., Higashijima, S. I. & Okamoto, H. Transgenic
tools targeting the basal ganglia reveal both evolutionary conservation and specialization of
neural circuits in zebrafish. Cell Rep. 43, 113916 (2024).
32. Islam, T., Torigoe, M., Tanimoto, Y. & Okamoto, H. Adult zebrafish can learn Morris water
maze-like tasks in a two-dimensional virtual reality system. Cell Rep. Methods 4, 100863
(2024).
33. Torigoe, M., Islam, T., Kakinuma, H. et al. Zebrafish capable of generating future state
prediction error show improved active avoidance behavior in virtual reality. Nat. Commun. 12,
1â€“21 (2021).
34. Holman, J. G., Lai, W. W., Pichler, P., Saska, D., Lagnado, L. & Buckley, C. L. A behavioral and
modeling study of control algorithms underlying the translational optomotor response in
larval zebrafish with implications for neural circuit function. PLoS Comput. Biol. 19, e1010924
(2023).
35. Isomura, T., Kotani, K. & Jimbo, Y. Cultured cortical neurons can perform blind source
separation according to the free-energy principle. PLoS Comput. Biol. 11, e1004643 (2015).
36. Isomura, T. & Friston, K. J. In vitro neural networks minimise variational free energy. Sci. Rep.
8, 16926 (2018).
47
bioRxiv preprint doi: https://doi.org/10.1101/2025.08.06.668947; this version posted August 7, 2025. The copyright holder for this preprint
(which was not certified by peer review) is the author/funder. All rights reserved. No reuse allowed without permission.
37. Bahl, A. & Engert, F. Neural circuits for evidence accumulation and decision making in larval
zebrafish. Nat. Neurosci. 23, 94â€“102 (2020).
38. Funamizu, A., Kuhn, B. & Doya, K. Neural substrate of dynamic Bayesian inference in the
cerebral cortex. Nat. Neurosci. 19, 1682â€“1689 (2016).
39. Del Giudice, M. Effective dimensionality: A tutorial. Multivar. Behav. Res. 56, 527â€“542 (2021).
40. Kohavi, R. A study of cross-validation and bootstrap for accuracy estimation and model
selection. In Proceedings of the 14th international joint conference on Artificial intelligence
14, 1137â€“1143 (1995).
41. Aldarondo, D., Merel, J., Marshall, J. D. et al. A virtual rodent predicts the structure of neural
activity across behaviours. Nature 632, 594â€“602 (2024).
42. Friston, K. J., Harrison, L. & Penny, W. Dynamic causal modelling. Neuroimage 19, 1273â€“1302
(2003).
43. Friston, K. J., Preller, K. H., Mathys, C. et al. Dynamic causal modelling revisited. Neuroimage
199, 730â€“744 (2019).
44. UeltzhÃ¶ffer, K. Deep active inference. Biol. Cybern. 112, 547â€“573 (2018).
45. Van de Maele, T., Dhoedt, B., Verbelen, T. & Pezzulo, G. A hierarchical active inference model
of spatial alternation tasks and the hippocampal-prefrontal circuit. Nat. Commun. 15, 9892
(2024).
46. Schwartenbeck, P. & Friston, K. J. Computational phenotyping in psychiatry: a worked
example. eNeuro 3, e0049-16.2016 (2016).
47. Fletcher, P. C. & Frith, C. D. Perceiving is believing: a Bayesian approach to explaining the
48
bioRxiv preprint doi: https://doi.org/10.1101/2025.08.06.668947; this version posted August 7, 2025. The copyright holder for this preprint
(which was not certified by peer review) is the author/funder. All rights reserved. No reuse allowed without permission.
positive symptoms of schizophrenia. Nat. Rev. Neurosci. 10, 48â€“58 (2009).
48. Friedrich, J., Zhou, P. & Paninski, L. Fast online deconvolution of calcium imaging data. PLoS
Comput. Biol. 13, e1005423 (2017).
49. Hodgkin, A. L. & Huxley, A. F. A quantitative description of membrane current and its
application to conduction and excitation in nerve. J. Physiol. 117, 500â€“544 (1952).
50. FitzHugh, R. Impulses and physiological states in theoretical models of nerve membrane.
Biophys. J. 1, 445â€“466 (1961).
51. Nagumo, J., Arimoto, S. & Yoshizawa, S. An active pulse transmission line simulating nerve
axon. Proc. IRE 50, 2061â€“2070 (1962).
52. Kaelbling, L. P., Littman, M. L. & Cassandra, A. R. Planning and acting in partially observable
stochastic domains. Artif. Intell. 101, 99-134 (1998).
53. Dauwels, J. On variational message passing on factor graphs. In 2007 IEEE International
Symposium on Information Theory (IEEE, 2007).
54. Smith, R., Friston, K. J. & Whyte, C. J. A step-by-step tutorial on active inference and its
application to empirical data. J. Math. Psychol. 107, 102632 (2022).
55. Isomura, T. Predicting individual learning trajectories in zebrafish via the free-energy principle
[Code]. GitHub https://github.com/takuyaisomura/reverse_engineering (2025).
Acknowledgements
T.I. is supported by the Japan Society for the Promotion of Science (JSPS) KAKENHI under Grant
Number JP23H04973, the Japan Agency for Medical Research and Development (AMED) under
49
bioRxiv preprint doi: https://doi.org/10.1101/2025.08.06.668947; this version posted August 7, 2025. The copyright holder for this preprint
(which was not certified by peer review) is the author/funder. All rights reserved. No reuse allowed without permission.
Grant Number JP23wm0625001, and the Japan Science and Technology Agency (JST) CREST under
Grant Number JPMJCR22P1. The funders had no role in study design, data collection and analysis,
decision to publish, or preparation of the manuscript.
Competing interest declaration
The authors declare no competing interests.
Table 1. Correspondence of variables and functions
Neural network formation Variational Bayes formation
Sensory inputs ğ‘œ(ğ‘¡) âŸº ğ‘œ Sensory inputs
)
ğ‘¥(ğ‘¡)
Middle-layer neural activity [ ] âŸº ğ¬ State posterior
ğ‘¥(ğ‘¡) )
ğ‘¦(ğ‘¡)
Output-layer neural activity [ ] âŸº ğ›… Action posterior
ğ‘¦(ğ‘¡) )
Action ğ›¿(ğ‘¡) âŸº ğ›¿ Action
)
Neuromodulator ğ›¤(ğ‘¡) âŸº ğ›¤ Risk
)
sig(ğ‘Š) âŸº ğ€
- 3-
Synaptic weights sig(ğ¾) âŸº ğe Parameter posterior
- 3-
sig(ğ‘‰) âŸº ğ‚e
- 3-
ğœ™=
ğœ™= â‰” [ 3] âŸº lnğ· State prior
ğœ™=
Firing thresholds (constant >
*
ğœ™
parts) ğœ™* â‰” â€˜ 3a âŸº lnğ¸ Action prior
*
ğœ™
>
50
bioRxiv preprint doi: https://doi.org/10.1101/2025.08.06.668947; this version posted August 7, 2025. The copyright holder for this preprint
(which was not certified by peer review) is the author/funder. All rights reserved. No reuse allowed without permission.
â„= âŸº lnğ€ â‹…1Qâƒ—+lnğe â‹…1Qâƒ—+lnğ·
- >- >- -
Adaptive firing thresholds
â„ * âŸº lnğ‚e â‹…1Qâƒ—+lnğ¸
- >- -
Bold case variables (e.g., ğ¬ ) denote the posterior expectations of the corresponding italic case
D
random variables (e.g., ğ‘  ); index ğ‘™ is for ğ‘™ = 0,1; and ğe = ğ+diag[ğ·]<3 and ğ‚e =
D
ğ‚+diag[ğ¸]<3 indicate the inverse mappings. Refer to the previous paper [15,16] for details.
51