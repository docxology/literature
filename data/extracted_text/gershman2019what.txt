O R I GI N A L A R T IC L E
NBDT}
T h E O R y
7HATDOESTHEFREEENERGYPRINCIPLETELLUSABOUT
THEBRAIN?
3AMUELJ.GERSHMAN1∗
1DEPARTMENTOF0SYCHOLOGYANDCENTERFOR
BRAIN3CIENCE,(ARVARD5NIVERSITY,
CAMBRIDGE,-!,02138,53!
CORRESPONDENCE
.ORTHWEST,ABORATORIES,52OxFORD3T.,
2OOM295.05,CAMBRIDGE,-!,02138,53!
EMAIL:GERSHMAN@FAS.HARVARD.EDU
FUNDINGINFORMATION
4HISWORKWASSUPPORTEDBYARESEARCH
FELLOWSHIPFROMTHE!LFRED0.3LOAN
&OUNDATION.
4HEFREEENERGYPRINCIPLEHASBEENPROPOSEDASAUNIFYING
ACCOUNTOFBRAINFUNCTION.)TISCLOSELYRELATED,ANDINSOME
CASESSUBSUMES,EARLIERUNIFYINGIDEASSUCHASBAYESIANIN-
FERENCE,PREDICTIVECODING,ANDACTIVELEARNING. 4HISARTI-
CLECLARIﬁESTHESECONNECTIONS,TEASINGAPARTDISTINCTIVEAND
SHAREDPREDICTIONS.
KEY7O2D3
BAYESIANBRAIN,DECISIONTHEORY,VARIATIONALINFERENCE,PREDICTIVE
CODING
1 | I.42OD5C4IO.
4HEFREEENERGYPRINCIPLE(&E0)STATES,INANUTSHELL,THATTHEBRAINSEEKSTOMINIMIzESURPRISE; 1=.)TISARGUABLYTHEMOST
AMBITIOUSTHEORYOFTHEBRAINAVAILABLETODAY,CLAIMINGTOSUBSUMEMANYOTHERIMPORTANTIDEAS,SUCHASPREDICTIVECODING,
EFﬁCIENTCODING,BAYESIANINFERENCE,ANDOPTIMALCONTROLTHEORY.(OWEVER,ITISPRECISELYTHISGENERALITYTHATRAISESA
CONCERN:WHATExACTLYDOES&E0PREDICT,ANDWHATDOESITNOTPREDICT?!DDRESSINGTHISCONCERNISNOTEASY,BECAUSETHE
ASSUMPTIONSUNDERLYINGAPPLICATIONSOF&E0AREMALLEABLE(E.G.,DIFFERENTAPPLICATIONSUSEDIFFERENTGENERATIVEMODELS,
DIFFERENTALGORITHMICAPPROxIMATIONS,ANDDIFFERENTNEURALIMPLEMENTATIONS).-OREOVER,SOMEOFTHESEASSUMPTIONSARE
SHAREDWITHOTHERTHEORIES,ANDSOMEAREIDIOSYNCRATIC;SOMEASSUMPTIONSARECENTRALTOTHETHEORY,ANDOTHERSARE ad
hoc ORMADEFORANALYTICALCONVENIENCE.
4HISARTICLESYSTEMATICALLYDECONSTRUCTSTHEASSUMPTIONSUNDERLYING&E0,WITHTHEGOALOFIDENTIFYINGWHATITS
DISTINCTIVETHEORETICALCLAIMSARE.!SWILLBECOMECLEAR,&E0DOESNOTHAVEA ﬁxEDSETOFDISTINCTIVECLAIMS.2ATHER,IT
MAKESDIFFERENTCLAIMSUNDERDIFFERENTSETSOFASSUMPTIONS.4HISISNOTNECESSARILYABADTHING,PROVIDEDWECANVERIFY
THESEASSUMPTIONSINANYPARTICULARAPPLICATIONANDTHUSRENDERTHETHEORETICALASSUMPTIONSFALSI ﬁABLE.
1
arXiv:1901.07945v5  [q-bio.NC]  2 Oct 2019
2 3!-5E, J.GE23(-!.
BEFOREPROCEEDING,WEMUSTADDRESSTWOqUALMSWITHTHISDECONSTRUCTIVEAPPROACH.3OMEPROPONENTSOF&E0
MIGHTREASONABLYARGUETHATIDENTIFYINGDISTINCTIVETHEORETICALCLAIMSISPOINTLESS;THEWHOLEPOINTOFAUNIFYINGTHEORY
ISTOUNIFYCLAIMS,NOTDISTINGUISHTHEM. (OWEVER,THEFUNDAMENTALISSUEHEREISNOTWHETHERONETHEORYISBETTER
THANANOTHER,BUTHOWTOASSIGNCREDITANDBLAMETODIFFERENTTHEORETICALASSUMPTIONS.)F&E0FAILSTOACCOUNTFORTHE
DATA,ISTHATATTRIBUTABLETOTHEASSUMPTIONTHATTHEBRAINISBAYESIAN,ORAPARTICULARALGORITHMICIMPLEMENTATIONOF
BAYESIANINFERENCE,ORPARTICULARASSUMPTIONSABOUTTHEPROBABILISTICMODEL?ONLYBYANSWERINGSUCHqUESTIONSCANWE
UNDERSTANDTHESUCCESSESANDFAILURESOFAUNIFYINGTHEORY,DEVISESUITABLETESTSOFITSASSUMPTIONS,ANDIDENTIFYWAYSTO
IMPROVETHETHEORY.
!NOTHERqUALMWITHTHISAPPROACHISBASEDONTHEARGUMENTTHAT&E0ISNOTATHEORYATALL,INTHESENSETHATATHEORY
CONSTITUTESASETOFFALSI ﬁABLECLAIMSABOUTEMPIRICALPHENOMENA.7HATMAKESITA principLe,RATHERTHANATHEORY,ISTHAT
ITCONSTITUTESASETOFSELF-CONSISTENTSTATEMENTSINAFORMALMATHEMATICALSYSTEM.)NTHISSENSE,APRINCIPLECANNOTBE
FALSIﬁEDTHROUGHTHESTUDYOFEMPIRICALPHENOMENA.!THEORYDESIGNATESCORRESPONDENCESBETWEENFORMALSTATEMENTS
ANDEMPIRICALPHENOMENA,ANDTHUSCANBEFALSI ﬁEDIFTHETHEORYMAKESINCORRECTPREDICTIONSONTHEBASISOFTHESE
CORRESPONDENCES.6IEWEDINTHISWAY,&E0ISUNOBJECTIONABLE:ITSMATHEMATICALSOUNDNESSISSUF ﬁCIENTDEMONSTRATION
OFITSCREDENTIALSASAPRINCIPLE.(EREWEWILLBECONCERNEDWITHITSCREDENTIALSASATHEORY,ANDTHEREFOREWEWILLPAY
PARTICULARATTENTIONTOSPECI ﬁCIMPLEMENTATIONS(PROCESSMODELS).
2 | 4HEBAYE3IA.B2AI.HYPO4HE3I3
!SAPRELUDETO&E0,ITWILLBEHELPFULTOBRIE ﬂYDESCRIBETHEBAYESIANBRAINHYPOTHESIS; 2,3,4=,WHICHCANBEExPRESSEDIN
TERMSTHATAREMOREFAMILIARTONEUROSCIENTISTS,ANDISINFACTEqUIVALENTTO&E0UNDERCERTAINCONDITIONS(ASELABORATED
INTHENExTSECTION).4HE ﬁRSTCLAIMOFTHEBAYESIANBRAINHYPOTHESISISTHATTHEBRAINISEqUIPPEDWITHANINTERNAL(OR
“GENERATIVE”)MODELOFTHEENVIRONMENT,WHICHSPECI ﬁESA“RECIPE”FORGENERATINGSENSORYOBSERVATIONS(DENOTEDBY o)
FROMHIDDENSTATES(DENOTEDBY s).4HISINTERNALMODELMAYNOTBEREPRESENTEDExPLICITLYANYWHEREINTHEBRAIN;THE
CLAIMISTHATTHEBRAINCOMPUTES“ASIF”ITHADANINTERNALMODEL.)NORDERFORTHEBAYESIANBRAINHYPOTHESISTOHAVEANY
PREDICTIVEPOWER,ITISNECESSARYTOMAKESPECI ﬁCASSUMPTIONSABOUTTHESTRUCTUREOFTHEINTERNALMODEL.
4HEREARETWOCOMPONENTSOFTHEINTERNALMODELTHATNEEDTOBESPECI ﬁED. &IRST,HIDDENVARIABLESAREDRAWN
FROMAprior distribution,p(s).&ORExAMPLE,THEHIDDENSTATEMIGHTBETHEORIENTATIONOFALINESEGMENTONTHESURFACE
OFANOBJECT,ANDTHEPRIORMIGHTBEADISTRIBUTIONTHATFAVORSCARDINALOVEROBLIqUEORIENTATIONS; 5=. 3ECOND,THE
SENSORYOBSERVATIONSAREDRAWNFROMANOBSERVATIONDISTRIBUTIONCONDITIONALONTHEHIDDENSTATE, p(o|s).&ORExAMPLE,
THEHIDDENLINEORIENTATIONISPROJECTEDONTOTHERETINAANDTHENENCODEDBYTHE ﬁRINGOFRETINALGANGLIONCELLS.4HIS
ENCODINGPROCESSMIGHTBENOISY(DUETOSTOCHASTICITYOFNEURAL ﬁRING)ORAMBIGUOUS(DUETOTHEOPTICALPROJECTION
OFTHREEDIMENSIONSONTOTHETWO-DIMENSIONALRETINALIMAGE),SUCHTHATDIFFERENTSETTINGSOFTHEHIDDENSTATECOULD
PLAUSIBLY“ExPLAIN”THEOBSERVATIONSTOVARYINGDEGREES.4HESEDEGREESOFPLAUSIBILITYAREqUANTI ﬁEDBYTHE LikeLihood,THE
PROBABILITYOFTHEOBSERVATIONSUNDERTHEOBSERVATIONDISTRIBUTIONGIVENAHYPOTHETICALSETTINGOFTHEHIDDENSTATE.
4HESECONDCLAIMOFTHEBAYESIANBRAINHYPOTHESISISTHATTHETHEPRIORANDTHELIKELIHOODARECOMBINEDTOINFERTHE
HIDDENSTATEGIVENTHEOBSERVATIONS,ASSTIPULATEDBYBAYES’RULE:
p(s|o)= p(o|s)p(s)
p(o) , (1)
WHEREp(s|o)ISTHEposterior distributionANDp(o)=Í
s p(o|s)p(s)ISTHEmarginaL LikeLihood(FORCONTINUOUSSTATES,THE
SUMMATIONISREPLACEDWITHINTEGRATION).7ECANTHINKOFBAYES’RULEAS“INVERTING”THEINTERNALMODELTOCOMPUTEA
3!-5E, J.GE23(-!. 3
BELIEFABOUTTHEHIDDENSTATEOFTHEENVIRONMENTGIVENTHEOBSERVATIONS.
4HEBAYESIANBRAINHYPOTHESISCANBENATURALLYExTENDEDTOSETTINGSWHEREANAGENTCANIN ﬂUENCEITSOBSERVATIONS
BYTAKINGACTIONSACCORDINGTOAPOLICY π,WHICHISAMAPPINGFROMOBSERVATIONSTOADISTRIBUTIONOVERACTIONS.)NTHE
SIMPLESTVARIANT,ANAGENTCHOOSESAPOLICYTHATMAxIMIzES information gain:
I(π)=
Õ
o
p(o|π)D[p(s|o, π)||p(s|π)], (2)
WHEREoNOWDENOTESAFUTUREOBSERVATION,AND DDENOTESTHEKULLBACK-,EIBLER(K,)DIVERGENCE(ALSOKNOWNASreLative
entropy):
D[p(s|o, π)||p(s|o)]=
Õ
s
p(s|o, π)LOGp(s|o, π)
p(s|π) . (3)
4HEExPRESSIONFOR I(π)ISEqUIVALENTTO“BAYESIANSURPRISE”; 6=,ANDTOTHEMUTUALINFORMATIONBETWEEN s ANDo
CONDITIONALONπ;7,8=.)NFORMATIONMAxIMIzATIONHASBEENSTUDIEDExTENSIVELYINTHECOGNITIVEPSYCHOLOGYLITERATURE
;9,10,11=. -OREGENERALLY,INFORMATIONMAxIMIzATIONCANBEUNDERSTOODASAFORMOF active LearningTHATHASBEEN
STUDIEDExTENSIVELYINTHEMACHINELEARNINGANDSTATISTICSLITERATURE;12=.
)NFORMATIONGAINMAxIMIzATIONISASPECIALCASEOFBAYESIANDECISIONTHEORY,WHERETHEUTILITY u(o)= D[p(s|o, π)||p(s|π)]
OFANOBSERVATIONCORRESPONDSTOINFORMATIONGAIN.)FTHEOBSERVATIONSAREVALENCED(REWARDSORPUNISHMENTS),THEN
UTILITIESMAYREﬂECTTHEIRGOODNESSTOTHEAGENT,WHOSEEKSTOMAxIMIzETHEExPECTEDUTILITY:
Å[u(o)|π]=
Õ
o
p(o|π)u(o). (4)
4HISANALYSISCANBEGENERALIzEDTOSEqUENTIALDECISIONPROBLEMS;SEE 13=,WHEREANAGENT’SACTIONSANDOBSERVATIONS
UNFOLDOVERTIME.4YPICALLY,THEGOALINSEqUENTIALDECISIONPROBLEMSISTOMAxIMIzEDISCOUNTEDCUMULATIVEUTILITY(RETURN):
R(O)=u(o1)+γu(o2)+γ2u(o3)+··· (5)
WHEREWEHAVEINTRODUCEDASUBSCRIPTDENOTINGTIME-STEPANDTHEBOLDNOTATION O=[o1, o2, . . .]DENOTESTHETIME-SERIES
OFOBSERVATIONS.4HEDISCOUNTFACTOR γDOWN-WEIGHTSFUTUREUTILITYExPONENTIALLYASAFUNCTIONOFTEMPORALDISTANCE.4HE
ExPECTEDRETURNUNDERTHEPOSTERIORISTHENDE ﬁNEDANALOGOUSLYTOExPECTEDUTILITY:
Å[R(O)|π]=
Õ
O
p(O|π)R(O). (6)
)NSEqUENTIALDECISIONPROBLEMS,ANAGENTNEEDSTOTRADEOFFGATHERINGINFORMATIONTOREDUCEUNCERTAINTY(ExPLORATION)
ANDTAKINGACTIONSTHATYIELDIMMEDIATEREWARD(ExPLOITATION).4HISMEANSTHATPREFERENCESFORINFORMATIONWILLARISE
INSTRUMENTALLYINTHESEqUENTIALDECISIONSETTING;THEYNEEDNOTBEBUILTExPLICITLYINTOTHEUTILITYFUNCTION.
4HEREARESEVERALPOINTSWORTHNOTINGHEREBEFOREMOVINGON:
• !LTHOUGHTHEBAYESIANBRAINHYPOTHESISHASRECEIVEDCONSIDERABLESUPPORT,THEREARENUMEROUSEMPIRICALDEVIATIONS
FROMITSCLAIMS(E.G.,;14,15=,)SOMEOFWHICHMAYBERATIONALIzEDBYCONSIDERINGAPPROxIMATEINFERENCEALGORITHMS
;16=.4HEVARIATIONALALGORITHMSWECONSIDERBELOWAREExAMPLESOFSUCHAPPROxIMATIONS.7EWILLNOTEVALUATE
THEEMPIRICALVALIDITYOFTHE(APPROxIMATE)BAYESIANBRAINHYPOTHESIS,FOCUSINGINSTEADONMORECONCEPTUALISSUES
4 3!-5E, J.GE23(-!.
RELATEDTOTHEFREEENERGYPRINCIPLE.
• 4HEBAYESIANBRAINHYPOTHESISDOESNOTMAKEANYSPECI ﬁCCLAIMSABOUTTHEPRIORSANDLIKELIHOODSOFANINDIVIDUAL.
2ATHER,THECENTRALCLAIMCONCERNSCONSISTENCYOFBELIEFS:ABAYESIANAGENTWILLCONVERTPRIORBELIEFSINTOPOSTERIOR
BELIEFSINACCORDANCEWITHBAYES’RULE.
• 4HEBAYESIANBRAINHYPOTHESISABSTRACTSAWAYFROMANYPARTICULARALGORITHMICORNEURALCLAIMS: ITISPURELYA
“COMPUTATIONAL-LEVEL”HYPOTHESIS.!LLALGORITHMSTHATCOMPUTETHEPOSTERIORExACTLYGIVEEqUIVALENTPREDICTIONS
WITHREGARDTOTHECENTRALCLAIMSOFTHEBAYESIANBRAINHYPOTHESIS,ANDLIKEWISEANYNEURALIMPLEMENTATIONWILL
GIVEEqUIVALENTPREDICTIONS.4HESEEqUIVALENCESDONOTHOLD,HOWEVER,WHENWECONSIDER approximateINFERENCE
SCHEMES,WHICHMAYSYSTEMATICALLYDEVIATEFROMTHEBAYESIANIDEAL.7EWILLRETURNTOTHISPOINTBELOW.
3 | 4HE5.2E342IC4EDF2EEE.E2GYP2I.CIPLEI3BAYE3IA.I.FE2E.CE
4HEBASICIDEAOFTHE&E0ISTOCONVERTBAYESIANINFERENCEINTOANOPTIMIzATIONPROBLEM(SEE; 17=FORATUTORIALINTRO-
DUCTION).4HISIDEAWASﬁRSTDEVELOPEDINPHYSICS,ANDLATERINMACHINELEARNING,TOHANDLECOMPUTATIONALLYINTRACTABLE
INFERENCEPROBLEMS.4HEKEYALGORITHMICTRICK,ASWEWILLSEE,ISTORESTRICTTHEOPTIMIzATIONPROBLEMINSUCHAWAYTHATIT
ISNOTSEARCHINGOVERALLPOSSIBLEPOSTERIORDISTRIBUTIONS.
!SSUMEWEHAVEAVAILABLEAFAMILYOFDISTRIBUTIONS Q(DISCUSSEDFURTHERINTHENExTSECTION),ANDWECANCHOOSEONE
DISTRIBUTIONq ∈Q TOAPPROxIMATE p(s|o).4HISLEADSTOTHEFOLLOWING“VARIATIONAL”OPTIMIzATIONPROBLEM:
q∗(s)=ARGMIN
q(s)
D[q(s)||p(s|o)]. (7)
4HEK,DIVERGENCEIS0WHEN q(s)= p(s|o).4HUS,IFp(s|o)ISCONTAINEDINTHEVARIATIONALFAMILY Q,THENTHESOLUTION
OFTHEOPTIMIzATIONPROBLEMYIELDSTHEExACTPOSTERIOR: q∗(s)=p(s|o).4HISHOLDSTRUEWHENTHEVARIATIONALFAMILYIS
UNRESTRICTED(I.E.,CONTAINSALLPOSSIBLEDISTRIBUTIONSWITHSUPPORTONTHEHYPOTHESISSPACE).
!LGORITHMICALLY,THISOPTIMIzATIONPROBLEMISNOTVERYPRACTICALBECAUSETOCOMPUTETHEK,DIVERGENCEWENEED
ACCESSTOq(s)—PRECISELYTHEPROBLEMWEARETRYINGTOSOLVE!(OWEVER,ITTURNSOUTTHATONECANREFORMULATETHISPROBLEM
INAWAYTHATISMOREPRACTICAL,BASEDONTHEFOLLOWINGIDENTITY:
LOGp(o)= D[q(s)||p(s|o)]−F[ q(s)], (8)
WHEREF[q(s)]ISTHEvariationaL free energy:
F[q(s)]=
Õ
s
q(s)LOG q(s)
p(o, s). (9)
4HEFREEENERGYISEqUIVALENTTOTHENEGATIVEOFTHE evidence Lower bound,THEMORECOMMONTERMINTHEMACHINELEARNING
LITERATURE;18=.
.OTETHATTHEFREEENERGYONLYREqUIRESKNOWLEDGEOF p(s|o)UPTOANORMALIzINGCONSTANT,SINCE p(s|o)∝ p(o|s)p(s).
4HISISTYPICALLYUNPROBLEMATIC,SINCEWECANOFTENCOMPUTETHEPRIOR p(s)ANDLIKELIHOODp(o|s)OFANYPARTICULARSTATE s.
CRITICALLY,THEIDENTITYABOVEIMPLIESTHATMINIMIzINGTHEFREEENERGYISEqUIVALENTTOMINIMIzINGK,DIVERGENCE,SINCETHE
TWOMUSTBALANCEEACHOTHEROUTTOMATCHTHEMARGINALLIKELIHOOD,WHICHIS ﬁxEDASAFUNCTIONOF q.4HUS,MINIMIzING
FREEENERGYWHENTHEVARIATIONALFAMILYISUNRESTRICTEDISEqUIVALENTTOExACTBAYESIANINFERENCE.
)F&E0=BAYES,THENWECANNOTDISTINGUISHITSPREDICTIONSFROMOTHERASYMPTOTICALLYCORRECTINFERENCEALGORITHMS,
3!-5E, J.GE23(-!. 5
SUCHAS-ONTECARLOSAMPLING,ExCEPTWHENTHESEALGORITHMSARERESTRICTEDINSOMEWAY.-ONTECARLOMETHODSMAY,FOR
ExAMPLE,BERESTRICTEDINTERMSOFTHENUMBEROFSAMPLESTHEYGENERATEORHOWTHEYGENERATETHESAMPLES(E.G.,; 19=).
OPTIMIzATIONOFFREEENERGYISTYPICALLYRESTRICTEDBYPLACINGCONSTRAINTSONTHEVARIATIONALFAMILY,ASWEDISCUSSNExT.
4 | 2E342IC4I.G4HE6A2IA4IO.ALFAMILY
)FTHEHYPOTHESISSPACEISVAST,THENSUMMING(ORINTEGRATING)OVERALLPOSSIBLEHYPOTHESESTOCOMPUTETHEFREEENERGY
WILLBEINTRACTABLE.4HUS,ESSENTIALLYALLPRACTICALAPPLICATIONSOFFREEENERGYOPTIMIzATIONMAKEUSEOFARESTRICTIONON Q
THATRENDERSTHEOPTIMIzATIONTRACTABLE(ASWILLBEDISCUSSEDBELOW).4HEIMPORTANTPOINTFORPRESENTPURPOSESISTHAT
ASLONGASTHETRUEPOSTERIORISIN Q,THEOPTIMALq∗WILLBEEqUALTOTHEPOSTERIOR.4HUS,&E0INITSMOSTGENERALFORMIS
INDISTINGUISHABLEFROMBAYESIANINFERENCE.
0RACTICALAPPLICATIONSOFFREEENERGYOPTIMIzATIONRESTRICT QINSOMEWAYTOMAKETHEPROBLEMTRACTABLE.4HESE
RESTRICTIONSTYPICALLYMEANTHATTHEPOSTERIORISNOLONGERCONTAINEDIN Q,ANDTHUSTHEDISTRIBUTIONTHATMINIMIzESFREE
ENERGYWILLDEVIATEFROMBAYES-OPTIMALITY:q∗(s), p(s|o).
4HEWIDELYUSED“MEAN-ﬁELD”APPROxIMATIONASSUMESTHATTHEPOSTERIORFACTORIzESACROSSCOMPONENTSOF s(I.E.,
DIMENSIONSOFTHESTATESPACE):
q(s)=
Ö
i
qi(si). (10)
&ORExAMPLE,IF)’MTRYINGTOINFERTHEPOSTERIOROVERTHEHEIGHTANDWEIGHTOFANINDIVIDUALGIVENTHEIRGENDER,)COULD
ASSUMETHATTHEPOSTERIORFACTORIzESINTO q(HEIGHT|GENDER)ANDq(WEIGHT|GENDER).BECAUSETHETRUEPOSTERIORRARELY
FACTORIzES,THEMEAN-ﬁELDAPPROxIMATIONWILLPRODUCESYSTEMATICERRORS.&ORExAMPLE,IFTHEFACTORIzATIONISACROSSA
SEqUENCEOFSTATES,THEPOSTERIORMAYBEBIASEDBYTHEORDEROFTHEDATA.)NTRIGUINGLY,THESEERRORSCANBEDISCERNEDIN
HUMANBEHAVIOR;20,21=.ONTHEOTHERHAND,THEMEAN-ﬁELDAPPROxIMATIONMAYWORKWELLINMANYCASES,WHICHISWHYIT
ISWIDELYADOPTEDINMACHINELEARNING.4HISEFFECTIVENESSCANRENDERITDIF ﬁCULTTOTESTASAPROCESSMODEL,BECAUSEIT
OFTENMAKESSIMILARPREDICTIONSTOExACTBAYESIANINFERENCE.
7HENsISCONTINUOUS,ANOTHERCOMMONRESTRICTIONISTOASSUMETHATTHEPOSTERIORISGAUSSIAN; 22=,PARAMETRIzED
BYAMEAN µANDCOVARIANCEMATRIx Σ:
q(s)= N(s;µ, Σ). (11)
4HESEPARAMETERSARETHENCHOSENTOMINIMIzETHEFREEENERGY,TYPICALLYBYGRADIENTDESCENT.4HEGAUSSIANAPPROxIMA-
TIONCANBEMOTIVATEDBYTHE“BAYESIANCENTRALLIMITTHEOREM,”WHICHSTATESTHATTHEPOSTERIORISAPPROxIMATELYGAUSSIAN
AROUNDTHEMODEWHENTHEAMOUNTOFDATAISLARGERELATIVETOTHEDIMENSIONALITYOF s.)TCANALSOBEGENERALIzEDTO
MIxTURESOFGAUSSIANSTOAPPROxIMATEMULTIMODALPOSTERIORS;23=.
ONECHALLENGEFACINGAPPLICATIONSOFTHEGAUSSIANAPPROxIMATIONISTHATTHEFREEENERGYISNOT,INGENERAL,TRACTABLE
(ExCEPTINTHECASEWHERETHEExACTPOSTERIORISGAUSSIAN). 4ODEALWITHTHISISSUE,ACOMMONTECHNIqUE,KNOWNAS
THELapLace approximation,ISTOUSEASECOND-ORDER4AYLORSERIESExPANSIONAROUNDTHEPOSTERIORMODE.4HISREPLACES
THENONLINEARFREEENERGYWITHAqUADRATICFUNCTION,RENDERINGTHEFREEENERGYTRACTABLE.4HEPRICEWEPAYFORTHIS
APPROxIMATIONISTHATWEARENOLONGEROPTIMIzINGTHEFREEENERGY,ANDWEHAVENOGUARANTEETHATTHISWILLPRODUCE
SENSIBLEANSWERS,OREVENCONVERGE.)TTURNSOUT,HOWEVER,THATTHE,APLACEAPPROxIMATIONHASINTRIGUINGIMPLICATIONSFOR
THENEUROBIOLOGICALIMPLEMENTATIONOFBAYESIANINFERENCE.
6 3!-5E, J.GE23(-!.
5 | P2EDIC4I6ECODI.G
4HE,APLACEAPPROxIMATIONCANBEUSEDTODERIVEARGUABLYTHEMOSTIN ﬂUENTIALANDDISTINCTIVEASPECTOF&E0— predictive
coding,ACCORDINGTOWHICHFEEDBACKPATHWAYSCONVEYPREDICTIONS,ANDFEEDFORWARDPATHWAYSINTHEBRAINCONVEY
PREDICTIONERRORS(DISCREPANCIESBETWEENDATAANDPREDICTIONS).4HEIDEAOFPREDICTIVECODINGHASALONGHISTORYIN
SIGNALPROCESSING;24=,ANDWASPREVIOUSLYPROPOSEDASATHEORYOFREDUNDANCYREDUCTION(EF ﬁCIENTCODING)INNEURAL
SIGNALS;25=.&RISTONANDCOLLEAGUESSHOWEDHOWPREDICTIVECODINGCOULDBEDERIVEDWITHINTHEFRAMEWORKOFFREEENERGY
MINIMIzATION;22,26,27=,HOWITCOULDBEMAPPEDONTOTHESTRUCTUREOFBIOLOGICALLYREALISTICMICROCIRCUITS; 28=,ANDHOW
ITCOULDBEAPPLIEDTOMOTORCONTROL;29=ANDACTIONSELECTIONMOREGENERALLY(ATOPICWEVISITINTHENExTSECTION).
&RISTONANDCOLLEAGUESSTARTEDFROMTHEFOLLOWINGASSUMPTIONS:
• 4HEINTERNAL(GENERATIVE)MODELISHIERARCHICALLYSTRUCTURED,SUCHTHATHIDDENSTATESATHIGHERLEVELSGENERATEHIDDEN
STATESATLOWERLEVELS.
• 4HEAPPROxIMATEPOSTERIORFACTORIzESACROSSHIDDENSTATEDIMENSIONSWITHINANDBETWEENLEVELSOFTHEINTERNAL
MODEL(I.E.,THEMEAN-ﬁELDAPPROxIMATION).
• EACHCOMPONENTOFTHEFACTORIzEDPOSTERIORISMODELEDASAGAUSSIAN.
4HEYTHENUSEDTHE,APLACEAPPROxIMATIONTOAPPROxIMATETHEFREEENERGYANDDERIVEUPDATERULESFOROPTIMIzATION
BASEDONGRADIENTDESCENT.4HEYSHOWEDTHATTHISOPTIMIzATIONSCHEMECORRESPONDSTOAFORMOFPREDICTIVECODING,
WHICHISFOUNDUBIqUITOUSLYINTHEENGINEERINGLITERATURE(E.G.,KALMAN ﬁLTERING).
)TISIMPORTANTTOEMPHASIzETHATPREDICTIVECODINGIS notAGENERICCONSEqUENCEOF&E0,OREVENOF&E0WITHA
SPECIﬁCAPPROxIMATIONFAMILY.)TISDERIVEDFROMACOMBINATIONOFASSUMPTIONSABOUTTHEINTERNALMODEL(HIERARCHICAL
ORGANIzATION),THEAPPROxIMATIONFAMILY(FACTORIzEDANDGAUSSIAN),THEAPPROxIMATIONOFTHEFREEENERGY(qUADRATIC
AROUNDTHEMODE),ANDTHEOPTIMIzATIONSCHEME(GRADIENTDESCENT). 7ITHALLOFTHESEASSUMPTIONSINPLACE,&E0
DOESMAKECLAIMSTHATGOBEYONDTHEGENERALBAYESIANBRAINHYPOTHESIS,ANDHAVERECEIVEDAMPLEEMPIRICALSUPPORT
;30,31,32,33,34=.!LTERNATIVELY,SOMEAUTHORSHAVEExPLOREDVARIANTSOF&E0THATDONOTINVOKEPREDICTIVECODING,OR
COMBINEITWITHOTHERNEURALMESSAGEPASSINGSCHEMES(E.G.,;35=).
6 | AC4I6EI.FE2E.CE
,ETUSRETURNNOWTOTHESETTINGINWHICHANAGENTCANTAKEACTIONS(ACCORDINGTOPOLICY π)TOINﬂUENCEITSOBSERVATIONS.
)NTHISSETTING,&E0POSITSTHATTHEAGENTSEEKSTOMINIMIzE expectedFREEENERGYUNDERFUTUREOBSERVATIONS oANDFUTURE
STATEs;36=:
Õ
o
p(o|s, π)
Õ
s
q(s|π)LOG q(s|π)
p(o, s|π)=−
Õ
o
q(o|π)D[q(s|o, π)||q(s|π)]−
Õ
o
q(o|π)LOGp(o|π), (12)
WHEREq(s|π)ISTHEAPPROxIMATEBELIEFABOUTFUTURESTATE sPRIORTOOBSERVING o.&RISTONANDCOLLEAGUESREFERTOTHE
MINIMIzATIONOFExPECTEDFREEENERGYWITHRESPECTTOACTIONSAS active inference. .OTETHATHERETHELIKELIHOODIS
STIPULATEDTOBE p(o|s, π)=q(o|s, π),ANDWEHAVEASSUMEDTHATTHEPREDICTIVEPOSTERIOR q(s|o, π)≈ p(s|o, π).
7HENTHEAPPROxIMATEPOSTERIORISExACT,THE ﬁRSTTERMINTHEExPRESSIONISTHENEGATIVEINFORMATIONGAINANDTHE
3!-5E, J.GE23(-!. 7
SECONDTERMISTHEENTROPY H[p(o|π)]OFTHEFUTUREOBSERVATIONSCONDITIONALONTHEPOLICY:
Õ
o
p(o|s, π)
Õ
s
p(s|π)LOG p(s|π)
p(o, s|π)=−I(π)+H[p(o|π)]. (13)
)FINADDITIONOBSERVATIONSAREDETERMINISTICFUNCTIONSOFTHEPOLICY,THENTHEENTROPYTERMIS0,ANDMINIMIzINGExPECTED
FREEENERGYISEqUIVALENTTOMAxIMIzINGINFORMATIONGAIN.4HUS,UNDERCERTAINCONDITIONSACTIVEINFERENCEISEqUIVALENT
TOTHEINFORMATIONGAINPOLICYSTUDIEDINSTANDARDBAYESIANTREATMENTSOFINFORMATIONACqUISITION; 10=. 7HENTHE
OBSERVATIONSARESTOCHASTICANDCANBEINTERPRETEDASREWARDOUTCOMES(SEENExTSECTION),ACTIVEINFERENCEINSTANTIATESA
FORMOFRISK-SENSITIVECONTROL,SINCEACTIONSTHATREDUCEOUTCOMEVARIABILITYWILLBEFAVORED(SEE; 36=FORMOREDISCUSSION).
!NOTHERWAYOFTHINKINGABOUTTHEENTROPYTERMISTHATITRE ﬂECTSTHE“CODINGCOST”OFUNPREDICTABLEDATA,SINCEENTROPY
ISALOWERBOUNDONTHEAVERAGENUMBEROFBITSNEEDEDTOCOMMUNICATEOBSERVATIONSVIAASENSORYCHANNELWITHOUTLOSS
OFINFORMATION;37=.4HUS,ACTIVEINFERENCEPREFERSACTIONSTHATPRODUCEOBSERVATIONSWHICHAREBOTHINFORMATIVEAND
PREDICTABLE.
!SINTHEPREVIOUSSECTIONS,WECANASKWHICHASPECTSOFTHISANALYSISAREGENERICIMPLICATIONSOFTHEBAYESIAN
BRAINHYPOTHESIS(WITHANINFORMATIONGAINPOLICY),ANDWHICHARESPECI ﬁCTO&E0.7ESHOWEDTHAT&E0ISEqUIVALENTTO
BAYESIANINFORMATIONGAINONLYUNDERTHESPECIALCASEOFANExACTPOSTERIORANDDETERMINISTICOUTCOMESINTHEFUTURE.
7HENTHEDETERMINISMCONSTRAINTISRELAxED,INFORMATIONGAINANDExPECTEDFREEENERGYWILLBESUBSTANTIVELYDIFFERENT.
7 | PLA..I.GA3I.FE2E.CE
!NUMBEROFPAPERSONACTIVEINFERENCEMAKEANADDITIONALCONCEPTUALMOVE(E.G.,; 38,39,36=),REINTERPRETINGTHE
ENTROPYTERMASAFORMOF extrinsic vaLue,CONTRASTINGITWITHTHE epistemic vaLueOFTHEINFORMATIONGAINTERM.CENTRALTO
THISREINTERPRETATIONISTHEPOSTULATETHATTHEUTILITYOFANOUTCOMEISEqUALTOITSLOGPRIORPROBABILITY, u(o)=LOGp(o|π),
USUALLYREFERREDTOASITS prior preference.(.OTETHATWEARECONDITIONINGONTHEPOLICYHERETOEMPHASIzETHATTHEFREE
ENERGYISBEINGCOMPUTEDFORA ﬁxEDPOLICY.)4HISLEADSTOAFORMOF pLanning as inference;40,41=,WHEREBYMINIMIzING
FREEENERGYOPTIMIzESACOMBINATIONOFExPECTEDUTILITY(ExTRINSICVALUE)ANDINFORMATIONGAIN(EPISTEMICVALUE).
!TﬁRSTGLANCE,THISSEEMSRATHERODD;WHYSHOULDUTILITYBEPROPORTIONALTOPROBABILITY?5NDOUBTEDLYTHEREAREHIGH
PROBABILITYEVENTSTHATHAVELOWUTILITY(E.G.,IFYOUAREBORNINTOPOVERTYTHENLACKINGACCESSTOBASICGOODSMAYBEHIGHLY
PROBABLE).(OWEVER,NOTETHATTHISISPOTENTIALLYJUSTBAYESIANDECISIONTHEORYINDISGUISE:ASLONGAS)’MALLOWEDTO
CHOOSEPROBABILITIESTHATAREPROPORTIONALTOUTILITIES,&E0WILLCOINCIDEWITHBAYESIANDECISIONTHEORY.4HECRITICALSTEP
INTHISLOGICISTHEASSUMPTIONTHATEVOLUTIONHASEqUIPPEDUSWITHTHEBELIEFTHATLOWUTILITYSTATESARELOWPROBABILITY,
DUETOTHEFACTTHATIFOURANCESTORSSPENTALOTOFTIMEINTHOSESTATESTHEYWOULDBELESSLIKELYTOREPRODUCE.7HETHEROR
NOTTHISISAREASONABLEASSUMPTION,THETECHNICALPOINTISTHATPLANNINGASINFERENCECANBEUNDERSTOODASANOTATIONAL
VARIANTOFBAYESIANDECISIONTHEORY,PROVIDEDTHEUTILITIESANDPROBABILITIESCOINCIDE(FREEENERGYTHEORISTSTYPICALLY
STIPULATETHATTHEYCOINCIDE).&E0CANMAKEDISTINCTIVEPREDICTIONSWHENTHEYDON’TCOINCIDE,ORWHENTHEPLANNING
ASINFERENCETRANSFORMATIONLEADSTODIFFERENTALGORITHMICAPPROxIMATIONSORNEURALIMPLEMENTATIONS,PROVIDEDTHE
UTILITIESANDPRIORPREFERENCESCOINCIDE(I.E.,EFFECTIVELY,REPLACINGUTILITYWITHPRIORPREFERENCES).
8 | CO.CL53IO.3
4HEREARESEVERALTAKE-HOMEMESSAGESFROMTHISARTICLE:
8 3!-5E, J.GE23(-!.
• &ORPASSIVEOBSERVATIONS(NOACTIONS),THEPREDICTIONSOF&E0AREINDISTINGUISHABLEFROMTHEPREDICTIONSOFTHE
BAYESIANBRAINHYPOTHESISWHENTHEVARIATIONALFAMILYISUNRESTRICTED(I.E.,THEWHENTHEExACTPOSTERIORISINTHE
VARIATIONALFAMILY,ANDHENCEMINIMIzINGFREEENERGYISEqUIVALENTTOExACTINFERENCE).
• 0REDICTIVECODINGISNOTAGENERICCONSEqUENCEOF&E0;ITARISESONLYUNDERCERTAINRESTRICTIONSOFTHEVARIATIONAL
FAMILYANDASPECI ﬁCCHOICEOFOPTIMIzATIONSCHEME.
• )NTHEACTIVESETTING(OBSERVATIONSCANBEIN ﬂUENCEDBYACTIONS),ACTIVEINFERENCEISEqUIVALENTTOANINFORMATION
GAINPOLICYWHENTHEAPPROxIMATEPOSTERIORISExACTANDTHEOBSERVATIONSAREDETERMINISTICFUNCTIONSOFACTIONS.
7HENOBSERVATIONSARESTOCHASTIC,ACTIVEINFERENCEINDUCESAFORMOFRISK-AVERSIONNOTFOUNDINTHEINFORMATION
GAINPOLICY.
• 7HENUTILITIESAREINTERPRETEDASLOGPROBABILITIES,&E0CORRESPONDSTOAFORMOFPLANNINGASINFERENCE,ACLASS
OFALGORITHMSFORUTILITYMAxIMIzATION.4HEPREDICTIONSOF&E0AREDISTINGUISHEDFROMUTILITYMAxIMIzATIONWHEN
UTILITIESDON’TCORRESPONDTOLOGPROBABILITIES.1
• 7HENUTILITIESAREINTERPRETEDASPRIORPREFERENCES,&E0PLACESVALUEONINFORMATIONGAIN.4HISALSOARISESNATURALLY
INBAYESIANDECISIONTHEORYAPPLIEDTOSEqUENTIALDECISIONPROBLEMSANDHENCEISNOTADISTINCTIVEPREDICTION.
4HESETAKE-HOMEMESSAGESDONOTExHAUSTTHESETOFIDEASTHATHAVEBEENINTRODUCEDUNDERTHEBANNEROF&E0.&OR
ExAMPLE,&E0HASBEENOFFEREDASA ﬁRST-PRINCIPLEACCOUNTOFSELF-ORGANIzATION;43=ANDECOLOGICALNICHECONSTRUCTION
;44=.7EHAVEFOCUSEDHEREONISSUESTHATAREMORECENTRALTONEUROSCIENCE.
4HEBROADERPOINTOFTHISARTICLEISTHATAUNIFYINGTHEORYLIKE&E0NEEDSTOBEDECONSTRUCTEDINORDERTOBEPROPERLY
EVALUATEDANDCOMPAREDTOALTERNATIVETHEORIES.BYUNDERTAKINGPARTOFTHISDECONSTRUCTION,WEHOPETOMAKETHE
ELEGANTSYNTHESISOFFEREDBY&E0MOREACCESSIBLETOTHEBROADERNEUROSCIENCECOMMUNITY.
| ACKNOWLEDGMENTS
)AMGRATEFULTOBEN6INCENT,-OMCHIL4OMOV,CHRIS3UMMER ﬁELD,GIOVANNI0EzzULO,0ETERBATTAGLIA,JANDRUGOWITSCH,
2ANI-ORAN,9UqING(OU,JASCHA!CHTERBERG,2OBERT2OSENBAUM,3ABYA3HIVKUMAR,AND.ATHANIELDAWFORCOMMENTS
ONANEARLIERDRAFTOFTHEPAPER.
2EFE2E.CE3
;1= &RISTONK.4HEFREE-ENERGYPRINCIPLE:AUNIﬁEDBRAINTHEORY?.ATURE2EVIEWS.EUROSCIENCE2010;11:127.
;2= ,EE43,-UMFORDD.(IERARCHICALBAYESIANINFERENCEINTHEVISUALCORTEx.JO3!!2003;20:1434–1448.
;3= KNILLDC,0OUGET!. 4HEBAYESIANBRAIN:THEROLEOFUNCERTAINTYINNEURALCODINGANDCOMPUTATION. 42E.D3IN.EURO-
SCIENCES2004;27:712–719.
;4= DOYAK,)SHII3,0OUGET!,2AO20.BAYESIANBRAIN:0ROBABILISTIC!PPROACHESTO.EURALCODING.-)40RESS;2007.
;5= GIRSHICK!2,,ANDY-3,3IMONCELLIE0.CARDINALRULES:VISUALORIENTATIONPERCEPTIONRE ﬂECTSKNOWLEDGEOFENVIRONMENTAL
STATISTICS..ATURE.EUROSCIENCE2011;14:926.
;6= )TTI,,BALDI0.BAYESIANSURPRISEATTRACTSHUMANATTENTION.6ISION2ESEARCH2009;49:1295–1306.
;7= COVER4-,4HOMASJ!.ELEMENTSOF)NFORMATION4HEORY.JOHN7ILEY&3ONS;1991.
14ECHNICALLY,UTILITIESCANALWAYSBEFORMULATEDASLOGPROBABILITIES. BUTITISANEMPIRICALqUESTIONWHETHERSUBJECTIVEBELIEFSANDPREFERENCESDISCLOSEDBY
BEHAVIORCOINCIDE;42=.
3!-5E, J.GE23(-!. 9
;8= ,INDLEYD6. ONAMEASUREOFTHEINFORMATIONPROVIDEDBYANExPERIMENT. 4HE!NNALSOF-ATHEMATICAL3TATISTICS
1956;27:986–1005.
;9= OAKSFORD-,CHATER.. !RATIONALANALYSISOFTHESELECTIONTASKASOPTIMALDATASELECTION. 0SYCHOLOGICAL2EVIEW
1994;101:608–631.
;10= .ELSONJD.&INDINGUSEFULqUESTIONS:ONBAYESIANDIAGNOSTICITY,PROBABILITY,IMPACT,ANDINFORMATIONGAIN.0SYCHOLOGICAL
2EVIEW2005;112:979–999.
;11= 4SIVIDIS0,GERSHMAN3,4ENENBAUMJ,3CHULz,.)NFORMATIONSELECTIONINNOISYENVIRONMENTSWITHLARGEACTIONSPACES.)N:
0ROCEEDINGSOFTHE!NNUAL-EETINGOFTHECOGNITIVE3CIENCE3OCIETY,VOL.36;2014..
;12= 3ETTLESB.!CTIVELEARNING.3YNTHESIS,ECTURESON!RTIﬁCIAL)NTELLIGENCEAND-ACHINE,EARNING2012;6:1–114.
;13= DAYAN0,DAW.D. DECISIONTHEORY,REINFORCEMENTLEARNING,ANDTHEBRAIN. COGNITIVE,!FFECTIVE,&BEHAVIORAL.EURO-
SCIENCE2008;8:429–453.
;14= 3OLTANI!,KHORSAND0,GUOC,&ARASHAHI3,,IUJ. .EURALSUBSTRATESOFCOGNITIVEBIASESDURINGPROBABILISTICINFERENCE.
.ATURECOMMUNICATIONS2016;7:11393.
;15= 2AHNEVD,DENISON2..3UBOPTIMALITYIN0ERCEPTUALDECISION-AKING.BEHAVIORALANDBRAIN3CIENCES2018;P.1–107.
;16= GERSHMAN3J,(ORVITzEJ,4ENENBAUMJB. COMPUTATIONALRATIONALITY:!CONVERGINGPARADIGMFORINTELLIGENCEINBRAINS,
MINDS,ANDMACHINES.3CIENCE2015;349:273–278.
;17= BOGACz2. !TUTORIALONTHEFREE-ENERGYFRAMEWORKFORMODELLINGPERCEPTIONANDLEARNING. JOURNALOF-ATHEMATICAL
0SYCHOLOGY2017;76:198–211.
;18= BLEID-,KUCUKELBIR!,-C!ULIFFEJD.6ARIATIONALINFERENCE:!REVIEWFORSTATISTICIANS.JOURNALOFTHE!MERICAN3TATISTICAL
!SSOCIATION2017;112:859–877.
;19= DASGUPTA),3CHULzE,GERSHMAN3J.7HEREDOHYPOTHESESCOMEFROM?COGNITIVE0SYCHOLOGY2017;96:1–25.
;20= DAW.D,COURVILLE!C,DAYAN0.3EMI-RATIONALMODELSOFCONDITIONING:4HECASEOFTRIALORDER2008;P.431–452.
;21= 3ANBORN!.,3ILVA2.CONSTRAININGBRIDGESBETWEENLEVELSOFANALYSIS:!COMPUTATIONALJUSTI ﬁCATIONFORLOCALLYBAYESIAN
LEARNING.JOURNALOF-ATHEMATICAL0SYCHOLOGY2013;57:94–106.
;22= &RISTONK,-ATTOUTJ,4RUJILLO-BARRETO.,!SHBURNERJ,0ENNY7. 6ARIATIONALFREEENERGYANDTHE,APLACEAPPROxIMATION.
.EUROIMAGE2007;34:220–234.
;23= GERSHMAN3J,(OFFMAN-D,BLEID-. .ONPARAMETRICVARIATIONALINFERENCE. )N:0ROCEEDINGSOFTHE29TH)NTERNATIONAL
CONFERENCEON)NTERNATIONALCONFERENCEON-ACHINE,EARNINGOMNIPRESS;2012.P.235–242.
;24= ELIAS0.0REDICTIVECODING–).)2E4RANSACTIONSON)NFORMATION4HEORY1955;1:16–24.
;25= 2AO20,BALLARDD(.0REDICTIVECODINGINTHEVISUALCORTEx:AFUNCTIONALINTERPRETATIONOFSOMEExTRA-CLASSICALRECEPTIVE-
ﬁELDEFFECTS..ATURE.EUROSCIENCE1999;2:79.
;26= &RISTONK.(IERARCHICALMODELSINTHEBRAIN.0,O3COMPUTATIONALBIOLOGY2008;4:E1000211.
;27= &RISTONK,KIEBEL3.0REDICTIVECODINGUNDERTHEFREE-ENERGYPRINCIPLE.0HILOSOPHICAL4RANSACTIONSOFTHE2OYAL3OCIETYOF
,ONDONB:BIOLOGICAL3CIENCES2009;364:1211–1221.
;28= BASTOS!-,5SREY7-,!DAMS2!,-ANGUNG2,&RIES0,&RISTONKJ.CANONICALMICROCIRCUITSFORPREDICTIVECODING..EURON
2012;76:695–711.
10 3!-5E, J.GE23(-!.
;29= &RISTONK.7HATISOPTIMALABOUTMOTORCONTROL?.EURON2011;72:488–498.
;30= !ITCHISON,,,ENGYEL-.7ITHORWITHOUTYOU:PREDICTIVECODINGANDBAYESIANINFERENCEINTHEBRAIN.CURRENTOPINIONIN
.EUROBIOLOGY2017;46:219–227.
;31= -URRAY3O,KERSTEND,OLSHAUSENB!,3CHRATER0,7OODSD,.3HAPEPERCEPTIONREDUCESACTIVITYINHUMANPRIMARYVISUAL
CORTEx.0ROCEEDINGSOFTHE.ATIONAL!CADEMYOF3CIENCES2002;99:15164–15169.
;32= 3UMMERﬁELDC,4RITTSCHUHE(,-ONTIJ-,-ESULAM--,EGNER4..EURALREPETITIONSUPPRESSIONRE ﬂECTSFULﬁLLEDPERCEP-
TUALExPECTATIONS..ATURE.EUROSCIENCE2008;11:1004.
;33= EGNER4,-ONTIJ-,3UMMERﬁELDC.ExPECTATIONANDSURPRISEDETERMINENEURALPOPULATIONRESPONSESINTHEVENTRALVISUAL
STREAM.JOURNALOF.EUROSCIENCE2010;30:16601–16608.
;34= KOK0,DE,ANGE&0. 0REDICTIVECODINGINSENSORYCORTEx. )N:!N)NTRODUCTIONTO-ODEL-BASEDCOGNITIVE.EUROSCIENCE
3PRINGER;2015.P.221–244.
;35= &RISTONKJ,0ARR4,DE6RIESB. 4HEGRAPHICALBRAIN: BELIEFPROPAGATIONANDACTIVEINFERENCE. .ETWORK.EUROSCIENCE
2017;1:381–414.
;36= &RISTONK,2IGOLI&,OGNIBENED,-ATHYSC,&ITzGERALD4,0EzzULOG. !CTIVEINFERENCEANDEPISTEMICVALUE. COGNITIVE
.EUROSCIENCE2015;6:187–214.
;37= 3HANNONCE.!MATHEMATICALTHEORYOFCOMMUNICATION.BELL3YSTEM4ECHNICALJOURNAL1948;27:379–423.
;38= &RISTONKJ,DAUNIzEAUJ,KIEBEL3J.2EINFORCEMENTLEARNINGORACTIVEINFERENCE?0LO3ONE2009;4:E6421.
;39= &RISTONK,3AMOTHRAKIS3,-ONTAGUE2. !CTIVEINFERENCEANDAGENCY:OPTIMALCONTROLWITHOUTCOSTFUNCTIONS. BIOLOGICAL
CYBERNETICS2012;106:523–541.
;40= BOTVINICK-,4OUSSAINT-.0LANNINGASINFERENCE.4RENDSINCOGNITIVE3CIENCES2012;16:485–488.
;41= KAPPEN (J, GóMEz 6, OPPER -. OPTIMAL CONTROL AS A GRAPHICAL MODEL INFERENCE PROBLEM. -ACHINE ,EARNING
2012;87:159–182.
;42= GERSHMAN3J,DAW.D,-2ABINOVICH06K&RISTON,EDITOR,0ERCEPTION,ACTIONANDUTILITY:4HETANGLEDSKEIN. -)40RESS;
2012.
;43= &RISTONK.,IFEASWEKNOWIT.JOURNALOFTHE2OYAL3OCIETY)NTERFACE2013;10:20130475.
;44= CONSTANT!,2AMSTEAD-J,6EISSIERE30,CAMPBELLJO,&RISTONKJ.!VARIATIONALAPPROACHTONICHECONSTRUCTION.JOURNAL
OF4HE2OYAL3OCIETY)NTERFACE2018;15:20170685.