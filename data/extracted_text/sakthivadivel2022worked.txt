arXiv:2206.12996v2  [physics.class-ph]  6 Sep 2022
A WORKED EXAMPLE OF THE BAYESIAN MECHANICS OF
CLASSICAL OBJECTS
Dalton A R Sakthivadivel
darsakthi.github.io
VERSES Research Lab, Los Angeles, CA, 90016, USA
Department of Mathematics, Stony Brook University, Stony B rook, NY, USA
Department of Physics and Astronomy, Stony Brook Universit y, Stony Brook, NY, USA
(Dated: 7th September 2022)
Bayesian mechanics is a new approach to studying the mathematics a nd physics of inter-
acting stochastic processes. Here, we provide a worked example o f a physical mechanics for
classical objects, which derives from a simple application thereof. W e summarise the current
state of the art of Bayesian mechanics in doing so. We also give a sket ch of its connections
to classical chaos, owing to a particular N = 2 supersymmetry.
CONTENTS
I. Introduction 2
II. Mechanics 4
A. Classical physics in one dimension 4
B. The basics of Bayesian mechanics 4
C. A physics of beliefs 8
D. A physics by beliefs 10
III. A general equation for Bayesian classical mechanics 14
IV. A question of quantum ontology 18
V. The matching of modes 21
VI. The tracking of modes 22
A. Terminal mode-matching 22
B. Inﬁnite mode-tracking 24
VII. Path-tracking, and a simple case of G-theory 26
2
A. Path-tracking 26
B. A ﬁrst idea of G-theory 29
References 31
I. INTRODUCTION
Under the free energy principle [Fri19], Bayesian mechanic s is a new approach to studying
the mathematics and physics of interacting stochastic proc esses. In essence, Bayesian mechanics
is a particular sort of mathematical physics for coupled ran dom dynamical systems, providing
a mechanical theory for how the statistical properties of ph ysical systems change in a space of
Bayesian beliefs, based on how their physical properties ch ange in space and time [Fri12, PDCF20,
RSH+22]. Bayesian mechanics is particularly interested in syst ems with some notion of regularity,
termed ‘self-evidencing’ systems in previous literature. 1 A self-evidencing system occupies an
attractor in the state space, and has some set of stereotypic al behaviours deﬁnitional of the sort
of system it is. The key deliverable of Bayesian mechanics is that a random dynamical system is
an estimator for statistics or parameters of another system to which it is coupled, making it an
inference machine, and that we can understand attractors an d phases in state space in virtue of
these belief dynamics.
Prosaically, the point of learning and representation in ‘g enuine’ inference agents, such as bio-
logical and artiﬁcial neural networks, is to mirror the envi ronment within the agent’s own struc-
ture—its tissue or weight conﬁgurations. 2 In this sense, however, encoding data from the envir-
onment in an agential structure is simply a coupling between agent and environment. Indeed, the
foregoing statement is simply a statement that a coupled ran dom dynamical system is the preim-
age of some function into its environment, σ, instantiating some representation of its environment
within its own structure. This is the ‘self’ of the agent refe rred to as a coupled random dynamical
system. Bayesian mechanics is thus a new set of techniques fo r understanding the relationship
between statistical quantities and the physical dynamics e ncoding those quantities, or reﬂected by
those quantities, in coupled random dynamical systems, wit h application to new areas of statistical
mechanics like stochastic thermodynamics [Fri19, PDCF20] .
1 This term of art originates in neuroscience [Hoh16], where t he free energy principle has its origins, as an attempt
to explain the physics and philosophy of learning in the huma n cortex—viewed as a Bayesian mechanical problem,
a brain learning about an environment is one random dynamica l system performing inference about another, with
an aim towards the attractor states characteristic of allos tasis [Wie48]. Note also that this paper uses ‘system’
diﬀerently to [Fri19], which says ‘particle’ where we say sy stem and ‘system’ where we say agent-environment loop.
2 This remark has been paraphrased from Maxwell J D Ramstead.
3
Albeit conceptually powerful, the use of the free energy pri nciple (FEP) and Bayesian mechanics
to describe speciﬁc physical systems is rarely codiﬁed in th e literature. There are examples where
it reproduces known algorithms like various types of contro l [MTSB20, DCFHP21, STvdM +22]),
as well as simple dissipative systems [AMTB22] and more comp lex systems exhibiting Lorentzian
chaos [FHU +21], but recent work has treated it as a purely formal positio n that systems constrain
themselves to fall within acceptable regimes of certain exi stential variables, thus inducing such
attractor structures in the state space.
More speciﬁcally, in [Sak22c, RSH +22], Bayesian mechanics is introduced as the mechanics of
beliefs—but it is challenging to determine the physical mec hanics of systems carrying those beliefs.
This would require solving diﬃcult PDEs for non-equilibriu m steady state densities in general, or
else, equations of motion for internal states on the synchro nous statistical manifold. Likewise, it is
often claimed that the FEP is as simple and general as the prin ciple of stationary action [FCS +22],
and it can be sketched out how the Bayesian mechanics of inter nal states of classical objects might
look [Fri19]. Nevertheless, there has yet to be a systematic investigation of even the Bayesian
mechanics of classical physics, despite it being readily av ailable due to recent formulations as a
least action principle.
Here, inspired by remarks in [RSH +22], we give a worked example of the classical mechanics of
objects with trivial (e.g., inﬁnitely precise) belief dyna mics—in a fairly direct sense, the simplest
case of Bayesian mechanics [Sak22c]. In doing so we provide a general formulation of classical
physics for the working Bayesian mechanic. This paper not on ly surveys recent literature (includ-
ing that of the author) and gives a constructive example of a B ayesian mechanical system, but
ideally, will ground future discussions of the free energy p rinciple even more solidly in conventional
mathematics and physics. Of independent interest, it also s erves as a derivation of classical physics
from the principle of constrained maximum calibre, and reco vers old results on supersymmetry
theory in classical mechanics.
Acknowledgements
The author thanks Lancelot Da Costa, Karl J Friston, Brennan Klein, and Maxwell J D Ram-
stead for valuable conversations. This paper has beneﬁtted from comments by Conor Heins and Igor
V Ovchinnikov, as well members and collaborators of the Mathematically Structured Programming
Group at the University of Strathclyde, especially Matteo Capucc i.
4
II. MECHANICS
A. Classical physics in one dimension
The mechanics of classical objects are embodied by Newton’s law that systems accelerate along
force gradients, by precisely the direction and magnitude o f the total force applied—no more, and
no less. The derivation of this fact is simple. Let K = 1
2 mv2
t , where qt is the position of some
point mass at t and its velocity is the time derivative vt = ˙qt, and V be some scalar potential.
Now deﬁne a path as a particular function 3 q(t) (e.g., a parabolic path could be q(t) = q0 − 1
2 gt2,
whilst a straight path could be q(t) = q0), and introduce the temporary time variable τ. Taking
the action functional
S[q(t)] =
∫ t
0
1
2mv2
τ − V (qτ ) dτ (1)
a path of least action (or more generally, for which the action is stationar y) obeys the equation
−∂qV = m∂tv
by standard arguments in functional analysis. One can refer to [RSH +22, Section 2] and references
therein for an overview; alternatively, see [Cal22] for a mo re advanced pedagogical treatment, and
[GS00, Arn13] for mathematically sophisticated resources . This is Newton’s second law,
F = ma. (2)
Though appearing esoteric, this logical sequence simply ex presses that a path of least action always
follows (2)—that is, a system always accelerates along a for ce gradient, never using extra energy by
resisting or compounding that force. For an appropriate spe ciﬁcation of forces F , we get various
sorts of mechanics, like motion in gravitational ﬁelds or cl assical approximations of ﬂuid ﬂow (also
called continuum mechanics). Given mass data, and initial c onditions ˙q(0) and q(0) (along with
other boundary conditions), we can produce dynamical traje ctories for some particular system by
actually using the law of motion given by Newtonian mechanic s under the least action principle.
B. The basics of Bayesian mechanics
Bayesian mechanics can be seen as an account of the laws of mot ion deriving from the free
energy principle, concerning how Bayesian beliefs—and hen ce, systems with beliefs, such as coupled
3 Imagine realisations of a random process as individual func tions consisting of a drift added to a particular sequence
of noise values; indeed, this is our motivation.
5
random dynamical systems, which perform inference over the things to which they couple—behave
under certain determinants of probabilistic motion. Much like classical mechanics serves an account
of systems that obey Newton’s second law by minimising the cl assical action, Bayesian mechanics
is an account of systems that engage in approximate Bayesian inference by minimising surprisal.
In this and the following section, we will iterate over the ma in constructs of Bayesian mechanics
at a progressively ﬁner scale, unpacking the main insights f rom [Fri19, Sak22c, RSH +22]. The
rest of the paper will contextualise those 250 or so pages wit hin a worked example of physics
in the classical world, furnishing new results along the way , such as the derivation of classical
physics from the principle of constrained maximum entropy, as well as the (re-)introduction of
supersymmetry as an explanation for classical chaos. The pa per will proceed mostly linearly, ﬁrst
discussing the abstract principle that all coupled stochas tic dynamical systems satisfying certain
properties (e.g., the existence of a Markov blanket) follow , then discussing how that principle yields
a law of motion for inferential systems, and then three examp les of dynamics under that law of
motion. (See [RSH +22] for the original schematic of this distinction.)
The pure physics of the FEP arguably dates back to two landmar k papers in the literature,
[Fri19] and [PDCF20]. In [Fri19, PDCF20], and later in [DCFH P21], the idea was introduced
that the FEP has gestured at a new sort of physics—one about th e mechanics of Bayesian beliefs,
and how they reﬂect the behaviour of systems carrying those b eliefs. In [Sak22c, RSH +22] it is
discussed that one can understand this in the same sense as cl assical mechanics arises from the
least action principle, or identically, that diﬀusion arise s from the maximisation of entropy, with
that least action principle being laid out in [FCS +22] (to be formulated in detail in forthcoming
work). Dually, we can understand our own beliefs about a syst em modelling its environment—or
the system’s model of itself—as being ruled by Bayesian mech anics, under the observation and
updating rules which are a consequence thereof. A full decon struction can be found in [RSH +22].
What is central to Bayesian mechanics? Beginning with the mo st recent formulation in
[FCS+22], the FEP is nothing but the least action principle applie d to some surprisal 4 S =
− ln{p(−)}, where the application of this ‘least surprisal principle’ to speciﬁc objects determines
the mechanical theory about those objects. Let a stochastic process X under p(x, t ) with sample
paths γ be described by the It¯ o stochastic diﬀerential equation
dXt = f(Xt, t ) dt +
√
2D dWt . (3)
Here, Xt is a random variable at t and f(Xt, t ) is a vector ﬁeld yielding the drift at any state Xt,
4 The empty argument p(− ) indicates our agnosticism about the input to p; it is important to note that the surprisal
of diﬀerent states constitutes a boundary condition yieldi ng diﬀerent sorts of dynamics [RSH +22, Section 3].
6
which may itself change over time. Since d Wt is a Wiener process, the expected state at some
time t is precisely f(Xt, t ). Immediately we arrive at an important qualiﬁcation: by hy pothesis,
the ensuing discussion applies to cases where ﬂuctuations a re distributed as zero-mean Gaussian
densities with constant variance D. This aligns with an ideal heat bath assumption. 5
Let ω t = vt − f(Xt, t ), where ω t can also be regarded as a label for the heuristic ˙Wt, be a
ﬂuctuation of any realisation of this ﬂow at t. Note that a realisation x(t) = {Xs = xs}s∈ 0:t is
(abusing types slightly) nothing but a sample path γ, and so, we have
˙γt − Ep(γ)[γ]t (4)
for ω t. A quadratic 6 form L(ω t) can naturally be deﬁned on the tangent space to the state spa ce,
such that the surprisal is its integral along a given path γ of L:
S[γ] =
∫ t
0
1
4D ⟨ω τ , ω τ ⟩dτ .
The Lagrangian, the integrand of S[γ], is a function of noise. The surprisal of a path is then
proportional to half its accumulated squared deviation fro m the expected ﬂow f(Xt, t ), normalised
by the scaling constant
√
2D. Morally, this is in the same sense as the classical action is proportional
to half the square of the accumulated deviation of motion fro m a potential well [RSH +22, Section
2]. That this action equals 7 the surprisal of a path γ for a given initial condition, p(x(t) | x0), is a
simple consequence of the path probability measure being de ﬁned as
p(x(t) | x0) = exp {−λS [γ]} (5)
in [Sei12], which is indeed the canonical deﬁnition of such a n object in any abstract Wiener space
[Øks03, ¨Ust06], and is the point of attack in [FCS +22]. Such a ‘path-dependant surprisal’ is referred
to as the stochastic entropy by [Sei12], and is deeply relate d to statistics on the path space of a
random walk (see [DB78], as well as [NS20] and related work on logarithmic heat kernels 8). This
deﬁnition of the action is consistent with the quadratic for m 1
2 ⟨vt, v t⟩ deﬁned in classical mechanics.
The action generates the Fokker-Planck equation for the pro bability of a state x at t,
∂tp(x, t ) = −∂x[f(x, t )p(x, t )] + D∂xxp(x, t ),
5 The same limitation appears in both [Sei12] and [FCS +22], which this work rests on. It is characteristic of most
all of statistical physics, even frameworks valid away from equilibrium.
6 Note that in the Stratonovich convention, more amenable to c alculus on manifolds, there is an additional term
in the Lagrangian L indicated; see e.g. equation 15 here: [CL VW19]. Physically , by ignoring that term, we have
assumed perturbations to the ﬂow have short characteristic timescales and are not ‘remembered’ for long, and
also, that the surprisal ought to be quadratic.
7 Note that the surprisal we go on to describe concerns the prob ability of an entire trajectory given a particular
initial state—an entire path up to t.
8 The author thanks Robert W Neel for suggesting this point of d iscussion.
7
by giving rise to a probability density over coordinate and t ime pairs.
Deﬁne two random dynamical systems η and µ. In virtue of (4), the action of either system—and
thus, ultimately, the surprisal—is parameterised by some m odal or expected path. Suppose that
η and µ are coupled by some function σ, that one has an additional random dynamical system b
capturing the interactions between the two, and that condit ional expectations ˆµb,t = Ep(µ t|bt)[µt]
and ˆηb,t = Ep(ηt|bt)[ηt] exist; moreover, assume the statistics of the two processe s can be distin-
guished, in the sense of being independent conditioned on bt.9 By construction, σ(ˆµb,t ) = ˆηb,t . It
is immediate that µ is an estimator for the statistics of η [Sak22c]. That is to say, in the case of
random systems whose physical dynamics are coupled, these s tatistical quantities are also coupled,
in a way that can be interpreted as the systems performing inf erence over each other. Recall that
the path which minimises (4) is the expected path. Our claim f ollows from the observation that
the least surprising path of µ is the one which tracks the dynamics of η across the synchronisation
function σ, and vice-versa; this means that systems that minimise their own surprisal m ust ‘know’
something about their environment. Systems that minimise s urprisal given a control parameter
σ− 1(ˆηb,t ) are particularly good models of an environment, whilst sys tems that ﬂuctuate with high
probability are not.
Hence, inference over an environment is equivalent in this s ense to occupying unsurprising
states. When we discuss models of ‘things’ or systems, we are interested in states which are
somehow ‘thing-like,’ or systemic, i.e., attractors which deﬁne that thing, which that thing should
not ﬂuctuate too far away from [Sak22c]. More broadly, gener al things which perform estimation
must stay coherent in order to be an estimator (that is to say— we must have a µ to have a σ; see
[RSF22]); that this coherence is a necessary condition for s ynchronisation (read: estimation under
a coupling), and that surprisal-minimisation follows from synchronisation, is simply the statement
that things which exist reﬂect data about their environment s. It is like saying that things which
exist in the universe must obey the laws of physics as fundame ntal laws—when the wind blows and
shakes a tree branch, on one reading, it is because the tree br anch has inertia, but not enough to
resist the force of the wind; on another, it is because the tre e branch reduces its surprisal about the
state of the world by modelling it. 10 It is surprising not to follow these laws—for a tree branch to
spontaneously resist the force of the wind entails a contrad iction, which are usually surprising in
the iron-clad realm of physical law. Either that branch no lo nger exists, in which case it can neither
9 This framework degenerates in the case where σ is the identity, but this case is vacuous, since it assumes η is
identical to µ.
10 The author owes this example to a similar remark stated to him by David I Spivak. For non-agential objects like
the boughs of a tree, this latter view is artiﬁcially teleolo gical—or perhaps even pure metaphor—and is referred
to as ‘as if’ inference. Though analogical in general, it has been argued that this does not constitute a failure of
the model [Sak22c, Section 4.3 and Remark 5.1]; [RSH +22, Section 6.3].
8
move with the wind nor be still, or, it has suddenly become muc h heavier than a tree branch. As a
tautology, things that are surprising are things that ought not happen as we expect, like breaking
the laws of physics. The aim of this paper is, in some sense, to see how insightful this analogy to
forces and motion is.
We can understand this surprisal minimisation as the system holding an inferred model of
the world parameterised by a mode and a variance, the ‘recogn ition density’ r(η; ˆηb, ˆϑη|b), arising
from minimising a free energy functional. Suppose the syste m estimates the moments of the
environment, such that a density r(η | µ) exists where σ(µb) = ηb such that σ(ˆµb) = ˆηb. Now
consider the functional
∫
ln{r(η | µ)}r(η | µ) dη −
∫
ln{p(η, b, µ )}r(η | µ) dη , (6)
the divergence between the variational model and the true jo int density. This expands to
∫
ln{r(η | µ)}r(η | µ) dη −
∫
ln{p(η | b, µ )}r(η | µ) dη − ln{p(b, µ )}. (7)
If r(η | µ) = p(η, b, µ ) then it also decomposes and the entire functional, includi ng the surprisal
of blanket and internal states, evaluates to zero; this is ex act Bayesian inference. If the system
estimates external states by modelling r(η | µ) = p(η | b, µ ) = p(η | b)—which we can show
[Sak22c, Lemmas 4.1 and 4.2; Theorem 4.1] occurs when µ = ˆµb such that (again, abusing types
slightly) σ(µ) = ˆηb—then the divergence in (7) vanishes. In other words, if the s ystem estimates
data about the environment by engaging in mode-matching, th en an upper bound on − ln{p(b, µ )}
is minimised.
The principle of maximum calibre is a generalisation of maxi mum entropy to trajectories
[PGLD13]. Using this technology, we can construct the same m odel over trajectories of a pro-
cess:
∫
ln{r(η(t) | µ(t))}r(η(t) | µ(t)) dη(t) −
∫
ln{p(η(t), b (t), µ (t))}r(η(t) | µ(t)) dη(t) , (8)
which appears exactly as expected. More about maximum calib re, and what has been called
‘path-tracking,’ will be discussed later.
C. A physics of beliefs
The particular idea of inference under synchronisation in S ection II B—which packages together
surprisal minimisation, estimation, and coupling into a mo delling framework—is referred to as
9
approximate Bayesian inference [Sak22c, Theorem 4.1], and in particular, is referred to as ‘mode-
matching’ when these parameters are stationary: by minimis ing surprisal, the most likely state is
σ− 1(ˆηb,t ). The a priori assumption that systems minimise surprising events can be j ustiﬁed using
large deviation principles [Tou09], and as such, most any se t of coupled random dynamical systems
can be expected to perform approximate Bayesian inference o f some sort. What is more striking
is that two distinct (in the above sense) systems which estim ate each other’s statistics necessarily
come equipped with a pair ( bt, σ ), chosen such that they ﬂuctuate around each other’s most li kely
states, and that any two systems with the right input/output ﬂow (such that they ﬂuctuate around
each other’s states) come with ( bt, σ ) such that they estimate each other’s statistics [Sak22c, L emma
4.3].
Bayesian mechanics formulates changes in physical states a s changes in probabilities estimated
by η and µ [PDCF20, RSH +22]. In this sense, Bayesian mechanics is continuous with th e rest
of statistical physics, and is merely a novel (and possibly m ore general) way of modelling how
inference techniques like the principle of maximum entropy play a role in physics. Since we can
understand the average state of µ as the preimage of σ, we can understand it as a parameter for
the probabilities of states of η—in a sense we do this automatically, since we can understand a
system µ existing a particular way in virtue of the likely states η of the things interacting with
it, causing or not causing particular µ—and in so doing, we can relate µ to a belief mechanics
by thinking of µ as encoding inferences about the assignment of probabiliti es to states of η. In
simpler terms, systems exist in a particular way based on the ir environment. When we model a
system, we automatically model it as modelling its environm ent by encoding this sort of statistical
estimation in our model of the system. We expect a thing to exi st as a particular ‘thing’ based
on whether or not it can exist that way in a given environment. This places constrain ts on what
σ− 1(ˆηb,t ) must be for a system to be ‘system-like’ (e.g., stone-like, human-like, and so forth); dually,
it informs what σ(ˆµb,t ) must be, given we have a particular system (e.g., humans req uire oxygen to
breathe and cannot live for very long beneath water; stones d o not mind.). In both cases we have
a sort of allostatic attractor characteristic of the system . Besides the explicitly non-teleological 11
notion of the constraints or intended preimage which are deﬁ nitional of a system, an important
dual observation is that this parameterisation of likely in ternal and external states is one reading
11 By teleological we mean an explanation of the way something ‘is’ which is base d on the ‘purpose’ of the system,
the means by which a goal is achieved—here, the minimisation of surprisal—rather than its intrinsic nature—an
enforced deﬁnition for itself, called an ontological poten tial [Sak22c, RSH +22]. Indeed, one can explicitly contrast
this with the normative role a set of constraints on system st ates plays. See [MB17] or [GN22] for recent reviews
of the diﬀerences between these approaches in modelling sel f-organising systems, and how they also reinforce each
other—namely, the minimisation of surprisal can be seen as a llowing the system to meet some set of constraints as
a goal, evincing an attractor in the state space. This appear s to be one sort of statement of our duality [Sak22c,
Section 3, Section 6.2].
10
of Bayesian mechanics which is consistent with the idea of pe rception or estimation in Bayesian
inference.
It is a deep result in [Fri19] that the existence of a system vi a the presence of a Markov blanket
is the minimisation of surprisal, and in [Sak22c] it is shown that we can understand that surprisal
minimisation as the control of key existential or essential variables which are deﬁnitional of the
system. Mathematically, as we stated above, it is equivalen t to the ﬂuctuations of a realisation of
the system about that modal value parameterising the surpri sal, and this is even more obvious in
the form indicated in (5). Conceptually it is equivalent to a sking that systems stay coherent if they
are (i) at some optimal set-point despite their surrounding s, or dually, (ii) encoding optimal beliefs
about their surroundings. As we have already stated, there a re two senses in which this is true: if a
system estimates its environment, it is organised cohesive ly into the preimage of σ; dually, a system
is an estimator only if it exists in a cohesive fashion to begi n with. More complicated formulations
of Bayesian mechanics update this statistical estimation t o a sort of information gathering, where
systems that are able to stay cohesive for longer and enforce an intended state learn enough about
η to change either ˆηb,t or the coupling σ− 1(ˆηb,t ), and hence maintain an intended ˆ µb,t .
Viewing this as a maximum entropy problem (see [RSH +22] or [RSF22] for overviews, or [Sak22c]
for details), we have in (6) the constraint that the surprisa l of the model of external states is, on
average, zero—it is a perfect model [Sak22c, Proposition 4. 1]. In (7), we ask that the surprisal of
the approximate model is on average no greater than the intri nsic surprisal of the system [Sak22c,
Proposition 4.2].
D. A physics by beliefs
We may also view such a constraint as applying to the internal states of the system; as stated,
this is the control-theoretic view, which we are automatica lly sympathetic to in virtue of speaking
of internal states as parameters of the free energy function al.
We have leveraged the fact that, in virtue of being coupled, a value for µ parameterises a recog-
nition density, and that this minimises a bound on surprisal , which arises from the system ﬁtting
a simpler parametric model r(η; σ(µb)) to an approximate posterior density p(η | b). Assume both
densities are Gaussian or that p(η | b) is well approximated by a Gaussian, a so-called Laplace
approximation. Let Σ synchronise variances, just as σ did means or maximum a posteriori estim-
ates (what we have called modes). Consider the following: th e KL divergence for the univariate
11
Gaussians
DKL
[
r
(
η; σ(µb), Σ( ϑµ |b)
)
∥ p(η; ˆηb, ˆϑη|b)
]
evaluates easily to
ln
{ ˆϑη|b
Σ( ϑµ |b)
}
+ Σ( ϑµ |b)2 + (σ(µb) − ˆηb)2
2 ˆϑ2
η|b
− 1
2,
and this expression vanishes when µ = ˆµb and ϑµ |b = ˆϑµ |b, such that σ and Σ act on these
parameters appropriately. Generalisations to the multiva riate case follow easily. (Looking at this
functional form, it is obvious that the variational free ene rgy couples the two systems.)
We might also observe that the system minimises a surprisal f unction of its own beliefs when
the KL divergence vanishes, since − ln{r(η | µ = ˆµb)} = ( σ(µb) − ˆηb)2 = 0 in that case, where
Er[− ln{r(η | µ)}] = Er
[
(σ(µb) − ˆηb)2]
= Σ( ϑµ |b)
= Ep(η|b)
[
(σ(µb) − ˆηb)2]
= Ep(η|b)[− ln{p(η | b)}]
(9)
by construction (recovering Proposition 4.2 of [Sak22c]).
Moreover, the system minimises a surprisal function of its o wn states when the KL divergence
vanishes, since − ln{p(µ | η = ˆηb)} = ( µb −σ− 1(ˆηb))2 = 0. Whilst subtler than it ﬁrst appears, 12 our
na¨ ıve suspicion that the systems synchronise across both s ides of the blanket is valid at the point
of synchrony, since the roots of these two equations are the s ame. This allows us to view Bayesian
mechanics dually, as a control problem, where the system mai ntains an unsurprising set-point ˆ µb.
There is no guarantee of either being possible in general; th e system may be constantly surprised
if, for instance, it cannot occupy the expected value mirror ing the environment (at which point it
will cease to exist as it was, and transition to a new dynamica l regime with whatever mean it can
occupy) or if the Gaussian approximation indicated here is a bad model of the environment (under
which samples of η are surprising). This ‘sleight of hand’ is what lends the tau tological truth that
systems which exist do unsurprising things—and that couple d systems which exist synchronise
their statistics—a more interesting, model-based interpr etation.
As stated, if we have the two constraints
Ep(µ |η)[µ | η] = σ− 1(ˆηb) = ˆµb (10)
12 See “Adjoint Statistical Inferences,” forthcoming, for an extended treatment of the functional form of this duality.
12
and
Ep(µ |η)
[
µ − Ep(µ |η)[µ | η]
] 2 = Σ − 1( ˆϑη|b),
where η is now a choice of parameter, then we have a maximum entropy problem : the expected
surprisal of µ given b is equal to the intended value of the expected deviation of µ given b from
the synchronised value of the parameter, which is the intend ed average. The foregoing statement
that the average surprisal is non-zero, but the surprisal is zero for the average state, is that the
distribution of µ given b is a Gaussian, whose entropy (expected surprisal) is some in tended variance
(expected quadratic ﬂuctuation): we have
− ln{p(µ | η)} = ( µ − σ− 1(ˆηb))2
for the stationary solution to that maximum entropy problem . Note that the dual of the constraint
equation (10)—i.e., that the mean of r(η | µ) is the same as the mean of p(η | b),
Er(η|µ )[η | µ] = σ(ˆµb) = ˆηb = Ep(η|b)[η | b], (11)
is precisely the constraint that the mode of one density sync hronises to the mode of the other.
This reasoning also applies to the variance constraint foll owing (10).
In (9) and (11), we constrain the variance and mean of two diﬀer ent densities to be equal. Our
observation that this is necessary and suﬃcient for the mini misation of variational free energy is
nothing more than an instance of the information projection theorem. Note also a consequence of
(9), that the average surprisal is generically non-zero : the expectation of this surprisal, which is
equivalent to a variance, is Σ − 1( ˆϑη|b). That is, if the variance is non-zero, then so too is the aver age
surprisal. Instead, the surprisal of the average state is zero and hence the ideal system, on average,
minimises surprisal , since the average state of that system is a surprisal minimi ser. In parallel to
this, the system explores the state space by ﬂuctuating prec isely how it must in order to sample
the full suite of environmental states, ˆϑη|b. Since the path measure is formulated such that the
average of ﬂuctuations is the expected surprisal, and thus, the entropy, this is really a consequence
that the entropy of a constrained maximum entropy distribut ion is whatever the average value of
the constraint is, which is not generically zero (see [PGLD1 5] for an argument along these lines).
Prosaically, we could say that the average surprisal of the s ystem is not minimised in general, but
the surprisal is minimised by the system on average.
Finally, a remark on notation before we proceed further: not ice that we have imposed the
constraint that the internal state, sans explicit consideration of the blanket state, is on average
13
the synchronised average internal state given a blanket state. Implicitly, we have incorporated a
constraint that the input-output ﬂows characterising the M arkov blanket are aligned, such that
blanket state b is shared. In other words, this is not only a constraint that t he system synchronises;
we also fold in a constraint that the interface b is shared, such that synchronisation is possible.
The suggestion of this very point goes back to deﬁning the syn chronisation function as a function
of two arguments, µb, recapitulating the tensor-Hom adjunction in [Sak22c, Lem ma 4.3]. Indeed,
there it is shown that the synchronisation function exists i f and only if the interface is shared, in
which case, a partial function ξ(b, −) of µ exists.13
This maximum entropy model is our belief about the state of th e system whose beliefs are
minimising free energy [RSF22]. Since this is equivalent (i n fact, dual) to a problem of variational
free energy minimisation, the same laws of motion for belief updating that Bayesian mechanics
deﬁnes apply to our own beliefs, and symmetrically, such law s are implemented by our beliefs
about the systems being modelled. This makes Bayesian mecha nics also a control problem: we
model a system as leveraging its model—and these laws of moti on in belief space—to engage
in a kind of KL control, where the control parameter is the sur prisal-minimising average state.
Generalising, we could think of path-tracking [RSH +22] as a path integral control problem given
a reference trajectory ˆ µb(t), conjectured in [Sak22b] and discussed later in this paper (see also
[BDCF+22, STvdM +22] for recent work in this direction).
Indeed, when we speak about control, we can dualise the above problem to ask that a system
controls itself to maintain a system-like set-point. That i s, we ask that the self-surprisal (the
magnitude of ﬂuctuations)
− ln{p(µt | ηt)} = ( µt − σ− 1(ˆηb,t ))2
is minimised, and moreover, that the accumulated surprisal
− ln{p(µ(t) | η(t))} =
∫ t
0
(µτ − σ− 1(ˆηb,τ ))2
is minimised. This inherits directly from our above discuss ion about path probability measures.
Bayesian mechanics leads to various types of approximate Ba yesian inference, just like classical
mechanics admits diﬀerent applications of Newton’s laws of m otion (e.g., the continuum mechanics
of ﬂuid ﬂow, or orbital mechanics for satellite motion). As s tated, when that parameter is trivial,
we have mode-matching; when it is dynamic, this is referred t o as mode-tracking [RSH +22]. When
13 The same idea appears elsewhere in statistical physics in va rious disguises; see [Lyn22] or [Mye22] for detailed
formulations of input-output composition.
14
applied to beliefs about the trajectories of external and ac tive states, we have a more general
version of Bayesian mechanics only recently explored, incl uding active inference [BDCF +22]. This
has been referred to as ‘path-tracking’ in [RSH +22]. The taxonomy described here exists in the
same sense as minimising the action of the Lagrangian L = K − V yields Newton’s second law of
motion, which can be applied to various sorts of systems when we know what sort of function V
is. We will work out in some detail what this taxonomy looks li ke in the world of classical physics.
In summary, Bayesian mechanics contains two key pieces of da ta: the surprisal action, and the
synchrony map σ (and thus, implicitly, a boundary). These data deﬁne belief s and belief dynam-
ics, respectively, and pair them with a characteristic geom etry (information geometry [Ama16], the
study of statistical manifolds , or so-called ‘spaces of beliefs’). It is interesting that m ost physical
theories are paired with a characteristic geometry in which they play out [ADH10], such as sym-
plectic geometry in classical physics [AGN01]. Later in the paper we will point out the appearance
of symplectic forms in Bayesian mechanics, which is notable given the analogy we draw.
III. A GENERAL EQUATION FOR BAYESIAN CLASSICAL MECHANICS
We begin with a classical particle described by a position va riable, q, at some time t. The
mass of the particle will be denoted by m. The position plays the role of an internal state for the
particle. The particle has an external environment interac ting with it, whose states η determine
what forces are acting on it. This paper will build classical physics as the Bayesian mechanics of
classical objects in an environment.
Why have we chosen classical physics as the setting of our exe rcise? Classical physics is well-
established as the consequence of a particularly simple lea st action principle, with as many ﬂavours
of kinematics as there are forms of approximate Bayesian inf erence [RSH +22, Section 3] meaning
that there is an opportunity to formulate straightforward l east surprisal rules for this case. More
interestingly, because the dynamics of classical systems a re non-dissipative and exhibit periodic or
chaotic motion, classical physics leads directly to challe nging mathematical and physical situations
which are of interest to describe. The characterisation of c lassical physics as a mechanics for
inﬁnitely precise beliefs makes it easier to handle some of t his diﬃculty, which we will observe
in Section VII. Finally, if Bayesian mechanics is a physics w hose boundary conditions are related
to boundaries, we will see classical physics is particularl y easy to formulate: the sparsity of the
coupling is almost obvious.
Let Ft be the vector of total force applied to the system at a time t, ∑
i Fi,t . The reception
15
of an applied force is like a blanket state for the particle, w hich can couple to and aﬀect internal
states. The attentive reader will likely have noted that a fo rce is not a state of the particle, but is
an interaction of the environment with the states of the part icle. Initially it may seem suspect that
this Markov blanket is not part of the system, nor is it a physi cal state at all. It is perhaps a type
error to identify a force with the measurement of that force, but beyond that, our construction is
unproblematic for the following reasons: (i) the measureme nt of a force Ft is exactly a sensory state,
(ii) a Markov blanket can be construed as simply that set of st ates which enforces the separation
or distinguishability of two systems [Sak22d], which a forc e certainly is, (iii) the failure of a force to
map onto an internal state is precisely the failure for separ ation to be enforced, which is also when
surprisal is high (see [Sak22c], where it is proven that the i ntegrity of the boundary is equivalent to
low system surprisal under a good variational model) meanin g this functions as a Markov blanket
regardless of its physicality. Moreover, simple objects ha ve, in general, correspondingly simple
Markov blankets.14 A single sensory state for a single classical point particle ﬁts that bill.
That being stated, we consider Ft itself to be like a sensory state of the particle. As such, we
have an inverse synchrony map,
σ− 1 : ηt → Ft → qt.
The former map, η − 1, merely sends external states of the world to the forces the w orld applies on
objects, which will be done implicitly throughout the paper , as we provide worked examples with
particular applied forces. Let s be a temporary time variable. The latter map, µ (Fη,t ) = qt, is the
solution to an integral equation determined by Newton’s sec ond law,
F (η, t ) ↦→
∫∫ F (η, s )
m = qt.
In other words, the particular functional form for the coupl ing σ we have used is one that sends
the average acceleration of the system to the average force a pplied to the system,
σ− 1(ηF,t ) = qF,t .
The ideal path of internal states, which encodes an optimal ( i.e., unsurprising) belief about
what the system is being told to do by the environment, consis ts of precisely these qt, for whom
σ(qF,t ) = ηF,t . Note the consistency with more recent formulations of the F EP: for as long as
there exists a particle, there exists some (possibly trivia l) blanket distinguishing that particle from
14 See “Path Integrals, Particular Kinds and Strange Things,” forthcoming. See also [FFGL22] for an argument
that boundaries are information-theoretic objects; it fol lows that things with many states and a large amount of
information to be transmitted need suitably complex bounda ries, and things that do not, do not.
16
its environment along its path of evolution [FCS +22, Sak22b]. We can argue that such a blanket
exists—that any classical particle under the partition ind icated above is sparsely coupled on the
time-scale over which it exists—simply by pointing out that we can read oﬀ Ft and need not
consider ηt to get internal states qt. Physically, this is the intuitive statement that it is only a force
that matters to motion, not what generated that force. Hence , by construction, for as long as a
classical particle exists to be acted on, it has a blanket. Se e [HDC22, Sak22d] for more on sparse
coupling.
Just as we presume that the mechanics of beliefs should lead t o physical mechanics (control),
minimisation of the surprisal should lead to physical mecha nics (Newton’s laws of motion) and
trajectories that abide by those mechanics. In establishin g that physical mechanics follows from
Bayesian mechanics, we ﬁrst focus on beliefs about internal states, and relate them to the beliefs
carried by internal states afterwards. The surprisal Lagrangian, − ln{p(−)}, is applied either to
p(qt) given Ft, or is applied symmetrically to the probability of p(ηt) given Ft. We would like to see
whether the minimisation of surprisal under σ recovers classical physics in the context of Bayesian
mechanics, so we try to minimise − ln{p(qt | ηt)} under the parameterisation − ln{p(qt; σ− 1(ηF,t ))}.
Here, we take a moment to remind ourselves that dualising the object in the Lagrangian to internal
states gives us a physics of our beliefs about the system, or the system’s beliefs about itse lf, which
is the duality indicated in [Sak22c]. Contrast this with the surprisal Lagrangian on external states,
which gives a physics of the system’s beliefs about its envir onment, in [FCS +22]. So, to set the
stage, we change to the dual problem to (8) (i.e., ﬁnding p(µ(t) | η(t)) instead).
Under a noise injection, or else some uncertainty associate d to the belief about a position at
t, this becomes a problem of mapping means to means, in the sens e of the approximate Bayesian
inference lemma. We are primarily interested in the probabi lity of deviating from the path of least
action, such that our (state-wise) surprisal is a measure of
p(qt; σ− 1(ˆηF,t )) = p(qt; ˆqF,t ).
Suppose the acceleration at a given time is constrained such that, on average, it obeys the forces
being applied to it at that time. This is an instantaneous pic ture, licensing a non-dynamical
application of Bayesian mechanics (note that we used that in Section II A as well, where the
instantaneous story behind derivatives licenses dropping the time variable from q(t), a position in
time). Denoting an expectation with E and neglecting subscripts, this gives us the equation
Ep(q)[q] =
∫∫ F (η)
m . (12)
17
Suppose we also constrain the system to be classical, in the sense of having inﬁnite precision. This
is a variance constraint, namely, that
Ep(q)
[ (
q − Ep(q)[q]
)2]
= 0 .
When asking about paths, we ask that the accumulated varianc e of or along a path is also zero:
Ep(q,t )
[ ∫ t
0
(
q(τ) − Ep(q,τ )[q(τ)]
)2 dτ
]
= 0 . (13)
A similar law for the total squared displacement of a path has been used to produce Newton’s laws
from the principle of maximum path entropy (maximum calibre ) before [GDG14]. Both of the
above equations are simply a constraint that the optimal acc eleration does not deviate from what
the environment tells it to, which implies the approximate B ayesian inference lemma when under
the additional constraint that the average state is the valu e of the synchronisation map [Sak22c].
Here we have arrived at an important point: our belief about a system is an FEP-theoretic
model of the system. We believe the system constrains itself to be the optimal parameter for
some belief over what it is supposed to do in its environment. That parameter happens to be
the least surprising internal state given some external sta te and a shared blanket state. This is
what is meant in previous discussions about beliefs about in ternal states being dual to beliefs about
external states. That is, in the sense that building a model o f a system which constrains the system
to exist at an ideal internal state is maximum entropy, maxim ising the entropy of our model under
these constraints is the ‘doing’ of the free energy principle. 15
The optimal (i.e., least biased [PGLD13]) belief under thes e two constraints can be derived from
the principle of constrained maximum entropy, yielding
p(q) = exp
{
−λ1
⏐
⏐
⏐
⏐q − λ2
∫∫ F (η)
m
⏐
⏐
⏐
⏐
2}
(14)
with λ1, λ 2 > 0 being Lagrange multipliers for the constraints indicated above. Considered dy-
namically, this equation can be given as a path probability d ensity
p(q, t ) = exp
{
−λ1(t)
∫ t
0
⏐
⏐
⏐
⏐q(τ) − λ2(τ)
∫ ∫ F (η, s )
m
⏐
⏐
⏐
⏐
2
dτ
}
. (15)
When λ− 1
1 (t) ≪ 1 and λ2(t) = 1 for all t, we can reproduce classical dynamics. In particular,
in the limit λ1 → ∞ , there is no uncertainty at all, and the most likely path unde r those con-
straints—the classical path of least action, by constructi on—is the only path we lend any non-zero
15 The idea that the maximum entropy principle under existenti al variables is the free energy principle under a
synchronisation map was ﬁrst suggested in [And21]. A proof o f this can be found in [Sak22c].
18
probability to. This is something like a classical limit for our path probability, in the same sense
as taking ℏ → 0 recovers classical mechanics from Feynman’s path integra l. Moreover, a reliable
heuristic is that ﬂuctuations in the theory are scaled by D such that λ1 ∝ D− 1. The degree to
which something can explore states within some allostatic b ounds is precisely the variance under a
Laplace approximation, yielding an important role for the L agrange multipliers on the maximum
entropy side of the story. This role is not necessarily evide nt in the FEP proper, nor in conceptual
treatments of this duality which are divorced of process-le vel details.
Finally, note that (15) is (5) for a modal path given by (12). T his will be our general equation
for Bayesian classical mechanics. 16
IV. A QUESTION OF QUANTUM ONTOLOGY
We began with the aim of showing that classical physics can be derived from Bayesian mech-
anics, by showing that deviations from a classical law of mot ion are surprising given a particular
action functional, and that Bayesian mechanics describes t he minimisation of surprisal. Do systems
actually infer what their classical laws of motion are, and f ollow those inferences to avoid surprisal?
More to the point: is there a less ‘just so’ aspect of reproduc ing classical physics from the assump-
tion that the least surprising trajectory of a system minimi ses the classical action? Can we do this
without arbitrarily assuming the laws of classical physics and merely showing that unsurprising
systems obey those laws? There is indeed a more concrete inte rpretation of this inference, one
which makes the idea behind (15) more subtle.
In fact, what we have shown in the foregoing statements is tha t, under surprisal minimisation,
a system takes a classical path when that path is the average. We can demonstrate that this has
some further meaning by showing Bayesian mechanics is natur ally derived from simpler arguments
about the role of probability in quantum mechanics, such tha t the modal path of any ﬂuctuating
system is a classical path, and surprisal minimisation alre ady exists in quantum mechanics. That
is, we can derive Bayesian mechanics from the idea that a syst em is classical on average, just as
we can derive classical mechanics from the idea that systems obey Bayesian mechanics for classical
averages. This suggests a view that (i) systems with randomn ess do inference over their classical
laws, and (ii) in the quantum setting we recover classical ph ysics by doing inference. A more
complete quantum physics manual for the Bayesian mechanic i s to be written elsewhere.
16 Note that, for a heuristic integral over an inﬁnitesimal tim e, i.e., from t to d t, (15) is equal to (14). This makes the
equation with the time integral the general case. Intuitive ly, what we have noted is a statement that instantaneous
variations in a path accumulate along the path as the path goe s forward in time.
19
Begin from the supposition that classical equations of moti on are asymptotics of quantum
equations of motion, given by the empirical observation tha t we can measure classical eﬀects more
readily than quantum ones, but also, that classical equatio ns of motion depend on parameters
with underlying quantum eﬀects, in such a way that quantum eﬀec ts still bleed into the classical
world when we ‘zoom in’ to the extent that those parameters ar e no longer renormalised. 17 This
leads directly to the correspondence principle, a law of large numbers for quantum probabilities.
The consequence of this classical ‘limit’ is that the evolut ion of the most likely state of a quantum
system gives us what we deﬁne as classical physics. Proven by Ehrenfest in 1927, we can rewrite
this result (assuming |∂ttq(t)| is bounded above almost surely—physically, a thoroughly re asonable
assumption) as
− Ep(q(t))
[
∂qV (q)
]
= m Ep(q(t))
[
∂ttq(t)
]
.
So, assuming distance constraints like those above, such th at we have a Gaussian measure or
otherwise a Laplace approximation—a constraint which is qu adratic in ﬂuctuations—the most
likely path ought to be a classical equation of motion. We wil l repeat this argument in Bayesian
mechanical language, aided by the technology of the path int egral.18
In order to reproduce the idea that, probabilistically, qua ntum ﬂuctuations are merely correc-
tions to classical estimates, we take a Wiener measure where the variance of path probability—as it
is given by the probability of the velocity on such a path—is s caled by some characteristic constant
m
2ℏ ,
Z− 1 exp
{
− m
2ℏ
∫ t
0
∂sq(s)2 ds
}
dq(t) .
Note that, technically, we have Wick rotated our ﬁeld theory . Note also that, appealing to the
Trotter product formula, we can separate out the potential a nd assume it is zero everywhere on
the support.
As we remarked before, setting λ1 = ℏ and taking the scaling of quantum ﬂuctuations to
zero, and making use of the fact that ﬂuctuations are precise ly what contribute to the surprisal,
we have a statement that in the quantum regime of Bayesian mec hanical dynamics, the least
surprising trajectory of the system is one that follows an ov erlying classical equation of motion.
Indeed, under the WKB approximation, the most likely path in the path integral is the classical
equation of motion of the ﬁeld. Without quantum ﬂuctuations about this classical solution we
17 This is also referred to as an adiabatic approximation, and a ppears in semi-classical physics.
18 We point the reader to [Hal13] for details.
20
have classical physics, whereas in perturbative approxima tions to quantum mechanics, such as the
quantum eﬀective action, we add those quantum ﬂuctuations in as higher order correction terms
to a classical ansatz.19
So, we are now armed with two facts: basic physical observati ons suggest that classical paths
are most likely paths, and, the canonical measure on paths is in terms of ﬂuctuations about such
a classical mode. We wish to see if the mathematical fact that this is the canonical description
of path probability reﬂects the physical fact that classica l equations of motion are the most likely
paths of a system. Our formulation suggests that taking the l imit ℏ → 0 would be the right
approach. Formally, this limit scales ﬂuctuations to zero, revealing the most likely state as the one
with constant velocity v(0): a classical equation of motion under our identically ze ro potential,
from where we derive no applied force and hence no accelerati on.
Though we omit the proof, one can indeed prove that taking ℏ → 0 results in classical equations
of motion. As noted by Feynman, this most likely path is what i s most likely to be determined by
observation (experiment), and thus determines the classic al limit of the path integral. That this
story—the most likely path is the classical one due to a priori assumptions about the state and
measurability of the world—implies the minimisation of sur prisal, as well as following from it (as
discussed in Section III) is non-trivial.
What does it actually mean when we pass from ‘most likely’ to ‘ least surprising?’ Least surpris-
ing to whom? Certainly the experimenter—there is a sense in which the en tire problem is dualised,
and we are minimising the surprisal of our beliefs about what a system does. That is, the two
random dynamical systems coupled here are a quantum particl e and an environment (including,
perhaps, an external observer).
Do quantum particles do inference over where their classica l paths are, organising themselves
on average into the preimage of the average state of the obser ver, who expects to see a system
follow a force applied? In the sense of estimating what that p ath is by taking a path which
wastes the least energy (so to speak) in response to a force an d in absence of quantum noise—and
encoding such a path in their own dynamics, thereby inferrin g what another object ‘tells’ them to
do classically—they do. This makes Bayesian mechanics a use ful way of modelling how a quantum
system treats information and interactions with its enviro nment,20 defaulting to classical equations
of motion on average. It is in this Bayesian mechanical sense that classical physics is a result of
19 This section assumes there is a unique such classical solution to the system. Degenerate classica l minima are
handled by instanton theory, which we will not cover here. An excellent overview of the topic can be found in
[VZNS82].
20 We will refer the reader to [FFGL22] and related references f or more details about quantum information theory
under the FEP.
21
Bayesian inference in a quantum regime. It is not so trivial t hat, at the quantum level, such a
particle is inferring what its classical trajectory—in mod ern parlance, inferring what its coherent
state—is, given some noise statistics and a macroscopic or higher -level force acting on it. It is this
higher-level inference that organises the noisy, quantum s ystem into a classical system. 21
More relevant to our case would be to return to the example of t he boughs of a tree. A particle
undergoing a force must minimise surprisal to stay cohesive , as we argued, and therefore can be
read as inferring where the environment is directing it: wha t the environment is doing and how it
is interacting with the particle. At the classical level, th is is a concrete inference problem, wherein
we try to ﬁnd the maximum a posteriori estimate of a density with thermal or quantum noise,
furnishing the classical path ‘intended’ by the environmen t.
V. THE MATCHING OF MODES
This section begins a worked example of the typology describ ed in [RSH +22, Section 3]. We
begin with ‘mode-matching.’ Mode-matching is the applicat ion of Bayesian mechanics to stationary
objects which engage in approximate Bayesian inference [Fr i19, Sak22c, RSH +22]. In this case, by
deﬁnition of stationarity, the most likely internal state i s ﬁxed. Typically valid over only a brief
time-scale—since nothing is stationary forever and nothin g which is stationary and non-adaptive
resists entropy for long—this is the simplest case of Bayesi an mechanics.
Inspired by [Sak22c], we formulate mode-matching under app roximate Bayesian inference as
internal states being constrained to be optimal parameters for a recognition density. Again, this is
fully equivalent to the proper FEP. Using Theorem 4.2 (ibid) , we can formulate the minimisation
of surprisal applied to internal states − ln{p(q | ηF )} as a demand that the log-probability equals
some constraint on those internal states, with further prec ision-based minimisation possible over
an ensemble of states. Here, that constraint is
S[q] = − ln{p(q | η)} = λ1
(
q −
∫∫ F (η)
m
)2
.
Note the similarity to equation 3.5 in [DCFHP21]. Under appr oximate Bayesian inference (and a
further, but generically acceptable, Laplace assumption) , the ideal state is the most likely state,
which is the minimiser of this squared displacement.
The system we describe could be a stone performing inference over the cancelling of its gravit-
21 The same phenomena has been demonstrated in self-organisin g soft matter systems [RHT +21], suggesting this
may be a promising line of research on collective excitation s in condensed matter.
22
ational pull and the normal force emanating from the ground, obeying
∑
F = −Fg + FN = 0 . (16)
In this case, the stone’s acceleration is zero, and under the initial conditions v(0) = 0, q(0) = 0,
it goes straight to—and remains at—the mode q = 0. Referring back to the Introduction, the
mode is a particular attractor which is a ﬁxed point for the sy stem. Indeed, for stationary initial
conditions, the surprisal above is zero precisely when ( q − 0)2 = 0.
Notably, this also means that for Bayesian mechanics to be co nsistent in the classical setting,
it must (for stationary modes) imply Newton’s ﬁrst law—i.e. , that for every applied force, there is
a force of equal magnitude applied in the opposite direction .
VI. THE TRACKING OF MODES
Mode-tracking can be summarised as the existence of a target mode, i.e., a desired mode that
systems are tracking towards, either for a ﬁnite time or cons tantly. This allows us to describe
the most likely ﬂow of autonomous states as a ﬂow of beliefs [F ri19, PDCF20, AMTB22, RS22],
and involves the iteration of approximate Bayesian mechani cs [Sak22c]. Within mode-tracking we
introduce two further distinctions, which is a more granula r approach than the three-fold structure
described in the Introduction: systems which track, but set tle to, a mode, and systems which
constantly chase a mode. The former is an example of a system t hat terminates in mode-matching,
whilst the latter is an example of a system that is in constant motion. For both cases, we pass to
an idea of dynamics, gesturing at an application of the princ iple of maximum calibre [Sak22b].
A. Terminal mode-matching
Suppose the total force applied is dynamic, but eventually e quilibrates. An example would be
a stone tossed into the air, which travels through a gravitat ional ﬁeld and eventually returns to
the ground. The variant of (16) corresponding to that motion is F = −Fg, and the solution of the
integral equation (12) under that F is
q(t) = q(0) + v(0)t − 1
2gt2 (17)
where g is the acceleration due to gravity. This equation has a stead y state value where the mode
q(t) = 0 and remains there, reached at some hitting time thit. For instance: for v(0) = 0 metres
23
per second and q(0) ≈ 4. 91 metres above the ground, thit ≈ 1 second. So, we can consider the full,
dynamic-in-time force as
−Fg(t) + 1hit(t)FN (t),
where 1(−) is an indicator function—the constant function equal to on e on t ≥ thit, and zero
elsewhere. This terminates in the mode-matching explored i n the previous section, since for all
t ≥ thit, we have ∑ F = 0. Indeed, q(t ≥ thit) = 0 by construction; this is a stationary mode.
By solving (12) as a constraint relation, we have actually as ked that the average path obeys
(17) and that no other path q(t) deviates from that path. That is, we want q(t) = ˆq(t) in the ideal
case. As such, classical objects can be modelled as performi ng inference over the forces driving
their motion, and given that they ﬁnd known laws of motion uns urprising, get driven to the mode
described in Section V by following (17). For example—it wou ld be surprising to the very fabric
of space-time if a stone which had landed on the ground at some thit were to spontaneously jump
after. Thus, by obeying (17) and following classical laws of motion, the surprisal of motion is
minimised. We will detail this below.
We begin by asking that q(t) should equal ˆ q(t). Under our other constraint on the expected
path—the solution to (12), given above—eventually, ˆ q(t) = 0 (in particular, for all t ≥ thit). We
could view this as dynamical inference more generally, or, t he construction of a realisation of some
path under a steady state density with mode zero, such that ˆ q(t) = 0 after some convergence
time (here, thit). In that case, the system goes directly to ˆ q as its kinetic energy ‘dissipates’ into
potential energy.
In greater detail: a path consists of a list of states. Each su ch state is increasingly more likely as
we approach the mode, and indeed, a mean-reverting process w ill go to a mode on average under
a quadratic potential. As such, the average path taken by the system performs a gradient ascent
on the probability density, or equivalently, a gradient des cent on the surprisal. Note that we are
not working in a path space here; rather, the path exists on a p robability density, as a lift of a
list of states, which is indeed simply a path—but, we don’t sp eak about surprisal minimisation
on such a path directly, instead speaking about the tendency of any path to go to a ﬁxed point.
Mathematically, this means that the motion of q(t) is a gradient descent on |q(t) − ˆq(t)|2, with
some convergence time thit, and q(t) = ˆq(t) = 0 for t ≥ thit. Since the logarithm of (14) is this
distance when λ2 = 1, this is equivalently a minimisation of surprisal. That i s, we have
∂tq(t) = −λ1∇ ln{p(q)},
24
such that the least surprising state is the mode, and the system takes a path towards that mode.
Moreover, the least surprising path to the least surprising state ought to traverse the distance
from some initial q(0) to ˆq the quickest, which (for a ﬁxed velocity) is the path given by a direct
gradient descent on the distance. It would be of interest in f uture work to give a uniﬁed view of
these approaches, i.e., to prove that under certain asympto tic conditions, least surprising paths are
paths towards least surprising states.
Since λ1 scales ﬂuctuations, it is proportional to the inverse diﬀusi on coeﬃcient, or the cov-
ariance, more generally. Additionally, since there is no ra ndom motion and no opportunity to
explore, the motion is described by a pure gradient descent, and so this yields one component of
the Helmholtz decomposition discussed in [Fri19]. Note tha t the instantaneous Lagrange multi-
plier λ plays a diﬀerent role than the dynamical Lagrange multiplier λ(t). In particular, the former
selects states whilst the latter selects paths, a distincti on that becomes important when we deal
with paths towards least surprising states, as we have here. We still desire λ1(t)− 1 → 0 as we
did in Section IV, to reproduce classical path selection. In the Gaussian case this is precisely our
uncertainty over paths, as we mentioned.
B. Inﬁnite mode-tracking
This section will discuss itinerant objects whose gravitat ional ﬁeld is such that the mode is
never stationary—which we could call mode-chasing, as a sub -type of mode-tracking. Consider a
planet in a gravitational potential equal in all directions : there is no stationary state, and hence,
no meaningful mode, to the dynamics of this system. Na¨ ıvely , there is no parameter through
which to minimise surprisal. This does not mean the FEP canno t describe satellite motion. On
the contrary—the application of the FEP to complicated syst ems is where it truly shines [RS22].
Here, we can iterate self-evidencing to ﬁnd out what constan t motion dictated by a consistently
dynamical principle might look like.
Like any classical system, in the absence of a force acting on it, a satellite system will continue
to move on its trajectory. This is Newton’s ﬁrst law—the usua l aphorism being, ‘a body in motion
tends to stay in motion; a body at rest tends to stay at rest. . . ’ with the phrase ‘. . . unless
acted upon by an outside force’ often appended. As such, the h itting time formulation of Section
VI A is no longer directly useful, but having no hitting time certainly is. Note that the lack of
a mode—but presence of circular, solenoidal ﬂows—for true c lassical systems 22 is consistent with
22 That is, energetically conservative systems, or systems in the absence of dissipative forces. Although not a dissip-
25
[DCFHP21, Sak22c].
Such a system has no dissipative component, since it is purel y classical. This means the gradient
descent describing the mode-matching dynamics we discusse d in Section VI A degenerates, in the
opposite sense as any exploratory component of the ﬂow degen erated in that section. Here, we
have a system which travels along a level set of a sphere of rad ius r, and in particular, travels
such that the surprisal of states (parameterised by a statio nary mode) is a non-zero constant along
a path. By simple arguments in symplectic geometry—the geom etric study of ﬂows in classical
physics [AGN01, dS08]—ﬂows which are level sets of some Lagr angian23 and which admit radial
coordinates are described by a skew-symmetric matrix. Inde ed, level sets of the sphere centred on
ˆq, projected down to the state space, are integral curves of th e following equation:
∂t

q1(t)
q2(t)

 =

 0 ν
−ν 0



q1(t)
q2(t)

 + 1
ν

ˆq1(t)
ˆq2(t)

 , (18)
where ν controls the system’s frequency, or speed of travel along on e such level set. Note that this
system of equations corresponds to the second-order ordina ry diﬀerential equation
∂ttq(t) = −ν2q(t)
for either coordinate q1 or q2 (simply perform the matrix multiplication in (18), take the derivative
∂ttqi(t), and insert the expression for ∂tqj(t) into the result) whose solution is
q1(t) = r cos(νt) + r sin(νt) + ˆq1,
q2(t) = r sin(νt) − r cos(νt) + ˆq2
for some constant r > 0. Note also that
− ∇ ln{p(q, t )} = 2 λ1(q(t) − λ2 ˆq). (19)
As such, for an appropriate choice of λ1 (namely, one half, or half the coeﬃcients of the gradient
descent operator, should it exist) and λ2 (namely, −1/ν ), inserting (19) component-wise into (18)
yields
∂tqi(t) = −∇i
j ln{p(q, t )} = Qi
j qj(t) + 1
ν ˆqi
with Q1
2 = ν and Q2
1 = −ν, which is exactly the other piece of the Helmholtz decomposi tion.
ative system, one can contrast this with the loss of energy of motion that occurs upon colliding with the ground
in Section VI A. It is consistent that such systems have a mode whilst unperturbed satellite motion does not.
23 Note that we typically consider a Hamiltonian, which is metr ic isomorphic to a Lagrangian.
26
As we stated, the matrix operator indicated is skew-symmetr ic, and, the gradient on the sphere
is locally orthogonal to these level sets—that is, moving on a level set does not change the gradient.
Since there is no mode for these dynamics, we cannot describe a gradient descent on surprisal in
the sense of Section VI A, but we can say that it is a gradient de scent for which the value of
the gradient is preserved, with velocity scaled by the matri x indicated. Future work will make
the arguments given here—with respect to the Helmholtz deco mposition being an artefact of the
geometric nature of certain ﬂows—more formal.
VII. PATH-TRACKING, AND A SIMPLE CASE OF G-THEORY
This section will progress the construction to more complex forms of path-tracking that are not
amenable to the mode-based descriptions we discussed previ ously.
What has been called G-theory is the duality between maximum calibre and the genre of
Bayesian mechanics applying to surprisal on paths [RSH +22], which we have begun to explore
here. This pitches G-theory as the generalisation of the duality explored in [Sa k22c], extending
that construction to paths. In its full generality it is thou ght to accommodate descriptions of
complex systems (like non-Markovian behaviours, moving at tractors, and non-stationary statistics)
more naturally and with greater ﬁdelity than in the past. Som e inspiration for this comes from the
previously mentioned principle of maximum calibre, which d oes famously well on diﬃcult problems
in non-equilibrium statistical physics [PGLD13, DWW +18, GDAD20]. These results suggest that,
whatever G-theory will prove to be, it will be a canonical modelling fra mework for complex systems.
Here we provide a simple example of this framework by formula ting path-tracking, the least
surprisal principle on paths—our third sort of approximate Bayesian inference—as an explicit
problem of dynamical constraints. We then formulate a conne ction to chaos by examining the
path-based nature of G-theory in greater detail.
A. Path-tracking
Recall our results on mode-tracking in Section VI A. The cons truction there is obviously ineleg-
ant—besides formulating the path over the state space inste ad of doing proper dynamical inference,
it exchanged the proper accumulated squared displacement i n (15) with a less general instantan-
eous squared displacement at thit. Foreshadowing a more general extension to paths, the most
natural formulation of this problem is readily seen as a grad ient ascent on the path probability
27
density. Under maximum calibre, our constraints lead to a pr obability density
exp
{
−λ1(t)|q(t) − ˆq(t)|2
}
,
where the expected path (17) is denoted by ˆ q(t), and |q(t) − ˆq(t)|2 is limitingly zero. For dynamic
F , this is a moving Gaussian, with mode centred along the path f or a given state-wise marginal.
That is, it is centred on the list of q’s visited classically for a list of times, like a crest in the path
space that runs directly over the intended states (and hence , a sort of mountain of probability for
realisations ﬂowing along the state space, concentrating t hem in that region). Path tracking is
obvious in this situation—it appears to follow a gradient de scent on the action, ﬁnding the most
likely path by ﬁnding the summit at each t of p(q(t)).
We can indeed still discuss a gradient descent in this case, b ut it is a functional gradient on
the action S, such that the gradient descent is on deviations along a path , minimising ﬂuctuations
from the path of least action—and this is precisely the princ iple of least action, or of least surprisal,
when the path of least action is the expected path (guarantee d by (4), as discussed in Section II B).
Let δq(t) be some ﬁrst order variation of a path away from a path of stat ionary action at t (see
[RSH+22, Figure 1] for a depiction), which is in fact a realisation at t of some ﬂuctuation away
from the expected path. Analytically, this means that we hav e
δq(t) = − ˆ∇S[q(t)]
where the kernel of the gradient in the path space, ˆ∇, is a path such that the system only changes
to second order under variation—that is, it is a path q(t) such that the distance between q(t) and
∫∫
F (η, t ) is minimised. This equation simply expresses that the path of least variation is the
stationary, or expected, path. This means the system will mo st likely settle into an evolutionary
regime that follows the expected path, which is least surpri sing—however, note this is simply a
model of that process, since there are no such ﬂuctuations in classical physics. Instead, we are
interested purely in the zero point of the gradient.
Recall what the surprisal is in this case—the logarithm of (1 5) is merely the classical action.
As such, the statement that systems evolve on stationary poi nts of the classical action functional
follows directly from a gradient descent on path surprisal g iven that systems follow forces. As such,
the above equation reduces to
δq(t) = − ˆ∇ ln{p(q, t )}
= ˆ∇
[
λ1(t)
∫ t
0
⏐
⏐
⏐
⏐q(τ) − λ2(τ)
∫ ∫ F (η, s )
m
⏐
⏐
⏐
⏐
2
dτ
]
,
28
which yields
δq(t) = 0 ⇐ ⇒ ∂ttq(t) − F (η, t )
m = 0 .
Since our path space gradient on surprisal reproduces the Eu ler-Lagrange equation as the functional
gradient of S[q(t)], this is precisely classical mechanics. (As before, futu re work—here, regarding
the Euler-Lagrange operator in Bayesian mechanics—should be done to make this perfectly rigor-
ous.)
In the inﬁnite mode-tracking case, we have something simila r. For simplicity, we take the path
of a satellite moving about a ﬁxed central body of radius r as a circle
q1(t)2 + q2(t)2 = r2.
This is a constraint that the expected path is a circle of radi us r, and that realisations of q ought
to have norm r2. We will parameterise this as an expected path which is ˆ q(t) = [ˆq1(t), ˆq2(t)] =
[r cos(t), r sin(t)]. The surprisal Lagrangian measures precisely these devi ations from a circle,
⟨
q(t) − [r cos(t), r sin(t)], q (t) − [r cos(t), r sin(t)]
⟩
.
In this form it is even more apparent that our Lagrangian, the quadratic form deﬁned in (4), is
a metric on noise, ω = q − ˆq.24 Once more, it is exactly the distance of q(t) from a circular path
parameterised by [ r cos(t), r sin(t)]. As for surprisal—again, given that systems move on geode sics
through space-time, it would be surprising to see a system ch ange its path to deviate from the
curvature of space-time, and thus, to not follow the induced potential ﬁeld. The ﬁnal relation we
derive is
δq(t) = 0 ⇐ ⇒ q(t) − [r cos(t), r sin(t)] = 0 .
Given centripetal forces and the absence of tangential forc es on a radial parameterisation of the
circle, we can derive that
∂ttq(t) − C M
r2 = 0 ,
where C is determined to be Newton’s gravitation constant; this equ ation then yields the acceler-
ation for a system orbiting a central body of mass M in circular fashion.
24 In fact, we could choose to denote the Lagrangian as g(ω, ω ), for reasons of geometric signiﬁcance.
29
B. A ﬁrst idea of G-theory
In Sections III and IV, we introduced the idea that surprisal minimisation arose from solving
for the Lagrange multiplier for a constraint that the most li kely path was an on-shell trajectory,
described by (13). When this Lagrange multiplier is limitin gly zero, and the particle does perfect
inference over the forces being applied to it, we have classi cal mechanics. Here the uncertainty
over both environment and system necessarily degenerated.
This curiosity—that Bayesian mechanics, when cast in the la nguage of the principle of maximum
calibre, naturally leads to a path integral representation of classical mechanics—is upgraded to a
more interesting observation that, when viewed through the lens of a classical system interacting
with an environment, a path probability density is the most i nformative about the system; in
particular, that it is the most general way of understanding what an environment ‘tells’ the system
to do, and how that can be represented probabilistically as t he system estimating those forces and
following them so as to produce good (that is, unsurprising) inferences.
Although path-tracking is already a more elegant way of disc ussing the simple problems on
display here, as expected, the problems the full generality of Bayesian mechanics seeks to provide
solutions to are radically diﬀerent than the simple Newtonia n laws of motion investigated thus
far. Moreover, to produce key identities in classical physi cs like the Euler-Lagrange equation, we
practically began from where we wanted to end up: with the ass umption that classical systems
follow forces. 25 Here, we aim to eventually formulate chaotic or itinerant sy stems under Bayesian
mechanics, as has been done for earlier forms of the free ener gy principle [FHU +21]. A sketch of
one such result will be found in this second subsection.
Let Γ be the space of paths and C(t) be a source for the ﬁeld (this is merely an external
ﬁeld driving x(t), and is generically comparable to an electric current). At the path of minimal
surprisal, and under the demand that there is no other path po ssible, we have a Dirac measure
over the classical path. Hence, the solution can trivially b e transformed into the following path
integral representation:
Z[C] =
∫
Γ
∏
t
δ(xt − xt, cl)e− λ1(t)
∫ t
0 C(τ)x(τ)dτ Dx(t) (20)
where x(t)cl is the classical solution to the equations of motion of inter est and the product of Dirac
measures over intervals of t of size ε > 0 is given (as such, note our paths are discretised). The
25 However—in defence of the author, and with reference to Sect ion IV, what we really did was say that the least
surprising path of a system with quantum or statistical ﬂuct uations is the one that obeys a classical equation of
motion—a less trivial result.
30
term ∏
t δ(xt − xt, cl) in the path integral enforces a weight of one for classical p aths and a weight
of zero for all others. Note that we assume anti-periodic bou ndary conditions in (20).
Two standard tricks are to rewrite a Dirac measure in terms of a Jacobian determinant, and
then to rewrite a determinant in terms of a path integral over ‘ghost ﬁelds.’ These are anti-
commuting variables that behave like auxiliary fermionic ﬁ elds. Following the procedure described
in [GRT89]—which entails rewriting the on-shell trajector y x(t)cl in terms analogous to second-
order variations ˙ω , rewriting the Dirac measure on that function as a particula r determinant, and
then, introducing a pair of ghosts θ and ¯θ—we have the following transformation of the Bayesian
mechanical path integral:
∫
˜Γ
exp
{
i
∫ t
0
ξ(vτ − vτ, cl) + i¯θ ˙ωθ dτ
}
Dx(t)DξDθD¯θ
where we have taken C(t) to be identically zero (hence it has disappeared) and intro duced a
temporary variable ξ after passing to imaginary variables. Note that
i
∫ t
0
ξ(vτ − vτ, cl) dτ
reintroduces a term proportional to our surprisal Lagrangi an (in Fourier variables), arising organ-
ically from deﬁning what it means to be a classical path—and t hat there is an additional term
−
∫ t
0
¯θ ˙ωθ dτ
arising from the transformations on ∏
t δ(xt − xt, cl) described. The latter term corresponds to a
fermionic sector of our theory, as discussed; whilst the sur prisal term deﬁnes a bosonic sector in
contrast (this appears to be consistent with [Sak22a]). Not e also that, in spite of the appearance
of an imaginary quantity in the path integral, there is no con stant ℏ. That ultimately preserves
the classicality of this path integral.
Moreover, these ghost ﬁelds deﬁne a pair of supercharges; th is is due to invariance under a pair
of BRST transformations which relate bosonic and fermionic degrees of freedom, and generate a
superalgebra under the commutator. This is the deﬁnition of a supersymmetry: a theory which
does not change when we exchange fermionic particles for bos onic particles, and vice-versa; hence,
a theory which is symmetric under the action of one or more sup ercharges, which here are a pair of
so-called BRST operators. Bayesian classical mechanics is thus an N = 2 supersymmetry theory. 26
This supersymmetry has a striking interpretation that give s us a glimpse of the power of G-theory:
the ghost ﬁelds themselves appear to correspond to Jacobi ﬁe lds, measuring the divergences in
26 We will suggest [Tac15] to the reader for a classic, if advanc ed, review.
31
state space of classical trajectories with similar initial points—a typical metric for chaos which
can easily be related to Lyapunov exponents (see [Gra88] for a worked example in the case of
supersymmetric formulations of stochastic dynamics). The breaking of this supersymmetry, when
two ground states can be produced, is a candidate geometric b asis for non-ergodicity [GR89, pages
388–389].
For the Bayesian mechanic who does not usually carry supersy mmetries in their toolbox, we can
zoom out and say the following: the extra ghost ﬁelds—whose i ntroduction is what yields a super-
symmetric theory, and conversely, which arise from making t he theory supersymmetric—naturally
encode the sensitivity of motion to initial conditions. Thi s means that Bayesian mechanics is po-
tentially a canonical set of tools with which to model system s exhibiting classical chaos. Likewise,
the breaking of this supersymmetry, where θ and ¯θ no longer deform one trajectory into another,
corresponds to certain non-periodic, non-mixing motions; or, the non-ergodic regimes underlying
much of complex and non-equilibrium dynamics. (Formally, t his gives rise to an integrable system,
which is necessarily non-ergodic.)
Far more work remains to be done on the nature of supersymmetr ic Bayesian mechanics, and
especially its connections to chaos and the Bayesian gauge t heory introduced in [Sak22a, Sak22c,
RSH+22]; however, for now we only note that this exciting connect ion to certain features of com-
plexity is evidently a mere consequent of the use of G-theory. The theory described above is
known to reﬁne to more nuanced discussions of chaos and insta ntonic dynamics in supersymmetric
stochastic processes [Ovc16, see especially Section 5.4], potentially allowing for new descriptions of
complex systems.
[ADH10] Sir Michael Francis Atiyah, Robbert Dijkgraaf, and Nigel J H itchin. Geometry and physics.
Philosophical Transactions of the Royal Society A: Mathema tical, Physical and Engineering Sciences ,
368(1914):913–926, 2010.
[AGN01] Vladimir I Arnol’d, Alexander B Givental, and Sergei P Novikov. Symplectic Geometry. In
Dynamical Systems IV , pages 1–138. Springer, 2001.
[Ama16] Shun-ichi Amari. Information Geometry and its Applications , volume 194 of Applied Mathematical
Sciences. Springer, 2016.
[AMTB22] Miguel Aguilera, Beren Millidge, Alexander Tschantz, and Ch ristopher L Buckley. How partic-
ular is the physics of the free energy principle? Physics of Life Reviews , 40:24–50, 2022.
[And21] Mel Andrews. The math is not the territory: navigating the free energy principle. Biology &
Philosophy, 36(3):1–19, 2021.
32
[Arn13] Vladimir I Arnol’d. Mathematical Methods of Classical Mechanics , volume 60 of Graduate Texts in
Mathematics. Springer, 2013.
[BDCF+22] Alessandro Barp, Lancelot Da Costa, Guilherme Fran¸ ca, Karl J Friston, Mark Girolami, Mi-
chael I Jordan, and Grigorios A Pavliotis. Geometric methods for sa mpling, optimisation, inference
and adaptive agents. 2022. Preprint arXiv:2203.10592.
[Cal22] Jeﬀ Calder. The Calculus of Variations . 2022. Available from:
https://www-users.cse.umn.edu/~jwcalder/CalculusOfVariations.pdf.
[CLVW19] Leticia F Cugliandolo, Vivien Lecomte, and Fr´ ed´ eric Van Wij land. Building a path-integral
calculus: a covariant discretization approach. Journal of Physics A: Mathematical and Theoretical ,
52(50):50LT01, 2019.
[DB78] Detlef D¨ urr and Alexander Bach. The Onsager-Machlup fun ction as Lagrangian for the most
probable path of a diﬀusion process. Communications in Mathematical Physics , 60(2):153–170, 1978.
[DCFHP21] Lancelot Da Costa, Karl J Friston, Conor Heins, and Grig orios A Pavliotis. Bayesian mechanics
for stationary processes. Proceedings of the Royal Society A , 477(2256):20210518, 2021.
[dS08] Ana Cannas da Silva. Lectures on Symplectic Geometry , volume 1764 of Lecture Notes in Mathem-
atics. Springer, 2008.
[DWW+18] Purushottam D Dixit, Jason Wagoner, Corey Weistuch, Steve P ress´ e, Kingshuk Ghosh, and
Ken A Dill. Perspective: Maximum caliber is a general variational princip le for dynamical systems.
The Journal of Chemical Physics , 148(1):010901, 2018.
[FCS+22] Karl J Friston, Lancelot Da Costa, Noor Sajid, Conor Heins, Ka i Ueltzh¨ oﬀer, Grigorios A Pavli-
otis, and Thomas Parr. The free energy principle made simpler but no t too simple. 2022. Preprint
arXiv:2201.06387.
[FFGL22] Chris Fields, Karl J Friston, James F Glazebrook, and Micha el Levin. A free energy principle
for generic quantum systems. Progress in Biophysics and Molecular Biology , 2022.
[FHU+21] Karl J Friston, Conor Heins, Kai Ueltzh¨ oﬀer, Lancelot Da Cos ta, and Thomas Parr. Stochastic
chaos and Markov blankets. Entropy, 23(9):1220, 2021.
[Fri12] Karl J Friston. A free energy principle for biological systems . Entropy, 14(11):2100–2121, 2012.
[Fri19] Karl J Friston. A free energy principle for a particular physic s. 2019. Preprint arXiv:1906.10184.
[GDAD20] Kingshuk Ghosh, Purushottam D Dixit, Luca Agozzino, and Ken A Dill. The maximum caliber
variational principle for nonequilibria. Annual Review of Physical Chemistry , 71:213–238, 2020.
[GDG14] Diego Gonz´ alez, Sergio Davis, and Gonzalo Guti´ errez. Ne wtonian dynamics from the principle of
maximum caliber. Foundations of Physics , 44(9):923–931, 2014.
[GN22] Andrea Gambarotto and Auguste Nahas. Teleology and the o rganism: Kant’s controversial legacy
for contemporary biology. Studies in History and Philosophy of Science , 93:47–56, 2022.
[GR89] Ennio Gozzi and Martin Reuter. Algebraic characterization o f ergodicity. Physics Letters B , 233(3-
4):383–392, 1989.
[Gra88] Robert Graham. Lyapunov exponents and supersymmetr y of stochastic dynamical systems. Euro-
33
physics Letters , 5(2):101, 1988.
[GRT89] Ennio Gozzi, Martin Reuter, and William D Thacker. Hidden BRS in variance in classical mech-
anics. II. Physical Review D , 40(10):3363, 1989.
[GS00] Izrail M Gelfand and Richard A Silverman. Calculus of Variations . Courier Corporation, 2000.
[Hal13] Brian C Hall. Quantum Theory for Mathematicians , volume 267 of Graduate Texts in Mathematics .
Springer, 2013.
[HDC22] Conor Heins and Lancelot Da Costa. Sparse coupling and Mar kov blankets: a comment on “How
particular is the physics of the Free Energy Principle?” by Aguilera, M illidge, Tschantz and Buckley.
Physics of Life Reviews , 42:33–39, 2022.
[Hoh16] Jakob Hohwy. The self-evidencing brain. Noˆ us, 50(2):259–285, 2016.
[Lyn22] Owen Lynch. Relational composition of physical systems: a categorical approach. Master’s thesis,
2022.
[MB17] Matteo Mossio and Leonardo Bich. What makes biological orga nisation teleological? Synthese,
194(4):1089–1114, 2017.
[MTSB20] Beren Millidge, Alexander Tschantz, Anil K Seth, and Christ opher L Buckley. On the relation-
ship between active inference and control as inference. In The First International Workshop on Active
Inference, pages 3–11, 2020. Preprint arXiv:2006.12964.
[Mye22] David Jaz Myers. Categorical Systems Theory . 16 February edition,
2022. Available from https://github.com/DavidJaz/DynamicalSystemsBook,
http://davidjaz.com/Papers/DynamicalBook.pdf.
[NS20] Robert W Neel and Ludovic Sacchelli. Uniform, localized asympt otics for sub-Riemannian heat
kernels and diﬀusions. 2020. Preprint arXiv:2012.12888.
[Øks03] Bernt Øksendal. Stochastic Diﬀerential Equations . Springer, 2003.
[Ovc16] Igor V Ovchinnikov. Introduction to supersymmetric theo ry of stochastics. Entropy, 18(4):108,
2016.
[PDCF20] Thomas Parr, Lancelot Da Costa, and Karl J Friston. Mar kov blankets, information geometry
and stochastic thermodynamics. Philosophical Transactions of the Royal Society A , 378(2164):20190159,
2020.
[PGLD13] Steve Press´ e, Kingshuk Ghosh, Julian Lee, and Ken A Dill. P rinciples of maximum entropy and
maximum caliber in statistical physics. Reviews of Modern Physics , 85(3):1115, 2013.
[PGLD15] Steve Press´ e, Kingshuk Ghosh, Julian Lee, and Ken A Dill. R eply to C Tsallis’ conceptual
inadequacy of the Shore and Johnson axioms for wide classes of com plex systems. Entropy, 17(7):5043–
5046, 2015.
[RHT+21] Maxwell J D Ramstead, Casper Hesp, Alexander Tschantz, Rya n Smith, Axel Constant, and
Karl J Friston. Neural and phenotypic representation under the free-energy principle. Neuroscience &
Biobehavioral Reviews, 120:109–122, 2021.
[RS22] Maxwell J D Ramstead and Dalton A R Sakthivadivel. Some minimal notes on notation and minima:
34
a comment on “How Particular is the Physics of the Free Energy Princ iple?” by Aguilera, Millidge,
Tschantz, and Buckley. Physics of Life Reviews , 42:4–7, 2022.
[RSF22] Maxwell J D Ramstead, Dalton A R Sakthivadivel, and Karl J Fr iston. On the map-territory
fallacy fallacy. 2022. Preprint arXiv:2208.06924.
[RSH+22] Maxwell J D Ramstead, Dalton A R Sakthivadivel, Conor Heins, Mag nus Koudahl, Beren Mil-
lidge, Lancelot Da Costa, Brennan Klein, and Karl J Friston. On Baye sian mechanics: a physics of
and by beliefs. 2022. Preprint arXiv:2205.11543.
[Sak22a] Dalton A R Sakthivadivel. A constraint geometry for infere nce and integration. 2022. Preprint
arXiv:2203.08119.
[Sak22b] Dalton A R Sakthivadivel. Regarding ﬂows under the free en ergy principle: a comment on “How
Particular is the Physics of the Free Energy Principle?” by Aguilera, M illidge, Tschantz, and Buckley.
Physics of Life Reviews , 42:25–28, 2022.
[Sak22c] Dalton A R Sakthivadivel. Towards a geometry and analysis f or Bayesian mechanics. 2022. Preprint
arXiv:2204.11900.
[Sak22d] Dalton A R Sakthivadivel. Weak Markov blankets in high-dimen sional, sparsely-coupled random
dynamical systems. 2022. Preprint arXiv:2207.07620.
[Sei12] Udo Seifert. Stochastic thermodynamics, ﬂuctuation theo rems and molecular machines. Reports on
Progress in Physics , 75(12):126001, 2012.
[STvdM+22] Eli Sennesh, Jordan Theriault, Jan-Willem van de Meent, Lisa Feld man Barrett, and Karen
Quigley. Deriving time-averaged active inference from control prin ciples. In The Third International
Workshop on Active Inference . 2022. Preprint arXiv:2208.10601. To appear.
[Tac15] Yuji Tachikawa. N = 2 Supersymmetric Dynamics for Pedestrians , volume 890 of Lecture Notes in
Physics. Springer, 2015.
[Tou09] Hugo Touchette. The large deviation approach to statistic al mechanics. Physics Reports , 478(1-
3):1–69, 2009.
[¨Ust06] Ali S ¨Ust¨ unel. An Introduction to Analysis on Wiener Space , volume 1610 of Lecture Notes in
Mathematics. Springer, 2006.
[VZNS82] Arkady I Va˘ ınshte˘ ın, Valentin I Zakharov, Viktor A Novik ov, and Mikhail A Shifman. ABC of
instantons. Soviet Physics Uspekhi , 25(4):195–215, 1982.
[Wie48] Norbert Wiener. Cybernetics or Control and Communication in the Animal and t he Machine . The
MIT Press, 2019 edition, 1948.