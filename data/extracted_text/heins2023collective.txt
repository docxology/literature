Collective behavior from surprise minimization
Conor Heins∗a,b,c,e, Beren Millidged, Lancelot Da Costae,f,g, Richard P. Mannh,
Karl Fristone,g, and Iain D. Couzin†a,b,c
aDepartment of Collective Behaviour, Max Planck Institute of Animal Behavior, Konstanz D-78457, Germany
bCentre for the Advanced Study of Collective Behaviour, University of Konstanz, Konstanz D-78457, Germany
cDepartment of Biology, University of Konstanz, Konstanz D-78457, Germany
dMedical Research Council Brain Networks Dynamics Unit, University of Oxford, Oxford OX1 3TH, UK
eVERSES Research Lab, Los Angeles, CA 90016, USA
fDepartment of Mathematics, Imperial College London, London SW7 2AZ, UK
gWellcome Centre for Human Neuroimaging, University College London, London, WC1N 3AR, UK
hDepartment of Statistics, School of Mathematics, University of Leeds, Leeds, LS2 9JT, UK
Abstract
Collective motion is ubiquitous in nature; groups of animals, such as fish, birds,
and ungulates appear to move as a whole, exhibiting a rich behavioral repertoire that
ranges from directed movement to milling to disordered swarming. Typically, such
macroscopic patterns arise from decentralized, local interactions among constituent
components (e.g., individual fish in a school). Preeminent models of this process de-
scribe individuals as self-propelled particles, subject to self-generated motion and ‘social
forces’ such as short-range repulsion and long-range attraction or alignment. However,
organisms are not particles; they are probabilistic decision-makers. Here, we introduce
an approach to modelling collective behavior based on active inference. This cognitive
framework casts behavior as the consequence of a single imperative: to minimize sur-
prise. We demonstrate that many empirically-observed collective phenomena, including
cohesion, milling and directed motion, emerge naturally when considering behavior as
driven by active Bayesian inference — without explicitly building behavioral rules or
goals into individual agents. Furthermore, we show that active inference can recover
and generalize the classical notion of social forces as agents attempt to suppress predic-
tion errors that conflict with their expectations. By exploring the parameter space of
the belief-based model, we reveal non-trivial relationships between the individual be-
liefs and group properties like polarization and the tendency to visit different collective
states. We also explore how individual beliefs about uncertainty determine collective
decision-making accuracy. Finally, we show how agents can update their generative
model over time, resulting in groups that are collectively more sensitive to external
fluctuations and encode information more robustly.
∗cheins@ab.mpg.de
†icouzin@ab.mpg.de
1
arXiv:2307.14804v4  [nlin.AO]  14 May 2024
Significance Statement
We introduce a model of collective behavior, proposing that individual members within a
group, such as a school of fish or a flock of birds, act to minimize surprise. This active
inference approach naturally generates well-known collective phenomena such as cohesion
and directed movement without explicit behavioral rules. Our model reveals intricate rela-
tionships between individual beliefs and group properties, demonstrating that beliefs about
uncertainty can shape collective decision-making accuracy. As agents update their genera-
tive model in real-time, groups become more sensitive to external perturbations and more
robust in encoding information. Our work provides fresh insights into understanding collec-
tive dynamics and could inspire strategies in the study of animal behavior, swarm robotics
and distributed systems.
Introduction
The principles underlying coordinated group behaviors in animals have inspired research in
disciplines ranging from zoology to engineering to physics [1–3]. Collective motion in partic-
ular has been a popular phenomenon to study, due in part to its striking visual manifestation
and ubiquity (e.g., swarming locusts, schooling fish, flocking birds and herding ungulates),
and in part to the simplicity of models that can reproduce many of its qualitative features;
like cohesive, directed movement [4–7]. Because of this, collective motion is often cited as a
canonical example of a self-organizing complex system, wherein collective properties emerge
from simple interactions among distributed components.
Popular theoretical models cast collective motion as groups composed of self-propelled
particles (SPPs) that influence one another via simple ‘social forces.’ Early models like the
Vicsek model [6] consider only a simple alignment interaction, where each particle aligns
its direction of travel with the average heading of its neighbors. While oversimplifying
the biological mechanisms in play, SPP models — like the Vicsek model — are useful for
their amenability to formal understanding, e.g., the computation of universal quantities and
relations through hydrodynamic and mean-field limits [8–11].
Recent research has shifted towards more biologically-motivated approaches that aim to
model the specific behavioral circuits and decision-rules that govern individual behaviors
[12–15]. While these models are less analytically-tractable than SPP models, they are more
appealing to domain specialists like biologists, as they can generate predictions about sensory
features in an individual’s environment that are necessary and sufficient for evoking behav-
ior. Furthermore, these predictions can be tested experimentally [14, 16]. This data-driven
approach can thus provide mechanistic insights into the biological and cognitive origins of
decision-making [13, 17].
In this work, we propose a model class that blends the first-principles, theoretical ap-
proach of physical models with biological-plausibility, resulting in an ecologically-valid but
theoretically-grounded agent-based model of collective behavior. Our model class is based
on active inference, a framework for designing and describing adaptive systems where all
2
aspects of cognition — learning, planning, perception, and action — are viewed as a process
of inference [18–21]. Active inference originated in theoretical neuroscience as a normative
account of self-organizing, biological systems as constantly engaged in predictive exchanges
with their sensory environments [22–25].
Collective motion models: from self-propelled particles to
Bayesian agents
In popular self-propelled particle models, an individual’s movement is described as driven
by a combination of social and environmental forces. These forces are often treated as
vectors that capture various tendencies seen in biological collective motion, such as repulsion,
attraction (to neighbors or external targets), and alignment. These forces can then be
combined with various nonlinearities and weights to capture mechanisms of interaction.
In contrast, the active inference approach forgoes specifying explicit vectorial forces, and
instead starts by modelling all behavior as the solution to an inference problem, namely
the problem of inferring the latent causes of sensations. Perception and action strive to
improve the agent’s predictions of sensory inputs, based on its internal model of its world
(see Figure 1A). By equipping this internal model with expectations about the environment’s
underlying tendencies, ‘social forces’ can emerge naturally as agents attempt to suppress
sensory data that are mismatched with their expectations. This perspective-shift offers a
unifying modelling ontology for describing adaptive behavior, while also resonating with
cybernetic principles like homeostatic regulation and process theories of neural function like
predictive coding [26–29].
Active inference blends the construct validity of cognitivist approaches with the first-
principles elegance of physics-based approaches by invoking minimization of a single, all-
encompassing objective function that explains behavior: surprise, or, under certain assump-
tions, prediction error. As an example of this perspective shift, in this work we investigate
a specific class of generative models that can be used to account for the types of collective
behaviors exhibited by animal groups. In doing so, we hope to showcase the benefits of
the framework, while also proposing a testable model class for use in studies of biological
collective motion.
Active inference and generative models of behavior
A common pipeline in the quantitative study of animal behavior involves selecting a can-
didate behavioral algorithm or decision rule that may explain a given behavior, and then
fitting the parameters of the candidate model to experimental or observational data [16, 30].
While these approaches often yield strong quantitative fits to data, the explanatory power of
the models reduces to the interpretation of hard-coded parameters, which often have opaque
relationships to real biological mechanisms or constructs [31].
3
Agent
xt
Social forces
Decision rules
Environment
Classical self-propelled particles
yt
Agent
Sensorimotor 
interface
Environment
at
xt
Inference
Control
Active inference agents
0 2 4 6 8 10 12
Observation, y h ,l
sz ,h
y h ,l
x h ,l
yh,1yh,2
yh,3
yh,4
xh,2
xh,3
xh,4
Focal agent
Generative model  ! p(˜y,˜x)=p(˜y|˜x)p(˜x)
Sector-speciﬁc observations    are sampled from 
the sector-speciﬁc distance  
yh,l
xh,l
Hidden states   comprise the agent’s environmentx
x
yxh,1
xh,l= 1
Kl∑j∈Nl
∥rj−r∥
r=[r1,r2]
Sector-speciﬁc average distance
Observation
0 2 4 6 8 10 12
Observation, y h , l
s z , h
y h , l
x h , l
yh,1
yh,2
yh,3
yh,4
xh,2
xh,3
xh,4
Focal agent
Generative model  
! p(˜y, ˜x) = p(˜y|˜x)p(˜x)
Sector-speciﬁc observations    are sampled from 
the sector-speciﬁc distance  
yh,l
xh,l
Hidden states   comprise the agent’s environmentx
x
y
xh,1
xh,l = 1
Kl ∑j∈Nl
∥rj −r∥
r= [r1,r2]
Sector-speciﬁc average distance
Observation
xt−1
Dynamic generative model Sector-speciﬁc average distance Sector-speciﬁc observations    are sampled 
from the sector-speciﬁc distance  
yh,l
xh,l
Observation  yh,l
A
B
yt−1
xt
yt
xt+1
yt+1
xt
x′  t
x′  ′  t
yt
y′  t
f(xt)
df
dxt
x′  t
g(xt)
dg
dxt
x′  t
Time-series Generalized coordinates
 p(˜x, ˜y)
Figure 1: A: Schematic illustrating the Bayesian perspective in the context of our single
agents, where the hidden states of the environment are segregated from a focal agent by
means of sensory datayt (right panel ofA). This contrasts with classic self-propelled particle
models (left panel ofA), where environmental or social information manifests in terms of
socialforcesonthefocalindividual, whoemitsitsownactionsbasedonhand-crafteddecision-
rules (e.g., changes to heading direction). B: Schematic illustration of the sector-specific
distance tracking. The left panel shows a Bayesian network representation of a dynamic
generative model (i.e., a time-series model), that represents the time-evolution of a latent
variable x1,...,T and simultaneous observationsy1,...T . Shown are both a standard time-series
representation (lower left) and its equivalent representation as generalized coordinates of
motion ˜xt = (xt, x′
t, x′′
t , ...) (right). We show the orders of differentiation used for our model
in practice (3 orders of motion for˜x and 2 orders of motion for˜y). The middle panel ofB
showshoweachcomponentofthevectorialhiddenstate x = (xh,1, ..., xh,L) iscomputedasthe
average nearest-neighbor distance for the neighbors within each visual sector. Observations
are generated as noisy, Gaussian samples centered on the sector-wise distance hidden state
(right panel ofB). This requires the agent to estimate the true hidden statext by performing
inference with respect to a generative model of how sensory data are generatedp(˜y, ˜x).
4
In the active inference framework we rather ask: what is the minimal model an organism
might have of its environment that is sufficient to explain its behavior? Behavior is cast as
the process by which the agent minimizes surprise or prediction error, with respect to this
model of the world [22, 32]. The principle of prediction-error minimization enjoys empirical
support in neuroscience [26, 33] and a theoretical basis in the form of the Free Energy
Principle [22, 23, 25], an account of all self-organizing systems that casts them as implicit
models of their environments, ultimately in the service of minimizing the surprise (a.k.a.,
self-information) associated with sensory states [34–36].
What states-of-affairs count as surprising hinges on a generative model that can assign
a likelihood to sensory data. When it comes to modelling behavior driven by this principle,
the challenge then becomes specifying a generative or world model, whereby a particular
pattern of behavior simply emerges by minimizing surprise.
According to active inference, agents minimize surprise by changing their beliefs about
the world (changing which observations are considered surprising) or by acting on the world
to avoid surprising sensory data. The former strategy is thought to correspond to passive
processes such as perception and learning, whereas the latter corresponds to processes like
active sensing and movement. Action is thus motivated by the desire to generate sensations
that are as least surprising as possible.
In this paper, we describe the motion of mobile, mutually-sensing agents as emerging
from a process of collective active inference, whereby agents both estimate the hidden causes
of their sensations, while also actively changing their position in space in order to minimize
prediction error. In contrast to models that use pre-specified behavioral rules for generat-
ing behavior, generative models entail collective behavior by appealing to a probabilistic
representation of how an organism’s sensory inputs are generated.
A generative model for a (social) particle
We now consider a sufficient generative model for an individual in a moving group. We equip
this individual, hereafter referred as the focal agent, with a representation of a simple random
variable: the local distancex between itself and its neighbors. For generality, we can expand
this into a multivariate random variable to describe a set of distancesx = ( x1, x2, ..., xL)
that track the distance between the focal agent and its neighbors withinL different sensory
sectors (see Figure 1B). We analogize theseL sectors to adjacent visual fields of an agent’s
field of view [37, 38].
The focal agent possesses a model of the distance(s) x and its sensations thereof y.
In particular, our focal agent represents the dynamics ofx using a stochastic differential
equation (a.k.a., a state-space model) defined by a driftf and some stochastic forcingω —
we refer to this component of the generative model as the dynamics model. The stochastic
term ω captures the agent’s uncertainty about paths ofx over time. The agent also believes
it can sensex via observationsy, mediated by a sensory map, which we call the observation
model. This is defined by some (possibly non-linear) functiong with additive noisez. The
agent’s generative model is then fully described by a pair of equations that detail 1) the
5
time-evolution of the distance and 2) the simultaneous generation of sensory samples of the
distance:
D˜x = ˜f + ˜ω ˜y = ˜g + ˜z (1)
All random variables are described using generalized coordinates of motion with the
convention ˜q = {q, q′, q′′, ...}. Generalized coordinates allow us to represent the trajectory
of a random variable using a vector of local time derivatives (position, velocity, acceleration,
etc.). The matrixD is a generalized derivative operator that moves a vector of generalized
coordinates up one order of motion D(x, x′, x′′, ...)⊤ = ( x′, x′′, x′′′, ...)⊤. The generalized
functions ˜f and ˜g therefore operate on vectors of generalized coordinates (seeSI Appendix,
Section A for details on generalized coordinates and filtering).
Generalized filtering and active inference
An agent equipped with this dynamic generative model then performs active inference by
updating its beliefs (state estimation, or filtering) and control states (action) to minimize
surprise.
Inference entails updating a probabilistic belief over hidden states˜x in the face of sensory
data ˜y. Our agents solve this filtering problem using generalized filtering [39, 40], an algo-
rithm for approximate Bayesian inference and parameter estimation on dynamic state-space
models. This is achieved by minimizing the variational free energyF, a tractable upper
bound on surprise (i.e., negative log evidence or marginal likelihood). The agent minimizes
thefreeenergywithrespecttoabeliefdistribution q(˜x) withparameters ν; thisapproximates
the true posteriorqν(˜x) ≈ p(˜x|˜y), which is the optimal solution in the context of Bayesian
inference. The true posterior p(˜x|˜y) is difficult to compute for many generative models
due to the difficult calculation of the marginal (log) likelihoodln p(˜y). Variational methods
circumvent this intractable marginalization problem by replacing it with a tractable opti-
mization problem: namely, adjusting an approximate posterior to match the true posterior
by minimizingF with respect to its (variational) parametersν.
We parameterizeq(˜x) as a Gaussian with mean-vector˜µ, which is a natural choice for
this generative model since the assumption of normally-distributed noises˜z, ˜ω imply that
the true posterior will be Gaussian near the posterior modearg maxp(˜x|˜y). The implicit
Gaussian (i.e., Laplace) assumption is ubiquitous in the modelling and signal processing
literature [41] and can be regarded as a ‘minimal’ assumption, by appeal to things like
the central limit theorem and related principles (e.g., Jaynes’ maximum entropy principle).
According to generalized filtering,˜µ is updated using a sum of prediction errors:
6
d˜µ
dt ∝ −∇˜µF(˜µ, ˜y)
∝ ˜εz − ˜εω
where ˜εz = ˜y − ˜g(˜µ)
˜εω = D˜µ − ˜f(˜µ) (2)
The ensuing evidence accumulation can be regarded as a natural generalization of predic-
tive coding [26, 42, 43], where beliefs about local trajectories˜µ are updated using a running
assimilation of sensory and model prediction errors:˜εz and ˜εω, respectively. For notational
clarity, we have omitted terms that weigh these prediction errors; the so-called generalized
sensory and model precisions˜Πz, ˜Πω, which encode the agent’s assumptions about the mag-
nitude and correlation structure of noise. The importance of these precisions will become
clear later, when understanding the relationship between precision-weighted prediction errors
and social forces.
While inference entails changing the approximate posterior means ˜µ to best explain
sensory data, action entails changing the data itself to better match the data to one’s current
beliefs. Similar to the update scheme in (A.21), actions are also updated by minimizing free
energy:
da
dt = −∇aF(˜µ, ˜y(a))
= −∇˜yF(˜µ, ˜y(a))∇a˜y(a)
∝ −˜ε⊤
z ∇a˜y(a) (3)
Actions thus are updated using a product of sensory prediction errors˜εz and a ‘sensori-
motor contingency’∇a˜y(a) or reflex arc. This sort of ‘reflexive action’ — where control is
simply targeted at minimizing sensory prediction errors — underlies active inference accounts
of motor control [27, 44], and can be formally related to proportional-integral-derivative
(PID) control [45]. These prediction errors measure how far an agent’s observations are from
its expectations; the agent then acts using (3) to minimize this deviation. Active inference
agents are thus driven to act in a way that aligns with their (biased) expectations about the
world [46]. In the next section, we will see how building a particular type of bias into each
agent’s generative model leads to the appearance terms in (3) that resemble social forces.
Social forces as a consequence of predictive control
In particular, we take the agent’s action to be its heading directiona = v, and examine the
case where the agent observes the distance to its neighbors within a single sensory sector,
i.e., L = 1, x = (x1). We distinguish the agent’s representation of the distancex from the
actual distance using the subscripth. Thereforexh = (xh,1, xh,2, ..., xh,L) denotes the average
7
distances (and corresponding sensory samplesyh) calculated using the actual positions of
other agents. For the case ofL = 1, and assuming the agent observes both the distance and
its rate of changey′
h,1, this is:
xh,1 = 1
K
X
j∈Nin
∥rj − r∥ yh,1 = xh,1 + zh,1
x′
h,1 = dxh,1
dt y′
h,1 = x′
h,1 + z′
h,1 (4)
Nin is the set of neighbors within the agent’s single sensory sector,K is the size of this
set, r is the focal agent’s position vector, andrj is the position vectors of neighborj. The
sensory observation of the generalized distance˜yh = ( yh,1, y′
h,1) is a sample of the hidden
state, perturbed by some additive noises˜z = (zh,1, z′
h,1). By expanding the active inference
control rule in (3), we arrive at the following differential equation for the heading vector:
dv
dt = ξ′
z∆ˆr
ξ′
z = π′
z,1(y′
h,1 − µ′
h,1)
∆ˆr = 1
K
X
j∈Nin
∆rj
∥∆rj∥, ∆rj = rj − r (5)
The average vector∆ˆr is exactly the (negative) ‘sensorimotor contingency’ term∇a˜y(a)
from (3) (seeSI Appendix, Section A for detailed derivations):
∇v ˜y(v) = ∇ry = 1
K
X
j∈Nin
r − rj
∥r − rj∥ = −∆ˆr (6)
The simple action update in (5) means that the focal agent moves along a vector pointing
towards the average position of its neighbors. Whether this movement is attractive or repul-
sive is determined by the sign of the precision-weighted prediction errorξ′
z = π′
z,1(y′
h,1 −µ′
h,1),
and its magnitude depends on two factors: 1) the sensory precision or ‘reliability’π′
z,1 that
the agent affords observations of the rate-of-change ofyh,1; and 2) the degree to which these
rate-of-change observations deviate from their predicted valuey′
h,1 − µ′
h,1.
The presence of both attractive and repulsive forces depends on the agent’s model of the
distance dynamics, captured by the functional form of˜f. In particular, consider forms of˜f
that relaxx to some attracting fixed pointη >0. Equipped with such a stationary model of
the local distance, inference dynamics (c.f., (A.21)) will constantly bias its predictionsµ ac-
cording to the prior belief that the distance is pulled toη. Given this biased dynamics model
and the action update in (3), such an agent will move to ensure that distance observations
˜yh are equal to the fixed pointη.
This action update shows immediate resemblance to the attractive and repulsive vectors
common to social force-based models [4, 5, 7], which often share the following general form:
8
Fattr ∝
X
j∈ZA
rij
∥rij∥
Frepul ∝ −1
K
X
j∈ZR
rij
∥rij∥
(7)
where ZA, ZR refer to distance-defined zones of attraction or repulsion, respectively. In
the active inference framework, these social forces emerge as the derivative of the observa-
tions with respect to action∇a ˜y, where the sign and magnitude of the precision-weighted
sensory prediction errorξ′
z determines whether the vector is attractive (towards neighbors)
or repulsive (away from neighbors). The transition point between attraction and repulsion
is therefore given byη, the point at which prediction errors switch sign.
An important consequence of this formulation is that, unlike the action rule used in social
force-based models, the ‘steady-state’ solution occurs when all social forces disappear (when
prediction errors vanish). In this case, the agent ceases to change its heading direction and
adopts its previous velocity. This occurs when the agent’s sensations align with its (biased)
predictions yh,1 ≈ η. In classic SPP models, this is equivalent to the different social force
vectors exactly cancelling each other.
We can therefore interpret social force-based models as limiting cases of distance-inferring
active inference agents, because one can conceive of social forces as just those forces induced
by free energy gradients; namely, the forces that drive belief-updating. In the case of our
active inference agents, attractive and repulsive forces emerge naturally when we assume A)
agents model the local distance dynamics as an attractor with some positive-valued fixed
point η; B) agents can act by changing their heading direction and C) agents observe at least
the first time derivative of their observations (e.g.,y′
h,1, but seeSI Appendix, Section A for
detailed derivations).
It is worth highlighting the absence of an explicit, vectorial alignment force in this model,
consistent with experimental findings in two species of fish [12, 17]. The heading vectors of
neighbors is nevertheless implicitly incorporated into the calculation of first-order predic-
tion errors ξ′
z via the first order hidden statex′
h,1 (c.f., (4) and SI Appendix, Eq.(A.40)).
In particular, thex′
h,1 (from which the observationsy′
h,1 are sampled) is equivalent to the
‘relative velocity’ term used in so-called selective attraction and repulsion models, where the
instantaneous rate at which neighbours approach or move away, is used to drive movement
[47]. However, explicit alignment forces as seen in the Vicsek model [6] and 2- and 3-Zone
Couzin models [7, 48] can also be recovered if we assume agents have a generative model of
the average angle between their heading vector and those of their neighbors (seeSI Appendix,
Section B for derivations of alignment forces).
9
Multivariate sensorimotor control
Having recovered social forces as free energy gradients in the case of a single sensory sector
(L = 1), we now revisit the general formulation of the generative model’s state-space, where
the hidden variablex is treated as anL-dimensional vector state:x = (x1, x2, ..., xL), with
correspondingly L-dimensional observationsy = (y1, y2, ..., yL).
Specifically, we consider eachxl to represent the average distance-to-neighbors within
one of a subset of adjacent sensory sectors, where each sector is offset from the next by
a fixed inter-sector angle (see Figure 1B for a schematic of the multi-sector set-up). The
rest of the generative model is identical; the agents estimate these distances (and their
temporalderivatives x′
l, x′′
l , ...)whilechangingtheirheadingdirectiontominimizefreeenergy.
Following the same steps as in the case of a single sector, the resulting update rule forv is
a weighted sum of ‘sector-vectors’, where generalized observations from each sector-specific
modality ˜yl are used to compute the prediction errors that scale the corresponding sector-
vector. This generalizes the scalar-vector product in (5) to a matrix-vector product:
dv
dt = ˜ξ
⊤
z ∆ ˆR
∆ ˆR = −


∇v ˜y1
∇v ˜y2
...
∇v ˜yL

 (8)
where now the (negative) sensorimotor contingency−∇a˜y = ∆ ˆR is a matrix whose rows
contain the partial derivatives∇v ˜yl (i.e. the ‘sector-vectors’). Each sector-vector is a vector
pointing towards the average neighbor position within sectorl.
Numerical results
Given a group of active inference agents — equipped with the generative models described
in previous sections — it is straightforward to generate trajectories of collective motion by
integrating each agent’s heading vector over time:˙ri = vi, i∈ {1, 2, ..., N} where N is the
number of agents. We update all heading directions{vi}N
i=1 and beliefs {˜µi}N
i=1 in parallel
via a joint gradient descent on their respective free energies:
˙v1 = −∇v1 F(˜µ1, ˜y1) ˙˜µ1 = −∇˜µ1 F(˜µ1, ˜y1)
˙v2 = −∇v2 F(˜µ2, ˜y2) ˙˜µ2 = −∇˜µ2 F(˜µ2, ˜y2)
... ...
˙vN = −∇vN F(˜µN , ˜yN ) ˙˜µN = −∇˜µN F(˜µN , ˜yN ) (9)
10
A
B Polarization Milling probability
Polarized Milling Disordered
Figure 2: A: Example snapshots of different collective states in schools ofN = 50 active
inference agents. Each line represents the trajectory of one individual, and color gradient
represents time, from earliest (light blue) to latest (purple). The polarized regime in the
left panel was simulated with the default parameters listed in supplementary Table E1. The
milling regime (middle panel) was achieved by increasing the variance of velocity fluctuations
(encoded inσ2
z′,h) from0.01 to 0.05 (relative to the default configuration) and increasingλz
from 1.0 to 1.2. The disordered regime was achieved by increasing the sensory smoothness
parameter to 2.0 and decreasing η from 1.0 to 0.5 and α from 0.5 to 0.1 (relative to the
default configuration). B: Average polarization (left) and milling probability (right) shown
as a function of the two factorized components of the sensory precision,Γz (log-transformed)
and λz. For each combination of precision parameters, we ran500 independent trials of ‘free
schooling,’ and then averaged the quantities of interest across trials. Each ‘free schooling’
trial lasted15 seconds (1500 time steps withdt = 0.01s); the time-averaged metrics (polar-
ization and milling probability, respectively, were computed from the last10 seconds of the
trial.
11
For the simulation results shown here, each agent tracks the average distancexl within
a total of L = 4 sensory sectors that each subtend 60◦ (starting at −120◦ and ending
at +120◦, relative to the focal agent’s heading direction) and observe the sector-specific
distances calculated using all neighbors lying within5.0 units of the focal agent’s position.
Each agent represents the vector of local distances as a generalized state with 3 orders of
motion: ˜x = {x, x′, x′′}, ˜µ = {µ, µ′, µ′′}. Agents can observe the first and second orders
of the distance˜y = {y, y′}, i.e. the distance itself and its instantaneous rate-of-change. In
the numerical results to follow, we use active inference to study the relationship between the
properties of individual cognition (e.g., the parameters of agent-level generative models) and
collective phenomenology.
Collective regimes
Simulated groups of these distance-inferring agents display robust, cohesive collective motion
(see Figure 2A and Supplemental Movies S1-S5). Figure 2A displays examples of different
types of group phenomena exhibited in groups of active inference agents, whose diversity
and types resemble those observed in animal groups [49, 50] and in other collective motion
models [6, 7, 51]. These range from directed, coherent movement with strong inter-agent
velocity correlations (‘polarized motion’) to group rotational patterns, like milling, which
features high angular momentum around the group’s center-of-mass.
Relating individual beliefs to collective outcomes
In all but the most carefully constructed systems [31, 52, 53], the relationship between
individual and collective representations is often opaque. In particular, the relationship
between individual level uncertainty or ‘risk’ and collective behavior is an open area of
research. For instance, some research has indicated that increased risk-sensitivity at the level
of the individual may lead to decreased risk-encoding at the collective level [54]. Inspired by
these observations, we use active inference to examine the quantitative relationship between
uncertainty at the individual level and collective phenomenology. We begin by examining
common metrics of group motion like polarization and angular momentum [7]. In Figure
2B we explore how polarization and angular momentum are affected by two components
of agent-level sensory uncertainty (i.e., inverse sensory precision): 1) the absolute precision
that agents associate to sensory noise and 2) the autocorrelation or ‘smoothness’ associated
to that noise.
These components are encoded in each agent’s observation model, which assumes gener-
alized distance observations˜y are normally-distributed around the generalized state˜x:
P(˜y|˜x) = N(˜y; ˜x, ˜Σz) (10)
Wherewefocusontheparameterizationoftheinverseofthecovariancematrix, a.k.a., the
precision matrix ˜Πz =

˜Σz
−1
. This precision matrix factorizes into two sub-matrices, one
12
encoding the amplitude of random fluctuationsz and one encoding their temporal smooth-
ness, i.e., the inverse of the covariance between different derivatives of random fluctuations
(e.g., betweenz and z′):
˜Πz = Πz ⊗ ˜Πz
where Πz =


Γz,1 0 . . . 0
0 Γ z,2
... ...
0 Γ z,L

 (11)
˜Πz =
1 0
0 2 λ2
z

(12)
Intuitively,Γz encodes the variance or amplitude that the agent associates with the noise
in each of its L sensory sectors zl, and λz encodes how ‘smooth’ the agent believes the
noise is [40, 55]. A higher value ofλz implies that the agent believes sensory noise is more
serially-correlated (e.g., random fluctuations in optical signals caused by smooth variations
in refraction due to turbulence in water). Section C.1 of theSI Appendix shows how the
smoothnessparameter λz canbederivedfromanoiseprocesswithaGaussianautocorrelation
function. The consequences of this parameterization can be mapped back to the first-order
prediction errorsξ′
z that drive action in (5) and (8):
ξ′
z =


2Γz,1λ2
z(y′
h,1 − µ′
h,1)
2Γz,2λ2
z(y′
h,2 − µ′
h,2)
...
2Γz,Lλ2
z(y′
h,L − µ′
h,L)

 (13)
Here, we have simply written the precision assigned to noisezh,l in a particular sensory
sector as a product of the amplitude and smoothness parameters:π′
z,l = 2Γz,lλ2
z.
Figure 2B shows how the different components (amplitude and smoothness) of the agent’s
beliefs about uncertainty determine group behavior, as quantified by average polarization
and milling probability. Average polarization is defined here as the time average of the
polarization of the group, where the polarization at a given timep(t) measures the alignment
of velocities of agents comprising the group [7, 56]:
ˆp = 1
T − t0
TX
t=t0
p(t) p(t) = 1
N ∥
NX
i=1
vi(t)∥ (14)
Note that the time average is calculated once steady-state has been reached, where the
beginning of this state is indicated byt0 (for the heatmaps shown in 2B, we calculate these
average metrics witht0 = 5s). High average polarization indicates directed, coherent group
movement. The left panel of Figure 2B shows howΓz and λz contribute to the average
13
polarization of the group. An increase in either parameter causes polarization to decrease
and angular momentum to increase, reflecting the transition from directed motion to a
milling regime, where the group rotates around its center of mass. We calculate the milling
probability (c.f. right panel of Figure 2B) as the proportion of trials where the time-averaged
angular momentum surpassed0.5. The average angular momentum can be used to quantify
the degree of rotational motion, and is calculated as the time- and group-average of the
individual angular momenta around the groups’ center of massc:
ˆm = 1
T − t0
TX
t=t0
m(t) m(t) = 1
N ∥
NX
i=1
ric(t) × vi(t)∥ (15)
where ric is a relative position vector for agenti, defined as the vector pointing from the
group centerc to agenti’s position:ri −c. We observed a large range ofΓz and λz for which
the milling regime (high average angular momentum) was stable (Figure 2B, right side).
This stands in contrast to earlier self-propelled particular models like the original 3-zone
Couzin model, where milling was only stable under a relatively limited range of parameters
[7].
These collective changes can be understood by recalling how first-order prediction errors
ξ′
z (and thus the velocity update) depend onΓz and λz:
ξ′
z ∝ 2Γzλ2
z (16)
In practice, this means that as the group believes in more predictable (less rough) first-
order sensory informationy′
z, the group as a whole is more likely to enter rotational, milling-
like regimes. However, the enhancing effect of these first-order prediction errorsξ′
z on ro-
tational motion is bounded; if prediction errors are over-weighted (e.g. highΓz and/or λz),
the group becomes more polarized again and likely to fragment (seeSI Appendix, Fig. E1).
This fragmentation probability occurs at both low and high levels ofΓz and λz, implying
that there is an optimal range of individual-level sensory precision where cohesive group
behavior (whether polarized or milling) is stable. Thus, our model predicts that assuming
one’s sensory information is highly-precise is neither required, or in fact even desirable, for
animals in order to facilitate collective motion.
We have seen how one can use active inference to relate features of individual-level beliefs
(in this case, beliefs about sensory precision) to collective patterns, focusing in the present
case on common metrics for studying collective motion like polarization and the tendency
to mill.
In the following sections, we move from looking at group-level patterns that occur during
free movement, to studying the consequences of individual-level uncertainty for collective
information-processing. We begin by investigating how collective information transfer de-
pends on individual-level beliefs about the relative precisions associated with different types
of sensory information.
14
A B
Proportion informed
Accuracy
Average 
accuracy
log   Γz−Social
log   Γz−Target
Figure 3: A: Collective accuracy as a function of proportion informed orpinf for differing
values of the sensory precision assigned to social observationsΓz−Social. Average accuracy for
each condition (combination ofpinf , Γz−Social, Γz−Target) was computed as the proportion of
successful hits across500 trials. Here, the average accuracy is further averaged across all the
values of theΓz−Target parameter, meaning each accuracy here is computed as the average of
15000 total trials (500 trials per condition× 30 different values ofΓz−Target). B: Collective
accuracy as a function of both the social and target precisions (Γz−Social, Γz−T arget, shown
in log-scale) averaged across values ofpinf ranging from pinf = 0.15 to pinf = 0.40. Each
condition’s accuracy was computed as the proportion of accurate decisions from500 trials.
15
Collective information transfer
In this section, we take inspiration from the collective leadership and decision-making liter-
ature to investigate how individuals in animal groups can collectively navigate to a distant
target [48, 57–59]. This phenomenon is an example of effective leadership through collective
information transfer and is remarkable for a number of reasons; one that speaks to its emer-
gent nature, is the fact that these collective decisions are possible despite — and indeed even
because of — the presence of uninformed individuals in the group [57]. Figure 3A shows
that active inference agents engaged in this task reproduce a result from earlier work [48] on
the relationship between the proportion of uninformed individuals and collective accuracy.
Namely, as the proportion of informed individuals increases, so does the accuracy of reaching
the majority-preferred target. In the same vein as earlier sections, we also investigated the
dependence of this effect, as well as the average target-reaching accuracy, on individual-level
beliefs.
We operationalize the notion of an agent being ‘informed’ (about an external target) by
introducing a new latent variable to its generative model; this variablextarget represents the
distance between the informed agent’s positionr and a point-mass-like target with position
vector T = [ T1, T2]. We thus define this new hidden state and observation as follows:
xtarget = ∥T − r∥, ytarget = xtarget + ztarget. Just like the ‘social’ distance observationsyh,
this target distance observation ytarget represents a (potentially-noisy) observation of the
true distance xtarget. As before, the agent represents both the target distancextarget and
its observations ytarget using generalized coordinates of motion. Each informed agent has
a dynamics model of ˜xtarget, whereby they assume the target-distance is driven by some
drift function ftarget(xtarget) = −αtxtarget which relaxes to0. As with the social distances,
we truncate the agent’s generalized coordinates embedding of the target distance to three
orders of motion and the generalized observations to two orders of motion.
Each informed agent maintains a full posterior belief˜µ = (˜µ1, ˜µ2, ...,˜µL, ˜µtarget) about
the local distances˜x1, ˜x2, ...,˜xL as well as the target distance˜xtarget.
Using identical reasoning to arrive at the action updates in (5) and (8), one can augment
the matrix-vector product in (8) with an extra sensorimotor contingency and prediction error
that represents target-relevant information:
dv
dt = ˜ξ
⊤
z

∆ ˆR
∆T

∆T = −∇v ˜ytarget = T − r
∥T − r∥ (17)
This matrix-vector product can then be seen as a weighted combination of social and
target vectors, with the weights afforded to each equal to their respective precision-weighted
prediction errors:
16
dv
dt = ξsocial∆ ˆR| {z }
Social vector
+ ξtarget∆T| {z }
Target vector
(18)
This expression is analogous to the velocity update in Equation (3) of Ref. [48], where
a ‘preferred direction’ vector is integrated into the agent’s action update with some pre-
determined weight. This weight is described as controlling the relative strengths of non-
social vs. social information. For active inference agents, the weighting of target-relevant
information emerges naturally as a precision-weighted prediction error (here represented as
ξtarget), and the target-vector itself is equivalent to a sensorimotor reflex arc, that represents
the agent’s assumptions about how the local flow of the target distancey′
target changes as a
function of the agent’s heading directionv. An important consequence of this construction,
is that, unlike in previous models where this weight is ‘baked-in’ as a fixed parameter, the
weight assigned to the target vector is dynamic, and fluctuates according to how much the
agent’sexpectationsaboutthetargetdistance ˜µtarget predictthesensedtargetdistance ytarget.
Using this new construction, we can simulate a group of active inference agents, in which
some proportionpinf of agents represent this extra set of target-related variables as described
above. To generate ˜ytarget observations for these informed individuals, we placed a spatial
target ata fixed distanceawayfrom the group’scenter-of-mass and thenallowed theinformed
individuals to observe the generalized target distance ˜ytarget = ( ytarget, y′
target). We then
integratedthecollectivedynamicsovertimeandmeasuredtheaccuracywithwhichthegroup
was able to navigate to the target (see Materials and Methods for details). By performing
hundreds of these trials for different values ofpinf , we reproduced the results of Ref. [48] in
Figure 3. We see that as the number of informed individuals increases, collective accuracy
increases. However, this performance gain depends on the agents‘ beliefs about sensory
precision, which we now dissociate into two components:Γz-Social ( the precision assigned
to the social distance observations) andΓz-Target (the precision assigned to target distance
observations). By varying these two precisions independently, which respectively scaleξsocial
and ξtarget in (18), we can investigate the dependence of collective accuracy on the beliefs of
individual agents about the uncertainty attributed to different sources of information.
Figure 3A shows the average collective accuracy as a function ofpinf , for different levels
of the social distance precisionΓzSocial. The pattern that emerges is that the social preci-
sion, that optimizes collective decision-making, sits within a bounded range. The general
effect of social precision is to essentially balance the amplification of target-relevant infor-
mation throughout the school, with the need for the group to maintain cohesion. When
social precision is too high, agents over-attend to social information and are not sensitive
to the information provided by informed individuals; when it is too low, the group is likely
to fragment and will not accurately share target-relevant information; meaning only the in-
formed individuals will successfully reach the target. Figure 3B shows that a similar optimal
precision-balance exists for ΓzTarget. Here, we show average collective accuracy (averaged
across values of pinf as a function of social- and target-precision. Maximizing collective
accuracy appears to rely on agents balancing the sensory precision they assign to different
17
sources of information; under the active inference model proposed here, this balancing act
can be exactly formulated in terms of the variances (inverse precisions) afforded to different
types of sensory cues.
Online plasticity through parameter learning
The ability of groups to tune their response to changing environmental contexts, such as
rapid perturbations or informational changes, is a key feature of natural collective behavior
[15, 54]. However, many self-propelled particle models lack a generic way to incorporate this
behavioral sensitivity [48] and exhibit damped, ‘averaging’-like responses to external inputs
[60]. This results from classical models usually equipping individuals with fixed interaction
rules and constant weights for integrating different information sources. While online weight-
updating rules and evolutionary algorithms have been used to adaptively tune single-agent
parameters in some cases [48, 59, 61], these approaches are often not theoretically principled
and driven by specific use-cases [with notable exceptions [62–64]].
Active inference offers an account of tune-able sensitivity, using the same principle used
to derive action and belief-updating in previous sections: minimizing surprise. In practice,
this sensitivity emerges when we allow agents to update their generative models per se in
real-time. Updating generative model parameters over time is often referred to as “learning”
in the active inference literature [65], since it invokes the notion of updating beliefs about
parameters rather than states, where parameters and states distinguish themselves by fast
and slow timescales of updating, respectively. We leverage this idea to allow agents to adapt
their generative models and thus adapt their behavioral rules, referring to this process as
plasticity, in-line with the notion of short-term plasticity in neural circuits [66]. To enable
agents to update generative model parameters, we can simply augment the coupled gradient
descent in (9) with an additional dynamical equation, this time by minimizing free energy
with respect to model parameters, which we subsume into a setθ:
˙θ = −∇θF(˜µ, ˜y, θ) (19)
The generative model parametersθ represent the statistical contingencies or regularities
agents believes govern their sensory world; this includes the various precisions associated
with sensory and process noises˜Πz, ˜Πω and the parameters of the dynamics and observation
models, ˜f, ˜g. Since the free energy is a smooth function of all the generative model parame-
ters, in theory learning can be done with respect to any parameter using procedure entailed
by (19).
In practice, combining parameter-learning with active inference usually implies a separa-
tion of timescales, whereby learning or plasticity occurs concurrently to state inference and
action but at a slower update rate. In all the results shown here, agents update parame-
ters an order of magnitude more slowly than they update beliefs or actions. To furnish a
interpretable example of plasticity, in the simulations described here, we enabled agents to
update their beliefs about the sensory smoothness parameterλz. We chose sensory smooth-
ness due to its straightforward relationship to the magnitude of sensory prediction errors
18
y2
y3
y4
y1
μ1
μ2
μ3
μ4
Stimulated
agent
Pseudo-motion 
stimulus Stimulus-evoked neural activity
y1 y2 y3 y4
y2
y3
y4
y1
μ1
μ2
μ3
μ4
Stimulated
agent
Pseudo-motion 
stimulus
Stimulus-evoked 
neural activity
y1 y2 y3 y4
``
A B
C
Stimulus time 
+1
-1
0
2.5 5.0 7.5 10.0 12.5 15.0 17.5
0.2
0.4
0.6
0.8
1.0
0.0
Time since perturbation (seconds)
Perturbation size (number of agents changed)
5 10 15 20 25
Perturbation size (number of agents changed)
5 10 15 20 25
Group turning magnitude (! )cos(θ)
0.2
0.4
0.8
1.0
0.0 Integrated turning magnitude
0.6
1.2
1.4
0.2
0.4
0.8
1.0
0.0 Probability of response
0.6
Self-propelled particles
Learning disabled
Learning enabled
Learning disabled
Learning enabled
Pre-perturbation period (same histories)
Learning disabled, post-perturbation
Learning enabled, post-perturbation
Figure 4: A: Schematic of the sensory perturbation protocol. The ‘pseudo-motion’ stim-
ulus consists of repetitively perturbing the agent’s sensory sectors with a moving wave of
prediction errors in the agent’s velocity-observation modalityy′
h. The top panel shows stim-
ulus pattern as a heatmap over (amplitude over time) with two repetitions, starting from
negative (red, sectors1 and 2) and transitioning to positive (blue, sectors3 and 4) prediction
errors. The sign-switch in the stimulus (from negative to positive) mimics a moving object
that first moves towards focal individual and then moves away. The temporal order of the
stimulus across the sectors can be used to selectively emulate a right-moving vs. left-moving
object, relative to the focal individual’s heading-direction. The bottom panel shows how
the stimulated agent’s beliefs about the distance hidden stateµ changes over the course
of the motion stimulus, with these beliefs being analogized to hypothetical neural activity.
B: Response magnitude to a perturbation in presence or absence of parameter learning.
Left panel: example pair of 2-D trajectories of active inference agents with matched pre-
perturbation histories, in response to an individual perturbation. The ability to perform
parameter-learning is left on in one stochastic realization (green) and turned off in the other
(blue), following the perturbation. Right panel: initialization-averaged collective responses
(group turning angle) to perturbation of active inference agents when learning is enabled or
disabled. The perturbation response of a 2-zone self-propelled particle model (purple line)
based on [48] is also shown for reference.C: Collective response as a function of the num-
ber of perturbed individuals, comparing simulations where parameter-learning is enabled to
those where it’s disabled. Shown is the mean response with highest density regions (HDRs)
of integrated turning magnitude within 500-1000 ms of the perturbation (left) and response
probability (right) computed fromNi = 200 independent initializations of each condition.
For each initialization, the average metric is computed acrossNr = 50 independent real-
izations that were run forward from the same point in time, following a sensory prediction
error perturbation (to a randomly-chosen set of perturbed agents). Response probability is
computed as the proportion of independent realizations, per initialization, where the group
turning rate exceededπ radians within the first 10 seconds of the perturbation.
19
(c.f. the relation in (16) andSI Appendix, Section C). As agents tuneλz to minimize free
energy, belief updating and action will at the same time become quadratically more or less
responsive to sensory information.
One example of where behavioral plasticity is crucial for collective information processing
is a group’s ability to rapidly amplify behaviorally-relevant information, e.g., detecting the
presence of a predator [67–69]. To study the effect of behavioral plasticity on collective re-
sponsiveness, weperturbedsingleagentsingroupsofactiveinferenceagentswhileenablingor
disabling online plasticity. We perturbed groups by inducing transient ‘phantom’ prediction
errors in random subsets of agents and measuring the resulting turning response of the group
(see Materials and Methods for details). These prediction errors were structured (see Figure
4A) to mimic a transient visual stimulus, e.g., a loom stimulus or approaching predator [70],
which reliably induces a sustained turning response in the chosen individual [60]. Figure 4
shows the effect of enabling plasticity on the size and sensitivity of collective responses to
these perturbations. Not only do plasticity-enabled groups respond more strongly to per-
turbations of single-agents, compared to their plasticity-disabled counterparts (4B), but the
magnitude of the collective response is also more sensitive to the size of the perturbation
(4C). As has been measured in biological collectives [71], the plasticity-enabled groups col-
lectively encode the size of perturbations with higher dynamic range than plasticity-disabled
controls.
The active inference framework provides a flexible and theoretically-principled approach
to modeling adaptive, collective behavior with tuneable sensitivity, that eschews ad-hoc
update rules or expensive evolutionary simulations. The plasticity mechanism proposed here
is not limited to updating beliefs about sensory smoothness: it can be extended to update
beliefs about any model parameter using the same principle. The ability to adapt generative
model parameters in real-time represents a promising avenue for future research in active
inference and collective behavior, and may lead to more biologically-plausible hypotheses
about the mechanisms underlying adaptive responses in the natural world.
Discussion
We have proposed active inference as a flexible, cognitively-inspired model class that can
be used in the theoretical study of collective motion, as well as in empirical settings as an
individual-level model of behavior. By framing behavior as the consequence of prediction-
error minimization — with respect to an individual’s world model — we offer examples of
how naturalistic collective motion emerges in, where individual behavior is driven by the im-
perative to minimize the surprisal associated with sensory signals. Under mild distributional
assumptions, this surprise is scored by an interpretable proxy; namely, prediction error. In
the particular case of collective motion, a group of active inference agents equipped with
a simple generative model of local social information can recover and generalize the social
forces that have been the core mechanism in classical SPP models of collective motion. The
active inference framework also provides a probabilistic interpretation of ad-hoc ‘weight’ pa-
rameters that are often used in these models, in terms of the precisions that agents associate
20
to different types of sensory information.
We have also shown how the active inference framework can be used to characterize
the relationship between generative model parameters and emergent information-processing
capacities, as measured by collective information transfer and responsiveness to external
perturbations. Active inference’s generality allows us to relax the typically-static behavioral
rules of SPP models, by enabling agents to flexibly tune their sensitivity to prediction errors.
This is achieved via principled processes like parameter learning (i.e., ‘plasticity’), and can
be used to model naturalistic features of collective behavior, such as the tendency to amplify
salient (i.e., precise) information, that have largely evaded modelling in the SPP paradigm,
except in cases where adaptation rules are explicitly introduced [48, 59]. However, when
we simply allow agents to update parameters, in addition to beliefs and agents, using the
principle of surprise-minimization, many hallmarks of these naturalistic behaviors can be
easily obtained.
The surprise minimization approach adopted here is both theoretically grounded in fun-
damental physical, cybernetic and informational principles [23, 72–74] while also biologically-
inspired, due to the scalability of the belief and action update rules, which are hypothesized
to be implementable on neuronal circuits [43]. Our approach thus also harmonizes with
modern ‘data-driven’ approaches in behavioral biology, that aim to quantitatively estimate
the behavioral algorithms used by different biological systems directly from experimental
data [13–15].
By providing a flexible modeling approach that casts perception, action, and learning
as manifestations of the single drive to minimize surprise, we have highlighted active infer-
ence as a toolbox for studying collective behavior in natural systems. Future work in this
area could explore how the framework can be used to investigate other forms of collective
behavior (not just collective motion), like multi-choice decision-making, social foraging and
communication [75, 76]. The results shown in the current work serve primarily as a proof of
concept: we started by writing down a specific, hypothetical active inference model of agents
engaged in group movement, and then generated naturalistic behaviors by integrating the
resulting equations of motion (i.e., free energy gradients) for this particular model. Taking
inspiration from fields like computational psychiatry [77, 78], we emphasize the ability to
move from simple forward modelling of behavior to data-driven model inversion, whereby one
hopes to infer the values of parameters that best explain empirical data (of e.g., behavioral
movement data). Instead of using ‘force mapping’ techniques to estimate social forces from
behavioral measurements [79, 80], our approach would instead frame the problem as one of
computational phenotyping, where alternative generative models that a particular animal
might be equipped with, could be estimated from behavioral or neural data acquired from
that animal. The resulting ‘social forces’ or interaction rules would then emerge as those
behaviors that minimize surprise, relative to the generative model that best explains the an-
imal’s behavior. Both the estimation of model parameters and alternative model structures
can be achieved through Bayesian model inversion and system identification methods like
Bayesian model selection, averaging or reduction [81].
21
Materials and Methods
For all simulations we randomly initialized the positions and (unit-magnitude) velocities ofN
particles, and integrated the equations of motion for active inference and generalized filtering
using a forwards Euler-Maruyama scheme with an integration window of∆t = 0.01s (see SI
Appendix, Section E for details). We varied group sizeN and the length of the simulation
T (in seconds) depending on the experiment. Detailed background on generalized filtering,
activeinference, andderivationsspecifictothegenerativemodelweusedforcollectivemotion
can be found in the SI Appendix, Section A. All other parameters used for simulations,
unless stated otherwise, are listed inSI Appendix, Table E.1. The code (written in JAX
and Julia) used to perform simulations can be found in the following open-source repository:
https://github.com/conorheins/collective_motion_actinf [82].
Quantifying fragmented groups
For all experiments, we excluded trials where the group failed to maintain cohesion (or
fragmented) to a sufficient degree. We deemed any given trial fragmented, when at least one
individualwasfurtherthan2.0dimensionlessunitsawayfromallotherindividualsforatleast
3 of the last 10 seconds of the trial. For the perturbation experiments, groups were excluded
if this criterion was reached during the last 5 seconds of the 20 second post-perturbation
period.
Collective information transfer experiments
For each trial of collective target-navigation, we initialized a group ofN = 30 agents with
random positions and velocities (centered on the origin) and augmented the generative mod-
els of a fixed proportionpinf of the total number of agents, wherepinf ranged from0.05 to
1.0, with extra latent and observed variables representing the distance to the target with
position vector T. The distance to the target was always 10 units from the origin. We
measured collective accuracy as follows: we count a given trial as successful if the group is
able to navigate to within0.25 units of the target without losing cohesion withinT = 15
seconds (the length of each trial). The accuracy for a given experimental condition was then
computed as the proportion of successes observed in500 total trials.
Perturbation experiments
For the perturbation experiments, we simulatedNi = 200 randomly-initialized independent
runs ofN = 50 agents, which we term independent initializations. We ran each initialization
forward forT = 100 seconds, a point at which metrics like average polarization, angular mo-
mentum, and median nearest-neighbor distance were highly likely to have stopped changing
and fluctuate around a stationary value. Starting atT = 100 we then split each initializa-
tion into two further sets ofNr = 50 parallel realizations. Each realization used a different
22
random seed used to A) generate the action- and observation-noises; and B) select the candi-
date agent(s) for perturbation. Note that the splitting of seeds atT = 100 means that each
realization has an identical history up until that point. We enabled parameter learning of
λz in one set of realizations and we left it disabled in the other. We then perturbed random
subsets of agents in both learning-enabled and -disabled realizations (2% - 50% of the group,
i.e., 1 to 25 agents), by transiently inducing first-order prediction errorsξ′
z in the perturbed
individuals. We computed the relative group turning angle after the perturbation for20s to
generate the plots in Figure 4B and C.
Acknowledgements: The authors would like to thank Brennan Klein, Jake Graving,
Armin Bahl, Dimitrije Markovic, Thomas Parr, Pawel Romanczuk, and Manuel Baltieri
for discussions during the writing of this manuscript, and Maya Polovitskaya for creating the
fish schematic used in the figures. CH and IDC acknowledge support from the Office of Naval
Research Grant N0001419-1-2556, Germany’s Excellence Strategy-EXC 2117-422037984 (to
IDC), the Max Planck Society, the European Union’s Horizon 2020 research and Innovation
Programme under the Marie Skłodowska-Curie Grant agreement (to IDC; #860949), the
PathFinder European Innovation Council Work Programme (to IDC; #101098722), and the
John Templeton Foundation (to CH; #61780). LD is supported by the Fonds National de
la Recherche, Luxembourg (Project code: 13568875) and the Engineering and Physical Sci-
ences Research Council Centre for Doctoral Training in Mathematics of Random Systems:
Analysis, Modelling and Simulation (EP/S023925/1). RPM is supported by UK Research
and Innovation Future Leaders Fellowship MR/S032525/1 and the Templeton World Charity
Foundation Inc. TWCF-2021-20647. KF is supported by funding for the Wellcome Centre
for Human Neuroimaging (Ref: 205103/Z/16/Z), a Canada-UK Artificial Intelligence Initia-
tive (Ref: ES/T01279X/1) and the European Union’s Horizon 2020 Framework Programme
for Research and Innovation under the Specific Grant Agreement No. 945539 (Human Brain
Project SGA3).
References
[1] Peter F Major and Lawrence M Dill. “The three-dimensional structure of airborne bird
flocks”. In:Behavioral Ecology and Sociobiology4.2 (1978), pp. 111–122.
[2] Scott Camazine, Jean-Louis Deneubourg, Nigel R Franks, James Sneyd, Eric
Bonabeau, and Guy Theraulaz.Self-organization in biological systems. Princeton uni-
versity press, 2003.
[3] Michael Rubenstein, Christian Ahler, and Radhika Nagpal. “Kilobot: A low cost scal-
able robot system for collective behaviors”. In:2012 IEEE International Conference
on Robotics and Automation. IEEE. 2012, pp. 3293–3298.
[4] Ichiro AOKI. “A Simulation Study on the Schooling Mechanism in Fish”. In:NIPPON
SUISAN GAKKAISHI 48.8 (1982), pp. 1081–1088.doi: 10.2331/suisan.48.1081.
23
[5] Craig W Reynolds. “Flocks, herds and schools: A distributed behavioral model”. In:
Proceedings of the 14th annual conference on Computer graphics and interactive tech-
niques. 1987, pp. 25–34.
[6] Tamás Vicsek, András Czirók, Eshel Ben-Jacob, Inon Cohen, and Ofer Shochet. “Novel
type of phase transition in a system of self-driven particles”. In:Physical review letters
75.6 (1995), p. 1226.
[7] Iain D Couzin, Jens Krause, Richard James, Graeme D Ruxton, and Nigel R Franks.
“Collective memory and spatial sorting in animal groups”. In:Journal of theoretical
biology 218.1 (2002), pp. 1–12.
[8] John Toner and Yuhai Tu. “Flocks, herds, and schools: A quantitative theory of flock-
ing”. In:Physical review E58.4 (1998), p. 4828.
[9] David JT Sumpter. “The principles of collective animal behaviour”. In:Philosophical
transactions of the royal society B: Biological Sciences361.1465 (2006), pp. 5–22.
[10] Eric Bertin, Michel Droz, and Guillaume Grégoire. “Boltzmann and hydrodynamic
description for self-propelled particles”. In:Physical Review E74.2 (2006), p. 022101.
[11] Pierre Degond and Sébastien Motsch. “Continuum limit of self-driven particles with
orientation interaction”. In: Mathematical Models and Methods in Applied Sciences
18.supp01 (2008), pp. 1193–1215.
[12] James E Herbert-Read, Andrea Perna, Richard P Mann, Timothy M Schaerf, David
JT Sumpter, and Ashley JW Ward. “Inferring the rules of interaction of shoaling fish”.
In: Proceedings of the National Academy of Sciences108.46 (2011), pp. 18726–18731.
[13] Daniel S Calovi, Ugo Lopez, Sandrine Ngo, Clément Sire, Hugues Chaté, and Guy
Theraulaz. “Swarming, schooling, milling: phase diagram of a data-driven fish school
model”. In:New journal of Physics16.1 (2014), p. 015026.
[14] Andrew M Hein, Douglas L Altshuler, David E Cade, James C Liao, Benjamin T
Martin, and Graham K Taylor. “An algorithmic approach to natural behavior”. In:
Current Biology30.11 (2020), R663–R675.
[15] Ashkaan K Fahimipour, Michael A Gil, Maria Rosa Celis, Gabriel F Hein, Benjamin T
Martin, and Andrew M Hein. “Wild animals suppress the spread of socially transmitted
misinformation”. In: Proceedings of the National Academy of Sciences120.14 (2023),
e2215428120.
[16] Jacques Gautrais, Francesco Ginelli, Richard Fournier, Stéphane Blanco, Marc So-
ria, Hugues Chaté, and Guy Theraulaz. “Deciphering interactions in moving animal
groups”. In:PLoS computational biology8.9 (2012), e1002678.
[17] Yael Katz, Kolbjørn Tunstrøm, Christos C Ioannou, Cristián Huepe, and Iain D
Couzin. “Inferring the structure and dynamics of interactions in schooling fish”. In:
Proceedings of the National Academy of Sciences108.46 (2011), pp. 18720–18725.
[18] Karl J Friston, Jean Daunizeau, and Stefan J Kiebel. “Reinforcement learning or active
inference?” In:PloS one 4.7 (2009), e6421.
24
[19] Karl Friston, Thomas FitzGerald, Francesco Rigoli, Philipp Schwartenbeck, and Gio-
vanni Pezzulo. “Active inference: a process theory”. In:Neural computation29.1 (2017),
pp. 1–49.
[20] Thomas Parr, Giovanni Pezzulo, and Karl J Friston.Active inference: the free energy
principle in mind, brain, and behavior. MIT Press, 2022.
[21] Lancelot Da Costa, Thomas Parr, Noor Sajid, Sebastijan Veselic, Victorita Neacsu,
and Karl Friston. “Active inference on discrete state-spaces: a synthesis”. In:Journal
of Mathematical Psychology99 (2020), p. 102447.
[22] Karl Friston. “A theory of cortical responses”. In: Philosophical transactions of the
Royal Society B: Biological sciences360.1456 (2005), pp. 815–836.
[23] Karl Friston, James Kilner, and Lee Harrison. “A free energy principle for the brain”.
In: Journal of Physiology-Paris100.1-3 (2006), pp. 70–87.
[24] Karl Friston. “What is optimal about motor control?” In:Neuron 72.3 (2011), pp. 488–
498.
[25] Karl Friston, Lancelot Da Costa, Noor Sajid, Conor Heins, Kai Ueltzhöffer, Grigorios
A. Pavliotis, and Thomas Parr. “The Free Energy Principle Made Simpler but Not Too
Simple”. In: Physics Reports. The Free Energy Principle Made Simpler but Not Too
Simple 1024 (June 2023), pp. 1–29.issn: 0370-1573.doi: 10.1016/j.physrep.2023.
07.001. (Visited on 08/30/2023).
[26] Rajesh PN Rao and Dana H Ballard. “Predictive coding in the visual cortex: a func-
tional interpretation of some extra-classical receptive-field effects”. In:Nature neuro-
science 2.1 (1999), pp. 79–87.
[27] Rick A Adams, Stewart Shipp, and Karl J Friston. “Predictions not commands: active
inference in the motor system”. In:Brain Structure and Function218.3 (2013), pp. 611–
643.
[28] Abdullahi Ali, Nasir Ahmad, Elgar de Groot, Marcel Antonius Johannes van Gerven,
and Tim Christian Kietzmann. “Predictive coding is a consequence of energy efficiency
in recurrent neural networks”. In:Patterns 3.12 (2022).
[29] Charlotte Caucheteux, Alexandre Gramfort, and Jean-Rémi King. “Evidence of a pre-
dictive coding hierarchy in the human brain listening to speech”. In:Nature human
behaviour 7.3 (2023), pp. 430–441.
[30] Kevin N Laland. “Social learning strategies”. In: Animal Learning & Behavior32.1
(2004), pp. 4–14.
[31] Peter M Krafft, Erez Shmueli, Thomas L Griffiths, Joshua B Tenenbaum, et al.
“Bayesian collective learning emerges from heuristic social learning”. In:Cognition 212
(2021), p. 104469.
[32] Manuel Baltieri and Christopher L Buckley. “Generative models as parsimonious de-
scriptions of sensorimotor loops”. In:arXiv preprint arXiv:1904.12937(2019).
25
[33] Cem Uran, Alina Peter, Andreea Lazar, William Barnes, Johanna Klon-Lipok,
Katharine A. Shapcott, Rasmus Roese, Pascal Fries, Wolf Singer, and Martin Vinck.
“Predictive coding of natural images by V1 firing rates and rhythmic synchronization”.
In: Neuron 110.7 (2022), 1240–1257.e8.issn: 0896-6273.doi: https://doi.org/10.
1016/j.neuron.2022.01.002 . url: https://www.sciencedirect.com/science/
article/pii/S0896627322000022.
[34] Karl Friston. “The free-energy principle: a rough guide to the brain?” In:Trends in
cognitive sciences13.7 (2009), pp. 293–301.
[35] Jakob Hohwy. “The self-evidencing brain”. In:Noûs 50.2 (2016), pp. 259–285.
[36] Karl Friston. “A free energy principle for a particular physics”. In: arXiv preprint
arXiv:1906.10184 (2019).
[37] Bertrand Collignon, Axel Séguret, and José Halloy. “A stochastic vision-based model
inspired by zebrafish collective behaviour in heterogeneous environments”. In:Royal
Society open science3.1 (2016), p. 150473.
[38] Renaud Bastien and Pawel Romanczuk. “A model of collective behavior based purely
on vision”. In:Science advances6.6 (2020), eaay0792.
[39] Karl Friston, Klaas Stephan, Baojuan Li, and Jean Daunizeau. “Generalised filtering”.
In: Mathematical Problems in Engineering2010 (2010).
[40] Karl Friston, Jérémie Mattout, Nelson Trujillo-Barreto, John Ashburner, and Will
Penny. “Variational free energy and the Laplace approximation”. In:Neuroimage 34.1
(2007), pp. 220–234.
[41] David JC MacKay and David JC Mac Kay.Information theory, inference and learning
algorithms. Cambridge university press, 2003.
[42] Janneke FM Jehee, Constantin Rothkopf, Jeffrey M Beck, and Dana H Ballard. “Learn-
ing receptive fields using predictive feedback”. In:Journal of Physiology-Paris100.1-3
(2006), pp. 125–132.
[43] Michael W Spratling. “A review of predictive coding algorithms”. In:Brain and cogni-
tion 112 (2017), pp. 92–97.
[44] Antonella Maselli, Pablo Lanillos, and Giovanni Pezzulo. “Active inference unifies in-
tentional and conflict-resolution imperatives of motor control”. In:PLoS computational
biology 18.6 (2022), e1010095.
[45] Manuel Baltieri and Christopher L Buckley. “PID control as a process of active infer-
ence with linear generative models”. In:Entropy 21.3 (2019), p. 257.
[46] Christopher L Buckley, Chang Sub Kim, Simon McGregor, and Anil K Seth. “The
free energy principle for action and perception: A mathematical review”. In:Journal
of Mathematical Psychology81 (2017), pp. 55–79.
[47] Pawel Romanczuk, Iain D Couzin, and Lutz Schimansky-Geier. “Collective motion due
to individual escape and pursuit response”. In:Physical Review Letters102.1 (2009),
p. 010602.
26
[48] Iain D Couzin, Jens Krause, Nigel R Franks, and Simon A Levin. “Effective leader-
ship and decision-making in animal groups on the move”. In:Nature 433.7025 (2005),
pp. 513–516.
[49] Ch Becco, Nicolas Vandewalle, Johann Delcourt, and Pascal Poncin. “Experimental
evidences of a structural and dynamical transition in fish school”. In:Physica A: Sta-
tistical Mechanics and its Applications367 (2006), pp. 487–493.
[50] Kolbjørn Tunstrøm, Yael Katz, Christos C Ioannou, Cristián Huepe, Matthew J Lutz,
andIainDCouzin.“Collectivestates,multistabilityandtransitionalbehaviorinschool-
ing fish”. In:PLoS computational biology9.2 (2013), e1002915.
[51] Irene Giardina. “Collective behavior in animal groups: theoretical models and empirical
studies”. In:HFSP journal 2.4 (2008), pp. 205–219.
[52] Rafael Kaufmann, Pranav Gupta, and Jacob Taylor. “An active inference model of
collective intelligence”. In:Entropy 23.7 (2021), p. 830.
[53] Conor Heins, Brennan Klein, Daphne Demekas, Miguel Aguilera, and Christopher L
Buckley. “Spin glass systems as collective active inference”. In:Active Inference: Third
International Workshop, IWAI 2022, Grenoble, France, September 19, 2022, Revised
Selected Papers. Springer. 2023, pp. 75–98.
[54] Matthew MG Sosna, Colin R Twomey, Joseph Bak-Coleman, Winnie Poel, Bryan C
Daniels, Pawel Romanczuk, and Iain D Couzin. “Individual and collective encoding
of risk in animal groups”. In:Proceedings of the National Academy of Sciences116.41
(2019), pp. 20556–20561.
[55] Thomas Parr, Jakub Limanowski, Vishal Rawji, and Karl Friston. “The computational
neurology of movement under active inference”. In:Brain (2021).
[56] Jerome Buhl, David JT Sumpter, Iain D Couzin, Joe J Hale, Emma Despland, Edgar R
Miller, and Steve J Simpson. “From disorder to order in marching locusts”. In:Science
312.5778 (2006), pp. 1402–1406.
[57] Iain D Couzin, Christos C Ioannou, Güven Demirel, Thilo Gross, Colin J Torney, An-
drew Hartnett, Larissa Conradt, Simon A Levin, and Naomi E Leonard. “Uninformed
individuals promote democratic consensus in animal groups”. In: science 334.6062
(2011), pp. 1578–1580.
[58] Ariana Strandburg-Peshkin, Damien R Farine, Iain D Couzin, and Margaret C Cro-
foot. “Shared decision-making drives collective movement in wild baboons”. In:Science
348.6241 (2015), pp. 1358–1361.
[59] Vivek H Sridhar, Liang Li, Dan Gorbonos, Máté Nagy, Bianca R Schell, Timothy
Sorochkin, Nir S Gov, and Iain D Couzin. “The geometry of decision-making in indi-
viduals and collectives”. In:Proceedings of the National Academy of Sciences118.50
(2021).
27
[60] Allison Kolpas, Michael Busch, Hong Li, Iain D Couzin, Linda Petzold, and Jeff
Moehlis. “How the spatial position of individuals affects their influence on swarms:
a numerical comparison of two popular swarm dynamics models”. In:PloS one 8.3
(2013), e58525.
[61] Anastasia Bizyaeva, Alessio Franci, and Naomi Ehrich Leonard. “Nonlinear opinion dy-
namics with tunable sensitivity”. In:IEEE Transactions on Automatic Control(2022).
[62] Heiko Hamann. “Evolution of collective behaviors by minimizing surprise”. In:Artificial
Life Conference Proceedings. MIT Press One Rogers Street, Cambridge, MA 02142-
1209, USA journals-info ... 2014, pp. 344–351.
[63] Tanja Katharina Kaiser and Heiko Hamann. “Innate Motivation for Robot Swarms by
Minimizing Surprise: From Simple Simulations to Real-World Experiments”. In:IEEE
Transactions on Robotics38.6 (2022), pp. 3582–3601.
[64] Daniela Gandolfi, Francesco M Puglisi, Giulia M Boiani, Giuseppe Pagnoni, Karl J
Friston, Egidio D’Angelo, and Jonathan Mapelli. “Emergence of associative learning
in a neuromorphic inference network”. In:Journal of Neural Engineering19.3 (2022),
p. 036022.
[65] Karl Friston, Thomas FitzGerald, Francesco Rigoli, Philipp Schwartenbeck, Giovanni
Pezzulo, et al. “Active inference and learning”. In:Neuroscience & Biobehavioral Re-
views 68 (2016), pp. 862–879.
[66] MatthiasHHennig.“Theoreticalmodelsofsynapticshorttermplasticity”.In: Frontiers
in computational neuroscience7 (2013), p. 45.
[67] Ashley JW Ward, James E Herbert-Read, David JT Sumpter, and Jens Krause. “Fast
and accurate decisions through collective vigilance in fish shoals”. In:Proceedings of
the National Academy of Sciences108.6 (2011), pp. 2312–2315.
[68] Ariana Strandburg-Peshkin, Colin R Twomey, Nikolai WF Bode, Albert B Kao, Yael
Katz, Christos C Ioannou, Sara B Rosenthal, Colin J Torney, Hai Shan Wu, Simon
A Levin, et al. “Visual sensory networks and effective information transfer in animal
groups”. In:Current Biology23.17 (2013), R709–R711.
[69] Jacob D Davidson, Matthew MG Sosna, Colin R Twomey, Vivek H Sridhar, Simon
P Leblanc, and Iain D Couzin. “Collective detection based on visual information in
animal groups”. In:Journal of the Royal Society Interface18.180 (2021), p. 20210142.
[70] Roy Harpaz, Minh Nguyet Nguyen, Armin Bahl, and Florian Engert. “Precise visuo-
motor transformations underlying collective behavior in larval zebrafish”. In:Nature
communications 12.1 (2021), p. 6578.
[71] Luis Gómez-Nava, Robert T Lange, Pascal P Klamser, Juliane Lukas, Lenin Arias-
Rodriguez, David Bierbach, Jens Krause, Henning Sprekeler, and Pawel Romanczuk.
“Fish shoals resemble a stochastic excitable system driven by environmental perturba-
tions”. In:Nature Physics(2023), pp. 1–7.
28
[72] Roger C Conant and W Ross Ashby. “Every good regulator of a system must be a
model of that system”. In:International journal of systems science1.2 (1970), pp. 89–
97.
[73] AlexanderDWissner-GrossandCameronEFreer.“Causalentropicforces”.In: Physical
review letters110.16 (2013), p. 168702.
[74] Hannes Hornischer, Stephan Herminghaus, and Marco G Mazza. “Structural transition
in the collective behavior of cognitive agents”. In:Scientific reports9.1 (2019), p. 12477.
[75] Daniel Ari Friedman, Alec Tschantz, Maxwell JD Ramstead, Karl Friston, and Axel
Constant. “Active Inferants: an active inference framework for ant colony behavior”.
In: Frontiers in behavioral neuroscience15 (2021), p. 647732.
[76] Mahault Albarracin, Daphne Demekas, Maxwell JD Ramstead, and Conor Heins.
“Epistemic communities under active inference”. In:Entropy 24.4 (2022), p. 476.
[77] P Read Montague, Raymond J Dolan, Karl J Friston, and Peter Dayan. “Computa-
tional psychiatry”. In:Trends in cognitive sciences16.1 (2012), pp. 72–80.
[78] Ryan Smith, Paul Badcock, and Karl J Friston. “Recent advances in the application of
predictive coding and active inference models within clinical neuroscience”. In:Psychi-
atry and Clinical Neurosciences(2020). url: https://onlinelibrary.wiley.com/
doi/abs/10.1111/pcn.13138.
[79] R Escobedo, V Lecheval, V Papaspyros, F Bonnet, F Mondada, Clément Sire, and
Guy Theraulaz. “A data-driven method for reconstructing and modelling social inter-
actions in moving animal groups”. In:Philosophical Transactions of the Royal Society
B 375.1807 (2020), p. 20190380.
[80] Rajnesh K Mudaliar and Timothy M Schaerf. “An examination of force maps targeted
at orientation interactions in moving groups”. In:Plos one 18.9 (2023), e0286810.
[81] William D Penny, Jérémie Mattout, and N Trujillo-Barreto. “Bayesian model selection
and averaging”. In:Statistical Parametric Mapping: The analysis of functional brain
images. London: Elsevier(2006).
[82] Conor Heins. Collective Motion ActInf. Deposited on July 27, 2023. 2023.url: https:
//github.com/conorheins/collective_motion_actinf.
29
A An active inference model of collective motion
Eachagentwithinourmodelofcollectivemotionmaintainsaninternalmodelofitslocalenvi-
ronment represented by average distances to its neighbours. These distances are partitioned
into L sensory sectors x = x1, x2, ..., xL, with each agent observing noisy versions of these
distances through a corresponding sensory channely = y1, y2, ..., yL. Each agent estimates
the hidden distance variable(s)x over time using its observed sensory statesy. In practice,
each agent implements this through a form of variational Bayesian inference developed for
continuous data-assimilation in dynamic environments calledgeneralized filtering, which can
be seen as a variational, more flexible version of Kalman filters. This dynamic inference
process entails updating posterior beliefs aboutx using a gradient descent on variational
free energy. In the case of Gaussian assumptions about observation and state noise, these
free energy gradients resemble a precision-weighted average of sensory and state prediction
errors. This comprises the state-estimation component of active inference and is unpacked
in detail in Section A.1.
In addition to estimating the hidden distance variable with generalized filtering, each
agent also changes its heading directionv in order to minimize the same variational free
energy functional. When the agent’s model of the distance dynamics is strongly ‘biased’
by a prior belief that the steady-state value of the distance variable(s)˜x hovers around a
particular value η, then agents will change their heading in a way that appears like they
‘want’ to maintain this target distance between them and their neighbours. Concretely, this
means they move closer to neighbors when the sensed distancey is larger than expected,
and move away from neighbors wheny is smaller than expected.
This symmetry between belief updating and action, as both following the gradients of
the same loss function, is what theoretically distinguishes active inference from other con-
tinuous control schemes, which often use different objectives for estimation and control. In
the following sections we detail the processes of state-estimation and action under active
inference.
A.1 Generalized filtering overview
Agents estimate hidden statesx as the variational solution to a Bayesian inference problem;
they achieve this in practice using an online-filtering algorithm known as generalized filtering
[1, 2]. Generalized filtering is a generic Bayesian filtering scheme for non-linear state-space
models formulated in generalized coordinates of motion [3]. It subsumes, as special cases,
variational filtering [4], dynamic expectation maximization [5] and generalized predictive
coding [6]. This inversion scheme relies on a simple dynamical generative specification of
hidden states x and how they relate to observationsy. The generative model starts by
postulatingthatthetimeevolutionofavariable x isgivenbyastochasticdifferentialequation
with the following form:
dxt
dt = f(xt) + ωt (A.1)
30
where f is some deterministic flow function (i.e., a vector field) that depends on the
current state xt, and ωt is a (smooth) additive Gaussian noise process. Under generalized
filtering, we successively differentiate (A.1), to finesse the difficult computation of thepaths
or trajectories of xt locally in time, by instead focusing on the much easier problem of
computing the serial derivatives of xt. This allows one to express a local trajectory of
⃗ x= {xt, xt+1, . . . , xt+T } in terms of the derivatives ofxt, i.e., ˜xt = (x′
t, x′′
t , x′′′
t , . . . , x[n]
t , . . .),
where x[n]
t := dn
dtn xt. We used the notation ˜xt to denote a vector of these higher orders
of motion at time t, a representation known asgeneralized coordinates. The equivalence
between generalized coordinates and paths locally in time follows from Taylor’s theorem,
where the path ofx around some time t can be expressed as a combination of its higher
order derivatives:
xt+h = x[0]
t +
∞X
n=1
x[n]
n! hn (A.2)
Note that the (local in time) equality between a path⃗ xand its Taylor series only holds
when the sample paths ofxt are analytic functions, which itself requiresf to be analytic
and the noise process ωt to be analytic (in particular non-white noise fluctuations) [7].
Successively differentiating the base equation in (A.1) (and ignoring contributions of the
flow of order higher than one) yields a series of stochastic differential equations that describe
the evolution of each order of motionx[n]
t as depending on its own state and thenth derivative
of the noise [3]:
˙x = f(x) + ω
˙x′ = fxx′ + ω′
˙x′′ = fxx′′ + ω′′
...
⇒ D˜x = ˜f + ˜ω
where, following the notation used in [1–3], we use the notationfx for the Jacobian (i.e.,
matrix of first order partial derivatives) of the flow functionf evaluated atx, i.e.,Jf (x), and
omit the time variable from our notation for conciseness. Note that the above construction
assumes a local linearization off around x, in the sense that it ignores the contribution of
higher order derivatives of the flow [3]. TheD is the time derivative operator in generalised
coordinates, with identity matrices along the first leading (block) diagonal and˜f, ˜ω are the
generalized flow function and generalized noises, respectively:
D =


0 I
... ...
... I
0


˜f =


f(x[0])
fxx[1]
...
fxx[n]

 ˜ω =


ω[0]
ω[1]
...
ω[n]


31
Here, n is some chosen order at which to truncate the derivatives. This truncation means
that the Taylor expansion of a path⃗ xin (A.2) is rendered an approximation – valid locally in
time. Having specified a dynamics overx (and its reformulation in generalized coordinates),
we are in a position to specify theobservation model. In generalized filtering, the generative
model of state dynamics is supplemented with an observation model that maps hidden states
x to their sensory consequencesy via some (differentiable) sensory mapg(x) and additive
Gaussian smooth fluctuationsz:
yt = g(xt) + zt (A.3)
Likethestates, wecansimilarlyexpressobservationsingeneralizedcoordinatesbysucces-
sivelydifferentiating (A.3)toobtainasimilarsingleexpressionforthegeneralizedobservation
equation:
y = g(x) + z
y′ = gxx′ + z′
y′′ = gxx′′ + z′′
...
⇒ ˜y = ˜g + ˜z
where here theith motion of observationsy[i] is not a function of itself but rather that of
the motion of the (generalized) hidden statesx[i] and fluctuationsz[i]. In other words, the
motion of observations tracks the simultaneous motion of the states, subject to any nonlin-
earities in the sensory mapg and the motion of the noisez. Given Gaussian assumptions on
the generalised noises˜ω and ˜z, we can then write down the full hidden state and observation
model p(˜y, ˜x) in terms of Gaussian densities:
D˜x = ˜f + ˜ω ˜ω ∼ N(˜ω; 0, ˜Σω)
˜y = ˜g + ˜z ˜z ∼ N(˜z; 0, ˜Σz)
=⇒ p(˜y, ˜x) = p(˜y|˜x)p(D˜x|˜x)
= N(˜y; ˜g, ˜Σz)N(D˜x; ˜f, ˜Σω) (A.4)
This Gaussian specification of the generative model licenses efficient, online update rules
for the sufficient statistics of approximate posterior beliefs that track the expected value of
the generalised hidden state˜x. This relies on a simple expression for the variational free
energy of this state-space model; as we will see in the following sections, this not only enables
efficient state estimation (a.k.a, updating beliefs about hidden states˜x), but also algorithms
for inferring generative model parameters.
32
A.2 State estimation under generalized filtering
Generalized filtering relies on optimizing posterior beliefs in order to minimizevariational
free energyF, an upper bound on thesurprise associated with observationsy under some
generative modelm:
F ≥ −ln p(y; m)| {z }
surprise
(A.5)
where the model m defines a joint distribution over observations and latent variables
p(y, ϑ). The latent variables themselvesϑ are often split into hidden statesx and parameters
θ. Exact Bayesian inference entails obtaining the posterior distribution over latent variables
p(ϑ|y), which can be expressed using Bayes rule:
p(ϑ|y) = p(y, ϑ)
p(y) (A.6)
p(y) ≜
Z
p(y, ϑ)dϑ (A.7)
where hereafter we leave out the dependence on the modelm.
In order to compute the posterior exactly, one has to compute the marginal probability of
observations p(y), also known as the marginal likelihood or model evidence. Computing the
marginal likelihood is often intractable or difficult in practice, motivating the introduction
of the variational bound, the free energyF, also known as the (negative) evidence lower-
bound or ELBO. This can be shown by writingF as the Kullback-Leibler divergence between
some "variational" distributionq(ϑ; ν) over latent variables with parametersν and the true
posterior p(ϑ|y):
F = Eq [ln q(ϑ) − ln p(y, ϑ)]
= DKL (q(ϑ; ν)||p(ϑ|y)) −ln p(y)| {z }
surprise
(A.8)
=⇒ F ≥ −ln p(y) (A.9)
The upper bound holds because the Kullback-Leibler divergence is always non-negative
DKL(p||q) ≥ 0. Intuitively, as the variational distributionq(ϑ; ν) better approximates the
true posterior distributionp(ϑ|y), where the (in)accuracy of the approximation is measured
by the KL divergence, then the tighter the free energy bounds the surprise. This decom-
position also makes clear why minimizingF with respect to variational parametersν is a
way to update the variational distributionq to approximate the true posteriorp(ϑ|y). The
variational distribution is thus often referred to as an approximate posterior, where the ex-
act posterior obtained by applying Bayesian rule as in Equation (A.6) corresponds to the
variational posterior that minimisesF.
33
Now we turn to deriving the Laplace-approximation to the variational free energy (VFE)
for the Gaussian state-space models used in generalised filtering. The Laplace approxima-
tion is an analytically tractable way to approximate the true posterior with a Gaussian
distribution, which simplifies inference to an online filtering algorithm that corresponds to
minimizing a sum of squared prediction errors.
Recall that our goal is to perform inference on the latent variablesϑ by optimizing an
approximate posterior distributionq(ϑ; ν). In our case, we letϑ = {x, θ} where x are hidden
states and θ encompass other generative model parameters (e.g., hyperparameters of the
generative model like ˜f, ˜g, ˜Σz, ˜Σω). For now we focus on inference over hidden states x
and treat parameter inference later. Under the Laplace approximation we use a Gaussian
distribution for the approximate posterior distributionq(x; ν):
q(x; ν) = N(x; µ, Σν
|{z}
ν
) (A.10)
where the variational parametersν are comprised of the sufficient statistics of a Gaussian
distribution: the mean µ and covariance Σν. We add the subscript ν to the variational
variance to distinguish it from generative model covariances, e.g.˜Σz, ˜Σω.
We can now arrive at a more specific expression for the variational free energy using the
Gaussian form of the variational distribution. We start by decomposing the free energy into
the sum of an expected energy term and a (negative) entropy, where the energy is defined
as the negative log joint density over states and observations:−ln p(x, y) and the negative
entropy is that of the variational posterior i.e.,Eq[ln q(x; ν)]:
F = Eq [−ln p(x, y)] − 1
2 [ln |Σ| + d ln 2πe] (A.11)
where d is the dimensionality ofx and the full term on the right follows from the entropy
of a multivariate Gaussian:H[N(x; µ, Σ)] = 1
2 [ln |Σ| + d ln 2πe].
Additionalassumptionsallowonetofurthersimplifytheexpectedenergyterm Eq [−ln p(x, y)];
namely, if we assume that the posterior is tightly peaked around the meanµ and thatp(x, y)
is twice-differentiable inx, we can motivate a 2nd-order Taylor expansion of the expected
energy term around its mode, i.e. whenx = µ:
Eq [−ln p(x, y)] ≈ Eq
"
−ln p(µ, y) − ∇x ln p(x, y)

x=µ
(x − µ) − 1
2(x − µ)⊤∇2
x ln p(x, y)

x=µ
(x − µ)
#
= −ln p(µ, y) − 1
2 tr
 
Σ∇2
x ln p(x, y)

x=µ
!
(A.12)
Combining this approximation of the expected energy with the remaining terms in the
variational free energy, we can now write the full expression of the Laplace-approximated
free energyFL:
34
FL = −ln p(µ, y) − 1
2 tr
 
Σ∇2
x ln p(x, y)

x=µ
!
− 1
2 (ln |Σ| + d ln 2πe) (A.13)
A useful feature of this expression is that the optimal variational covarianceΣν can
obtained by setting the derivative ofFL with respect to the covarianceΣ equal to 0 and
solving forΣ, i.e. finding the values of the covariance that minimize theFL:
∂FL
∂Σ = 0 ⇐⇒ Σν = −
 
∇2
x ln p(x, y)

x=µ
!−1
(A.14)
i.e., the optimal variance of the variational distribution is the curvature of the Laplace
energy around its mode. Substituting this expression back into the full free energy, we can
then write an expression that only depends on the mean vectorµ of the variational density,
since the variatonal varianceΣν is now expressed as a function of the mean:
FL = −ln p(µ, y) + 1
2 tr
 
Σν(Σν)−1
| {z }
=d
−1
2 (ln |Σν| + d ln 2πe)
= −ln p(µ, y) − 1
2 (ln |Σν| + d ln 2π) (A.15)
This means that the Laplace approximation to the variational free energy is a function of
only the variational meanµ and sensory observationsy, because the variational varianceΣν is
itself a function ofµ. Belief updating then consists in minimizing the Laplace-approximated
free energyFL with respect toµ:
˙µ ∝ −∇µFL(µ, y) (A.16)
Which consists of descending the gradient of the energy and log determinant terms with
respect toµ. When the generative modelp(x, y) is Gaussian, the energy term is quadratic
in µ and y. This means that its gradient can be written in terms of precision-weighted
prediction errors, which score the difference between the expected observations (given the
current value ofµ) and the actual observationsy. This notion of using prediction errors to
estimate hidden quantities is also known as predictive coding [8–10]. The log determinant
term — in all of our cases of interest — turns out to have a vanishing gradient with respect
to µ. In summary, the free energy gradient is a sum of precision-weightedprediction errors,
and µ evolves to minimize those prediction errors.
To illustrate this, we take the simplest example — that of a linear, static, joint Gaussian
generative model, where the prior over hidden statesp(x) is a Gaussian density with meanη
35
and covarianceΣω, and the observation modelp(x|y) is a Gaussian density with meang(x),
which is some linear function of the hidden state:
y ∼ N(g(x), Σz), x ∼ N(η, Σω). (A.17)
For this linear Gaussian generative model, the variational meanµ only influences the
expected energy term ofFL, because the optimal covarianceΣν is independent ofµ. Thus
we ignore the constant entropy term and write out the energy as a sum of precision-weighted
prediction errors:
−ln p(µ, y) = −ln p(y|µ) − ln p(µ)
= 1
2

εT
z Πzεz + εT
ω Πωεω

where Πz = (Σz)−1, Πω = (Σω)−1
and εz = y − g(µ), εω = µ − η (A.18)
We can write out gradients of this quadratic energy function to yield the update equation
for the meansµ as in (A.16), and see thatµ changes as a precision-weighted sum of ‘sensory‘
and ‘model’ prediction errors (up to additive constants):
˙µ = −∇µFL(µ, y)
= −∇µ
1
2
 
εT
z Πzεz + εT
ω Πωεω

= −

(gµ)T Πzεz + Πωεω

(A.19)
Note that the variational means only depend on the terms ofFL containing εz and εω, so
that the update reduces to a gradient descent on a sum of squared prediction errors. This
belief update scheme illustrates the key principles of predictive coding under the Laplace
approximation: conditional means, denoted asµ, change as a function of precision-weighted
prediction errors. The concept of precision-weighting in belief updating is intuitive: if the
generative model attributes higher variance to sensory fluctuations as compared to state
variance (i.e.,Πz < Πω), then sensory data is relatively unreliable and consequently makes
a smaller impact on posterior beliefs. Therefore, the adjustment to the posterior mean
µ in (A.19) is primarily influenced by the state prediction error termΠωεω or the prior.
Conversely, when sensory information is allocated higher precision (lower variance) relative
to prior beliefs (i.e.,Πz > Πω), belief updates will strongly rely on sensory data.
We apply the above steps to derive the Laplace-approximated free energy with a Gaus-
sian posteriorq(x; ν) to the dynamical generative model in (A.4),which is constructed from
Gaussian densities. Note that we use the tilde notation to now indicate that all variables are
vectors of generalised coordinates, e.g.,˜y, ˜x, etc. Proceeding exactly as above, the Laplace
36
free energy is a sum of the energy, a log determinant term, and a constant term, i.e. (A.15).
Unlike in the linear Gaussian case, the potential non-linearity in the flows make that the log
determinant term varies with respect toµ. However, as it turns out its gradient is approxi-
mately zero under the local linear approximation. Therefore, the only term that matters in
the free energy as its gradient does not vanish is the energy term. In summary, we write:
FL ∝ ˜εT
z ˜Πz ˜εz + ˜εT
ω ˜Πω ˜εω (A.20)
˜εz ≜ ˜y − ˜g
˜εω ≜ D˜µ − ˜f
Here, the so-called ‘generalised errors’˜εz and ˜εω encapsulate sensory and state prediction
errors across orders of motion. Belief updating is again performed using a gradient descent
on free energy, but the dynamic nature of inference necessitates an additional ’motion’ term:
d˜µ
dt = D˜µ − ∇˜µFL
= D˜µ + g⊤
˜µ ˜ξz + f⊤
˜µ ˜ξω − D⊤ ˜ξω
where ˜ξz = ˜Πz ˜εz
˜ξω = ˜Πω ˜εω (A.21)
The additional termD˜µ places the gradient descent within the context of the expected
movement of the conditional means˜µ, and hence of the free energy minimum. This concept
has been referred to as ’gradient descent in a moving frame of reference’ [1]. This implies
that free energy minimization does not occur when the beliefs cease moving, but rather when
the belief update rated˜µ
dt is identical to the beliefs about the motion itselfD˜µ, in other words
when ∂F
∂˜µ = 0 ⇐⇒ D˜µ = d˜µ
dt . This additional temporal correction proves beneficial in a
dynamic data assimilation regime, where incoming observations are integrated online with
beliefs that are evolving according to their own prior dynamics [1].
A.3 Active inference for continuous control
Active inference casts action or control as issuing from the same process of free energy min-
imization as used for state estimation; the only difference is that we now have an additional
set of variables, actionsa, that can be changed to minimize free energy as well. The update
equation for actionsa closely resembles that used to update the variational meanµ, i.e., a
gradient descent on the (Laplace-encoded) variational free energy:
da
dt = −∂FL(µ, y(a))
∂a
= − ∂FL
∂y(a)
∂y(a)
∂a (A.22)
37
where we have now introduced a dependence between of observationsy on actions a.
This allows us to express the free energy gradient with respect to action as the product
of the derivative of the free energy with respect to observations ∇yFL(µ, y(a)) and the
derivative of the function mapping from actions to observations ∂y(a)
∂a . The free energy
gradient with respect to observations is exactly the sensory prediction error∇yFL(µ, y(a)) =
ξz = Π( y − g(x)). This assumed dependence of observations on actions underwrites the
notion that active inference agents cannot directly measure how their actions affect hidden
states, but may only do so via their sensory consequences. This has been speculated to
explain the architecture of descending motor pathways in corticospinal systems, where motor
commands are ‘unpacked’ into proprioceptive predictions at the level of spinal circuits and
other lower motor nuclei. Action is thus realized by minimizing proprioceptive prediction
errors via classical reflex arcs [11]. The reflex arc term ∂y(a)
∂a of (A.22) is analogous to a
forward model in motor control [12], because it reflects the agent’s implicit assumptions
about how the agent’s own actions lead to their (anticipated) sensory consequences. This
sort of update rule leads active inference agents to minimize sensory prediction errors via
these ‘baked-in’ sensorimotor contingencies. In this way active inference has been referred
to as ‘action by self-fulfilling prophecy’ [6]. In other words, the agent generates top-down
expectations of ‘preferred’ sensory inputs, which then generates prediction errors which can
then be suppressed through low-level motoric reflexes [11].
A.4 Filtering and control for a self-propelled particle
Having derived a routine for state estimation and action through a generalized gradient
flow on the Laplace-approximated variational free energyFL, we can now apply this to
the simulation of collective motion. In what follows, we write down a sufficient generative
model for a single self-propelled agent and unpack the corresponding free energy gradients
((A.20) and (A.22)) using the structure and parameters of the chosen generative model. In
this section we unpack the per-agent generative model of local distances described in the
main text and demonstrate how a more parametric, unconstrained version of social forces
are reproduced by minimizing free energy with respect to the distance-tracking generative
model.
A.4.1 A generalised filter for local distances and their time evolution
As described in the main text, each agent represents a anL-dimensional vector x where
x = (x1, x2, ..., xL).1 The agent not only represents the instantaneous value (or ‘position’) of
x but also its generalized motion, which we truncate at 3rd order:
1We use the bold notationx to represent a vector-valued variable
38
˙x = f(x) + ω
˙x′ = fxx′ + ω′
˙x′′ = fxx′′ + ω′′
⇒ D˜x = ˜f + ˜ω
The flow at the first orderf is a linear dynamical system with drift matrixA and fixed
point with valueη:
f(x) = −A(x − η) (A.23)
The eigenvalues of theL×L matrix A determine the rate at which the hidden statesx are
assumed to relax to their expected value ofη. In general, this matrix can be parameterized
arbitrarily to encode different kinds of linear couplings among the different hidden states
x1, x2, ..., xL. In the present work we parameterizeA simply as a diagonal matrix with a
single diagonal valueα >0, which can also be expressed as anα-scaled version of the identity
matrix L × L identity matrixIL:
A = −αIL (A.24)
In combination with the amplitude of random fluctuationsΣω, α determines how quickly
the hidden states relax to their mean value ofη.2 The generalised flow function˜f can thus
be written as a linear function of the generalised state˜x:
˜f =


f(x)
fxx′
fxx′′

 = −


A 0 0
0 A 0
0 0 A




x − η
x′
x′′


=


−αIL 0 0
0 −αIL 0
0 0 −αIL




x − η
x′
x′′

 = −α


x − η
x′
x′′

 (A.25)
where 0 are L × L matrices of zeros. We assume a multivariate Gaussian form for the
generalized noises ˜ω, meaning the density over the generalized motionD˜x is a Gaussian
density, which we hereafter refer to as the ‘dynamics model’ or ‘dynamical prior’:
P(D˜x|˜x) = N(D˜x; ˜f, ˜Σω) (A.26)
2Heuristically, it is an exponential decay rate.
39
Consistent with the block diagonal form of the generalised flow function˜f, we also assume
the covariance of the generalized noises˜Σω factorizes into a Kronecker product of ‘spatial’
and ‘temporal’ covariance matrices, i.e.,
˜Σω = Σω ⊗ ˜Σω (A.27)
where the spatial covariance Σω (note the bold superscript ω) represents covariance
between L noise processes at the zero-th orderω[0], i.e.,Σω = E[ω[0] ⊗ω[0]], and˜Σω encodes
covariance between different derivatives of the first order noise, i.e.,∀m, n:

˜Σω

nm
=
E[ω[n] ·ω[m]]. The entries of this covariance matrix can be written in terms of the derivatives
of the autocorrelation function of the random fluctuations evaluated at lag0, ρ(0):
ρ(h) ≜ (Σω)−1E[ω[0](τ) · ω[0](τ + h)]
⇒ ˜Σω =


1 0 ¨ ρ(0)
0 −¨ρ(0) 0
¨ρ(0) 0 ¨¨ρ(0)
...

 (A.28)
The checkerboard structure in the matrix reflects the fact that fluctuations at the first
order are orthogonal to their motion (first derivative), but anti-correlated with their 2nd,
4th, ..., etc. derivatives. A derivation of the temporal covariance matrix from the autocor-
relation function of the first-order fluctuations can be found in Appendix A.5.3 of [13]. In
the generative models of our agents, we assume a Gaussian autocorrelation function with
"smoothness" parameterλω, which yields a simple parameterization of˜Σω:
ρ(h) = e− h
2λω
2
(A.29)
⇒ ˜Σω =


1 0 − 1
2λ2ω
. . .
0 1
2λ2ω
0
− 1
2λ2ω
0 3
4λ4ω
... ...

 (A.30)
A higher value ofλω dampens the variance of the generalised fluctuations at higher orders
of differentiation. The correspondence of increasing λω to an increasingly-autocorrelated
process at the first order becomes intuitive once we consider the case of standard white
noise, i.e., the derivative of the Wiener process, whose higher orders of motion have infinite
variance (the state of the process at a given time changes infinitely quickly). This ability to
handle differentiable noise goes beyond the usual Markovian assumptions made in standard
state space models (e.g., Kalman-Bucy filters), which assume that the driving noise is white.
We parameterize theL × L spatial covarianceΣω through its precision matrixΠω, as a
diagonal matrix whose entries are given by a single precision (inverse variance)Γω:
40
Σω = (Πω)−1 =


Γω 0 0 . . .
0 Γ ω 0
0 0 Γ ω
... ...


−1
(A.31)
The observation likelihood describes sensory observationsy = {y1, y2, ..., yL} as noise-
perturbed copies of the hidden statesx. We truncate generalized observations at second
order, i.e., agents can sense the first order hidden statex and its motionx′:
y = x + z
y′ = x′ + z′ (A.32)
This can be equivalently expressed as a linear function˜g of the full generalised state
˜x = {x, x′, x′′}, where˜g represents multiplication with a non-invertible matrix that discards
acceleration informationx′′:
˜y = ˜g + ˜z
y
y′

=
IL 0 0
0 IL 0


x
x′
x′′

 +
z
z′

(A.33)
We leverage the same assumptions about the sensory noises˜z as we did for the state
noises ˜ω to end up with the following multivariate Gaussian form for the observation model:
p(˜y|˜x) = N(˜y; ˜g, ˜Σz) (A.34)
We parameterize the likelihood model’s sensory noises˜z identically to the state noises˜ω,
namely using a spatial precision parameterΓz and temporal smoothness parameterλz.
Having specified the dynamics and observation models in terms of Gaussian distributions,
we can write out the full generative model as a joint Gaussian density over (generalized)
hidden states and observations. We can furthermore define an approximate posterior over
the hidden states˜x that has a multivariate Gaussian formQ(˜x) = N(˜x; ˜µ; Σν), which can be
summarized entirely in terms of its posterior mean vector˜µ, due to the fact that under the
Laplace approximation the variational covariance depends directly on the mean. From here,
we can define the Laplace-approximated variational free energy for this generative model as
proportional to a sum of squared prediction errors:
41
p(˜y, ˜x) = p(˜y|˜x)p(D˜x|˜x)
= N(˜y; ˜g, ˜Σz)N(D˜x; ˜f, ˜Σω) (A.35)
FL = 1
2
h
˜ε⊤
z ˜Πz˜εz + ˜ε⊤
ω ˜Πω˜εω − ln

|˜Πz||˜Πω||Πν|

+ 3L ln 2π
i
where Πν ≜ (Σν)−1
˜εz = ˜y − ˜g(˜µ) =
 y − µ
y′ − µ′

, ˜εω = D˜µ − ˜f(˜µ) =


µ′ + α(µ − η)
µ′′ + αµ′
αµ′′

 (A.36)
where the sensory prediction errors˜εz score the difference between the generalized ob-
servations y, y′ and their expected valuesµ, µ′, and the model or process prediction errors
˜εω score the difference between the motion of the generalized meansD˜µ and their expected
motion ˜f(˜µ), which has been expanded above using the linear form of the flow function de-
tailed in (A.25). Note that here, due to the Laplace approximation, the generative model’s
expectation functions˜g, ˜f are evaluated at the variational mean˜µ, rendering the variational
beliefs a moving point-estimate of the hidden states˜x.
Filteringconsistsofupdating ˜µ asageneralizedgradientflowonthisenergyfunctional FL
as in (??). To be explicit, below we expand these free energy gradients using the particular
forms of˜g, ˜f used by our self-propelled particle agent:
d˜µ
dt = D˜µ − ∇˜µFL
= D˜µ + ∇˜µ˜g⊤˜ξz + ∇˜µ˜f⊤˜ξω − D⊤˜ξω
where ˜ξz = ˜Πz
 y − µ
y′ − µ′

˜ξω = ˜Πω


µ′ + α(µ − η)
µ′′ + αµ′
αµ′′


∇˜µ˜g =
IL 0 0
0 IL 0

, ∇˜µ˜f =


−αIL 0 0
0 −αIL 0
0 0 −αIL

 (A.37)
This sort of filtering scheme means that the agent’s beliefs˜µ will evolve as a moving
average of incoming sensory data˜y subject to a dynamical bias or "drag", which is a con-
sequence of the latent belief that hidden statesx continuously relax towards a fixed point
at η. Specifically, the beliefs are constantly pulled closer to the data in order to minimize
sensory prediction errors ˜ξz; however, this process itself incurs state prediction errors˜ξω
that will pull the beliefs back towards the fixed point. This constant tug of war between
sensory and process prediction errors can be shifted disproportionately in one direction by
42
adjusting the relative precisions of the likelihood vs. dynamical models, respectively. If the
process precision ˜Πω is high relative to the observation precision˜Πz, then the beliefs will
tend to their expected fixed point ofη. A similar enhancement of prior bias can be achieved
by increasing the drift rateα of the dynamics model, which increases the force drivingµ
towards η — this was the approach taken in [14], for example.
Note that when numerically integrating the differential equation in (A.37) with a forwards
Euler scheme, one uses a finite number of iterations to update the variational means˜µ, which
we termnInferIter, and a step-sizeκµ which scales the size of the increment to˜µ [6]. In all
simulations shown here, we setnInferIter = 1, κµ = 0.1 (see Table E.1 for details).
A.4.2 Closing the loop with observations and action
Inordertointerprettherandomvariablesofthegenerativemodelasrepresentingbehaviorally-
relevant features of an agent’s world, we now turn to specfiying thegenerative process, i.e.,
the actual physics of the world that our self-propelled particle agents will inhabit. In this
section we detail how the observations˜y for a single agent are generated from the positions
and velocities of other active inference agents, and how actions can be generated through
active inference, which in this contexts means changing continuous control variables using a
gradient descent on the same free energy used to derive the belief update equations of the
previous section.
We now shift our perspective to that of a single agent, hereafter referred to as thefocal
individual or focal agent, and specify how its sensory data˜y are generated. We start by
describing univariate hidden states and corresponding observations, where the true hidden
variable is an average nearest-neighbor distancexh. We add theh subscript to distinguish
these ‘real’ variables (hidden states, observations, noise terms) from their representations in
the generative model (e.g.,˜x, ˜y).
We indicate the focal individual with indexi; so the agenti-relative hidden statexh,i
denotes the average nearest-neighbor distance from the perspective of agenti. This average
distance xh,i is calculated from theK neighbors that form the interaction setNin of theith
focal individual. How to define the interaction setNin is a choice to make in each simulation,
but for the case of recapitulating classical, distance-dependent social forces models, we define
Nin as those neighbors that are within a fixed distanceR0 of the focal individual’s position:
xh,i ≜ 1
K
X
j∈Nin
∥∆rij∥
where Nin ≜ {j ̸= i : ∥∆rij∥ ≤R0} (A.38)
K ≜ |Nin|
∆rij ≜ rj − ri (A.39)
An additional filter onNin that is common to self-propelled particle models, is to only
include neighbors that subtend some angular extent (also known as a ‘vision cone’ or ‘visual
43
field’) relative to the focal agent’s velocity vectorvi. This is the approach taken in [15], for
instance, and in the simulations examined in the main text we do the same.
The vectorri denotes the 2-D coordinate of the focal agent, andrj is that of neighborj.
rij thus represents the relative displacement vector of neighbourj, from the perspective of
the focal agenti.
We also define the first temporal derivative of the local average distancex′
h,i:
˜xh,i ≜ (xh,i, x′
h,i)
x′
h,i ≜ dxh,i
dt = ∇rixh,i · vi +
X
j∈Nin
 
∇rj xh,i · vj

(A.40)
where vj is the velocity or heading vector of neighbourj. The expression in (A.40) means
that we can compute the first derivative or velocity of the distancex′
h,i as a function of the
positions and velocities of all agents, as opposed to some discrete-time approximation, e.g.,
x′
h,i ≈ xh,i(t+∆t)−xh,i(t)
∆t for some small∆t. Note that this expression forx′
h,i assumes a local
linearization ofxh,i at the radius defined byR0, i.e., this linearization will be a poor predictor
of the actual change in the statexh,i(t + ∆t) − xh,i(t) when neighbors are instantaneously
leaving or entering the interaction setNin. Observations ˜yh,i are perturbed versions of the
hidden states with additive generalised fluctuations˜zh,i:
yh,i = xh,i + zh,i
y′
h,i = x′
h,i + z′
h,i
where p(˜zh,i) = N(˜zh,i; 0, ˜Σz,h) (A.41)
In all simulations we parameterize the˜zh,i as independent Gaussian variables, i.e.,
˜Σz,h =
σ2
z,h 0
0 σ2
z′,h

(A.42)
where the two variancesσ2
z,h and σ2
z′,h can be set independently. The ‘perception’ step
of our active inference process proceeds by providing these observations to the filtering
equations in (A.37). The result is that posterior means˜µ appears to track˜xh,i over time,
while additionally estimating its higher-order motion (acceleration) viaµ′′′.
Finally, we now furnish a scheme for updating actions by mapping the control variables
a and sensorimotor contingency terms of (A.22) to the case of our distance-tracking self-
propelled agent.
We let actions be identifiable with the heading vectorvi of the focal individual, i.e.,
a = vi. For the simulations presented in the current paper, we always asserted that this
heading have unit magnitude, but in general this constraint is not necessary.
Given this definition of actions, we can unpack the sensorimotor contingency term∂y(a)
∂a
that appeared in the active inference control equation of (A.22), now lettinga = v and
44
turning partial derivatives into Jacobians to account for vectorial nature of actions (being a
velocity in 2-D) and observations (being comprised of two generalized coordinates):
dvi
dt = −∇vi ˜yh,i(vi)⊤∇˜yh,i(vi)FL (A.43)
Note here that observations˜yh,i are a function of actions; this is because observations are
a linear function of hidden states, which themselves are linear in the velocity vector of the
focal individualvi via the relation in (A.40). Importantly, however, the distance observation
yh,i does not directly depend on thevi — only the distance velocityy′
h,i does. This means
the sensorimotor contingency in (A.43) is comprised of non-zero partial derivatives only for
y′
h,i:
∇vi ˜yh,i(vi) =
∇viyh,i(vi)
∇viy′
h,i(vi)

=
 0
∇rixh,i

(A.44)
This has an important consequence for action, when we consider the form of the second
part of the action update in (A.43), the free energy gradient term∇˜yh,iFL:
∇˜yh,iFL = ˜ξz = ˜Πz ˜εz =
 Γz(yh,i − µ)
2Γzλ2
z(y′
h,i − µ′)

(A.45)
The free energy gradient with respect to observations is simply the generalized (precision-
weighted) sensory error˜ξz, which we have written in terms of the observations˜yh,i, posterior
beliefs ˜µ and precision parametersΓz, λz. The sparse form of the sensorimotor contingency
in (A.44) means that the 0th-order prediction errorξz will have no effect on behavior and
only the velocity prediction errorsξ′
z will be relevant for the update tovi, i.e.,
dvi
dt = −

ξz ∇viyh,i(vi)| {z }
=0
+ξ′
z∇viy′
h,i(vi)


= −ξ′
z∇rixh,i
= 2Γzλ2
z(y′
h,i − µ′)∆ˆr
where ∆ˆr = 1
K
X
j∈Nin
∆rij
∥∆rij∥ (A.46)
Note that, as for the inference update in (A.37), we updatevi using a fixed number
of action iterationsnActionIter and step-size κa, where here we setnActionIter = 1 , κa = 0 .1.
This action update equation has a few key implications for the behavior of active inference
agents equipped with this type of generative model, and its relationship to ‘classical’ self-
propelled particle models like the Couzin-Aoki model and the Reynolds or BOIDS model
45
[15–17]. The first is the fact that the sensorimotor contingency is identical to the ‘social
force’ vector used to drive interactions in self-propelled particle models∆ˆr; this the average
of the vectors pointing from each neighbor in the interacting set to the focal agent’s position
ri. The sign of the precision-weighted prediction error ϵ′
z determines whether the social
force is attractive (pointing towards other agents) or repulsive (pointing away from other
agents). Secondly, the fact that actions only depend on velocity observations, rather than
state observations, means that agents will adjust their heading according to how the (sensed)
distance is instantaneously changing (its velocity), rather than its value. This lends action
a predictive, anticipatory power and accounts for why we observe robust polarized motion
in the absence of an explicit alignment term like in classic self-propelled particle models [15,
18]. The alignment-like forces emerges from the fact that the velocity vectors of other agents
vj, j∈ Nin are integrated into the computation ofy′
h,i via the relation in the second line of
(A.40).
One of the defining features of other self-propelled particle models like the Couzin-Aoki
model [15, 16] is the presence and priorization of interaction zones. The two main zones
used in these models, and which on their own are sufficient for group cohesion, are a narrow
repulsion zone defined by some radiusrr and a wider attraction zone with radiusra, where
ra > rr. Neighboring agents within the repulsive radius exert repulsive forces on the focal
agent, while those beyond the repulsion radius but within the attraction zone exert attrac-
tive forces, where the difference between attraction and repulsion is given by the sign of the
force vector∆ˆr. The active inference model leads to an effective notion of zones, but rather
than being explicitly encoded, these zones emerge through the fixed-point attractorη pa-
rameterizing the generative model’s dynamics modelf. This is made clear when we examine
the precision-weighted prediction errorξ′
z, which itself is a function of velocity observations
y′
h,i and velocity beliefsµ′. Consider the limiting case of when inference is strongly biased
by the dynamics modelf (i.e., in the case thatΓω > Γz or largeα); the generalised beliefs
˜µ will be strongly drawn to the setpointη of the dynamics prior, i.e.,
˜µ =


µ
µ′
µ′′

 ≈


η
0
0


Under this assumption, the precision-weighted prediction errorξ′
z approximates2Γzλ2
zy′
h,i,
and thus signals whether neighbors are instantaneously approaching or moving away from
the focal agent, whereξ′
z < 0 indicates they are approaching andξ′
z > 0 indicates they are
moving away. This in turn determines whether the update to the focal agent’s actionvi
is repulsive or attractive, as its sign determines the direction of the social force vector∆ˆr.
Although the first order distanceyh,i does not directly drive action, it does so indirectly
through its effect on inference ofµ′. If we consider the case when the sensed distanceyh,i
drops below the setpointη, then one can reason through the cascade of prediction errors
that ultimately lead to a repulsive force. As a direct consequence of a drop inyh,i below
µ, sensory prediction errorsξz will become negative, whose minimization will requireµ to
move belowη. This process in turn incurs slower-moving (negative) model prediction errors
46
ξω, whose minimization drivesµ back to its fixed point ofη, given the dynamic constraint
for the beliefs to relax to their fixed point. In order to accomplish this upward movement
of µ, either the rate of change ofµ or the sensed distance itself must be positive, i.e.,˙µ >0
or yh,i > 0. In the absence of positiveyh,i, model prediction errors will driveµ′ (and hence
˙µ) above0. This temporarily sets a larger radius of repulsion, i.e., a larger range ofy′
h,i for
which ξ′
z is negative and for which repulsive forces impact the focal agent’s velocity. This
causes the agent to move away from its neighbors and thus further increaseyh,i, under the
assumption that the agent’s prediction of the distance dynamics are correlated with the true
change in xh,i. Belief updating and action thus work together to accelerate the return of
µ towards η and ˜ξz, ˜ξω towards 0; for this reason active inference is often described as an
account of action and perception driven by ‘self-fulfilling prophecy’ [6].
In order to imbue action with a more direct coupling to the neighbors‘ distances as is done
in the classical self-propelled particle models, rather than the velocity of the distance, one
could hand-craft the sensorimotor contingency term∇vi ˜yh,i to enforce a coupling between
yh,i and vi. This would render the action rule equivalent to a ‘soft’-form of PD control
[14], where errors on both the first order state(yh,i − µ) ≈ (yh,i − η) and its derivative
(y′
h,i − µ′) ≈ y′
h,i would drive changes to the velocity.
A.5 Extending to multiple sensory sectors
The results of the previous sections can be straightforwardly extended to the multivariate
case as explored in the main text. The focal agent now senses the local distance computed
across a set of distinct sensory sectors. For the model explored in the current work, we split
up the computation of the local distance variable into a set ofL sensory adjacent sectors
that comprise an arc of a given angle, relative to the agent’s heading vectorvi. We define
the multivariate distance hidden state as follows (dropping the focal agent indexi from the
sector-specific hidden states to avoid subscript overload):
xh,i =


xh,1
xh,2
...
xh,L

 (A.47)
where xh,l ≜ 1
Kl
X
j∈Nl
∥∆rij∥
where Nl is the set of neighbors in thelth sensory sector, andKl = |Nl| (c.f., (A.39)). As
with the scalar hidden state defined above, we also equip the vector of sector distancesxh,i
with corresponding sector-specific, generalized observations˜yh,i, i.e.
47
yh,i = xh,i + zh,i (A.48)
y′
h,i = x′
h,i + z′
h,i
where p(˜zh,i) = N(˜zh,i; 0, ˜Σz,h) (A.49)
such that the focal individual now observes a vector of local (noise-perturbed) distances
and their first orders of motion. Note that the generalized covariance matrix here˜Σz,h is now
a 2L × 2L size matrix, that encodes the covariance structure between sector-specific noise
and their generalized orders. For all simulations we generated uncorrelated noise across
the different sectors, although spatially-smooth noise could be modelled by introducing off
diagonal elements in˜Σz,h, i.e.,E[zh,lzh,k] ̸= 0.
The agent’s generative model is also extended to the multivariate state-space formulation
we began with, using a vector of generalised hidden states˜x = (˜x1, ˜x2, ...,˜xL) to estimate
the local distance within each sensory sector. Belief-updating consists in updating a vector
of generalised means˜µ through integration of (A.37).
The action update has an identical form as before, except now the sensorimotor con-
tingency term ∇vi ˜yh,i(vi) is a collection of partial derivative vectors, one for each sensory
sector:
dvi
dt = −∇vi ˜yh,i(vi)⊤∇˜yh,iFL
∇vi ˜yh,i(vi) =
∇viyh,i(vi)
∇viy′
h,i(vi)

=


0
...
0
∇rixh,1
∇rixh,2
...
∇rixh,L


(A.50)
Thelast L rowsofthisJacobianmatrixencodethegradientsofthesector-specificdistance
velocities y′
h,l with respect to the focal agent’s action; these partial derivatives are vectors
pointing from the average position of the neighbors in sectorl towards the focal individual.
When we combine the Jacobian matrix in (A.50) with the sensory prediction error term
˜yh,i (i.e., the free energy gradients∇˜yh,iFL), we are left with the following update for the
velocity:
48
dvi
dt = ξ′
z · ∆ ˆR =
ξ′
z,1 ξ′
z,2 . . . ξ′
z,L

·


∆ˆr1
∆ˆr2
...
∆ˆrL


=
LX
l=1
ξ′
z,l∆ˆrl = 2Γzλ2
z
LX
l=1
(y′
h,l − µ′
l)∆ˆrl (A.51)
where ∆ˆrl = 1
Kl
X
j∈Nl
∆rij
||∆rij||
The action thus becomes a weighted sum of ‘sector-vectors’∆ˆrl, which are vectors point-
ing from the focal agent’s positionri towards the average position of the neighbors inNl.
The weights that scale each∆ˆrl are the precision-weighted prediction errors associated with
velocity observations emanating from the appropriate sectorξ′
z,l ∝ (y′
h,l − µ′
l). The fact we
can pull the spatiotemporal precision terms2Γzλ2
z outside the sum over sector-vectors, inher-
its from a between-sector independence assumption, built into the agent’s sensory likelihood
model P(˜y|˜x) (see (A.31)). If the generative model allowed for between-sector correlations
(i.e. Σz was not diagonal), then the action update would include cross-terms that couple
prediction errors from one sector to the sector-vector from another sector.
An active inference agent equipped with such a multivariate representation of the local
neighbor-distances thus engages in a sort of ‘predictive balancing-act’, differentially respond-
ing more or less to each part of its sensory field in accordance with how much sensations
deviate from their posterior expectationsµ′
l, where the sign and degree of this deviation is
scored byξ′
z,l.
Gaussianity of the generative model
One may question the use of a Gaussian form for the generalized noises˜z, ˜ω and a linear
form for˜f and ˜g. These assumptions guarantee a simple generative model whose free energy
gradients (with respect to both the state belief˜µ and actionv) are linear in the generalized
distance observations˜y. The reason we use a Gaussian form here, is to achieve those simple,
linear free energy gradients, i.e., those which align with the classical social forces seen in
SPP models (more specifically, the selective attraction-and-repulsion forces first described in
[19]); in other words, it is exactly an active inference model equipped with this sort of model
(and observations with two generalized coordinates, aka position and velocity) that acts in
a way equivalent to being driven by vectorial social forces. Note that this also means the
Laplace approximation to the posterior over˜x is not an approximation at all, but leads to
exact inference.
Existing social force models where the forces are linear in the state, can thus be read
as special cases of active inference agents equipped with Gaussian generative models – this
is a close cousin to the relationship between linear PID controllers and Gaussian active
49
inference models derived in [14]. However, if we were to use a different, non-Gaussian of the
generative model (either through breaking Gaussianity of the noise model or by introducing
nonlinear forms of ˜f, ˜g), then the updates to the beliefs and actions would no longer be
linear functions of the generalized posterior means ˜µ and observations ˜y, but could be
arbitrary, nonlinear functions of these variables – and the resulting social forces would have
no guaranteed interpretation in terms of attraction and repulsion. Such extensions are
an interesting avenue for future work; one interesting possibility would be to explore new
extensions of social forces, where the noises˜z, ˜ω are assumed to belong to the exponential
family and that the dynamics model˜f is smooth and contains attracting fixed points (i.e.,
regions of˜ xwhere the derivatives of˜f vanish). A obvious consequence of such assumptions,
is that when the posterior belief˜µ is near these fixed points, i.e.,˜µ ≈ arg min˜x ∇˜x˜f(˜x) =⇒
˜µ′ = 0, wewouldstillrecoverattractiveandrepulsivesocialforceswhosemagnitudewouldbe
approximately linear in the distance observations˜y. This is equivalent to making a locally-
quadratic (i.e., Laplace) approximation to the free energy landscape around its minima –
this corresponds to just those points in belief-space where the posterior is well-approximated
by a Gaussian.
B Alignment forces from active inference on angles
In previous sections we have shown how repulsive and attractive forces emerge from active
inference models in which the agent entertains a latent representation of the average local
distance between itself and its neighbors, and how its heading direction couples to (the
derivative of) that variable. In this section we derive alignment-based social forces, like
those that appear in the Reynolds, Couzin, and Vicsek models [15, 17, 18], as a special case
of active inference, where an agent infers the (cosine) angle between its own heading and
that of its neighbors, and acts under the prior belief that this angle tends to0.
As before, we start with a generative model that represents a generalised latent variable
˜xϕ that evolves in time with Gaussian additive fluctuations˜ωϕ. We use the ϕ subscript
to distinguish this angle-tracking latent variable from the distance-tracking variable of the
previous section. We truncate the generalized representation of this state at second order,
i.e. ˜xϕ = {xϕ, x′
ϕ}, leading to a dynamical equation and corresponding likelihood of the
following form:
˙xϕ = −αϕ(xϕ − 1) + ωϕ
˙x′
ϕ = −αϕx′
ϕ + ω′
ϕ
=⇒ p(D˜xϕ|˜xϕ) = N(D˜xϕ; ˜fϕ, ˜Σωϕ) (B.52)
where ˜fϕ =
−αϕ(xϕ − 1)
−αϕx′
ϕ

, ˜Σωϕ =
"
σ2
ωϕ 0
0 σ2
ω′
ϕ
#
(B.53)
The observation model describes a mapping from the0th-order state to a corresponding
observation thereof, perturbed again by Gaussian innovations:
50
yϕ = xϕ + zϕ
=⇒ p(yϕ|xϕ) = N(yϕ; xϕ, σ2
zϕ) (B.54)
Following the same steps as we did previously for the multivariate, distance-tracking
generative model, we can write down the Laplace-approximated variational free energy of
this model as a quadratic function of the observations and generalized means˜µϕ:
FL ∝ ε⊤
zϕΠzϕεzϕ + ˜ε⊤
ωϕ
˜Πωϕ ˜εωϕ
where εzϕ ≜ yϕ − µϕ
˜εωϕ ≜ D˜µϕ − ˜fϕ
The agent performs a gradient descent onFL to infer the value of˜xϕ in light of sensory
observations. This inference is encoded by a Gaussian variational posterior with mean˜µϕ. As
before, we can tune model parameters such that inference is strongly biased by the dynamics
model ˜fϕ, where the zeroth-order of motionµϕ ≈ 1. The reason we set the set-point at1
becomes evident when we consider the generation of sensory data and actions.
Assume that the focal agent with indexi observes the local average cosine angle between
its own heading vectorvi and those of its neighborsvj, j∈ Nin, where neighbors are once
again defined by membership in some interaction zone3:
yϕ = 1
K
X
j∈Nin
v⊤
i vj = ⟨cos(θij⟩Nin (B.55)
where the equivalence between the dot products and the cosine angle is assured when we
assume allvk, k∈ {i} ∪Nin have unit magnitude. Recall that if two unit-magnitude vectors
vi, vj are parallel, their dot product (cosine angle) is 1. When we once again assume that
agents act by adjusting their heading direction, then the action update given the continuous
active inference rule in (A.22) has the following form:
dvi
dt = − 1
σ2
zϕ
(yϕ − µϕ)ˆv ≈ (1 − yϕ)ˆv (B.56)
where ˆv = 1
K
X
j∈Nin
vj (B.57)
The approximation in the first line holds when we assume the sensory varianceσ2
zϕ is
1 and the dynamics prior (either via increasingα or decreasing σ2
ωϕ) dominates inference
3For notational convenience and because it doesn’t change the derivations, we omit observation noise on
yϕ.
51
such thatµϕ ≈ 1. In this case, the focal agenti then updates its velocity using the average
neighbor velocity. This is proportional to the alignment force in e.g. [15, 18], except that
it is also scaled by how unaligned the focal individual is with its neighbourhood, scored by
1 − yϕ.
C Online parameter estimation
In this section we derive update rules for the generative model parameters using a simple
gradient descent scheme on the Laplace-approximated variational free energy. In the active
inference literature this process of updating parameters, as opposed to beliefs about states,
is often analogized to online learning or neural plasticity [20, 21].
C.1 Updating sensory smoothness
In this section we derive an update equation for the sensory smoothness parameterλz, which
captures the generative model’s assumptions about the temporal autocorrelation structure
of sensory noisez.
Recall the formulation of state space models in generalized coordinates of motion in
Section A.1. In addition to providing a concise description of local paths of the state⃗ xt in
terms of its higher derivativesx′, x′′, ..., x[n], stochastic differential equations in generalized
coordinates also allow one to expressserial correlationsin the noises at the first orderz, by
assuming that it can be differentiated (has non-zero, smooth autocovariance) and represented
in terms of hierarchical or generalized noisesz′, z′′, z′′′, ..., z[n].
Recall the parameterization of the generalized sensory precision˜Πz as a factorization
into two precision matrices, that respectively represent agent’s beliefs about the ‘spatial’ and
‘temporal’ covariance structure. We parameterize these with the two precision parameters
Γz and λz. Γz encodes the agent’s belief about the overall magnitude of the fluctuations, and
λz encodes beliefs about their their serial correlations in time, assuming a Gaussian form for
their autocorrelation:
˜Πz = S(λz) ⊗ Π(Γz)
Π(Γz) =


Γ11
Γ22
...
ΓLL


S(λz) =


1 0 − 1
2λ2z
. . .
0 1
2λ2z
0
− 1
2λ2z
0 3
4λ4z
... ...


−1
(C.58)
52
We implement a form of behavioral plasticity by allowing agents to updateλz using
observations. We accomplish this using a gradient descent on variational free energy:
dλz
dt = −κθ
∂F
∂λz
(C.59)
where the ‘learning rate’κθ is typically set to be at least an order of magnitude lower
than the update rate of inferenceκµ; in all simulations we useκθ = 0.001 and nLearnIter = 1
iteration. This enforces a separation of timescales that is typical in generalized filtering and
state-space models that perform simultaneous state- and parameter-estimation [3, 5, 14].
To compute the gradients of the variational free energy with respect toλz, we can start
by expressing those components of the (Laplace-approximated) variational free energy that
depend onλz:
F(λz) = ˜ε⊤
z ˜Πz˜εz − ln

det ˜Πz

(C.60)
where we only have included the terms that depend on the sensory precision˜Πz due to
its dependence onλz. The full gradient is then simply:
∂F
∂λz
= ˜ε⊤
z ˜Πz˜εz
∂λz
−
∂ ln

det ˜Πz

∂λz
(C.61)
Starting with the case of a single sensory sectorL = 1, then the generalized prediction
error ˜εz is a vector of prediction errors, one for each order of motion:˜εz = {εz, ε′
z, ε′′
z, ...}
where a sensory prediction error at a given order of motion is simply:ε[n]
z = y[n] −˜g[n], where
the n subscript refers to an order of differentiation. In the case of3 generalized coordinates
for the simple scalar case:
∂F
∂λz
= 4Γzλz(ε′
z)2 + ε′′
z(8Γzε′′
zλ3
z + 2Γzεzλz) + 2Γzλzεzε′′
z − 6
λz
= 4Γzλz(εzε′′
z + (ε′
z)2 + 2λ2
z(ε′′
z)2) − 6
λz
(C.62)
Meaning that the update for theλz parameter can be simplified to (omitting the learning
rate κθ):
dλz
dt = −4Γzλz(εzε′′
z + (ε′
z)2 + 2λ2
z(ε′′
z)2) + 6
λz
(C.63)
In the case of the distance-tracking generative model we explore in the main text, we
assume that the agents can only observe the0th (position, y) and 1st (velocity,y′) orders of
53
motion of the hidden states˜x. This means there are no longer 2nd-order prediction errorsε′′
z
and the update becomes even simpler:
dλz
dt = −4Γzλz(ε′
z)2 + 6
λz
≈ −4Γzλz(y′
h,i)2 + 6
λz
(C.64)
where approximation in the second line results in the case of ‘biased’ inference, i.e.,
µ ≈ η =⇒ µ′ ≈ 0, allowing us to replace the velocity prediction errory′
h,i − µ′ with y′
h,i.
Given that spatial and temporal precisions are independent from each other due to the
factorization of the generalized precision matrix, and further given the diagonal structure of
the spatial precisionΠz (i.e., independence in random fluctuations across sensory sectors),
we can write an update forλz that is a sum of squared prediction errors across sensory
sectors:
dλz
dt ≈ −4Γzλz
LX
l=1
(y′
h,l)2 − 6L
λz
(C.65)
The quadratic form of this update means that the update to the smoothness parameter
decays in proportion with the overall magnitude of the velocity prediction errors, regardless
of its sign. This means that if the distance is fluctuating quickly in any direction, then the
agent will infer that fluctuations are slightly-less serially-correlated at the0th order, reflected
by a decrease inλz.
D Addingatargetrepresentationintothegenerativemodel
As described in the main text, it is straightforward to add an additional observation model
and dynamics model to an agent’s generative model to represent the distance between itself
and some abstract spatial target, which in the context of the collective information transfer
experiments, we represent withT:
˙xtarget = −αtargetxtarget + ωtarget ytarget = xtarget + ztarget
˙x′
target = −αtargetx′
target + ω′
target y′
target = x′
target + z′
target (D.66)
We truncate the generalized hidden states at third order˜xtarget = (xtarget, x′
target, x′′
target)
and the observations at second order˜ytarget = (ytarget, y′
target). When the agent assumes the
generalized noises˜ωtarget and ˜ztarget are zero-mean and normally-distributed with covariances
˜Σωtarget and ˜Σztarget and leverage the Laplace approximation exactly as we did in the previ-
ous section, then we can supplement the Laplace-approximated free energy in (A.35) with
additional terms corresponding to target-related prediction errors:
54
FL ∝ 1
2
h
˜ε⊤
z-Soc ˜Πz-Soc˜εz-Soc + ˜ε⊤
ω-Soc ˜Πω-Soc˜εω-Soc + ˜ε⊤
z-Tar ˜Πz-Tar˜εz-Tar + ˜ε⊤
ω-Tar ˜Πω-Tar˜εω-Tar
i
+ C
(D.67)
Here we use the suffixes "-Soc" or "-Tar" to indicate ‘social’ relevant information (re-
lated to the average neighbor distance) and the ‘target’ prediction errors.C captures all
the additional terms (log determinants of precision matrices, etc.) that are constant with
respect to the posterior means˜µ = ( ˜µSocial, ˜µTarget). Following the same reasoning as used
to derive the inference and action rules for the case of the social distance hidden states
and observations(˜xSocial, ˜ySocial), we can do the same to derive active inference rules for the
target-relevant hidden states and observations˜xtarget, ˜ytarget:
d˜µSocial
dt = D˜µSocial − ∇˜µSocial FL(˜µSocial, ˜ySocial) dv
dt = −(∇vFL(˜µSocial, ˜ySocial) + ∇vFL(˜µTarget, ˜yTarget))
d˜µTarget
dt = D˜µTarget − ∇˜µTargetFL(˜µTarget, ˜yTarget) (D.68)
Where expanding the free energy gradients on the right equation leads to an expression
for the action update in terms of a precision-weighted sum of vectors, appearing in (18) in
the main text.
E Numerical methods
We used a forwards Euler-Maruyama scheme to the integrate a (Itô-style) stochastic differ-
ential equation for the positions of all agents over time:
drt = vtdt + σadWt (E.69)
where the variance of ‘action noise’σ2
a was set to0.01 for all experiments unless explicitly
stated otherwise. We used a step size of∆t = 0 .01s in the integration. For the current
timestep τ in ‘simulation time’, we used a simple forwards Euler scheme to integrate the
differential equations used for belief updating (see (A.37)) and action (see (A.43)) for each
agent in parallel. We use the positions and heading vectors of all agents from the previous
integration timestep (τ − ∆t) to generate the observations for the current timestep.
The collective information transfer experiments were performed using custom Julia code,
and all other simulations were implemented in JAX using custom code. To accelerate the
parameter scans overpinf , Γz-Social, andΓz-Target to create the results in Figure 3 in the main
text, we used the high-performance computing clusters (Cobra and Draco) provided by the
Max Planck Computing and Data Facility.
55
Table E.1:Default parameter configuration used in numerical simulations (unless otherwise
stated). First column denotes the name of the parameter, second column denotes its default
value and third column indicates whether the parameter concerns the generative process (the
physics of the simulation environment), the generative model used for active inference, or a
hyperparameter (e.g., used in the active inference algorithm).
Parameter Value Type
∆t (Euler integration step, in seconds) 0.01 generative process
Number of sensory sectors 4 generative process
Sector angle (in degrees◦) 60 generative process
R0 (interaction radius, in arbitrary units) 5 generative process
σ2
a 0.01 generative process
σ2
z,h 0.01 generative process
σ2
z′,h 0.01 generative process
Γz 1.0 generative model
Γω 1.0 generative model
λz 1.0 generative model
λω 1.0 generative model
α 0.5 generative model
αtarget 0.5 generative model
η 1.0 generative model
Number of generalised coordinates (x) 3 hyperparameter
Number of generalised coordinates (y) 2 hyperparameter
κµ 0.1 hyperparameter
nInferIter 1 hyperparameter
κa 0.1 hyperparameter
nActionIter 1 hyperparameter
κθ 0.001 hyperparameter
nLearnIter 1 hyperparameter
56
Supplemental References
[1] Karl Friston, Klaas Stephan, Baojuan Li, and Jean Daunizeau. “Generalised filtering”.
In: Mathematical Problems in Engineering2010 (2010).
[2] Karl Friston. “Hierarchical models in the brain”. In:PLoS computational biology4.11
(2008).
[3] Bhashyam Balaji and Karl Friston. “Bayesian state estimation using generalized coor-
dinates”. In:Signal processing, sensor fusion, and target recognition XX8050 (2011),
pp. 716–727.
[4] Karl J Friston. “Variational filtering”. In:NeuroImage 41.3 (2008), pp. 747–766.
[5] Karl J Friston, N Trujillo-Barreto, and Jean Daunizeau. “DEM: a variational treatment
of dynamic systems”. In:Neuroimage 41.3 (2008), pp. 849–885.
[6] Christopher L Buckley, Chang Sub Kim, Simon McGregor, and Anil K Seth. “The
free energy principle for action and perception: A mathematical review”. In:Journal
of Mathematical Psychology81 (2017), pp. 55–79.
[7] Karl Friston, Lancelot Da Costa, Noor Sajid, Conor Heins, Kai Ueltzhöffer, Grigorios
A Pavliotis, and Thomas Parr. “The free energy principle made simpler but not too
simple”. In:Physics Reports1024 (2023), pp. 1–29.
[8] Karl Friston. “A theory of cortical responses”. In: Philosophical transactions of the
Royal Society B: Biological sciences360.1456 (2005), pp. 815–836.
[9] Karl Friston and Stefan Kiebel. “Predictive coding under the free-energy principle”. In:
Philosophical Transactions of the Royal Society B: Biological Sciences364.1521 (2009),
pp. 1211–1221.
[10] Yanping Huang and Rajesh PN Rao. “Predictive coding”. In:Wiley Interdisciplinary
Reviews: Cognitive Science2.5 (2011), pp. 580–593.
[11] Rick A Adams, Stewart Shipp, and Karl J Friston. “Predictions not commands: active
inference in the motor system”. In:Brain Structure and Function218.3 (2013), pp. 611–
643.
[12] Karl Friston. “What is optimal about motor control?” In:Neuron 72.3 (2011), pp. 488–
498.
[13] Thomas Parr, Giovanni Pezzulo, and Karl J Friston.Active inference: the free energy
principle in mind, brain, and behavior. MIT Press, 2022.
[14] Manuel Baltieri and Christopher L Buckley. “PID control as a process of active infer-
ence with linear generative models”. In:Entropy 21.3 (2019), p. 257.
[15] Iain D Couzin, Jens Krause, Richard James, Graeme D Ruxton, and Nigel R Franks.
“Collective memory and spatial sorting in animal groups”. In:Journal of theoretical
biology 218.1 (2002), pp. 1–12.
57
[16] Ichiro AOKI. “A Simulation Study on the Schooling Mechanism in Fish”. In:NIPPON
SUISAN GAKKAISHI 48.8 (1982), pp. 1081–1088.doi: 10.2331/suisan.48.1081.
[17] Craig W Reynolds. “Flocks, herds and schools: A distributed behavioral model”. In:
Proceedings of the 14th annual conference on Computer graphics and interactive tech-
niques. 1987, pp. 25–34.
[18] Tamás Vicsek, András Czirók, Eshel Ben-Jacob, Inon Cohen, and Ofer Shochet. “Novel
type of phase transition in a system of self-driven particles”. In:Physical review letters
75.6 (1995), p. 1226.
[19] Pawel Romanczuk, Iain D Couzin, and Lutz Schimansky-Geier. “Collective motion due
to individual escape and pursuit response”. In:Physical Review Letters102.1 (2009),
p. 010602.
[20] Karl Friston, Thomas FitzGerald, Francesco Rigoli, Philipp Schwartenbeck, Giovanni
Pezzulo, et al. “Active inference and learning”. In:Neuroscience & Biobehavioral Re-
views 68 (2016), pp. 862–879.
[21] Lancelot Da Costa, Thomas Parr, Noor Sajid, Sebastijan Veselic, Victorita Neacsu,
and Karl Friston. “Active Inference on Discrete State-Spaces: A Synthesis”. In:Journal
of Mathematical Psychology99 (Dec. 2020), p. 102447.issn: 0022-2496.doi: 10.1016/
j.jmp.2020.102447. (Visited on 01/27/2021).
Supplemental Movie Legends
Movie 1 Example of a simulation ofN = 96 agents that includes a dynamic transition
from polarized to milling regime. Parameters: σ2
z′,h = 0.05; Sector angle = 80◦; R0 = 10
units; κa = 0.2; λω = 0.5; λz = 2.0. Unless specified, all remaining parameters are as listed
in Table E.1.
Movie 2 Example of a polarized group ofN = 64 agents. Parameters: Sector angle= 80◦;;
κa = 0.2; λω = 0.5; λz = 1.5.
Movie3 Exampleofamillingregimeobservedin N = 64 agents. Parameters: σ2
z′,h = 0.04;
Sector angle= 80◦; α = 1.0; κa = 0.2; λω = 0.8; λz = 1.8.
Movie 4 Example of a disordered regime observed inN = 96 agents. Parameters: Number
of sensory sectors= 2; Sector angle= 160◦; R0 = 10.0 units; α = 0.2; η = 0.5, κa = 0.2;
λω = 0.1; λz = 1.787.
Movie 5 Metastable ‘snaking’ configuration observed in N = 64 agents. Parameters:
σ2
z′,h = 0.04; Sector angle= 80◦; α = 0.1; κa = 0.2; λω = 0.5; λz = 2.2.
58
Fragmentation probability
Figure E.1:Fragmentation probability as a function of the two precision parameterslog Γz
and λz. Fragmentation probability was quantified as the proportion of trials (out of 500 inde-
pendent trials per condition) where the group fragmented. A trial was considered fragmented
if least one individual was further than 2.0 dimensionless units from all other individuals for
at least 3 of the last 10 seconds of the 15-second trial. All other parameters are identical to
those used in Figure 2B in the main text.
59