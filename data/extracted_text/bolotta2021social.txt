SOCIAL NEURO AI:
SOCIAL INTERACTION AS THE "DARK MATTER " OF AI
A PREPRINT
Samuele Bolotta
Department of Computer Science and Operations Research
Université de Montréal
Montreal, QC, H2S 3H1
samuele.bolotta@ppsp.team
Guillaume Dumas
Mila - Quebec Artiﬁcial Intelligence Institute
CHU Sainte-Justine Research Center, Department of Psychiatry
Université de Montréal
Montreal, QC, H2S 3H1
guillaume.dumas@ppsp.team
April 12, 2022
ABSTRACT
This article introduces a three-axis framework indicating how AI can be informed by biological
examples of social learning mechanisms. We argue that the complex human cognitive architecture
owes a large portion of its expressive power to its ability to engage in social and cultural learning.
However, the ﬁeld of AI has mostly embraced a solipsistic perspective on intelligence. We thus argue
that social interactions not only are largely unexplored in this ﬁeld but also are an essential element
of advanced cognitive ability, and therefore constitute metaphorically the “dark matter” of AI. In
the ﬁrst section, we discuss how social learning plays a key role in the development of intelligence.
We do so by discussing social and cultural learning theories and empirical ﬁndings from social
neuroscience. Then, we discuss three lines of research that fall under the umbrella of Social NeuroAI
and can contribute to developing socially intelligent embodied agents in complex environments.
First, neuroscientiﬁc theories of cognitive architecture, such as the global workspace theory and the
attention schema theory, can enhance biological plausibility and help us understand how we could
bridge individual and social theories of intelligence. Second, intelligence occurs in time as opposed
to over time, and this is naturally incorporated by dynamical systems. Third, embodiment has been
demonstrated to provide more sophisticated array of communicative signals. To conclude, we discuss
the example of active inference, which offers powerful insights for developing agents that possess
biological realism, can self-organize in time, and are socially embodied.
arXiv:2112.15459v3  [cs.MA]  11 Apr 2022
Social Neuro AI: Social Interaction as the "dark matter" of AI A PREPRINT
1 The importance of social learning
Social learning categories Various approaches have
been proposed in order to reach a human-like level of
intelligence. For example, some argue that scaling foun-
dational models (self-supervised pretrained deep network
models), data and compute can lead to such kind of in-
telligence Yuan et al. [2022], Bommasani et al. [2021].
Others argue that attention, understood as a dynamical con-
trol of information ﬂow Mittal et al. [2020], is all we need.
Transformers have proposed a general purpose architecture
where inductive biases shaping the ﬂow of information are
learned from the data itself Vaswani et al. [2017]; this ar-
chitecture can be applied to various domains ranging from
sequence learning to visual processing and time-series fore-
casting. Others argue that by having a complex enough
environment, any reward should be enough to elicit some
complex behaviour and end up in intelligent behaviour that
subserves the maximisation of such reward. This therefore
discards the idea that specialised problem formulations
are needed for each ability Silver et al. [2021]. Our pro-
posal stems from the idea that human cognitive functions
such as theory of mind (the capacity to understand other
people by ascribing mental states to them) and explicit
metacognition (the capacity to reﬂect on and justify our
behaviour to others) are not genetically programmed, but
rather constructed during development through social in-
teraction Heyes [2018]. . Since their birth, social animals
use their conspeciﬁcs as vehicles for gathering informa-
tion that can potentially help them respond efﬁciently to
challenges in the environment, avoiding harm and maxi-
mizing rewards Kendal et al. [2018]. Learning adaptive
information from others results in better regulation of task
performance, especially by gaining ﬁtness beneﬁts and in
avoiding some of the costs associated with asocial, trial-
and-error learning, such as time loss and energy loss as
well as exposure to predation Clark and Dumas [2016]. Im-
portantly, cultural inheritance permeates a broad array of
behavioural domains, including migratory pathways, for-
aging techniques, nesting sites and mates Whiten [2021].
The spread of such information across generations gives
social learning a unique role in the evolution of culture and
therefore makes it a crucial candidate to investigate the
biological bases of human cognition Gariépy et al. [2014].
In the current paper, we do not focus extensively on the
differences between social learning in humans and in other
animals as the cognitive processes used in acquiring be-
haviour seem to be very similar across a wide range of
species Heyes [2012]. What sets humans apart from other
animals, however, is: a) social learning in humans is highly
rewarded from early infancy Nielsen et al. [2012] b) the
nature of the inputs surrounding humans is way more com-
plex than for other animals Heyes [2012]. According to
the ontogenetic adaptation hypothesis Tomasello [2020],
human infant’s unique social-cognitive skills are the result
of shared intentionality (capacity to share attention and
intention) and are adaptations for life in a cultural group -
with individuals coordinating, communicating and learn-
ing from each other in several ways. Recent reviews have
identiﬁed four main categories of social learning that differ
in what is socially learnt and in the cognitive skills that
are required Hoppitt and Laland [2008], Whiten [2021]
(Figure 1). These categories have been developed through
the approach of behaviourism. While we acknowledge
that there is more to social learning than mere behaviour
(the affective and cognitive dimensions are equally crucial
Gruber et al. [2021]), we keep it as the focus of this short
article because it is an empirically solid starting point with
clariﬁed mechanisms. The purpose of this section, then, is
to give an example of social learning mechanisms that are
common across multiple species and can be understood as
a natural form of Social Neuro-AI. Moreover, this section
aims at demonstrating how social interactions are a key
component of biological intelligence; we make the case
that they might be of inspiration for the development of
socially intelligent artiﬁcial agents that can cooperate efﬁ-
ciently with humans and with each other. In other words,
although there are examples of social agents (chatbots,
non-player characters in video games, social robots), we
argue that social interactions still remain the "dark mat-
ter" of the ﬁeld. These social behaviours often emerge
from a Piagetian perspective on human intelligence. As
argued by Kovaˇc et al. [2021], mainstream Deep Reinforce-
ment Learning research sees intelligence as the product of
the individual agent’s exploration of the world; it mainly
focuses on sensorimotor development and problems involv-
ing interaction with inanimate objects rather than social
interactions with animate agents. This approach can and
has given rise to apparent social behaviours, but we argue
that this is not the best approach, as it does not involve any
focus on the genuine social mechanisms per se Dumas et al.
[2014a]. Instead, it sees social behaviours as a collateral
effect of the intelligence of a solitary thinker. For this rea-
son, as Schillbach and colleagues (2013) argued a decade
ago that social interactions were the "dark matter" of cog-
nitive neuroscience, here we argue that social interactions
can also be considered metaphorically as the "dark matter"
of AI Schilbach et al. [2013]. Indeed, more than being a
rather unexplored topic, social interactions can constitute a
critical missing piece for the understanding and modelling
of advanced cognitive abilities.
At the most elementary level, enhancement consists of an
agent observing a model that focuses on particular objects
or locations and consequently adopting the same focus
Heyes [1994], Thorpe [1963]. For example, it was demon-
strated that bees outside the nest land more often on ﬂowers
that they had seen preferred by other bees Worden and Pa-
paj [2005]. This skill requires social agents to perform
basic associative learning in relation to other agents’ ob-
served actions; it is likely to be the most widespread form
of social learning across the animal kingdom. A more
complex form of social learning consists of observational
conditioning, which exposes a social agent to a relation-
ship between stimuli Heyes [1994]; this exposure causes a
change in the agent. For example, the observation of ex-
perienced demonstrators facilitated the opening of hickory
nuts by red squirrels, relative to trial-and-error learning
Weigl and Hanson [1980]. This is therefore a mechanism
through which agents learn the value of a stimulus from
2
Social Neuro AI: Social Interaction as the "dark matter" of AI A PREPRINT
the interaction with other agents. Yet a more complex form
of social learning consists of affordance learning, which
allows a social agent to learn the operating characteristics
of objects or environments by observing the behaviour of
other agents Whiten [2021]. For example, pigeons that
saw a demonstrator push a sliding screen for food made
a higher proportion of pushes than observers in control
conditions, thus exhibiting affordance learning Klein and
Zentall [2003]. In other words, the animals perceive the
environment partly in terms of the action opportunities that
it provides. Finally, at the most complex level, copying
another individual can take the shape of pure imitation,
where every detail is copied, or emulation, where only
a few elements are copied Byrne [2002]. For example,
most chimpanzees mastered a new technique for obtain-
ing food when they were under the inﬂuence of a trained
expert, whereas none did so in a population lacking an
expert Whiten [2005]. As to what is required for imita-
tion, there are debates in the literature ranging from the
distinctions between program-level and production-level
imitation Byrne [2002] to the necessity of pairing Theory
of Mind (ToM) with behavioural imitation to obtain ‘true’
imitation Call et al. [2005]. We refer the reader to Breazeal
and Scassellati [2002] for a more detailed discussion of
imitation in robots.
Social learning strategies Crucially, while social learn-
ing is widespread, using it indiscriminately is rarely bene-
ﬁcial. This suggests that individuals should be selective in
what, when, and from whom they learn socially, by follow-
ing ‘social learning strategies’ (SLSs; Kendal et al. [2018]).
Several SLSs might be used by the same population and
even by the same individual. The aforementioned cate-
gories of social learning have been shown to be reﬁned by
modulating biases that can strengthen their adaptive power
Kendal et al. [2018]. For example, an important SLS is
copying when asocial learning would be costly; research
has shown that, when task difﬁculty increases, various ani-
mals are more likely to use social information. Individuals
also prefer using social information when they are uncer-
tain about a task; high-ﬁdelity copying is observed among
children who lack relevant personal information Wood
et al. [2013]. In general, other state-based SLSs can affect
the decision to use social information, such as age, social
rank, and reproductive state of the learner; for example,
low- and mid-ranking chimpanzees are more likely to use
social information than high-ranking individuals Kendal
et al. [2015]. Model-based biases are another crucial cat-
egory; for example, children prefer to copy prestigious
individuals, where status is evidenced by their older age,
popularity and social dominance Flynn and Whiten [2012].
Multiple evidence also suggests that a conformist transmis-
sion bias exists, whereby the behaviour of the majority of
individuals is more likely to be adopted by others Kendal
et al. [2018].
Social learning in neuroscience We have presented ev-
idence that social learning is a crucial hallmark of many
species and it manifests itself across different behavioural
domains; without it, animals would lose the possibility
to quickly acquire valuable information from their con-
speciﬁcs and therefore lose ﬁtness beneﬁts. However, one
important question is: how does the brain mediate social
processes and behaviour? Despite the progress made in so-
cial neuroscience and in developmental psychology, only
in the last decade, serious efforts have started focusing
on the answer to this question - as neural mechanisms of
social interaction were seen as the “dark matter” of social
neuroscience Schilbach et al. [2013]; recently, a framework
for computational social neuroscience has been proposed,
in an attempt to naturalize social interaction Tognoli et al.
[2018]. At the intra-brain level, it was demonstrated that
social interaction is categorically different from social per-
ception and that the brain exhibits different activity patterns
depending on the role of the subject and on the context in
which the interaction is unfolding Dumas et al. [2012a].
At the inter-brain level, functional Magnetic Resonance
Imaging (fMRI) or Electroencephalography (EEG) record-
ings of multiple brains (i.e. hyperscanning) have allowed
to demonstrate inter-brain synchronization during social
interaction - speciﬁcally, while subjects were engaged in
spontaneous imitation of hand movements Dumas et al.
[2010]. Interestingly, the increase in coupling strength
between brain signals was also shown to be present during
a two-person turn-taking verbal exchange with no visual
contact, in both a native or a foreign language context
Pérez et al. [2019]. Inter-brain synchronization is also
modulated by the type of task and by the familiarity be-
tween subjects Djalovski et al. [2021]. Overall, this shows
that, beyond their individual cognition, humans are also
coupled in the social dimension. Interestingly, the ﬁeld
of computational social neuroscience has also focused on
explaining the functional meaning of such correlations
between inter-brain synchronization and behavioural cou-
pling. A biophysical model showed that the similarity of
both endogenous dynamics and anatomical structure might
facilitate inter-individual synchronization and explain our
propensity to socially bind with others via perception and
actions Dumas et al. [2012a]. More speciﬁcally, the con-
nectome, a wiring diagram that maps all neural connec-
tions in the brain, not only facilitates the integration of
information within brains, but also between brains. In
those simulations, tools from dynamical systems thus sug-
gest that beyond their individual cognition, humans are
also dynamically coupled in the social realm Dumas et al.
[2012a].
Social learning and language development Regarding
language development in humans, cognitive and structural
accounts of language development have often conceptual-
ized linguistic abilities as static and formal sets of knowl-
edge structures, ignoring the contextual nature of language.
However, good communication must be tailored to the
characteristics of the listener and of the context - language
can also be explained as a social construct Whitehurst
[1978]. For example, evidence shows that the language
outcome of children with cochlear implants is heavily in-
ﬂuenced by parental linguistic input during the ﬁrst years
after cochlear implantation Holzinger et al. [2020]. In
terms of speciﬁc social learning variables, imitation has
3
Social Neuro AI: Social Interaction as the "dark matter" of AI A PREPRINT
Figure 1: Social learning categories. Figure inspired by Whiten [2005].
also been shown to play a major role in boosting language
development, usually in the form of selective imitation
Whitehurst et al. [1974], Whitehurst and Vasta [1975].
Moreover, in children with autism spectrum disorder, so-
cial learning variables such as joint attention, immediate
imitation, and deferred imitation have been shown to be
the best predictors of language ability and rate of com-
munication development Toth et al. [2006]. These results
clearly suggest that social learning skills have an inﬂuence
on language acquisition in humans.
2 Steps towards Social Neuro AI
How could social learning be useful for AI? In the
previous sections, we have provided convincing evidence
that interpersonal intelligence enhances intrapersonal in-
telligence through the mechanisms and biases of social
learning. It is a crucial aspect of biological intelligence
that possesses a broad array of modulating biases meant
to strengthen its adaptive power. Recent efforts in com-
putational social neuroscience have paved the way for a
naturalization of social interactions.
Multi-agent reinforcement learning (MARL) is the best
subﬁeld of AI to investigate the interactions between multi-
ple agents. Such interactions can be of three types: cooper-
ative games (all agents working for the same goal), compet-
itive games (all agents competing against each other), and
mixed motive games (a mix of cooperative and competitive
interactions). At each timestep t, each agent is attempting
to maximize its own reward by learning a policy that op-
timizes the total expected discounted future reward. We
refer the reader to high-quality reviews that have been writ-
ten on MARL Wong et al. [2021], Nguyen et al. [2020],
Hernandez-Leal et al. [2019]. Here, we highlight that,
among others, low sample efﬁciency is one of the great-
est challenges for MARL, as millions of interactions with
the environment are usually needed for agents to learn.
Moreover, multi-agent joint action space increases expo-
nentially with the number of agents, leading to problems
that are often intractable. In the last few years, part of
the AI community has already started demonstrating that
these problems can be alleviated by mechanisms that allow
for social learning Jaques [2019], Ndousse [2021]. For
example, rewarding agents for having a causal inﬂuence
over other agents’ actions leads to enhanced coordination
and communication in challenging social dilemma envi-
ronments Jaques et al. [2019] and rewarding agents for
coordinating attention with another agent improves their
ability of coordination, by reducing the cost of exploration
Lee et al. [2021]. More in general, concepts from com-
plex systems such as self-organization, emergent behavior,
swarm optimization and cellular systems suggest that col-
lective intelligence could produce more robust and ﬂexible
solutions in AI, with higher sample efﬁciency and higher
generalization Ha and Tang [2021]. In the following sec-
tions, we argue that to exploit all beneﬁts that social learn-
ing can offer AI and robotics, more focus on biological
plausibility, social embodiment and temporal dynamics is
needed. Studies have focused on the potential of conduct-
ing research at the intersection of some of these three axes
Husbands et al. [2021], Kerzel et al. [2017]. Moreover, it
is worth noticing that Dumas et al. [2012b], Heggli et al.
[2019] offer a tentative glimpse of what the intersection
of the three axes would look like - both using dynamical
systems with computational simulations to address falsiﬁ-
able scientiﬁc questions associated with the idea of social
embodiment.
2.1 Biological plausibility
Biological plausibility refers to the extent to which an
artiﬁcial architecture takes inspiration from empirical re-
sults in neuroscience and psychology. The social learning
skills and biases that we have shown so far are boosted in
humans by their advanced cognitive architecture Whiten
4
Social Neuro AI: Social Interaction as the "dark matter" of AI A PREPRINT
[2021]. Equipping artiﬁcial agents with complex social
learning abilities will therefore require more complex ar-
chitectures that can handle a great variety of information
efﬁciently. This is exactly what "Neuro-AI" aims at: draw-
ing on how evolution has shaped the brain of humans and
of other animals in order to create more robust agents
(Figure 2). While the human unconscious brain aligns
well with the current successful applications of deep learn-
ing, the conscious brain involves higher-order cognitive
abilities that perform much more complex computations
than what deep learning can currently do Bengio [2019].
More speciﬁcally, “unconsciousness” is where most of
our intelligence lies and involves unconscious abilities
related to view-invariance, meaning extraction, control,
decision-making and learning; “i-consciousness” is the
part of human consciousness that is focused on integrating
all available evidence to converge toward a single decision;
“m-consciousness” is the part of human consciousness
that is focused on reﬂexively representing oneself, utiliz-
ing error detection, meta-memory and reality monitoring
Graziano [2017a]. Notably, recent efforts in the deep learn-
ing community have indeed focused on Neuro-AI: build-
ing advanced cognitive architectures that are inspired from
neuroscience. In particular, the global workspace theory
(GWT) is the most widely accepted theory of conscious-
ness, and it postulates that when a piece of information
is selected by attention, it may non-linearly achieve “ig-
nition”, enter the global workspace (GLW) and be shared
across specialized cortical modules, therefore becoming
conscious Baars [1993]; Dehaene et al. [1998]. The use
of such a communication channel in the context of deep
learning was explored for modelling the structure of com-
plex environments. This architecture was demonstrated
to encourage specialization and compositionality and to
facilitate the synchronization of otherwise independent
specialists Goyal et al. [2021]. Moreover, inductive biases
inspired by higher-order cognitive functions in humans
have been shown to improve OOD generalization. Over-
all, this section proposes that we draw inspiration from
one structure we know is capable of comprehensive in-
telligence capable of perception, planning, and decision
making: the human brain (Figure 2). For a more extensive
discussion on biological plausibility in AI, we refer the
reader to Hassabis et al. [2017], Macpherson et al. [2021].
2.2 Temporal dynamics
(Figure 2). More speciﬁcally, FFNs allow signals to travel
only from input to output, whereas RNNs can have sig-
nals traveling in both directions and therefore introduce
loops in the network. Incorporating differential equations
in a RNN (continuous-time recurrent neural network) can
help learn long-term dependencies Chang et al. [2019] and
model more complex phenomena, such as the effects of
incoming inputs on a neuron. Moreover, viewing RNNs as
a discretization of ordinary differential equations (ODEs)
driven by input data has led to gains in reliability and ro-
bustness to data perturbations Lim et al. [2021a]. This
becomes clear when one notices that many fundamental
laws of physics and chemistry can be formulated as dif-
ferential equations. In general, differential equations are
expected to contribute to shifting the perspective from
representation-centered to self-organizing agents Brooks
[1991]. The former view has been one predominant way of
thinking about autonomous systems that exhibit intelligent
behaviour: such autonomous agents use their sensors to
extract information about the world they operate in and
use it to construct an internal model of the world and there-
fore rationally perform optimal decision making in pursuit
of some goal. In other words, autonomous agents are in-
formation processing systems and their environment can
be abstracted away as the source of answers to questions
raised by the ongoing agents’ needs. Cognitive processes
are thought to incorporate representational content and to
acquire such contents via inferential processes instantiated
by the brain. Importantly, according to this view, the sen-
sorimotor connections of the agents to the environment are
still relevant to understand their behaviour, but there is no
focus on what such connections involve and how they take
place Newell and Simon [1976]. The latter view, in line
with the subsumption architecture introduced by Rodney
Brooks Brooks [1991], shows how the representational
approach ignores the nonlinear dynamical aspect of intel-
ligence, that is, the temporal constraints that characterize
the interactions between agent and environment. Instead,
dynamics is a powerful framework that has been used to
describe multiple natural phenomena as an interdependent
set of coevolving quantitative variables van Gelder [1998]
and a crucial aspect of intelligence is that it occurs in time
and not over time. If we abstract away the richness of
real time, then we also change the behaviour of the agents
Smithers [2018]. In other words, one should indeed focus
on the structural complexity and on the algorithmic com-
putation the agents need to carry out, but without abstract-
ing away the dynamical aspects of the agent-environment
interactions: such dynamical aspects are pervasive and,
therefore, necessary to explain the behaviour of the system
van Gelder [1998], Smithers [2018], Barandiaran [2017].
2.3 Social embodiment
There has been a resurgence of enactivism in cognitive
neuroscience over the past decade, emphasizing the circu-
lar causality induced by the notion that the environment is
acting upon the individual and the individual is acting upon
the environment. To understand how the brain works, then
one has to acknowledge that it is embodied Clark [2013],
Hohwy [2013]. Evidence for this shows that embodied in-
telligence in human children arises from the interaction of
the child with the environment through a sensory body that
is capable of recognizing the statistical properties of such
interaction Smith and Gasser [2005]. Moreover, higher pri-
mates interpret each other as psychological subjects based
on their bodily presence; social embodiment is the idea
that the embodiment of a socially interactive agent plays
a signiﬁcant role in social interactions. It refers to “states
of the body, such as postures, arm movements, and facial
expressions, that arise during social interaction and play
central roles in social information processing.” Thompson
and Varela [2001], Barsalou et al. [2003]. This includes
5
Social Neuro AI: Social Interaction as the "dark matter" of AI A PREPRINT
internal and external structures, sensors, and motors that al-
low them to interact actively with the world. We argue that
robots are more socially embodied than digital avatars for
a simple reason: they have a higher potential to use parts of
their bodies to communicate and to coordinate with other
agents (Figure 2). At a high level, sensorimotor capabilities
in the avatar and robots are meant to model their role in bi-
ological beings: the agent now has limitations in the ways
they can sense, manipulate, and navigate its environments.
Importantly, these limitations are closely tied to the agent’s
function Deng et al. [2019]. The idea of social embodiment
in artiﬁcial agents is supported by evidence of improve-
ments in the interactions between embodied agents and
humans Zhang et al. [2016]. Studies have shown positive
effects of physical embodiment on the feeling of an agent’s
social presence, the evaluation of the agent, the assessment
of public evaluation of the agent, and the evaluation of the
interaction with the agent Kose-Bagci et al. [2009], Gupta
et al. [2021]. In robots, social presence is a key component
in the success of social interactions and it can be deﬁned
as the combination of seven abilities that enhance a robot’s
social skills: 1. Express emotion 2. Communicate with
high-level dialogue 3. Learn/recognize models of other
agents 4. Establish/maintain social relationships 5. Use
natural cues 6. Exhibit distinctive personality and character
7. Learn/develop social competencies Lee [2006]. Social
embodiment thus equips artiﬁcial agents with a more artic-
ulated and richer repertoire of expressions, ameliorating
the interactions with it Jaques [2019]. For instance, in
human-robot interaction, a gripper is not limited to its role
in the manipulation of objects. Rather, it opens a broad
array of movements that can enhance the communicative
skills of the robot and, consequently, the quality of its
possible interactions Deng et al. [2019]. The embodied
agent is therefore the best model of the aspects of the world
relevant to its surviving and thriving, through performing
situationally appropriate actions Ramstead et al. [2020]
(Figure 2). Therefore, it will be crucial to scale up the
realism of what the agents perceive in their social context,
going from simple environments like GridWorld to more
complex ones powered by video-game engines and, ﬁnally,
to extremely realistic environments, like the one offered
by the MetaHuman Creator of Unreal Engine. In parallel,
greater focus is needed on the mental processes supporting
our interactions with social machines, so as to develop
a more nuanced understanding of what is ‘social’ about
social cognition Cross and Ramsey [2021] and to gather
insights critical for optimising social encounters between
humans and robots Henschel et al. [2020]. For a more
extensive discussion on embodied intelligence, we refer
the reader to Roy et al. [2021]. These advancements will
hopefully result in more socially intelligent agents and
therefore in more fruitful interactions between humans and
virtual agents.
3 Active inference
The active inference framework represents a biologically
realistic way of moving away from rule-governed manip-
ulation of internal representations to action-oriented and
situationally appropriate cognition Friston et al. [2006].
More speciﬁcally, active inference can be seen as a self-
organising process of action policy selection Ramstead
et al. [2020], which a) concerns the selective sampling of
the world by an embodied agent, and b) instantiates in
a generative model the goal of minimizing their surprise
through perception and action Ramstead et al. [2020]. In
other words, generative models do not encode exploitable
and symbolic structural information about the world, be-
cause cognition does not perform manipulation of internal
representations, but rather instantiates control systems that
are expressed in embodied activity and utilize information
encoded in the approximate posterior belief Ramstead et al.
[2020]. Interestingly, by grounding GWT within the em-
bodied perspective of the active inference framework, the
Integrated World Modeling Theory (IWMT) suggests that
conscious experience can only result from autonomous
embodied agents with global workspaces that generate in-
tegrative models of the world with spatial, temporal and
causal coherence Safron [2020].
Active inference models are still very discrete in their archi-
tectures, especially regarding high-level cognitive aspects,
but they may be a good class of models to raise the ten-
sion between computation and implementation (Figure
2). Therefore, they only have been able to handle small
policies and state–spaces, while also requiring the envi-
ronmental dynamics to be well known. However, using
deep neural networks to approximate key densities, the
agent can scale to more complex tasks and obtain per-
formance comparable to common reinforcement learning
baselines Millidge [2020]. Moreover, one advantage of
active inference is that the associated biologically inspired
architectures predict future trajectories of the agent N steps
forward in time, rather than just at the next step. By sam-
pling from these trajectories, the variance of the decision
is reduced Millidge [2020].
Interestingly, by grounding GWT within the embodied per-
spective of the active inference framework, the Integrated
World Modeling Theory (IWMT) suggests that complexes
of integrated information and global workspaces can entail
conscious experiences if (and only if) they are capable
of generating integrative world models with spatial, tem-
poral, and causal coherence. These ways of categorizing
experience are increasingly recognized as constituting es-
sential “core knowledge” at the foundation of cognitive
development (Spelke and Kinzler, 2007). In addition to
space, time, and cause, IWMT adds embodied autonomous
selfhood as a precondition for integrated world modeling.
4 A detailed proposal: how can increased
biological plausibility enhance social
affordance learning in artiﬁcial agents?
Attention has become a common ingredient in deep learn-
ing architectures. It can be understood as a dynamical
control of information ﬂow Mittal et al. [2020]. In the
last decade, transformers have demonstrated how attention
6
Social Neuro AI: Social Interaction as the "dark matter" of AI A PREPRINT
may be all we need, obtaining excellent performances in
sequence learning Vaswani et al. [2017], visual process-
ing Dosovitskiy et al. [2020] and time-series forecasting
Lim et al. [2021b]. While transformers proposed a general
purpose architecture where inductive biases shaping the
ﬂow of information are learned from the data itself, we
can imagine a higher-order informational ﬁlter built on top
of attention: an Attention Schema (AS), namely a descrip-
tive and predictive model of attention. In this regard, the
attention schema theory (AST) is a neuroscientiﬁc theory
that postulates that the human brain, and possibly the brain
of other animals, does construct a model of attention: an
attention schema Graziano and Webb [2015]. Speciﬁcally,
the proposal is that the brain constructs not only a model of
the physical body but also a coherent, rich, and descriptive
model of attention. The body schema contains layers of
valuable information that help control and predict stable
and dynamic properties of the body; in a similar fashion,
the attention schema helps control and predict attention.
One cannot understand how the brain controls the body
without understanding the body schema, and in a similar
way one cannot understand how the brain controls its lim-
ited resources without understanding the attention schema
Graziano [2017a]. The key reason a higher-order ﬁlter
on top of attention seems a promising idea for deep learn-
ing comes from control engineering: a good controller
contains a model of the item being controlled Conant and
Ross Ashby [1970]. More speciﬁcally, a descriptive and
predictive model of attention could help the dynamical
control of attention and therefore maximize the efﬁciency
with which resources are strategically devoted to differ-
ent elements of an ever-changing environment Graziano
[2017b]. Indeed, the performance of an artiﬁcial agent in
solving a simple sensorimotor task is greatly enhanced by
an attention schema, but its performance is greatly reduced
when the schema is not available Wilterson and Graziano
[2021]. Therefore, the study of consciousness in artiﬁcial
intelligence is not a mere pursuit of metaphysical mystery;
from an engineering perspective, without understanding
subjective awareness, it might not be possible to build ar-
tiﬁcial agents that intelligently control and deploy their
limited processing resources. It has also been argued that,
without an attention schema, it might be impossible to
build artiﬁcial agents that are socially intelligent. This idea
stems from the evidence that points at an overlap of social
cognition functions with awareness and attention functions
in the right temporo-parietal junction of the human brain
Mitchell [2008]. It was then proposed that an attention
schema might also be used for social cognition, giving rise
to an overlap between modelling one’s own attention and
modelling others’ attention. In other words, when we at-
tribute to other people an awareness of their surroundings,
we are constructing a simpliﬁed model of their attention - a
schema of others’ attention Graziano and Kastner [2011a].
Indeed, such a model would enhance the ability of the
agent to predict social affordances in real time, which is a
goal the ﬁeld has been trying to achieve in different ways
Ardón et al. [2021], Shu et al. [2016]. Without a model of
others’ attention, even if we had detailed information about
them, we could not predict their behaviour on a moment-
by-moment basis. However, with a component that tracks
how and where other agents are focusing their resources in
the environment, the probabilities for many affordances in
the environment become computable in real time Graziano
[2019]. Speciﬁcally, there are three predictions that are
investigated in this proposal. The ﬁrst prediction is that,
without an attention schema, attention is still possible, but
it suffers deﬁcits in control and thus leads to worse perfor-
mance. The second prediction is that an attention schema
is useful for modeling the attention of other agents as well
—as the machinery that computes information about other
people’s attention is the same machinery that computes
information about our own attention Graziano and Kastner
[2011b]. The third prediction is that an agent equipped
with an attention schema is going to have better OOD
generalization than a classic Proximal Policy Optimization
agent Schulman et al. [2017], especially in environments in
which the ability to intelligently control and deploy limited
processing resources is necessary.
5 Conclusion
At the crossroads of robotics, computer science, psychol-
ogy, and neuroscience, one of the main challenges for
humans is to build autonomous agents capable of partici-
pating in cooperative social interactions. This is important
not only because AI will play a crucial role in daily life
well into the future, but also because, as demonstrated by
results in social neuroscience and evolutionary psychol-
ogy, intrapersonal intelligence is tightly connected with
interpersonal intelligence, especially in humans Dumas
et al. [2014b]. In this opinion article, we have proposed
an approach that uniﬁes three lines of research that, at
the moment, are separated from each other; in particu-
lar, we have proposed three research directions that are
expected to enhance efﬁcient exchange of information be-
tween agents. Biological plausibility attempts to increase
the robustness and OOD generalization of algorithms by
drawing on knowledge about biological brains; temporal
dynamics attempts to better capture long-term temporal de-
pendencies; social embodiment proposes that states of the
body that arise during social interaction play central roles
in social information processing. Unifying these axes of
research would contribute to creating agents that are able
to cooperate efﬁciently in extremely complex and realistic
environments Dennis et al. [2021], while interacting with
other embodied agents and with humans.
7
Social Neuro AI: Social Interaction as the "dark matter" of AI A PREPRINT
Figure 2: Billions of humans interact daily with algorithms — yet AI is far from human social cognition. We argue
that creating such socially aware agents may require "Social Neuro-AI" — a program developing 3 research axes: 1.
Biological plausibility 2. Temporal dynamics 3. Social embodiment. Overall, those steps towards socially aware agents
will ultimately help in aligned interactions between natural and artiﬁcial intelligence. Figure inspired by Schilbach et al.
[2013].
8
Social Neuro AI: Social Interaction as the "dark matter" of AI A PREPRINT
References
Sha Yuan, Hanyu Zhao, Shuai Zhao, Jiahong Leng, Yangx-
iao Liang, Xiaozhi Wang, Jifan Yu, Xin Lv, Zhou Shao,
Jiaao He, Yankai Lin, Xu Han, Zhenghao Liu, Ning
Ding, Yongming Rao, Yizhao Gao, Liang Zhang, Ming
Ding, Cong Fang, Yisen Wang, Mingsheng Long, Jing
Zhang, Yinpeng Dong, Tianyu Pang, Peng Cui, Lingx-
iao Huang, Zheng Liang, Huawei Shen, Hui Zhang,
Quanshi Zhang, Qingxiu Dong, Zhixing Tan, Mingx-
uan Wang, Shuo Wang, Long Zhou, Haoran Li, Junwei
Bao, Yingwei Pan, Weinan Zhang, Zhou Yu, Rui Yan,
Chence Shi, Minghao Xu, Zuobai Zhang, Guoqiang
Wang, Xiang Pan, Mengjie Li, Xiaoyu Chu, Zijun Yao,
Fangwei Zhu, Shulin Cao, Weicheng Xue, Zixuan Ma,
Zhengyan Zhang, Shengding Hu, Yujia Qin, Chaojun
Xiao, Zheni Zeng, Ganqu Cui, Weize Chen, Weilin Zhao,
Yuan Yao, Peng Li, Wenzhao Zheng, Wenliang Zhao,
Ziyi Wang, Borui Zhang, Nanyi Fei, Anwen Hu, Zenan
Ling, Haoyang Li, Boxi Cao, Xianpei Han, Weidong
Zhan, Baobao Chang, Hao Sun, Jiawen Deng, Juanzi
Li, Lei Hou, Xigang Cao, Jidong Zhai, Zhiyuan Liu,
Maosong Sun, Jiwen Lu, Zhiwu Lu, Qin Jin, Ruihua
Song, Ji-Rong Wen, Zhouchen Lin, Liwei Wang, Hang
Su, Jun Zhu, Zhifang Sui, Jiajun Zhang, Yang Liu, Xi-
aodong He, Minlie Huang, Jian Tang, and Jie Tang. A
roadmap for big model. arXiv:2203.14101 [cs], Mar
2022. URL http://arxiv.org/abs/2203.14101.
arXiv: 2203.14101.
Rishi Bommasani, Drew A. Hudson, Ehsan Adeli, Russ
Altman, Simran Arora, Sydney von Arx, Michael S.
Bernstein, Jeannette Bohg, Antoine Bosselut, Emma
Brunskill, Erik Brynjolfsson, Shyamal Buch, Dallas
Card, Rodrigo Castellon, Niladri Chatterji, Annie Chen,
Kathleen Creel, Jared Quincy Davis, Dora Demszky,
Chris Donahue, Moussa Doumbouya, Esin Durmus,
Stefano Ermon, John Etchemendy, Kawin Ethayarajh,
Li Fei-Fei, Chelsea Finn, Trevor Gale, Lauren Gillespie,
Karan Goel, Noah Goodman, Shelby Grossman, Neel
Guha, Tatsunori Hashimoto, Peter Henderson, John He-
witt, Daniel E. Ho, Jenny Hong, Kyle Hsu, Jing Huang,
Thomas Icard, Saahil Jain, Dan Jurafsky, Pratyusha
Kalluri, Siddharth Karamcheti, Geoff Keeling, Fereshte
Khani, Omar Khattab, Pang Wei Koh, Mark Krass, Ran-
jay Krishna, Rohith Kuditipudi, Ananya Kumar, Faisal
Ladhak, Mina Lee, Tony Lee, Jure Leskovec, Isabelle
Levent, Xiang Lisa Li, Xuechen Li, Tengyu Ma, Ali
Malik, Christopher D. Manning, Suvir Mirchandani,
Eric Mitchell, Zanele Munyikwa, Suraj Nair, Avanika
Narayan, Deepak Narayanan, Ben Newman, Allen Nie,
Juan Carlos Niebles, Hamed Nilforoshan, Julian Nyarko,
Giray Ogut, Laurel Orr, Isabel Papadimitriou, Joon Sung
Park, Chris Piech, Eva Portelance, Christopher Potts,
Aditi Raghunathan, Rob Reich, Hongyu Ren, Frieda
Rong, Yusuf Roohani, Camilo Ruiz, Jack Ryan, Christo-
pher Ré, Dorsa Sadigh, Shiori Sagawa, Keshav San-
thanam, Andy Shih, Krishnan Srinivasan, Alex Tamkin,
Rohan Taori, Armin W. Thomas, Florian Tramèr, Rose E.
Wang, William Wang, Bohan Wu, Jiajun Wu, Yuhuai
Wu, Sang Michael Xie, Michihiro Yasunaga, Jiaxuan
You, Matei Zaharia, Michael Zhang, Tianyi Zhang,
Xikun Zhang, Yuhui Zhang, Lucia Zheng, Kaitlyn Zhou,
and Percy Liang. On the opportunities and risks of
foundation models. arXiv:2108.07258 [cs], Aug 2021.
URL http://arxiv.org/abs/2108.07258. arXiv:
2108.07258.
Sarthak Mittal, Alex Lamb, Anirudh Goyal, Vikram V oleti,
Murray Shanahan, Guillaume Lajoie, Michael Mozer,
and Yoshua Bengio. Learning to combine top-down
and bottom-up signals in recurrent neural networks with
attention over modules. In International Conference on
Machine Learning, pages 6972–6986. PMLR, 2020.
Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob
Uszkoreit, Llion Jones, Aidan N Gomez, Łukasz Kaiser,
and Illia Polosukhin. Attention is all you need. In Ad-
vances in neural information processing systems, pages
5998–6008, 2017.
David Silver, Satinder Singh, Doina Precup, and Richard S.
Sutton. Reward is enough. Artiﬁcial Intelligence, 299:
103535, Oct 2021. doi:10.1016/j.artint.2021.103535.
URL https://www.sciencedirect.com/
science/article/pii/S0004370221000862.
Cecilia Heyes. Cognitive Gadgets. Harvard University
Press, April 2018. ISBN 9780674985155. URL
https://www.degruyter.com/document/doi/10.
4159/9780674985155/html.
Rachel L. Kendal, Neeltje J. Boogert, Luke Rendell,
Kevin N. Laland, Mike Webster, and Patricia L.
Jones. Social learning strategies: Bridge-building
between ﬁelds. Trends in Cognitive Sciences , 22(7):
651–665, 2018. doi:10.1016/j.tics.2018.04.003. URL
https://linkinghub.elsevier.com/retrieve/
pii/S1364661318300949.
Ian Clark and Guillaume Dumas. The regulation of task
performance: a trans-disciplinary review. Frontiers in
psychology, 6:1862, 2016.
Andrew Whiten. The burgeoning reach of ani-
mal culture. Science, 372(6537):eabe6514,
April 2021. doi:10.1126/science.abe6514. URL
https://www.sciencemag.org/lookup/doi/10.
1126/science.abe6514.
Jean-François Gariépy, Karli Watson, Emily Du,
Diana Xie, Joshua Erb, Dianna Amasino, and
Michael Platt. Social learning in humans and
other animals. Frontiers in Neuroscience , 8,
2014. URL https://www.frontiersin.org/
article/10.3389/fnins.2014.0005.
Cecilia Heyes. What’s social about social learn-
ing? Journal of Comparative Psychology (Wash-
ington, D.C.: 1983) , 126(2):193–202, May 2012.
doi:10.1037/a0025180.
Mark Nielsen, Francys Subiaul, Bennett Galef, Thomas
Zentall, and Andrew Whiten. Social learning in hu-
mans and nonhuman animals: Theoretical and em-
pirical dissections. Journal of Comparative Psychol-
ogy, 126(2):109–113, 2012. doi:10.1037/a0027758.
9
Social Neuro AI: Social Interaction as the "dark matter" of AI A PREPRINT
URL http://doi.apa.org/getdoi.cfm?doi=10.
1037/a0027758.
Michael Tomasello. The adaptive origins of uniquely
human sociality. Philosophical Transactions of the
Royal Society B: Biological Sciences , 375(1803):
20190493, Jul 2020. doi:10.1098/rstb.2019.0493. URL
https://royalsocietypublishing.org/doi/
full/10.1098/rstb.2019.0493.
Will Hoppitt and Kevin N. Laland. Chapter 3 So-
cial Processes Inﬂuencing Learning in Animals:
A Review of the Evidence , volume 38, page
105–165. Elsevier, 2008. ISBN 9780120045389.
doi:10.1016/S0065-3454(08)00003-X. URL
https://linkinghub.elsevier.com/retrieve/
pii/S006534540800003X.
Thibaud Gruber, Marina Bazhydai, Christine Sievers, Fab-
rice Clément, and Daniel Dukes. The abc of social
learning: Affect, behavior, and cognition. Psychological
Review, Jul 2021. doi:10.1037/rev0000311.
Grgur Kova ˇc, Rémy Portelas, Katja Hofmann, and
Pierre-Yves Oudeyer. Socialai: Benchmarking socio-
cognitive abilities in deep reinforcement learning agents.
arXiv:2107.00956 [cs] , Sep 2021. URL http://
arxiv.org/abs/2107.00956. arXiv: 2107.00956.
Guillaume Dumas, Gonzalo C de Guzman, Emmanuelle
Tognoli, and JA Scott Kelso. The human dynamic clamp
as a paradigm for social interaction. Proceedings of the
National Academy of Sciences, 111(35):E3726–E3734,
2014a.
Leonhard Schilbach, Bert Timmermans, Vasudevi Reddy,
Alan Costall, Gary Bente, Tobias Schlicht, and Kai
V ogeley. Toward a second-person neuroscience.
Behavioral and Brain Sciences, 36(4):393–414, 2013.
doi:10.1017/S0140525X12000660. URL https://
www.cambridge.org/core/product/identifier/
S0140525X12000660/type/journal_article.
C. M. Heyes. Social learning in animals: categories
and mechanisms. Biological Reviews of the Cam-
bridge Philosophical Society, 69(2):207–231, May 1994.
doi:10.1111/j.1469-185x.1994.tb01506.x.
W. H Thorpe. Learning and instinct in animals. Methuen,
1963.
Bradley D Worden and Daniel R Papaj. Flower choice
copying in bumblebees. Biology Letters, 1(4):504–507,
December 2005. doi:10.1098/rsbl.2005.0368. URL
https://royalsocietypublishing.org/doi/10.
1098/rsbl.2005.0368.
Peter D. Weigl and Elinor V . Hanson. Observa-
tional learning and the feeding behavior of the
red squirrel tamiasciurus hudsonicus: The on-
togeny of optimization. Ecology, 61(2):213–218,
1980. doi:https://doi.org/10.2307/1935176. URL
https://esajournals.onlinelibrary.wiley.
com/doi/abs/10.2307/1935176.
Emily D. Klein and Thomas R. Zentall. Imita-
tion and affordance learning by pigeons (columba
livia). Journal of Comparative Psychology , 117(4):
414–419, 2003. doi:10.1037/0735-7036.117.4.414.
URL http://doi.apa.org/getdoi.cfm?doi=10.
1037/0735-7036.117.4.414.
Richard W. Byrne. Imitation of novel complex ac-
tions: What does the evidence from animals mean? ,
volume 31, page 77–105. Academic Press, Jan
2002. doi:10.1016/S0065-3454(02)80006-7. URL
https://www.sciencedirect.com/science/
article/pii/S0065345402800067.
Andrew Whiten. The second inheritance system of chim-
panzees and humans. Nature, 437(7055):52–55, 2005.
doi:10.1038/nature04023. URL http://www.nature.
com/articles/nature04023.
Josep Call, Malinda Carpenter, and Michael Tomasello.
Copying results and copying actions in the process of
social learning: chimpanzees (pan troglodytes) and hu-
man children (homo sapiens). Animal Cognition, 8(3):
151–163, Jul 2005. doi:10.1007/s10071-004-0237-8.
Cynthia Breazeal and Brian Scassellati. Robots that imitate
humans. Trends in Cognitive Sciences, 6(11):481–487,
Nov 2002. doi:10.1016/S1364-6613(02)02016-8. URL
https://www.sciencedirect.com/science/
article/pii/S1364661302020168.
Lara A. Wood, Rachel L. Kendal, and Emma G. Flynn.
Copy me or copy you? the effect of prior experience
on social learning. Cognition, 127(2):203–213,
2013. doi:10.1016/j.cognition.2013.01.002. URL
https://linkinghub.elsevier.com/retrieve/
pii/S0010027713000103.
Rachel Kendal, Lydia M. Hopper, Andrew Whiten,
Sarah F. Brosnan, Susan P. Lambeth, Steven J. Schapiro,
and Will Hoppitt. Chimpanzees copy dominant and
knowledgeable individuals: implications for cultural
diversity. Evolution and Human Behavior, 36(1):65–72,
2015. doi:10.1016/j.evolhumbehav.2014.09.002. URL
https://linkinghub.elsevier.com/retrieve/
pii/S109051381400110X.
Emma Flynn and Andrew Whiten. Experimen-
tal “microcultures” in young children: Identify-
ing biographic, cognitive, and social predictors
of information transmission: Identifying predic-
tors of information transmission. Child Develop-
ment, 83(3):911–925, 2012. doi:10.1111/j.1467-
8624.2012.01747.x. URL http://doi.wiley.com/
10.1111/j.1467-8624.2012.01747.x.
Emmanuelle Tognoli, Guillaume Dumas, and J. A. Scott
Kelso. A roadmap to computational social neuroscience.
Cognitive Neurodynamics , 12(1):135–140, 2018.
doi:10.1007/s11571-017-9462-0. URL http://link.
springer.com/10.1007/s11571-017-9462-0 .
Guillaume Dumas, Mario Chavez, Jacqueline Nadel,
and Jacques Martinerie. Anatomical connectiv-
ity inﬂuences both intra- and inter-brain synchro-
nizations. PLoS ONE , 7(5):e36414, May 2012a.
doi:10.1371/journal.pone.0036414. URL https://dx.
plos.org/10.1371/journal.pone.0036414.
10
Social Neuro AI: Social Interaction as the "dark matter" of AI A PREPRINT
Guillaume Dumas, Jacqueline Nadel, Robert Soussig-
nan, Jacques Martinerie, and Line Garnero.
Inter-brain synchronization during social inter-
action. PLoS ONE , 5(8):e12166, August 2010.
doi:10.1371/journal.pone.0012166. URL https://dx.
plos.org/10.1371/journal.pone.0012166.
Alejandro Pérez, Guillaume Dumas, Melek Karadag,
and Jon Andoni Duñabeitia. Differential brain-to-
brain entrainment while speaking and listening in
native and foreign languages. Cortex, 111:303–315,
2019. doi:10.1016/j.cortex.2018.11.026. URL
https://linkinghub.elsevier.com/retrieve/
pii/S0010945218304052.
Amir Djalovski, Guillaume Dumas, Sivan Kinreich,
and Ruth Feldman. Human attachments shape
interbrain synchrony toward efﬁcient performance
of social goals. NeuroImage, 226:117600, 2021.
doi:10.1016/j.neuroimage.2020.117600. URL
https://linkinghub.elsevier.com/retrieve/
pii/S1053811920310855.
Grover J. Whitehurst. The contributions of so-
cial learning to language acquisition. Contem-
porary Educational Psychology , 3(1):2–10, Jan
1978. doi:10.1016/0361-476X(78)90002-4. URL
https://www.sciencedirect.com/science/
article/pii/0361476X78900024.
Daniel Holzinger, Magdalena Dall, Susana Sanduvete-
Chaves, David Saldaña, Salvador Chacón-Moscoso,
and Johannes Fellinger. The impact of family en-
vironment on language development of children
with cochlear implants: A systematic review and
meta-analysis. Ear Hearing , 41(5):1077–1091,
2020. doi:10.1097/AUD.0000000000000852. URL
https://journals.lww.com/10.1097/AUD.
0000000000000852.
Grover J Whitehurst, Marsha Ironsmith, and Michael
Goldfein. Selective imitation of the passive con-
struction through modeling. Journal of Exper-
imental Child Psychology , 17(2):288–302, Apr
1974. doi:10.1016/0022-0965(74)90073-3. URL
https://www.sciencedirect.com/science/
article/pii/0022096574900733.
Grover J. Whitehurst and Ross Vasta. Is language acquired
through imitation? Journal of Psycholinguistic Re-
search, 4(1):37–59, Jan 1975. doi:10.1007/BF01066989.
URL https://doi.org/10.1007/BF01066989.
Karen Toth, Jeffrey Munson, Andrew N. Meltzoff, and
Geraldine Dawson. Early predictors of communi-
cation development in young children with autism
spectrum disorder: Joint attention, imitation, and toy
play. Journal of Autism and Developmental Disor-
ders, 36(8):993–1005, Nov 2006. doi:10.1007/s10803-
006-0137-7. URL https://doi.org/10.1007/
s10803-006-0137-7 .
Annie Wong, Thomas Bäck, Anna V . Kononova, and Aske
Plaat. Multiagent deep reinforcement learning: Chal-
lenges and directions towards human-like approaches.
arXiv:2106.15691 [cs], Jun 2021. URLhttp://arxiv.
org/abs/2106.15691. arXiv: 2106.15691.
Thanh Thi Nguyen, Ngoc Duy Nguyen, and Saeid Naha-
vandi. Deep reinforcement learning for multi-agent
systems: A review of challenges, solutions and ap-
plications. IEEE Transactions on Cybernetics, 50(9):
3826–3839, 2020. doi:10.1109/TCYB.2020.2977374.
URL http://arxiv.org/abs/1812.11794. arXiv:
1812.11794.
Pablo Hernandez-Leal, Bilal Kartal, and Matthew E. Tay-
lor. A survey and critique of multiagent deep reinforce-
ment learning. Autonomous Agents and Multi-Agent
Systems, 33(6):750–797, 2019. doi:10.1007/s10458-
019-09421-1. URL http://arxiv.org/abs/1810.
05587. arXiv: 1810.05587.
Natasha Jaques. Social and affective ma-
chine learning, 2019. URL https:
//www.media.mit.edu/publications/
social-and-affective-machine-learning/ .
Kamal Ndousse. Emergent social learning via
multi-agent reinforcement learning, 2021. URL
https://scholar.google.com/citations?
view_op=view_citation&hl=it&user=
8iCb2TwAAAAJ&sortby=pubdate&citation_
for_view=8iCb2TwAAAAJ:j3f4tGmQtD8C.
Natasha Jaques, Angeliki Lazaridou, Edward Hughes,
Caglar Gulcehre, Pedro A. Ortega, D. J. Strouse, Joel Z.
Leibo, and Nando de Freitas. Social inﬂuence as intrin-
sic motivation for multi-agent deep reinforcement learn-
ing. arXiv:1810.08647 [cs, stat], Jun 2019. URL http:
//arxiv.org/abs/1810.08647. arXiv: 1810.08647.
Dennis Lee, Natasha Jaques, Chase Kew, Jiaxing Wu,
Douglas Eck, Dale Schuurmans, and Aleksandra Faust.
Joint attention for multi-agent coordination and so-
cial learning. arXiv:2104.07750 [cs] , August 2021.
URL http://arxiv.org/abs/2104.07750. arXiv:
2104.07750.
David Ha and Yujin Tang. Collective intelligence for
deep learning: A survey of recent developments.
arXiv:2111.14377 [cs] , Nov 2021. URL http://
arxiv.org/abs/2111.14377. arXiv: 2111.14377.
Phil Husbands, Yoonsik Shim, Michael Garvie, Alex
Dewar, Norbert Domcsek, Paul Graham, James
Knight, Thomas Nowotny, and Andrew Philippides.
Recent advances in evolutionary and bio-inspired
adaptive robotics: Exploiting embodied dynamics.
Applied Intelligence , 51(9):6467–6496, Sep 2021.
doi:10.1007/s10489-021-02275-9. URL https://doi.
org/10.1007/s10489-021-02275-9 .
Matthias Kerzel, Erik Strahl, Sven Magg, Nicolás Navarro-
Guerrero, Stefan Heinrich, and Stefan Wermter. Nico —
neuro-inspired companion: A developmental humanoid
robot platform for multimodal interaction. In 2017 26th
IEEE International Symposium on Robot and Human
Interactive Communication (RO-MAN), page 113–120,
Aug 2017. doi:10.1109/ROMAN.2017.8172289.
11
Social Neuro AI: Social Interaction as the "dark matter" of AI A PREPRINT
Guillaume Dumas, Mario Chavez, Jacqueline Nadel, and
Jacques Martinerie. Anatomical connectivity inﬂuences
both intra- and inter-brain synchronizations.PLOS ONE,
7(5):e36414, 2012b. doi:10.1371/journal.pone.0036414.
URL https://journals.plos.org/plosone/
article?id=10.1371/journal.pone.0036414.
Ole Adrian Heggli, Joana Cabral, Ivana Konva-
linka, Peter Vuust, and Morten L. Kringelbach.
A kuramoto model of self-other integration
across interpersonal synchronization strategies.
PLOS Computational Biology , 15(10):e1007422,
2019. doi:10.1371/journal.pcbi.1007422. URL
https://journals.plos.org/ploscompbiol/
article?id=10.1371/journal.pcbi.1007422.
Yoshua Bengio. The consciousness prior.
arXiv:1709.08568 [cs, stat] , December 2019.
URL http://arxiv.org/abs/1709.08568. arXiv:
1709.08568.
Michael S. A. Graziano. The attention schema
theory: A foundation for engineering artiﬁcial
consciousness. Frontiers in Robotics and AI , 4:60,
November 2017a. doi:10.3389/frobt.2017.00060. URL
http://journal.frontiersin.org/article/10.
3389/frobt.2017.00060/full.
Bernard J. Baars. A Cognitive Theory of Conscious-
ness. Cambridge University Press, July 1993. ISBN
9780521427432. Google-Books-ID: 7w6IYeJRqyoC.
Stanislas Dehaene, Michel Kerszberg, and Jean-Pierre
Changeux. A neuronal model of a global workspace in
effortful cognitive tasks. Proceedings of the National
Academy of Sciences, 95(24):14529–14534, November
1998. doi:10.1073/pnas.95.24.14529. URL https:
//www.pnas.org/content/95/24/14529.
Anirudh Goyal, Aniket Didolkar, Alex Lamb, Kartikeya
Badola, Nan Rosemary Ke, Nasim Rahaman, Jonathan
Binas, Charles Blundell, Michael Mozer, and Yoshua
Bengio. Coordination among neural modules through a
shared global workspace. arXiv:2103.01197 [cs, stat],
March 2021. URL http://arxiv.org/abs/2103.
01197. arXiv: 2103.01197.
Demis Hassabis, Dharshan Kumaran, Christopher
Summerﬁeld, and Matthew Botvinick. Neuroscience-
inspired artiﬁcial intelligence. Neuron, 95(2):245–258,
Jul 2017. doi:10.1016/j.neuron.2017.06.011. URL
https://www.sciencedirect.com/science/
article/pii/S0896627317305093.
Tom Macpherson, Anne Churchland, Terry Sejnowski,
James DiCarlo, Yukiyasu Kamitani, Hidehiko
Takahashi, and Takatoshi Hikida. Natural and
artiﬁcial intelligence: A brief introduction to
the interplay between ai and neuroscience re-
search. Neural Networks , 144:603–613, Dec
2021. doi:10.1016/j.neunet.2021.09.018. URL
https://www.sciencedirect.com/science/
article/pii/S0893608021003683.
Bo Chang, Minmin Chen, Eldad Haber, and Ed H. Chi. An-
tisymmetricrnn: A dynamical system view on recurrent
neural networks. arXiv:1902.09689 [cs, stat], Feb 2019.
URL http://arxiv.org/abs/1902.09689. arXiv:
1902.09689.
Soon Hoe Lim, N. Benjamin Erichson, Liam Hodgkinson,
and Michael W. Mahoney. Noisy recurrent neural net-
works. arXiv:2102.04877 [cs, math, stat], Dec 2021a.
URL http://arxiv.org/abs/2102.04877. arXiv:
2102.04877.
Rodney A. Brooks. Intelligence without represen-
tation. Artiﬁcial Intelligence , 47(1):139–159, Jan
1991. doi:10.1016/0004-3702(91)90053-M. URL
https://www.sciencedirect.com/science/
article/pii/000437029190053M.
Allen Newell and Herbert A. Simon. Computer science as
empirical inquiry: symbols and search. Communications
of the ACM, 19(3):113–126, March 1976. doi:10/dnhcsn.
URL https://doi.org/10.1145/360018.360022.
Tim van Gelder. The dynamical hypothesis in cognitive
science. Behavioral and Brain Sciences , 21(5):
615–628, 1998. doi:10/dk8nfn. URL https://
www.cambridge.org/core/product/identifier/
S0140525X98001733/type/journal_article.
Tim Smithers. Are Autonomous Agents Information
Processing Systems? , page 123–162. Routledge,
1 edition, May 2018. ISBN 9781351001885.
doi:10.4324/9781351001885-4. URL https://
www.taylorfrancis.com/books/9781351001878/
chapters/10.4324/9781351001885-4.
Xabier E. Barandiaran. Autonomy and enactivism:
Towards a theory of sensorimotor autonomous
agency. Topoi, 36(3):409–430, 2017. doi:10/ghh82k.
URL http://link.springer.com/10.1007/
s11245-016-9365-4 .
Andy Clark. Whatever next? predictive brains,
situated agents, and the future of cognitive
science. Behavioral and Brain Sciences , 36
(3):181–204, June 2013. doi:10/f4xkv5. URL
https://www.cambridge.org/core/journals/
behavioral-and-brain-sciences/article/
whatever-next-predictive-brains-situated-agents-and-the-future-of-cognitive-science/
33542C736E17E3D1D44E8D03BE5F4CD9.
Jakob Hohwy. The Predictive Mind. Oxford University
Press, November 2013. ISBN 9780199682737. Google-
Books-ID: z7gVDAAAQBAJ.
Linda Smith and Michael Gasser. The development of em-
bodied cognition: six lessons from babies. Artiﬁcial Life,
11(1–2):13–29, 2005. doi:10.1162/1064546053278973.
Evan Thompson and Francisco J. Varela. Radical em-
bodiment: neural dynamics and consciousness. Trends
in Cognitive Sciences , 5(10):418–425, October 2001.
doi:10/c75qx5.
Lawrence W. Barsalou, Paula M. Niedenthal, Aron K.
Barbey, and Jennifer A. Ruppert. Social em-
bodiment. Psychology of Learning and Motiva-
tion - Advances in Research and Theory , page
12
Social Neuro AI: Social Interaction as the "dark matter" of AI A PREPRINT
43–92, 2003. doi:10.1016/S0079-7421(03)01011-
9. URL https://experts.illinois.edu/en/
publications/social-embodiment.
Eric Deng, Bilge Mutlu, and Maja Mataric. Em-
bodiment in socially interactive robots. Founda-
tions and Trends in Robotics , 7(4):251–356, 2019.
doi:10.1561/2300000056. URL http://arxiv.org/
abs/1912.00312. arXiv: 1912.00312.
Mengsen Zhang, Guillaume Dumas, JA Scott Kelso, and
Emmanuelle Tognoli. Enhanced emotional responses
during social coordination with a virtual partner. In-
ternational Journal of Psychophysiology , 104:33–43,
2016.
Hatice Kose-Bagci, Ester Ferrari, Kerstin Dautenhahn,
Dag Sverre Syrdal, and Chrystopher L. Nehaniv.
Effects of embodiment and gestures on social inter-
action in drumming games with a humanoid robot.
Advanced Robotics , 23(14):1951–1996, January
2009. doi:10.1163/016918609X12518783330360.
URL https://doi.org/10.1163/
016918609X12518783330360.
Agrim Gupta, Silvio Savarese, Surya Ganguli, and Li Fei-
Fei. Embodied intelligence via learning and evolution.
Nature Communications , 12(1):5721, October 2021.
doi:10.1038/s41467-021-25874-z. URL https://www.
nature.com/articles/s41467-021-25874-z .
Kwan Lee. Are physically embodied social agents
better than disembodied social agents?: The effects of
physical embodiment, tactile interaction, and people’s
loneliness in human–robot interaction. International
Journal of Human-Computer Studies, 64(10):962–973,
October 2006. doi:10.1016/j.ijhcs.2006.05.002. URL
https://www.sciencedirect.com/science/
article/abs/pii/S1071581906000784.
Maxwell JD Ramstead, Michael D Kirchhoff, and Karl J
Friston. A tale of two densities: active inference is
enactive inference. Adaptive Behavior, 28(4):225–239,
August 2020. doi:10/gf97c4. URL https://doi.org/
10.1177/1059712319862774.
Emily S. Cross and Richard Ramsey. Mind meets machine:
Towards a cognitive science of human–machine inter-
actions. Trends in Cognitive Sciences, 25(3):200–212,
Mar 2021. doi:10.1016/j.tics.2020.11.009. URL https:
//www.cell.com/trends/cognitive-sciences/
abstract/S1364-6613(20)30297-7.
Anna Henschel, Ruud Hortensius, and Emily S. Cross.
Social cognition in the age of human-robot interac-
tion. Trends in Neurosciences, 43(6):373–384, Jun 2020.
doi:10.1016/j.tins.2020.03.013.
Nicholas Roy, Ingmar Posner, Tim Barfoot, Philippe Beau-
doin, Yoshua Bengio, Jeannette Bohg, Oliver Brock,
Isabelle Depatie, Dieter Fox, Dan Koditschek, Tomas
Lozano-Perez, Vikash Mansinghka, Christopher Pal,
Blake Richards, Dorsa Sadigh, Stefan Schaal, Gau-
rav Sukhatme, Denis Therien, Marc Toussaint, and
Michiel Van de Panne. From machine learning to
robotics: Challenges and opportunities for embod-
ied intelligence. arXiv:2110.15245 [cs] , Oct 2021.
URL http://arxiv.org/abs/2110.15245. arXiv:
2110.15245.
Karl Friston, James Kilner, and Lee Harrison. A free
energy principle for the brain. Journal of Physiology-
Paris, 100(1):70–87, July 2006. doi:10/dxgwt3. URL
https://www.sciencedirect.com/science/
article/pii/S092842570600060X.
Adam Safron. An integrated world modeling theory
(iwmt) of consciousness: Combining integrated infor-
mation and global neuronal workspace theories with
the free energy principle and active inference frame-
work; toward solving the hard problem and character-
izing agentic causation. Frontiers in Artiﬁcial Intel-
ligence, 3, 2020. URL https://www.frontiersin.
org/article/10.3389/frai.2020.00030.
Beren Millidge. Deep active inference as variational
policy gradients. Journal of Mathematical Psychology,
96:102348, Jun 2020. doi:10.1016/j.jmp.2020.102348.
URL https://www.sciencedirect.com/
science/article/pii/S0022249620300298.
Alexey Dosovitskiy, Lucas Beyer, Alexander Kolesnikov,
Dirk Weissenborn, Xiaohua Zhai, Thomas Unterthiner,
Mostafa Dehghani, Matthias Minderer, Georg Heigold,
Sylvain Gelly, et al. An image is worth 16x16 words:
Transformers for image recognition at scale. arXiv
preprint arXiv:2010.11929, 2020.
Bryan Lim, Sercan Ö Arık, Nicolas Loeff, and Tomas Pﬁs-
ter. Temporal fusion transformers for interpretable multi-
horizon time series forecasting. International Journal
of Forecasting, 2021b.
Michael S. A. Graziano and Taylor W. Webb. The
attention schema theory: a mechanistic account of
subjective awareness. Frontiers in Psychology , 6:
500, 2015. doi:10.3389/fpsyg.2015.00500. URL
https://www.frontiersin.org/article/10.
3389/fpsyg.2015.00500.
Roger C. Conant and W. Ross Ashby. Every good
regulator of a system must be a model of that sys-
tem †. International Journal of Systems Science , 1
(2):89–97, 1970. doi:10.1080/00207727008920220.
URL http://www.tandfonline.com/doi/abs/10.
1080/00207727008920220.
Michael S. A. Graziano. The attention schema
theory: A foundation for engineering artiﬁcial
consciousness. Frontiers in Robotics and AI , 4:60,
November 2017b. doi:10.3389/frobt.2017.00060. URL
http://journal.frontiersin.org/article/10.
3389/frobt.2017.00060/full.
Andrew I. Wilterson and Michael S. A. Graziano. The
attention schema theory in a neural network agent:
Controlling visuospatial attention using a descrip-
tive model of attention. Proceedings of the Na-
tional Academy of Sciences , 118(33), Aug 2021.
doi:10.1073/pnas.2102421118. URL https://www.
pnas.org/content/118/33/e2102421118.
13
Social Neuro AI: Social Interaction as the "dark matter" of AI A PREPRINT
J. P. Mitchell. Activity in right temporo-parietal junction is
not selective for theory-of-mind. Cerebral Cortex, 18(2):
262–271, February 2008. doi:10.1093/cercor/bhm051.
URL https://academic.oup.com/cercor/
article-lookup/doi/10.1093/cercor/bhm051.
Michael S. A. Graziano and Sabine Kastner. Human con-
sciousness and its relationship to social neuroscience:
A novel hypothesis. Cognitive Neuroscience , 2(2):
98–113, 2011a. doi:10.1080/17588928.2011.565121.
URL http://www.tandfonline.com/doi/abs/10.
1080/17588928.2011.565121.
Paola Ardón, Èric Pairet, Katrin S. Lohan, Subrama-
nian Ramamoorthy, and Ronald P. A. Petrick. Build-
ing affordance relations for robotic agents - a review.
arXiv:2105.06706 [cs] , May 2021. URL http://
arxiv.org/abs/2105.06706. arXiv: 2105.06706.
Tianmin Shu, M. S. Ryoo, and Song-Chun Zhu. Learn-
ing social affordance for human-robot interaction.
arXiv:1604.03692 [cs] , Apr 2016. URL http://
arxiv.org/abs/1604.03692. arXiv: 1604.03692.
M.S.A. Graziano. Attributing awareness to others: The at-
tention schema theory and its relationship to behavioural
prediction. Journal of Consciousness Studies, 26(3–4):
17–37, Jan 2019.
Michael S. A. Graziano and Sabine Kastner. Human con-
sciousness and its relationship to social neuroscience:
A novel hypothesis. Cognitive Neuroscience , 2(2):
98–113, 2011b. doi:10.1080/17588928.2011.565121.
URL http://www.tandfonline.com/doi/abs/10.
1080/17588928.2011.565121.
John Schulman, Filip Wolski, Prafulla Dhariwal, Alec
Radford, and Oleg Klimov. Proximal policy optimiza-
tion algorithms. arXiv:1707.06347 [cs] , Aug 2017.
URL http://arxiv.org/abs/1707.06347. arXiv:
1707.06347.
Guillaume Dumas, Julien Laroche, and Alexandre
Lehmann. Your body, my body, our coupling moves
our bodies. Frontiers in human neuroscience, 8:1004,
2014b.
Michael Dennis, Natasha Jaques, Eugene Vinitsky, Alexan-
dre Bayen, Stuart Russell, Andrew Critch, and Sergey
Levine. Emergent complexity and zero-shot transfer via
unsupervised environment design. arXiv:2012.02096
[cs], Feb 2021. URL http://arxiv.org/abs/2012.
02096. arXiv: 2012.02096.
14