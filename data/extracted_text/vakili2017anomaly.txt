arXiv:1709.03573v1  [cs.LG]  11 Sep 2017
1
Anomaly Detection in Hierarchical Data
Streams under Unknown Models
Sattar V akili 1 , Qing Zhao 1, Chang Liu 2 and Chen-Nee Chuah 2
1 School of Electrical and Computer Engineering, Cornell Uni versity, {sv388,qz16}@cornell.edu
2 Electrical and Computer Engineering Department, Universi ty of California, Davis, {chuah,cchliu}@ucdavis.edu
Abstract
W e consider the problem of detecting a few targets among a lar ge number of hierarchical data
streams. The data streams are modeled as random processes wi th unknown and potentially heavy-tailed
distributions. The objective is an active inference strate gy that determines, sequentially, which data stream
to collect samples from in order to minimize the sample compl exity under a reliability constraint. W e
propose an active inference strategy that induces a biased r andom walk on the tree-structured hierarchy
based on conﬁdence bounds of sample statistics. W e then esta blish its order optimality in terms of both
the size of the search space (i.e., the number of data streams ) and the reliability requirement. The results
ﬁnd applications in hierarchical heavy hitter detection, n oisy group testing, and adaptive sampling for
active learning, classiﬁcation, and stochastic root ﬁndin g.
I. I NTRODUCTI ON
W e consider the problem of detecting a few targets with abnor mally high mean values among
a large number of data streams. Each data stream is modeled as a stochastic process with an
unknown and potentially heavy-tailed distributions. The s tochastic nature of the data streams
may be due to the inherent randomness of the underlying pheno menon or the noisy response of
the measuring process. The number of targets is unknown. The objective is to identify all targets
(if any) or declare there is no target to meet a required detec tion accuracy with a minimum
number of samples.
Inherent in a number of applications (see Sec. I-A) is a tree- structured hierarchy among the
large number of data streams. With each node representing a d ata stream, the tree structure
encodes the following relationship: the abnormal mean of a t arget leads to an abnormal mean
2
in every ancestor of the target (i.e., every node on the short est path from this target to the root
of the tree). W e illustrate in Fig. 1 a special case of a binary -tree hierarchy.
T argets are of two types: leaf-level targets and hierarchic al targets. A leaf-level target is a leaf
(level 0) of the tree whose mean is above a given threshold. Hierarchi cal targets are deﬁned
recursively in an ascending order of the level of the tree. Sp eciﬁcally, an upper-level node with
an anomalous mean is a (hierarchical) target if its mean rema ins above a given threshold after
excluding all its target descendants (if any). Otherwise, t his upper-level node is only a reﬂecting
point for merely being an ancestor of a target (see Fig. 1).
The objective of the problem is to detect all targets quickly and reliably by fully exploiting
the hierarchical structure of the data streams. Speciﬁcall y, we seek an active inference strategy
that determines, sequentially, which node on the tree to pro be and when to terminate the search
in order to minimize the sample complexity for a given level o f detection reliability. W e are
particularly interested in strategies that achieve a subli near scaling of the sample complexity
with respect to the number of data streams. In other words, ac curate detection can be achieved
by examining only a diminishing fraction of the search space as the search space grows.
(l=3)
(l=2)
(l=1)
(l=0)
(1,0) (2,0) (3,0) (4,0) (5,0) (6,0) (7,0) (8,0)
(1,1) (2,1) (3,1) (4,1)
(1,2) (2,2)
(1,3)
Fig. 1. A tree-structured hierarchy with l denoting the level of the tree and (k, l) the kth node on the l-th level ( (1,0) is a
leaf-level target, (3,1) is a hierarchical target. Nodes (1,1), (1,2), (1,3), and (2,2) are reﬂecting points). .
A. Applications
The above general problem of detecting abnormal mean values in hierarchical data streams
arises in a number of active inference and learning applicat ions in networking and data analytics.
3
W e give below several representative examples to make the fo rmulation of the problem concrete.
Heavy hitter and hierarchical heavy hitter detection: In Internet and other communication
and ﬁnancial networks, it is a common observation that a smal l number of ﬂows, referred to as
heavy hitters (HH), account for the most of the total trafﬁc [ 1]. Quickly identifying the heavy
hitters is thus crucial to network stability and security. W ith limited sampling resources at the
router, however, maintaining a packet count of each individ ual ﬂow is highly inefﬁcient, if not
infeasible. The key to an efﬁcient solution is to consider pr eﬁx aggregation based on the source
or destination IP addresses. This naturally leads to a binar y tree structure with all targets (HHs)
at the leaf level.
A more complex version of the problem is hierarchical heavy h itter (HHH) detection, in
which the search for ﬂows with abnormal volume extends to agg regated ﬂows. In other words,
there exist hierarchical targets. HHH detection is of parti cular interest in detecting distributed
denial-of-service attacks [2].
Noisy group testing: In group testing, the objective is to identify a few defectiv e items in
a large population by performing tests on subsets of items. E ach group test gives a binary
outcome, indicating whether the tested group contains any d efective items. The problem was
ﬁrst motivated by the blood-test screening of draftees duri ng W orld W ar II, for which Robert
Dorfman originated the idea of testing blood samples pooled from a group of people [3]. Since
then, the problem has found a wide range of applications, inc luding idle channel detection [4],
network tomography [5], detecting malicious users and atta ckers [6], [7], and DNA sequencing
and screening [8], [9].
Most work on group testing assumes error-free test outcomes (see Sec. I-C for a more
detailed discussion on existing work). The problem studied in this paper includes, as a special
case, adaptive group testing under general and unknown nois e models for the test outcomes.
Speciﬁcally, the outcome of a group test is no longer a determ inistic binary value, but rather a
Bernoulli random variable with an unknown parameter that re presents the false alarm probability
(when the tested group contains no defective items) or the de tection power (i.e., the probability of
correct detection when the test group contains defective it ems). A data stream thus corresponds
to the noisy Bernoulli test outcomes of a given subset of the p opulation. The hierarchy of the
data streams follows from the “subset” relationship among t he corresponding test groups. Under
the practical assumption that false alarm and miss detectio n probabilities are smaller than 1/2,
targets are those leaf nodes whose mean value exceeds 1/2. A more detailed mapping of the
4
noisy group testing problem to the active inference problem studied in this paper is given in
Sec. V.
Adaptive sampling with noisy response: The problem also applies to adaptive sampling with
noisy response for estimating a step function in [0, 1]. Such problems arise in active learning of
binary threshold classiﬁers for document classiﬁcation [1 0] and stochastic root ﬁnding [11].
Partitioning the [0, 1] interval into small intervals and sampling the boundary poi nts of each
interval, we can map the adaptive sampling problem to the tar get search problem where the target
is the small interval containing the location of the step. Ex amining larger intervals (consisting
of several smaller intervals) induces a hierarchical struc ture of the noisy responses. See Sec. V
for a detailed discussion.
B. Main Results
W e develop an active inference strategy for detecting an unk nown number of targets among
a large number N of data streams with unknown distributions. The performanc e measure is the
number of samples (i.e., detection delay) required for achi eving a conﬁdence level above 1 −ǫ
(i.e., the probability that the declared target set does not equal to the true set is bounded by
ǫ). By fully exploiting the tree-structured hierarchy, the p roposed active inference strategy has a
sample complexity that is order optimal in both the size N of the search space and the reliability
constraint ǫ.
Referred to as Conﬁdence Bounds based Random W alk (CBRW), th e proposed strategy
consists of a global random walk on the tree interwoven with a local conﬁdence-bound based test.
Speciﬁcally, it induces a biased random walk that initiates at the root of the tree and eventually
arrives and terminates at a target with the required reliabi lity. Each move in the random walk is
guided by the output of a local conﬁdence-bound based sequen tial test carried on each child of
the node currently being visited by the random walk. This loc al sequential test module ensures
that the global random walk is more likely to move toward the t arget than move away from it
and that the random walk terminates at a true target with a suf ﬁciently high probability.
The sample complexity of CBRW is analyzed using properties o f biased random walk on
a tree and large deviation results on the concentration of th e sample mean statistic. W e show
that the sample complexity of CBRW is in the order of O(log N + log 1
ǫ ) provided that the gap
between the mean value of each data stream and the given thres hold is bounded away from 0. It
is thus order optimal in both N and ǫ as determined by information-theoretic lower bounds. Of
5
particular signiﬁcance is that the effect on the sample comp lexity from an enlarged search space
(increasing N) and an enhanced reliability (decreasing ǫ) is additive rather than multiplicative.
This results from the random walk structure which effective ly separates two objectives of moving
to the targets with O(log N) samples and declaring the targets at the desired conﬁdence l evel with
O(log 1
ǫ ) samples. The proposed strategy applies to unknown heavy-ta iled distribution models and
preserves its order optimality in both N and ǫ. Comprising of calculating conﬁdence bounds of
the mean and performing simple comparisons, the proposed st rategy is computationally efﬁcient.
C. Related W ork
The problem studied here is related to several active learni ng and sequential inference prob-
lems. W e discuss here representative studies most pertinen t to this paper and emphasize the
differences in our approach from these existing studies.
Noisy group testing: V ariations of the classic group testing have been extensive ly studied in
the literature focusing mainly on the noisless case. There a re several recent studies that consider
one-sided error (false positive or false negative) in the te st outcomes [12]–[14] or symmetric
error (with equal false positive and false negative probabi lities) [15]–[17] with known error
probabilities. T o our best knowledge, the result in this pap er is the ﬁrst applicable to noisy
group testing under general and unknown noise models.
Adaptive sampling with noisy response: The main body of work on adaptive sampling is
based on a Bayesian approach with binary noise of a known mode l. A popular Bayesian strategyis
the Probabilistic Bisection Algorithm (PBA), which update s the posterior distribution of the step
location after each sample (based on the known model of the no isy response) and chooses
the next sampling point to be the median point of the posterio r distribution. Although several
variations of the method have been extensively studied in th e literature [18]–[20] following the
pioneering work of [21], there is little known about the theo retical guarantees, especially when
it comes to unknown noise models. In this paper we present a no n-Bayesian approach to the
adaptive sampling problem under general unknown noise mode ls.
HH and HHH detection: Prior solutions for online detection of HHHes typically inv olve
adjusting which preﬁxes to monitor either at the arrival of e ach packet [22]–[24], or at periodic
intervals [25], [26]. A particularly relevant work is the ad aptive monitoring algorithm proposed
by Jose et al. [25], where a ﬁxed number of measurement rules are adjusted a t periodic intervals
based on the aggregate packet counts matching to each of thes e rules. At each time interval,
6
the aggregate count is compared to a heuristically chosen th reshold (e.g., a fraction of link
capacity), to determine whether it is an HHH, and whether the rules need to be kept in the
next interval, or expanded to monitor the children of the pre ﬁx, or collapsed and combined with
upstream nodes. While the proposed CBRW has a similar ﬂavor o f moving among parent and
children, which is very much inherent to the HHH detection pr oblem, the decision criteria used
to adjust the preﬁx is different. Instead of comparing with a ﬁxed threshold, our decision is
based on statistical metric determined by the desired detec tion error. Different from the heuristic
studies in the literature, the proposed strategy offers per formance grantee and order optimality.
W e provide a rigorous framework that succinctly captures th e tradeoff between detection time
and overall detection performance.
Pure-exploration bandit problems: The problem studied here is also related to the so-called
pure-exploration bandit problems [27] where the objective is to search for a subset of bandit arms
with certain properties. In particular, in the Thresholdin g Bandit problem introduced in [28], the
objective is to determine the arms with mean above a given thr eshold. The key difference is that
the thresholding bandit problem does not assume any structu re in the arms and has a linearly
growing sample complexity in the number of arms. The focus of this paper is on exploiting the
hierarchical structure inherent to many applications to ob tain sublinear sample complexity with
the size of the search space.
Active hypothesis testing for anomaly detection: The active inference problem considered
here falls into the general class of sequential design of exp eriments pioneered by Chernoff in
1959 [29] with variations and extensions studied in [30]–[3 3]. These studies assume known
or parametric models and focus on randomized test strategie s. This paper, however, adopts a
nonparametric setting and proposes a deterministic strate gy. A number of studies on anomaly
detection within the sequential and active hypothesis test ing framework exist in the literature
(see an excellent survey in [34] and a few recent results in [3 5]–[38]). These studies in general
assume known models and do not address hierarchical structu re of the search space. A particularly
relevant work is [40], in which a test strategy based on a rand om walk on a binary tree was
developed. While the CBRW policy proposed here shares a simi lar structure as the test strategy
developed in [40], the latter work assumes that the stochast ic models of all data streams are
known and the testing strategy relies on using the likelihoo d ratios calculated based on the
known distributions. For the unknown model scenario consid ered in this paper, the conﬁdence-
bound based statistics used for guiding the biased random wa lk are fundamentally different from
7
the likelihood ratio. As a result, the performance analysis also differs.
II. P ROBLEM FORMULATI ON AND PRELIMINAR I ES
A. Problem F ormulation
Consider a set of N data streams conforming to a binary-tree structure with K leaf nodes
as illustrated in Fig. 1 (extensions to general tree structu res are discussed in Sec. V). Let (l, k)
(l = 0 , 1, . . . , L, k = 1 , . . . , 2L−l) denote the kth node at level l of the tree. Let {Xk,l(t)}∞
t=1
denote the corresponding random process which is independe nt and identically distributed with
an unknown distribution fk,l and an unknown mean µk,l.
Associated with each level l of the tree is a given threshold ηl that deﬁnes the targets of
interest. Speciﬁcally, a leaf-level target is a node at leve l l = 0 whose mean µk,0 exceeds η0.
Hierarchical targets are deﬁned recursively in terms of l. Speciﬁcally, a hierarchical target at
level l > 0 is a node whose mean value remains above the threshold ηl after excluding all its
target decedents. The tree-structured hierarchy encodes t he following relationship among nodes
in terms of their mean values: for an arbitrary node (k, l), if µk,l > η l, then µk′,l′ > η l′ for all
(k′, l′) on the shortest path from (k, l) to the root node of the tree.
An active inference strategy π = ( {at}t≥1, Tπ, Sπ) consists of a sampling strategy {at}t≥1, a
stopping rule τπ, and a terminal decision rule Sπ. The sampling strategy {at}t≥1 is a sequence
of functions mapping from past actions and observations to a node of the tree to be sampled
at the current time t. The stopping rule Tπ determines when to terminate the search, and the
decision rule Sπ declares the detected set of targets at the time of stopping. Let EF and PF
denote, respectively, the expectation and the probability measure under distribution model F=
{f(k,l)}l=0,1,...,L
k=1,...,2L−l
. The objective is as follows:
minimizeπ EF Tπ,
s.t. PF [Sπ ̸= S] ≤ǫ,
where Sis the true set of targets.
B. Sub-Gaussian, Heavy-T ailed, and Concentration Inequal ity
W e consider a general distribution fk,l for each process. Due to different concentration behav-
iors, sub-Gaussian and heavy-tailed distributions are tre ated separately. Recall that a real-valued
8
random variable X is called sub-Gaussian [41] if, for all λ ∈(−∞, ∞),
E[eλ(X−E[X])] ≤eξλ2/2 (1)
for some constant ξ > 0. W e assume (an upper bound on) ξ is known. For sub-Gaussian random
variables, Chernoff-Hoeffding concentration inequaliti es hold. Speciﬁcally [42]:













P
[
X(s) +
√
2ξ log 1
p
s < µ
]
≤p
P
[
X(s) −
√
2ξ log 1
p
s > µ
]
≤p,
(2)
where X(s) = 1
s
∑ s
t=1 X(t) is the sample mean of s independent samples of X.
For heavy-tailed distributions, the moment generating fun ctions are no longer bounded, and
the Chernoff-Hoeffding type of concentration inequalitie s do not hold. However, the following
can be said about a truncated sample mean statistic in place o f the sample mean in (2). Assume
that a b-th ( 1 < b < 2) moment of X is bounded:
E[Xb] ≤u, (3)
for some u > 0. Deﬁne the following truncated sample mean with a parameter p ∈(0, 1
2 ]
ˆX(s, p) = 1
s
s∑
t=1
X(t)/BD
{
|X(t)|≤ ( ut
log 1
p
)1/b
}
. (4)
W e then have (Lemma 1 in [43]),













Pr
[
ˆX(s, p) −4u1/b(
log 1
p
s )
b−1
b > µ
]
≤p
Pr
[
ˆX(s, p) + 4 u1/b(
log 1
p
s )
b−1
b < µ
]
≤p.
(5)
III. A N ACTIVE INFERENC E STRATEGY : CBRW
In this section, we present the Conﬁdence Bounds based Rando m W alk (CBRW) policy. W e
focus on the case of a single target and sub-Gaussian distrib utions. Extensions to multiple target
detection and heavy-tailed distributions are discussed in Sec. V.
9
A. Detecting Leaf-Level T argets
W e ﬁrst consider applications where it is known that the targ et is at the leaf level. This
includes, for example, HH detection, noisy group testing, a nd adaptive sampling as discussed in
Sec. I-A.
The basic structure of CBRW consists of a global random-walk module interwoven with a
local CB-based sequential test module at each step of the ran dom walk. Speciﬁcally, the CBRW
policy performs a biased random walk on the tree that eventua lly arrives and terminates at the
target with the required reliability. Each move in the rando m walk (i.e., which neighboring node
to visit next) is guided by the output of the local CB-based se quential test module. This module
ensures that the random walk is more likely to move toward the target than to move away from
the target and that the random walk terminates at the true tar get with high probability.
Consider ﬁrst the local CB-based sequential test module. Th is local sequential test is carried
out on a speciﬁc node (random process) {X(t)}∞
t=1, where we have omitted the node index (k, l)
for simplicity. The goal is to determine whether the mean val ue of {X(t)}∞
t=1 is below a given
threshold η at a conﬁdence level of 1 −β or above the threshold at a conﬁdence level of 1 −α.
If the former is true, the test module outputs 0, indicating this node is unlikely to be an ancestor
of a target or the target itself. If the latter is true, the out put is 1. Let L(α, β, η ) denote this local
sequential test with given parameters {α, β, η }. It sequentially collects samples from {X(t)}∞
t=1.
After collecting each sample, it determines whether to term inate the test and if yes, which value
to output based on the following rule:
• If
X(s) −
√
2ξ log 2s3
α
s > η , terminate and output 1.
• If X(s) +
√
2ξ log 2s3
β
s < η , terminate and output 0.
• Otherwise, continue taking samples,
where X(s) denotes the sample mean obtained form s observations and ξ is the distribution
parameter speciﬁed in (1). W e now specify the random walk on t he tree based on the outputs
of the local CB-based tests. Let (k, l) denote the current location of the random walk (which is
initially set at the root node). Consider ﬁrst l > 1. The left child of (k, l) is ﬁrst probed by the
local module L(α, β, η ) with parameters set to α = β = p0 where p0 can be set to any constant
in (0, 1 − 1√
2 ), and η being the threshold associated with level l −1 of the children of (k, l).
If the output is 1, the random walk moves to the left child of (k, l), and the procedure repeats.
Otherwise, the right child of (k, l) is tested with the same set of parameters, and the random
10
1: Initialization: Initial location of the random walk (k, l) = (1, L), p0 ∈(0, 1 − 1√
2 ), α = β = p0,
ǫ ∈(0, 0.5), ST OP = 0.
2: loop while ST OP =0
3: if l > 1 then
4: T est the left child of (k, l) by L(α, β, η l− 1)
5: if the output of the test on the left child is 1 then
6: Move to the left child of (k, l).
7: else if the output of the test on the left child is 0 then
8: T est the right child of (k, l) by L(α, β, η l− 1)
9: if the output of the test on the right child is 1 then
10: Move to the right child of (k, l).
11: else if the output of the test on the right child is 0 then
12: Move to the parent of (k, l).
13: end if
14: end if
15: else if l = 1 then
16: T est the left child of (k, l) by L( ǫ
2LCp0
, β, η l− 1).
17: if the output of the test on the left child is 1 then
18: Declare the left child of (k, l)as the target.
19: Set STOP=1.
20: else if the output of the test on the left child is 0 then
21: T est the right child of (k, l) by L( ǫ
2LCp0
, β, η l− 1).
22: if the output of the test on the right child is 1 then
23: Declare the right child of (k, l)as the target.
24: Set STOP=1.
25: else if the output of the test on the right child is 0 then
26: Move to the parent of (k, l).
27: end if
28: end if
29: end if
30: end loop
Fig. 2. The random walk module of CBRW for detecting a single l eaf-level target.
11
walk moves to the right child if this test outputs 1. If the outputs of the tests on both children
are 0, the random walk moves back to the parent of (k, l) (the parent of the root node is deﬁned
as itself). The values for {α, β, η }speciﬁed above ensure that the random walk moves toward
the target with a probability greater than 1/2. When the random walk arrives at a node on level
l = 1 , the left child of (k, l) is ﬁrst probed by the local module L(α, β, η ) with parameters set
to α = ǫ
2LCp0
, β = p0 and η = η0 where
Cp0 = 1(
1 −exp(−2(1 −2(1 −p0)2)2)
)2 . (6)
If the output is 1, the random walk terminates and the left child of (k, l) is declared as the target.
Otherwise, the right child of (k, l) is tested with the same set of parameters, and the random
walk terminates with the right child declared as the target i f this test outputs 1. If the outputs
of the tests on both children are 0, random walk moves back to the parent of (k, l). The values
for {α, β, η }speciﬁed above ensure that the random walk terminates at and declares the true
target with the required conﬁdence level of 1 −ǫ. A description of CBRW for detecting a single
leaf-level target is given in Fig. 2.
B. Detecting Hierarchical T argets
W e now consider the case where the target may reside at higher levels of the tree. The following
modiﬁed CBRW policy detects a potentially hierarchical tar get with the required conﬁdence level
of 1 −ǫ.
Let (k, l) denote the current location of the random walk (which is init ially set at the root
node). Consider ﬁrst (k, l) is a non-leaf node with l > 0. The node (k, l) is ﬁrst probed by the
local module L(α, β, η ) with parameters set to α = β = p0 where p0 ∈(0, 1 − 1
3√
2 ) and η = ηl.
If the output is 0, the random walk moves to the parent of (k, l). If the output is 1, then the
left child of (k, l) is tested by the local module L(α, β, η ) with parameters set to α = β = p0
and η = ηl−1. If the output is 1, the random walk moves to the left child. Otherwise, the righ t
child of (k, l) is tested with the same set of parameters, and the random walk moves to the right
child if this test outputs 1. If the outputs of the tests at (k, l) and its children are 1, 0, and 0,
respectively, then (k, l) is likely to be a hierarchical target and the random walk stay s at (k, l).
When the random walk stays at the same node (k, l), the same tests are repeated on (k, l) and its
children with an increased conﬁdence level. W e increase the conﬁdence level by dividing α and
12
1: Initialization: Initial location of the random walk (k, l) = (1, L), parameters ST OP = 0, p0 ∈
(0, 1 − 1
3√
2 ), α = β = p0, ǫ ∈(0, 0.5)), CH
p0 , ST OP = 0.
2: loop while ST OP = 0
3: if l > 0 then
4: T est (k, l) by L(α, β, η l)
5: if the output of the test on (k, l) is 0 then
6: Move the parent of (k, l). Set α = β = p0.
7: else if the output of the test on (k, l) is 1 then
8: T est the left child of (k, l) by L(α, β, η l− 1).
9: if the output of the test on the left child of (k, l) is 1 then
10: Move to the left child of (k, l). Set α = β = p0.
11: else if the output of the test on the left child of (k, l) is 0 then
12: T est the right child of (k, l) by L(α, β, η l− 1).
13: if the output of the test on the right child of (k, l) is 1 then
14: Move to the right child of (k, l). Set α = β = p0.
15: else if the output of the test on the right child of (k, l) is 0 then
16: if α < ǫ
3LCHp0
then
17: Declare (k, l) as the target.
18: Set ST OP = 1.
19: else
20: Divide α and β by 2: α ←α
2 and β ←β
2 .
21: end if
22: end if
23: end if
24: end if
25: else if l = 0 then
26: T est (k, l) by L( ǫ
3LCH
p0
, β, η l)
27: if the output of the test on (k, l) is 0 then
28: Move to the parent of (k, l).
29: else if the output of the test on (k, l) is 1 then
30: Declare (k, l) as the target.
31: Set ST OP = 1.
32: end if
33: end if
34: end loop
Fig. 3. The random walk module of CBRW for detecting a single h ierarchical target.
13
β by 2 iteratively. When the current value of α and β becomes smaller than ǫ
3LCHp0
, the random
walk stops and declares (k, l) as the target. The value of
CH
p0 = 1(
1 −exp(−2(1 −2(1 −p0)3)2)
)2 (7)
ensures the desired conﬁdence level of 1−ǫ at detection of the target. If the random walk moves
to a new location the values of α and β is reset to p0. When the random walk arrives at a leaf
node (k, l) with l = 0 , the leaf node is tested by the local module L(α, β, η ) with parameters
set to α = ǫ
3LCHp0
, β = p0 and η = η0. If the output is 1, the random walk stops and declares
(k, l) as the target. Otherwise, the random walk moves to the parent of (k, l). A description of
CBRW for detecting a single hierarchical target is given in F ig. 3.
IV . P ERFORM AN C E ANALYSIS
In this section, we analyze the sample complexity of CBRW . W e again focus on the case
of a single target and sub-Gaussian distributions and leave extensions to more general cases to
Sec. V.
A. The Sample Complexity of the CB-based Sequential T est Mod ule
T o analyze the sample complexity of CBRW , we ﬁrst analyze the sample complexity of the
local CB-based sequential test module L(α, β, η ) in the lemma below . W e then analyze the
behavior of the random walk to establish the number of times t hat the local sequential test is
carried out.
Lemma 1. Let µ denote the expected value of an i.i.d. sub-Gaussian random p rocess {X(t)}∞
t=1.
Let τL be the stopping time of the CB-based sequential test L(α, β, η ) applied to {X(t)}∞
t=1. W e
have, in the case of µ > η ,
P[
X(T ) +
√
2ξ log 2T 3
β
T < η ] ≤β, (8)
E[T ] ≤ 48
(µ −η)2 log
24 3
√
2
α
(µ −η)2 + 2. (9)
In the case of µ < η ,
14
P[X(T ) −
√
2ξ log 2T 3
α
2T > η ] ≤α, (10)
E[T ] ≤ 48
(µ −η)2 log
24 3
√
2
β
(µ −η)2 + 2. (11)
Proof. See Appendix A.
The inequalities (8) and (10) establish the conﬁdence level s for the local sequential CB-
based test. Both results on the conﬁdence levels and the samp le complexity are based on the
concentration inequalities given in (2).
B. The Sample Complexity of CBRW
In both cases of leaf-level target detection and hierarchic al target detection, the sample com-
plexity of CBRW is order optimal in both N and 1
ǫ as stated in Theorem 1 below .
Theorem 1. Assume that there exists δ > 0 such that µk,l −ηl ≥ δ for all (k, l) (l =
0, 1, . . . , L, k = 1 , . . . , 2L−l). W e have1
EF [TCBRW ] = O(log2 N + log 1
ǫ ) (12)
and
PF [SCBRW ̸= S] ≤ǫ. (13)
Proof. See Appendix B.
The gap µk,l −ηl in the mean value of a random process at level l and the threshold at the
respective level indicates the informativeness of the obse rvations. It is a practical assumption
that the gap is bounded away from 0. W e might also naturally assume that the higher levels are
less informative; thus, have smaller gaps. For example, in g roup testing, tests from larger groups
of items are less informative about the presence of defectiv e items. Under this assumption we
can provide a ﬁnite-time upper bound on the sample complexit y of CBRW .
W e ﬁrst introduce some auxiliary notions which are useful in understanding the trajectory
of the random walk in CBRW . Under leaf-level target setting, consider a sequence of subtrees
1 The search space for the case of detecting leaf-level target is of size K, the number of leaf nodes. However, since N = 2K− 1
is of the same order of K, (12) satisﬁes for both K and N.
15
EF [TCBRW ] ≤ 2
L∑
l=1
Cp0
( 48
(µrl,l −ηl)2 log
24 3
√
2
p0
(µrl,l −ηl)2 + 2
)
+ 48
(µr0,0 −η0)2 log
24
3
√
2Cp0 L
ǫ
(µr0,0 −η0)2 + 2. (14)
EF [TCBRW ] ≤ 3
L∑
l=10+1
CH
p0
1 −p0
[( 48
(µrl,l −ηl)2 log
24 3
√
2
p0
(µrl,l −ηl)2 + 2
)
+ p0
(1 −p0)
16 log 2
(µrl,l −ηl)2
]
+ 3
2∑
l′=1
CH
p0
1 −p0
[( 48
(µr′
l,l′ −ηl′ )2 log
24 3
√
2
p0
(µr′
l,l′ −ηl′ )2 + 2
)
+ p0
(1 −p0)
16 log 2
(µrl′ ,l′ −ηl′ )2
]
+ log2
6LCH
p0 p0
ǫ
( 48
(µrl0 ,l0 −ηl0 )2 log
24 3
√
4
ǫ
(µrl0 ,l0 −ηl0 )2 + 2
)
. (15)
Fig. 4. Finite-regime upper bounds on the performance of CBR W under leaf-level (14) and hierarchical (15) target settin gs.
{T1, T2, ..., TL}of T. Subtree TL is obtained by removing the biggest half-tree containing th e tar-
get from T. Subtree Tl is iteratively obtained by removing the biggest half-tree c ontaining the tar-
get from the half-tree containing the target in the previous iteration. In the example given in Fig. 1,
T3 = {(1, 3), (2, 2), (3, 1), (4, 1), (5, 0), (6, 0), (7, 0), (8, 0)}, T2 = {(1, 2), (2, 1), (3, 0), (4, 0)}
and T1 = {(1, 1), (2, 0)}. Let (rl, l) denote the child of the root node of Tl. Under hierarchical
target setting with a hierarchical target at level l0, let subtrees {Tl0+1, ..., TL}be the same as
deﬁned for a target that is a decedent of the hierarchical tar get. Also, deﬁne T′
1 and T′
2 as subtrees
whose root nodes are children of the hierarchical target. Le t (r′
l, l) denote the root node of T′
l .
A detailed ﬁnite-time upper bound on the sample complexity o f CBRW is given in (14)
and (15) where (r0, 0) and (rl0 , l0) denote the targets under leaf-level and hierarchical setti ngs,
respectively.
V . E XTENSIONS AND DISCUSSIO NS
In this section, we discuss extensions to more general scena rios and the mapping of various
applications to the target detection problem at hand.
16
A. Detecting an Unknown Number of T argets
Detecting |S|> 1 targets with |S|known can be easily implemented by sequentially locating
the targets one by one. W e assume that each target can be remov ed after it is located by CBRW 2 .
T o ensure that the reliability constraint holds, we replace ǫ with ǫ
|S| in each search of a single
target. The reliability constraint holds by union bound on t he error probabilities of the searches
for a single target.
When the number of targets is unknown, but an upper bound Smax ≥|S| on the number of
targets is known, we can similarly detect the targets one by o ne. T o ensure that the reliability
constraint holds, we replace ǫ with ǫ
2Smax
in each search of a single target. The stopping rule for
the overall search can be implemented by testing the root nod e. Speciﬁcally, the root node is
tested by L(ǫ0, ǫ0, ηL) with ǫ0 = ǫ
2Smax
every LCp0 steps in the random walk under leaf target
setting and every LCH
p0 steps under the hierarchical target setting. The reliabili ty constraint holds
by union bound on the error probabilities of the searches for a single target and error in stopping
the overall search before ﬁnding all targets.
Under both leaf-level and hierarchical target settings, wi th this modiﬁcation, the sample
complexity of ﬁnding single targets simply add up to ab O(|S|log K + |S|log 1
ǫ ) overall sample
complexity.
B. Heavy-T ailed Distributions
The extension to more general distribution models can be imp lemented by only modifying
the local CB-based test Lin a way that the conﬁdence levels remain the same. As a result , the
behavior of the random walk on the tree remains the same.
Speciﬁcally, for heavy-tailed distributions with existin g b’th moment as given in (3), we modify
the test L
• If ˆX(s, α) −4u1/b(
log 2s3
α
s )
b−1
b > η , terminate and output 1.
• If ˆX(s, β) + 4 u1/b(
log 2s3
β
s )
b−1
b < η , terminate and output 0.
• Otherwise, continue taking samples.
2 For example, in group testing, the detected defective item i s no longer tested in any subsequent group tests or in HHH
detection, the packet count of each detected HHH can be subtr acted from the packet count of the parents.
17
The resulting CBRW achieves the same O(log N + log 1
ǫ ) sample complexity under both leaf-
level and hierarchical target settings. The proofs follow s imilar to the proofs of Theorem 1 and
Lemma 1, using conﬁdence bounds (5) instead of (2) in the proo f of Lemma 1.
C. General Tree Structures
Consider a general tree-structured hierarchy as shown in Fi g. 5. The CBRW policy can be
modiﬁed as follows.
T o have the required conﬁdence level in taking the steps towa rd the target, the input parameters
in the local CB-based sequential test Lare modiﬁed based on the degree dk,l of each node (k, l)
in the tree. In particular, under the leaf-level target sett ing, we choose p0 ∈(1 − 1
2−(dk,l−1) ) and
α = ǫ
(D−1)LC where L is the maximum distance from the root node to a leaf node, D is the
maximum degree of the nodes in the tree and C is a constant independent of K and ǫ. Under
the hierarchical target setting, we choose p0 ∈(1 − 1
2−dk,l ) and when increasing the conﬁdence
level iteratively to detect the hierarchical target, we ter minate the search when p goes below
ǫ
DLC . The random walk moves to a child or the parent of the current l ocation according to the
outputs of the tests.
Following similar lines as in the proof of Theorem 1, we can sh ow a sample complexity of
O(LD) + O(log 1
ǫ ) under both leaf-level and hierarchical target settings.
Fig. 5. A general tree-structured hierarchy .
18
D. Mapping from V arious Applications
HH and HHH detection: The CBRW policy directly applies to leaf-level HH and HHH
detection under leaf-level and hierarchical target settin gs, respectively. In particular, provided
a controllable counter which can be assigned to each IP preﬁx , we assign the counter to the
current location which is desired to be tested according to L. Based on the packet count, the
counter is moved on the tree according to CBRW . When there are several counters available the
tree can be partitioned to smaller subtrees and CBRW is run on each subtree separately to make
an efﬁcient use of the available counters.
Noisy group testing: In group testing, the objective is to identify a few defectiv e items in
a population of K items performing tests on subsets of items. Each group test g ives a binary
outcome, indicating whether the tested group contains any d efective items. W e consider the case
of adaptive group testing under general and unknown noise mo dels for test outcomes. Speciﬁcally,
the outcome of a group test is a Bernoulli random variable wit h an unknown parameter that
represents the false alarm or missed detection probability .
The CBRW policy under leaf-level target setting directly ap plies to noisy group testing where
the defective items are the leaf-level targets. Each data st ream corresponds to the noisy Bernoulli
test outcomes of the given subsets of the population. The par ent-children relationship on the
tree represents the subset relationship among the correspo nding test groups such that the group
corresponding to the parent is the union of the groups corres ponding to the children. Under
the practical assumption that false alarm and miss detectio n probabilities are smaller than
1/2, targets are those data streams generated by a singleton sub set (i.e., leaf nodes) with a
mean value exceeding 1/2. Although group testing problem does not necessarily confo rm to a
predetermined hierarchical structure, the proposed solut ion offers order optimal number of tests
in both population size and reliability constraint.
Adaptive sampling with noisy response: Consider the [0, 1] interval as the input space.
W e limit the input space to be one-dimensional in order to dem onstrate the main idea. The
hypothesis class, denoted by H, is the set of all step functions on [0,1] interval.
H=
{
hz : [0 , 1] →R, hz(x) = /BD
{(z,1]}(x), z ∈(0, 1)
}
(16)
Each hypothesis hz assigns a binary label to each element of the input space [0, 1]. There is a
true hypothesis hz∗ that determines the ground truth labels for the input space.
19
The learner is allowed to make sequential observations by ad aptively sampling hz∗ . The
observations are however noisy. The goal is to design a seque ntial sampling strategy aiming
at minimizing the sample complexity required to obtain a con ﬁdence interval of length ∆ for z∗
at a 1 −ǫ conﬁdence level. Speciﬁcally, the learner chooses the samp ling point x at each time
t and receives a noisy sample of the true hypothesis.
W e consider two noise models with unknown distribution. In t he ﬁrst noise model, the learner
observes a noisy sample of the threshold function in the form of
hN
z∗ (x; t) = hz∗ (x; t) + n(x, t), (17)
where n(x, t) is a zero mean sampling noise that possibly depends on the sam pling point x and
is generated i.i.d. over t.
In the second noise model, the binary samples can ﬂip from zer os to ones and vice versa.
Speciﬁcally, the learner receives erroneous binary sample s with an error probability of p(.) in
the form of
hB
z∗ (x; t) = hz∗ (x; t) ⊕B(x, t), (18)
where ⊕is the boolean sum and B(x, t) is a Bernoulli random variable with P[B(x, t) = 1] =
p(x) that may depend on the sampling point x and is generated i.i.d. over t.
W e now present a solution to the adaptive sampling problem ba sed on the results obtained
for CBRW strategy. For the simplicity of presentation we ass ume ∆ = 1
2L (K = 1
∆ ). Let each
node on a binary tree T represent an interval [zL
k,l, zR
k,l] ⊂[0, 1] with zL
k,l = ( k2L−l −1)∆ and
zU
k,l = k2L−l∆ . The interval corresponding to each node on the tree is the un ion of the intervals
corresponding to its children.
What remains to be speciﬁed is what entails when probing a nod e/interval (k, l). When (k, l)
is probed the boundary points of the interval are tested by L(α, β, η ) with parameters set to
ηl = 0 .5 and α = β = p0 on a non-leaf node, and α = ǫ
2LCp0
, β = p0 on a leaf node where p0
can be set to any constant in (0, 1 − 1
4√
2 ). The output is 1 (indicating that the interval is likely to
contain z∗) if and only if the output of Lis 0 on the left boundary and 1 on the right boundary.
The output is 0 otherwise. From the results on the analysis of CBRW the above solution has a
sample complexity of O( 1
c2 log K + 1
c2 log 1
ǫ ) where c is 0.5 under the ﬁrst noise model and c is
a lower bound on the gap in 0.5 −p(.) under the second noise model.
20
VI. C ONCLUSION
In this paper, we studied the problem of detecting a few targe ts among a large number of
hierarchical data streams modeled as random processes with unknown distributions. W e designed
a sequential strategy to interactively choose the sampling point aiming at minimizing the sample
complexity subject to a reliability constraint. The propos ed sequential sampling strategy detects
the targets at the desired conﬁdence level with an order opti mal logarithmic sample complexity in
both problem size and the parameter of reliability constrai nt. W e further showed the extensions
of the results to a number of active inference and learning pr oblems in networking and data
analytics applications.
The results obtained in this work extend to the detection of a nomaly in other statistics such as
variance. In particular, replacing the sample mean with sam ple variance in the local CB-based
sequential test and modifying the second term in the upper an d lower conﬁdence bounds in
the local CB-based sequential test, both the CBRW policy and its sample complexity analysis
apply to anomaly detection where the anomalies manifest in t he variance. Similar results can be
obtained for other statistics assuming the existence of an e fﬁcient estimator.
REFERENC E S
[1] K. Thompson, G. Miller, and R. Wilder, “Wide-area intern et trafﬁc patterns and characteristics, ” IEEE Network , vol. 11,
pp. 1017, Nov 1997.
[2] P . E. A yres, H. Sun, H. J. Chao, and W . C. Lau “ Alpi: A ddos de fense system for high-speed networks, ” IEEE Journal on
Selected Areas in Communications , vol. 24, no. 10, pp. 18641776, 2006. 24(10):18641776, 2006 .
[3] R. Dorfman, “The detection of defective members of large populations, ” in Annals of Mathematical Statistics , vol. 14, pp.
436171, 1943.
[4] A. Sharma and C. Murthy , “Group testing based spectrum ho le search for cognitive radios, ” IEEE Transactions on V ehicular
T echnology,2014.
[5] M. Cheraghchi, A. Karbasi, S. Mohajer, and V . Saligrama, “Graph-constrained group testing, ” IEEE Transactions on
Information Theory, vol. 58, pp. 248172, Jan 2012.
[6] M. T . Thai, Y . Xuan, I. Shin, and T . Znati, “On detection of malicious users using group testing techniques, ” in The 28th
International Conference on Distributed Computing System s, pp. 206173, 2008.
[7] S. Khattab, S. Gobriel, R. Melhem, and D. Mosse, “Live bai ting for service-level DoS attackers, ” in The 27th IEEE
Conference on Computer Communications, April 2008.
[8] H. Q. Ngo and D.-Z. Du, “ A survey on combinatorial group te sting algorithms with applications to DNA library screenin g, ”
Discrete mathematical problems with medical applications , vol. 55, pp. 171172, 2000.
[9] D. Balding, W . Bruno, D. T orney , and E. Knill, “ A comparat ive survey of non-adaptive pooling designs, ” in Genetic mapping
and DNA sequencing, pp. 133174, Springer, 1996.
21
[10] R. Castro and R. Nowak, “Minimax Bounds for Active Learn ing, ” IEEE Transactions on Information Theory , vol. 54,
no. 5, pp. 2339-2353, 2008.
[11] P . I. Frazier, S. G. Henderson, R. W aeber, “Probabilist ic bisection converges almost as quickly as stochastic appr oximation”,
available at arXiv:1612.03964v1 [math.PR] , 2016.
[12] G. Atia and V . Saligrama, “Noisy group testing: An infor mation theoretic perspective, ” in 47th Annual Allerton Conference
on Communication, Control, and Computing, pp. 355172, IEEE, 2009.
[13] G. K. Atia and V . Saligrama, “Boolean compressed sensin g and noisy group testing, ” IEEE Transactions on Information
Theory, vol. 58, no. 3, pp. 18801701, 2012.
[14] V . Y . T an and G. Atia, “Strong impossibility results for noisy group testing, ” in ICASSP, pp. 82571761, 2014.
[15] M. Cheraghchi, A. Hormati, A. Karbasi, and M. V etterli, “Compressed sensing with probabilistic measurements: A gr oup
testing solution, ” in 47th Annual Allerton Conference on Communication, Control , and Computing , pp. 3017, IEEE, 2009.
[16] S. Cai, M. Jahangoshahi, M. Bakshi, and S. Jaggi, “Grote sque: noisy group testing (quick and efﬁcient), ” in 51st Annual
Allerton Conference on Communication, Control, and Comput ing, pp. 12341741, IEEE, 2013.
[17] C. L. Chan, S. Jaggi, V . Saligrama, and S. Agnihotri, “No n-adaptive group testing: Explicit bounds and novel algori thms, ”
IEEE Transactions on Information Theory, vol. 60, no. 5, pp. 30191735, 2014.
[18] R. W aeber, P . I. Frazier, S. G. Henderson, “Bisection Se arch With Noisy Responses, ” in SIAM Journal on Control and
Optimization, vol. 51, no. 3, pp. 22611779.
[19] M. Ben-Or and A. Hassidim, “The Bayesian learner is opti mal for noisy binary search, ” in Proceedings of the 49th Annual
IEEE Symposium on F oundations of Computer Science, IEEE , pp. 221170 ,2008.
[20] R. Castro and R. Nowak, “ Active learning and sampling, ” in F oundations and Applications of Sensor Management, Springer,
New Y ork, pp. 177170, 2008.
[21] M. Burnashev and K. Zigangirov , “ An interval estimatio n problem for controlled observations, ” Problemy P eredachi
Informatsii, vol 10 , pp. 5117, 1974.
[22] G. Cormode, F . Korn, S. Muthukrishnan, and D. Srivastav a, “Finding hierarchical heavy hitters in streaming data” ACM
Trans. Knowl. Discov . Data, vol. 1, no.4, pp 1-48, 2008.
[23] L. Y uan, C. Chuah, and P . Mohapatra, “Progme: T owards pr ogrammable network measurement” In Proceedings of the
2007 Conference on Applications, T echnologies, Architect ures, and Protocols for Computer Communications, SIGCOMM,
ACM 2007.
[24] Y . Zhang, S. Singh, S. Sen, N. Dufﬁeld, and C. Lund, “Onli ne identiﬁcation of hierarchical heavy hitters: Algorithm s,
evaluation, and applications, ” In Proceedings of the 4th ACM SIGCOMM Conference on Internet Measurement, IMC, ACM,
2004.
[25] L. Jose, M. Y u, and J. Rexford, “Online measurement of la rge trafﬁc aggregates on commodity switches” In Proceedings
of the 11th USENIX Conference on Hot T opics in Management of I nternet, Cloud, and Enterprise Networks and Services,
Hot-ICE, USENIX Association, 2011.
[26] M. Mitzenmacher, T . Steinke, and J. Thaler, “Hierarchi cal heavy hitters with the space saving algorithm, ” In Proceedings
of the Meeting on Algorithm Engineering and Experiments, AL ENEX, 2012.
[27] S. Chen, T . Lin, I. King, M. Lyu, and W Chen, “Combinatori al pure exploration of multiarmed bandits, ” in Advances in
Neural Information Processing Systems , pp. 379177, 2014
[28] A. Locatelli, M. Gutzeit, A. Carpentier, “ An optimal al gorithm for the Thresholding Bandit Problem, ” available at :
arXiv:1605.08671v1, 2016.
[29] H. Chernoff, “Sequential design of experiments, ” The Annals of Mathematical Statistics , vol. 30, no. 3, pp. 755770, 1959.
22
[30] S. Nitinawarat, G. K. Atia, and V . V . V eeravalli, Contro lled sensing for multihypothesis testing, IEEE Transactio ns on
Automatic Control, vol. 58, no. 10, pp. 24512464, 2013.
[31] S. Nitinawarat and V . V . V eeravalli, Controlled sensin g for sequential multihypothesis testing with controlled m arkovian
observations and nonuniform control cost, Sequential Anal ysis, vol. 34, no. 1, pp. 124, 2015.
[32] M. Naghshvar and T . Javidi, Active sequential hypothes is testing, The Annals of Statistics, vol. 41, no. 6, pp. 2703 2738,
2013.
[33] M. Naghshvar and T . Javidi, Sequentiality and adaptivi ty gains in active hypothesis testing, IEEE Journal of Selec ted
T opics in Signal Processing, vol. 7, no. 5, pp. 768782, 2013.
[34] A. T ajer, V . V . V eeravalli, and H. V . Poor, Outlying sequ ence detection in large data sets: A data-driven approach, I EEE
Signal Processing Magazine, vol. 31, no. 5, pp. 4456, 2014.
[35] K. Cohen, Q. Zhao Active Hypothesis T esting for Anomaly Detection IEEE Transactions on Information Theory , vol. 61 ,
no. 3, pp. 1432-1450, March, 2015.
[36] K. Cohen, Q. Zhao Asymptotically Optimal Anomaly Detec tion via Sequential T esting IEEE Transactions on Signal
Processing, vol. 63, no. 11, pp. 2929-2941, June, 2015.
[37] K. Leahy and M. Schwager, Always choose second best: Tra cking a moving target on a graph with a noisy binary sensor,
in European Control Conference (ECC), 2016, pp. 17151721, I EEE, 2016.
[38] G. Fellouris, G. V . Moustakides, and V . V . V eeravalli, M ultistream quickest change detection: Asymptotic optimal ity under a
sparse signal, in IEEE International Conference on Acousti cs, Speech and Signal Processing (ICASSP), 2017, pp. 644464 47,
2017.
[39] B. Huang, K. Cohen, Q. Zhao, ”Sequential Active Detecti on of Anomalies in Heterogeneous Processes, ” arXiv preprin t
arXiv:1704.00766
[40] C. W ang, K. Cohen, Q. Zhao, “ Active Hypothesis T esting o n A Tree: Anomaly Detection under Hierarchical Observation s, ”
to appear in proceedings of ISIS , 2017.
[41] P . Chareka, O. Chareka, S. Kennendy , “Locally Sub-Gaus sian Random V ariable and the Stong Law of Large Numbers, ”
Atlantic Electronic Journal of Mathematics , vol. 1, no. 1, pp. 75-81, 2006.
[42] R. V ershynin, “Introduction to the Non-Asymptotic Ana lysis of Random Matrices, ” available at
http://arxiv .org/abs/1011.3027v6.
[43] S. Bubeck, N. Cesa-Bianchi, G. Lugosi, “Bandits with he avy tail, ” arXiv:1209.1727 [stat.ML] , September 2012.
APPENDIX A
Proof of Lemma 1. The proof of Lemma 1 is based on concentration inequalities f or Sub-
Gaussian distributions.
23
W e prove inequality (9) here. The other case, µ < η (11), can be proven similarly.
P
[
X(T ) +
√
2ξ log 2T 3
β
T < η
]
≤ P
[
sup
s
X(s) +
√
2ξ log 2s3
β
s < η
]
≤
∞∑
s=1
P
[
X(s) +
√
2ξ log 2s3
β
s < η
]
≤
∞∑
s=1
exp(−log 2s3
β ) (19)
=
∞∑
s=1
p
2s3
≤ β.
Inequity (19) is obtained by (2).
W e next analyze the E[T ] for µ > η . Let s0 = min {s ∈N :
√
2 log 2s3
α
s ≤µ−η
2 , s > 1}, for
n ≥s0:
P[T ≥n] ≤ P
[
sup
{
s : X(s) +
√
2ξ log 2s3
β
s > η, and
X(s) −
√
2ξ log 2s3
α
s < η
}
≥n
]
≤ P
[
sup
{
s : X(s) −
√
2ξ log 2s3
α
s < η
}
≥n
]
≤
∞∑
s=n
P
[
X(s) −
√
2ξ log 2s3
α
s < η
]
≤
∞∑
s=n
P
[
Xs −µ < −
√
2 log 2s3
α
s
]
(20)
≤
∞∑
s=n
exp(−log 2s3
α )
≤
∞∑
s=n
α
2s3
≤ α
4(n −1)2 .
24
Notice that (20) holds because n ≥s0. W e can write E[T ] in terms of P[T ≥n] as
E[T ] =
∞∑
n=0
P[T ≥n] (21)
= s0 +
∞∑
n=s0
P[T ≥n]
≤ s0 +
∞∑
n=s0
α
4(n −1)2
≤ s0 + 1.
For the last inequality notice that s0 is deﬁned to be bigger than 1. It remains to ﬁnd s0. Note
that for all x > 0 we have log x < √x so log log x < log √x = 1
2 log x. For s = 48
(µ−η)2 log
24 3√2
α
(µ−η)2
log 2s3
α = 3 log
3
√
2
αs
= 3 log
3
√
2
α
48
(µ −η)2 log
24 3
√
2
α
(µ −η)2
= 3 log
3
√
2
α
24
(µ −η)2 + 3 log log
( 24 3
√
2
α
(µ −η)2
)2
≤ 3 log
3
√
2
α
24
(µ −η)2 + 3 log
3
√
2
α
24
(µ −η)2
= 6 log
3
√
2
α
24
(µ −η)2
= 6 (µ −η)2
48 s.
Thus, for s = 48
(µ−η)2 log
24 3
√
2
α
(µ−η)2 ,
√
2 log 2s3
α
s ≤µ −η
2 .
So, we have the following upper bound for s0
s0 ≤⌈ 48
(µ −η)2 log
24 3
√
2
α
(µ −η)2 ⌉+ 1. (22)
The addition of 1 is because s0 is deﬁned to be bigger than 1. Thus,
E[T ] ≤ 48
(µ −η)2 log
24 3
√
2
α
(µ −η)2 + 2, (23)
25
which completes the proof.
APPENDIX B
Proof of Theorem 1. An upper bound on the sample complexity of test Lis provided in Lemma 1.
Here, we establish an upper bound on the number of times that t est Lis called in CBRW . First,
consider the case of leaf-level target setting.
In order to analyze the trajectory of the random walk, we cons ider the last passage time Tl
of the random walk from each subtree Tl. W e prove an upper bound on E[Tl] for each l which
gives an upper bound on the total number of times that test Lis called. Notice that the total
number of times that test Lis called is not bigger than 2 ∑ L
l=1 E[Tl].
The random walk initially starts at the root node at distance L from the target. Deﬁne the
parameters Wt as the steps of the random walk: Wt = 1 if the random walk moves one step
further from the target at time t, Wt = −1 if the random walk moves one step closer to the
target, and Wt = 0 when the random walk does not move. Clearly, ∑ τ
t=1 Wt = −L where τ is
the stopping time of the random walk. The random walk stops wh en the policy declares a leaf
node as the target. For the mean value of Wt, from Lemma 1, we have
E[Wt] = P[Wt = 1] −P[Wt = −1]
≤ 1 −2(1 −p0)2
< 0.
Notice that if the random walk is within the subtree TL at step t, we have
t∑
s=1
Ws > 0. (24)
Thus, we can write
P[TL > n ] ≤ P
[
sup{t ≥1 :
t∑
s=1
Ws > 0}> n
]
(25)
≤
∞∑
t=n
P
[ t∑
s=1
Ws > 0
]
≤
∞∑
t=n
exp
(
−1
2t(1 −2(1 −p0)2)2
)
(26)
= exp(−2n(1 −2(1 −p0)2)2)
1 −exp(−2(1 −2(1 −p0)2)2).
26
Inequity (26) is obtained by Hoeffding inequality for Berno ulli distributions. W e can obtain
E[TL] from P[TL > n ] based on the sum of tail probabilities as
E[TL] =
∞∑
n=0
P[TL > n ]
≤
∞∑
n=0
exp(−2n(1 −2(1 −p0)2)2)
1 −exp(−2(1 −2(1 −p0)2)2)
= 1(
1 −exp(−2(1 −2(1 −p0)2)2)
)2 .
Let us deﬁne
Cp0 = 1(
1 −exp(−2(1 −2(1 −p0)2)2)
)2 , (27)
which is a constant independent of K and ǫ. From the symmetry of binary tree, it can be seen
that E[Tl] ≤Cp0 for all l and the expected number of points visited by the random walk i s upper
bounded by 2LCp0 . Under the assumption that the informativeness of observat ions decreases in
higher levels we can replace the sample complexity of test Lat the highest level and arrive at
the ﬁrst term in (14). The second term in (14), is obtained by d irect application of Lemma 1 on
the sample complexity of test Lat the target node.
It remains to show that CBRW satisﬁes the reliability constr aint. W e know that at each visit
of a leaf node the probability of declaring a non-target node as the target is lower than ǫ
2LCp0
by the design of the test at leaf nodes. Thus, from the upper bo und on the expected number of
points visited by the random walk we have
P[Sδ ̸= {(k0, 0)}] ≤ 2LCp0
ǫ
2LCp0
= ǫ.
Order optimality of log K follows from information theoretic lower bound. Order opti mality
of log 1
ǫ can be established following standard techniques in sequen tial testing problems.
An upper bound on the sample complexity of CBRW under hierarc hical target setting can be
obtained similarly. The trajectory of the random walk can be analyzed by considering the last
passage times Tl of the random walk from subtrees Tl for l = l0 + 1, ..., L, as well as the last
27
passage times T ′
1 and T ′
2 of the random walk from subtrees T′
1 and T′
2 which can be shown to
not bigger than CH
p0 following the similar lines as in the proof of Theorem 1 with
CH
p0 = 1(
1 −exp(−2(1 −2(1 −p0)3)2)
)2 . (28)
The analysis under hierarchical target setting differs fro m the analysis under leaf-level target
setting in that the consecutive calls of test Lon the same node results in increasing the conﬁdence
level. W e establish an upper bound on the expected total numb er Ttot of observations from a
node at a series of consecutive calls of test Lon the node where the conﬁdence level is divided
by 2 iteratively at each time. Let T (k) be the number of samples taken at k’th consecutive call
of test Lon a node. By design of CBRW strategy under hierarchical targ et setting the value
of p in test Lis divided by 2 until the ﬁrst time k that p0
2k−1 < ǫ
3LCHp0
. Thus there are at most
⌈log2
3LCH
p0 p0
ǫ ⌉consecutive calls of test Lon one node. On a non-target node:
E[Ttot ] ≤
⌈log2
3LCHp0 p0
ǫ ⌉∑
k=1
pk−1
0 E[T (k)]
≤
∞∑
k=1
pk−1
0
( 48
(µ −η)2 log
24 3
√
2k
p0
(µ −η)2 + 2
)
≤
∞∑
k=1
pk−1
0
( 48
(µ −η)2 log
24 3
√
2
p0
(µ −η)2 + 2
)
+
∞∑
k=1
pk−1
0
48
(µ −η)2 log
3√
2k−1
= 1
1 −p0
( 48
(µ −η)2 log
24 3
√
2
p0
(µ −η)2 + 2
)
+ p0
(1 −p0)2
16 log 2
(µ −η)2 . (29)
Upper bound on E[Ttot ] in a conservative upper bound on each single time that the tes t Lis
called.
28
On the target node:
E[Ttot ] ≤
⌈log2
3LCHp0 p0
ǫ ⌉∑
k=1
E[T (k)]
≤ ⌈log2
3LCH
p0 p0
ǫ ⌉
( 48
(µ −η)2 log
24 3
√
4
ǫ
(µ −η)2 + 2
)
≤ log2
6LCH
p0 p0
ǫ
( 48
(µ −η)2 log
24 3
√
4
ǫ
(µ −η)2 + 2
)
. (30)
From the upper bound on E[Ttot ], the upper bound on the sample complexity of CBRW can
be obtained. The satisfaction of the constraint on error pro bability can be shown similar to the
leaf-level target setting.