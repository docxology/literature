Accepted for publication in the 2020 International Conference on Robotics and Automation (ICRA)
Cognitive and motor compliance in intentional human-robot interaction
Hendry F. Chame‚Ä† and Jun Tani‚Ä†
Abstract‚ÄîEmbodiment and subjective experience in human-
robot interaction are important aspects to consider when
studying both natural cognition and adaptive robotics to hu-
man environments. Although several researches have focused
on nonverbal communication and collaboration, the study of
autonomous physical interaction has obtained less attention.
From the perspective of neurorobotics, we investigate the
relation between intentionality, motor compliance, cognitive
compliance, and behavior emergence. We propose a variational
model inspired by the principles of predictive coding and active
inference to study intentionality and cognitive compliance, and
an intermittent control concept for motor deliberation and
compliance based on torque feed-back. Our experiments with
the humanoid Torobo portrait interesting perspectives for the
bio-inspired study of developmental and social processes.
I. INTRODUCTION
Our society is probably changing into a world populated
by natural and artiÔ¨Åcial beings, where we will coexist with
robots at home and the oÔ¨Éce. However, at present, there is
still an important gap to be overcome, in particular, when
we pause to contemplate the amazing complexity of natural
behavior. This sort of sophistication is related to important
properties, among which are autonomy and intentionality.
When studying motor interaction between a human and
a robot, some works have focused on goal-directed collab-
oration (e.g. mediated by physical objects [1], and behavior
improvement [2]), leaving aside the social dimension of the
interaction with the robot partner. With some exceptions,
direct contact in autonomous behavior has been avoided
[3]. Moreover, in social robotics, the non-verbal aspects of
interaction have been studied from diverse modalities (e.g.
facial expressions [4] and touch [5]), though motor clues in
direct contact have attracted less attention.
In psychology, physical interaction is considered an in-
tuitive means of communication during human early life,
which underlies the acquisition and development of social
and cognitive skills [6]. Hence, it is paramount for human
development, and it is relevant for studying learning from
the perspective of developmental robotics [7].
Intentional motor interaction is certainly a broad phe-
nomenon that ought to be delimited. Thus, by taking inspi-
ration on neuroscience research, we hold the assumption that
intentionality involves an optimization process in hierarchical
representation structures, in which a top-down information
Ô¨Çow characterizes the agency of purposeful actions in a given
context, whereas a bottom-up information Ô¨Çow accounts for
theirconsequences.Weinvestigatethiswithintheperspective
‚Ä† Cognitive Neurorobotics Research Unit (CNRU), Okinawa Institute of
Science and Technology (OIST), Okinawa, Japan 904-0495.
E-mail: {hendryfchame, tani1216jp}@gmail.com
of Friston‚Äôsfree energy principle theory [8], according to
which the brain attempts to resolve conÔ¨Çicts possibly appear-
ing between the top-down information Ô¨Çow, developed by a
generative model, and the bottom-up sensory Ô¨Çow, through
minimizing free energy as a statistical quantity.
Our research is interested in the study of harmonious
(or coherent) and disharmonious (or incoherent) interaction
between the human and the robot. Thus, an important
distinction is established between physical (or motor) and
cognitive (or representational) compliance. The former is
deÔ¨Åned as the capacity to be driven by external physical
action, which can be conforming or conÔ¨Çicting with the
intended action; whereas the later involves the Ô¨Çexibility in
modifying the generative process according to information
from the ascending process, that is, the capacity to be driven
by sensory evidence (the inference process).
After having established the previous considerations, we
claim that the originality and main contribution of our
research is to study the relation between physical and cog-
nitive compliance in purposeful motor interaction. Within
the perspective of neurorobotics, we propose a variational
model, inspired by the principles of predictive coding and
active inference [9], to study intentionality and cognitive
compliance. We propose an intermittent control concept
for the study of motor deliberation and compliance that
takes into account torque feed-back. From the analysis of
interaction and behavior emergence in experiments with the
human-sized Torobo platform, we illustrate the relevance of
our work to the study of direct interaction, with interesting
perspectives for the bio-inspired approach to developmental
and social robotics.
II. RELATED WORK
Although independently developed, our research has been
consistent with the free energy principle theory [9]. In
[10] a deterministic hierarchical neural network architecture
operating on diÔ¨Äerent time scales (i.e. a Multiple Timescale
Recurrent Neural Network, or MTRNN) was proposed for
learning temporal sequences. Inspired by these ideas, be-
havior imitation was studied from visual and proprioceptive
representations (e.g. in [11]).
Inordertoimprovegeneralization,stochasticmodelinghas
been adopted where uncertainty in training data is learned as
a Gaussian distribution in the output layer [12]. However, a
limitation of this approach is the fact that the context layers
in the hierarchy remained deterministic.
The emergence of the variational Bayes auto-encoder
(VAE) framework [13] paved the way for optimizing in-
ference and learning probabilistic distributions in latent
arXiv:1911.01753v4  [cs.RO]  30 Jun 2020
variables, by re-parameterizing the variational lower bound.
This framework has been extended for studying on-line
interaction, as for example anticipating human behavior [14].
The predictive-coding-inspired variational recurrent neu-
ral network (PV-RNN) [15] has been proposed recently
in our lab. It is a variational model capable of learning
probabilistic structures in Ô¨Çuctuating temporal patterns, by
modifying dynamically the stochasticity of the represented
latent states. DiÔ¨Äerent from VAEs, inputs are not propagated
in the network during forward computations. Instead, predic-
tion errors areback propagated through time(BPTT).
Unlike [11], where the robot imitates the human behavior
from visual input, our work is focused on direct physical
interaction based exclusively on the proprioceptive source of
information. Since our interest is to investigate autonomous
and possibly conÔ¨Çicting interaction, diÔ¨Äerent from [14], our
study does not focus on predicting the human behavior, but
on the inference process over proprioceptive representations.
Thus, the agent receives the human intentions through how
its body posture is changed within the interaction, which
characterizes a form of primary intersubjective experience
[16], as studied inembodied social cognition(ESC) theory.
III. COGNITIVE COMPLIANCE
As a variational framework, PV-RNN includes a gener-
ative and an inference model (see Fig. 1). The generative
model involves the prior distributions. It does hierarchical
predictions on the output layer following a top-down Ô¨Çow.
That is, the prediction is generated from the information
represented in the latent state. The inference model involves
posterior distributions, so the information Ô¨Çow goes in the
bottom-up sense. Predictions are done starting from the evi-
dence (i.e., a given observation), and the latent representation
is modiÔ¨Åed in order to approximate the evidence.
Let1 the generative model P be deÔ¨Åned from the pa-
rameters , distributed among the components: generated
predictionx, stochasticzand the deterministicdlatent states.
For a predictionx1‚à∂T = (x1,x2,..., xT), and considering the
parameters x, z, andd, P factorizes such that:
P
 x1‚à∂T,z1‚à∂T,d1‚à∂T√∞z0,d0
 =
T√á
t=1
Px
 xt√∞dt
Pz
 zt√∞dt‚àí1
Pd
 dt√∞dt‚àí1,zt
 (1)
Let the deterministic states be deÔ¨Åned according to a
MTRNN structure. For thekth context layer at timet, with
timescale k, the internal dynamics are represented such that
1Notation: layer‚Äôs latent states are denoted bold low-case, biases are
denoted b, weight connexion are denoted W with subscripts indicating
the origin and destination of the connection (e.g., Wzd are the weights
connecting z to d units). Superscripts k indicate the level in the MTRNN
hierarchy. Finally, the superscripts p and q are used to distinguish between
variables that belong to the prior and posterior distributions, respectively.
A two-layer PV-RNN architecture
Error Regression (inference) Generation (prediction)
High
Low
Output
Evidence
q,q aŒº,aœÉ  q,q aŒº,aœÉ  p,p 
z z z
‚ãØ d d d ‚ãØ
q,q aŒº,aœÉ  q,q aŒº,aœÉ  p,p 
z z z
‚ãØ d d d ‚ãØ
x x x
e e
y y
Time ‚ãØ t‚àí1 t t+1 ‚ãØ
Fig. 1: The notation has been simpliÔ¨Åed for clarity, so thek
and t indexes have been dropped. The time constantk (see
Eq. (2)) is greater in the High layer than in the Low layer.
Since the High layer is the top on the hierarchy, the term
Wkk+1
dd dk+1
t‚àí1 is removed, analogously, the termWkk‚àí1
dd dk‚àí1
t‚àí1
is removed for the Low layer. The top-down process Ô¨Çow is
represented by gray arrows. Red arrows illustrate the bottom-
upprocessÔ¨Çow,whereerrorisbackpropagatedthroughtime.
The on-line inference process computed in a sliding time
window is named Error Regression [10].
uk
t =Wkk
dddk
t‚àí1 +Wkk‚àí1
dd dk‚àí1
t‚àí1 +Wkk+1
dd dk+1
t‚àí1 +Wkk
ddzk
t
hk
t =

1‚àí 1
k

hk
t‚àí1 + 1
k
uk
t
dk
t =tanh  hk
t
 .
(2)
The prior distributionPz
 zt√∞dt‚àí1
 is modeled as a Gaus-
sian with diagonal covariance matrix, such that
Pz
 zt√∞dt‚àí1
 =Óà∫  zt;p
t,p
t
, (3)
where p
t and p
t are, respectively, the mean and standard
deviation ofzt =p
t +p
t ‚àó, withsampled fromÓà∫(0,1).
The variables [p
t,log (p
t)] =fz(dt‚àí1) are obtained with
fz(.) the one layer feed-forward neural network, such that
p,k
t =tanh

Wkk
Œºddk
t‚àí1 +bp,k
Œº

log

p,k
t

=Wkk
œÉddk
t‚àí1 +bp,k
œÉ
. (4)
Let the inference modelQ (the approximate posterior)
be deÔ¨Åned from the parameters, such that
Q(zt√∞dt‚àí1,et‚à∂T)= Óà∫  zt;q
t,q
t
, (5)
where q
t and q
t are, respectively, the mean and standard
deviation ofzt =q
t +q
t ‚àó, withsampled fromÓà∫(0,1).
The variables[q
t,log(q
t)]= fz(dt‚àí1,aÃÑ x)are obtained with
fz(.) the one layer feed-forward neural network, such that
q,k
t =tanh

Wkk
Œºddk
t‚àí1 +aÃÑ x,k
Œº,t +bq,k
Œº

log

q,k
t

=Wkk
œÉddk
t‚àí1 +aÃÑ x,k
œÉ,t +bq,k
œÉ
. (6)
The parametersaÃÑ x
1‚à∂T are introduced to provide the network
with information about the prediction error in relation to
a given pattern ÃÑx. Thus, aÃÑ x
1‚à∂T is changed back propagating
through time the prediction erroret‚à∂T, so information about
the future steps ofÃÑxt‚à∂T, and existing dependencies with the
current time stept, are captured. These terms are deÔ¨Åned by
aÃÑ x,k
Œº,t =aÃÑ x,k
Œº,t + )L
)aÃÑ x,k
Œº,t
aÃÑ x,k
œÉ,t =aÃÑ x,k
œÉ,t + )L
)aÃÑ x,k
œÉ,t
. (7)
with  denoting the learning rate.
Let the Variational Evidence Lower Bound (ELBO)
L(,) be deÔ¨Åned by
L(,)=
T√â
t=1

EqœÄ
log xt√∞ÃÉdt,zt
‚àí
wKL

QœÄ
 zt√∞ÃÉdt‚àí1,et‚à∂T
‚ÄñPz
 zt√∞ÃÉdt‚àí1

.
(8)
Since dt is deterministic givendt‚àí1 and zt, ÃÉdt denotes the
center of a Dirac distribution. The Ô¨Årst term at the right of the
equation is a reconstruction component, it corresponds to the
expected log-likelihood under the posterior distributionQœÄ.
The second therm is a regulation component, it corresponds
to the Kullback-Leibler (KL) divergence between the prior
and the posterior distributions of the latent variables. The
meta-parameterwadjusts the optimization weight in learning
the posterior and the prior distributions. After dropping the
random variable notation to improve readability, the KL
component can be expressed as
KL

QœÄ‚ÄñPz

=log
0
p
q
1
+(p ‚àíq)2 +(q)2
2(p)2 ‚àí1
2 (9)
Finally, the variablexi,t, related to the ith dimension of
the output space, is deÔ¨Åned such that
xi,t =softmax

Wdxid0
t +bxi

. (10)
Unlike [15], we do not include inxi,t connections from the
stochastic latent distributions at the Low level.
IV. MOTOR COMPLIANCE
In conformity with the principles of ethics in robotics
experiments, inspired by the famous Asimov‚Äôs three laws of
robotics [17], motor compliance is studied within the context
of social ethical conventions. Thus, the human and the robot
actions must preserve each other‚Äôs integrity and safety.
Computational theories of human control have pointed
out the plausibility of continuous and intermittent control
systems in the brain, with the latter being possibly driven by
events [18]. Intermittent control is related to the prefrontal
cortex, the premotor cortex, and the basal ganglia areas, it
has been studied in the context of postural regulation [19].
We model motor control as a hybrid intermittent process
driven by intentionality and social interaction. The rationale
behind this is the following. When contact between the
human and the robot is established, their intended motion
may complement or be to some extent incongruent. Thus,
in both the human and the robot cases, the body posture
must be adapted to the other‚Äôs inÔ¨Çuence to preserve a safe
interaction. Expressed in other terms, once external forces
acting on the body induce signiÔ¨Åcant joint torques, the joint
should exhibit viscoelasticity, so it becomes compliant to
the external force. Once the external constraints cease to be
relevant, active control should be resumed from a gradual
transition to the desired state. Hence, in this hybrid view,
each robot articulation is controllable instantaneously by one
of two possible schemes: a compliant and an active scheme.
Let the switching between the compliant and the active
modes of jointj at timet rely on a continuous observation
process of the torque ÃÇ j,t, and the prediction on the body
dynamics act
j,t . The estimation of the external torque induced
in the interaction is such that
ÃÇ ext
j,t = ÃÇ j,t ‚àíact
j,t . (11)
Thus, switching to the compliant mode occurs once√∞ÃÇ ext
j,t √∞ >
th
j exceeds a thresholdth
j .
Let the joint position j,t be regulated by the active
control scheme in charge of tracking a reference position
net
j,t , intended by the agent (i.e. it is generated by the
neural network). The target position act
j,t+1, in relation to
the observation ÃÇj,t, is obtained from a discrete proportional
control law, such that
act
j,t+1 =a
j,t

net
j,t ‚àí ÃÇj,t

. (12)
Since j,t may diÔ¨Äer considerably from net
j,t under the
compliant scheme, in order to avoid abrupt motions, the
proportional gaina
j,t is set as the cosine transition modulated
by √≥√≥√≥net
j,t ‚àí ÃÇj,t
√≥√≥√≥, from a minimum to a maximum gain.
Let the joint positionj,t be regulated by the compliant
control scheme in charge of following the torque induced
by the human. A discrete time proportional integral (PI)
feedback control law with gainsp
j and i
j is adopted, so
ext
j,t+1 = ÃÇj,t +p
j ÃÇ ext
j,t +f
H
i
j
√â
t
ÃÇ ext
j,t
I
. (13)
In both the active and the compliant schemes the target
correction is saturated to preserve safety in behavior. Thus,
the functionf(.)acts as a reset windup to the integral term.
As explained before, due to the fact that the control is done
in the joint space, an interesting situation emerges where the
joints may be set to diÔ¨Äerent control schemes. Hence, the
human provides feedback to the robot through the compliant
joints, while receiving feedback about the robot‚Äôs intention
from the active joints. However, it is also interesting to
include soft impedance in the compliant joints in order to
enhance the interaction experience. Thus, the target position
in the compliant scheme is obtained such that
com
j,t+1 =ext
j,t+1 +n
js

net
j,t ‚àí ÃÇj,t

, (14)
with n
j a gain parameter ands(.) a saturation function.
V. METHODOLOGY
On the robot side, the variables studied wereintentionality
(desired behavior in relation to the human‚Äôs actions) and
compliance in the physical (or motor, M) and the represen-
tational (or cognitive, C) dimensions. As shown in Table I,
several proÔ¨Åles were deÔ¨Åned to study compliance. Regarding
the motor dimension, the exclusively compliant modeMteach
was employed for kinesthetic demonstration of the behavior
primitives, and the interaction modeMinter was set based on
the hybrid controller (including the active and the compliant
schemes). Concerning the cognitive dimension, the proÔ¨Åles
Crigid, Cmod, and Cflex were deÔ¨Åned corresponding, respec-
tively, to a rigid, a moderate, and a Ô¨Çexible agent.
TABLE I: The cognitive and motor proÔ¨Åles.
ProÔ¨Åle Description
Mteach Kinesthetic teaching (with the compliance scheme only)
Minter Interaction (with the active and compliant schemes)
Crigid Strong intentionality (w=0.01)
Cmod Moderate intentionality (w=0.001)
Cflex Low intentionality (w=0.0001)
The implementation of hybrid motor control in Torobo is
illustrated in Fig. 2. A dataset was constituted with three
behavior primitives (see Fig. 3), sampled at 4 Hz, during 90
time steps. The cognitive proÔ¨Åles in Table I were modeled in
the PV-RNN architecture (see Fig. 1). It included a Low layer
(40 d units, 4 z units, and=2) and a High layer (10 d units,
1 z unit, and = 10). All learnable variables were updated
during the training phase, whereas in interaction mode only
the terms a were updated (see Eqs. (6)(7)). Conforming to
Table I, speciÔ¨Åc values for w (Eq. (8)) were selected for
training (50K epochs). For interactionw=1.0e‚àí5 was set
for all the proÔ¨Åles, since it produced the best results.
On the human side, the variables under study areintention-
ality (desired behavior in relation to the robot‚Äôs actions) and
engagement(physical eÔ¨Äorts invested in the task). Finally, on
the mutual interaction side, the variablebehavior emergence
(how similar the robot‚Äôs posture is to the known primitives)
is studied through a regression observer. Since the motion
primitives were reasonably diÔ¨Äerent from one another, a
feed-forward model was designed (12Input, 150Hidden1, 15
Hidden2, 3Output, with tanh activation for the hidden layers
and sigmoid activation for the output layer), and trained by
supervised learning with the joint instantaneous positions. A
success rate of 100% was achieved in the test set.
Hybrid motor control in Torobo
Network Hybrid Planner Driver Hardware
Inverse dynamic model
Start net
j,t
ÃÇj,t ‚àó
j,t+1 ‚Ä†
j,t+1
ÃÇ j,t
act
j,t
Fig. 2: The Network block includes the PV-RNN model,
it computes the desired positionnet
j,t based on the current
estimation ÃÇj,t. From measuredÃÇ j,t and estimated torqueact
j,t
(by inverse dynamics), the Hybrid controller computes the
next target‚àó
j,t+1. The Planner calculates a trajectory for the
target in open-loop via intermediate positions‚Ä†
j,t+1. Lately,
the robot Driver manages the Hardware plant.
The experimental and simulation environments
A B C
Fig. 3: The primitives visualized in the Gazebo simulator
were captured by kinesthetic demonstration with Torobo.
Experimental protocol: Six scenarios were portrayed
conforming the pairs AB, AC, BA, BC, CA, CB; with the
left term representing the robot‚Äôs intended behavior, and the
right term corresponding to the human intended behavior
(the subject was instructed to induce a given primitive in the
robot behavior). For example, AB means the robot wants to
do A and the human wants to do B. A total of 54 trials were
registered for the experimental subject (6 pairs x 3 cognitive
models x 3 times), during 300 time steps each.
Software platform: The open-source implementation
of the models is provided by the neural robotics library
[20]. From previous experiences [21], C++ was chosen as
the base programming language. The programs run in the
Robot Operative System (ROS) Kinetic Kane over Ubuntu
16.04 LTS. The Network block (Fig. 2) ran at 4 Hz in the
host computer (Alienware Aurora R7, 12 Intel¬Æ Core‚Ñ¢ i7-
8700K CPU at 3.70GHz, and 31.1 GiB RAM memory).
In interaction mode, BPTT was computed within a sliding
window (20 time steps) during 28 epochs. The models
learned 12 degrees of freedom (6 for each arm), constant
desired references were given to the torso and the head joints.
VI. RESULTS
The training results are shown in Fig. 4. As noticed,
although the reconstruction component of the ELBO (see Eq.
(8)) approached to zero in all cases, which indicates good
predictions from the posterior distribution; the smaller the
meta-parameter w was set (right plot), the more dissimilar
the posterior and the prior distributions were, which implies
more stochasticity in the generative process.
0 1 2 3 4 5
n √ó104
0.0
0.2
0.4
0.6
0.8
Reconstruction
√ó103
Crigid
Cmod
CÔ¨Çex
0 1 2 3 4 5
n √ó104
0.0
0.5
1.0
1.5
Regulation
√ó104
Crigid
Cmod
CÔ¨Çex
Reconstruction Regulation
Fig. 4: Training during 50k epochs. The reconstruction and
the regulation terms of the ELBO (see Eq. (8)).
A. Simulations
Two preliminary studies were conducted. The Ô¨Årst one
investigated the accuracy of the generative process. For this,
the primitives were generated during 90 time steps (the same
length of the captured sequences in the dataset) by each
cognitive model (see Table I). The comparison is done by
calculating at each time step the mean squared error (MSE)
between the referenceÃÑxand the generatedxsequences. The
models Crigid and Cmod performed similarly well (see Fig.
5), whereasCflex had a more stochastic generative process.
0 20 40 60 80
Time step
0
100
200MSE in deg
A
B
C
Crigid
Cmod
CÔ¨Çex
Generative process accuracy
Fig. 5: Comparison between the references constituting the
training dataset and the learned generation.
The second study analyzed cognitive compliance through
thelatentstate d.Figure6presentsacomparisonontwoprin-
cipal component analysis (PCA) for the generation process
of the primitives A, B, and C (left column), and the inference
process (right column). Errors were BPTT by taking the
diÔ¨Äerence between the model‚Äôs prediction and recorded joint
positions of A, B, and C. What is being analyzed is the
possibility of transition from the generation of one primitive
to another, given the evidence. That is, to what extent
stochasticity from the hidden random distributions, received
through the parameters a (see Eqs. (6)(7)), is allowed to
aÔ¨Äect the contextual representation during on-line inference.
All transitions could be obtained, except from BC with
Crigid. As noticed, Cflex representations were simpler, and
converged faster to conform the evidence.
‚àí2 0 2 4
‚àí2
‚àí1
0
1
2
3
4
A
B
C
‚àí2 0 2 4
‚àí2
‚àí1
0
1
2
3
4
BA
BB
BC
‚àí2 0 2 4
‚àí2
‚àí1
0
1
2
3
4
A
B
C
‚àí2 0 2 4
‚àí2
‚àí1
0
1
2
3
4
BA
BB
BC
‚àí2 0 2 4
‚àí2
‚àí1
0
1
2
3
4
A
B
C
‚àí2 0 2 4
‚àí2
‚àí1
0
1
2
3
4
BA
BB
BC
Inference processGeneration process
Crigid
Cmod
Cflex
Crigid
Cmod
Cflex
Initial state
Final states
Fig. 6: Two-PCA High layer‚Äôs statesd. Agents were set to
generate B (intention), but received A, B, and C as evidence.
B. Experiments
The performance of the intermittent controller for congru-
ent and incongruent interaction is shown in Fig. 7. As no-
ticed, smooth trajectories resulted from tracking the network
signal while complying to the external torque induced by the
human. Table II compares emergent behavior to the robot‚Äôs
intended behavior for the three cognitive agents, based on
the regression observer‚Äôs evaluation. Table III shows the
mean and standard deviation of the estimated external torque
during the experiment. In Fig. 8, emergent behavior for the
pair BC is compared to the intended behavior of the robot2.
2The experiment video is available at: https://youtu.be/f4TXmB7HV-s
0 10000 20000 30000 40000 50000 60000 70000
‚àí2
‚àí1
0
1
e
Œònet
ÀÜŒò
0 10000 20000 30000 40000 50000 60000 70000
Time in ms
‚àí4
‚àí2
0
2
4
e
Œònet
ÀÜŒò
Motor control performance
Congruent interaction
Incongruent interaction
ÃÇ ext
net
ÃÇ
ÃÇ ext
net
ÃÇ
Fig. 7: Torobo‚Äôs right elbow follows a sinusoidal limit cycle
reference. Torque in Nm, angle in rad.
0
5
0
5
0
5
0
5
0
5
0 50 100 150 200 250 300
Time step
0
5
Emergent behavior vs. intention (3rd BC trial)
Primitive B Primitive A
Primitive B Primitive C
Primitive B Primitive C
Crigid
Crigid
Cmod
Cmod
Cflex
Cflex
Fig. 8: Two-PCA, emergent behavior: green, intention: red.
C. Discussion
The results supported the plausibility to model distinct
cognitive styles through the meta parameter w. Thus, by
learning to strongly approximate the prior and posterior
distributions (see Fig 4), the rigid agent was able to generate
accurate behavior (see Fig 5), but it was less sensitive to
evidence. Indeed, it obtained greater diÔ¨Äerences between the
intended and observed behaviors (see Table II). Contrarily,
the Ô¨Çexible agent was trained investing less eÔ¨Äorts in learning
to approximate these distributions, which resulted in stochas-
tic or hesitating behavior. The moderate agent presented a
good balance between accuracy and cognitive Ô¨Çexibility.
When analyzing the human engagement in the interaction,
qualitative diÔ¨Äerences can be observed among the agents (see
Table III, the lowest mean values per trial are highlighted in
bold). Since the subject was instructed to induce as long
as possible a certain behavior, with the rigid agent eÔ¨Äorts
were probably more invested in modifying the robot posture
to encourage the generation of the desired primitive, given
the agent‚Äôs reluctance to change. Hence, the interactions were
arduous and relied mostly on the compliant component of the
TABLE II: Probability of the robot intendingI and behaving
B, according to the desired motions induced by the human.
Crigid Cmod Cflex
Data p(I) p(B) p(I) p(B) p(I) p(B)
Simulation 0.466 0.467 0.761 0.759 0.843 0.841
Exp. trial 1 0.122 0.365 0.562 0.588 0.245 0.393
Exp. trial 2 0.274 0.476 0.705 0.686 0.394 0.451
Exp. trial 3 0.302 0.498 0.590 0.619 0.405 0.501
TABLE III: External torque‚àë
j √∞ÃÇ ext
j,t √∞ in Nm for trials.
Crigid Cmod Cflex
Case T1 T2 T3 T1 T2 T3 T1 T2 T3
Mean
AB 2.0 1.4 1.9 1.9 1.8 1.8 2.0 2.0 1.9
AC 2.4 2.0 1.1 2.2 1.8 1.7 2.4 2.0 2.2
BA 1.9 1.6 1.4 1.6 1.4 1.6 1.7 1.4 1.4
BC 2.2 2.0 1.4 2.1 1.9 2.0 2.3 1.8 2.2
CA 1.9 2.2 1.9 2.0 1.5 2.1 1.8 1.9 2.2
CB 1.9 2.1 1.8 1.9 1.9 1.8 2.0 2.2 2.1
Standard Deviation
AB 0.9 0.8 0.9 1.0 1.0 0.9 1.1 1.0 1.0
AC 1.2 0.9 0.7 1.0 0.9 0.8 1.1 1.0 1.1
BA 1.0 0.9 0.7 0.9 0.9 0.8 0.9 0.8 0.8
BC 1.0 0.9 0.8 1.0 0.9 1.0 1.2 0.9 1.0
CA 0.9 0.9 0.8 1.0 1.0 1.3 0.9 0.9 1.0
CB 0.8 1.0 0.8 0.9 1.0 0.8 1.0 1.1 0.9
hybrid motor control scheme. Considering the Ô¨Çexible agent,
it likely adopted the desired posture shape, but eÔ¨Äorts were
required to keep consistent interaction. It was challenging
to induce gradual changes in behavior, due to erraticness
and loss of bilateral symmetry, which would explain the
disparity of simulated and experimental results. In relation
to the moderate agent, smoother interactions were obtained
and less eÔ¨Äorts appeared to be invested, since the agent was
able to both change the posture and generate the behavior
consistently.Finally,inagreementwith [7],learningprobably
occurred on the human side, since bothp(I)and p(B)were
generally larger from the Ô¨Årst to the third trials.
VII. CONCLUSIONS AND FUTURE WORK
This work focused on the study of physical interaction
between a human and a robot, and considered both co-
herent and incoherent scenarios. An important distinction
was established between motor and cognitive compliance.
A variational model, inspired by the principles of predictive
coding and active inference, was proposed to model cognitive
compliance as the capacity to be driven by sensory evidence.
An intermittent control concept was proposed to study motor
deliberation while adapting to the human interaction, based
on torque feed-back. The experiments results pointed out
a trade-oÔ¨Ä between cognitive compliance and reÔ¨Ånement
in autonomous motion. We believe that this trade-oÔ¨Ä can
be explored in developmental robotics to investigate on-line
learning [7]. From the perspective of human-robot interaction
research, our results would also open interesting possibilities
for the study of social cognition in human science, including
topics inmotivation [22] andintersubjectivity [20].
REFERENCES
[1] S. Pellegrinelli, H. Admoni, S. Javdani, and S. Srinivasa, ‚ÄúHuman-
robot shared workspace collaboration via hindsight optimization,‚Äù in
2016 IEEE/RSJ International Conference on Intelligent Robots and
Systems (IROS). IEEE, 2016, pp. 831‚Äì838.
[2] C. T. Landi, F. Ferraguti, C. Fantuzzi, and C. Secchi, ‚ÄúA passivity-
based strategy for coaching in human-robot interaction,‚Äù in2018 IEEE
International Conference on Robotics and Automation (ICRA). IEEE,
2018, pp. 1‚Äì6.
[3] M. Kollmitz, D. B√ºscher, T. Schubert, and W. Burgard, ‚ÄúWhole-
body sensory concept for compliant mobile robots,‚Äù in2018 IEEE
International Conference on Robotics and Automation (ICRA). IEEE,
2018, pp. 1‚Äì5.
[4] C. T. Ishi, T. Minato, and H. Ishiguro, ‚ÄúAnalysis and generation
of laughter motions, and evaluation in an android robot,‚Äù APSIPA
Transactions on Signal and Information Processing, vol. 8, 2019.
[5] Y. Hu and G. HoÔ¨Äman, ‚ÄúUsing skin texture change to design emotion
expression in social robots,‚Äù in2019 14th ACM/IEEE International
Conference on Human-Robot Interaction (HRI). IEEE, 2019, pp.
2‚Äì10.
[6] L. S. Vygotsky,Mind in society: The development of higher psycho-
logical processes. Harvard university press, 1980.
[7] S. Ikemoto, H. B. Amor, T. Minato, B. Jung, and H. Ishiguro,
‚ÄúPhysical human-robot interaction: Mutual learning and adaptation,‚Äù
IEEE Robotics Automation Magazine, vol. 19, no. 4, pp. 24‚Äì35, Dec
2012.
[8] K. Friston, ‚ÄúThe free-energy principle: a uniÔ¨Åed brain theory?‚ÄùNature
reviews neuroscience, vol. 11, no. 2, p. 127, 2010.
[9] K. Friston, J. Mattout, and J. Kilner, ‚ÄúAction understanding and active
inference,‚Äù Biological cybernetics, vol. 104, no. 1-2, pp. 137‚Äì160,
2011.
[10] J. Tani, ‚ÄúLearning to generate articulated behavior through the bottom-
up and the top-down interaction processes,‚ÄùNeural Networks, vol. 16,
no. 1, pp. 11‚Äì23, 2003.
[11] J. Hwang, J. Kim, A. Ahmadi, M. Choi, and J. Tani, ‚ÄúDealing with
large-scale spatio-temporal patterns in imitative interaction between a
robot and a human by using the predictive coding framework,‚ÄùIEEE
Transactions on Systems, Man, and Cybernetics: Systems, 2018.
[12] S. Murata, J. Namikawa, H. Arie, S. Sugano, and J. Tani, ‚ÄúLearning
to reproduce Ô¨Çuctuating time series by inferring their time-dependent
stochastic properties: Application in robot learning via tutoring,‚ÄùIEEE
Transactions on Autonomous Mental Development, vol. 5, no. 4, pp.
298‚Äì310, 2013.
[13] D. P. Kingma and M. Welling, ‚ÄúAuto-encoding variational bayes,‚Äù
arXiv preprint arXiv:1312.6114, 2013.
[14] J. B√ºtepage, H. Kjellstr√∂m, and D. Kragic, ‚ÄúAnticipating many futures:
Online human motion prediction and generation for human-robot
interaction,‚Äù in2018 IEEE International Conference on Robotics and
Automation (ICRA). IEEE, 2018, pp. 1‚Äì9.
[15] A. Ahmadi and J. Tani, ‚ÄúA novel predictive-coding-inspired variational
rnn model for online prediction and recognition,‚ÄùNeural computation,
vol. 31, no. 11, pp. 2025‚Äì2074, 2019.
[16] S. Spaulding, ‚ÄúIntroduction to debates on embodied social cognition,‚Äù
Phenomenology and the Cognitive Sciences, vol. 11, no. 4, pp. 431‚Äì
448, 2012.
[17] I. Asimov,I, robot. Gnome Press, 1950, vol. 1.
[18] P. Gawthrop, I. Loram, M. Lakie, and H. Gollee, ‚ÄúIntermittent control:
a computational theory of human control,‚ÄùBiological cybernetics, vol.
104, no. 1-2, pp. 31‚Äì51, 2011.
[19] H. Tanabe, K. Fujii, Y. Suzuki, and M. Kouzaki, ‚ÄúEÔ¨Äect of intermittent
feedback control on robustness of human-like postural control system,‚Äù
ScientiÔ¨Åc reports, vol. 6, p. 22446, 2016.
[20] H. F. Chame, A. Ahmadi, and J. Tani, ‚ÄúTowards hybrid primary
intersubjectivity: a neural robotics library for human science,‚ÄùarXiv
preprint arXiv:2006.15948, 2020.
[21] H. F. Chame and C. Chevallereau, ‚ÄúGrounding humanoid visually
guided walking: From action-independent to action-oriented knowl-
edge,‚ÄùInformation Sciences, vol. 352, pp. 79‚Äì97, 2016.
[22] H. F. Chame, F. P. Mota, and S. S. da Costa Botelho, ‚ÄúA dynamic
computational model of motivation based on self-determination theory
and CANN,‚ÄùInformation Sciences, vol. 476, pp. 319‚Äì336, 2019.