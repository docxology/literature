1 
 
Modeling the sense of presence of remote participants in hybrid 
communication and its application to the design of avatar robot behavior  
 
Takuma Miyaguchi1 and Hideyoshi Yanagisawa1* 
1 Graduate School of Engineering, The University of Tokyo, Tokyo, Japan 
 
* Corresponding author 
E-mail: hide@mech.t.u-tokyo.ac.jp (HY) 
Abstract 
 Hybrid face-to-face and online communication have the problem that only the 
local participants are stimulated and the remote participants are excluded or the local 
participants forget about the remote participants. These problems were considered as the 
lack of sense of the presence of remote participants. As the first quantitative approach to 
the presence, to the best of our knowledge, we formulated the sense of the presence of a 
remote participant in hybrid communication using a Bayesian framework. We also applied 
the knowledge gained from the simulation with the Bayesian model to the avatar robotâ€™s 
intervention behavior and encouraged the local participants to speak by intervening in the 
remote participantâ€™s behavior using an avatar robot. We hypothesized that beliefs about the 
remote participantâ€™s mental states would be a factor in the remote participantâ€™s presence. 
We formulated presence as model evidence for otherâ€™s mental state. We then modeled the 
influence of the avatar robotâ€™s behavior on the local participantsâ€™ statements using an active 
inference framework that included the presence of a remote participant as a latent variable. 
Through simulations with the model, it was possible to predict that the gaze behavior of 
the avatar robot would encourage local participants to speak. Based on the simulation 
results, we designed the gaze behavior of an avatar robot. Finally, we examined the 
effectiveness of the designed gaze behavior of the avatar robot. The gaze behavior 
expressed more of the remote participantâ€™s attention and interest in local participants, but 
local participants expressed fewer opinions in the meeting tasks. The results suggest that 
gaze behavior increased the presence of the remote participant and discouraged the local 
participant from speaking in the context of the experimental task. We believe that presence 
has a sufficiently large influence on whether participants want to express an opinion. It is 
worth investigating the influence of presence and its control methods using Bayesian 
2 
 
models. 
Introduction 
In recent years, many conferences and lectures have been conducted in a hybrid 
format combining face-to-face and online communication. Problems with hybrid 
communication have been reported [1]. In particular, the problem is that only local 
participants are stimulated and the remote participants are excluded and the local 
participants forget the remote participants. Several studies have attributed the problems 
encountered in hybrid communication to a lack of remote participants and have attempted 
to increase their presence. For example, Yankelovich et al. developed a device that 
combines a remotely controllable display and a high-quality speaker to increase the social 
presence of remote participants [1]. Van Dijk et al. proposed a 3D interface that can 
naturally reflect gaze direction in images by arranging the placement of cameras and 
images and investigating the effects on the perception of social presence [2]. However, 
these studies are limited to qualitative discussions, and to our knowledge, a quantitative 
approach to presence using mathematical models has not yet been proposed. 
The mathematical model allows us to comprehensively predict the effects of 
changes in latent variables on the presence and the effects of presence. These predictions 
may exceed human intuition. In addition, we can research along the cycle: first, we predict 
the effect of changes in the set of latent variables on presence through simulations and then 
discover new latent variables through experiments and update the model. Thus, we believe 
that proposing a mathematical model for presence will enable a more effective approach 
to problems related to presence. 
Ogasawara et al. formulated a sense of existence for other avatars in VR using a 
Bayesian perceptual model [3]. They modeled the sense of existence as the model evidence 
for the spatiotemporal localization of the avatar. In short, they physically modeled the 
senses of the avatar. However, we have formulated the presence of remote participants, 
which causes problems in hybrid communication. By exploring the causes of these 
problems, we set up a hypothesis about the factors of presence. 
In addition, using a mathematical model of presence, we propose an avatar robot 
behavior that promotes the statements of local participants. In groups with different status 
levels, low-status members tend to be reluctant to express their opinions about 
interpersonal risks. We used an avatar robot to intervene in the behavior of high-status 
3 
 
members in an attempt to solve this problem.  
This study has two objectives. First, the presence of a remote participant in hybrid 
communication is formulated. Second, we apply findings from the simulation with a 
Bayesian model to the intervening behavior of the avatar robot and promote the local 
participantâ€™s statement by intervening with the avatar robot in the remote participantâ€™s 
behavior. 
In the mathematical modeling of the sense of the presence of a remote person, we 
first explain the conversational experiment with an avatar robot and the hypothesis for the 
presence factor. We then introduce active inference and explain the mathematical modeling 
of the remote participantsâ€™ presence. 
In designing the gaze behavior of the avatar robot that encourages the expression 
of opinions by local participants in the discussion, we explain the mathematical modeling 
and simulations for designing the avatar robotâ€™s behavior that promotes local participantsâ€™ 
statements. The focus was on statements made in groups with different social status levels. 
The model considers the presence of a remote participant as a latent variable. In addition, 
an avatar robotâ€™s gaze behavior based on the simulation findings is proposed. 
In Experiment: Effect of the intervention in the gaze behavior of the avatar robot 
on the statements of local participants, we describe an experiment to investigate the 
effectiveness of the designed gaze behavior. We recreated a situation in which low-status 
members were reluctant to express their opinions with groups with different social status 
levels. 
Methods 
Significance of the use of the avatar robot 
 In this study, an avatar robot as a device for remote participation is used in hybrid 
communication. The avatar robot is a prototype developed by Sony Group Corporation, 
with whom we are conducting joint research. Fig 1 shows an overview of an avatar robot. 
The avatar robot plays the voice of the remote party through the speaker. The avatar robot 
also mirrors the remote participantâ€™s gaze, blink, and head rotation. 
 
4 
 
 
Fig 1. Avatar robot used in this study.  
 
 These two features are important for the use of avatar robots. First, the avatar 
robot accurately reproduced the gaze direction of the remote participant. In hybrid systems 
that use a plane display, it is difficult to determine the gaze direction of a remote participant. 
It has been reported that the transmission of gaze direction is more accurate when a robot's 
three-dimensional head rotates than when a remote participant's face appears on a display 
[4]. The avatar robot rotates its head along with the head rotation of the remote participant. 
We believe that the avatar robot can accurately reproduce the gaze direction.  
 Second, the avatar robot can intervene in the transmission of a remote participantâ€™s 
nonverbal behavior (i.e., head rotation, gazing, and blinking). The avatar robot not only 
reflects the behavior of the remote participant but also edits, transforms, or automates it. 
Non-verbal behaviors express emotions [5] and cognitive states [6]. We have attempted to 
control presence by intervening in non-verbal behaviors and controlling the transmission 
of emotions and cognitive states. 
Mathematical modeling of the sense of the presence of a remote 
person 
Conversational experiment with an avatar robot to formulate hypotheses 
about the definition and factors of presence. 
 We conducted a conversational experiment with an avatar robot as a first step in 
the mathematical modeling of presence. The purpose was to formulate a hypothesis about 
the definition and factors of the presence of remote participants. 
 One remote participant and three local participants took part in a conversation task. 
Fig 2 shows the arrangement of participants in the conversational experiment. Two 

5 
 
conversation formats (presentation and discussion) were set as tasks. The reason for this is 
that it is necessary to observe or experience different conversation scenes (i.e., where one 
participant talks to others, where there are free alternations, and where one participant 
addresses another). 
 
 
Fig 2. Arrangement of participants in the conversation experiment. 
 
 The presence being investigated is attributed to problems in hybrid 
communication, such as the problem that only local participants are stimulated, that remote 
participants are excluded, or that the local participants forget the remote participants. 
Therefore, we discuss the reasons why only local participants become excited, why remote 
participants are excluded, or why they forget about remote participants. The following 
reasons were cited as causes: 
ï¬ It is difficult for remote participants to take turns during active alternation because 
only remote participants experience a delay. 

6 
 
ï¬ It is difficult for local participants to understand the mental states of remote 
participants, such as their thoughts and cognitive states. 
ï¬ It is difficult for local participants to allow remote participants to take turns because 
they cannot predict the remote participantsâ€™ responses.   
Of these three points, we focused on the bottom two, which pertain to the 
recognition of remote participants. The avatar robot can display a remote participantâ€™s gaze, 
blink, and head rotation, but it cannot display other behaviors, such as facial expressions 
and hand gestures. A hybrid system that shows a remote participant on a display can 
represent the remote participantâ€™s facial expressions and hand gestures, but it is difficult to 
know where the remote participant is looking. In any hybrid system, the cues to the mental 
states of the remote participants were less than in face-to-face communication. Therefore, 
it is difficult to determine the mental state of a remote participant. In addition, it is difficult 
to predict remote participantsâ€™ responses when they are unaware of their mental states. The 
risk of communication errors, such as speaking to a remote participant who is not ready to 
respond and the difficulty of speaking in accordance with the remote participant's thoughts, 
seems to be the cause of the difficulties in talking to remote participants. 
We hypothesized that the difficulty in detecting the mental state of a remote 
participant was related to problems in hybrid communication and the presence of remote 
participants. We also hypothesized that beliefs about remote participantsâ€™ mental states 
would be a factor in remote participantsâ€™ presence. In this study, we used the active 
inference framework [7] to mathematically capture beliefs about a remote participantâ€™s 
mental state. 
 
Active inference 
 In this section, the active inference method is described, which is used to model 
the sense of presence. A detailed explanation can be found in [7]. 
 Active inference is a mathematical framework based on the idea that perception 
and learning can be understood as minimizing variational free energy (VFE) and action 
selection and planning. Decision-making can be understood as minimizing the expected 
free energy (EFE) [7]. To explain active inference, Bayesian inference is discussed first. 
 Bayesian inference uses Bayesâ€™ theorem to infer the hidden states of the external 
world from the observations generated by these hidden states. The term â€œhiddenâ€ here 
means that the state itself cannot be observed directly but can only be inferred from 
7 
 
observation (sensory stimuli). Eq. (1) shows the Bayesâ€™ theorem. 
ğ‘(ğ‘ |ğ‘œ)=ğ‘(ğ‘œ|ğ‘ )ğ‘(ğ‘ )
ğ‘(ğ‘œ) (1) 
 The hidden state is denoted by s, and the observation is denoted by o. The term 
ğ‘(ğ‘ |ğ‘œ) is the posterior encoding belief regarding the state obtained by inference. The term 
ğ‘(ğ‘œ|ğ‘ )  is the likelihood of encoding knowledge about the mapping between the 
observation and state. The term ğ‘(ğ‘ ) is the prior encoding prediction of the state before 
the observation. The term ğ‘(ğ‘œ) is the model evidence encoding the plausibility of the 
generative model. Bayesâ€™ theorem states that the likelihood and prior are combined to 
derive the posterior. 
 Bayesâ€™ theorem, however, cannot be computed directly for all but the simplest 
distributions. This is because calculating the model evidence requires summing the 
probabilities of the observations under all possible states of the generative model. Eq. (2) 
shows the formula for model evidence: 
ğ‘(ğ‘œ)=à·ğ‘(ğ‘œ,ğ‘ )
à¯¦
=à·ğ‘(ğ‘œ|ğ‘ )ğ‘(ğ‘ )
à¯¦
(2) 
 Therefore, variational inference was performed to approximate the posterior. An 
approximate posterior ğ‘(ğ‘ ) is introduced. The VFE was then calculated and expressed as 
the Kullback-Leibler divergence (KL divergence) between ğ‘(ğ‘ ) and the generative model 
ğ‘(ğ‘œ,ğ‘ ). KL divergence corresponds to a measure that calculates the dissimilarity between 
two distributions. Eq. (3) shows the VFE. 
ğ¹=à·ğ‘(ğ‘ )ln ğ‘(ğ‘ )
ğ‘(ğ‘œ,ğ‘ )à¯¦
(3) 
 Variationally update ğ‘(ğ‘ ) . If ğ‘(ğ‘ )  is found to minimize the VFE, then 
approximate the true posterior ğ‘(ğ‘ |ğ‘œ) at that point. 
 This explains the perceptual mechanism in active inferences. Next, action 
selection is discussed. 
 In action selection, the brain also makes decisions that provide future observations 
to minimize the VFE. However, future outcomes have not yet been observed. Therefore, 
the EFE (i.e., the expected value of the VFE) was calculated and minimized. The expected 
free energy of the action policy Ï€ is expressed in Eq. (4) [7]: 
8 
 
ğºà°— =à·ğ‘(ğ‘œ,ğ‘ |ğœ‹)ln ğ‘(ğ‘ |ğœ‹)
ğ‘(ğ‘œ,ğ‘ |ğœ‹)à¯¦,à¯¢
(4)
=à·ğ‘(ğ‘œ,ğ‘ |ğœ‹)ln ğ‘(ğ‘ |ğœ‹)
ğ‘(ğ‘ |ğ‘œ,ğœ‹)à¯¦,à¯¢
âˆ’à·ğ‘(ğ‘œ|ğœ‹)lnğ‘(ğ‘œ|ğœ‹)
à¯¢
â‰ˆà·ğ‘(ğ‘œ,ğ‘ |ğœ‹)ln ğ‘(ğ‘ |ğœ‹)
ğ‘(ğ‘ |ğ‘œ,ğœ‹)à¯¦,à¯¢
âˆ’à·ğ‘(ğ‘œ|ğœ‹)lnğ‘(ğ‘œ|ğ¶)
à¯¢
 
 Two substitutions are made in the third line of Eq. (4). First, the approximate 
posterior ğ‘(ğ‘œ,ğ‘ |ğœ‹)  replaces the true posterior ğ‘(ğ‘ |ğ‘œ,ğœ‹) . Second, ğ‘(ğ‘œ|ğ¶)  replaces 
ğ‘(ğ‘œ|ğœ‹) in the second term. C is the prior preference, and ğ‘(ğ‘œ|ğ¶) encodes the observation 
that the agent prefers based on the prior preference. 
  
Mathematical modeling of presence using an active inference framework 
 The sense of the presence of the remote participant in hybrid communication is 
modeled using active inference.  
 Ogasawara et al. modeled the sense of the existence of another personâ€™s avatar in 
VR as the magnitude of model evidence or the smallness of surprise when perceiving 
stimuli related to the spatiotemporal localization of the avatar [3]. We hypothesized that 
beliefs about the mental states of remote participants would be a factor in the presence of 
the remote participants in the conversation experiment. The sense of presence by 
considering beliefs about a remote participantâ€™s mental state was modeled by using the 
model proposed by Ogasawara et al. 
 The sense of the presence of remote participants in hybrid communication was 
modeled as the model evidence of the mental states of remote participants. The large 
amount of model evidence for the mental state of a remote participant indicates its clarity. 
Therefore, the model evidence is associated with the presence of remote participants. With 
this model, the presence of remote participants can be expressed as latent variables in an 
active inference framework. 
Designing the gaze behavior of the avatar robot that encourages 
the expression of opinions by local participants in the discussion 
 In this section, the behavior of the avatar robot is designed that encourages the 
expression of opinions by local participants in the discussion and solves the problem of 
expressing opinions in groups with different social status levels. For this purpose, the 
9 
 
influence of the gaze behavior of a high-status member on the statements of the low-status 
members was modeled, including the presence modeled in the active inference framework. 
Then, simulations using the model were performed, and insights were obtained for 
designing the avatar robotâ€™s behavior. 
Problems in expressing opinions in groups with different levels of social 
status 
 In group discussions, sharing information and exchanging opinions are important 
because they enhance the performance of the group. Sharing information can allow groups 
with divergent knowledge or recognition levels to pool and summarize all information [8]. 
It is reported that that disagreement in groups is associated with increased creativity [9] 
and better decision making [10]. 
 However, voicing opinions to share information or express dissenting views is 
often associated with interpersonal risks. Speaking out against the prevailing opinion in 
the group can lead to social exclusion from the group [11]. Expressing opinions can elicit 
critical feedback and create an impression of incompetence in others. If there are people 
in the group who can influence their promotion or salary, expressing their opinions can be 
a more concrete and risky action [12]. Therefore, in groups with different status levels, the 
problem arises that low-status members hesitate to express their opinions because they fear 
interpersonal risks.  
Mathematical modeling of the influence of the gaze behavior of a high-
status member on the statements of low-status members 
 The characteristics and behaviors of high-status members influence the statements 
of others. Whether the team leader is cooperative or coaching-oriented has been reported 
to be a factor predicting a teamâ€™s psychological safety [12]. Psychological safety is the 
shared belief that a team is safe to take risks in interpersonal relationships and is related to 
team membersâ€™ learning behaviors [12]. Shim et al. found that differences in group 
members' influence decreased when a group leader directed more gaze toward a low-status 
member. [13]. 
 We promoted the statements of low-status members by intervening in the non-
verbal behavior of high-status members using the avatar robot. To design the behavior of 
an avatar robot to promote the statements of low-status members, the influence of the 
behavior of a high-status member on the statements of low-status members was modeled 
10 
 
using an active inference framework. 
  
 Fig 3 shows the proposed Bayesian model of the influence of a high-status 
memberâ€™s behavior on the statements of low-status members. s is the hidden state; o is the 
observation; A is likelihood mapping between states and observations (observation model); 
B is the transition matrix; C is the prior preferences; and D is the initial state priors. The 
model was divided into three fields: Level 1-1, Level 2, and Level 1-2. In all fields, the 
agent of inference is a low-status member. The fields are described as follows: 
 
 

11 
 
Fig 3. Bayesian model of the influence of the gaze behavior of a high-status member 
on the statements of low-status membersï¼ 
A: likelihood mapping between states and observations (observation model), B: transition 
matrices, C: prior preferences, D: initial state priors, G: expected free energy, s: states, o: 
observations, Ï€: posterior distribution over actions. Superscripts indicate the fields to 
which the variables belong. The subscript represents the time step. In all fields, the agent 
of inference is a low-status member.  
 
 In Level 1-1, a low-standing member infers whether a high-standing member is 
attentive based on the gaze behavior of that member. Humans can tell what other people 
are paying attention to from their gazes [14]. Therefore, an agent receiving a direct gaze 
infers that the person is attentive to the agent. Alternatively, the agent receiving oneâ€™s 
averted gaze infers that the person is not paying attention to the agent. The observational 
model ğ‘àµ«ğ‘œ(à¬µà¬¿à¬µ)à¸«ğ‘ (à¬µà¬¿à¬µ)àµ¯ is described by Eq. (5). ğœà¬µà¬¿à¬µ is the precision of Level 1-1 of the 
observation model. ğœ()  is the softmax function. Exp(âˆ’4)  is added to prevent the 
formation of ln(0). By transforming lines 3 and 4 in Eq. (5), the noise associated with the 
observations and the ambiguities in the mapping between the observations and states can 
be accounted for. 
ğ‘œ(à¬µà¬¿à¬µ) ={ğ‘‘ğ‘–ğ‘Ÿğ‘’ğ‘ğ‘¡ ğ‘”ğ‘ğ‘§ğ‘’ ğ‘ğ‘£ğ‘’ğ‘Ÿğ‘¡ğ‘’ğ‘‘ ğ‘”ğ‘ğ‘§ğ‘’}, 
  ğ‘ (à¬µà¬¿à¬µ) ={ğ‘ğ‘¡ğ‘¡ğ‘’ğ‘›ğ‘¡ğ‘–ğ‘£ğ‘’ ğ‘¢ğ‘›ğ‘ğ‘œğ‘›ğ‘ğ‘’ğ‘Ÿğ‘›ğ‘’ğ‘‘} 
ğ´à¬µà¬¿à¬µ=á‰‚1 0
0 1 á‰ƒ
ğ´(à¬µà¬¿à¬µ):ğ‘àµ«ğ‘œ(à¬µà¬¿à¬µ)à¸«ğ‘ (à¬µà¬¿à¬µ)àµ¯=ğœ(ğœà¬µà¬¿à¬µâˆ— ln(ğ´à¬µà¬¿à¬µ+ exp(âˆ’4))) (5)
 
 The agent infers the mental state of the high-status member at Level 1-1. Therefore, 
the model evidence of the inference in Level 1-1 corresponds to the sense of the presence 
of a high-status member. 
 In Level 2, a low-status member infers whether they are included in a group based 
on the results of the inference in Level 1-1. An included state corresponds to a high level 
of psychological safety. Hirak et al. [15] reported that the leaderâ€™s inclusivity is positively 
correlated with the psychological safety perceived by other members. A leaderâ€™s inclusivity 
is defined as the leaderâ€™s openness and accessibility in interactions with other members. It 
is assumed that the agent thinks that they are included in the group from the attention and 
interests of the group of high-status members. In contrast, it is assumed that the agent 
thinks that the high-status members' unconcern is exclusive to them. The observational 
12 
 
model ğ‘àµ«ğ‘ (à¬µà¬¿à¬µ)à¸«ğ‘ (à¬¶)àµ¯ is described by Eq. (6). 
ğ‘ (à¬µà¬¿à¬µ) ={ğ‘ğ‘¡ğ‘¡ğ‘’ğ‘›ğ‘¡ğ‘–ğ‘£ğ‘’ ğ‘¢ğ‘›ğ‘ğ‘œğ‘›ğ‘ğ‘’ğ‘Ÿğ‘›ğ‘’ğ‘‘}, 
  ğ‘ (à¬¶) ={ğ‘–ğ‘›ğ‘ğ‘™ğ‘¢ğ‘‘ğ‘’ğ‘‘ ğ‘’ğ‘¥ğ‘ğ‘™ğ‘¢ğ‘‘ğ‘’ğ‘‘} 
ğ´à¬¶ =á‰‚1 0
0 1 á‰ƒ
ğ´(à¬¶):ğ‘àµ«ğ‘ (à¬µà¬¿à¬µ)à¸«ğ‘ (à¬¶)àµ¯=ğœ(ğœà¬¶ âˆ— ln(ğ´à¬¶ + exp(âˆ’4))) (6)
 
 In Level 1-2, a low-status member selects their action: expressing an opinion or 
not. Expressing an opinion leads to group feedback. It is assumed that the agent learns 
whether the group agrees with their opinion. Observational model ğ‘àµ«ğ‘œ(à¬µà¬¿à¬¶)à¸«ğ‘ (à¬µà¬¿à¬¶)àµ¯  is 
described as Eq. (7). The observational model varies when the probability of a faulty 
inference is considered. 
ğ‘œ(à¬µà¬¿à¬¶) ={ğ‘ğ‘”ğ‘Ÿğ‘’ğ‘’ğ‘šğ‘’ğ‘›ğ‘¡ ğ‘‘ğ‘–ğ‘ ğ‘ğ‘”ğ‘Ÿğ‘’ğ‘’ğ‘šğ‘’ğ‘›ğ‘¡}, 
  ğ‘ (à¬µà¬¿à¬¶) ={ğ‘ğ‘”ğ‘Ÿğ‘’ğ‘’ğ‘šğ‘’ğ‘›ğ‘¡ ğ‘‘ğ‘–ğ‘ ğ‘ğ‘”ğ‘Ÿğ‘’ğ‘’ğ‘šğ‘’ğ‘›ğ‘¡} 
ğ´(à¬µà¬¿à¬¶):ğ‘àµ«ğ‘œ(à¬µà¬¿à¬¶)à¸«ğ‘ (à¬µà¬¿à¬¶)àµ¯=á‰‚0.8 0.2
0.2 0.8á‰ƒ (7) 
 The agent has prior preferences for future observations associated with action 
selection at Level 1-2. Prior preferences encode the rewards and aversions gained from the 
observations. Expressing an opinion involves interpersonal risk. Expressing a dissenting 
opinion can lead to social exclusion from a group [11]. We established a negative 
preference for observing ğ‘‘ğ‘–ğ‘ ğ‘ğ‘”ğ‘Ÿğ‘’ğ‘’ğ‘šğ‘’ğ‘›ğ‘¡. Considering that psychological safety promotes 
learning behaviors with interpersonal risk [12], we formulated the magnitude of negative 
preference changes by inclusiveness in the group inferred at Level 2. 
 It can be modeled that prior preferences depend on context. In this case, the EFE 
is described by Eq. (8) [16]: 
ğºà°—
(à¬µà¬¿à¬¶) = âˆ’ à· ğ‘àµ«ğ‘œ(à¬µà¬¿à¬¶),ğ‘ (à¬µà¬¿à¬¶)à¸«ğœ‹(à¬µà¬¿à¬¶)àµ¯lnğ‘àµ«ğ‘ (à¬µà¬¿à¬¶)à¸«ğ‘œ(à¬µà¬¿à¬¶),ğœ‹(à¬µà¬¿à¬¶)àµ¯
ğ‘àµ«ğ‘ (à¬µà¬¿à¬¶)à¸«ğœ‹(à¬µà¬¿à¬¶)àµ¯à¯¦(à°­à°·à°®),à¯¢(à°­à°·à°®)
âˆ’ à·ğ‘àµ«ğ‘œ(à¬µà¬¿à¬¶)à¸«ğœ‹(à¬µà¬¿à¬¶)àµ¯lnğ‘á‰€ğ‘œ(à¬µà¬¿à¬¶)á‰šğ‘ à°›
(à¬¶)á‰
à¯¢(à°­à°·à°®)
(8)
 
 The second term ğ‘á‰€ğ‘œ(à¬µà¬¿à¬¶)á‰šğ‘ à°›
(à¬¶)á‰ in Eq. (8) is the prior preference, which depends 
on the context at time Ï„. When the agent assumes that they are included in the group and 
that psychological safety is high, the agent perceives it as safe to take interpersonal risks. 
In contrast, when the agent assumes that they are excluded from the group and 
psychological safety is low, the agent perceives the danger of taking interpersonal risks. 
13 
 
Therefore, a negative preference is set only for ğ‘œ(à¬µà¬¿à¬¶) =ğ‘‘ğ‘–ğ‘ ğ‘ğ‘”ğ‘Ÿğ‘’ğ‘’ğ‘šğ‘’ğ‘›ğ‘¡  when ğ‘ (à¬¶) =
ğ‘’ğ‘¥ğ‘ğ‘™ğ‘¢ğ‘‘ğ‘’ğ‘‘. Prior preference is described as context-dependent, as in Eq. (9). 
ğ‘œ(à¬µà¬¿à¬¶) ={ğ‘ğ‘”ğ‘Ÿğ‘’ğ‘’ğ‘šğ‘’ğ‘›ğ‘¡ ğ‘‘ğ‘–ğ‘ ğ‘ğ‘”ğ‘Ÿğ‘’ğ‘’ğ‘šğ‘’ğ‘›ğ‘¡}, 
ğ‘ (à¬¶) ={ğ‘–ğ‘›ğ‘ğ‘™ğ‘¢ğ‘‘ğ‘’ğ‘‘ ğ‘’ğ‘¥ğ‘ğ‘™ğ‘¢ğ‘‘ğ‘’ğ‘‘} 
ğ‘àµ«ğ‘œ(à¬µà¬¿à¬¶)à¸«ğ‘ (à¬¶)àµ¯=á‰‚0 0
0 âˆ’1á‰ƒ (9) 
 The EFE of Eq. (8) allows for the consideration of prior preferences as a function 
of the discrete context. In modeling the influence of the level of psychological safety on 
action selection, we formulated the prior preference as shown in Eq. (10). 
ğ¶(à¬¶):ğ‘àµ«ğ‘œ(à¬µà¬¿à¬¶)à¸«ğ¶àµ¯=ğ‘àµ«ğ‘ (à¬¶) =ğ‘–ğ‘›ğ‘ğ‘™ğ‘¢ğ‘‘ğ‘’ğ‘‘àµ¯ğ‘àµ«ğ‘œ(à¬µà¬¿à¬¶)à¸«ğ‘ (à¬¶) =ğ‘–ğ‘›ğ‘ğ‘™ğ‘¢ğ‘‘ğ‘’ğ‘‘àµ¯
+ğ‘àµ«ğ‘ (à¬¶) =ğ‘’ğ‘¥ğ‘ğ‘™ğ‘¢ğ‘‘ğ‘’ğ‘‘àµ¯ğ‘àµ«ğ‘œ(à¬µà¬¿à¬¶)à¸«ğ‘ (à¬¶) =ğ‘’ğ‘¥ğ‘ğ‘™ğ‘¢ğ‘‘ğ‘’ğ‘‘àµ¯ (10) 
 Then, EFE is described in Eq. (11). 
ğºà°—
(à¬µà¬¿à¬¶) = âˆ’ à· ğ‘àµ«ğ‘œ(à¬µà¬¿à¬¶),ğ‘ (à¬µà¬¿à¬¶)à¸«ğœ‹(à¬µà¬¿à¬¶)àµ¯lnğ‘àµ«ğ‘ (à¬µà¬¿à¬¶)à¸«ğ‘œ(à¬µà¬¿à¬¶),ğœ‹(à¬µà¬¿à¬¶)àµ¯
ğ‘àµ«ğ‘ (à¬µà¬¿à¬¶)à¸«ğœ‹(à¬µà¬¿à¬¶)àµ¯à¯¦(à°­à°·à°®),à¯¢(à°­à°·à°®)
âˆ’ à·ğ‘àµ«ğ‘œ(à¬µà¬¿à¬¶)à¸«ğœ‹(à¬µà¬¿à¬¶)àµ¯lnğ‘àµ«ğ‘œ(à¬µà¬¿à¬¶)à¸«ğ¶àµ¯
à¯¢(à°­à°·à°®)
(11)
 
 
Simulations based on the Bayesian model 
 We performed simulations using the proposed model of the influence of a high-
status memberâ€™s gaze behavior on the low-status membersâ€™ statements to design the 
intervention behavior of an avatar robot.  
 The action selection probability of a low-status member in each condition was 
simulated. The action selection probability is calculated using Eq. (12). 
ğœ‹={ğ‘’ğ‘¥ğ‘ğ‘Ÿğ‘’ğ‘ ğ‘  ğ‘ğ‘› ğ‘œğ‘ğ‘–ğ‘›ğ‘–ğ‘œğ‘› ğ‘‘ğ‘œ ğ‘›ğ‘œğ‘¡ ğ‘’ğ‘¥ğ‘ğ‘Ÿğ‘’ğ‘’ ğ‘ğ‘› ğ‘œğ‘ğ‘–ğ‘›ğ‘–ğ‘œğ‘›}
ğ‘(ğœ‹)=ğœ(âˆ’ğ›¾ğº) ( 12) 
 The term Î³ is the expected precision of EFE. The initial value was set to 1. Term 
G is a vector consisting of the EFEs of the two actions. The term ğœ()  is the softmax 
function. We used the MATLAB code spm_MDP_VB_X_tutorial.m from [7] to perform 
the simulations. 
 The avatar robot can intervene in observation in Level 1-1 (ğ‘œ(à¬µà¬¿à¬µ)), likelihood 
mapping between states and observations in Level 1-1 (ğ‘àµ«ğ‘œ(à¬µà¬¿à¬µ)à¸«ğ‘ (à¬µà¬¿à¬µ)àµ¯ ), and prior in 
Level 1-1 (ğ‘(ğ‘ (à¬µà¬¿à¬µ)) ), which express predictions before observation. Conditions that 
changed the model variables were simulated. The simulation conditions are listed in Table 
14 
 
1. By observing the action selection that follows the EFE, we set the initial value of the 
EFEâ€™s expected precision (Î³) to one. 
 
Table 1ï¼Conditions of the simulationï¼ 
Condition Observation 
ğ’(ğŸà¬¿ğŸ) 
Likelihood mapping 
ğ‘¨(ğŸà¬¿ğŸ):ğ’‘àµ«ğ’(ğŸà¬¿ğŸ)à¸«ğ’”(ğŸà¬¿ğŸ)àµ¯ 
Initial state prior 
ğ‘«(ğŸà¬¿ğŸ):ğ’‘(ğ’”(ğŸà¬¿ğŸ)) 
1 Direct gaze ğœà¬µà¬¿à¬µ =0.2 
ğ‘àµ«ğ‘œ(à¬µà¬¿à¬µ)à¸«ğ‘ (à¬µà¬¿à¬µ)àµ¯
=á‰‚0.691 0.309
0.309 0.691á‰ƒ 
ğ‘àµ«ğ‘ (à¬µà¬¿à¬µ)àµ¯=á‰‚0.5
0.5á‰ƒ 
2 Averted gaze ğœà¬µà¬¿à¬µ =0.2 
ğ‘àµ«ğ‘œ(à¬µà¬¿à¬µ)à¸«ğ‘ (à¬µà¬¿à¬µ)àµ¯
=á‰‚0.691 0.309
0.309 0.691á‰ƒ 
ğ‘àµ«ğ‘ (à¬µà¬¿à¬µ)àµ¯=á‰‚0.5
0.5á‰ƒ 
3 Direct gaze ğœà¬µà¬¿à¬µ =0~1.0 ğ‘àµ«ğ‘ (à¬µà¬¿à¬µ)àµ¯=á‰‚0.5
0.5á‰ƒ 
4 Direct gaze ğœà¬µà¬¿à¬µ =0.2 
ğ‘àµ«ğ‘œ(à¬µà¬¿à¬µ)à¸«ğ‘ (à¬µà¬¿à¬µ)àµ¯
=á‰‚0.691 0.309
0.309 0.691á‰ƒ 
ğ‘=0~1.0 
ğ‘àµ«ğ‘ (à¬µà¬¿à¬µ)àµ¯
=á‰‚ ğ‘
1âˆ’ğ‘á‰ƒ 
s: states, o: observations, ğœà¬µà¬¿à¬µ : precision of Level 1-1 the likelihood mapping. 
Superscripts indicate the fields to which the variables belong. 
 
 In condition 1, we simulated the action selection probability when the agent 
observes the direct gaze of the high-status member as observation ğ‘œ(à¬µà¬¿à¬µ) . We set the 
precision of the observation model to 0.2 to account for the uncertainties in the mapping 
between the inferred state and observed gaze. We set the prior as ğ‘àµ«ğ‘ (à¬µà¬¿à¬µ)àµ¯=á‰‚0.5
0.5á‰ƒ under 
the assumption that the agent equally predicts whether the high-standing member pays 
attention to and is interested in them. 
 In condition 2, the action selection probability was simulated when the agent 
observes the averted gaze of a high-status member as observation ğ‘œ(à¬µà¬¿à¬µ). By comparing 
the results of conditions 1 and 2, the influence of the avatar robotâ€™s conversion of an 
averted gaze to a direct gaze on a low-status memberâ€™s statement was predicted. We set the 
15 
 
precision of the observation model prior to the same values as condition 1. 
 Under condition 3, the action selection probability was simulated by changing the 
precision of the observation model ğ‘àµ«ğ‘œ(à¬µà¬¿à¬µ)à¸«ğ‘ (à¬µà¬¿à¬µ)àµ¯. The prior was set as ğ‘àµ«ğ‘ (à¬µà¬¿à¬µ)àµ¯=
á‰‚0.5
0.5á‰ƒ under the assumption that the agent equally predicts whether the high-status member 
pays attention to and is interested in them. The influence of a high-status member changing 
their gaze behavior to one that expressed more attention and interest in what the low-status 
member said was predicted.  
 In condition 4, the action selection probability was simulated by changing the 
prior ğ‘àµ«ğ‘ (à¬µà¬¿à¬µ)àµ¯. The precision of the observational model was set to 0.2 to account for 
uncertainties in the mapping between the inferred state and observed gaze. The prior 
encodes the prediction of whether the high-status member pays attention and interest to 
the agent. The influence of adding a prior motion [17] to the gaze behavior of the high-
status member by the avatar robot, which enabled the prediction of the gaze movement on 
what the low-status member said, was predicted. 
 Table 2 lists the simulation results of action selection probability under conditions 
1 and 2. The probability of expressing an opinion is higher under condition 1 than under 
condition 2. Thus, it is predicted that changing the gaze behavior of the high-status member 
from an averted gaze to a direct gaze will encourage the low-status member to speak. 
 Fig 4 shows the simulation results of the action selection probability under 
condition 3. The higher the precision of the observation model, the higher the probability 
of expressing an opinion. Therefore, it is predicted that changing the gaze behavior of high-
status members to one that expresses more attention and interest will encourage a low-
status member to express an opinion. 
 Fig 5 shows the simulation results of the action selection probability under 
condition 4. The higher the degree of prediction that a high-status member will pay 
attention and show interest in the agent, the higher the probability of an opinion being 
expressed. Based on this result, it is predicted that adding preliminary movements to the 
gaze behavior of high-status members would encourage low-status members to speak. 
 Based on these findings, we designed the gaze behavior of an avatar robot. In this 
study, we designed the gaze behavior when the remote participant spoke, which seemed to 
express more attention to local participants. 
Table 2. Simulation results of action selection probability under conditions 1 and 2. 
16 
 
 
s: states, o: observations, ğœà¬µà¬¿à¬µ : precision of Level 1-1 the likelihood mapping. 
Superscripts indicate the fields to which the variables belong. Using a mathematical model, 
we simulated the probability of a low-status member speaking after seeing the gaze 
behavior of a high-status member in each condition. 
 
 
Condition Observation 
ğ’(ğŸà¬¿ğŸ) 
Likelihood mapping 
ğ‘¨(ğŸà¬¿ğŸ):ğ’‘àµ«ğ’(ğŸà¬¿ğŸ)à¸«ğ’”(ğŸà¬¿ğŸ)àµ¯ 
Initial state prior 
ğ‘«(ğŸà¬¿ğŸ):ğ’‘(ğ’”(ğŸà¬¿ğŸ)) 
Probability 
of 
expressing 
an opinion  
1 Direct gaze ğœà¬µà¬¿à¬µ =0.2 
ğ‘àµ«ğ‘œ(à¬µà¬¿à¬µ)à¸«ğ‘ (à¬µà¬¿à¬µ)àµ¯
=á‰‚0.691 0.309
0.309 0.691á‰ƒ 
ğ‘àµ«ğ‘ (à¬µà¬¿à¬µ)àµ¯=á‰‚0.5
0.5á‰ƒ 0.3729 
2 Averted gaze  ğœà¬µà¬¿à¬µ =0.2 
ğ‘àµ«ğ‘œ(à¬µà¬¿à¬µ)à¸«ğ‘ (à¬µà¬¿à¬µ)àµ¯
=á‰‚0.691 0.309
0.309 0.691á‰ƒ 
ğ‘àµ«ğ‘ (à¬µà¬¿à¬µ)àµ¯=á‰‚0.5
0.5á‰ƒ 0.0571 
17 
 
Fig 4. The influence of precision of the Level 1-1 observation model on the probability 
that a low-status member expresses an opinion.  
Precision adjusts the ambiguity of the mapping between states and observations. Higher 
precision indicates that the mapping is more precise. The observation model in Level 1-1 
is a mapping between the attentional states of high-status members (attentive/unconcerned 
to a low-status member) and their gaze behavior. 
 
 
Fig 5. The influence of prior distribution in Level 1-1 ï¼ˆğ’‘àµ«ğ’”(ğŸà¬¿ğŸ)àµ¯=[ğ’‚ ğŸ âˆ’ğ’‚]ï¼‰on 
the probability that a low-status member expresses an opinion.  
The state derived by a low-status member in Level 1-1 is the attention state of a high-status 
member (attentive/unconcerned to a low-status member). A higher value of a means that a 
low-status member predicts that a high-status member is more likely to direct their 
attention and interest toward a low-status member. 
Design of the gaze behavior of the avatar robot 
 Based on the simulation results, the gaze behavior of an avatar robot was designed 
in conjunction with a remote participantâ€™s speech. First, the requirements for gaze behavior 
are explained. Second, the design of a gaze behavior is explained that satisfies these 
requirements. Then, the actual designed gaze behavior is explained. 

18 
 
 Based on the initial simulation results, we determined to make the avatar robot 
automatically cast a direct gaze, regardless of the remote participantâ€™s gaze behavior. 
However, if the gaze behavior appears to be automated, the local participants may not 
perceive that the remote participant is paying attention to or is interested in them. Thus, 
the first requirement is that gaze behavior should be natural and not artificial. We also 
predicted that gaze behavior expressing more attention, interest, and preliminary 
movement would encourage low-status members to speak in the simulations. Therefore, 
the second requirement is that gaze behavior should express more attention and interest. 
We used a preliminary movement to satisfy this requirement. 
 Next, the design of a gaze behavior is explained that satisfies these two 
requirements. In this study, natural behavior is designed by using the techniques and ideas 
of animators. Animators express vivid behaviors by emphasizing and exaggerating 
necessary behavioral features and omitting unnecessary behavioral features [17]. 
Therefore, our design guidelines emphasize behavioral features that can be a cue to pay 
attention for local participants and omit the rest. It is likely that this guideline realizes a 
gaze behavior that satisfies both requirements. 
 Finally, the designed gaze behavior is described. Table 3 lists the behavioral 
features incorporated into the gaze behavior of the avatar robot and their meanings. We 
implemented these behavioral features in the gaze behavior while a remote participant was 
speaking. 
Table 3. Behavioral features incorporated into the gaze behavior of the avatar robot 
and meanings of them. 
Behavioral features incorporated into 
the gaze behavior of the avatar robot 
Meanings of the behavioral features 
Blinks before and after the head swing ï¬ Preliminary movement of viewpoint 
swift [17][18]ï¼ 
ï¬ Imitation of real behavior [17]. 
ï¬ Emphasis on head swing stoppage 
[17]ï¼ 
Omitting the blink except for the blink 
before and after the head swing 
ï¬ Enhancing impressions of blinks 
before and after the head swingï¼ 
ï¬ Enhancing impressions of direct gaze 
[19]. 
19 
 
  
  
Experiment: Effect of the intervention in the gaze behavior of 
the avatar robot on the statements of local participants 
Gaze behavior of the avatar robot used in the experiment 
 Participants were divided into an experimental and a control group. For each 
group, we used the different gaze behavior of the avatar robot when the remote participant 
(the researcher) spoke.  
 For the experimental groups, the avatar robot described in the previous section 
was used. In this task, the researcher acted as a remote participant using an avatar robot, 
and the two participants were local participants. Fig 6 shows the arrangement of the 
participants and the avatar robot in the experiment. The avatar robot looked at each 
participant in the experimental group in turn. When the researcher breathed, the avatar 
robot changed the direction of its gaze. 
 In the control group, the avatar robot looked at the center of the two participants 
throughout the researcher's speech. To avoid an unnatural impression, we implemented and 
used a blink pattern in which the avatar robot blinked once after three seconds and twice 
after another three seconds. 
 The specific implementation of the gaze behaviors is described in the Supporting 
Information. 
 
Emphasis on slow-in/slow-out [17] in head 
swing 
ï¬ Imitation of real behavior. 
ï¬ Emphasis on head swing stop [17]. 
Implementation of eye movements 
associated with blinking and head 
swinging 
ï¬ Imitation of real behavior. 
Head swinging associated with a breather ï¬ Imitation of real behavior. 
ï¬ Expression that the subjects of the 
speech and eye behavior are the same 
20 
 
 
Fig 6. Arrangement of participants and the avatar robot in the experiment. 
 
Participants 
Participants were recruited from among students at the University of Tokyo who 
had no visual or hearing impairments and whose native language was Japanese, using both 
snowball sampling and voluntary responses. Twenty-two students (16 male, six female) in 
the experimental group and 22 students (16 male, five female, one no answer) participated 
in this study. For controlling the influence of acquaintances and gender combinations, we 
created pairs of same-gender participants who did not know each other. A female pair who 
was acquainted with each other and a pair of female and no-answer participants who had 
selected the same candidate before the discussion were excluded from the analysis. 
This study was approved by the Research Ethics Committee of the School of 
Engineering, The University of Tokyo (Approval No. KE22-59). All study participants 
provided informed consent. 

21 
 
Design 
 We used a hidden-profile task [8] to quantitatively investigate whether local 
participantsâ€™ statements were promoted. In the hidden-profile task, participants received 
partial information about their choices. Participants can only choose the best option if they 
share unique information with each other. Therefore, a hidden-profile task is used to study 
group information elaboration [13] and team performance in learning [20]. 
 A group consisting of one researcher and two participants performed a hidden 
profile task. Participants read the profiles of three hypothetical candidates for the student 
body president and then decided which candidate was best suited for the position. The 
profiles did not include complete information about the candidates and contained unique 
information provided to only one participant. We examined whether each participantâ€™s 
statement was promoted by evaluating the amount of unique information shared. 
Participants played a game that reproduced the relationship between their boss 
and subordinates during discussions in the hidden-profile task. We call this the bossâ€“
subordinate game. The researcher played the game in the role of the boss, and participants 
acted as subordinates. We calculated each participantâ€™s score using the boss-subordinate 
game rules. Participants were then told that in addition to the gratuities, they would receive 
snacks according to their scores. After the experiment, all participants were given the same 
number of snacks. The boss-subordinate game states that a subordinate who disagrees with 
their boss has the risk of a point deduction for their statements. This risk is related to the 
subjective judgment of the boss. This rule structure reproduces a situation in which low-
status members are reluctant to express their opinions because of the interpersonal risks. 
The profiles were designed so that each participant supported a different 
candidate: candidate B or candidate C. The researcher supported candidate B as the 
supervisor. Thus, a participant who supported candidate C risked their statements 
according to the boss-subordinate game rules. The profiles were created by modifying the 
method used in [8]. 
 In the actual experiments, there were cases where the participants did not support 
the candidates as intended. In such cases, the researcher selected and supported candidates 
B or C, so there were participants who agreed and disagreed with the boss. We refer to a 
participant who agrees with the boss as Participant 1 and a participant who disagrees with 
the boss as Participant 2. 
 
22 
 
Procedure 
 After completing the informed consent form, the participants completed 
questionnaire testing personality traits prior to the experiment. They then began the 
hidden-profile task. This hidden-profile task consists of individual and discussion phases. 
In the individual phase, each participant reads the profile and indicates which candidates 
they support at that time.  
Then, the researcher explains the boss-subordinate game that is played in the 
discussion phase. The researcher then moved to another room and connected to an avatar 
robot. After confirming that the connection to the avatar robot was successful, the 
researcher asked the participants to report the candidates they had selected for the 
individual phase. The order of reporting was as follows: participants who received the 
profile that recommended candidate B reported first, followed by those who received the 
profile that recommended candidate C.  
The researcher then explained the discussion phase and gave an opinion as the 
boss (which candidate was supported and why). While the researcher explained this, the 
avatar robot looked at each participant in turn in the experimental group. In the control 
group, the avatar robot continued to gaze at the middle of the two participants, while the 
researcher gave an opinion. After the researcher expressed an opinion as the boss, the 
participants engaged in a free discussion about which candidate should be nominated for 
student body president. During the free discussion, the researcher did not speak, and the 
avatar robot continued to observe the center of the two participants. 
The participants reported to the researcher the candidate who should be nominated 
as student body president after reaching an agreement within five minutes of the start of 
the free discussion. The hidden profile task was completed when the researcher received 
the report. The researcher distributed a questionnaire asking for unique information shared 
by the group during the free discussion, as well as subjective ratings of the discussion 
phase experience. After debriefing and conducting the interviews, the participants received 
snacks as an additional reward and were dismissed. 
 
Measures 
 Objective and subjective indexes were used to assess the effect of the avatar 
robot's gaze behavior on participants. 
 As an objective index, the amount of unique information shared by each 
23 
 
participant during the free discussion was measured. The amount of unique information 
shared by Participant 1 (who agreed with the researcher as the boss) was referred to as 
sum1. The amount of unique information shared by Participant 2 (who disagreed with the 
researcher as the boss) was referred to as sum2. The profile that Participant 1 had read 
contained six unique items of information that supported the bossâ€™s opinion and three items 
of information that did not support the bossâ€™s opinion. The amount of shared unique 
information that supported the bossâ€™s opinion was measured, and this number is referred 
to as agreement1. That unique information indicated that the candidate supported by the 
boss was desirable or indicated that the candidate not supported by the boss was 
undesirable. Additionally, the amount of shared unique information that did not support 
the bossâ€™s opinion was measured, and this number was referred to as disapproval1. The 
total number of agreement1 and disapproval1 responses was sum1. Participant 1 answered 
questions about the unique information they had shared with the group during the free 
discussion from all the unique information. Participant 2 read nine unique pieces of 
information that did not support the bossâ€™s opinion. Participant 2 answered questions about 
the unique information they shared with the group during the free discussion from all the 
unique information. 
 In addition, the amount of unique information that the participants were hesitant 
to share was measured. The number of responses from Participant 1 was called hesitation1, 
and the number of responses from Participant 2 was called hesitation2. 
 Subjective indexes to measure the effects on participants were used that were not 
included in the objective indexes. The subjective indexes were based on a model of the 
influence of a high-ranking memberâ€™s gaze behavior on the opinions of low-ranking 
members. 
 How easy it was to identify the gaze direction while the researcher was connected 
to the avatar robot was measured. It was checked whether participants could observe the 
direct gaze of the high-ranking member (the researcher) at Level 1-1 of the model. 
 Perceptions of attention and interest, while the researcher was connected to the 
avatar robot, were measured. Perceptions of attention and interest indicate whether 
participants infer that they are receiving attention and interest from the high-ranking 
member in Level 1-1 of the model. Perception of attention and interest is an index of how 
large the model evidence is for the model from which participants inferred that they 
received attention and interest from high-ranking members (i.e., how large the presence of 
high-ranking members is). 
24 
 
 We then measured the inclusiveness of each group. We checked whether 
participants in Level 2 inferred from their perception of attention and interest that they 
were included in the group. 
 The ease with which participants were able to express their opinions during the 
free discussion was measured. It was checked whether participants felt that it was easy to 
select the action of expressing themselves in Level 1-2. 
 Participants responded on a 7-level Likert scale to four of the above items: ease 
of identifying gaze direction, perception of attention and interest, involvement in the group, 
and ease of expressing opinions. 
 It was assumed that the results would be influenced by the participantsâ€™ 
personality traits. Therefore, prior to the hidden profile task, participantâ€™s extraversion and 
neuroticism using the Big-Five marker was measured [21].  
 After debriefing, participants were asked about whether they perceived any risk 
in sharing information during the free discussion and what their impression of the avatar 
robot was while the researcher was speaking. 
In addition, a video of the discussion phase of the hidden profile task was recorded 
and used to discuss the experimental results. 
Hypothesis 
 The gaze behavior used in the experimental group was designed to express 
attention and interest to local participants. Thus, we hypothesized the following:  
H1.  The ease with which gaze direction could be identified increased in the experimental 
group compared to the control group for both Participant 1 (a participant who agreed 
with the researcher as the boss) and Participant 2 (a participant who disagreed with 
the researcher as the boss). 
H2. The perception of attention and interest increased in the experimental group compared 
to the control group for both Participants 1 and 2. 
Based on the model of the influence of the gaze behavior of the high-status member 
on the statements of low-status members, we hypothesized the following: 
H3. Participant 2â€™s inclusivity in the experimental group increased compared to the control 
group.  
H4. The ease with which participant 2 expresses their opinion increased in the 
experimental group compared to the control group.  
There seemed to be no significant differences between the two groups in terms of 
25 
 
Participant 1â€™s inclusion in the group and the ease of expressing their opinions. This is 
because Participant 1 agreed with the boss and rated the boss highly in both groups. 
In addition, we hypothesize the following: 
H5. Index sum2 will increase in the experimental group compared to the control group.  
H6. Index hesitation 2 will decrease in the experimental group compared to the control 
group.  
This was due to the fact that the designed gaze behavior promoted the statements of 
Participant 2â€™s statements with interpersonal risks. In contrast, Participant 1 had low risk 
in their statements because they contained a lot of clear information that supported the 
bossâ€™s opinion. There were no significant differences between the two groups in terms of 
sum1 and hesitation1. 
Data analysis 
 We analyzed the results of the experiments with 40 participants (experimental 
group: 16 male and four female; control group: 16 male and four female). A between-
subjects analysis was performed. When the personality traits of the participants 
(extraversion and neuroticism) were significantly related to the indices, we performed an 
analysis of covariance (ANCOV A) with personality traits as covariates and the participant 
group of (experimental group or control group) as a factor. When the effect of the 
personality traits of the participants on the indices was not significant, a two-tailed t-test 
was performed to compare the experimental and control groups on the objective and 
subjective ratings. The threshold for significance (alpha) was 0.05. 
Results 
 Fig 7 shows the amount of unique information shared by a participant who agreed 
with the researcher as boss (Participant 1). Fig 8 shows the amount of unique information 
shared by a participant who disagreed with the researcher as boss (Participant 2). The index 
sum2 was significantly lower in the experimental group than in the control group (t(18) = 
-3.104, p = 0.006). Index sum2 shows the amount of unique information that Participant 2 
shared. This result contradicts H5. Moreover, the value of sum1 was also significantly 
lower in the experimental group than in the control group (t(18) = -2.137, p = 0.047). The 
index sum1 shows the amount of unique information shared by Participant 1.  
There were no significant differences between the experimental and control 
26 
 
groups for hesitation 2 (t(18) = 0.911, p = 0.828). Thus, H6 was not supported. 
 
 
Fig 7. Number of unique pieces of information shared by a participant who agreed 
with the high-standing member. * p<0.05, ** p<0.01. Error bars indicate standard 
deviations.  
Disapproval1: number of unique pieces of information shared that did not support the 
opinions of high-status members. Agreement1: number of unique pieces of information 
shared that supported high status memberâ€™s opinion. Hesitation1: number of unique pieces 
of information that were not shared when participants hesitated whether or not to share. 
Sum1: total of dessent1 and assent1. A participant who agreed with a high status member 
had six unique pieces of information that supported the high-status memberâ€™s opinion and 
three that did not support the high-status memberâ€™s opinion. 
 
 
Fig 8. Number of unique pieces of information shared by a participant who disagreed 
with the high-status member. * p<0.05, ** p<0.01. Error bars show standard deviations.  

27 
 
Hesitation2: number of unique pieces of information that were not shared when 
participants hesitated whether or not to share. Sum2: number of unique pieces of 
information shared by a participant who disagreed with the high-status member. A 
participant who disagreed with the high-status member had nine unique pieces of 
information that did not support the high-status memberâ€™s opinion. 
 
 Fig 9 shows the subjective rating of Participant 1. Fig 10 shows the subjective 
rating of Participant 2. For both Participant 1 and Participant 2, the ease of identifying the 
gaze direction was significantly higher in the experimental group than in the control group 
(ease of identifying the gaze direction of Participant 1: t(18) = 5.513, p < 0.001, ease of 
identifying the gaze direction of Participant 2: t(18) = 2.994, p = 0.008). These results are 
consistent with H1.  
For both Participant 1 and Participant 2, perceptions of attention and interest were 
significantly higher in the experimental group than in the control group (Participant 1â€™s 
perception of attention and interest: t(18) = 2.832, p = 0.011. Participant 2â€™s perception of 
attention and interest: t(18) = 2.374, p = 0.029). Thus, H2 is supported.  
However, there were no significant differences between the experimental and 
control groups in terms of in-group inclusivity or ease of expressing opinions (inclusivity 
for Participant 1: t(13.072) = -0. 397, p = 0.698; ease of expressing opinions for Participant 
1: t(18) = -1.698, p = 0.107; inclusivity for Participant 2: t(18) = -0. 616, p = 0.546; ease 
of expressing opinions for Participant 2: t(18) = -0.843, p = 0.410). Therefore, H3 and H4 
are not supported. 
 
 
Fig 9. Subjective evaluation of a participant agreeing with the high-status member. * 
p<0.05, ** p<0.01. Error bars show standard deviations.  

28 
 
 
 
Fig 10. Subjective evaluation of a participant disagreeing with the high-status 
member. * p<0.05, ** p<0.01. Error bars show standard deviations.  
 
Discussion 
 For both Participant 1 and Participant 2, perceptions of attention and interest were 
significantly greater in the experimental group than in the control group (Participant 1: 
agrees with the researcher as the boss, Participant 2: disagrees with the researcher as the 
boss). Therefore, we assumed that the gaze behavior of the avatar robot increased the 
presence of the remote participant (the researcher as boss), as hypothesized. We also 
received responses from participants such as â€œI felt like I was being watched,â€ and â€œI 
assumed the researcher was talking to the participant he was looking atâ€ during the post 
debriefing interview. We hypothesize that the gaze behavior increased the model evidence 
of each local participant, by inferring that the boss was paying attention and interest to 
them, and thus increasing the presence of the remote boss. 
 However, sum1 and sum2 are significantly smaller in the experimental group than 
in the control group, contrary to H5 (Index sum1 and sum2 show the number of unique 
pieces of information shared by Participants 1 and 2). We believe that these results are 
attributable to the incorrect modeling of Level2 in the constructed model.  
 In the subordinate game, Participant 2 was at risk of a point reduction if they 
expressed an opinion. If the boss chose the â€œRejection of an opinionâ€ option when 
Participant 2 expressed a dissenting opinion, Participant 2â€™s score would be reduced. 
Therefore, the presence of a boss may have led Participant 2 to be aware that they were 

29 
 
being monitored by the boss and to strongly perceive the risks of expressing an opinion. 
In other words, we assume that Participant 2 inferred from the boss's attention and interest 
at Level 2 of the model that the boss was monitoring them.  
 Based on this discussion, the model of the influence of a high-status memberâ€™s 
gaze behavior on low-status membersâ€™ statements was updated, as shown in Fig 11. 
 
 
Fig 11. Modified mathematical model of the influence of the gaze behavior of a high-
status member on the statements of low-status membersï¼Inferred states and 
observation model in Level 2 is modified. A: likelihood mapping between states and 

30 
 
observations (observation model), B: transition matrices, C: prior preferences, D: initial 
state priors, G: expected free energy, s: states, o: observations, Ï€: posterior distribution 
over actions. Superscripts are used to indicate the fields to which variables belong. 
Subscripts indicate the time step. In all fields, the agent of inference is a low-status member. 
 
 First, we explain Level 1-1. In this experiment, perceptions of attention and 
interest were increased by the gaze behavior of the avatar robot, as hypothesized. Therefore, 
the observation model for Level 1-1 is defined in Eq. (13), which is the same as before the 
modification. 
ğ‘œ(à¬µà¬¿à¬µ) ={ğ‘‘ğ‘–ğ‘Ÿğ‘’ğ‘ğ‘¡ ğ‘”ğ‘ğ‘§ğ‘’ ğ‘ğ‘£ğ‘’ğ‘Ÿğ‘¡ğ‘’ğ‘‘ ğ‘”ğ‘ğ‘§ğ‘’}, 
  ğ‘ (à¬µà¬¿à¬µ) ={ğ‘ğ‘¡ğ‘¡ğ‘’ğ‘›ğ‘¡ğ‘–ğ‘£ğ‘’ ğ‘¢ğ‘›ğ‘ğ‘œğ‘›ğ‘ğ‘’ğ‘Ÿğ‘›ğ‘’ğ‘‘} 
ğ´à¬µà¬¿à¬µ=á‰‚1 0
0 1 á‰ƒ
ğ‘àµ«ğ‘œ(à¬µà¬¿à¬µ)à¸«ğ‘ (à¬µà¬¿à¬µ)àµ¯=ğœ(ğœà¬µà¬¿à¬µâˆ— ln(ğ´à¬µà¬¿à¬µ+ exp(âˆ’4))) (13)
 
 Next, Level 2 is described. There was no significant difference between the 
experimental and control groups in terms of in-group inclusivity. However, we believe that 
the perception of the bossâ€™s attention and interest increased the feeling of being monitored 
by the boss. Therefore, we changed the hidden state ğ‘ (à¬¶)  from ğ‘ (à¬¶) =
{ğ‘–ğ‘›ğ‘ğ‘™ğ‘¢ğ‘‘ğ‘’ğ‘‘ ğ‘’ğ‘¥ğ‘ğ‘™ğ‘¢ğ‘‘ğ‘’ğ‘‘}  to ğ‘ (à¬¶) ={ğ‘šğ‘œğ‘›ğ‘–ğ‘¡ğ‘œğ‘Ÿğ‘’ğ‘‘ ğ‘›ğ‘œğ‘¡ ğ‘šğ‘œğ‘›ğ‘–ğ‘¡ğ‘œğ‘Ÿğ‘’ğ‘‘} . We reformulate the 
observation model in Level2 as Eq. (14). 
ğ‘ (à¬µà¬¿à¬µ) ={ğ‘ğ‘¡ğ‘¡ğ‘’ğ‘›ğ‘¡ğ‘–ğ‘£ğ‘’ ğ‘¢ğ‘›ğ‘ğ‘œğ‘›ğ‘ğ‘’ğ‘Ÿğ‘›ğ‘’ğ‘‘}, 
  ğ‘ (à¬¶) ={ğ‘šğ‘œğ‘›ğ‘–ğ‘¡ğ‘œğ‘Ÿğ‘’ğ‘‘ ğ‘›ğ‘œğ‘¡ ğ‘šğ‘œğ‘›ğ‘–ğ‘¡ğ‘œğ‘Ÿğ‘’ğ‘‘} 
ğ´à¬¶ =á‰‚1 0
0 1 á‰ƒ
ğ‘àµ«ğ‘ (à¬µà¬¿à¬µ)à¸«ğ‘ (à¬¶)àµ¯=ğœ(ğœà¬¶ âˆ— ln(ğ´à¬¶ + exp(âˆ’4))) (14)
 
 Next Level 1-2 is described. The observation model for Level 1-2 is defined in Eq. 
(15), which is the same as before the modification. 
ğ‘œ(à¬µà¬¿à¬¶) ={ğ‘ğ‘”ğ‘Ÿğ‘’ğ‘’ğ‘šğ‘’ğ‘›ğ‘¡ ğ‘‘ğ‘–ğ‘ ğ‘ğ‘”ğ‘Ÿğ‘’ğ‘’ğ‘šğ‘’ğ‘›ğ‘¡}, 
  ğ‘ (à¬µà¬¿à¬¶) ={ğ‘ğ‘”ğ‘Ÿğ‘’ğ‘’ğ‘šğ‘’ğ‘›ğ‘¡ ğ‘‘ğ‘–ğ‘ ğ‘ğ‘”ğ‘Ÿğ‘’ğ‘’ğ‘šğ‘’ğ‘›ğ‘¡} 
ğ‘àµ«ğ‘œ(à¬µà¬¿à¬¶)à¸«ğ‘ (à¬µà¬¿à¬¶)àµ¯=á‰‚0.8 0.2
0.2 0.8á‰ƒ (15) 
 We changed the prior preference in Level 1-2 because the context ğ‘ (à¬¶)  is 
modified. In the experimental task, being monitored by the boss led low-status members 
(participants) to perceive the risks of a point deduction according to the boss-subordinate 
31 
 
game rule. Thus, the boss-subordinate game rule determines the risk of disagreeing with 
the boss. Therefore, we changed ğ‘ (à¬¶)  from ğ‘ (à¬¶) ={ğ‘–ğ‘›ğ‘ğ‘™ğ‘¢ğ‘‘ğ‘’ğ‘‘ ğ‘’ğ‘¥ğ‘ğ‘™ğ‘¢ğ‘‘ğ‘’ğ‘‘}  to ğ‘ (à¬¶) =
{ğ‘šğ‘œğ‘›ğ‘–ğ‘¡ğ‘œğ‘Ÿğ‘’ğ‘‘ ğ‘›ğ‘œğ‘¡ ğ‘šğ‘œğ‘›ğ‘–ğ‘¡ğ‘œğ‘Ÿğ‘’ğ‘‘}  and set a negative preference only to ğ‘œ(à¬µà¬¿à¬¶) =
ğ‘‘ğ‘–ğ‘ ğ‘ğ‘”ğ‘Ÿğ‘’ğ‘’ğ‘šğ‘’ğ‘›ğ‘¡ when ğ‘ (à¬¶) =ğ‘šğ‘œğ‘›ğ‘–ğ‘¡ğ‘œğ‘Ÿğ‘’ğ‘‘. We reformulate the prior preference at Level 1-
2 as Eq. (16). 
ğ‘œ(à¬µà¬¿à¬¶) ={ğ‘ğ‘”ğ‘Ÿğ‘’ğ‘’ğ‘šğ‘’ğ‘›ğ‘¡ ğ‘‘ğ‘–ğ‘ ğ‘ğ‘”ğ‘Ÿğ‘’ğ‘’ğ‘šğ‘’ğ‘›ğ‘¡}, 
ğ‘ (à¬¶) ={ğ‘šğ‘œğ‘›ğ‘–ğ‘¡ğ‘œğ‘Ÿğ‘’ğ‘‘ ğ‘›ğ‘œğ‘¡ ğ‘šğ‘œğ‘›ğ‘–ğ‘¡ğ‘œğ‘Ÿğ‘’ğ‘‘} 
ğ‘àµ«ğ‘œ(à¬µà¬¿à¬¶)à¸«ğ‘ (à¬¶)àµ¯=á‰‚ 0 0
âˆ’1 0á‰ƒ (16) 
 The simulations were performed with the updated model. We changed observation 
ğ‘œ(à¬µà¬¿à¬µ)  under each condition. Table 9 lists the simulation conditions and results of the 
action selection probability. The model variables that did not change in each condition 
were set the same as those in the model before modification and are shown in the 
Supporting Information. 
 
Table 9. Conditions of the simulation using the modified model and simulation results 
of action selection probability under each condition. 
 
s: states, o: observations, ğœà¬µà¬¿à¬µ : precision of Level 1-1 the likelihood mapping. 
Superscripts indicate the fields to which the variables belong.  
 
 The simulation results in Table 9 indicate that the probability of speaking up in 
Condition Observation 
ğ’(ğŸà¬¿ğŸ) 
Likelihood mapping 
ğ‘¨(ğŸà¬¿ğŸ):ğ’‘àµ«ğ’(ğŸà¬¿ğŸ)à¸«ğ’”(ğŸà¬¿ğŸ)àµ¯ 
Initial state prior 
ğ‘«(ğŸà¬¿ğŸ):ğ’‘(ğ’”(ğŸà¬¿ğŸ)) 
Probability 
of 
expressing 
an opinion  
1 Direct gaze ğœà¬µà¬¿à¬µ =0.2 
ğ‘àµ«ğ‘œ(à¬µà¬¿à¬µ)à¸«ğ‘ (à¬µà¬¿à¬µ)àµ¯
=á‰‚0.691 0.309
0.309 0.691á‰ƒ 
ğ‘àµ«ğ‘ (à¬µà¬¿à¬µ)àµ¯=á‰‚0.5
0.5á‰ƒ 0.0571 
2 Averted gaze  ğœà¬µà¬¿à¬µ =0.2 
ğ‘àµ«ğ‘œ(à¬µà¬¿à¬µ)à¸«ğ‘ (à¬µà¬¿à¬µ)àµ¯
=á‰‚0.691 0.309
0.309 0.691á‰ƒ 
ğ‘àµ«ğ‘ (à¬µà¬¿à¬µ)àµ¯=á‰‚0.5
0.5á‰ƒ 0.3729 
32 
 
condition 1 is lower than that in condition 2, so the high-status member (or the avatar 
robot) giving a direct gaze to the low-status members withholds their statements. The 
experimental result that sum2 was lower in the experimental groups than that in the control 
groups was supported by simulations with the updated model. 
  We believe that Participant 2â€™s withholding of statements led to the reduction of 
sum1 in the experimental groups. When Participant 2 did not say very much, Participant 1 
did not need to state much about the object. In addition, a significant positive correlation 
was found between sum2 and sum1 (r = 0.587, N = 20, p = 0.007).  
 The gaze behavior of the avatar robot was only performed before the free 
discussion, in which participants expressed their opinions. Nevertheless, gaze behavior 
significantly increased the presence of remote participants and influenced the statements 
of local participants in the free discussion. 
Conclusion 
 In this study, we formulated sense of presence as model evidence for inferring the 
mental states of others. We then proposed that gaze behavior should increase the sense of 
presence, which is the model evidence, to infer that the remote participant is attentive to 
the local participants. Simulations following the model predicted that gaze behavior would 
promote the local participantsâ€™ statements. We investigated whether the designed gaze 
behavior promoted local participantsâ€™ expressing an opinion using the meeting task that 
reproduced the discussion of a group with different standings. The experimental results 
suggest that the gaze behavior of the avatar robot significantly increases the presence of 
the remote participant, which restrains local participantsâ€™ from expressing an opinion in 
the context of the experimental task. 
The gaze behavior of the proposed avatar robot increased the presence of remote 
participants. We believe that gaze behavior can contribute to communication in a context 
where the presence of the remote participants has a positive effect. For example, when 
subordinates want to appeal to their skills or make a contribution to their boss, the presence 
of the boss will encourage the subordinatesâ€™ statements. In these cases, transforming the 
bossâ€™s behavior into the avatar robotâ€™s gaze behavior developed in this study may promote 
the subordinatesâ€™ statements. 
The finding that less attentive behavior while speaking promotes subordinatesâ€™ 
statements in this context can also be used for intervention by an avatar robot. The behavior 
33 
 
of an avatar robot can change in this context. The avatar robot may exhibit less attentive 
behavior in contexts where the presence of a boss exerts pressure and may exhibit the gaze 
behavior developed in this study in contexts where the presence of a boss encourages 
subordinates. Therefore, it is important to understand the appropriate presence of remote 
participants in each context. 
The experimental results showed that the presence of the remote participants 
restrained the local participantsâ€™ statements. This result is inconsistent with our hypothesis. 
However, this indicates that the presence of the model has sufficient influence to constrain 
the participantsâ€™ statements. In addition, previous studies [1][2] have taken the approach 
of increasing presence. However, as the current study shows, presence can have a negative 
effect on communication. Therefore, we argue that it is worthwhile to study the influence 
of presence and control methods using mathematical models. 
This study has some limitations. First, the experiment was conducted with only 
Japanese participants. The effects of an avatar robotâ€™s gaze behavior may be different in 
different cultures. Second, participants' prior knowledge of the robot's features was not 
standardized in this experiment. It is hypothesized that the perception of behavior will be 
different when participants believe that the robot reflects behavior of the remote 
participants and when they do not. 
 . 
Acknowledgments 
 We would like to express our sincere gratitude to Professor Tamotsu Murakami of 
the Department of Mechanical Engineering, School of Engineering, University of Tokyo, 
for his valuable comments during the workshop. 
 We express our sincere gratitude to Ryuichi Suzuki, Mari Yasuda, Naoki Nishida, 
Shin Shiroma, and other Sony Group employees for providing us with the necessary 
equipment for our research activities, consulting with the code used to implement the 
avatar robot's behavior, and for the helpful suggestions through meetings and the avatar 
robot experience. 
 We would like to express our sincere gratitude to Kazuhiro Oikawa, Principal 
Technical Specialist, for advising us on the facilities, equipment, and experimental 
environment and for preparing the research environment. 
 We would like to express our sincere thanks to Secretary Yuri Nozaki for her help 
34 
 
in handling the paperwork for the experimental participantsâ€™ rewards. 
 We would also like to express our sincere appreciation to all those who 
participated in the preliminary and main experiments of this study as well as those who 
helped us recruit participants. 
References 
1. Yankelovich N, Simpson N, Kaplan J, Provino J. Porta-person: telepresence for the 
connected conference room. ACM; 2007. https://doi.org/10.1145/1240866.1241080 
2. van Dijk B, Zwiers J, op den Akker R, Kulyk O, Hondorp H, Hofs D, et al. Conveying 
directional gaze cues to support remote participation in hybrid meetings. In: Toward 
Autonomous, Adaptive, and Context-Aware Multimodal Interfaces. Theoretical and 
Practical Issues. Berlin, Heidelberg: Springer Berlin Heidelberg, p. 412-28. 
https://doi.org/10.1007/978-3-642-18184-9_36 
3. Ogasawara KJ, Usuda T, Wu X, Hasegawa T, Hirako M, Fujita S, et al. Visual-
olfactory integration to enrich the digital experience. International Symposium on 
Affective Science and Engineering. 2022;ISASE2022(0):1 â€“4. 
https://doi.org/10.5057/isase.2022-C000033 
4. Kawaguchi I, Morita T, Kuzuoka H, Suzuki Y . Effect of gaze presented by 
telepresence robot with humanoid head on remote communication. Transactions of 
Human Interface Society. 2018;20(4):457-68. 
5. Heylen DKJ. Head gestures, gaze and the principles of conversational structure. 
International Journal of HR: Humanoid Robotics. 2006;3(11/3):241-67. 
https://doi.org/10.1142/S0219843606000746 
6. Hall JA, Horgan TG, Murphy NA. Nonverbal communication. Annual Review of 
Psychology. 2019;70(1):271-94. https://doi.org/10.1146/annurev-psych-010418-
103145 
7. Smith R, Friston KJ, Whyte CJ. A step-by-step tutorial on active inference and its 
application to empirical data. Journal of Mathematical Psychology. 2022;107:102632. 
https://doi.org/10.1016/j.jmp.2021.102632 
8. Stasser G, Titus W. Pooling of unshared information in group decision making: Biased 
information sampling during discussion. Journal of Personality and Social Psychology. 
1985;48(6):1467-78. https://doi.org/10.1037/0022-3514.48.6.1467 
9. Mitchell R, Nicholas S, Boyle B. The role of openness to cognitive diversity and group 
35 
 
processes in knowledge creation. Small Group Research. 2009;40(5):535-54. 
https://doi.org/10.1177/1046496409338302 
10. Schulz-Hardt S, Brodbeck FC, Mojzisch A, Kerschreiter R, Frey D. Group decision 
making in hidden profile situations: Dissent as a facilitator for decision quality. 
Journal of Personality and Social P sychology. 2006;91(6):1080-93. 
https://doi.org/10.1037/0022-3514.91.6.1080 
11. Garner JT, Iba DL. Changes in eye contact and attraction scores relative to ostracism 
and dissent. Small Group R esearch. 2015;46(1):3-26. 
https://doi.org/10.1177/1046496414550880 
12. Edmondson A. Psychological safety and learning behavior in work teams. 
Administrative Science Q uarterly. 1999;44(2):350 -83. 
https://doi.org/10.2307/2666999 
13. Shim S, Livingston RW, Phillips KW, Lam SSK. The impact of leader eye gaze on 
disparity in member influence: Implications for process and performance in diverse 
groups. Academy of Management J ournal. 2021;64(6):1873-900. 
https://doi.org/10.5465/amj.2017.1507 
14. Frischen A, Bayliss AP, Tipper SP. Gaze cueing of attention: Visual attention, social 
cognition, and individual differences. Psychological Bulletin. 2007;133(4):694-724. 
https://doi.org/10.1037/0033-2909.133.4.694 
15. Hirak R, Peng AC, Carmeli A, Schaubroeck JM. Linking leader inclusiveness to work 
unit performance: The importance of psychological safety and learning from failures. 
The Leadership Q uarterly. 2012;23(1):107 -17. 
https://doi.org/10.1016/j.leaqua.2011.11.009 
16. Parr T, Friston KJ. The anatomy of inference: Generative models and brain structure. 
Frontiers in Computational Neuroscience. 201 8;12:90-. 
https://doi.org/10.3389/fncom.2018.00090 
17. Richard W. Translated by Yoko G. The animatorâ€™s survival kit: Expanded 
Edition.Graphic-sha Publishing; 2011. 
18. Takafumi M. Animation as "Painting with Timeâ€: The artistic expression in 
â€œEvangelion: 2.0 You Can (Not) Advanceâ€ (2009) directed by Hideaki Anno. Jimbun 
ronkyu. 2012;61(4):99-125. 
19. Omori Y , Miyata Y . Estimates of impressions based on frequency of blinking. Social 
behavior and personality. 2001;29(2):159 -67. 
https://doi.org/10.2224/sbp.2001.29.2.159 
36 
 
20. Tost LP, Gino F, Larrick RP. When power makes others speechless: The negative 
impact of leader power on team performance. Academy of Management Journal. 
2013;56(5):1465-86. https://doi.org/10.5465/amj.2011.0180 
21. Tsutomu N, Iori T, Takafumi W, Ryuichi K, Ai N, Hiroyuki N. Development of a short 
form of the Japanese Big-Five Scale, and a test of its reliability and validityï¼ Japanese 
Journal of Psychology. 2012;83(2):91-9. https://doi.org/10.4992/jjpsy.83.91 
  
37 
 
Supporting Information 1 
S1 Text. Specific Implementation of the gaze behavior of the avatar robot. 2 
 Data was collected on the changes in head rotation, gaze, and blinking that 3 
accompany gaze behavior. The data were analyzed according to the situation. S2 Table 4 
shows the flow of the implemented gaze behavior. 5 
 Here, the data for the head rotation, gaze, and blink that were used in Behavior 6 6 
is described. The graphs of head rotation, gaze, and blink that were used in Behavior 6 are 7 
shown in S3â€“S5 Figs. 8 
 The head rotation data consisted of three angles: yaw (shake), pitch (nod), and roll 9 
(tilt). The three-axis actuator is rotated according to these three angles. In Behavior 6, the 10 
pitch was 0Â°, which corresponded to the angle of eye contact with the local participant, 11 
combined with the gaze. Roll did not change from 0Â°, indicating the lack of head tilt. The 12 
yaw changed from -20Â°, the angle at which the eyes met local participant 2, to 10Â°, the 13 
angle at which the eyes met local participant 1, at 0.52 s after the behavior onset. Owing 14 
to the eye design, the absolute value of the angle of eye contact with local Participant 1 15 
was smaller than that with local Participant 2. 16 
 The data for the change in yaw over 0.52 s were generated using the inverse 17 
tangent function, as shown in Eq. (S1). 18 
ğœ”= 10
à¬¶à¯§à¬¿à¬´.à¬¹
à¬´.à¬¶à¬¹
ğ‘¦ğ‘ğ‘¤=àµ
5,   ğ‘–ğ‘“ ğœ”= 1,
ğ‘¡ğ‘ğ‘›à¬¿à¬µ 2ğœğœ”
1 âˆ’ğœ”à¬¶ âˆ’ 20,ğ‘–ğ‘“ ğœ”â‰  1 (ğ‘†1) 19 
 The term t is the time from the beginning of the behavior, and Î¶ is a parameter that 20 
adjusts the slow-in/slow-out emphasis. The first term in the third row of Eq. (S1) is the 21 
inverted sign of the phase angle of the second-order delay element whose angular 22 
frequency is Ï‰ (ğº(ğ‘ )= à¬µ
à¯¦à°®à¬¾à¬¶à°à¯¦à¬¾à¬µ). Using Eq (S1), the emphasis of slow-in and slow-out 23 
can be adjusted while maintaining the time required for the yaw angle to change the 24 
constant. 25 
 The gaze data are represented as the position of the pupil in coordinates on the xy-26 
plane with 0â‰¤xâ‰¤100 and 0â‰¤yâ‰¤100. The pupil image is moved to the position defined by 27 
the xâ€“y coordinates in the eye display. The x-coordinate (horizontal coordinate) was 28 
38 
 
displaced linearly in the direction of gaze shift and then returned slightly in the opposite 29 
direction in a time (0.31 s) shorter than the change in yaw angle. This indicates that the 30 
eyes moved earlier than the head rotated. The y coordinate (vertical coordinate) was 31 
displaced vertically downward with a blink. These eye movements imitated the behavioral 32 
features discovered by analyzing the eye-gaze data logs obtained from the avatar robot. 33 
 The blink data is an integer between 0 and 100, representing the degree of eye 34 
opening. At 0, the avatar robot's eyes are meditative, and at 100, its eyes are fully open. 35 
Blinks were performed at the beginning of the yaw change and immediately before the end 36 
of the yaw change. These were implemented as blinks before and after the head swing. 37 
 The data of the other behaviors were created by applying the data of Behavior 6. 38 
 The avatar robot changed its behavior at the start, during breathing, and at the end 39 
of the speech of the remote participant, as shown in S5 Table. We coded the start of speech 40 
as the time when the 16-bit PCM value of the remote participant's input audio exceeded a 41 
certain value. The breath-hold timing was coded as the time in which the 16-bit PCM value 42 
of the remote participant's input audio fell below a certain value during Behaviors 2â€“6. 43 
The end of the remote participant's speech was defined as the time at which the participant 44 
pressed the button. 45 
 46 
S2 Table. Flow of the implemented gaze behavior of the avatar robot. 47 
Timing when gaze behavior takes place Behavior 
number 
Gaze behavior 
Before a remote participant speaks. 
(In the controlled group, the avatar robot 
performed Behavior 1 while the researcher 
was speaking.) 
1 Keep looking between two 
local participants. 
When a remote participant begins to speak. 2 Direct its gaze at local 
participant 1. 
After Behavior 2 or Behavior 6, until a 
remote participant takes a breath. 
3 K eep looking at local 
participant 1. 
When a remote participant takes a breath 
during Behavior 3. 
4 Direct its gaze at local 
participant 2. 
After Behavior 4, until a remote participant 
takes a breath. 
5 Keep looking at local 
participant 2. 
39 
 
When a remote participant takes a breath 
during Behavior 5. 
6 Direct its gaze at local 
participant 1. 
At the end of a remote participant's speech. 
If the avatar robot is in Behavior 3, Behavior 
7 starts; if the avatar robot is in Behavior 5, 
Behavior 8 starts. 
7,8 Direct its gaze between two 
local participants. 
 48 
 49 
S3 Fig. Head rotation of the avatar robot in Behavior 6. Using these data as input, we 50 
controlled the head rotation of the avatar robot. 51 
 52 
 53 
S4 Fig. Gaze of the avatar robot in Behavior 6. The gaze data are the pupil positions 54 

40 
 
expressed as coordinates in the xy-plane with 0â‰¤xâ‰¤100, 0â‰¤yâ‰¤100. The pupil positions of 55 
the two eyes are made to be the same. 56 
 57 
 58 
S5 Fig. Blink of the avatar robot in Behavior 6. The blink data were integers from 0 to 59 
100, representing the degree of eye opening; at 0, the avatar robot's eyes were closed, and 60 
at 100, they were fully open. 61 
 62 
