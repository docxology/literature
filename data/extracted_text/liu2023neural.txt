A Neural Network Implementation for Free
Energy Principle⋆
Jingwei Liu1[0009−0004−3160−9326]
University of California San Diego, La Jolla CA 92092, USA
Abstract. The free energy principle (FEP), as an encompassing frame-
work and a unified brain theory, has been widely applied to account for
various problems in fields such as cognitive science, neuroscience, social
interaction, and hermeneutics. As a computational model deeply rooted
in math and statistics, FEP posits an optimization problem based on
variational Bayes, which is solved either by dynamic programming or
expectation maximization in practice. However, there seems to be a bot-
tleneck in extending the FEP to machine learning and implementing such
models with neural networks. This paper gives a preliminary attempt at
bridging FEP and machine learning, via a classical neural network model,
the Helmholtz machine. As a variational machine learning model, the
Helmholtz machine is optimized by minimizing its free energy, the same
objective as FEP. Although the Helmholtz machine is not temporal, it
gives an ideal parallel to the vanilla FEP and the hierarchical model of
the brain, under which the active inference and predictive coding could
be formulated coherently. Besides a detailed theoretical discussion, the
paper also presents a preliminary experiment to validate the hypothesis.
By fine-tuning the trained neural network through active inference, the
model performance is promoted to accuracy above 99%. In the mean-
time, the data distribution is continuously deformed to a salience that
conforms to the model representation, as a result of active sampling.
Keywords: Helmholtz machine · Free energy Principle · Active infer-
ence · Hierarchical model
1 Introduction
Free Energy Principle (FEP) as an encompassing framework and a unified brain
theory [10] has been widely applied to account for various phenomena in many
cognition, humanity-related fields such as psychology[3], music[21], linguistic
communication[15], cultural niche construction[5], embodiment[1], autopoiesis[20],
emotion recognition[7]. In the meanwhile, as a computational model deeply
rooted in math and statistics, FEP posits an optimization problem based on vari-
ational Bayesian inference, which is solved either by dynamic programming[16]
or expectation maximization[9]. However, there seems to be a bottleneck in ex-
tending FEP to the fields of machine learning, which have been the hotspots
⋆ This work is done in Prof. Shlomo Dubnov’s experimental seminar.
arXiv:2306.06792v1  [cs.NE]  11 Jun 2023
2 J. Liu
for solving statistical and engineering problems in recent years. There are a few
works that bridge active inference and reinforcement learning[26], and here is a
survey on seeking the common ground for active inference and deep learning[23].
However, as a variational-based method, FEP cannot be seen equally, or be gen-
eralized trivially, to reinforcement learning, a reward-based training method.
This work gives a preliminary attempt at bridging FEP and machine learning,
via a classical neural network model, the Helmholtz machine. There are three
features of using the Helmholtz machine to study FEP under neural network
settings:
1. The Helmholtz machine uses variational free energy as its objective, which is
in accord with the FEP. In other words, we maintain the variational essence
of FEP by using a corresponding variational machine-learning method, which
minimizes the free energy.
2. If reinforcement learning is considered as capturing the qualities of expected
free energy, which involves planning and future outcomes of sequential events,
then the Helmholtz machine is a perfect parallel for the free energy. Although
the Helmholtz machine is not temporal, in many aspects, it’s an ideal proto-
type for implementing FEP and active inference in a neural network fashion,
which will be argued extensively in this paper.
3. The Helmholtz machine also presents a satisfactory simulation for the hierar-
chical model of the brain. The forward and backward connections and hierar-
chical message passing are inherent in the implementation of the Helmholtz
machine.
This paper includes two main sections. Section 2 gives a theoretical account
to the interrelationship of the free energy principle and the Helmholtz machine
from aspects of mathematical formulation, model training and parameter updat-
ing, biological interpretability and plausibility. It provides a theoretical basis for
generalizing FEP via the Helmholtz machine to broader model-fitting schemas
in the neural networks for machine learning. Section 3 presents a preliminary
experiment we designed to test the model. The model performs pretty well as
the theoretical analysis indicates. In training stage I, the Helmholtz machine
achieves an accuracy of 0.94 under traditional data fitting; In training stage II,
we apply the active inference in FEP to actively sample the input sensations
as salience. After a few rounds of fine-tuning, the model accuracy was boosted
above 0.99, which presents high generation accuracy while keeping generation
diversity at a satisfactory level.
2 Free Energy Principle and Helmholtz Machine
2.1 Variational Inference for Statistics
Here we give a brief overview of variational inference (VI)[2] in Bayesian statistics
and show how this concept is linked to the free energy principle and Helmholtz
A Neural Network Implementation for Free Energy Principle 3
machine. To maintain the notational consistency, we use the standard notations
in [6].
The goal is to determine the posteriorP(α|d), where d denotes the observable
data, and α is variously referred to as hidden causes, latent variables, or hidden
states. According to Bayes’ rule,
P(α|d) = P(α, d)
P(d) = P(α, d)R
α P(α, d)dα (1)
The integral over underlying causes is usually intractable (either unavailable
in closed form or requires exponential time to compute), so the true posterior
P(α|d) cannot be computed directly.
Remark 1. We give a separate account for the conditional data d in P(α|d).
In classical variational inference[2], d represents the entire dataset, thus the
latent distribution P(α|d) is independent of single data point, and all model
properties resort to latent local and global variables. Therefore, we can see that
an approximate posterior Q(α) is used to approximate the true posteriorP(α|d),
where Q is not conditioned on the observations. This formulation is widely used
in statistical variational inference and all resources I’ve read about the free energy
principle such as [11] [13] [25].
However, in many other settings, we frequently see that another form of
approximate posterior Q(α|d) is used, the most prominent case is in VAE [19].
In the Helmholtz machine, this conditional Q(α|d) is also used as approximate
posterior (it’s not explicitly given in [6], but in [18], it’s clearly stated). The main
reason is that the data d is treated point-wisely in these models, thus the latent
cause distributions conditioned on individual data points vary from each other.
However, as the distribution Q(α|d) is parameterized by ϕ, which is amortized
to all data points, the approximate posterior is still tractable and works a similar
way as in the unconditioned case.
As the Helmholtz machine is the model we adopt, we will use the conditioned
approximate posterior in the following discussions. In spirit, it differs little from
the vanilla version as the formula deduction unfolds. To recap, we use an ap-
proximate posterior Qϕ(α|d) to approximate the true posterior P(α|d), where
Qϕ(α|d) belongs to a parameterized family Qϕ of probability densities. Our goal
is to find the member of this family that minimizes Kullback-Leibler (KL) di-
vergence to the exact posterior,
Q∗
ϕ(α|d) = arg min
Qϕ(α|d)∈Qϕ
DKL[Qϕ(α|d)||P(α|d)] (2)
The variational method kicks in when we decompose the true posterior in
the KL-divergence term,
DKL[Qϕ(α|d)||P(α|d)] = EQ[log Qϕ(α|d)] − EQ[log P(α|d)] (3)
= EQ[log Qϕ(α|d)] − EQ[log P(α, d)] + logP(d) (4)
4 J. Liu
The distribution P(α, d) is called the generative model, as it denotes the joint dis-
tribution of the latent and observable variables. The generative model is usually
assumed as known in VI and FEP, as the way environment generates observa-
tions from causes is innate.
Now the problem falls on the third term in Equation (4), what we call the
log-evidence, or negative surprisal, log P(d). This term is again intractable, so
to circumvent it, we use the nonnegativity of KL-divergence, rewrite (4) as
log P(d) ≥ EQ[log P(α, d)] − EQ[log Qϕ(α|d)] (5)
where the right-hand side term EQ[log P(α, d)] − EQ[log Qϕ(α|d)] is called the
evidence lower bound (ELBO). By maximizing ELBO we implicitly maximize
the log-evidence log P(d). The free energy is given by the negative ELBO,
F = EQ[log Qϕ(α|d)] − EQ[log P(α, d)] = DKL[Qϕ(α|d)||P(α, d)] (6)
which is the ultimate minimization goal in VI, FEP, and the Helmholtz machine.
Remark 2. The minimization term F is seen as a compromise in VI. Since we
cannot minimize DKL[Qϕ(α|d)||P(α|d)] directly, we find some cheap approxi-
mation that we can compute. However, I claim it’s not the case for generative
models. In generative models which use generation as an organic component of
model construction, the generative density P(α, d) is a necessity instead of the
posterior P(α|d), since we are not only finding the best set of parameters in a
density family that approximates a given distribution, but also using generated
samples to regulate the recognition process (Helmholtz machine, VAE) or active
sampling the generations to improve accuracy (FEP).
In Helmholtz machine, instead of pre-defining a generative model P(α, d), in
a more realistic way (since the generative density is usually unknown in real-life
problems), we parameterize this distribution by θ, and construct the free energy
minimization goal
F = DKL[Qϕ(α|d)||Pθ(α, d)] (7)
By jointly optimizing the two sets of parameters ϕ and θ in an EM (expectation-
maximization) manner, we minimize the free energy of the system.
In FEP, the free energy is reformulated as the two equations,
F = DKL[Qϕ(α|d)||P(α|d)] − log P(d) (8)
= DKL[Qϕ(α|d)||P(α)] − EQ[log P(d|α)] (9)
Equation (8) is interpreted from its first term as optimizing the recognition
density of the brain to approximate the true distribution of the world, which
shares the same goal as VI, minimizing DKL[Qϕ(α|d)||P(α|d)]; Equation (9) is
interpreted more inclined to its second term, EQ[log P(d|α)], as a way to actively
sample the sensory inputs that conform to the current representations, thus
improving accuracy (please refer to [10] for more details). In this work, we will
integrate the classical Helmholtz machine which is trained under minimization of
A Neural Network Implementation for Free Energy Principle 5
variational free energy with the active inference in FEP. Besides the parameter
optimization, the model also performs active inference by a selective sampling
of the environment, which entails a modulation of attention reflected in the
distribution of evidence.
2.2 Neural Network for Machine learning
This work explores a way of implementing FEP using neural networks in ma-
chine learning. Traditionally, problems formulated under FEP are either solved
by DEM (dynamic expectation-maximization)[12] or MDP (Markov decision
process)[25]. Although the Helmholtz machine is not a temporal model, it uses
real neurons specified by modern neural networks and updates its parameters
via gradient descent. Under the current world trend, we believe it’s imperative
to extend FEP to the machine learning field and to solve problems using neural
network architectures.
Fig. 1.The Helmholtz Machine. The Helmholtz Machine is a fully connected feed-
back neural network with hierarchical architecture. The solid lines show the bottom-
up recognition process parameterized by ϕ, and the dashed lines show the top-down
generation process parameterized by θ. The activity of each neuron is computed from
the activities of all neurons in its previous layer. The activation functions are given in
the text.
The structure of the Helmholtz machine is shown in Fig. 1. It’s a layered
hierarchical model composed of stochastic binary neurons, connected by bottom-
up recognition weights ϕ and top-down generative weights θ. In this work, we
did two major modifications to the original model in [6],
1. The activity of the stochastic binary neuron is changed from{0, 1} to {−1, 1}.
6 J. Liu
2. The bias is added when computing the linear activation of each neuron.
The first modification is done due to the derivative form of F with respect to
its parameters, for example, ∂F
∂θm+1,m
k,n
= −sm+1
k (sm
n − pm
n ). The neuron activity
from the previous layer is used as a multiplier on the derivatives, which means if
sm+1
k = 0, the gradient equals zero, thus no updating will be performed for this
parameter θm+1,m
k,n by gradient descent. Therefore, the parameter updating will
be half paralyzed when neuron activities alternate between 0 and 1. To make
the learning more efficient, we replace the activity value 0 with −1, thus zero
gradients won’t occur unless pm
n approaches sm
n .
The Helmholtz machine is fully connected. The activation of each neuron is
a linear combination of all the neurons from its previous layer plus bias,
am
n (θ, sm+1) =
X
k
θm+1,m
k,n sm+1
k + bm+1,m
n (10)
where the activation of the n-th neuron in layer m is computed by a weighted
sum of all activities sm+1
k in layer m+1 weighted by its corresponding parameter
θm+1,m
k,n , plus the biasbm+1,m
n for this neuron. Here the previous layer is the upper
layer m + 1, which corresponds to the top-down generative process indicated by
dashed lines in Fig. 1. We added the bias term to the original formulation to
expand the parameter set, thus endowing more freedom for the neural network
to fit the data.
The probability is calculated by the sigmoid function σ(x) = 1/(1 + e−x) of
activation, which nonlinearly compresses the range into (0 , 1).
pm
n (θ, sm+1) = σ(am
n ) = σ(
X
k
θm+1,m
k,n sm+1
k + bm+1,m
n ) (11)
Similarly, the activation probability of a neuron in the bottom-up recognition
process is computed as
qm
n (ϕ, sm−1) = σ(
X
k
ϕm−1,m
k,n sm−1
k + bm−1,m
n ) (12)
where the previous layer is the lower layer m −1, and the probability is denoted
with q. The notations are consistent with our notations in Equation (7). The
recognition density Qϕ(α|d) and the generative density Pθ(α, d) are computed
by the product of the probabilities of all neurons, namely
Qϕ(α|d) =
Y
m>1
Y
n
[qm
n (ϕ, sm−1)]
1+sm
n
2 [1 − qm
n (ϕ, sm−1)]
1−sm
n
2 (13)
Pθ(α, d) =
Y
m≥1
Y
n
[pm
n (θ, sm+1)]
1+sm
n
2 [1 − pm
n (θ, sm+1)]
1−sm
n
2 (14)
Each neuron gives a Bernoulli distribution as the activity of sm
n takes value −1
or 1.
A Neural Network Implementation for Free Energy Principle 7
As the explicit form of the free energy F = DKL[Qϕ(α|d)||Pθ(α, d)] is given
by equations (13) (14), now we should consider how to compute the derivatives
of Fϕ,θ thus minimizing this term by gradient descent. If we refer back to the
structure of the Helmholtz machine in Fig. 1, we can see the neurons are con-
nected recurrently. Besides that, the change of activities in one layer will affect
the behavior of all neurons in higher layers, which makes backpropagation ex-
tremely difficult. To tackle this problem, a customized algorithm is designed for
training this system, which is the wake-sleep algorithm [18].
The wake-sleep algorithm disentangles the recognition parameters ϕ and the
generative parameter θ by separating the training into two phases. In the wake
phase, the bottom-up recognition process is performed using the current weights
ϕ to get an instance of complete neuron assignments α by sampling activities
from {−1, 1} based on the probability of each neuron qm
n . Now we update the
generative parameters θ based on the complete neuron activities encoded in α,
which makes the target values available for training the hidden units locally, thus
disentangling them from the multi-layer coupling. In the sleep phase, the recog-
nition weights ϕ are turned off and a random instance is generated based on the
current top-down weights θ. Alternatively, we update ϕ according to the neu-
ron assignments of this generated instance while keeping the generative weights
fixed. By iterating the wake and sleep phases, updating ϕ and θ alternatively,
the objective function Fϕ,θ is minimized in an EM manner.
Now let’s compute the derivatives of Fϕ,θ with respect to the generative
weights. We can write out Equation (7) as
F = EQϕ[log Qϕ(α|d)] − EQϕ[log Pθ(α, d)] (15)
Since ϕ and θ are decoupled, the first term in Equation (15) is constant when
computing ∂F
∂θ , thus we write out the second term as
EQϕ[log Pθ(α, d)] =
X
α
Qϕ(α|d) logPθ(α, d) (16)
As the latent cause α is generated by random sampling as a single instance, the
summation over all possible hidden causes in Equation (16) is ignored with the
weighting term Qϕ(α|d), thus the objective is further simplified as
log Pθ(α, d) =
X
m≥1
X
n
(1 + sm
n
2 log[pm
n (θ, sm+1)] + 1 − sm
n
2 log[1 − pm
n (θ, sm+1)])
(17)
If we plug in Equation (11) and calculate its derivatives with respect to θ and
b, we easily derive the local delta rule,
∂F
∂θm+1,m
k,n
= −sm+1
k (sm
n − pm
n ) (18)
∂F
∂bm+1,m
n
= −(sm
n − pm
n ) (19)
8 J. Liu
To update the recognition weights ϕ in the sleep phase, we exchange the relative
positions of P and Q, using ˜F = EPθ [log Pθ(α, d)] − EPθ [log Qϕ(α|d)] as a mod-
ified objective function, then the similar deductions follow which give the same
local delta rules for recognition weights. Finally, all the parameters are updated
by gradient descent x = x − γ ∂f
∂x , where γ is the learning step size.
Remark 3. From the derivation of the local delta rule we can tell, by decou-
pling the forward and backward passes, and updating based on a single sampled
instance, the objective function is simplified too much to be considered as varia-
tional or free-energy. However, this working algorithm is computationally cheap
and efficient, and it approximates the true objective in an ensemble sense, which
means the system minimizes the variational free energy after enough rounds of
iterations with sufficient accuracy (probably converges to a local minima instead
of the global minima).
Remark 4. The local delta rule is the simplest updating rule we could derive
from Equation (15). If we keep the weighting termQϕ(α|d) in Equation (16), the
local delta rule will also be weighted by this term, which gives what we call the
weighted local delta rule. In [6], another rule is given by replacing the stochastic
neuron activities with their holistic mean, which is the calculated probabilities of
neuron activations. In our preliminary experiments, we started with the classical
local delta rules. The comparison and evaluation of all updating rules will be
reserved for future work.
Here we present a brief account of the two-phase training mechanism of the
Helmholtz machine in comparison to the VAE. The Helmholtz machine is widely
acknowledged as the predecessor of VAE and both neural networks resort to vari-
ational machine learning. Instead of alternative two-phase training, VAE uses
a single objective function that jointly optimizes the recognition and genera-
tive processes. The advantage of the wake-sleep algorithm, for our application
purposes, mainly lies in three areas:
1. The decoupling of recognition and generation spares a whole lot of space
for creative manipulation and subtle mediation between these two processes,
thus available the ground for studying computational creativity and foraging
artistic usage of the model (future directions).
2. The idea of analysis-by-synthesis and inverting the hierarchical model in
real-time make active inference and real-time modifications possible. One of
the biggest differences between the Helmholtz machine and the VAE is that
the generation in the Helmholtz machine is unconstrained. It’s not subject to
the maximum likelihood and any generated sample could be used to update
the model parameters. In other words, the Helmholtz machine presents more
flexibility in the training process, a desired feature to serve our purposes.
3. The hierarchical structure and forward-backward connections in the Helmholtz
machine are a good parallel for the cortical hierarchies in our brain. This
point be illustrated in more detail in the following arguments.
A Neural Network Implementation for Free Energy Principle 9
2.3 Hierarchical Model for the Brain
It’s contended extensively in FEP-related works that the cortical responses in
our brain observe a hierarchical model with forward and backward connections,
where the forward driving connections convey prediction errors from a lower
area to a higher area, and nonlinear backward connections construct predictions
[8] [9] [12]. The brain trying to infer the causes of its sensory inputs and gener-
ating corresponding sensations is also a prevailing idea in FEP. As the author
doesn’t have a real background in neurobiology, the statements in this subsec-
tion couldn’t be presented with too much precision or detail. But in general, the
idea of analysis-by-synthesis is well demonstrated in the Helmholtz machine, and
Hinton pointed out that one of their motivations for developing the Helmholtz
machine is inspired by Friston’s cortical hierarchy theory [17]. In [12], Friston
also cited the paper on the Helmholtz machine [6]. By this cross-referencing, we
believe there is enough evidence to link the brain architecture to the Helmholtz
machine, and study the brain functions such as predictive coding, message pass-
ing, and predictive processing via the Helmholtz machine, at least at a reasonable
metaphorical level. Two preliminary comments could be made at this stage by
the working mechanism of the Helmholtz machine, while the validation and more
systematic discussions could only be realized after the numerical experiments are
carried out and a detailed examination is applied in future work.
1. In predictive processing [4], the processing of sensory inputs goes both ways
within the hierarchical model. Besides the bottom-up passive pattern recog-
nition of the stimuli, the brain also actively constructs the predictions via
top-down connections. The backward connections regulate the precision of
prediction errors that allow the system to cope with noisy and ambiguous
sensory inputs. In other words, the separate treatment of forward and back-
ward connections, which correspond to the wake and sleep phases in the
Helmholtz machine, is imperative to study PP (predictive processing) and
PC (predictive coding) related brain functions. Besides, due to the functional
asymmetry of forward and backward connections in the brain[12], where
backward connections are more modulatory or nonlinear in their effects on
neuronal responses, it’s also advantageous to decouple the two processes and
treat them separately, which allow more flexibility.
2. In hierarchical message passing, the synapses are characterized by their lo-
cal efficacy. It means that the prediction errors are resolved by each neuron
locally, which only receives responses from neurons at its current and pre-
ceding levels. This local efficacy well corresponds to the local delta updating
rules derived in the Helmholtz machine. This condition is important because
it permits a biologically plausible implementation, where the connections
driving inference run only between neighboring levels [8].
3 Experiment
The preliminary experiment is designed by a 4-layer Helmholtz machine, with
10, 8, 5, 3 neurons in each layer respectively (see Fig. 2). This section will present
10 J. Liu
a detailed experimental setup with data design and two-stage training, as well
as the experimental result which preserves adequate generative diversity, while
boosting the generation accuracy above 0.99 in the meantime (please see the
codes in my GitHub).
3.1 Training Stage I: Experimental Setup
Fig. 2.Helmholtz Machine with Active Inference. The experiment is implemented with
a 4-layer Helmholtz machine, with 10 , 8, 5, 3 neurons in each layer ascendingly. In the
sleep phase, activities in layer 4 are generated by generative bias from unity. The
training is implemented in two stages. In stage I, as the single lines connecting the
training set and the model on the left side indicate, the inputs are from the well-
formed region and the generations are unconstrained, which falls anywhere in the entire
space; in stage II, the parameters are fine-tuned by restricting the generations within
the well-formed region while actively deforming the input distribution based on the
model generations (double lines on the right side), resulting in the selected region that
conforms to the latent model representations.
A Neural Network Implementation for Free Energy Principle 11
The data design is inspired by the phenotypic boundary discussed in [14].
For a phenotype to exist it must possess defining characteristics or traits. These
traits essentially limit the agent to a bounded region in the space of all states
it could be in. Once outside these bounds, it ceases to possess that trait (cf, a
fish out of water). This bounded region corresponds to the well-formed region in
Fig. 2 and the entire space represents all possible states of the world.
To construct a valid subset of all 1024 possibilities of the combination of
binary-valued first-layer data neurons (2 10), we devise three well-formed rules
inspired by the musical gestalt. Metaphorically, we consider the 10 neurons as
a 10-note sequence, which represents a rhythmic pattern – 0 or −1 denotes the
rest (we will use 0 for discussion convenience but in numerical implementation
it’s always replaced by −1) and 1 denotes a percussive attack. Then the rules
entail, what is a valid rhythmic pattern?
Rule 1 The sequence always starts with 1.
Rule 2 Forbid single event that’s strongly isolated from other groups (00100),
and also avoid isolated event at the beginning (100) and the end (001) of the
sequence.
Rule 3 Forbid the extended break (0000).
We won’t give further explanations for the designing logic for these rules, but we
refer the readers who are interested to [22] for a better understanding of musical
grouping structures.
The advantage of rule-based generation is that, we have a metric to assess the
goodness of the generated samples by simply checking them against the rules,
thus the model performance could be measured with certainty. In training stage
I, we use this generated well-formed set as inputs, and update the recognition
weights with arbitrarily generated instances (see the single lines connecting the
data and machine on the left side in Fig. 2). As explained in [18], the model
aims to find the economical latent representations that prescribe the minimum
description length. After sufficient iterations, the generation accuracy reached
0.94 ±0.01, and couldn’t be further improved by repeating the current training.
3.2 Training Stage II: Active Inference
In training stage II, we fine-tune the model trained in stage I by active inference,
which boosted the generation accuracy to 0 .99+ with only 200 rounds of itera-
tions. In this stage, the generated instances in the sleep phase are filtered by the
well-formed rules, thus only valid generations within the phenotypic bounds are
accepted to train the recognition weights. In the meantime, the valid generations
are maintained to actively modify the distribution of the input set. The more an
instance is generated, the more salient it becomes in the evidence distribution.
This distribution modification could be viewed either as salience[24], in a
similar way of executing eye movements to sample the sensations that conform
to the agent’s expectations; or as niche construction[27], that renders real mod-
ifications on the environment such as the ”desire path”. Either way, the data
12 J. Liu
distribution changes due to active inference, thus the given input data (data
in the well-formed region) becomes actively sampled data (data in the selected
region) that reflects the current representations in the ”brain” (see the double
lines on the right side connecting the data and machine in Fig. 2).
Fig. 3.Reconfigured Data Distribution by Active Sampling. The well-formed set gives
a uniform initial distribution over all valid data points (in blue), which is continuously
deformed to the distribution in orange by active sampling.
The input data distribution is described in Fig. 3. The FEP-based active
training continuously deforms the uniform equal-probability distribution of the
initial dataset (in blue) to the active sampled distribution (in orange) that fits
the internal representation and capacity of the machine. After this second-stage
fine-tuning, the Helmholtz machine is able to generate almost 100% accurate
samples with a more focused range within all possibilities of the well-formed set
while keeping generative diversity to a satisfactory degree.
References
1. Allen, M., Friston, K.J.: From cognitivism to autopoiesis: towards a computa-
tional framework for the embodied mind. Synthese 195(6), 2459–2482 (2018).
https://doi.org/10.1007/s11229-016-1288-5
2. Blei, D.M., Kucukelbir, A., McAuliffe, J.D.: Variational Inference: A
Review for Statisticians. arXiv e-prints arXiv:1601.00670 (Jan 2016).
https://doi.org/10.48550/arXiv.1601.00670
3. Carhart-Harris, R.L., Friston, K.J.: The default-mode, ego-functions and free-
energy: a neurobiological account of freudian ideas. Brain 133(4), 1265–1283
(2010). https://doi.org/10.1093/brain/awq010
4. Clark, A.: Radical predictive processing. Southern Journal of Philosophy 53, 3–27
(2015). https://doi.org/10.1111/sjp.12120
A Neural Network Implementation for Free Energy Principle 13
5. Constant, A., Ramstead, M.J., Veissiere, S.P., Campbell, J.O., Friston, K.J.: A
variational approach to niche construction. Journal of the Royal Society Interface
15(141), 20170685 (2018). https://doi.org/10.1098/rsif.2017.0685
6. Dayan, P., Hinton, G.E., Neal, R.M., Zemel, R.S.: The helmholtz machine. Neural
computation 7(5), 889–904 (1995). https://doi.org/10.1162/neco.1995.7.5.889
7. Demekas, D., Parr, T., Friston, K.J.: An investigation of the free energy principle
for emotion recognition. Frontiers in Computational Neuroscience 14, 30 (2020).
https://doi.org/10.3389/fncom.2020.00030
8. Friston, K.: A theory of cortical responses. Philosophical transactions
of the Royal Society B: Biological sciences 360(1456), 815–836 (2005).
https://doi.org/10.1098/rstb.2005.1622
9. Friston, K.: Hierarchical models in the brain. PLoS computational biology 4(11),
e1000211 (2008). https://doi.org/10.1371/journal.pcbi.1000211
10. Friston, K.: The free-energy principle: a unified brain theory? Nature reviews neu-
roscience 11(2), 127–138 (2010). https://doi.org/https://doi.org/10.1038/nrn2787
11. Friston, K., FitzGerald, T., Rigoli, F., Schwartenbeck, P., ODoherty, J., Pezzulo,
G.: Active inference and learning. Neuroscience and Biobehavioral Reviews 68,
862–879 (2016). https://doi.org/https://doi.org/10.1016/j.neubiorev.2016.06.022,
https://www.sciencedirect.com/science/article/pii/S0149763416301336
12. Friston, K., Kiebel, S.: Predictive coding under the free-energy principle. Philo-
sophical transactions of the Royal Society B: Biological sciences 364(1521), 1211–
1221 (2009). https://doi.org/10.1098/rstb.2008.0300
13. Friston, K., Rigoli, F., Ognibene, D., Mathys, C., Fitzgerald, T., Pezzulo, G.:
Active inference and epistemic value. Cognitive Neuroscience6(4), 187–214 (2015).
https://doi.org/10.1080/17588928.2015.1020053, pMID: 25689102
14. Friston, K.J., Daunizeau, J., Kiebel, S.J.: Reinforcement learning or active infer-
ence? PloS one 4(7), e6421 (2009). https://doi.org/10.1371/journal.pone.0006421
15. Friston, K.J., Parr, T., Yufik, Y., Sajid, N., Price, C.J., Holmes, E.: Generative
models, linguistic communication and active inference. Neuroscience & Biobehav-
ioral Reviews 118, 42–64 (2020). https://doi.org/10.1016/j.neubiorev.2020.07.005
16. Friston, K.J., Rosch, R., Parr, T., Price, C., Bowman, H.: Deep temporal models
and active inference. Neuroscience & Biobehavioral Reviews 90, 486–501 (2018).
https://doi.org/10.1016/j.neubiorev.2017.04.009
17. Hinton, G.E.: Lecture 13.4 - the wake sleep algorithm (2017), https:
//www.youtube.com/watch?v=FBkhbqrFyo4&list=PLLssT5z_DsK_gyrQ_
biidwvPYCRNGI3iv&index=63
18. Hinton, G.E., Dayan, P., Frey, B.J., Neal, R.M.: The” wake-sleep” algo-
rithm for unsupervised neural networks. Science 268(5214), 1158–1161 (1995).
https://doi.org/10.1126/science.7761831
19. Kingma, D.P., Welling, M.: Auto-Encoding Variational Bayes. arXiv e-prints
arXiv:1312.6114 (Dec 2013). https://doi.org/10.48550/arXiv.1312.6114
20. Kirchhoff, M., Parr, T., Palacios, E., Friston, K., Kiverstein, J.: The
markov blankets of life: autonomy, active inference and the free energy
principle. Journal of The royal society interface 15(138), 20170792 (2018).
https://doi.org/10.1098/rsif.2017.0792
21. Koelsch, S., Vuust, P., Friston, K.: Predictive processes and the pe-
culiar case of music. Trends in cognitive sciences 23(1), 63–77 (2019).
https://doi.org/10.1016/j.tics.2018.10.006
22. Lerdahl, F., Jackendoff, R.S.: A Generative Theory of Tonal Music, reissue, with
a new preface. MIT press (1996)
14 J. Liu
23. Mazzaglia, P., Verbelen, T., C ¸ atal, O., Dhoedt, B.: The free energy principle for
perception and action: A deep learning perspective. Entropy 24(2), 301 (2022).
https://doi.org/10.3390/e24020301
24. Parr, T., Friston, K.J.: Attention or salience? Current opinion in psychology 29,
1–5 (2019). https://doi.org/10.1016/j.copsyc.2018.10.006
25. Parr, T., Friston, K.J.: Generalised free energy and active inference. Biological
cybernetics 113(5-6), 495–513 (2019). https://doi.org/10.1007/s00422-019-00805-
w
26. Tschantz, A., Millidge, B., Seth, A.K., Buckley, C.L.: Reinforcement
learning through active inference. arXiv preprint arXiv:2002.12636 (2020).
https://doi.org/10.48550/arXiv.2002.12636
27. Veissi` ere, S.P.L., Constant, A., Ramstead, M.J.D., Friston, K.J., Kir-
mayer, L.J.: Thinking through other minds: A variational approach to
cognition and culture. Behavioral and Brain Sciences 43, e90 (2020).
https://doi.org/10.1017/S0140525X19001213