Active inference, eye movements and oculomotor
delays
Laurent U. Perrinet1,2, Rick A. Adams2 and Karl J. Friston2
1Institut de Neurosciences de la Timone , CNRS / Aix-Marseille
Universit´ e - Marseille, France
2The Wellcome Trust Centre for Neuroimaging , University College
London - London, UK.
Keywords
Oculomotor delays; tracking eye movements; smooth pursuit eye movements;
generalized coordinates; perception; Bayesian ﬁltering; variational free energy;
active inference
Abstract
This paper considers the problem of sensorimotor delays in the optimal con-
trol of (smooth) eye movements under uncertainty. Speciﬁcally, we consider
delays in the visuo-oculomotor loop and their implications for active inference.
Active inference uses a generalisation of Kalman ﬁltering to provide Bayes opti-
mal estimates of hidden states and action in generalized coordinates of motion.
Representing hidden states in generalized coordinates provides a simple way
of compensating for both sensory and oculomotor delays. The eﬃcacy of this
scheme is illustrated using neuronal simulations of pursuit initiation responses,
with and without compensation. We then consider an extension of the gener-
ative model to simulate smooth pursuit eye movements — in which the visuo-
oculomotor system believes both the target and its centre of gaze are attracted
to a (hidden) point moving in the visual ﬁeld. Finally, the generative model is
equipped with a hierarchical structure, so that it can recognise and remember
unseen (occluded) trajectories and emit anticipatory responses. These simula-
tions speak to a straightforward and neurobiologically plausible solution to the
generic problem of integrating information from diﬀerent sources with diﬀer-
ent temporal delays and the particular diﬃculties encountered when a system
— like the oculomotor system — tries to control its environment with delayed
signals.
1
arXiv:1610.05564v1  [q-bio.NC]  18 Oct 2016
1 Introduction
1.1 Problem statement
This paper considers optimal motor control and the particular problems caused
by the inevitable delay between the emission of motor commands and their sen-
sory consequences. This is a generic problem that we illustrate within the con-
text of oculomotor control where it is particularly prescient (see for instance (Ni-
jhawan, 2008) for a review). Although we focus on oculomotor control, the more
general contribution of this work is to treat motor control as a pure inference
problem. This allows us to use standard (Bayesian ﬁltering) schemes to resolve
the problem of sensorimotor delays — by absorbing them into a generative or
forward model. Furthermore, this principled and generic solution has some
degree of biological plausibility because the resulting active (Bayesian) ﬁlter-
ing is formally identical to predictive coding, which has become an established
metaphor for neuronal message passing in the brain. We will use oculomotor
control as a vehicle to illustrate the basic idea using a series of generative models
of eye movements — that address increasingly complicated aspects of oculomo-
tor control. In short, we oﬀer a general solution to the problem of sensorimotor
delays in motor control — using established models of message passing in the
brain — and demonstrate the implications of this solution in the particular
setting of oculomotor control.
The oculomotor system produces eye movements to deploy sensory (retinal)
epithelia at very fast timescales. In particular, changes in the position of a
visual object are compensated for with robust and rapid eye movements, such
that the object is perceived as invariant, despite its motion (Ilg, 1997; Lisberger,
Morris, and Tychsen, 1987). This near-optimal control is remarkable, given the
absence of any external clock to coordinate dynamics in diﬀerent parts of the
visual-oculomotor system. An important constraint, in this setting, is axonal
conduction, which produces delays in sensory and motor signalling within the
oculomotor system. Figure 1 shows that in humans, for example, retinal signals
arriving at motion processing areas report the state of aﬀairs at least about
50 ms ago, while the action that follows is executed at least 40 ms in the fu-
ture (Inui and Kakigi, 2006); for a review, see (Masson and Ilg, 2010). Diﬀerent
sources of delays exist – such as the biomechanical delay between neuromuscular
excitation and eye movement. Due to these delays, the human smooth pursuit
system responds to unpredictable stimuli with a minimum latency of around
100 ms (Wyatt and Pola, 1987). In addition, these delays may produce oscil-
lations about a constant velocity stimulus (Robinson, 1965; Robinson, Gordon,
and Gordon, 1986), whose amplitude and frequency can be altered by artiﬁcially
manipulating the feedback (Goldreich, Krauzlis, and Lisberger, 1992).
Eye movements can anticipate predictable stimuli, such as the sinusoidal
movement of a pendulum (Barnes and Asselman, 1991; Dodge, Travis, and Fox,
1930; Westheimer, 1954); for a review, see (Barnes, 2008). Interestingly, ocu-
lar tracking can compensate for sensorimotor delays after around one or two
periods of sinusoidal motion – producing a tracking movement with little dis-
cernible delay (Barnes and Asselman, 1991). This suggests that the oculomotor
system can use sensory information from the past to predict its future sensory
states (including its actions), despite the fact that these sensory changes can
be due to both movement of the stimulus and movement of the eyes. The
2
time taken to compensate for delays increases with the unpredictability of the
stimulus (Michael and Jones, 1966), though the system can adapt quickly to
complex waveforms, with changes of velocity (Barnes and Schmid, 2002), single
cycles (Barnes, Barnes, and Chakraborti, 2000) or perturbed periodic waves –
where subjects appear to estimate their frequency using an average over recent
cycles (Collins and Barnes, 2009). Further studies suggest that diﬀerent sources
of information, such as auditory or verbal cues (Kowler, 1989) or prior knowl-
edge about the nature of sensory inputs (Montagnini, Spering, and Masson,
2006) can evoke anticipatory eye movements.
The aim of this work was to establish a principled model of optimal visual
motion processing and oculomotor control in the context of sensorimotor delays.
Delays are often ignored in treatments of the visual-oculomotor system; how-
ever, they are crucial to understanding the system’s dynamics. For instance,
delays may be important for understanding the pathophysiology of impaired
oculomotor control: schizophrenic smooth pursuit abnormalities are due to im-
pairments of the predictive (extra-retinal) motion signals that are required to
compensate for sensorimotor delays (Nkam et al., 2010; Thaker et al., 1999).
Surprisingly, delays may also explain a whole body of visual illusions (Changizi,
2001; Changizi and Widders, 2002; Changizi et al., 2008; Vaughn and Eagleman,
2013), even for visual illusions that involve a static display. Delays are also an
important consideration in control theory and engineering. Finally, neuronal
solutions to the delay problem speak to the representation of time in the brain,
which is essential for the proper fusion of information in the central nervous
system.
1.2 Existing solutions and the proposed hypothesis
A principled approach to optimal oculomotor control is provided by Bayesian ﬁl-
tering schemes that use probabilistic representations to estimate visual and ocu-
lomotor states. These states are hidden; i.e., they cannot be measured directly.
A popular scheme for linear control problems is the Kalman ﬁlter (Kalman,
1960). The Kalman scheme can be extended to accommodate biomechanical con-
straints, such as transmission delays (e.g., ﬁxed-lag smoothers). However, their
solutions can become computationally complex when delays are large in rela-
tion to discretisation time and are not biologically plausible. We have previously
considered generalized Bayesian ﬁltering in continuous time as a metaphor for
action and perception. This approach has been applied to eye movements (Fris-
ton et al., 2010b) and saccades in particular (Friston et al., 2012). However,
these applications ignored sensorimotor delays and their potentially confound-
ing eﬀects on optimal control.
Crucially, the active inference schemes we have considered previously are
formulated using representations in generalized coordinates of motion ; that is,
states (such as position) are represented along with their higher order tempo-
ral derivatives (such as speed, acceleration, jerk, etc). This means that one
has an implicit representation of hidden states in the recent past and future
that can be used to ﬁnesse the problems of delays. For example, it has been
shown that acceleration is a necessary component of the predictive drive to eye
movements (Bennett et al., 2007). In brief, generalized representations can be
projected to the past and to the future using simple (linear) mixtures of gener-
alized motion. Note that a representation of generalized motion can be explicit
3
or implicit by using a population coding scheme – as has been demonstrated for
acceleration (Lisberger and Movshon, 1999). Representations of generalized mo-
tion may be important for modelling delays when integrating information in the
brain from distal sources – such as other cortical columns in the same cortical
area or other areas that are connected with ﬁxed but diﬀerent delays (Roelf-
sema et al., 1997). The integration of information over time becomes particularly
acute in motor control, where the products of sensory processing couple back
to the sampling of sensory information through action.
In the context of action, acted inference ﬁnesses the problems with delayed
control signals in classical formulations of motor control by replacing command
signals with descending cortico-spinal predictions. For instance, the location of
receptive ﬁelds in the parietal cortex in monkeys is shown to shift transiently be-
fore an eye movement (Duhamel, Colby, and Goldberg, 1992). These predictions
are fulﬁlled at the peripheral level, using fast closed loop mechanisms (periph-
eral reﬂex arcs). In principle, “these predictions can anticipate delays if they
are part of the generative model,” (Friston, 2011): However, this anticipation
has never been demonstrated formally. Here, we show how generalized Bayesian
ﬁltering – as used in active inference – can compensate for both sensory and
motor delays in the visual-oculomotor loop.
It is important to mention what this work does not address. First, we focus
on tracking eye movements (pursuit of a single dot stimulus for a monocular
observer with ﬁxed head position): we do not consider other types of eye move-
ments (vergence, saccades, or the vestibulo-ocular reﬂex). Second, we take an
approach that complements existing models, such as those of (Robinson, Gor-
don, and Gordon, 1986) and (Krauzlis and Lisberger, 1989). Existing models
account for neurophysiological and behavioural data by reﬁning block-diagram
models of oculomotor control to describe how the system might work. We take
a more generic approach, in which we deﬁne the imperatives for any system
sampling sensory data, derive an optimal oculomotor control solution and show
why this solution explains the data. Although the two approaches should be
consistent, ours oﬀers a principled approach to identifying the necessary solu-
tions (such as predictive coding) to a given problem (oculomotor delays). We
hope to demonstrate the approach by modelling pursuit initiation and smooth
pursuit – and then consider the outstanding issue of anticipatory responses:
in previous treatments (Robinson, Gordon, and Gordon, 1986), “[anticipation]
has not been adequately modelled and no such attempt is oﬀered (. . . ) only
unpredictable movements are considered.”
1.3 Outline
The main contributions of our work are described in the subsequent ﬁve sec-
tions. First, section 2 summarises the basic theory behind active inference
and attempts to link generalized ﬁltering to conventional Bayesian ﬁlters used
in optimal control theory. This section then considers neurobiological imple-
mentations of generalized ﬁltering, in terms of predictive coding in generalized
coordinates of motion. This formulation allows us to consider the problem of
delayed sensory input and motor output in section 3 – and how this problem
can be ﬁnessed in a relatively straightforward way using generalized represen-
tations. Having established the formal framework (and putative neuronal im-
plementation), the ﬁnal three sections deal with successively harder problems
4
in oculomotor control. We start in Section 4 by considering pursuit initiation
using a simple generative model of oculomotor trajectories. Using simulations,
we consider the impact of motor delays, sensory delays and their interaction on
responses to a single sweep of a visual target. The subsequent section turns to
smooth pursuit eye movements – using a more sophisticated generative model
of oculomotor trajectories, in which prior beliefs about eye movements enable
the centre of gaze to predict target motion using a virtual or ﬁctive target (see
Section 5). In the ﬁnal section, we turn to hierarchical models of target trajecto-
ries that have explicit memories of hidden dynamics, which enable anticipatory
responses (see Section 6). These responses are illustrated using simulations of
anticipatory pursuit movements using (rectiﬁed) hemi-sinusoidal motion. In
short, these theoretical considerations lead to a partition of stimulus–bound
eye movements into pursuit initiation, smooth pursuit and anticipatory pursuit,
where each mode of oculomotor control calls on formal additions to the under-
lying generative model; however, they all use exactly the same scheme and basic
principles. Where possible, we try to simulate classic empirical results in this
ﬁeld – at least heuristically.
In short, these theoretical considerations lead to a partition of stimulus-
bound eye movements into pursuit initiation, smooth pursuit and anticipatory
pursuit, where each mode of oculomotor control calls on formal additions to the
underlying generative model. However, these models all use exactly the same
scheme and basic principles; in particular, they all use the same solution to the
oculomotor delay problem. These simulations illustrate that the active inference
scheme can reproduce classical empirical results in three distinct experimental
contexts.
2 From predictive coding to active inference
This section sets out the basic theory, before applying it to the special problem
of oculomotor delays in the following sections. We ﬁrst introduce the general
framework of active inference in terms of generalized Bayesian ﬁltering and
variational free energy minimisation. In brief, active inference can be regarded
as equipping standard Bayesian ﬁltering schemes with classical reﬂex arcs that
enable action, such as an eye movement, to fulﬁl predictions about hidden states
of the world. Second, we will brieﬂy describe the formalism of active inference in
terms of diﬀerential equations describing the dynamics of the world and internal
states of the visual-oculomotor system. The neurobiological implementation of
these diﬀerential equations is considered in terms of predictive coding, which
uses prediction errors on the motion of hidden states – such as the location
of a visual target. In the next section, we will turn to the special problem of
oculomotor delays and how this problem can be ﬁnessed using active inference in
generalized coordinates of motion. This solution will be illustrated in subsequent
sections using simulations of pursuit initiation responses and smooth pursuit.
Finally, we shall exploit the richness of hierarchical generative models – which
underlie active inference – to illustrate anticipatory eye movements that cannot
be explained by simply compensating for oculomotor delays.
5
τs · ⃗V
τm · ⃗V
⃗V
Figure 1: Problem statement: optimal motor control under axonal delays. The
central nervous system has to contend with axonal delays, both at the sensory
and the motor levels. For instance, in the human visuo-oculomotor system,
it takes approximately τs = 50 ms for the retinal image to reach the visual
areas implicated in motion detection, and a further τm = 40 ms to reach the
oculomotor muscles. As a consequence, for a tennis player trying to intercept
a ball at a speed of 20 m ·s−1, the sensed physical position is 1 m behind the
true position (as represented here by τs ·⃗V), while the position at the moment
of emitting the motor command will be .8 m ahead of its execution ( τm ·⃗V).
Note that while the actual position of the ball when its image produced by the
photoreceptors on the retina hits visual areas is approximately at 45 degrees
of eccentricity (red dotted line), the player’s gaze is directed to the ball at its
present position (red line), in anticipatory fashion. Optimal control directs
action (future motion of the eye) to the expected position (red dashed line) of
the ball in the future — and the racket (black dashed line) to the expected
position of the ball when motor commands reach the periphery (muscles).
6
agent environment 
    s=g(ψ,a)+ω   a=argminaF(s,µ)   µ=argminµF(s,µ)     ψ=f(ψ,a)+ω
Separated by a Markov blanket  
Hidden  
states  
Internal 
states 
Sensation  
Action  
Exchange with the environment 
1 
Sensory delays  
Motor delays  
Figure 2: This schematic shows the dependencies among various quantities mod-
elling exchanges of an agent with the environment. It shows the states of the
environment and the system in terms of a probabilistic dependency graph, where
connections denote directed dependencies. The quantities are described within
the nodes of this graph – with exemplar forms for their dependencies on other
variables (see main text). Hidden (external) and internal states of the agent are
separated by action and sensory states. Both action and internal states – en-
coding a conditional probability density function over hidden states – minimise
free energy. Note that hidden states in the real world and the form of their
dynamics can be diﬀerent from that assumed by the generative model; this is
why hidden states are in bold. See main text for further details.
7
2.1 From free energy to generalized ﬁltering
The scheme used here to model oculomotor behaviour has been used to model
several other processes and paradigms in neuroscience. This active inference
scheme is based upon three assumptions:
• The brain minimises the free energy of sensory inputs deﬁned by a gener-
ative model.
• The generative model used by the brain is hierarchical, nonlinear and
dynamic.
• Neuronal ﬁring rates encode the expected state of the world, under this
model.
The ﬁrst assumption is the free energy principle, which leads to active infer-
ence in the context of an embodied interaction of the system with its environ-
ment; where the system can act to change its sensory inputs. The free energy
here is a variational free energy that provides a computationally tractable up-
per bound on the negative logarithm of Bayesian model evidence (see Appendix
1). In Bayesian terms, this means that the brain maximises the evidence for
its model of sensory inputs (Ballard, Hinton, and Sejnowski, 1983; Bialek, Ne-
menman, and Tishby, 2001; Dayan et al., 1995; Gregory, 1980; Grossberg et al.,
1997; Knill and Pouget, 2004; Olshausen and Field, 1996). This is the Bayesian
brain hypothesis (Yuille and Kersten, 2006). If we also allow action to maximise
model evidence, we get active inference (Friston et al., 2010b). Crucially, unlike
conventional optimal control schemes, there is no ad hoc value or loss function
guiding action: Action minimises the free energy of the system’s model. This
permits the application of standard Bayesian solutions and simpliﬁes the im-
plicit neuronal architecture; for example, there is no need for an eﬀerence copy
signal (Friston, 2011). In this setting, desired movements are speciﬁed in terms
of prior beliefs about state transitions or the motion of hidden states in the gen-
erative model. Action then realises prior beliefs (policies) by sampling sensory
data that provides evidence for those beliefs.
The second assumption above is motivated by noting that the world is both
dynamic and nonlinear – and that hierarchical structure emerges inevitably
from a separation of temporal scales (Ginzburg, 1955; Haken, 1983). The third
assumption is the Laplace assumption that, in terms of neural codes, leads to
the Laplace code, which is arguably the simplest and most ﬂexible of all neural
codes (Friston, 2009). In brief, the Laplace code means that probabilistic rep-
resentations are encoded explicitly by synaptic activity in terms of their mean
or expectation (while the second order statistics such as dispersion or precision
are encoded implicitly in terms of synaptic activity and eﬃcacy). This lim-
its the representation of hidden states to continuous variables, as opposed to
discrete states; however, this is appropriate for most aspects of sensorimotor
processing. Furthermore, it ﬁnesses the combinatoric explosion associated with
discrete state space models. Restricting probabilistic representations to a Gaus-
sian form clearly precludes multimodal representations. Having said this, the
hierarchical form of the generative models allows for fairly graceful modelling
of nonlinear eﬀects (such as shadows and occlusions). For example, a Gaussian
variable at one level of the model may enter the lower levels in highly non-linear
8
way — we will see examples of this later. See Appendix 2 for a motivation of
the Laplace assumption from basic principles.
Under these assumptions, action and perception can be regarded as the
solutions to coupled diﬀerential equations describing the dynamics of the real
world (the ﬁrst pair of equations) and the behaviour of an agent (the second
pair of equations); expressed in terms of action and internal states that encode
conditional expectations about hidden states of the world (Friston et al., 2010b):
s= g(x,ν,a) +ων
˙x= f(x,ν,a) +ωx
(1)
˙a= −∂aF(˜s,˜µ)
˙˜µ= D˜µ−∂˜µF(˜s,˜µ)
For clarity, real-world states are written in boldface, while internal states of
the agent are in italics: Here (s,x,ν,a ) denote sensory input, hidden states,
hidden causes and action in the real world, respectively. The variables in the
second pair of equations (˜s,˜µ,a) correspond to generalized sensory input, con-
ditional expectations and action. Generalized coordinates of motion, denoted
by the ˜ notation, correspond to a vector representing the diﬀerent orders of
motion of a variable: position, velocity, acceleration, and so on (Friston et al.,
2010a). Using the Lagrangian notation for temporal derivatives, we get e. g. for
s: ˜s = ( s,s′,s′′,... ). In the absence of delays ˜ s(t) = ˜s(t) the agent receives
instantaneous sensations from the real world. The diﬀerential equations above
are coupled because sensory states depend upon action through hidden states
and causes (x,ν) while action a(t) = a(t) depends upon sensory states through
internal states ˜µ.
By explicitly separating real-world states –hidden from the agent– to its
internal states, one can clearly separate the generative model from the updating
scheme that allows to minimise the agent’s free-energy: The ﬁrst pair of coupled
stochastic diﬀerential equations describes the dynamics of hidden states and
causes in the world and how they generate sensory states. These equations are
stochastic because sensory states and the motion of hidden states are subject
to random ﬂuctuations ( ωx,ων).
The second pair of diﬀerential equations corresponds to action and percep-
tion respectively – they constitute a (generalized) gradient descent on varia-
tional free energy. The diﬀerential equation describing changes in conditional
expectations (perception) is known as generalized ﬁltering or predictive cod-
ing and has the same form as standard Bayesian (Kalman-Bucy) ﬁlters – see
also (Beal, 2003; Rao and Ballard, 1999). The ﬁrst term is a prediction based
upon a diﬀerential operator Dthat returns the generalized motion of the condi-
tional expectations; namely the vector of velocity, acceleration, jerk and so on
– such that D˜µ = (µ′,µ′′,µ′′′,... ). However, the expected velocity is not the
velocity of the expectation and comprises both prediction and update terms:
The second term reﬂects this correction and ensures the changes in conditional
expectations are Bayes-optimal predictions of hidden states of the world – in the
sense that they maximise the free energy bound on Bayesian model evidence.
See Figure 2 for a schematic summary of the implicit conditional dependencies
implied by Equation 1.
9
2.2 Hierarchical form of the generative model
To perform simulations using this scheme, one simply integrates or solves Equa-
tion 1 to simulate (neuronal) dynamics that encode conditional expectations
and ensuing action. Conditional expectations depend upon a generative model,
which we assume has the following (hierarchical) form
s= g(1)(x(1),v(1)) + ω(1)
ν
˙x(1) = f(1)(x(1),v(1)) + ω(1)
x
... (2)
ν(i−1) = g(i)(x(i),v(i)) + ω(i)
ν
˙x(i) = f(i)(x(i),v(i)) + ω(i)
x
...
Where (i) indexes the level in the hierarchical model. Note that we denote
the sensory layer as i= 0, but this indexing is somewhat arbitrary. This equa-
tion is just a way of writing down a generative model that speciﬁes a probability
density function over sensory inputs and hidden states and causes. This proba-
bility density is needed to deﬁne the free energy of sensory input: it is speciﬁed
in terms of functions ( f(i),g(i)) and Gaussian assumptions about random ﬂuc-
tuations (ω(i)
x ,ω(i)
ν ) on the motion of hidden states and causes. It is these that
make the model probabilistic – they play the role of sensory noise at the ﬁrst
level and induce uncertainty about states at higher levels. The precisions of
these ﬂuctuations are quantiﬁed by (Π (i)
x ,Π(i)
ν ) which are deﬁned as the inverse
of the respective covariance matrices.
The deterministic part of the model is speciﬁed by nonlinear functions of
hidden states and causes ( f(i),g(i)) that generate dynamics and sensory con-
sequences. Hidden causes link hierarchical levels, whereas hidden states link
dynamics over time. Hidden states and causes are abstract quantities that the
brain uses to explain or predict sensations – like the motion of an object in the
ﬁeld of view. In hierarchical models of this sort, the output of one level acts
as an input to the next. This input can produce complicated convolutions with
deep (hierarchical) structure. We will see examples of this later in particular in
the context of anticipatory movements.
2.3 Perception and predictive coding
Given the form of the generative model (Equation 2) one can write down the
diﬀerential equations (Equation 1) describing neuronal dynamics in terms of
prediction errors on the hidden causes and states. These errors represent the
diﬀerence between conditional expectations and predicted values, under the gen-
erative model (using A·B := ATB for the scalar product and omitting higher-
order terms):
10
2 
frontal eye fields geniculate 
visual cortex 
retinal input 
pons 
oculomotor 
signals 
Prediction error (superficial pyramidal cells) 
Conditional predictions (deep pyramidal cells) 
Top-down or backward 
predictions 
Bottom-up or forward 
prediction error 
proprioceptive input 
reflex 
arc 
(1)
ox
(1)
tx
(1) (1)
to xx
Angular position of target in intrinsic coordinates 
Angular direction of gaze in extrinsic coordinates 
Angular direction of target in extrinsic coordinates 
(1) (1)
t t os xx
(1)
oos x
pons 
Sensory inputs 
Figure 3: Schematic detailing a neuronal message passing scheme (generalized
Bayesian ﬁltering or predictive coding) that optimises conditional expectations
about hidden states of the world, given sensory (visual) data and the active
(oculomotor) sampling of those data. This diagram shows the speculative cells
of origin of forward driving connections (in red) that convey prediction error
from a lower area to a higher area and the backward connections (in black)
that construct predictions (Mumford, 1992). These predictions try to explain
away prediction error in lower levels. In this scheme, the sources of forward
and backward connections are superﬁcial (red) and deep (black) pyramidal cells
respectively. The equations on the right represent a generalized descent on free
energy under the hierarchical model described in the main text – this can be
regarded as a generalisation of predictive coding or Kalman ﬁltering: see (Fris-
ton, 2008). State-units are in black and error-units are in red. Here, we have
placed diﬀerent levels of some hierarchical model within the visual-oculomotor
system. Visual input arrives in an intrinsic (retinal) frame of reference that
depends upon the angular position of a stimulus and the direction of gaze. Ex-
teroceptive input is then passed to the lateral geniculate nuclei (LGN) and to
higher visual and prefrontal (e.g., motion sensitive, such as the frontal eye ﬁeld)
areas in the form of prediction errors. Crucially, proprioceptive sensations are
also predicted, creating prediction errors at the level of the cranial nerve nuclei
(pons). The special aspect of these proprioceptive prediction errors is that they
can be resolved through classical reﬂex arcs – in other words, they can elicit
action to change the direction of gaze and close the visual–oculomotor loop.
11
˙˜µ(i)
x = D˜µ(i)
x + ∂˜g(i)
∂˜µ(i)
x
·Π(i)
ν ˜ε(i)
ν + ∂˜f(i)
∂˜µ(i)
x
·Π(i)
x ˜ε(i)
x −DΠ(i)
x ˜ε(i)
x
˙˜µ(i)
ν = D˜µ(i)
ν + ∂˜g(i)
∂˜µ(i)
ν
·Π(i)
ν ˜ε(i)
ν + ∂˜f(i)
∂˜µ(i)
ν
·Π(i)
x ˜ε(i)
x −Π(i+1)
ν ˜ε(i+1)
ν
(3)
˜ε(i)
x = D˜µ(i)
x −˜f(i)(˜µ(i)
x ,˜µ(i)
ν )
˜ε(i)
ν = ˜µ(i−1)
ν −˜g(i)(˜µ(i)
x ,˜µ(i)
ν )
The quantities ˜ε(i) correspond to prediction errors (on hidden states x or
hidden causes ν). These are weighted by their respective precision vectors Π(i) in
the update scheme. Equation 3 can be derived fairly easily by computing the free
energy for the hierarchical model in Equation 2 and inserting its gradients into
Equation 1. This gives a relatively simple update scheme, in which conditional
expectations are driven by a mixture of prediction errors, where prediction errors
are deﬁned by the equations of the generative model.
It is diﬃcult to overstate the generality and importance of Equation 3 – its
solutions grandfather nearly every known statistical estimation scheme, under
parametric assumptions about additive noise (Friston, 2008). These range from
ordinary least squares to advanced variational deconvolution schemes. In this
form, one can see clearly the relationship between predictive coding and Kalman-
Bucy ﬁltering – changes in conditional expectations comprise a prediction (ﬁrst
term) plus a weighted mixture of prediction errors (remaining terms). The
weights play the role of a Kalman gain matrix and are based on the gradients
of the model functions and the precision of random ﬂuctuations.
In neural network terms, Equation 3 says that error-units receive predictions
from the same hierarchical level and the level above. Conversely, conditional
expectations (encoded by the activity of state units) are driven by prediction
errors from the same level and the level below. These constitute bottom-up
and lateral messages that drive conditional expectations towards a better pre-
diction to reduce the prediction error in the level below. This is the essence
of recurrent message passing between hierarchical levels to suppress free en-
ergy or prediction error: see (Friston and Kiebel, 2009) for a more detailed
discussion. In neurobiological implementations of this scheme, the sources of
bottom-up prediction errors, in the cortex, are thought to be superﬁcial pyra-
midal cells that send forward connections to higher cortical areas. Conversely,
predictions are conveyed from deep pyramidal cells by backward connections,
to target (polysynaptically) the superﬁcial pyramidal cells encoding prediction
error (Friston and Kiebel, 2009; Mumford, 1992). This deﬁnes an elementary
circuit that may be the basis of the layered organisation of the cortex (Bastos
et al., 2012). Figure 3 provides a schematic of the proposed message passing
among hierarchically deployed cortical areas.
2.4 Action
In active inference, conditional expectations elicit behaviour by sending predic-
tions down the hierarchy to be unpacked into proprioceptive predictions at the
12
level of (pontine) cranial nerve nuclei and spinal-cord. These engage classical re-
ﬂex arcs to suppress proprioceptive prediction errors and produce the predicted
motor trajectory
˙a= −∂aF = −(∂a˜ε(1)
ν ) ·Π(1)
ν ˜ε(1)
ν (4)
The reduction of action to classical reﬂexes follows because the only way
that action can minimise free energy is to change sensory (proprioceptive) pre-
diction errors by changing sensory signals. This highlights the tight relationship
between action and perception; cf., the equilibrium point formulation of motor
control (Feldman and Levin, 1995). In short, active inference can be regarded
as equipping a generalized predictive coding scheme with classical reﬂex arcs:
see (Friston, Daunizeau, and Kiebel, 2009; Friston et al., 2010b) for details.
The actual movements produced clearly depend upon (changing) top-down pre-
dictions that can have a rich and complex structure. This scheme is consistent
with the physiology and anatomy of the oculomotor system (for a review see (Ilg,
1997; Krauzlis, 2004); although our goal here is not to identify the role of each
anatomical structure but rather to give a schematic proof-of-concept.
2.5 Summary
In summary, we have derived equations for the dynamics of perception and
action using a free energy formulation of adaptive (Bayes-optimal) exchanges
with the world and a generative model that is both generic and biologically
plausible. A technical treatment of the material above will be found in (Friston
et al., 2010a), which provides the details of the generalized ﬁltering used to
produce the simulations in the next section. Before looking at these simulations,
we consider how delays can be incorporated into this scheme.
3 Active inference with sensorimotor delays
If action and sensations were not subject to delays, one could integrate (solve)
Equation 1 directly; however, in the presence of sensory and motor delays ( τs
and τa respectively) Equation 1 becomes a (stochastic and non-linear) delay
diﬀerential equation because ˜s(t) = ˜s(t−τs) and a(t) = a(t+ τa). In other
words, the agent receives sensations from (sees) the past, whilst emitting motor
signals that will be enacted in the future (we will only consider delays from the
sensory and motor sub-systems and neglect delays between neuronal systems in
this paper).
To ﬁnesse the integration of these delay diﬀerential equations one can ex-
ploit their formulation in generalized coordinates: By taking linear mixtures of
generalized motion one can easily map from the present to the future, using the
matrix operators:
13
T(τ) = exp(τD) =


1 1
1! τ 1
2! τ2 ...
0 1 1
1! τ ...
0 0 1 ...
0 0 0 ...


(5)
with D=


0 1 0 0
0 0 1 0
0 0 0 ...
0 0 0 0


The ﬁrst diﬀerential operator simply returns the generalized motionD˜x(t) =
˜x′(t) while the second delay operator produces generalized states in the future
T(τ)˜x(t) = ˜x(t+τ) (we deﬁne delays as positive by convention). Note that shift-
ing forward and backwards by the same amount of time produces the identity
operator T(τ)T(−τ) = I and that, more generally, T(τ1)T(τ2) = T(τ1 + τ2).
These delay operators are simple to implement computationally (and neuro-
biologically) and allow an agent to ﬁnesse the delayed coupling above by replac-
ing (delayed) sensory signals with future input ˜s(t) = T(τs)˜s(t−τs) = ˜s(t) for
subsequent action and perception. Alternatively, one can regard this compen-
sation for sensory delays as attempting to predict the past (see below). Gener-
alized coordinates allow the representation of the trajectory of a given variable
at any time (that is, its evolution in the near past and present) and thus allow
its projection into the future or past. Generalized representations are more ex-
tensive than ‘snapshots’ at a particular time and enable the agent to anticipate
the future (of delayed sensory trajectories) and represent hidden states in real
time – that is, representations that are synchronised with the external events.
In terms of motor delays, the agent can replace its internal motor signals with
action in the future a(t) = T(τa)a(t−τa) = a(t), such that when action signals
reach the periphery they correspond to the action encoded centrally. These
substitutions allow us to express action and perception in Equation 1 as 1:
˙a(t) = −∂aF(T(τa)T(τs)˜s(t−τs −τa),T(τa)˜µ(t−τa))
= −∂aF(T(τs −τs + τa −τa)˜s(t),T(τa −τa)˜µ(t))
(6)
˙˜µ(t) = D˜µ(t) −∂˜µF(T(τs)˜s(t−τs),˜µ(t))
= D˜µ(t) −∂˜µF(T(τs −τs)˜s(t),˜µ(t))
This equation distinguishes between true delays ( τ) and those assumed by
the agent (τ). When the two are the same, the delay operatorsT(τ−τ) = I : τ =
τ become identity matrices and Equation 6 reduces to Equation 1. When the
two diﬀer, Equation 6 permits the simulation of a system with uncompensated
delays. Notice how the dynamics of action in the ﬁrst diﬀerential equation are
1We have a made a slight approximation here becauseT(τa)˜µ(t−τa) = T(τa −τa)˜µ(t)
when, and only when, the free energy gradients are zero and ˙˜µ(t) = D˜µ(t). Under the
assumption that the perceptual destruction of these gradients is fast, in relation to action,
this can be regarded as an adiabatic approximation.
14
driven by a gradient descent on the free energy of sensations with composite
sensory and motor delays. In other words, action in the real world depends
upon sensory states generated τs + τa in the past.
One can now solve Equation 6 to simulate active inference, with or without
compensation for sensorimotor delays. We use a standard local linearisation
scheme for this integration (Ozaki, 1992), where delays enter at the point at
which sensory prediction error is computed and when it drives action: from
Equations 3 and 4:
˜ε(1)
ν = T(τs)˜s(t−τs) −˜g(1)(˜µ(1)
x ,˜µ(1)
ν )
= T(τs −τs)˜s(t) −˜g(1)(˜µ(1)
x ,˜µ(1)
ν )
(7)
˙a(t) = −(∂a˜ε(1)
ν ) ·Π(1)
ν T(τa)˜ε(1)
ν (t−τa)
= −(∂a˜ε(1)
ν ) ·Π(1)
ν T(τa −τa)˜ε(1)
ν (t)
Equation 7 means that perfect (errorless) prediction requiresT(τs)˜s(t−τs) =
˜g(1)(˜µ(1)
x ,˜µ(1)
ν ). In other words, errorless prediction means that the agent is ef-
fectively predicting the future projection of the past. Note again the dependency
of action, via prediction errors, on sensory states τs + τa in the past. See Ap-
pendix 3 for further details of the integration scheme used in the simulations
below.
3.1 Summary
This section has considered how the diﬀerential equations describing changes
in action and internal (representational) states can be ﬁnessed to accommodate
sensorimotor delays. This is relatively straightforward – in the context of gener-
alized schemes – using delay operators that take mixtures of generalized motion
to project states into the future or past. Sensory delays can be (internally)
simulated and corrected by applying delays to sensory input producing sensory
prediction error, while motor delays can be simulated and corrected by applying
delays to sensory prediction error producing action. Neurobiologically, the ap-
plication of delay operators just means changing synaptic connection strengths
to take diﬀerent mixtures of generalized sensations and their prediction errors.
We will now use these operators to look at the eﬀects of sensorimotor delays
with and without compensation.
4 Results: pursuit initiation
This section focuses on the consequences of sensory delays, motor delays and
their combination – in the context of pursuit initiation – using perhaps the
simplest generative model for active inference. Our purpose is to illustrate the
diﬃculties in oculomotor control that are incurred by delays and how these diﬃ-
culties dissolve when delays are accommodated during active inference. We start
with a description of the generative model and demonstrate its behaviour when
delays are compensated. We then use this normal behaviour as a reference to
look at failures of pursuit initiation induced by delays. In this section, responses
15
to a single sweep of rightward motion are used to illustrate basic responses. In
the next section, we consider pursuit of sinusoidal motion (with abrupt onsets)
and the implications for generative models that may be used by the brain.
4.1 Generative model of pursuit initiation
The generative model for pursuit initiation used here is very simple and is based
upon the prior belief that the centre of gaze is attracted to the target location.
The processes generating sensory inputs and the associated generative model
can be expressed as follows:
s=
[
so
st
]
=
[
xo
xt −xo
]
+ ω(1)
ν
˙x=
[ ˙xo
˙xt
]
=
[ 1
ta
a−1
to
xo
1
tm
(ν(1) −xt)
]
+ ω(1)
x
(8)
s=
[
so
st
]
=
[
xo
xt −xo
]
+ ω(1)
ν
˙x=
[ ˙xo
˙xt
]
=
[ 1
ts
(xt −xo)
1
tm
(ν(1) −xt)
]
+ ω(1)
x
ν(1) = ω(2)
x
The ﬁrst pair of equations corresponds to a noisy sensory mapping from
hidden states and the equations of motion for states in the real world. These
pertain to real-world variables representing the position of the target and of the
eye (in boldface). The remaining equations constitute the generative model of
how sensations are generated using the form of Equation 2. These deﬁne the
free energy in Equation 1 – and specify behaviour under active inference. The
variables constitute the ﬁrst layer of the hierarchical model (see Equation 2, but
for simplicity, we have written xinstead of x(1) and x instead of x(1).
The real-world provides sensory input in two modalities: proprioceptive in-
put from cranial nerve nuclei reports the angular displacement of the eyeso ∈R2
and corresponds to the centre of gaze. Note that, using the approximation of
relatively small displacements, we use Cartesian coordinates to follow previous
treatments e.g (Friston et al., 2010a). However visual space is better described
by bounded polar coordinates, and treatments of large eye movements should
account for this. Exteroceptive (retinal) input reports the angular position of
a target in a retinal (intrinsic) frame of reference st ∈R2. The indices o and
t thus refer to states of the oculomotor system or of the target, respectively.
Note that st is just the diﬀerence between the centre of gaze and target loca-
tion in an extrinsic frame of reference xt −xo. In this paper, we are modelling
the online inference of target position, and we are ignoring the problem of how
the causal structure of the environment is learned. We simply assume that
this structure has already been learned accurately, and therefore the dynamics
of the real-world and the generative model are the same. Clearly, this model
of visual processing is an enormous simpliﬁcation: we are assuming that place
coded spatial information can be summarised in terms of displacement vectors.
16
However, more realistic simulations – using a set of retinotopic inputs with clas-
sical receptive ﬁelds covering visual space – produce virtually the same results.
We will use more realistic models in future publications that deal with smooth
pursuit and visual occlusion. Here, we use the simpler formulation to focus on
delays and the diﬀerent sorts of generative models that can provide top-down
or extra-retinal constraints on visual motion processing.
The hidden states of this model comprise the true, real-world oculomotor
displacement (xo ∈R2) and target location ( xt ∈R2). The units of angular
displacement are arbitrary, but parameters are tuned to correspond to a small
displacement of 4 degrees of visual angle for one arbitrary unit (that is approx-
imately 4 times the width of a thumb’s nail at arm’s length). The oculomotor
state is driven by action with a time constant ofta = 64 ms and decays (slowly)
to zero through damping, with a time constant of to = 512 ms. The target loca-
tion is perturbed by hidden causes xt ∈R2 that describe the location to which
the target is drawn, with a time constant of tm = 16 ms. In this paper, the
random ﬂuctuations on sensory input and on the motion of hidden states are
very small, with a log precision of 16. In other words, the random ﬂuctuations
have a variance of exp( −16). This completes our description of the process
generating sensory information; in which hidden causes force the motion of a
target location and action forces oculomotor states. Target location and oculo-
motor states are combined to produce sensory information about the target in
an intrinsic frame of reference.
The generative model has exactly the same form as the generative process
but with one important exception: there is no action and the motion of the
hidden oculomotor states is driven by the displacement between the target lo-
cation and the central gaze (with a time constant of ts = 32 ms). In other
words, the agent believes that its gaze will be attracted to the location of the
target, which, itself, is being driven by some unknown exogenous force or hidden
cause. The log-precisions on the random ﬂuctuations in the generative model
were four, unless stated otherwise. This means that uncertainty about sensory
input, (motion of) hidden states and causes were roughly equivalent.
Having speciﬁed the generative process and model, we can now solve the
active inference scheme in Equation 1 and examine its behaviour. Sensorimotor
delays are implemented in the message passing from the generative process to the
generative model. This generative model produces pursuit initiation because it
embodies prior beliefs that the centre of gaze will follow the target location. This
pursuit initiation rests on conditional expectations about the target location in
extrinsic coordinates and the state of the oculomotor plant, where the location
is driven by hidden causes that also have to be inferred.
The generative model described in this section provides the equations re-
quired to simulate active inference using the formalism of the previous section.
In short, we now consider the generative model that deﬁnes the variational free
energy and (Bayes) optimal active inference.
4.2 Simulations
All simulations were performed with a time bin of 16ms and we report results
in milliseconds. All results were replicated with diﬀerent time bins (16ms, 8ms,
4ms, 2ms, 1ms) with minimal changes to the results. Figure 4 reports the con-
ditional estimates of hidden states and causes during the simulation of pursuit
17
Figure 4: This ﬁgure reports the conditional estimates of hidden states and
causes during the simulation of pursuit initiation, using a single rightward (pos-
itive) sweep of a visual target, while compensating for sensory motor delays.
We will use the format of this ﬁgure in subsequent ﬁgures: the upper left panel
shows the predicted sensory input (coloured lines) and sensory prediction errors
(dotted red lines) along with the true values (broken black lines). Here, we see
horizontal excursions of oculomotor angle (upper lines) and the angular position
of the target in an intrinsic frame of reference (lower lines). This is eﬀectively
the distance of the target from the centre of gaze and reports the spatial lag of
the target that is being followed (solid red line). One can see clearly the initial
displacement of the target that is suppressed after a few hundred milliseconds.
The sensory predictions are based upon the conditional expectations of hidden
oculomotor (blue line) and target (red line) angular displacements shown on
the upper right. The grey regions correspond to 90% Bayesian conﬁdence in-
tervals and the broken lines show the true values of these hidden states. One
can see the motion that elicits following responses and the oculomotor excur-
sion that follows with a short delay of about 64 ms. The hidden cause of these
displacements is shown with its conditional expectation on the lower left. The
true cause and action are shown on the lower right. The action (blue line) is
responsible for oculomotor displacements and is driven by the proprioceptive
prediction errors.
18
4 
-200 0 200 400 600 
0 
0.2 
0.4 
0.6 
0.8 
1 
Position 
Sensory input and predictions 
  
true 
estimated 
control 
delayed 
-200 0 200 400 600 
0 
0.2 
0.4 
0.6 
0.8 
1 
Action 
  
  
control 
delayed 
-200 0 200 400 600 
0 
0.2 
0.4 
0.6 
0.8 
1 
Position 
-200 0 200 400 600 
0 
0.2 
0.4 
0.6 
0.8 
1 
-200 0 200 400 600 
0 
0.2 
0.4 
0.6 
0.8 
1 
Time (ms) 
Position 
-200 0 200 400 600 
0 
0.2 
0.4 
0.6 
0.8 
1 
Time (ms) 
Sensory delays 
Motor delays 
Sensory and 
motor delays 
Figure 5: This ﬁgure illustrates the eﬀects of sensorimotor delays on pursuit
initiation (red lines) in relation to compensated (optimal) active inference – as
shown in the previous ﬁgure (blue lines). The left panels show the true (solid
lines) and estimated sensory input (dotted lines), while action is shown in the
right panels. Under pure sensory delays (top row), one can see clearly the delay
in sensory predictions, in relation to the true inputs. The thicker (solid and
dotted) red lines correspond respectively to (true and predicted) proprioceptive
input, reﬂecting oculomotor displacement. The middle row shows the equivalent
results with pure motor delays and the lower row presents the results with
combined sensorimotor delays. Of note here is the failure of optimal control
with oscillatory ﬂuctuations in oculomotor trajectories, which become unstable
under combined sensorimotor delays.
19
initiation, using a simple rightward sweep of a visual target and compensating
for sensorimotor delays: τs = τs and τa = τa. This compensation is eﬀectively
the same as simulating responses in the absence of delays – because the delay
operators reduce to the identity matrix. Target motion was induced using a
hidden cause that was a ramp function of post-stimulus time. Note that ramp
stimuli are often used in psychophysics, and this generative model – using veloc-
ity in place of position — produces the same results in velocity space. Indeed,
most models, such as (Robinson, Gordon, and Gordon, 1986) or (Krauzlis and
Lisberger, 1989), focus on modelling velocity responses. We choose to model
the tracking of position for two reasons: First, it is easy to generalise position
results to velocity using generalized coordinates of motion. Second, positional
errors can induce slow eye movements (Kowler and Steinman, 1979; Wyatt and
Pola, 1981) and we hoped to accommodate this in the model. If we assume
that the units of angular displacement are 4 degrees of visual angle, then the
resulting peak motion corresponds to about 20 degrees per second.
The upper left panel shows the predicted sensory input (coloured lines) and
sensory prediction errors (dotted red lines) along with the true values (broken
black lines). Here, we see horizontal excursions of oculomotor angle (upper
lines) and the angular position of the target in an intrinsic frame of reference
(lower lines). This is eﬀectively the distance of the target from the centre of
gaze and reports the spatial lag of the target that is being followed (solid red
line). One can see clearly an initial retinal displacement of the target that is
suppressed after approximately 20 ms. This eﬀect conﬁrms that the visual repre-
sentation of target position is predictive and that the presentation of a smooth
predictable versus an unpredictable target would induce a lag between their
relative positional estimates, as is evidenced in the ﬂash-lag eﬀect (Nijhawan,
1994).
The sensory predictions are based upon the conditional expectations of hid-
den oculomotor (blue line) and target (red line) angular displacements shown
on the upper right. The grey regions correspond to 90% Bayesian conﬁdence
intervals and the broken lines show the true values. One can see clearly the
motion that elicits pursuit initiation responses, where the oculomotor excursion
follows with a short delay of about 64 ms. The hidden cause of these displace-
ments is shown with its conditional expectation on the lower left. The true
cause and action are shown on the lower right. The action (blue line) is respon-
sible for oculomotor displacements and is driven by proprioceptive prediction
errors. Action does not return to zero because the sweep is maintained at an
eccentric position during this simulation. This eye position slightly undershoots
the target position: it is held at around 95% of the target eccentricity in the
upper right panel. Note that this corresponds roughly to the steady-state gain
observed in behavioural data, which was modelled explicitly by (Robinson, Gor-
don, and Gordon, 1986). For our purposes, these simulations can be regarded as
Bayes optimal solutions to the pursuit initiation problem, in which sensorimotor
delays have been accommodated (discounted) via absorption into the generative
model. We can now examine the performance in the absence of compensation
and see how sensory and motor delays interact to confound pursuit initiation:
The above simulations were repeated with uncompensated sensory delays
(τs = 0 ms and τs = 32 ms), uncompensated motor delays ( τa = 0 ms and
τa = 32 ms) and combined sensorimotor delays of 64 ms ( τa = τs = 0 ms and
τa = τs = 32 ms). To quantify behaviour, we focus on the sensory input and un-
20
derlying action. The position of the target in intrinsic coordinates corresponds
to spatial lag and usefully quantiﬁes pursuit initiation performance. Figure 5
shows the results of these three simulations (red lines) in relation to the com-
pensated (optimal) active inference shown in the previous ﬁgure (blue lines).
True sensory input corresponds to solid lines and its conditional predictions to
dotted lines. The left panels show the true and predicted sensory input, while
action is shown in the right panels. Under pure sensory delays (top row) one can
see the delay in sensory predictions, in relation to the true inputs. The thicker
(solid and dotted) red lines correspond respectively to (true and predicted) pro-
prioceptive input, reﬂecting oculomotor displacement. Crucially, in contrast to
optimal control, there are oscillatory ﬂuctuations in oculomotor displacement
and the retinotopic location of the target that persists even after the target is
stationary. These ﬂuctuations are similar to the oscillations elicited by adding
an artiﬁcial feed-back delay (Goldreich, Krauzlis, and Lisberger, 1992). Here,
the ﬂuctuations are caused by damped oscillations in action due to, and only
to, sensory proprioceptive and exteroceptive delays. These become unstable
(increasing in their amplitude) when the predicted value oscillates in counter-
phase with the real value. Similar oscillations are observed with pure motor
delays (middle row). However, here there is no temporal lag between the true
and predicted sensations (solid versus dashed lines). Furthermore, there is no
apparent delay in action – action appears to be emitted for longer, reaching
higher amplitudes. In fact, action is delayed but the delay is obscured by the
increase in the amplitude of action – that is induced by greater propriocep-
tive prediction errors. If we now combine both sensory and motor delays, we
see a catastrophic failure of oculomotor tracking (lower row). With combined
sensorimotor delays the pursuit initiation becomes unstable, with exponentially
increasing oscillations as action over-compensates for delay-dependent errors.
In eﬀect, the active inference scheme has undergone a phase transition from
a stable to an unstable ﬁxed point. We have illustrated this bifurcation by in-
creasing sensorimotor delays under a ﬁxed motor precision or gain in Equation 7.
The results in Figure 5 used a motor gain with a log precision of 2.5. We chose
this value because it produced stable responses with sensory or motor delays
alone and unstable dynamics with combined delays. These results illustrate
the profound and deleterious eﬀects of sensorimotor delays on simple pursuit
initiation, using biologically plausible values – namely sensorimotor delays of
64 ms and a target velocity of about 16 degrees per second. This also illustrates
the necessity of compensation for these delays so that the system can achieve
a more robust and stable response. One would anticipate, in the face of such
failures, real subjects would engage interceptive saccades to catch the target, of
the sort seen in schizophrenic patients (Levy et al., 1993). In the remainder of
this paper, we will concentrate on the nature of pursuit initiation and smooth
pursuit with compensated sensorimotor delays, using a reasonably high motor
gain with a log precision of four.
4.3 Pursuit initiation and visual contrast
Before turning to more realistic generative models of smooth pursuit, we con-
sider the empirical phenomena in which following responses to the onset of
target movement are suppressed by reducing the visual contrast of the tar-
get (Thompson, 1982). In simulations of this sort, visual contrast is modelled
21
in terms of the precision of sensory information in accord with Weber’s law –
see (Feldman and Friston, 2010) for details. Contrast-dependent eﬀects are easy
to demonstrate in the context of active inference. Figure 6 shows the spatial
lag – the displacement in intrinsic coordinates of the target from the centre of
gaze depicted by the solid red line in Figure 4 – as a function of contrast or
log-precision of exteroceptive sensory input. The upper panel shows the true
(solid lines) and predicted (dotted lines) spatial lag as a function of peristimulus
time for diﬀerent log precisions, ranging from two (low) to eight (high). The
peak lags are plotted in the lower panel as a function of visual contrast or log
precision. Since estimation error decreases as visual contrast increases, both
curves converge, leading to a decrease to zero of the prediction error. These re-
sults show, in accord with empirical observations, how the spatial lag (position
error) increases with contrast (Arnold, Ong, and Roseboom, 2009), while the
true lag decreases (Spering et al., 2005). A similar diﬀerence between percep-
tion and action was recently reported (Simoncini et al., 2012). The explanation
for this contrast–dependent behaviour is straightforward – because pursuit ini-
tiation is based upon proprioceptive prediction errors, it depends upon precise
sensory information. Reducing the precision of visual input – through reducing
contrast – increases uncertainty about visual information (sensory estimation
error) and places more weight on prior beliefs and proprioceptive sensations.
This reduces the perceived motion of the target and reduces the amplitude of
prediction errors driving action.
4.4 Summary
In this section, we have seen that sensorimotor delays can have profound and
deleterious eﬀects on optimal oculomotor control. Here, optimal control means
Bayes optimal active inference, in which pursuit initiation emerges sponta-
neously from prior beliefs about how a target attracts the centre of gaze. These
simulations demonstrate that it is relatively easy to compensate for sensorimo-
tor delays by exploiting representations in generalized coordinates of motion.
Furthermore, the resulting scheme has some construct validity in relation to
experimental manipulations of the precision or contrast of visual information.
However, there are certain aspects of oculomotor tracking that suggest the pur-
suit initiation model above is incomplete: when presented with periodic target
motion, the latency of motor gain (deﬁned operationally in terms of the target
and oculomotor velocities) characteristically reduces after the ﬁrst cycle of tar-
get motion (Barnes, Barnes, and Chakraborti, 2000). This phenomenon cannot
be reproduced by the pursuit initiation model above:
Figure 7 shows the responses of the pursuit initiation model to sinusoidal
motion using the same format as Figure 4. Here, the hidden cause driving the
target was a sine wave with a period of 512 ms that started after 256 ms. If we
focus on the spatial lag (solid red line in the upper left panel), one can see that
the lag is actually greater after one period of motion than at the onset of motion.
This contrasts with empirical observations, which suggest that the spatial lag
should be smaller after the ﬁrst cycle (Barnes, Barnes, and Chakraborti, 2000).
In the next section, we consider a more realistic generative model that resolves
this discrepancy and takes us from simple pursuit initiation to smooth pursuit.
22
5 
-200 -100 0 100 200 300 400 500 600 700 
0 
0.05 
0.1 
0.15 
0.2 
0.25 
0.3 
0.35 
Time (ms) 
Distance from target 
2 3 4 5 6 7 8 
0.18 
0.2 
0.22 
0.24 
0.26 
0.28 
0.3 
0.32 
0.34 
0.36 
log-Precision 
Spatial lag 
Peak lag 
(1) (1)|| to xx
Spatial lag 
Figure 6: This ﬁgure reports the spatial lag (the displacement of the target
from the centre of gaze) as a function of contrast (log precision of exteroceptive
sensory input). The upper panel shows the true (solid lines) and predicted
(dotted lines) spatial lag as a function of peristimulus time for diﬀerent log
precisions, ranging from two (black lines) to eight (red lines). The peak lags
are plotted in the lower panel as a function of visual contrast or log precision.
These results show how the perceived lag increases with contrast, while the true
lag decreases in accord with empirical observations.
23
6 
-200 0 200 400 600 800 1000 1200 
-1 
-0.5 
0 
0.5 
1 
Pursuit initiation: 
prediction and error 
-200 0 200 400 600 800 1000 1200 
-1 
-0.5 
0 
0.5 
1 
Periodic motion: 
hidden states 
-200 0 200 400 600 800 1000 1200 
-1 
-0.5 
0 
0.5 
1 
hidden causes 
time (ms) 
-200 0 200 400 600 800 1000 1200 
-1 
-0.5 
0 
0.5 
1 
time (ms) 
perturbation and action 
Position Position 
Figure 7: This ﬁgure uses the same format as Figure 4 – the only diﬀerence
here is that the target motion is sinusoidal. The key thing to take from this
simulation is that the peak spatial lag at the onset of the second cycle of target
motion is greater than the peak lag at the onset of the ﬁrst. This is contrary to
empirical predictions.
24
5 Results: smooth pursuit
In this section, we consider a slightly more realistic generative model that re-
places the prior beliefs about the target attracting the centre of gaze with the
belief that both the target and centre of gaze are attracted by the same (ﬁc-
tive) location in visual space. This allows pursuit initiation to anticipate the
trajectory of the target and pursue the target more accurately – providing the
trajectories are suﬃciently smooth. The idea behind this generative model is to
account for the improvements in tracking performance that are not possible at
the onset of motion and that are due to inference on smooth target trajectories.
5.1 Smooth pursuit model
The smooth pursuit model considered in this paper rests on a second-order
generalisation of the pursuit initiation model of previous section. Previously,
we have considered the motion of the oculomotor plant to be driven directly
by action. This form of action can be considered as an (adiabatic) solution to
a proper second-order formulation, in which action exerts a force and thereby
changes the angular acceleration of oculomotor displacement. This second-order
formulation can be expressed in terms of the following generative process and
model
s=
[ so
st
]
=
[ xo
xt −xo
]
+ ω(1)
ν
˙x=


˙xo
˙x′
o
˙xt

=


x′
t
1
ta
a−1
to
x′
o
1
tm
(ν(1) −xt)

+ ω(1)
x
(9)
s=
[ so
st
]
=
[ xo
xt −xo
]
+ ω(1)
ν
˙x=


˙xo
˙x′
o
˙xt

=


x′
t
1
tv
(ν(1) −xo) −ts
tv
x′
o
1
tm
(ν(1) −xt)

+ ω(1)
x
ν(1) = ω(2)
ν
Here, the only thing that has changed is that we have introduced new hidden
states corresponding to oculomotor velocity x′
o ∈R2. Action now changes the
motion of the velocity (i.e., acceleration), as opposed to the velocity directly.
This diﬀerence is reﬂected in the generative model but with one crucial addition
– the hidden oculomotor state is not driven by the displacement between thetar-
get and the centre of gaze but by the displacement between thehidden cause and
the centre of gaze. In other words, the hidden oculomotor states are attracted
by the hidden cause of target motion – not the target motion per se. The idea
here is that inference about the trajectory of the hidden cause should enable
an anticipatory optimisation of pursuit initiation, provided these trajectories
are smooth – hence a smooth pursuit model. Note that the equation of motion
in the oculomotor model ˙ xo = 1
ts
(xt −xo) (see Equation 8) is the (adiabatic)
solution to the equation used to model smooth pursuit: 1
tv
(ν(1) −xo)−ts
tv
x′
o = 0
25
7 
-200 0 200 400 600 800 1000 1200 
-1 
-0.5 
0 
0.5 
1 
Smooth pursuit: 
prediction and error 
-200 0 200 400 600 800 1000 1200 
-1 
-0.5 
0 
0.5 
1 
Periodic motion: 
hidden states 
-200 0 200 400 600 800 1000 1200 
-1 
-0.5 
0 
0.5 
1 
hidden causes 
time (ms) 
-200 0 200 400 600 800 1000 1200 
-1 
-0.5 
0 
0.5 
1 
time (ms) 
perturbation and action 
Position Position 
Figure 8: This ﬁgure uses the same format as the previous ﬁgure – the only dif-
ference here is that we have replaced the pursuit initiation model with a smooth
pursuit model. In the smooth pursuit model the centre of gaze is attracted by
a hidden cause of target motion, as opposed to the target per se. Note that, in
comparison to the previous ﬁgure, the peak lag at the onset of the second cycle
of target motion is now smaller than at the onset to the ﬁrst.
when ν(1) = xt (see Equation 9). As a result (and as conﬁrmed by simulations)
this model behaved similarly for the sweep stimulus used in Figures 4, 5, 6.
5.2 Simulations
We repeated the simulation reported in Figure 7 using the smooth pursuit gen-
erative model. The results of this simulation are shown in Figure 8 using the
same format as Figure 7. The key diﬀerence – in terms of performance – is that
the peak spatial lag after one cycle of motion is now less than the peak lag at the
onset of motion. The response to the sinusoid trajectory contrasts with simple
pursuit initiation and is more consistent with empirical observations. The true
and expected hidden states show that the oculomotor trajectory now follows the
target trajectory more accurately, particularly at the peaks of right and leftward
displacement. Interestingly, the amplitude of action has not changed very much
26
8 
-200 0 200 400 600 800 1000 1200 
-1 
-0.5 
0 
0.5 
1 
Smooth pursuit: 
prediction and error 
-200 0 200 400 600 800 1000 1200 
-1 
-0.5 
0 
0.5 
1 
Half-cycle motion: 
hidden states 
-200 0 200 400 600 800 1000 1200 
-1 
-0.5 
0 
0.5 
1 
hidden causes 
time (ms) 
-200 0 200 400 600 800 1000 1200 
-1 
-0.5 
0 
0.5 
1 
time (ms) 
perturbation and action 
Position Position 
Figure 9: This ﬁgure uses the same format as the previous ﬁgure – the only dif-
ference is that the target motion has been rectiﬁed so that it is (approximately)
hemi-sinusoidal. The thing to note here is that the improved accuracy of the
pursuit previously apparent at the onset of the second cycle of motion has now
disappeared – because active inference does not have access to the immediately
preceding trajectory. This failure of an anticipatory improvement in tracking is
contrary to empirical predictions.
27
(compare Figures 7 and 8, upper right panels). However, action is initiated with
a slightly shorter latency, which is suﬃcient to account for the improved pursuit
when informed by the prior beliefs about the smooth trajectory of the target.
5.3 Summary
In summary, by simply replacing the target with the hidden cause of target mo-
tion – as the attractor of oculomotor trajectories – we can account for empirical
observations of improved pursuit during periodic target motion. In the context
of active inference, this smooth trajectory can only be recognised – and used to
inform action – after the onset of periodic motion. However, this smooth pursuit
model still fails to account for anticipatory eﬀects that are not directly available
in sensory trajectories. Empirical observations suggest that any systematic or
regular structure in target motion can facilitate the accuracy of smooth pursuit,
even if this information is not represented explicitly in target motion. A nice
example of this rests on the use of rectiﬁed periodic motion, in which only right-
ward target excursions are presented. Experimentally, subjects can anticipate
the periodic but abrupt onset of motion, provided they recognise the underly-
ing periodic behaviour of the target. We can emulate this hemi-periodic motion
by thresholding the hidden cause to suppress leftward deﬂections. Figure 9
shows the results of simulating smooth pursuit using the same format as Fig-
ure 8. The only diﬀerence here is that we replaced the sinusoidal hidden cause
ν(t) = sin(2 πf ·t) with ν(t) = exp(4(sin(2 πf ·t) −1)). This essentially sup-
presses motion before rightward motion. This suppression completely removes
the beneﬁt of smooth pursuit after a cycle of motion – compare Figures 8 and 9.
Here, the peak spatial lag at the onset of the second cycle of motion is exactly
the same as the lag at the onset of motion; in other words, there is no apparent
beneﬁt of modelling the hidden causes of motion in terms of pursuit accuracy.
This failure to model the anticipatory eye movements seen experimentally leads
us to consider a full hierarchical model for anticipatory pursuit.
6 Results: anticipatory pursuit
This section presents a full hierarchical model of anticipatory smooth pursuit eye
movements that tries to account for anticipatory oculomotor responses that are
driven by extra-retinal beliefs about the periodic behaviour of targets. This en-
tails adding a hierarchical level to the model that enables the agent to recognise
and remember the latent structure in target trajectories and suitably optimise
its pursuit movements – which are illustrated here in terms of an improvement
in the accuracy of target following after the onset of rectiﬁed target motion.
6.1 Anticipatory pursuit
The generative process used in these simulations is exactly the same as in the
above (smooth pursuit) scheme (see Equation 9); however, the generative model
of this process is equipped with an extra level in place of the model for the hidden
cause of target motion in the generative model:
28
s=
[
so
st
]
=
[
xo
xt −xo
]
+ ω(1)
ν
˙x=


˙xo
˙x′
o
˙xt

=


x′
t
1
tv
(ν(1) −xo) −ts
tv
x′
o
1
tm
(ν(1) −xt)

+ ω(1)
x
(10)
ν(1) =
[
σ(x(2)
1 )
0
]
+ ω(2)
ν
˙x(2) =
[
˙x(2)
1
˙x(2)
2
]
= ν(2)
[
x(2)
2
−x(2)
1
]
+ ω(2)
x
ν(2) = η+ ω(3)
ν
The ﬁrst level of the generative model is exactly the same as above. However,
the hidden causes are now informed by the dynamics of hidden states at the
second level. These hidden states model underlying periodic dynamics using a
simple periodic attractor that produces sinusoidal ﬂuctuations of any amplitude
or phase and a frequency that is determined by a second level hidden cause
with a prior expectation of a frequency of η (in Hz). It is somewhat similar to
a control system model that attempted to achieve zero-latency target tracking
by ﬁtting the trajectory to a (known) periodic signal (Bahill and McDonald,
1983). Our formulation ensures a Bayes optimal estimate of periodic motion
in terms posterior beliefs about its frequency. In these simulations, we used a
ﬁxed Gaussian prior centred on the correct frequency with a period of 512 ms.
This prior reproduces a typical experimental setting in which the oscillatory
nature of the trajectory is known, but its amplitude and phase (onset) are
unknown. Indeed, it has been shown that anticipatory responses are cofounded
when randomising the inter-cycle interval (Becker and Fuchs, 1985). In principle,
we could have considered many other forms of generative model, such as models
with prior beliefs about continuous acceleration (Bennett et al., 2010).
As above, all the random ﬂuctuations were assumed to have a log preci-
sion of four. Crucially, the mapping between the second level (latent) hidden
states and the motion of ﬁrst level hidden states encoding trajectories in vi-
sual (extrinsic) space is nonlinear. This means that latent periodic motion can
be distorted in any arbitrary way. Here, we use a soft thresholding function
σ(x) = exp(4(x−1)) to suppress negative (rightward) excursions of the target
to model hemi-sinusoidal motion. This is the same function we used to generate
the motion in Figure 9. Note that if the precision of the noise at the second
level falls to zero and there is no (precise) information at this level, the gen-
erative model assumes that the random ﬂuctuations have an inﬁnite variance.
As a consequence, the prediction at the level below in the hierarchical model
simpliﬁes to ν(1) = ω(2)
ν , and we recover Equation 9 describing the smooth
pursuit model. As a consequence this parameter tunes the relative strength of
anticipatory modulation.
Figure 10 shows the results of simulating active inference under this antic-
ipatory model, using the same format as Figure 9. However, there is now an
extra level of hidden states encoding latent periodic motion. It can be seen
29
that expectations about hidden states attain nonzero amplitudes shortly after
motion onset and are periodic thereafter. These provide predictions about the
onset of rightward motion after the ﬁrst (latent) cycle, enabling a more accu-
rate oculomotor response. This is evidenced by the reduction in the spatial lag
at the onset of the second cycle of motion, relative to the ﬁrst (solid red lines
on the upper left). This improvement in accuracy should be compared to the
previous ﬁgure and reﬂects Bayes optimal anticipatory responses of the sort ob-
served empirically (Barnes, Barnes, and Chakraborti, 2000). Further evidence
of anticipatory inference can be seen by examining the conditional expectations
about hidden causes at the second level. Note the substantial reduction in pre-
diction error on the hidden cause (dotted red lines), when comparing the onset
of the second cycle to the onset of the ﬁrst. This reﬂects the fact that the con-
ditional expectations about the hidden cause show a much-reduced latency at
the onset of the second cycle due to top-down conditional predictions provided
by the second level hidden states. This recurrent and hierarchically informed
inference provides the basis for anticipatory oculomotor control and may be a
useful metaphor for the hierarchical anatomy of the visual-oculomotor system.
6.2 Summary
In conclusion, to account for anticipatory pursuit movements that are not im-
mediately available in target motion, one needs to equip generative models with
a hierarchal structure that can accommodate latent dynamics – that may or
may not be expressed at the sensory level. It is important to note that this
model is a gross simpliﬁcation of the complicated hierarchies that may exist
in the brain. For instance, while some anticipation may be induced in smooth
pursuit eye movements, some aspects, such as the aperture problem, may not be
anticipated (Montagnini, Spering, and Masson, 2006). In this model, the second
level hidden causes are simply driven by prediction errors and assume a con-
stant frequency. As a consequence, prior beliefs about frequency are modelled
as stationary. In the real brain one might imagine that models of increasing hi-
erarchical depth might allow for nonstationary frequencies and other dynamics
– that would better ﬁt behavioural data. We have chosen to illustrate the basic
ideas using a minimalistic example of anticipation in eye movements. Hierar-
chical extensions of this sort emphasise the distinction between visual motion
processing and attending oculomotor control based purely upon retinal and pro-
prioceptive input – they emphasise extra-retinal processing that is informed by
prior experience and beliefs about the latent causes of visual input. We will
exploit this anticipatory smooth pursuit model in future work, where visual
occluders are used to disclose beliefs about latent motion.
7 Discussion
In this paper, we have considered optimal motor control in the context of pur-
suit initiation and anticipatory smooth pursuit. In particular, we have taken a
Bayesian perspective on optimality and have simulated various aspects of eye
movement control using predictive coding and active inference. This provides
a solution to the problem of sensorimotor delays that reproduces the results of
earlier solutions — but using a neuronally plausible (predictive coding) scheme
30
9 
Position Position 
Position 
Frequency (Hz) 
Position Position 
Half-cycle motion: 
0 500 1000 
-1 
-0.5 
0 
0.5 
1 
Anticipatory model: 
prediction and error 
time (ms) 
0 500 1000 
-1 
-0.5 
0 
0.5 
1 
hidden states 
time (ms) 
0 500 1000 
-1 
-0.5 
0 
0.5 
1 
time (ms) 
0 500 1000 
-1 
-0.5 
0 
0.5 
1 
hidden states 
time (ms) 
0 500 1000 
-0.05 
0 
0.05 
0.1 
0.15 
0.2 
hidden causes 
time (ms) 
0 500 1000 
-1 
-0.5 
0 
0.5 
1 
time (ms) 
perturbation and action 
hidden causes 
Aperiodic motion: 
Figure 10: This ﬁgure uses the same format as the previous ﬁgure – the only
diﬀerence is that the generative model has been equipped with a second hier-
archical level that contains hidden states, modelling latent periodic behaviour
of the (hidden) causes of target motion. With this addition, the improvement
in pursuit accuracy apparent at the onset of the second cycle of motion is re-
instated. This is because the model has an internal representation of latent
causes of target motion that can be called upon even when these causes are not
expressed explicitly in the target trajectory.
31
that has been applied to a whole range of perceptual, psychophysical, decision
theoretic and motor control problems beyond oculomotor control. Active infer-
ence depends upon a generative model of stimulus trajectories and their active
sampling through movement. This requires a careful consideration of the gener-
ative models that might be embodied by the visual-oculomotor system – and the
sorts of behaviours one would expect to see under these models. The treatment
in this paper distinguishes between three levels of predictive coding with respect
to oculomotor control: the ﬁrst is at the lowest level of sensorimotor message
passing between the sensorium and internal states representing the causes of
sensory signals. Here, we examined the potentially catastrophic eﬀects of senso-
rimotor delays and how they can easily render oculomotor tracking inherently
unstable. This problem can be ﬁnessed – in a relatively straightforward way –
by exploiting representations in generalized coordinates of motion. These can be
used to oﬀset both sensory and motor delays, using simple and neurobiologically
plausible mixtures of generalized motion. We then motivated a model of smooth
pursuit eye movements by noting that a simple model of target following cannot
account for the improvement in visual tracking after the onset of smooth and
continuous target trajectories. In this paper, smooth pursuit was modelled in
terms of hidden causes that attracted both the target and centre of gaze simulta-
neously – enabling the trajectory of the target to inform estimates of the hidden
cause that, in turn, provide predictions about oculomotor consequences. While
this extension accounted for experimentally observed tracking improvements –
under continuous trajectories – it does not account for anticipatory movements
that have to accumulate information over time. This anticipatory behaviour
could only be explained with a deeper hierarchical model that has an explicit
representation of latent (periodic) structure causing target motion. When the
generative model was equipped with a deeper structure, it was then able to
produce anticipatory movements of the sort seen experimentally. Clearly, the
simulations in this paper are just heuristic and do not represent a proper sim-
ulation of neurobiological processing. However, they can be taken as proof of
principle that the basic computational architecture – in terms of generalized
representations and hierarchical models – can explain some important and em-
pirical facts about eye movements. In what follows, we consider the models in
this paper in relation to other models and how modelling of this sort may have
important implications for understanding the visual-oculomotor system.
7.1 Comparison with other models
The model that we have presented here speaks to and complements several
existing models of the oculomotor system. First, it shares some properties with
computer vision algorithms used for image stabilisation. Such models often use
motion detection coupled with salient feature detection for the registration of
successive frames (Lucas and Kanade, 1981). A major diﬀerence is that these
models are often applied to very speciﬁc problems or conﬁgurations for which
they give an eﬃcient, yet ad hoc solution. A more generic approach is to use -
as our model does - a probabilistic method, for instance particle ﬁltering (Isard
and Blake, 1998). Our model provides a constructive extension – as we integrate
the dynamics of both sensation and action. In principle, this could improve the
on-line response of feature tracking algorithms.
Second, using our modelling approach, we reproduce similar behaviours
32
shown by other neuromimetic models of the oculomotor system. For example,
the pursuit of a dot with known uncertainty can be modelled as the response
of a Kalman ﬁlter (Kalman, 1960). Both generalized Bayesian (active inference)
and Kalman ﬁltering predict the current state of the system using prior knowl-
edge (about previous target locations) and reﬁne these predictions using sensory
data (prediction errors). This analogy with block-diagrams from control theory
was ﬁrst highlighted by (Robinson, Gordon, and Gordon, 1986) and (Krauzlis
and Lisberger, 1989) – and has since been used widely (Grossberg et al., 1997).
For a recent treatment involving the neuromorphic modelling of cortical areas,
see (Shibata et al., 2005). However, it should be noted that the link with Kalman
ﬁltering is rarely explicit (but see (Xivry et al., 2013)); most models have been
derived heuristically, rather than as optimal solutions under a generative model.
One class of such neuromimetic models uses neural networks that mimic the be-
haviour of the Kalman ﬁlter (Haykin, 2001). This model was used to ﬁt and
predict the response of smooth pursuit eye movements under diﬀerent experi-
mental parameters (Montagnini et al., 2007) or while interrupting information
ﬂow (Bogadhi et al., 2011). Developing this methodology – and by analogy with
modular control theory architectures – these building blocks can be assembled
to accommodate increasingly complex behavioural tasks. This can take the form
of a multi-layered model for transparency processing (Raudies, Mingolla, and
Neumann, 2011) or of an interconnected graph connecting the form and motion
pathways (Beck, Ognibeni, and Neumann, 2008). Such models have been used
to understand adaptation to blanking periods and to tune the balance between
sensory and proprioceptive inputs (Madelain and Krauzlis, 2003). Our model is
diﬀerent in a key aspect: The Kalman ﬁlter is indeed the (Bayes) optimal solu-
tion under a linear generative model but a cascade of such solutions is not the
optimal solution to (non-linear) hierarchical models (Balaji and Friston, 2011).
The active inference approach considers the (embodied) system as a whole and
furnishes an optimal solution in the form of generalized Bayesian ﬁltering. In
particular, given the delays at the sensory and motor levels, it provides an opti-
mal solution that accommodates (or compensates for) these delays. As shown in
the results, the ensuing behavior reproduces experimental results from pursuit
initiation (Masson, Montagnini, and Ilg, 2010) to anticipatory responses (Avila
et al., 2006; Barnes, Barnes, and Chakraborti, 2000). The approach thus pro-
vides in inclusive framework, compared with heuristics used in neuromimetic
models that focus on speciﬁc aspects of oculomotor control (see below).
The model presented here shares many features with other probabilistic mod-
els. First, representations are encoded as probability density is. This allows
processing and control to be deﬁned in terms of probabilistic inference; for in-
stance, by specifying a prior belief that favours slow speeds (Weiss, Simoncelli,
and Adelson, 2002). This approach has been successful in explaining a wide
variety of physiological and psychophysical results. For example, it allows one
to model spatial (Perrinet and Masson, 2007) or temporal (Montagnini et al.,
2007) integration of information, using conditional independence assumptions.
Furthermore, recent developments have addressed the estimation of the shape
and parameters of priors for slow speeds (Stocker and Simoncelli, 2006) and
for the integration of ambiguous versus non-ambiguous information (Bogadhi,
Montagnini, and Masson, 2011). The active inference scheme used here relies on
generative models that entail exactly the same sorts of priors. It has also been
shown that free energy minimisation extends the type of probabilistic models
33
described above to encompass retinal stabilisation and oculomotor reﬂexes (Fris-
ton et al., 2010b). A crucial diﬀerence here is that we have explicitly considered
the problem of dynamics and delays. Our goal was to understand how the sys-
tem could provide an optimal solution, when it knows (or can infer) the delay
between sensing input (in the past) and processing information that informs ac-
tion (in the future). This endeavour allowed us to build a model – using simple
priors over the dynamics of the hidden causes – that reproduces the sorts of
anticipatory behaviour seen empirically.
7.2 Limitations
Clearly, there are many aspects of oculomotor control we have ignored in this
theoretical work. Foremost, we have used a limited set of stimuli to validate
the model. Pursuit initiation was only simulated using a simple sweep of a dot,
while smooth pursuit was studied using a sinusoidal trajectory. However, these
types of stimuli are commonly used in the literature, as they best characterise
the type of behaviour (following, pursuit) that we have tried to characterise:
see (Barnes, 2008) for a review. We have not attempted to reproduce the os-
cillations at steady state as in (Robinson, Gordon, and Gordon, 1986) or (Gol-
dreich, Krauzlis, and Lisberger, 1992), although this may help to optimise the
parameters of our model in relation to empirical data. The hemi-sinusoidal
stimulus is also a typical stimulus for studying anticipatory responses (Avila
et al., 2006; Barnes, Barnes, and Chakraborti, 2000). Further validations of this
model would call on a wider range of stimuli and consider and accumulated
wealth of neurophysiological and behavioural data (Tlapale et al., 2010).
In this paper, we have focused on inference under a series of generative
models of oculomotor control. We have not considered how these models are
acquired or learned. In brief, the acquisition of generative models and their
subsequent optimisation in terms of their parameters (i.e., synaptic connection
strengths) is an important, if distinct, issue. In the context of active inference,
model acquisition and perceptual learning can be cast in terms of model selection
and parameter optimisation through the minimisation of free energy. Under
certain simplifying assumptions, this learning reduces to associative plasticity.
A discussion of these and related issues can be found in Friston (2008).
The generative model used in this paper has no explicit representation of
space but only the uncertain, vectorial position of a target. We have previously
studied the role of prediction in solving problems that are associated with the
detection of motion using a dynamical and probabilistic model of spatial inte-
gration (Perrinet and Masson, 2012). Both that model and the current model
entertain a similar problem: that of the integration of local information into a
global percept, in both the temporal (this manuscript) and spatial (Perrinet and
Masson, 2012) domains. We have considered integrating sensory information in
the spatial domain: terms of the prediction of sensory causes and their sampling
by saccades (Friston, Thornton, and Clark, 2012), and of the eﬀects on smooth
pursuit of reducing the precision. This manipulation can account for several ab-
normalities of smooth pursuit eye movements typical of schizophrenia (Adams,
Perrinet, and Friston, 2012). In this paper, we have limited ourselves to integrat-
ing information over time. It would be nice, in the future, to consider temporal
and spatial integration simultaneously.
A ﬁnal limitation of our model is the simpliﬁed modelling of the physical
34
properties of the oculomotor system – due to the biophysics of the eyes and
photoreceptors, sensory input contains motion streaks that can inﬂuence the
detection of motion (Barlow and Olshausen, 2004). Furthermore, we have ig-
nored delays in neuronal message passing among and within diﬀerent levels of
the hierarchy: for a review of quantitative data from monkeys see (Salin and
Bullier, 1995). Finally, we have not considered in any depth the ﬁner details of
how predictive coding or Bayesian ﬁltering might be implemented neuronally. It
should be noted that predictive coding in the cortex was attended by some early
controversies; for example, paradoxical increases in visual evoked responses were
observed when prediction error should be minimal. For example, a match be-
tween sensory signals and descending predictions can lead to the enhancement
of neuronal ﬁring (Roelfsema, Lamme, and Spekreijse, 1998). The neuronal im-
plementation assumed in our work (see 2) ﬁnesses many of these issues. In this
(hypothetical) scheme, predictions and prediction errors are encoded by the
neuronal activity of deep and superﬁcial pyramidal cells respectively (Mumford
1992; Bastos et al. 2012). In this scheme, the enhancement of evoked responses
is generally thought to reﬂect attentional gain, which corresponds to the opti-
mization of the expected precision (inverse variance) of prediction errors, via
synaptic gain control (Feldman and Friston, 2010). Put simply, attention in-
creases the gain of salient or precise prediction errors that the predictions are
trying to suppress. Indeed, the orthogonal eﬀects of expectations and attention
in predictive coding have been established empirically using fMRI (Kok et al.,
2011). See Bastos et al. (2012) for a review of the anatomical and electrophysi-
ological evidence that is consistent with the scheme used here.
7.3 Perspectives
Notwithstanding the limitations above, this approach may provide some inter-
esting perspectives on neural computations in the oculomotor system. First,
the model presented here can be compared to existing models of the oculomo-
tor system. In particular, any commonalities of function suggest that extant
neuromimetic models may be plausibly implemented using a generic predic-
tive coding architecture. Second, the Bayes optimal control solution rests on
a computational (anatomical) architecture that can be informed by electro-
physiological or psychophysical studies. For example, we have considered only
delays at the motor and sensory level. However, delays in axonal conduction
between hierarchical levels – within the visual-oculomotor system – may have
implications for intrinsic and extrinsic connectivity: in visual search, predic-
tions generated in higher areas (say supplementary and frontal eye ﬁelds) may
exploit a shorter path, by stimulating the actuator to sample more information
(by making an eye movement) rather than accumulating evidence by explaining
away prediction errors in lower (striate and extrastriate) cortical levels (Masson,
Montagnini, and Ilg, 2010). By studying the structure of connections implied
by theoretical considerations (see Figure 3), our modelling approach could pro-
vide a formal framework to test these sorts of hypotheses. A complementary
approach would be to apply dynamic causal modelling (Friston, Harrison, and
Penny, 2003) to electrophysiological data, using predictive coding architectures,
such that transmission delays (and their compensation or modeling) among lev-
els of the visual-oculomotor system could be evaluated empirically. A recent
example of using dynamic causal modelling to test hypotheses based upon pre-
35
dictive coding architectures can be found in Brown and Friston (2013). This
example focuses on attentional gain control in visual hierarchies.
Second, this work may provide a new perspective for experiments, in par-
ticular for the generation of stimuli. We have previously considered such a line
of research by designing naturalistic, texture-like pseudo–random visual stimuli
to characterise spatial integration during visual motion detection (Leon et al.,
2012). We were able to show that the oculomotor system exhibits an increased
following gain, when stimuli have a broad spatial frequency bandwidth. Inter-
estingly, the velocities of these stimuli were harder to discriminate relative to
narrow bandwidth stimuli – in a two alternative forced-choice psychophysical
task (Simoncini et al., 2012). In this work, the authors used competitive dy-
namics based on divisive normalisation. Moreover, textured stimuli were based
on a simple forward model of motion detection (Leon et al., 2012). This may
call for the use of more complex generative models to generate such textures.
In addition, the use of gaze contingent eye-tracking systems allows real-time
manipulation of the conﬁguration (position, velocity, delays) of the stimulus,
with respect to eye position and motion. By targeting diﬀerent sources of un-
certainty, at the diﬀerent levels of the hierarchical model, one might be able to
get a better characterisation of the oculomotor system.
The confounding inﬂuence of delays inherent in neuronal processing is a
strong biophysical constraint on neuronal dynamics. Representations in gen-
eralized coordinates of motion provide a potential resolution that may have
enjoyed positive evolutionary pressure. However, it remains unclear how neural
information, represented in a distributed manner across the nervous system,
is integrated with exteroceptive, operational time. The “binding” of diﬀerent
information, without a central clock, seems essential, but the correlate of such
a temporal representation of sensory information (independent of delays) has
never been observed explicitly in the nervous system. Elucidating the neural
representation of temporal information would greatly enhance our understand-
ing of both neural computations themselves and our interpretation of measured
electromagnetic (EEG and MEG) signals that are tightly coupled to those com-
putations.
Acknowledgments
LuP was supported by EC IP project FP6-015879, “FACETS” and FP7-269921,
“BrainScaleS” and by the Wellcome Trust Centre for Neuroimaging. RAA and
KJF are supported by the Wellcome Trust Centre for Neuroimaging.
8 Appendix
8.1 Appendix 1: Variational free energy
Here, we derive various formations of free-energy and show they relate to each
other. We start with the quantity we want to bound and implicitly minimise —
namely, surprise or the negative log-evidence associated with sensory states ˜s(t)
that have been caused by some unknown quantities Ψ( t). These hidden causes
correspond to the (generalized) motion (that is, position, velocity, acceleration,
...) of a target that the oculomotor system is tracking.
36
−ln p(˜s) = −ln
∫
p(˜s,Ψ)dΨ (11)
We now simply add a non-negative cross-entropy or divergence between some
arbitrary (conditional) density q(Ψ) = q(Ψ|˜µ) and the posterior density p(Ψ|˜s)
to create a free-energy bound on surprise
F = −ln p(˜s) +
∫
q(Ψ) ln q(Ψ)
p(Ψ|˜s)dΨ
= −ln p(˜s) + D(q(Ψ)||p(Ψ|˜s)) (12)
The cross entropy term is non-negative by Gibb’s inequality. Because sur-
prise depends only on sensory states, we can bring it inside the integral and use
p(˜s,Ψ) = p(Ψ|˜s)p(˜s) to show free-energy is a Gibb’s energy G = −ln p(˜s,Ψ)
expected under the conditional density minus the entropy of the conditional
density
F =
∫
q(Ψ) ln q(Ψ)
p(Ψ|˜s)p(˜s)dΨ
=
∫
q(Ψ) ln q(Ψ)
p(Ψ,˜s)dΨ (13)
= −
∫
q(Ψ) lnp(Ψ,˜s)dΨ +
∫
q(Ψ) lnq(Ψ)dΨ
This is a useful formulation because it can be evaluated in a relatively
straightforward way given a probabilistic generative model p(˜s,Ψ). A ﬁnal re-
arrangement, using p(˜s,Ψ) = p(˜s|Ψ)p(Ψ), shows free-energy is also complexity
minus accuracy, where complexity is the divergence between the recognition
density q(Ψ) and the prior density p(Ψ)
F =
∫
q(Ψ) ln q(Ψ)
p(Ψ|˜s)p(˜s)dΨ
= −
∫
q(Ψ) lnp(˜s|Ψ)dΨ + D(q(Ψ)||p(Ψ)) (14)
8.2 Appendix 2: The maximum entropy principle and the
Laplace assumption
If we admit an encoding of the conditional density up to second order moments,
then the maximum entropy principle (Jaynes, 1957), implicit in the deﬁnition of
free energy above, requires q(Ψ|˜µ) = N(˜µ,Σ) to be Gaussian. This is because
a Gaussian density has the maximum entropy of all forms that can be speci-
ﬁed with two moments. Assuming a Gaussian form is known as the Laplace
assumption and enables us to express the entropy of the conditional density in
terms of its ﬁrst moment or expectation. This follows because we can minimise
free energy with respect to the conditional covariance as follows:
37
F = G(˜s,˜µ) + 1
2tr(Σ∂˜µ˜µG) −1
2 ln |Σ|
G= −ln p(˜s,Ψ)
∂ΣF = 1
2∂˜µ˜µG−1
2Π (15)
so that ∂ΣF = 0 implies
Π = ∂˜µ˜µG
F = G(˜s,˜µ) + 1
2 ln |∂˜µ˜µG| (16)
Here, the conditional precision Π(˜s,˜µ) is the inverse of the conditional co-
variance Σ(˜s,˜µ). In short, free energy is a function of generalized conditional
expectations and sensory states.
8.3 Appendix 3: Integrating or solving active inference
schemes using generalized descents.
Given a generative model or its associated Gibbs energy function, one can now
simulate active inference by solving the following set of ordinary diﬀerential
equations for a system that includes generalized real-world states and internal
states of the agent mediating (delayed) action and perception:
˙u=


˙˜s
˙˜x
˙˜ν
˙˜ων
˙˜ωx
˙˜µ
˙˜η
˙a


=


D˜g(˜x,˜ν,˜a) + D˜ων
˜f(˜x,˜ν,˜a) + ˜ωx
D˜ν
D˜ων
D˜ωx
D˜µ−∂˜µF(T(τs −τs)˜s,˜µ)
D˜η
−∂aF(T(τs −τs+ τa −τa)˜s,T(τa −τa)˜µ)


(17)
generalized action ˜a(t) is approximated using discrete values of a(t) from
the past. Note that we have included a prior expectation ˜η(t) of hidden causes
to complete the agent’s generative model of its world. Integrating or solving
Equation 17 corresponds to simulating active inference. The updates of the
collective states over time steps of ∆ t use a local linearisation scheme (Ozaki,
1992):
38
∆u= (exp(∆t·∂u˙u) −I)(∂u˙u)−1
∂u˙u=


0 D∂˜x˜g D∂˜ν˜g D ... D∂a˜g
∂˜x ˜f ∂˜ν ˜f I ∂ a ˜f
... D ... ...
D
... D ...
−∂˜µ˜sF ... −D∂˜µ˜µF −∂˜µ˜ηF −∂˜µaF
−∂˜η˜µF D
−∂a˜sF −∂a˜µF −∂a˜ηF −∂aaF


(18)
Details about how to compute the gradients and curvatures pertaining to
the conditional expectations can be found in (Friston et al., 2010a). These are
generally cast in terms of prediction errors using straightforward linear alge-
bra. Because action can only aﬀect free-energy through the sensory states, its
dynamics are prescribed by the following gradients and curvatures (ignoring
higher-order terms):
∂aF = (∂a˜ε(1)
ν ) ·Π(1)
a T(τa −τa)˜ε(1)
ν
∂aaF = (∂a˜ε(1)
ν ) ·Π(1)
a T(τa −τa)(∂a˜ε(1)
ν )
(19)
∂a˜ε(1)
ν = T(τs −τs)∂a˜s(t)
∂a˜s= ∂a˜g+ ∂˜x˜g(
∑
i
D−i(∂˜x ˜f)i−1)∂a ˜f
The partial derivative of the sensory states with respect to action and is spec-
iﬁed by the generative process. In biologically plausible instances of this scheme,
this derivative would have to be computed on the basis of a mapping from ac-
tion to sensory consequences. It is generally assumed that agents are equipped
with ∂a˜s epigenetically, because it has a simple form. For example, contract-
ing a muscle ﬁbre elicits a proprioceptive stretch signal in a one-to-one fashion.
The precision matrix Π(1)
a in Equation 19 is speciﬁed such that only propriocep-
tive prediction errors with these simple forms have nonzero precision. This can
be regarded as the motor gain in response to proprioceptive prediction errors.
Equation 18 may look complicated but can be evaluated automatically using nu-
merical derivatives for any given generative model. All the simulations in this
paper used just one routine — toolbox/DEM/spm ADEM.m— and summarised
in the script toolbox/DEM/ADEM oculomotor delays.m. Both are available as
part of the SPM software ( http://www.fil.ion.ion.ucl.ac.uk/spm).
References
Adams, Rick A., Laurent U. Perrinet, and Karl Friston (Oct. 2012). “Smooth
Pursuit and Visual Occlusion: Active Inference and Oculomotor Control in
Schizophrenia”. In: PLoS ONE 7.10. Ed. by Xiang Y. Zhang, e47502+.
39
Arnold, Derek H., Yolanda Ong, and Warrick Roseboom (May 2009). “Simple
diﬀerential latencies modulate, but do not cause the ﬂash-lag eﬀect”. In:
Journal of Vision 9.5.
Avila, Matthew T. et al. (Feb. 2006). “Role of anticipation in schizophrenia-
related pursuit initiation deﬁcits.” In: Journal of neurophysiology 95.2,
pp. 593–601.
Bahill, A. T. and J. D. McDonald (1983). “Model emulates human smooth
pursuit system producing zero-latency target tracking.” In: Biological cyber-
netics 48.3, pp. 213–222.
Balaji, Bhashyam and Karl Friston (2011). “Bayesian state estimation using
generalized coordinates”. In: Orlando, Florida, USA, 80501Y–80501Y–12.
Ballard, Dana H., Geoﬀrey E. Hinton, and Terrence J. Sejnowski (Nov. 1983).
“Parallel visual computation”. In: Nature 306.5938, pp. 21–26.
Barlow, Horace B. and Bruno A. Olshausen (May 2004). “Convergent evidence
for the visual analysis of optic ﬂow through anisotropic attenuation of high
spatial frequencies.” In: Journal of vision 4.6, pp. 415–426.
Barnes, G. R. and P. T. Asselman (Aug. 1991). “The mechanism of prediction
in human smooth pursuit eye movements.” In: The Journal of physiology
439, pp. 439–461.
Barnes, Graham R. (Dec. 2008). “Cognitive processes involved in smooth pursuit
eye movements.” In: Brain and cognition 68.3, pp. 309–326.
Barnes, Graham R., D. M. Barnes, and S. R. Chakraborti (Nov. 2000). “Ocular
pursuit responses to repeated, single-cycle sinusoids reveal behavior compat-
ible with predictive pursuit”. In: Journal of Neurophysiology 84.5, pp. 2340–
2355.
Barnes, Graham R. and A. M. Schmid (June 2002). “Sequence learning in human
ocular smooth pursuit.” In: Experimental Brain Research 144.3, pp. 322–35.
Bastos, Andre M. et al. (Nov. 2012). “Canonical microcircuits for predictive
coding”. In: Neuron 76.4, pp. 695–711.
Beal, Matthew J. (2003). Variational algorithms for approximate Bayesian in-
ference.
Beck, Cornelia, Thilo Ognibeni, and Heiko Neumann (Nov. 2008). “Object seg-
mentation from motion discontinuities and temporal occlusions: A biologi-
cally inspired model”. In: PLoS ONE 3.11. Ed. by Ernest Greene, e3807+.
Becker, W. and A. F. Fuchs (1985). “Prediction in the oculomotor system:
smooth pursuit during transient disappearance of a visual target.” In: Ex-
perimental brain research 57.3, pp. 562–575.
Bennett, S. J. et al. (Sept. 2007). “Target acceleration can be extracted and
represented within the predictive drive to ocular pursuit”. In: Journal of
Neurophysiology 98.3, pp. 1405–1414.
Bennett, Simon J. et al. (June 2010). “Oculomotor prediction of accelerative
target motion during occlusion: long-term and short-term eﬀects”. In: Ex-
perimental Brain Research 204.4, pp. 493–504.
Bialek, William, Ilya Nemenman, and Naftali Tishby (Nov. 2001). “Predictabil-
ity, complexity, and learning”. In: Neural Computation 13.11, pp. 2409–
2463.
Bogadhi, Amarender, Anna Montagnini, and Guillaume Masson (Sept. 2011).
“Interaction between retinal and extra retinal signals in dynamic motion
integration for smooth pursuit”. In: Journal of Vision 11.11, p. 533.
40
Bogadhi, Amarender et al. (Apr. 2011). “Pursuing motion illusions: a realistic
oculomotor framework for Bayesian inference”. In: Vision research 51.8,
pp. 867–880.
Changizi, Mark A. (2001). “’Perceiving the present’ as a framework for ecological
explanations of the misperception of projected angle and angular size”. In:
Perception 30.2, pp. 195–208.
Changizi, Mark A. and David M. Widders (2002). “Latency correction explains
the classical geometrical illusions”. In: Perception 31.10, pp. 1241–1262.
Changizi, Mark A. et al. (2008). “Perceiving the Present and a Systematiza-
tion of Illusions”. In: Cognitive Science: A Multidisciplinary Journal 32.3,
pp. 459–503.
Collins, C. J. S. and Graham R. Barnes (Oct. 2009). “Predicting the unpre-
dictable: weighted averaging of past stimulus timing facilitates ocular pursuit
of randomly timed stimuli.” In: The Journal of neuroscience : the oﬃcial
journal of the Society for Neuroscience 29.42, pp. 13302–14.
Dayan, P. et al. (Sept. 1995). “The Helmholtz machine.” In:Neural computation
7.5, pp. 889–904.
Dodge, R., R. C. Travis, and J. C. Fox (1930). “Optic nystagmus: III. Charac-
teristics of the slow phase”. In: Archives of Neurology 24, pp. 21–34.
Duhamel, J. R., C. L. Colby, and M. E. Goldberg (Jan. 1992). “The updat-
ing of the representation of visual space in parietal cortex by intended eye
movements”. In: Science 255.5040, pp. 90–92.
Feldman, Anatol G. and Mindy F. Levin (Feb. 1995). “The origin and use of
positional frames of reference in motor control”. In: Behavioral and Brain
Sciences 18.04, pp. 723–744.
Feldman, Harriet and Karl J. Friston (2010). “Attention, uncertainty, and Free-
Energy”. In: Frontiers in Human Neuroscience 4.
Friston, K. J., L. Harrison, and W. Penny (Aug. 2003). “Dynamic causal mod-
elling.” In: NeuroImage 19.4, pp. 1273–1302.
Friston, Karl (Nov. 2008). “Hierarchical models in the brain”. In: PLoS Com-
putational Biology 4.11. Ed. by Olaf Sporns, e1000211+.
Friston, Karl (July 2009). “The free-energy principle: a rough guide to the
brain?” In: Trends in cognitive sciences 13.7, pp. 293–301.
Friston, Karl (Nov. 2011). “What Is optimal about motor control?” In: Neuron
72.3, pp. 488–498.
Friston, Karl and Stefan Kiebel (Oct. 2009). “Cortical circuits for perceptual
inference”. In: Neural Networks 22.8, pp. 1093–1104.
Friston, Karl, Christopher Thornton, and Andy Clark (2012). “Free-Energy
minimization and the Dark-Room problem”. In: Frontiers in Psychology 3.
Friston, Karl et al. (2010a). “Generalised Filtering”. In: Mathematical Problems
in Engineering 2010, pp. 1–35.
Friston, Karl et al. (2012). “Perceptions as hypotheses: Saccades as experi-
ments”. In: Frontiers in Psychology 3.
Friston, Karl J., Jean Daunizeau, and Stefan J. Kiebel (July 2009). “Reinforce-
ment learning or active inference?” In: PLoS ONE 4.7, e6421+.
Friston, Karl J. et al. (Mar. 2010b). “Action and behavior: a free-energy formu-
lation”. In: Biological Cybernetics 102.3, pp. 227–260.
Ginzburg, V. (Dec. 1955). “On the theory of superconductivity”. In: Il Nuovo
Cimento (1955-1965) 2.6, pp. 1234–1250.
41
Goldreich, D., R. J. Krauzlis, and S. G. Lisberger (Mar. 1992). “Eﬀect of
changing feedback delay on spontaneous oscillations in smooth pursuit eye
movements of monkeys.” In: Journal of neurophysiology 67.3, pp. 625–638.
Gregory, R. L. (July 1980). “Perceptions as hypotheses”. In: Philosophical
Transactions of the Royal Society B: Biological Sciences 290.1038, pp. 181–
197.
Grossberg, S. et al. (Dec. 1997). “A neural model of multimodal adaptive sac-
cadic eye movement control by superior colliculus.” In:The Journal of neuro-
science : the oﬃcial journal of the Society for Neuroscience 17.24, pp. 9706–
9725.
Haken, Hermann (1983). Synergetik. Vol. 2. Berlin, Heidelberg: Springer Berlin
Heidelberg.
Haykin, Simon (Oct. 2001). Kalman ﬁltering and neural networks. Ed. by Simon
Haykin. New York, USA: John Wiley & Sons, Inc.
Ilg, Uwe J. (Oct. 1997). “Slow eye movements”. In: Progress in Neurobiology
53.3, pp. 293–329.
Inui, Koji and Ryusuke Kakigi (July 2006). “Temporal analysis of the ﬂow from
V1 to the extrastriate cortex in humans”. In: Journal of Neurophysiology
96.2, pp. 775–784.
Isard, Michael and Andrew Blake (1998). “Condensation: conditional density
propagation for visual tracking”. In: International Journal of Computer
Vision 29.1, pp. 5–28.
Jaynes, E. (Oct. 1957). “Information Theory and Statistical Mechanics. II”. In:
Physical Review 108.2, pp. 171–190.
Kalman, R. E. (1960). “A new approach to linear ﬁltering and prediction prob-
lems”. In: Journal of Basic Engineering 82.1, pp. 35–45.
Knill, D. and A. Pouget (Dec. 2004). “The Bayesian brain: the role of un-
certainty in neural coding and computation.” In: Trends in neurosciences
27.12, pp. 712–719.
Kok, P. et al. (Nov. 2011). “Attention Reverses the Eﬀect of Prediction in
Silencing Sensory Signals”. In: Cerebral Cortex 22.9, pp. 2197–2206.
Kowler, Eileen (Jan. 1989). “Cognitive expectations, not habits, control antici-
patory smooth oculomotor pursuit”. In: Vision Research 29.9. 9, pp. 1049–
1057.
Kowler, Eileen and Robert M. Steinman (Jan. 1979). “The eﬀect of expectations
on slow oculomotor control - I. Periodic target steps”. In: Vision Research
19.6. 6, pp. 619–632.
Krauzlis, R. J. and S. G. Lisberger (Mar. 1989). “A control systems model
of Smooth Pursuit Eye Movements with realistic emergent properties”. In:
Neural Computation 1.1, pp. 116–122.
Krauzlis, Richard J. (Feb. 2004). “Recasting the smooth pursuit eye movement
system”. In: Journal of Neurophysiology 91.2, pp. 591–603.
Leon, P. S. et al. (Mar. 2012). “Motion clouds: model-based stimulus synthesis
of natural-like random textures for the study of motion perception”. In:
Journal of Neurophysiology 107.11, pp. 3217–3226.
Levy, D. L. et al. (1993). “Eye tracking dysfunction and schizophrenia: a critical
perspective.” In: Schizophrenia bulletin 19.3, pp. 461–536.
Lisberger, S. G., E. J. Morris, and L. Tychsen (Mar. 1987). “Visual motion pro-
cessing and sensory-motor integration for smooth pursuit eye movements.”
In: Annual Review of Neuroscience 10.1, pp. 97–129.
42
Lisberger, S. G. and J. A. Movshon (Mar. 1999). “Visual motion analysis for
pursuit eye movements in area MT of macaque monkeys.” In: The Journal
of neuroscience : the oﬃcial journal of the Society for Neuroscience 19.6,
pp. 2224–2246.
Lucas, B. D. and T. Kanade (1981). “An Iterative Image Registration Technique
with an Application to Stereo Vision”. In: Proceedings of the Seventh Inter-
national Joint Conference on Artiﬁcal Intelligence, IJCAI 1981 . Vancouver,
Canada, pp. 674–679.
Madelain, Laurent and Richard J. Krauzlis (Aug. 2003). “Eﬀects of learning
on smooth pursuit during transient disappearance of a visual target.” In:
Journal of neurophysiology 90.2, pp. 972–982.
Masson, Guillaume S. and Uwe J. Ilg, eds. (2010). Dynamics of visual motion
processing: neuronal, behavioral and computational approaches. First. Berlin-
Heidelberg: Springer.
Masson, Guillaume S., Anna Montagnini, and Uwe J. Ilg (2010). “When the
Brain Meets the Eye: Tracking Object Motion”. In: Dynamics of Visual
Motion Processing. Ed. by Uwe J. Ilg and Guillaume S. Masson. Boston,
MA: Springer US. Chap. 8, pp. 161–188.
Michael, J. A. and G. M. Jones (Dec. 1966). “Dependence of visual tracking
capability upon stimulus predictability.” In: Vision research 6.12, pp. 707–
716.
Montagnini, Anna, Miriam Spering, and Guillaume S. Masson (Dec. 2006).
“Predicting 2D target velocity cannot help 2D motion integration for smooth
pursuit initiation.” In: Journal of neurophysiology 96.6, pp. 3545–3550.
Montagnini, Anna et al. (Jan. 2007). “Bayesian modeling of dynamic motion
integration”. In: Journal of Physiology (Paris) 101.1-3, pp. 64–77.
Mumford, D. (1992). “On the computational architecture of the neocortex. II.
The role of cortico-cortical loops.” In: Biological cybernetics 66.3, pp. 241–
251.
Nijhawan, Romi (July 1994). “Motion extrapolation in catching”. In: Nature
370.6487.
Nijhawan, Romi (May 2008). “Visual prediction: Psychophysics and neurophys-
iology of compensation for time delays”. In: Behavioral and Brain Sciences
31.02, pp. 179–198.
Nkam, Irene et al. (May 2010). “Impaired smooth pursuit in schizophrenia
results from prediction impairment only.” In: Biological psychiatry 67.10,
pp. 992–997.
Olshausen, B. A. and D. J. Field (June 1996). “Emergence of simple-cell re-
ceptive ﬁeld properties by learning a sparse code for natural images.” In:
Nature 381.6583, pp. 607–609.
Ozaki, T. (1992). “A bridge between nonlinear time series models and nonlinear
stochastic dynamical systems: a local linearization approach”. In: Statistica
Sinica 2.1, pp. 113–135.
Perrinet, Laurent U. and Guillaume S. Masson (2007). “Modeling spatial in-
tegration in the ocular following response using a probabilistic framework”.
In: Journal of Physiology (Paris) 101.1–3, pp. 46–55.
Perrinet, Laurent U. and Guillaume S. Masson (Oct. 2012). “Motion-Based Pre-
diction Is Suﬃcient to Solve the Aperture Problem”. In:Neural Computation
24.10, pp. 2726–2750.
43
Rao, R. P. and D. H. Ballard (Jan. 1999). “Predictive coding in the visual cortex:
a functional interpretation of some extra-classical receptive-ﬁeld eﬀects”. In:
Nat Neurosci 2.1, pp. 79–87.
Raudies, Florian, Ennio Mingolla, and Heiko Neumann (Aug. 2011). “A Model
of Motion Transparency Processing with Local Center-Surround Interactions
and Feedback”. In: Neural Computation 23.11, pp. 2868–2914.
Robinson, D. A. (1965). “The mechanics of human smooth pursuit eye move-
ment.” In: The Journal of Physiology 180, pp. 569–591.
Robinson, D. A., J. L. Gordon, and S. E. Gordon (Oct. 1986). “A model of
the smooth pursuit eye movement system”. In: Biological Cybernetics 55.1,
pp. 43–57.
Roelfsema, P. R., V. A. Lamme, and H. Spekreijse (Sept. 1998). “Object-based
attention in the primary visual cortex of the macaque monkey.” In: Nature
395.6700, pp. 376–381.
Roelfsema, Pieter R. et al. (Jan. 1997). “Visuomotor integration is associ-
ated with zero time-lag synchronization among cortical areas.” In: Nature
385.6612, pp. 157–161.
Salin, P. A. and J. Bullier (Jan. 1995). “Corticocortical connections in the visual
system: structure and function.” In: Physiological reviews 75.1, pp. 107–154.
Shibata, Tomohiro et al. (Apr. 2005). “A model of smooth pursuit in primates
based on learning the target dynamics”. In: Neural Networks 18.3, pp. 213–
224.
Simoncini, Claudio et al. (Nov. 2012). “More is not always better: adaptive
gain control explains dissociation between perception and action”. In: Nat
Neurosci 15.11, pp. 1596–1603.
Spering, Miriam et al. (May 2005). “Eﬀects of contrast on smooth pursuit eye
movements”. In: Journal of Vision 5.5.
Stocker, Alan A. and Eero P. Simoncelli (Mar. 2006). “Noise characteristics
and prior expectations in human visual speed perception”. In: Nature Neu-
roscience 9.4, pp. 578–585.
Thaker, G. K. et al. (Nov. 1999). “Smooth pursuit eye movements to extra-
retinal motion signals: deﬁcits in patients with schizophrenia.” In:Psychiatry
research 88.3, pp. 209–219.
Thompson, P. (1982). “Perceived rate of movement depends on contrast.” In:
Vision research 22.3, pp. 377–380.
Tlapale, milien et al. (June 2010).Towards a bio-inspired evaluation methodology
for motion estimation models . Tech. rep. RR-7317. INRIA, p. 18.
Vaughn, Don A. and David M. Eagleman (2013). “Spatial warping by oriented
line detectors can counteract neural delays”. In: Frontiers in Psychology 4.
Weiss, Yair, Eero P. Simoncelli, and Edward H. Adelson (June 2002). “Motion
illusions as optimal percepts”. In: Nature Neuroscience 5.6, pp. 598–604.
Westheimer, G. (1954). “Eye movement responses to a horizontally moving
visual stimulus”. In: Archives of Ophthalmology 52, pp. 932–43.
Wyatt, H. J. and J. Pola (Sept. 1981). “Slow eye movements to eccentric tar-
gets.” In: Investigative ophthalmology & visual science 21.3, pp. 477–483.
Wyatt, H. J. and J. Pola (1987). “Smooth eye movements with step-ramp
stimuli: the inﬂuence of attention and stimulus extent.” In: Vision research
27.9, pp. 1565–1580.
44
Xivry, Jean-Jacques O. de et al. (Oct. 2013). “Kalman Filtering Naturally
Accounts for Visually Guided and Predictive Smooth Pursuit Dynamics”.
In: The Journal of Neuroscience 33.44, pp. 17301–17313.
Yuille, Alan and Daniel Kersten (July 2006). “Vision as Bayesian inference:
analysis by synthesis?” In: Trends in Cognitive Sciences 10.7, pp. 301–308.
45