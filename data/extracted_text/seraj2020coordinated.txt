Coordinated Control of UAVs for Human-Centered Active Sensing of
Wildfires
Esmaeil Seraj1 and Matthew Gombolay1
Abstract—Fighting wildfires is a precarious task, imperiling
the lives of engaging firefighters and those who reside in the
fire’spath.Firefightersneedonlineanddynamicobservationof
the firefront to anticipate a wildfire’s unknown characteristics,
such as size, scale, and propagation velocity, and to plan
accordingly. In this paper, we propose a distributed control
framework to coordinate a team of unmanned aerial vehicles
(UAVs) for a human-centered active sensing of wildfires. We
develop a dual-criterion objective function based on Kalman
uncertainty residual propagation and weighted multi-agent
consensusprotocol,whichenablestheUAVstoactivelyinferthe
wildfire dynamics and parameters, track and monitor the fire
transition,andsafelymanagehumanfirefightersontheground
usingacquiredinformation.Weevaluateourapproachrelative
Fig. 1: Firefighters trying to control a back burn as the
to prior work, showing significant improvements by reducing
theenvironmentscumulativeuncertaintyresidualbymorethan Carr fire spreads toward Douglas City. Courtesy of the Los
102 and105 timesinfirefrontcoverageperformancetosupport Angeles Times (May 2019).
human-robotteamingforfirefighting.Wealsodemonstrateour
method on physical robots in a mock firefighting exercise.
also been applied to this problem to enable collaborative
I. INTRODUCTION monitoring of wildfires [11], [12], which can be enabled for
Fighting wildfires is a dangerous task and requires accurate onlinedataprocessingthroughNNpruningapproaches[13].
online information regarding firefront location, size and
scale, shape, and propagation velocity [1]. Firefighters may Many of the aforementioned studies require an accurate
lose their lives as a consequence of inaccurately anticipating function for fire-shape [10] to work, assuming an enlarging
informationeitherduetoinherentstochasticityinfirebehav- elliptical perimeter to be monitored by UAVs [1], [2], [6].
ior or low-quality and unusable information provided, such Supposing a shape model for large-scale wildfires is not
as low-resolution satellite images [2], [3]. Firefighters need realistic and thus not accurate [14]. While vision-based
frequent,high-qualityimagestomonitorthefirepropagation approaches are still struggling with fire smoke elimination
and plan accordingly (Fig. 1). Due to recent advances in and image stabilization problems [15], other approaches,
aerial robotic technology, UAVs have been proposed as a suchas[7],requireaheat-intensitymodelandaredependent
solution to overcoming the challenges of needing real-time on an accurate estimation of maximum heat-intensity within
information in fighting fires [4]. the entire fire-map. Additionally, [16] notes that RL and
In [1], a cooperative approach is proposed to detect local learning-based methods are prone to major drawbacks, such
fire areas in a wildfire using two groups of detector and ser- as scalability and domain shift problems as well as lack of
viceUAVagents.In[5],utilityofvisualandinfraredcameras formal guarantees on boundedness of errors, which are sig-
onheterogeneousUAVswithhoveringcapabilitiesisinvesti- nificant for safety-critical applications, such as firefighting.
gatedtomonitortheevolutionofthefirefrontshape.In[6],a There is a clear absence of human-centric approaches in
leader-follower-based distributed framework is proposed for theliteratureforUAVteamsforactivesensingofwildfireand
ateamofUAVstoevenlydistributeandtrackanellipticalfire firemonitoring.Thisismainlybecauseamajorityofprevious
perimeter. In [7], a heat-intensity-based distributed control studies are solely focused on autonomous fire detection
framework is designed for a team of UAVs to be capable of and surveilling a large burning area by drones rather than
closely monitoring a wildfire in open space. More recently, focusing on local human-defined areas of priority (areas of
both model-based (i.e., Kalman estimation) and learning- firefighter activity) and serving firefighters. In this study, we
based (deep convolutional neural network) methods have seekabettercontrolstrategy,towardahuman-centeredrobot
been used for cooperative prediction and tracking of the coordination, through better perception and accurate local
firefront shape [8], [9], [10]. Additionally, other learning- situational awareness. We overcome key limitations in prior
basedapproaches,suchasreinforcementlearning(RL),have work by developing an algorithmic framework to provide a
model-predictive mechanism that enables firefighters on the
1Institute for Robotics and Intelligent Machines, Georgia Institute
ground to receive online, high-quality information regarding
of Technology, Atlanta, GA 30332, USA eseraj3@gatech.edu,
matthew.gombolay@cc.gatech.edu their time-varying proximity to a fire.
0202
nuJ
41
]YS.ssee[
1v96970.6002:viXra
In our approach, we explicitly estimate the latent fire weather forecasting equipment. By ignoring the superscript
propagation dynamics and parameters via an adaptive ex- i in Eq. 1 and 2 and without losing generality, q˙ can be
t
tended Kalman filter (AEKF) predictor and the simplified estimatedforeachpropagatingfirefrontbyEq.3-4,whereq˙x
t
FARSITE wildfire propagation model [17] to account for andq˙xarefirst-orderfirefrontdynamicsforXandY axes[17]
t
firefighter’ssafetyandprovidethemwithonlineinformation
q˙
t
x=C(Rt,Ut)sin(θt) (3)
regarding propagating firefronts. This model allows us to
develop straightforward distributed control adapted from
q˙
t
y=C(Rt,Ut)cos(θt) (4)
(cid:18) (cid:19)
vehicle routing literature [18] to enable track-based fire cov- where C(Rt,Ut)=Rt 1− LB(√Ut) in which LB(Ut)=
erage. Moreover, a mathematical observation model through LB(Ut)+ GB(Ut)
which UAV sensors observe fire is derived to map from 0.936e0.256Ut+0.461e−0.154Ut−0.397 and GB(Ut)=LB(Ut)2−1.
state space to observation space. The calculated models are
B. Adaptive Extended Kalman Filter (AEKF)
then used in combination to derive a dual-criteria objective
We utilize an adaptive extended Kalman filter (AEKF) to
function in order to control a fleet of UAVs. The proposed
leveragethemathematicalfirepropagationmodelandtheob-
dual-criteria objective is an ad hoc, well-suited function to
servation model of a flying drone with respect to a dynamic
thewildfiremonitoringtask,whichminimizesenvironment’s
object on the ground to actively sense the fire-spots, infer
uncertainty on local, human-centered areas (first criteria)
wildfire dynamics and parameters, and propagate all sources
and maximizes coverage through ensemble-level formation
of measurement uncertainty. In a conventional extended
control of the robot network (second criteria).
Kalman filter (EKF), process and observation noise covari-
We empirically evaluate our approach against simulated
ances Q and Γ are often chosen as constant matrices based
wildfires alongside contemporary approaches for UAV cov- t t
onthestate-transitionmodelandsensoraccuracyanddonot
erage[7]aswellasagainstareinforcementlearningbaseline,
receive updates. However, this selection process is highly
demonstrating a promising utility of our approach. Our pro-
sensitivetouserexperienceandcanbeextremelyinaccurate.
posed coordinated controller is capable of reducing the cu-
We leverage AEKF [19], which introduces innovation and
mulativeuncertaintyresidualofthefireenvironmentbymore
residual-based updates for process and observation noise
than 102 and 105 times in firefront coverage performance
covariances, as shown in Eq. 5-6, where α is a forgetting
to support human-robot teaming for firefighting. We also
factor and d is the measurement innovation and is defined
assess the feasibility of our method through implementation t
as the difference between the actual measurement and its
on physical robots in a mock firefighting scenario.
predicted value. Moreover, K is the Kalman gain and H is
t t
II. PRELIMINARIES the observation Jacobian matrix.
(cid:16) (cid:17)
In this section, we first introduce the simplified FARSITE Qt=αQ t−1 +(1−α) Ktdtd t TK t T (5)
wildfire propagation mathematical model and calculate the (cid:16) (cid:17)
fire dynamics. We then review the fundamentals of AEKF.
Γt=αΓt−1 +(1−α) y˜ty˜
t
T+HtP
t|t−1
H
t
T (6)
These adaptive updates remove the assumption of constant
A. FireAreaSimulator(FARSITE):FirePropagationModel
covariancesQ andΓ andenableevenmoreaccuratepredic-
t t
The Fire Area Simulator (FARSITE) wildfire propagation tionsovertimeastheKalmanfilterleveragesitsobservations
model was first introduced by Finney et al [17], which is to improve the predicted covariance matrix P [19].
t|t−1
nowwidelyusedbytheUSDINationalParkService,USDA
Forest Service, and other land management agencies at the
III. PROBLEMSTATEMENTANDALGORITHMIC
federal and state levels. The model has been utilized to
OVERVIEW
simulate the spread of a wildfire, factoring in heterogeneous The focus of our study includes two important aspects of
conditions of terrain, fuels, and weather and their influence wildfire fighting: (1) providing high-quality information on
onfiredynamics.ThefullFARSITEmodelincludescomplex firefront status while accounting for physical and method-
equations, and precise model implementation requires a ologicalerrorsand(2)human-centeredcoverageandtracking
significant amount of geographical and physical information of wildfire to account for firefighter safety. Accordingly, we
on terrain, fuels, and weather. As such, researchers tend definehigh-qualityinformationashigh-resolutionandonline
to modify the model by considering few simplifying as- imagesofareasprioritizedbyhumans.Wetakeadvantageof
sumptions [7]. The wildfire propagation dynamics using a theestimateduncertaintyoftheenvironmenttoachievethese
simplified FARSITE model are shown in Eq. 1 and 2. objectives. Through a unified error propagation system, not
only can the physical and methodological uncertainties be
qi=qi +q˙i δt (1)
t t−1 t−1 leveraged to manage the human teams and account for their
d (cid:16) (cid:17)
q˙i= qi (2) safety, they can also be used to manage the UAV team, both
t dt t
in node-level and ensemble-level dynamics. An AEKF is a
Intheaboveequations,qi indicatesthelocationoffirefronti propercandidatefortheuncertaintypropagationsystemhere
t
attimet,andq˙i isitsgrowthrate(i.e.,propagationvelocity). since it can accumulate physical and methodological errors
t
q˙ is a function of fire spread rate (R), wind speed (U), and and generate a cumulative error map through the calculated
t t t
windazimuth(θ),whichareavailabletooursystemthrough probability distribution and predicted covariance matrix.
t
Accordingly, UAVs initially calculate two uncertainty Algorithm 1: Stages of the proposed human-centered
maps: (1) a firefront uncertainty map (Section IV-A.1) and coordinated control for a team of UAVs.
(2) a human uncertainty map (Section IV-A.2). The latter is input :Obtaintherendezvousarea pr,fire-mapQt,humanGPSdata
generatedthroughabimodaldistributionofhumanlocations p t h,UAVpositions p t d,andfirepropagationmodelM
as received by GPS devices while the first map is created 1 Movetorendezvousarea: p t d←Move(pr,p t d −1 )
by the AEKF’s online inference of firefront locations and 2 whileMissionDurationdo
error propagation (Section V). Through the combination 3 4 G G e e n n e e r r a a t t e e fi hu re m fr a o n nt un u c n e c r e t r a t i a n i t n y ty m m ap a : p: U U t h t ← f,q G t← PS( S q e h n ) se(Qt)
of these two error-maps, we obtain our first node-level
5
Combineuncertaintymaps:U
t
tot=U
t
f+U
t
h
controller (uncertainty-based controller, Section IV-A). We 6 Minimizethedual-criteriaobjectivefunction:
a e l n s c o ou in ra c g o e rp t o h r e at U e A a V n e te n a s m em t b o le m -l a e i v n e t l ai ( n fo a rm fo a r t m io a n t ) io c n on co tr n o s l e le n r su to s minH =argmax (cid:18)(cid:90) U t tot(cid:0)q t i(cid:1)dq− (cid:90) E dj (cid:16)(cid:13) (cid:13) (cid:13) p t d−p t j/d (cid:13) (cid:13) (cid:13) (cid:17) dp (cid:19)
qt i,pt d i∈Q d∈N
for maximizing the coverage (Section VI-B). The two con-
trollerscoordinatetogenerateavirtualpositionforeachUAV 7 Calculatetheoverallcontrolinputsanddeterminenewvirtualpositions
forUAVs:
(cid:16) (cid:17)
whichisthenfedtoapathplanningcontrollertogeneratethe pn =pv− uucc−ufcc δt
t+δt t d d
force required to move the UAV to the determined position
based on UAVs flight dynamics (Section VI). 8 Movetothenewdesiredposition:p t d +δt ←Move(p t n +δt ,p t d)
9 end
IV. METHOD 1 1 1 0 def Mo u v d e ,t ( = pd g ∑ , i p u t d a d ) t , t t i : (pd g , // p t d p ) d g + is u t r d h e ,t p e i( g p o d g a , l p p t d o ), siti ∀ o i n ∈ fo F r t droned
Algorithm 1 depicts an overview of the proposed human- 12 p t d +δt =p t d+ud,tδt
centered coordinated control procedure for monitoring wild- 13 def Sense(Qt ): //O t istheUAVobservationmodel
fires. Upon receiving a request, UAVs travel to the human- 14 qˆt=argmax qt ρ (cid:0) q t|t−1 ,pt−1,M t−1,O t−1 (cid:1)
defined areas of interest (i.e., rendezvous point, line 1 in
Algorithm 1). On arrival, UAVs sense the firefront by ex-
trapolating fire-spots q and generate a general uncertainty summing up the respective estimated uncertainty values of
t
map Utot by fusing AEKF error propagation and areas of eachpointtoobtainthegeneraluncertaintymapUtot attime
t t
human activity using GPS data (line 3-5 in Algorithm 1). t.Theuncertainty-basedcontroller’sobjectiveistominimize
Afterwards,acombinationofanuncertainty-basedoptimiza- the overall uncertainty residual in Utot. We present the
t
tion and a graph-based weighted consensus protocol forms details of calculating U f and U h in the following sections.
our new dual-criteria objective function H for a set of N Fig.2demonstratestheformationoftheuncertaintymapand
UAVs (line 6 in Algorithm 1). This objective function is the foundation of our human-centered controller.
then embedded as our coordinated control system to move 1) Firefront Uncertainty Map: We leverage AEKF to es-
UAVs to highly uncertain areas on the generated error map timateaprobabilitydistributionofthefire-spotlocationsand
to minimize the associated error while encouraging drones compute a measurement covariance for each point through
to maintain a distributed formation to increase the team linear error propagation techniques. Considering q t−1 as the
efficiencyinfieldcoverage(lines7-8inAlgorithm1).Mean- location of firefronts at current time and pd as the UAV
t−1
while,AEKFisalsousedtoinferthefirefrontcharacteristics, coordinates, a firefront location qˆ t one step forward in time
such as spatial distribution qˆ t , propagation velocity q˙ t , and is desired, given the current firefront distribution (q t−1 ), fire
direction , in order to calculate an individualized temporal propagationmodelwithcurrentparameters(M t−1 ),andUAV
safety index (SI) (Eq. 40) for firefighters. observation model of the field (O t−1 ) as in Eq. 8
minH =ar q g t i, m pt d ax (cid:18)(cid:90) i∈Q U t tot(cid:0) q t i(cid:1) dq− (cid:90) d∈N E dj (cid:16)(cid:13) (cid:13) (cid:13) p t d−p t j/d (cid:13) (cid:13) (cid:13) (cid:17) dp (cid:19) (7) qˆt=arg q m t axρ(q t−1 ,p t−1 ,M t−1 ,O t−1 ,qt) (8)
In AEKF, the uncertainty of the firefront locations over
where pd represents UAV positions and Q is the entire fire-
t time is measured as the state covariance P at time t. It
t|t
map. To generate the required control inputs for UAVs to
has been shown previously (see [20]) that minimizing the
move, we calculate the negative derivative of the objective
state covariance corresponds to maximizing the covariance
function with respect to the location of drones at time t.
residual S in Eq. 9
t
The following sections are dedicated to discussing and St=HtP
t|t−1
H
t
T+Γt (9)
formulating the two modules of the dual-criteria objective
function in Eq. 7, as well as elaborating on the uncertainty whereP t|t−1 isthepredictedcovariance,F t andH t areprocess
map generation process. and observation model Jacobians, and Q t and Γ t are the
corresponding noise covariances and can be calculated as
A. Criteria 1: Uncertainty-based Controller P =FP FT +Q. According to Eq. 9, by setting
t|t−1 t t−1|t−1 t t
We design our coverage and tracking controller to minimize p to identity, we see that a maximally informative
t|t−1
the uncertainty of the firefront locations over time, while position for drones is the one that minimizes the HHT, or
t t
focusing on the areas of human operation. To this end, in other words, the closest possible position where dynamic
we generate two uncertainty maps for (1) the propagating observations change rapidly [20]. As such, we generate an
fire locations U and (2) the areas of human activity U . uncertainty map which is reflective of the wildfire dynamics
f h
Eventually, we fuse these error maps together by linearly where a measurement residual can be calculated for each
B. Criteria 2: Weighted Multi-agent Consensus Protocol
To ensure that the combination of the above objective
functions results in local actions leading up to appropriate
globalperformance,weenforceanextracontrolterminsuch
a way that the UAVs also act on other easily measurable
information, such as the relative displacements to neighbor-
ing drones. This is specifically important to disperse UAVs,
while preserving the connectedness of the network, from
converging to an extreme minima (i.e., a highly uncertain
point). Accordingly, we leverage the weighted consensus
protocol [21] as in Eq. 13 for a set of N UAVs with the
objectiveofminimizingthetotaldisplacementerrorE while
ij
Fig.2:FusingAEKFmeasurementresidualandhumanGPS
preserving a distance of at least δ between all UAVs
datatogenerateanuncertaintymap.UAVsfocusonareasof
(cid:16)(cid:13) (cid:13)(cid:17)
humanactivitywhilecloselymonitoringthefirepropagation. minE =argminE ij (cid:13) (cid:13) p t i−p t j(cid:13) (cid:13) (13)
pt
p m o a i t n r t ix q S t t b a y nd su s m et m o i u n r g ob u j p ec t t h iv e e e t s o tim m a a t x e i d mi c z o e v S ar t . ia A nc c e co r r e d s i i n d g u l a y l , =argmin∑ N ∑ 1   (cid:13) (cid:13) (cid:13) p t i− (cid:13) p t j (cid:13) (cid:13) (cid:13) −δ (cid:13)   2 (14)
wederiveournewobjectivefunctionH asinEq.10,where pt i=1j∈Vi 2(∆−δ) ∆−(cid:13) (cid:13) p t i−p t j(cid:13) (cid:13)
Tr(.) represents the trace operation, and fovd is the field of
t
where j∈V represents j−thUAVwithinthecommunication
view (FOV) of drone d at time t. i
range ∆ of UAV i. In this way, a negative force will be
(cid:16) (cid:16) (cid:17)(cid:17)
minU 1 =argmax(Tr(St))=argmax Tr HtP t|t−1 H t T+Γt generatedtomoveUAVsapartfromorclosertoeachotherif
q t i∈fov t d q t i∈fov t d theyaregettingcloserthanδ orfartherthan∆(i.e.,theUAV
(cid:16) (cid:16) (cid:16) (cid:17) (cid:17)(cid:17)
=argmax Tr Ht FtP t−1|t−1 F t T+Qt H t T+Γt (10) network will become disconnected). Note that δ should be
q t i∈fov t d sethighenoughsothattheUAVteamcanspreadeffectively.
Details of online inference of the parameters in the above
equation are presented in Section V.
V. ONLINEINFERENCEOFWILDFIREDYNAMICS
2) Human Uncertainty Map: While hovering around the The joint probability density function in Eq. 8 is calculated
highly uncertain areas to provide firefighters with online through AEKF estimator. Using the aforementioned nota-
information regarding the firefront, UAVs are required to tions, the AEKF state transition and observation equations
focus on their human collaborators on the ground and take can now be stated as in Eq. 15 and 16
their safety into account by putting additional concentration
ontheareasofhumanoperation.Accordingly,UAVsreceive qt=f t−1 (q t−1 ,p t−1 ,R t−1 ,U t−1 ,θt−1 )+ωt (15)
human positions ph (i.e., through GPS devices) at time t qˆt=ht(qt,p t−1 )+νt (16)
t
as planar coordinates µx and µ y and generate a bimodal where p is the physical location of UAV. We reform the
t,h t,h t−1
Gaussian distribution for each human h to account for both state transition Eq. in 15 to account for all state variables in
error in GPS information as well as the mobility of the Θ = (cid:2) qx,qy,px,py,pz,R,U,θ (cid:3)T as in Eq. 17
t t t t t t t t t
humans. By assuming independence, a joint PDF can be (cid:34) (cid:35) (cid:34) (cid:12) (cid:35) (cid:34) (cid:35)
∂f (cid:12)
calculated as our human safety objective as in Eq. 11 Θt = (cid:12) Θt−1 +ωt, ∀i∈Θ (17)
U
2
=argmax∏P
ih
(cid:110)
q
t
i−p
t
h≥rs
(cid:111)
≥Ps (11) 8×1
∂Θi(cid:12) Θˆ
t−1|t−1 8×8 8×1
qt∈vh i∈vh where the process noise ω
t
. Therefore, we form the state
where v j represents the points in a safe circular vicinity transitionJacobianmatricesF t asinEq.18,includingpartial
of human h with radius r and P is a predefined safety derivatives of wildfire propagation dynamics in Eq. 1 and 2
s s
threshold for probability. P ih is a cumulative distribution with respect to all variables in state vector Θ t .
function (CDF) with respect to each human location p t h and q t x (cid:48) q t y (cid:48) p t ( (cid:48) 3) R t(cid:48) U t(cid:48) θt(cid:48)
a th ll e ap es p t r i o m a a c t h e i d ng fi fi re re -s f p ro o n t ts lo q c t i a . t T io o n c s al q c t ul a a l t o e n t g h s e id P e ih , i w nf e er l r e e v d era fi g re e q q t x y  0 1 1 0 0 0 ( ( 3 3 ) ) ∂ ∂ ∂ R q q t t t x y (cid:48) ∂ ∂ ∂ U q q t t t x y (cid:48) ∂ ∂ ∂ θ q q t t t x y (cid:48)  
q f p o i a . r ra W e m a e c e h t t h e h e rs n um ( i i n . a e t n e ., g a R r ˆ t a t , t l e o Uˆ c t t h a , t e a io n re n d su θ p ˆ l t t h ti ) a n b n g y d C A a D l E l F K a t p F o p t r b o o e a c g c a h r l e c in a u t g l e a r fi te t r h e a a fr n C o D t n h t F e s ∂ ∂ Θ f i (cid:12) (cid:12) (cid:12) (cid:12) Φˆ t(cid:48) = p R t ( t 3 t )       0 0 0 0 0 0 ( ( 3 3 ) ) ∂ 0 1 R t(cid:48) ∂U 0 0 t(cid:48) ∂ 0 0 θ t(cid:48)      (18)
sa
t
fe-distance. A Probability P is then calculated for each
Ut 0 0 0(3) 0 1 0 
individual as in Eq. 12
ih θt 0 0 0(3) 0 0 1
(cid:90) ∞ (cid:16) (cid:17) (cid:16) (cid:17)
Pih=
τ=ls
N µ
qt
i−p
t
h,σ
t
2
,i
dτ=1−CDF rs|µ
qt
i−p
t
h,σ
t
2
,i
(12)
where t(cid:48) =t−1 and superscript (3) represent number of
where µ and σ2 are calculated by AEKF (see Section V). column and row repetitions for all (cid:2) px,py,pz(cid:3) . We note that
qi t,i t t t
t
Eq. 11 is leveraged later in Section VII-A to compute an the parameters R, U, and U are not necessarily dynamic
t t t
individualized safety index for each firefighter. with time, and it is fairly reasonable to consider these
calculated as in Eq. 23
∂ ∂ Θ h i (cid:12) (cid:12) (cid:12) (cid:12) Θˆ t|t(cid:48) = ϕ ϕ U Rˆ ˆ t t t x x t        ∂ ∂ q 0 0 0 ϕ q t x t t x x ∂ ∂ q 0 0 0 ϕ q t y t t y y ∂ ∂ p 0 0 0 ϕ p t x t t x x ∂ ∂ p 0 0 0 ϕ p t y t t y y ∂ ∂ ∂ ∂ p 0 0 ϕ ϕ p p t z t t t y t z x y R 1 0 0 0 t U 0 1 0 0 t θ 0 0 0 0 t       
θˆ t 0 0 0 0 0 0 0 1
(23)
where the partial derivatives are derived as in Eq. 24-26,
using the aforementioned angle parameter equations
∂ϕx 1 (cid:18) 1 (cid:19)
t = (24)
Fig. 3: The UAV observation model. ∂q t x 1+ (cid:16) q t x−p t x(cid:17)2 p t z
pz
t
∂ϕx 1 (cid:18)−1 (cid:19)
t = (25)
physical parameters as constants for short periods of time. ∂p t x 1+ (cid:16) q t x−p t x(cid:17)2 p t z
However, in the case of analyzing the system for longer p t z
durations, temporal dynamics may apply [22], specifically ∂ϕ t x = 1 (qx−pz) (cid:18) −1 (cid:19) (26)
due to changes in wind speed and velocity. Exact estimation ∂p t z 1+ (cid:16) q t x−p t x(cid:17)2 t t (p t z)2
pz
of temporal dynamics related to these parameters are out t
of the scope of the current study, since we assume locality similar equations as above hold for Y-axis with qy and py .
t t
in time and space according to FARSITE [17]. The partial The process noise ω t in Eq. 17 accounts for both stochas-
derivatives of qx and qy with respect to parameters R , ticity in fire behavior and wildfire propagation model in-
t t t−1
U t−1 , and θ t−1 are computed by applying the chain-rule and accuracy. Moreover, the observation noise ν t is responsible
using Eq. 3-4 as shown in Eq. 19-21, where L(θ) equals to account for the estimation errors associated with both q t
sinθ and cosθ for X and Y axis, respectively. and pd which affect UAVs ability to extrapolate where a
t
fire is on the ground. Taking this into consideration is very
important.Bothω andν aremodeledasazero-meanwhite
t t
∂qt ∂L(θ) Gaussian noise with covariances Q t and Γ t , respectively.
∂θt−1
= C(Rt,Ut)
∂θ
δt (19)
Note that errors in X, Y, and Z axes coordinates of a
(cid:32) (cid:33) drone are loosely correlated, and thus, we also incorporate
∂ ∂ R q t− t 1 = 1− LB(Ut) L + B( (cid:112) Ut G ) B(Ut) L(θ)δt (20) n
in
o
i
n
ti
-
a
d
l
i
i
a
z
g
in
o
g
na
t
l
he
e
m
le
.
m
Q
ents
an
i
d
n
Γ
noi
t
s
h
e
en
co
r
v
e
a
c
r
e
i
i
a
v
n
e
ce
ad
m
ap
a
t
t
i
r
v
i
e
ces
up
w
da
h
t
e
e
n
s
(cid:18) (cid:19) t t
∂qt
=
R t(cid:48) LB(U t(cid:48))∂G ∂ B U (U t(cid:48) t(cid:48))−GB(U t(cid:48))∂L ∂ B U (U t(cid:48) t(cid:48))
L(θ)δt (21)
according to AEKF framework, as in Eq. 5 and 6.
∂U t−1 (cid:16) LB(U t(cid:48))+ (cid:112) GB(U t(cid:48)) (cid:17)2 VI. CONTROLLERDESIGN
Fig. 4 represents our node-level controller architecture for
i/d
each UAV d with neighboring UAVs p . Our controller
t
consists of three components: (1) an uncertainty-based con-
Next, we derive the observation model through which
trol component (UCC), (2) a formation control component
UAVs perceive dynamic fire-spots, according to Fig. 3. The
(FCC), and (3) a path planning component (PPC). The
observation mapping Eq. in 16 is reformed into Eq. 22
first controller performs exploitation to minimize the overall
uncertainty in the map as produced (i.e., firefront locations
(cid:34) Φˆ t (cid:35) 5×1 = (cid:34) ∂ ∂ Θ h i (cid:12) (cid:12) (cid:12) (cid:12) Φt|t (cid:35) 5×8 (cid:34) Φt (cid:35) 8×1 +νt, ∀i∈Θ (22) o i s s w r a d h r e m u s m ig i a n n n e o d r a d r t e o e r a t s m o a o m n f a a g x a e i c m ti t v i h z i e e ty e g ) x e p n w l e o h r r i a l a l e ti f o o t n h r e m as a s t w e io c e n o ll n o d a f s c c t o h o n e v t e r U r o a l A g le V e r .
The third controller component moves UAVs to any desired
next position (i.e., to rendezvous point, to human location
where Φ t = (cid:2) ϕ t x,ϕ t y,Rˆ t ,Uˆ t ,θˆ t (cid:3)T is a mapping vector through for close monitoring, or to next monitoring positions as
which the estimated parameters are translated into a unified, determined by dual-criteria controller). Assuming u = p˙
d d
observed angle-parameter vector Φˆ t . The angle parameters to be the quadcopter UAV dynamics, we develop each of
(i.e.,ϕ t x andϕ t y )containinformationregardingbothfirefront our control components in the following sections.
location
[qx,qy]
and UAV coordinates
[px,py].
According
t t t t
to Fig. 3, by projecting the looking vector of UAV to A. Uncertainty Controller Component (UCC)
planar coordinates, the angle parameters are calculated as Thefirstcontrollerworksbasedonthetheoryofartificialpo-
ϕx=tan−1 (cid:16) q t x−p t x(cid:17) and ϕ y=tan−1 (cid:16) q t y−p t y(cid:17) for X and Y axes, tential field [23] where each UAV is distributedly controlled
t pz t pz
t t
respectively. Then, the observation Jacobian matrix H is byanegativegradientofthegeneratedtotaluncertaintymap
t
B. Formation Controller Component (FCC)
Similar to the UCC, our formation controller component
(FCC) attempts to minimize the consensus displacement
error by using a gradient descent flow of the weighted
consensus protocol in Eq. 13, with respect to UAV pose,
as represented in Eq. 33.
(cid:32) (cid:33)
(cid:16) (cid:17)
u
d
fcc=−κ2
∂
∂
p
E
d
=−
(j,
∑
d)∈E
1−
(cid:16)
(cid:13) (cid:13) (cid:13)
∆
p
−
t d− δ
(cid:13) (cid:13)
p t d
p
/
d
j (cid:13) (cid:13) (cid:13)
−p d
p
/
t d
j (cid:13) (cid:13)
−
(cid:17)3
p t d/j (33)
Fig. 4: Node-level controller architecture of each drone d. (cid:13) t t (cid:13)
SimilarlogisticsasinEq.32canbederivedhereforthethree
Utot fromobjectivefunctionsinEq.10and13,withrespect
t axes of coordinate. Accordingly, the combination of control
to its position pd = (cid:2) px,py,pz(cid:3)T as follows in Eq. 27
t t t t inputs generated by UCC and FCC modules are leveraged
uu
d
cc=−κ1 ∂
∂
U
p
t t
d
ot (27) a
in
cc
E
o
q
rd
.
i
7
n
,
g
in
to
o
o
r
u
d
r
er
du
to
al
p
-c
r
r
o
i
d
te
u
r
c
ia
e
o
a
b
n
je
e
c
w
tiv
d
e
es
f
i
u
re
n
d
cti
l
o
o
n
c
,
at
i
i
n
o
t
n
ro
p
d
v
uc
f
e
o
d
r
t
where κ is the proportional gain parameter for the first eachUAVtomoveto.Assuch,aUAV’snewvirtualposition
1
controller. To derive the gradients with respect to the UAV will be updated and fed to path planning controller (PPC) as
coordinates, we first need to analytically derive the uncer- shown in Eq. 34.
(cid:16) (cid:17)
tainty objective function (Eq. 10). To do so, we insert the pv =pv− uucc−ufcc δt (34)
t+δt t d d
values of process and observation Jacobian matrices (i.e., F
t
and H) and the process and observation noise covariances C. Path Planning Controller (PPC)
t
(i.e.,Q t andΓ t )andcalculatethetraceofthefinalmatrix(see ThepurposeofthiscontrollermoduleistohelpaUAVmove
Section V). Eventually, after the simplifications, the CTC fromitscurrentpositiontoanewposition.ThePPCmodule
objective function equation can be derived as in 28 generates either an attractive force toward a desired pose
(cid:32) (cid:18) ∂ϕx(cid:19)2 (cid:18)
∂ϕ
y(cid:19)2 (cid:18) ∂ϕx(cid:19)2 or a repulsive force avoiding an undesirable one. Desired
minU =a
q
r
i
g
∈
m
fo
a
vd
x β1
∂q
t
t
x
+β2
∂q
t
t
y
+β3
∂p
t
t
x
p
an
o
d
ses
tra
in
ck
cl
i
u
n
d
g
e
w
th
il
e
dfi
in
re
iti
b
al
eg
r
i
e
n
n
s
de
a
z
n
v
d
ou
th
s
e
po
n
i
e
n
w
t w
vi
h
r
e
tu
re
al
c
p
o
o
v
s
e
i
r
t
a
io
g
n
e
t t
+β4 (cid:18) ∂
∂
ϕ
p
t
t y
y(cid:19)2 +β
5
(cid:32)(cid:18) ∂
∂
ϕ
p
t
t z
x(cid:19)2 + (cid:18) ∂
∂
ϕ
p
t
t z
y(cid:19)2(cid:33)(cid:33) (28)
a
p
s
t v +
i
δ
n
t g
E
e
q
n
.
e
3
ra
4
t
.
ed
Un
th
d
r
e
o
s
u
ir
g
a
h
bl
o
e
ur
po
d
s
u
e
a
s
l-
i
c
n
r
c
it
l
e
u
r
d
ia
e
o
o
b
n
j
e
e
s
ct
t
iv
h
e
at
fu
ar
n
e
cti
t
o
o
n
o
close to another UAV or too high/low of an altitude such
where the gradient terms can be calculated using introduced that the drone might capture low-quality pictures/catch fire.
angle-parameters. β i are covariance constants and are equal Leveraging an artificial potential field, we address these
(cid:16) (cid:17) (cid:16) (cid:17)
to β1 = P 11 +σ q 2 x , β2 = P 22 +σ q 2 y , β3 =σ p 2 x , β4 =σ p 2 y and problems by generating attractive and repulsive forces using
β =σ2. Accordingly, the final gradients in Eq. 27 with aquadraticfunctionofdistancesfromdesiredortoundesired
5 pz
respect to UAV pose can be calculated as in Eq. 29- 31 points. The attractive control force applied to each UAV pd
t
to any goal points pg at timet can be calculated as noted in
(cid:16) ∂ϕx(cid:17)2 (cid:16) ∂ϕx(cid:17)2 (cid:16) ∂ϕx(cid:17)2 t
∂ ∂U px
d
=β1 ∂ ∂ ∂ p q x
d
t t x +β3 ∂ ∂ ∂ p p x
d
t x d +β 5 ∂ ∂ ∂ p p x
d
t z d (29) E D q.
d
at 3 t 5 =
2
1 κg (cid:13) (cid:13)
(cid:13)
pd
g
−p
t
d (cid:13) (cid:13)
(cid:13)
2 and ua
d
tt=−∇D
d
att=κg (cid:16) pd
g
−p
t
d (cid:17) (35)
∂ ∂U py =β2 ∂
(cid:16)
∂ ∂ ∂ p ϕ q y t t y
y(cid:17)2
+β4 ∂
(cid:16)
∂ ∂ ∂ p ϕ p x t y d
y(cid:17)2
+β 5 ∂
(cid:16)
∂ ∂ ∂ p ϕ p y t z d
y(cid:17)2
(30) w th h e e r r e e p κ u g lsi i v s e th c e on p t r r o o p l o f r o ti r o c n e a g l e g n a e i r n a . te U d si t n o g a t v h o e id sa a m ny e n p o o t i a n t t io p n t g ,
d d d d
can be defined as in Eq. 36
∂ ∂U pz d
+
=
β
β
4
1 ∂ ∂ (cid:16) (cid:16)
∂
∂ ∂
∂
∂ ∂
p
ϕ p
p
ϕ q
z d
t
y d
y z d t t x x (cid:17) (cid:17) 2 2
+
+
β
β
5
2 
 
∂ (cid:16) ∂ ∂ ∂ ∂ (cid:16) p ϕ
∂
q ∂
∂
z d t t y y
p
ϕ
p
(cid:17)
z d
t
z d
x 2 (cid:17) + 2
+
β3 ∂ ∂ (cid:16) (cid:16)
∂
∂ ∂
∂
∂ ∂
p
ϕ p
p
ϕ p
z d
t
z d
y z d t x d x (cid:17) (cid:17) 2 2 
  (31)
D
u
d
r
r
e
e
p
p
=
=   
− 0 ζ
2 1
∇
κg
D
(cid:32)
re
(cid:13) (cid:13)
p
pd g − 1 p t d(cid:13) (cid:13) − 1 γ (cid:33)2
o
if
ther
(cid:13) (cid:13) (cid:13)
w
p
is
d g
e
−
.
p t d (cid:13) (cid:13) (cid:13) <γ (
(
3
3
6
7
)
)
d d
(cid:32) (cid:33)
1 1 1 (cid:16) (cid:17)
a a n t d tim ev e en t tu is al n ly o , te th d e a c s on in tro 3 l 2 inputtoUAVdfromUCCmodule =−ζκg (cid:13) (cid:13)pd g −p t d(cid:13) (cid:13) − γ (cid:13) (cid:13)pd g −p t d(cid:13) (cid:13) 3 pd g −p t d (38)
(cid:34) (cid:35)
uu
d
c
,t
c= κx ∂
∂
U
p
t t
x d
ot ,κy ∂
∂
U
p
t t
y d
ot ,κz ∂
∂
U
p
t t
z d
ot (32) w
un
h
d
e
e
r
s
e
ir
γ
abl
i
e
s
p
th
o
e
sit
d
io
is
n
tan
p
c
t g
e
a
b
n
e
d
tw
ζ
ee
=
n
1
cu
o
r
n
re
ly
nt
if
po
(cid:13) (cid:13)
s
p
it
t g
io
−
n
p
a
t d
n
(cid:13) (cid:13)
d
<
th
γ
e
.
Eventually, the general control law in order to generate the
We note that there is no need to explicitly calculate the
required force to move UAVs to their new locations can be
gradients of human uncertainty map with respect to UAV
formed as in Eq. 39
positions separately, since we linearly sum up the values
(non-negative) of the two maps (see Fig. 2).
u
d,t
=∑ua
d
t
,
t
t
i+ur
d
e
,t
pi, ∀i∈Ft (39)
i
Fig. 5: Simulation results of eight sample time-steps between t =20 (top-left) and t =300 (bottom-right) for distributed
coverage, representing drone FOVs projected on the ground. Dot rays show the FOV centroids.
where F is the set of all generated attractive and repulsive
t
forces at time t. Thus, the final position of UAV d gets
updated through pd =pd+u δt.
t+δt t d
VII. RESULTSANDSIMULATION
Weevaluatetheefficiencyofourcontrollerinsimulationand
against two benchmarks: (1) a state-of-the-art, model-based,
distributedcontrolalgorithm[7]and(2)adeepreinforcement
learning(RL)baseline.Thefirstbenchmark[7]isafireheat-
intensity-based distributed control framework for wildfire
coverage which incorporates FARSITE (as in Section II-A)
and a model for fire heat-intensity measure in order to max- Fig. 6: This figure depicts a quantitative comparison of our
imize the area-pixel density of the UAVs fire observations. coordinatedcontrollerwithpriorwork(left-side)andhuman
Furthermore,wetrainanRLpolicynetworktocontrolUAVs safety index (SI) variations as a temporal quantity, with
to reduce the uncertainty residual as measured by AEKF. respect to distance between an approaching firefront and a
The network consists of four convolutional layers followed human firefighter (right-side).
by three fully connected layers with ReLU activations. The
image of the fire area is an input while a direction for UAVs failed to learn during 800 episodes of training, our approach
is an output of the network. We define the reward at each shows significant improvements by reducing the cumulative
step as the negative sum of uncertainty residual across the uncertainty residual by more than 102x and 105x times.
entire map, encouraging the agent to minimize uncertainty We also evaluate the feasibility of our controller on
over time. physicalrobots.Thephysicalexperimentswithactualrobots
In our simulations, we initialize the fire-map with 20 were performed in the Robotarium, a remotely accessible
randomlyplacedignitionpointsin[50100]rangeandwithin swarm robotics research platform [24]. We tested the cov-
a500-by-500terrainwherethefiremodelparametersR,U, erage performance of our controller using five robots and
t t
and θ were chosen similar to [7], for comparison. A total similar fire environment as above. Fig. 7 represents example
t
of five drones were initialized around [50 300] coordinates demonstrationsofourexperiment.Resultsoftheexperiment
with initial altitude set to zero. UAV camera half-angles is demonstrated in the supplementary video, which can also
were set to [π,π]. The inter-distance δ and communication be found at https://youtu.be/j3YdIO5u fE.
4 6
range ∆ in our weighted consensus protocol were set to 50
and500,respectively.Themaximumandminimumaltitudes A. Safety Index to Secure Human Firefighters
were chosen to be 15 and 45, respectively. Fig. 5 depicts
As a corollary of our algorithm, we calculate an individu-
the simulation results of eight sample time-steps between
alized safety index (SI) as a temporal quantity for human
t=20(top-left)andt=300(bottom-right)asdetailedabove,
firefighters on the ground by leveraging the estimated wild-
representing drone FOVs projected on the ground.
fire dynamics and parameters and report this quantity to
The left-side figure in Fig. 6 shows a comparison for a
firefighters for situational awareness. Now, an individualized
team of UAVs controlled by our method, the distributed
safetyindex(SI)asameasureoftimeisdefinedasinEq.40
control proposed by [7], and the RL baseline. We ran
for human firefighters by taking into account the velocity of
the simulations for 100 time-steps for all three methods
the approaching firefront.
for a total of 10 trials where for each trial, a cumulative
(cid:32) (cid:33)−1
u co n v c e e r r e ta d in b ty y a w n a y s d c r a o lc n u e l s at a e t d e b ac y h th s e tep A . E W K h F il f e or th fi e re RL po b in as ts el n in o e t SI t h= i ∏ ∈vh P ih q˙ t i (cid:13) (cid:13)p p t t h h − − q q t t i i (cid:13) (cid:13) (40)
[3] J.-I. Kudoh and K. Hosoi, “Two dimensional forest fire detection
method by using noaa avhrr images,” in Geoscience and Remote
Sensing Symposium, 2003. IGARSS’03. Proceedings. 2003 IEEE In-
ternational,vol.4. IEEE,2003,pp.2494–2495.
[4] A. Ollero and L. Merino, “Unmanned aerial vehicles as tools for
forest-firefighting,”ForestEcologyandManagement,vol.234,no.1,
p.S263,2006.
[5] L. Merino, F. Caballero, J. R. M. de Dios, I. Maza, and A. Ollero,
“Automatic forest fire monitoring and measurement using unmanned
aerial vehicles,” in Proceedings of the 6th International Congress
on Forest Fire Research. Edited by DX Viegas. Coimbra, Portugal.
Citeseer,2010.
[6] K.A.GhamryandY.Zhang,“Cooperativecontrolofmultipleuavsfor
Fig. 7: Feasibility of the proposed distributed control algo- forest fire monitoring and detection,” in Mechatronic and Embedded
rithm for wildfire coverage evaluated on physical robots in Systems and Applications (MESA), 2016 12th IEEE/ASME Interna-
tionalConferenceon. IEEE,2016,pp.1–6.
Robotarium platform [24]. The experiment footage can be
[7] H.X.Pham,H.M.La,D.Feil-Seifer,andM.Deans,“Adistributed
found at https://youtu.be/j3YdIO5u fE. controlframeworkforateamofunmannedaerialvehiclesfordynamic
wildfire tracking,” in Intelligent Robots and Systems (IROS), 2017
In this equation, P is the CDF (from Eq. 12), v is the IEEE/RSJInternationalConferenceon. IEEE,2017,pp.6648–6653.
ih h
vicinity of human h, and q˙i is the estimated fire spread [8] T. Zhou, L. Ding, J. Ji, L. Li, and W. Huang, “Ensemble transform
t kalman filter (etkf) for large-scale wildland fire spread simulation
velocity of fire-spot i toward this vicinity. The ratio is to
using farsite tool and state estimation method,” Fire Safety Journal,
account for the direction of the firefront and equals to 1 vol.105,pp.95–106,2019.
if the firefront is directly approaching the coordinates where [9] Z. Lin, H. H. Liu, and M. Wotton, “Kalman filter-based large-scale
wildfire monitoring with a system of uavs,” IEEE Transactions on
thehumanislocated.Accordingly,weassumethreedifferent
IndustrialElectronics,vol.66,no.1,pp.606–615,2018.
ranges for SI to be announced at each time, namely (1) safe [10] M. Kumar, K. Cohen, and B. Homchaudhuri, “Cooperative control
if SIh ≥T, (2) warning if T ≤SIh <T, and (3) danger of multiple uninhabited aerial vehicles for monitoring and fighting
t s w t s wildfires,” Journal of Aerospace Computing, Information, and Com-
if SIh<T . Parameters T and T are predefined temporal-
t w s w munication,vol.8,no.1,pp.1–16,2011.
bounds for safety and warning situations, respectively. We [11] R. N. Haksar and M. Schwager, “Distributed deep reinforcement
leave the safety and warning thresholds T and T to be pre- learning for fighting forest fires with a network of aerial robots,” in
s w 2018 IEEE/RSJ International Conference on Intelligent Robots and
defined by humans, as these variables are subjective to the
Systems(IROS). IEEE,2018,pp.1067–1074.
firefighting scenario (e.g., a burning hospital versus forest [12] K.D.JulianandM.J.Kochenderfer,“Distributedwildfiresurveillance
fire) and are dependent on situational severity. The right- withautonomousaircraftusingdeepreinforcementlearning,”Journal
ofGuidance,Control,andDynamics,pp.1–11,2019.
sidefigureinFig.6depictsthevariations(i.e.mean±std)of
[13] F. Karimzadeh, N. Cao, B. Crafton, J. Romberg, and A. Raychowd-
SI with respect to distance between an approaching firefront hury, “Hardware-awarepruning ofdnns usinglfsr-generated pseudo-
with 10 points and a human firefighter over 100 trials of randomindices,”arXivpreprintarXiv:1911.04468,2019.
[14] D. Morvan, “Physical phenomena and length scales governing the
simulation. For this case, a single UAV was placed over the
behaviourofwildfires:acaseforphysicalmodelling,”Firetechnology,
fire area, inferring the fire-spot locations and parameters. vol.47,no.2,pp.437–460,2011.
[15] C. Yuan, Y. Zhang, and Z. Liu, “A survey on technologies for auto-
VIII. CONCLUSION matic forest fire monitoring, detection, and fighting using unmanned
aerial vehicles and remote sensing techniques,” Canadian journal of
We combined a node-level and an ensemble-level control
forestresearch,vol.45,no.7,pp.783–792,2015.
criteria to introduce a novel coordinated control algorithm [16] E. Seraj, A. Silva, and M. Gombolay, “Safe coordination of human-
for human-centered active sensing of wildfires, providing robotfirefightingteams,”arXivpreprintarXiv:1903.06847,2019.
[17] M. A. Finney, “Farsite: Fire area simulator-model development and
high-quality, online information to human firefighters on the
evaluation,” Res. Pap. RMRS-RP-4, Revised 2004. Ogden, UT: US
ground. In our approach, we take advantage of AEKF’s DepartmentofAgriculture,ForestService,RockyMountainResearch
errorpropagationcapabilitytogenerateageneraluncertainty Station.47p.,vol.4,1998.
[18] P.TothandD.Vigo,Thevehicleroutingproblem. SIAM,2002.
map, incorporating uncertainties about firefront dynamics
[19] S. Akhlaghi, N. Zhou,and Z. Huang, “Adaptive adjustment of noise
and areas of human activity. Our approach outperformed covarianceinkalmanfilterfordynamicstateestimation,”in2017IEEE
prior work for distributed control of UAVs for wildfire Power&EnergySocietyGeneralMeeting. IEEE,2017,pp.1–5.
[20] R.Sim,“Stableexplorationforbearings-onlyslam,”inProceedingsof
tracking as well as a reinforcement learning baseline.
the2005IEEEInternationalConferenceonRoboticsandAutomation.
IEEE,2005,pp.2411–2416.
ACKNOWLEDGMENT
[21] J. Corte´s and M. Egerstedt, “Coordinated control of multi-robot
We thank A. Silva for his role in implementing the RL systems: A survey,” SICE Journal of Control, Measurement, and
SystemIntegration,vol.10,no.6,pp.495–503,2017.
baseline. This work was funded by the Office of Naval
[22] P.Delamatar,A.Finley,andC.Babcock,“Downloadingandprocess-
Research under grant N00014-19-1-2076. ing noaa hourly weather station data,” dim (st), vol. 1, no. 30538,
p.12,2013.
REFERENCES [23] S.S.GeandY.J.Cui,“Newpotentialfunctionsformobilerobotpath
planning,” IEEE Transactions on robotics and automation, vol. 16,
[1] P.Sujit,D.Kingston,andR.Beard,“Cooperativeforestfiremonitoring no.5,pp.615–620,2000.
using multiple uavs,” in Decision and Control, 2007 46th IEEE [24] D.Pickem,P.Glotfelter,L.Wang,M.Mote,A.Ames,E.Feron,and
Conferenceon. IEEE,2007,pp.4875–4880. M.Egerstedt,“Therobotarium:Aremotelyaccessibleswarmrobotics
[2] D. W. Casbeer, D. B. Kingston, R. W. Beard, and T. W. McLain, research testbed,” in Robotics and Automation (ICRA), 2017 IEEE
“Cooperativeforestfiresurveillanceusingateamofsmallunmanned InternationalConferenceon. IEEE,2017,pp.1699–1706.
airvehicles,”InternationalJournalofSystemsScience,vol.37,no.6,
pp.351–360,2006.