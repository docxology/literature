Robot self/other distinction: active inference meets neural
networks learning in a mirror
PabloLanillos1 and JordiPages2 and GordonCheng3
Abstract. Self/otherdistinctionandself-recognitionareimportant ingthedoorforartificialagentstoself-recognizeandtoacquirethe
skills for interacting with the world, as it allows humans to differ- skillofself/otherdistinction.Actually,underneathself-recognition,
entiateownactionsfromothersandbeself-aware.However,onlya weneedbodyperceptionandactionprocesses,andthefirststepto
selectedgroupofanimals,mainlyhighordermammalssuchashu- achieveitiscontingency-learning[23].Accordingto[4],humanscan
mans,haspassedthemirrortest,abehaviouralexperimentproposed learnandpredicttheconsequenceofactionsandtheseforwardmod-
to assess self-recognition abilities. In this paper, we describe self- elsareusedtodeterminethesourceofthesensoryevents.Thus,in
recognitionasaprocessthatisbuiltontopofbodyperceptionuncon- thisworkweextrapolatedthisconcepttorobots.Theagentshould
sciousmechanisms.Wepresentanalgorithmthatenablesarobotto beabletoanswerthequestion“isthismybody?”byanswering“am
performnon-appearanceself-recognitiononamirroranddistinguish Igeneratingthoseeffectsintheworld?”.
its simple actions from other entities, by answering the following Wepresentanalgorithmthatenabledarobotwithnon-appearance
question:amIgeneratingthesesensations?Thealgorithmcombines self-recognitioncapabilities,byaddressingtherelationbetweenfor-
activeinference,atheoreticalmodelofperceptionandactioninthe wardmodelspredictionerroranditsusefordeterminingthesource
brain,withneuralnetworklearning.Therobotlearnstherelationbe- of the sensory cues. In other words, the artificial agent can self-
tweenitsactionsanditsbodywiththeeffectproducedinthevisual recognizethroughaccumulatingevidenceofproducingeffectsinthe
field and its body sensors. The prediction error generated between worldbyself-generatedactions.Forthatpurpose,therobotneedsto
themodelsandtherealobservationsduringtheinteractionisusedto learntheexpectedsensoryeffectof:thechangesinthevisualfield
inferthebodyconfigurationthroughfreeenergyminimizationandto whenitmovesthebodyandwhereitsbody(e.g.hand)willappear
accumulateevidenceforrecognizingitsbody.Experimentalresults inthevisualfieldwhenitisinfrontofthemirror.
onahumanoidrobotshowthereliabilityofthealgorithmfordiffer- Previousworksonartificialself-recognition,suchas[14,23,34],
entinitialconditions,suchasmirrorrecognitioninanyperspective, havebeenhardlycriticized[1]:“Merelysimulatingcertainfeatures
robot-robotdistinctionandhuman-robotdifferentiation. ofself-recognitionthroughtraining/programmingdoesnotmeanthat
theunderlyingmechanismsarethesame,similar,orevenremotely
1 Introduction related”.Actually,weagreethatexperimentalsimplificationsmake
debatablethatrobotsarecurrentlyabletoself-recognizeinthesame
“Ourbodiesareourgardens,tothewhichourwillsaregar- waythatchimpanzeesdo.Therefore,insteadofaddressingtheself-
deners.”Othello1603.WilliamShakespeare. perceptionawarenesslevel,wefocusedonbodysensorimotorlearn-
ingandintegrationandstudyinghowthesemechanismsaidinself-
Humans perceive their body in a flexible manner [5] but main-
recognitionandself/otherdistinction.
taining their identity [12]. Around the age of two, the majority of
infantsareabletopasstheself-recognitionmirrortest[31],likeele- Relationtootherapproaches
phants,dolphinsandsomenon-humanprimates[2].Thisexperiment Artificialintelligenceapproachesforself-recognitionarequitefar
hasbeenarguedtobehardlyintertwinedwithself-awarenessandso- fromthebiologicalplausibility[13,24].However,someofthemare
cialunderstanding[14]andthusconsciousness.Recently,acleaner alreadyaddressingrelevantcharacteristicsofself-perceptionsuchas
wrassefishreopenedthedebateaboutthesuitabilityofthistestfor timing,spatialcorrelationsandcontingency.
evaluatingself-awareness[20].Asreportedbytheauthors,itwasthe Ontheonehand,wehavemethodsthatdonotinvolvelearning.
firstfishtopassthemirrortest,wavingthenotionofconsciousness In[14]theyusedBayesianinferencetoaccumulateevidence.How-
bysuggestingdifferentevolutionarypathsandshowingabroadspec- ever,actionandperceptionhadtobebinaryvariablesandrequired
trumofself-awareness. continuousstablesegmentationofthebodyasanentity,complicating
Self-recognitioniscommonlyunderstoodasareflectiveprocess, itsscalabilitytorealscenarios.In[23]thisapproachwasextendedto
i.e. you are aware and able to think about it. However, it can be images and its relation with proprioception. The method depended
treated in two different levels [35]: the sensorimotor [25] and the ontheskinaccelerometersandtheimagegridsubsampling.Onthe
cognitive[2].Regardingthefirstlevel,wehypothesizethatthemir- otherhand,contingencyispossibletobelearntwithspikingneural
rortestcanbepartiallypassedwithoutbeingself-conscious,open- networks[29]andself/otherdistinctioncanbedevelopedbygradu-
allyincreasingspatiotemporalresolution[26].
1AcceptedatEuropeanConferenceonArtificialIntelligence(ECAI2020)
1DondersInstituteforBrain,CognitionandBehaviour,theNetherlands. Our approach involves both inference and learning and casts
2PALrobotics,Pujades77-79,4-408005Barcelona,Spain. self/other distinction and self-recognition to free energy minimiza-
3 Institute for Cognitive Systems, Technical University of Munich, Arcis- tion(i.e.variationalinference),inordertosolvethescalabilityand
strasse21,80333Munich,Germany.
0202
rpA
11
]OR.sc[
1v37450.4002:viXra
Figure1. Self-recognitioninthemirrorandself/otherdistinctionexperiments
partialinformationsensitivitylimitationsofpreviousapproaches. 2 Methods
2.1 Experimentaldesign
Predictivecodingapproach
Under the predictive coding [30] approach, the robot is able to Figure1showsthehumanoidrobotTIAGo[28]andthethreediffer-
learn (approximate) generative models of the world, especially the entscenariostested:infrontofthemirror,robot-robotinteractionand
effects of the body in the world. These prediction errors are used human-robotdifferentiation.TIAGoisamobilemanipulatorbyPAL
forinferringthebodystatebuttheyarealsoanindirectmeasureto Robotics that has been designed in a modular way. It is composed
distinguishtherobotgeneratedactions. ofadifferentialdrivebase;aliftingtorso;a7DoFarmandapan-
Defining the brain as an inference machine [19] that is able to tilthead.TherobothasalaserrangefinderonthebaseandaRGBD
interpret the world from partial information [9,15], body percep- cameraonthehead.Fortheexperiments,weonlyusedthemonocular
tion is presented here as an unconscious process that adapts em- RGBcameraas3Dcomputationsaredistortedinthemirrorsetting.
pirical information to current learned models. Based on the active Intermsofmanipulationcapabilities,ithasa7DoFarmandthelift-
inferenceparadigm[11,27],weformalizedbodyperceptionandac- ingtorsoprismaticjoint,beingabletoreachobjectsonthefloorup
tionasanoptimizationproblemthatminimizesthepredictionerror, toobjectsonshelvesataround1.75m.Fortheself/otherdistinction
i.e.,theerrorbetweentheexpectedsensoryeffectandtheobserved experiment,onlythearmwillbeused.Moreover,therobothasstereo
one[10].Accordingtoactiveinference,adaptationcanbeperformed microphonesspeakersandprofessionaltext-to-speechsoftware.Fig-
by changing the interpretation or belief or by acting to modify the ure2showsthemainmodularcomponentsoftherobotused.
worldaccordingtoourexpectations.Thus,wedeployedthisadap-
tation mechanism on a humanoid robot and studied the perceptual
response regarding self-recognition when executing movements in
frontofamirrororinfrontofotheragents.
Contributionandorganization
Thisworkpresentsanovelactiveinferencecomputationalmodel
that combines free energy optimization from [27] with function
learningfrom[22].ThelearningwasperformedbymeansofaMixed
DensityNetworks,MDN[3],toprovidescalabilityandinterpolation.
Thealgorithmenablesarobottorecognizeitselfinthemirrorusing
non-appearancebodycuesandtodistinguishitsbodyfromotheren-
tities.Ourapproach,asitincorporateslearning,isrobusttovariations
Figure2. TIAGorobotusedfortheexperiments
intherobotpositionandthemirrorlocationandangle.Ontopofthis
model,wewereabletocomputetheprobabilitythatourrobotwitha
2.2 Overallalgorithm
givensetofparameterswouldgenerateaparticularobservedsensor
value. The accumulation of this evidence yielded to self-recognize The algorithm 1 summarizes the whole process computed in the
itselfinthemirrorandperformself/otherdistinction. robotforself-recognitionandself/otherdifferentiation.First,thevi-
First, Section 2 describes the experimental setup and the com- sual input of the system is segmented using optical flow to extract
putational model. Section 3 shows the results and Section 4 ana- the visual 2D centroid of any visual blob and the histogram of vi-
lyze the relevance of the results with respect to robotics and artifi- sualmovementdirections.Thisdatawillbeusedasthevisualinput
cialintelligence,anddiscussesitslimitationsregardinganimalself- s andforcomputingtheprobabilityofbeingacontingenteventre-
v
recognition. spectively.Thepredictedsensorvaluesarecomputedbymeansofan
MDNanditspartialderivativeswithrespecttothelatentspace(i.e.
joint angles). Then the error between the predicted and the current
sensorinput(e.g.visualerrore )iscomputedandaddedintothedif-
v
ferentialequationweightedbyitsrelevancy(i.e.varianceΣ ).The
v
goalattractordynamicsarealsocomputedfortheleftandtheright
condition.Finally,theprobabilityofbeinggeneratingthatsensorin-
putiscomputed.
Iftheerrorbetweenthepredictionandtheobservedvaluesistoo
high(outlier),alearningprocessstarts,wheretherobotretrainthe
MDNwiththenewinput.Theoutcomedependsonthreeconditions.
(1)Whentherearenocontingenteffectstherobotisnotabletolearn
anythingandthereforeitisnotitself.(2)Whenitisabletolearnan
effect but then the model cannot properly approximate the sensory
effectthenitisnotitselfeither.Finally,(3)ifitisabletolearnthe
Figure3. Bodyperceptionmodelandnotation.(Left)Generativemodelof
effectandtheerrorisenoughsmallthenitwillaccumulateevidence
therobotperceptionandaction.(Right)Mirrorandrobotsetup.qarethejoint
untilitwillproperlyanswer:itisme.
measurementsandµ,µ(cid:48)istheinferredangleofthejointsanditsfirst-order
Algorithm1Self/otherdistinctionalgorithm
dynamics.visthevisuallocationofthehandandρthegoal.aiistheaction
exertedinjointi.
Require: Σ ,Σ ,Σ ,∆ LOGMIN,LOGMAX
p v µ t
1: µ←Initialjointsangleestimation adapted from the free energy principle approach model proposed
2: µ(cid:48),v,L←0 in[11]:
3: while¬recognized(p self )do
4: h←of(I),I ←camera (cid:46)Opticalflowhistogram
∂F(µ,ρ)
5: p(cont)←sigmoid(BCNN.forward(a,h)) (cid:46)Sec.2.3.3 Perception µ=argminF →µ˙ =µ(cid:48)− (1)
6: g,µ∗,Σ∗ ←MDN.forward(µ) (cid:46)PredictorSec.2.3.2 µ ∂µ
7: ∂ µ g←MDN.backward(µ∗,Σ∗) (cid:46)Sec.2.3.2 Action a=argminF →a˙ =− ∂F(µ,ρ) (2)
8: µ˙ ←0 (cid:46)ActiveInference.Sec2.3.1 a ∂a
9: if∃s p then (cid:46)Proprioception
10: e p =(s p −µ) 2.3.1 Activeinferencemodel
11: µ˙ =µ˙ +e p /Σ p We adapted the free energy model presented in [27] to the TIAGo
12: a˙ =a˙ −(e p /Σ p )∆ t robot.Usingjointencoderss andvisualinformations ,thegraphi-
p v
13: if∃s v then (cid:46)Vision calrepresentationoftheinferenceprocessisdescribedinFig.3.The
14: e v =(s v −g) agentencodesitsbeliefofitsbodyµwiththefollowingdensity[6]:
1 1 5 6 : : µ a˙ ˙ = = a µ ˙ ˙ − + ( ∂ ∂ µ µ g g T T e e v v / / Σ Σ v v )∆ t p(µ,s,ρ)=p(s p |µ)p(s v |µ)p(µ(cid:48)|µ,ρ) (3)
17: if∃s ρ then (cid:46)Goalattractorρdynamics Wherethefirsttwolikelihoodsarethesensormodalitycontributions
18: e f =(µ(cid:48)−f(µ,ρ)) (assumedindependentbetweeneachother)andthethirdtermisthe
19: µ˙ =µ˙ +∂ µ fTe f /Σ µ priordensityforthefirst-orderdynamics,whichalsodependsonthe
20: µ=µ+∆ t µ˙ (cid:46)1storderEulerintegration causal variables ρ. We will control the robot in joint velocities by
21: a=a+∆ t a˙ definingactionsaasthevelocityofeachjoint,thusonlyfirst-order
22: if∃s v then (cid:46)Self-recognitionSec.2.3.4 dynamicsareneeded.
23: L i =−0.5(eT v Σ− v 1e v +lndetΣ v +nln2π) Under the mean-field Laplace approximation, the free energy
24: L=L+L i +lnp(cont)
boundcanbeapproximatedas4:
25: p norm =(exp(L)−LOGMIN)/(LOGMAX−LOGMIN) (cid:20) 1 (cid:21)
26: p self =p self +K(p norm −p self ) F ≈−lnp({s,ρ},µ)− 2 ln|Σ|+nln2π (4)
27: ifoutlierthen
wherenisthesizeofµ.InordertosolveEq.1and2,wecomputed
28: whilei<N s ∧¬timeoutdo
thegradientofF withrespecttothelatentvariablesµ,a.
29: ifp(cont)>δthen (cid:46)LearningSec.2.3.3
30: Qx.append(s p );Qy.append(s v )
31: ifi>N s then ∂F = (s p −µ) + ∂g(µ)T (s v −g(µ)) + (5)
32: MDN.train(Qx,Qy) ∂µ Σ p ∂µ Σ v
∂f(µ,ρ)T (µ(cid:48)−f(µ,ρ))
+ (6)
∂µ Σ
2.3 Detailedcomputationalmodel µ
We describe in detail the body perception and action model and ∂F ∂s T(s −µ) ∂s T(s −g(µ))
then the method for self/other distinction. We define body percep- = p p + v v (7)
∂a ∂a Σ ∂a Σ
p v
tionasinferringjointanglesoftherobotarmµbymeansofdifferent
sensory modalities. The robot approximates the belief of his body whereg v (µ)isthevisualgenerativemodelthatislearnt(Sec.2.3.2)
by means of minimizing the free energy [10], computing the most andf(µ,ρ)isthemodeldynamicsofaperceptualattractor[27].
plausible solution of his arm location using the error between the
4Insomeformulationsofthefreeenergythesensorinputssandothercausal
predictedsensoryinputandtheobservedone.Mathematically,per- variablesarethedescribedbythesamevariable.However,inthispaper,we
ception and action are interpreted by the following two equations splitthemforclaritypurposes.
2.3.2 Generativemodelslearning
TosolveEq.5and7thegenerativemodelsforthesensorg(µ)and
itspartialderivative∂g/∂µshouldbeknown.Converselytoprevi-
ous works on active inference we enabled the robot to learn those
modelstakinginspirationfromourlatestcontributionsonbodyper-
ception with function learning [21,22]. However, in this case, we
usedaprobabilisticneuralnetworkmodeltoprovidescalabilityand
interpolation. The visual generative model is learnt by means of a
Mixture Density Network (MDN) [3]. In this way, we encode not
onlythemappingbuttheuncertaintyassociated.Inprinciple,thefor-
wardmodeloftherobotend-effectorwithrespecttothejointlatent (a) Trainingsamplesandg(µ) (b) MDNtrainingloss
spacecanbelearntusingjustoneGaussiankernel.However,weal-
lowedtherobottolearnmorecomplexvisualpatternsgeneratedby Figure5. LearnedmappingwiththeMDNfromthejointspositionstothe
theactionsorduetothelensnon-linearity.Thesamemodelcangen- 2Dvisualpoint(end-effector)computedthroughopticalflow.Visualsamples
eralizetoforwardmodellearningusingmorecomplexprobabilistic
(blue)usedfortrainingandg(µ)predictorlearned(red).Axisrangesthat
deep models [7] within the free energy framework. The predicted correspondtotheimagedimensionshavebeennormalizedbetween0and1
sensation is computed through the forward pass of the MDN and dividingbythewidth(640px)andtheheight(480px)respectively.
outputstheGaussianmixturemodelparameters:Π coefficients,s
i i where z is the neuron output, s is the mean value output of the
mean and Σ variance. To compute the prediction of the sensation i i
i selectedkernel,s isthecurrentobservationoftheend-effectorinthe
given the state s = g(µ) we select the maximum probable kernel v
andgetthemeanandthevarianceasfollows: visualfieldandP i∗ =Π i∗N(s i∗,σ i 2 ∗ )/ (cid:80) j Π j N(s j ,σ j 2)-See[3].
Inordertotraintheneuralnetworkweuseastheinputthejoints
estimated angles µ and as the output the 2D centroid location of
i∗ =argm i ax softmax(W Π T i h(µ)+b Π ) (8) thebiggestmovingopticalflowblob.Thepointsthatarecontingent
(see Sec. 2.3.3) are buffered into a batch that is then used to mod-
g(µ)=WTh(µ)+b (9)
s s ifynetworkweightsthroughbackpropagation[18].Thelossfunction
where h(µ) is the hidden layer output and W,b are the network usedisthestandardnegativelog-likelihoodoftheGaussianmixture
weights and bias respectively. Although for this specific visual lo- model:L=−ln (cid:80) i Π i N(s i ,σ i 2).
cationlearningonlyonehiddenlayerissufficient,morelayerscan
beaddedformorecomplexnon-linearfunctionlearning.
2.3.3 Contingencylearning
Weassumethattherobothasasystemthatisabletoclassifywhether
itisacontingenteffectornot.Thispriorknowledgecanbejustified
bystatingthattherobothaslearntthepotentialeffectofmovingthe
hand left and right in front of him. In essence, the robot has never
lookedinamirrorbuthasperformedactionswiththearmthatresult
inthefollowingcontingenteffectlearning:whentherobotmovesthe
handtotheleftproducesachangeinthevisualfieldwithaspecific
direction.Wecomputedtheeffectinthevisualfieldgiventheaction
(i.e.velocity)bymeansofanopticalflowalgorithm[33].Tolearn
to classify this effect we used a deep learning classifier with input
thestateoftherobot(i.e.estimatedjointstatesµ)andthevelocity
Figure4. ForwardmodellearningwithMDN.Theforwardpassgivesthe beingexerted(i.e.a)andtheoutputthehistogramoftheopticalflow
predictionandthebackwardpassgivesthepartialderivativewithrespectto velocitydirections.Figure6showstheinput,theoutputandthear-
thebodyconfigurationµ. chitectureoftheneuralnetwork.
Figure 4 describes the MDN to obtain the forward and partial
derivatives through the backward pass. Figure 5 shows an instance
ofthevisualforwardmodeltrainingfortherobotinfrontofthemir-
ror.Thenegativelog-likelihoodconvergesrapidlyin400epochs.The
bluedotscorrespondtothevisualsamplesacquiredwhentherobot
moves the arm and the red dots are generated with the learnt pre-
dictorg(µ)forrandomjointangleswithinthesetofthewavingleft
andrightmovement.Theinterpolationpowerofthenetworkshown
isreallycrucialforthestabilityoffreeenergyoptimization. Figure6. Contingentsensoryeventclassifier.Giventhehistogramofthe
Theinversemappingorpartialderivativewithrespecttothelatent opticalflowvelocitiesofthevisualfield(left),thejointstatesandtheveloci-
variableiscomputedthroughthebackwardpassoftheMDNofthe tiesbeingexerted,thedeepbinaryclassifiercomputeswhethertheeffectsare
mostplausibleGaussiankerneli∗. contingentfortheleftandrightaction.
∂g ∂ ( µ µ) =P i∗ (s i∗ σ − i 2 ∗ s v )∂ ∂ z µ i∗ (10) sifi F c i a g t u io r n e 7 of s s h a o m w p s le th s e of in t p h u e t t d e a st ta s , e t t h . e T l h e e ar j n o i i n n g t v c e u l r o v c e it a ie n s d (c th o e lo c u l r a e s d -
lines)forthehandwavemovementshowtheprofilesofleftandright R7,onehiddenlayerwith20units,two-dimensionaloutputs ∈R2
i
movements. The associated optical flow histogram (coloured dots) (i.e.hand2Dpositionintheimage).ThekernelswereGaussiandis-
varies depending on the movement. The orientations are split into tributions N with mean s and variance σ . We assumed that the
i i
10binsrepresentedwithdifferentcoloursandthey-axisisthenor- output variables (2D location in the image) have the same noise
malizedfrequency.Thelossfunctionusedisthebinarycross-entropy distribution, thus we only used one variance parameter for each
withlogisticoutput.Thenweusedasigmoidfunctiontocomputethe Gaussiankernel.WefixedthenumberofGaussianmixturestofour
probability.TheoptimizerwasAdamwith0.01learningrate.Itisim- (i∈(0,4)).TheoptimizerusedwasAdam[18]andthetrainingused
portanttohighlightthatwehadtoincludethenon-movementcaseto batchesof200samplesand1000epochs.
dealwiththesensornoise.Wetested,inFig.7(c),100randompoints
fromthetestsetwhereweincluded:self-generatedactions,Gaussian
3.1 Self-recognitioninthemirror
randomnoiseandnon-movementwithvisualinput.Thecontingency
probability(y-axis)isshownforallthosecases.Furthermore,some Therobotwasplacedin10randompositionsinfrontofabodysize
random samples have some probability of being classified as self- mirror (Fig. 1A) and we ran the experiment 10 times for each po-
generated. sition.Thearmwasalwaysvisibleinthemirrorandwedidnotin-
cludeanypriorinformationaboutthemirror.Allexperimentswere
successfullyclassifiedasitself.
Theprocedurewentasfollows.Therobotmovedthehandleftand
rightbysettinganattractoroftheend-effectorinthevisualfield.In
otherwords,thedesiredlocationintheimagechangedfromleftto
right of the image centre. The attractors were active for 2 seconds
each. Then, the delay between initiating the left and right waving
changed every time randomly in the range of 3 seconds. This en-
forcedthatactionswerenotperiodic.Finally,thetrainingfinishedif
(a) Jointvelocitiesand (b) Trainingloss (c) Classificationwith
thenumberofsampleswasmorethan200oritreached20seconds.
OFhistogram testdata
Figure 8(a) shows the prediction error dynamics for propriocep-
Figure7. Contingencyclassifierlearning.Theinputarethe7jointveloci- tione p andvisuals v cuesforonetrial5.Thebottomplotshowsthe
ties(lines)andtheopticalflowhistogramwith10bins(dots).Theoutputis meanandstandarddeviationoftheprobabilityofbeingselfinalltri-
theprobabilityofaimagevelocityvectorgeneratedbyanactiononthejoints. alswithnopriortrainingwiththemirror.Thefirsttimethattherobot
looksatthemirrorandstartsmovingthearm,therobotisnotable
2.3.4 Self-recognition:Isthatme? topredictitshandpositionproducingabigpredictionerror.Before
thetrainingstage,therobotwasnotabletorecognizeitself.Thus,it
In order to provide non-appearance self-recognition, we transform
startslearningtherelationbetweenitsbodystateandthevisualinput
thequestionofisthatme?intodidIgeneratethosesensorsvalues?
by means of the MDN (Sec. 2.3.2). After learning for 10 seconds,
Therobotaccumulatesevidenceofgeneratingthesensedeffectsin
the robot continues moving the hand left and right until it decides
theworld.Thisiscomputedthroughthemarginallikelihoodorsen-
whether it is him or not. After learning the forward model the er-
sory surprise. Highly surprising events (effects in the visual field)
rorinthevisualsensationdropsallowingthesystemtoaccumulate
drasticallydroptheprobabilityofbeingself.Conversely,inorderto
evidenceofbeingitself(themodeliscorrectlygeneratingthevisual
increasetheprobabilityofbeingself,theeffectshouldcontinuously
sensations).Still,therearesmallpredictionerrorsrelatedtotheadap-
matchtheexpectedvaluegeneratedbythelearntforwardmodel.
tationofthecurrentlearntmodelandrealobservations.Errorsinpro-
We compute the probability that our model with a given set of
prioceptionaregeneratedbytheperceptualattractorcreatedwhenit
parameters would generate a particular observed cue in the visual
hasthegoaltomovetotheleftortotheright.Anydisturbanceinthe
fieldas:
expectedvisualsensation(surprise)droppedtheprobabilityofbeing
1 self.
L =− (eTΣ−1e +lndetΣ +nln2π) (11)
i 2 v v v v
L=L+L i +lnp(contingent) (12) 3.2 Self/otherdistinction
where p(contingent) is computed with the deep net classifier of Fortheself/otherexperiment,weperformedthesameamountoftri-
Sec. 2.3.3. Inspired by [17], the probability of being itself is com- als.Wefacedtwosimilarrobotsdoingthesamemovementsbutdue
putedbynormalizationandsmoothingasfollows: to the randomness of the delays between actions they were asyn-
chronous (Fig. 1B). As well as in the previous experiment, figure
p =(exp(L)−LOGMIN)/(LOGMAX−LOGMIN) (13)
norm 8(b)showstheerrorinproprioceptiveandvisualcuesofoneofthe
p =p +K(p −p ) (14)
self self norm self trials.ThebottomplotofFig.8(b)showstheprobabilityofbeingself
foralltrials.Inthisexperiment,therobotcouldnotlearnanythingas
whereKisasmoothingconstantworkingasaKalmangain.
therewasnocausalitybetweentheactions(jointvelocities)andthe
observedsensoryinformation.Thisyieldedintothebigvisualpre-
3 Experimentalresults dictionerrorsafterthetraining.Thereforetherobotinferredthatitis
notitself.
Twoexperimentsweredesigned:self-recognitioninthemirror,de-
We further tested the model with an experimenter in front
pictedinFig.1A,andself/otherdistinctionwithothersimilarrobot
(Fig. 1B) and we observed that even when trying to perform the
andahuman,representedinFig.1B.Avideodescribingtheexper-
iments is here: https://youtu.be/3l9N972xjD8. The pa- 5Othertrialshavesimilarprofilesbutwithdifferentdelays.Thus,theydon’t
rametersoftheMDNnetworkwerefixedforallexperiments:µ ∈ bringanyfurtherinformation.
(a) self-recognitioninthemirror (b) self/otherdistinction
Figure8. Self-recognitionandself/otherdistinctionexperimentsvariabledynamics.epandev aretheproprioceptiveandvisualerrors.Duringlearning,the
activeinferenceupdateisdisabled.Theprobabilityofbeingself,p(self),riseswhenthepredictedvisualeffectiscontingentandmatchestheobservation.
samemovementstherobotwasabletoproperlydistinguishbetween monknowledgethecomparatormodel[8].Thisapproachdetermines
self-generatedandothergeneratedvisualcues.Inallcases,therobot thathumansareawareofproducinganeffectintheworldthrough
correctlyidentifiedtheagentinfrontasnotitself.However,asex- their actions (i.e. agency [16]) by means of the prediction error
pected,inthecaseofperfectsynchronizationtherobotwillidentifyit congruence.Someresearcherscriticizedthesimplisticvisionofthe
asitself.Fromthecognitionpointofviewinterpretinganotherrobot modelandproposedthatcontingencydetectionandcausalinference
as itself seems wrong, but also humans will perceive agency when shouldbealsoinvolvedasprocessesontopofcongruence[37].This
seeinganarmthatmovesateveryinstantwithcorrelationwiththeir issimilartoourmodel.Weusebothpredictionerrorandcontingency
commandstothemuscles. learning.Inessence,weproposethe“doublecomparator”modelin-
spiredbytheworkof[36].Thefirstcomparatoristhepredictionerror
mechanismthatapproximatethemodelslearnttorealityforimprov-
4 Machinesabletorecognizethemselves
ing interpretation. The second comparator takes into account other
processeslikespatio-temporalcontingencyandperformstheproper
Wepointedoutthatunconsciousbodyperception,actionandlearn-
distinction.Inourmodel,weengineeredthisabstractlevelusinga
ingisunderneathself-recognition.Experimentsshowedthatcontin-
probabilisticapproach,i.e.,bycalculatingthemarginallikelihoodto
gentnon-appearancecuescanbelearnedthroughinteractionandbe
accumulatetemporalevidenceandthencomputingtheprobabilityof
used to perform self/other distinction. The proposed algorithm en-
generatingthatobservedeffectinthesensoryspace.
abledtherobottorobustlyidentifyitselfinthemirrorjustbylearn-
ing the forward model, i.e., the expected visual input given the in-
Towardspassingtheoriginalmirrortest
ferredbodystate.Aslongasthearmappearedinthemirror,theini-
We showed how non-appearance cues can be used for self-
tialconditionswhereirrelevant.Thisisinlinewiththeexperiments
recognition. However, robots are still not able to pass the original
withnon-humanprimatesthatneededlearningwiththemirrorbefore
self-recognitiontestlikeanimalsdo[2].Forinstance,therobothere
achievingtheself-recognitionability.
didnotlearnthemappingbetweenthetactileandthevisualreflec-
Therobotwasalsoabletodifferentiateitselffromotherentities.
tiontoproducethemotorresponse.Inordertofullyproviderobots
Thealgorithmwassensitivetoanyunexpectedsensationsasweare
withafull-fledgedself-recognitionsimilartohumans,thereareaset
usingtheminimizationofsurpriseasthekeymechanismforthedif-
oftechnicalchallengesthatshouldbefurtheraddressed:
ferentiation.Evenwhentryingtodeceivethealgorithm(e.g.robot-
humanexperiment),anysmalldelayordifferencedroppeddownthe • Complex visual segmentation. The algorithm was designed for
probabilityofbeingitself.Interestingly,thevarianceparameters(rel- onlyonemovingblobsegmentationusingopticalflow.Complex
evanceofthesensorymodalityforinferringthebody)wascrucialfor inputswithmultiplecausalsourcesneedimprovedsegmentation.
dealingwiththerobotownnoisebutdifferentiatingfromotherenti- • Large scale input data. Forward models learning of the end-
tiescues.Wefurtherobservedaninterestingsideeffectofusingthe effector location in the image should be scaled to real sensory
actiontominimizethepredictionerror.Thehumanorrobothandin inputdata,suchasimages.
theself/otherdistinctionexperimentactedsometimesasanattractor • Wholebodyinteractions.Weusedthearmfortheexperimentsas
forthebodyinference,generatingmirroringactionssimilartoimita- aproof-of-concept.Thesameapproachcanbeextendedtowhole-
tion. bodyself/otherdistinction.
In summary, with these experiments, we are showing that • Other cues. The proprioceptive-visual tandem is just one of the
self/other distinction and self-recognition is possible to be imple- sensoryinputsinvolvedinself-recognition.Wedidnotmodelap-
mentedinartificialagents.Althoughitwillnotbeaconsciouscog- pearance,tactileorauditorycues.Weconsideredmovementcon-
nitiveprocessasdescribedinhumansorelephants,itwillhavesome tingencyasthefirstlevelofself-distinctionbutthenanappearance
commongroundinthesensorimotoraction-perceptionlevel. modelsimilartothebodyimageshouldbeincluded.
• Biologicalplausibility.Althoughthemathematicalabstractionof
Doublecomparatormodel body perception has strong neuroscience-inspired notions, using
Within the self-perception cognitive science literature it is com- themarginallikelihoodforaccumulatingevidencedoesnothave
adirectrelationwiththemechanismobservedinthebrain.How- [14] KevinGoldandBrianScassellati,‘Usingprobabilisticreasoningover
ever, it has roots into the model evidence approach under the timetoself-recognize’,RoboticsandAutonomousSystems,57(4),384–
392,(2009).
Bayesianbrainassumption.
[15] Hermann von Helmholtz, Handbuch der physiologischen Optik, vol-
ume9,LeopoldVoss,1867.
5 Conclusion [16] BernhardHommel,‘Actioncontrolandthesenseofagency’,Thesense
ofagency,307–326,(2015).
We proposed an algorithm for self/other distinction using non- [17] SebastianKahlandStefanKopp,‘Apredictiveprocessingmodelofper-
appearancesensorycuesbycombiningfreeenergyoptimizationwith ceptionandactionforself-otherdistinction’,Frontiersinpsychology,
9,2421,(2018).
neuralnetworklearning.Theapproachshowedtheimportanceofnot
[18] DiederikPKingmaandJimmyBa,‘Adam:Amethodforstochastic
onlylearningthemodelsofthebodybutalsoapproximatingthose optimization’,arXivpreprintarXiv:1412.6980,(2014).
models to the observed reality. After learning the humanoid robot [19] David C Knill and Alexandre Pouget, ‘The bayesian brain: the role
was able to accumulate evidence during the generated movements ofuncertaintyinneuralcodingandcomputation’,TRENDSinNeuro-
to discern whether it was itself or other entity in different scenar-
sciences,27(12),712–719,(2004).
[20] MasanoriKohda,TakashiHotta,TomohiroTakeyama,SatoshiAwata,
ios.Thisreliabilityisduetotheexplicithandlingofthesensorimo-
HirokazuTanaka,Jun-yaAsai,andAlexLJordan,‘Ifafishcanpass
toruncertaintyintheproposedmodel,whilestillperformingrobust the mark test, what are the implications for consciousness and self-
self-differentiation.Whentheexpectedsensationwassimilartothe awarenesstestinginanimals?’,PLoSbiology,17(2),e3000021,(2019).
sensorvalues,i.e.thepredictionerrorwaslow,theevidenceofbe- [21] Pablo Lanillos and Gordon Cheng, ‘Active inference with function
learningforrobotbodyperception’,InternationalWorkshoponContin-
ingitselfwasaccumulated.Conversely,anypredictionerrordropped
ualUnsupervisedSensorimotorLearning,IEEEDevelopmentalLearn-
down the probability of being itself yielding to self/other distinc- ingandEpigeneticRobotics(ICDL-Epirob),(2018).
tion.Thisworkstressesthatself-recognitionandself/otherdistinc- [22] PabloLanillosandGordonCheng,‘Adaptiverobotbodylearningand
tiongroundsonthebodyperceptionandactionmodelandthatitis estimationthroughpredictivecoding’,in2018IEEE/RSJInt.Conf.on
possible to give artificial agents, such as robots, these capabilities.
IntelligentRobotsandSystems(IROS),pp.4083–4090.IEEE,(2018).
[23] PabloLanillos,EmmanuelDean-Leon,andGordonCheng,‘Yielding
Furtherworkwillfocusonscalingtorawimages[32]andincluding
self-perception in robots through sensorimotor contingencies’, IEEE
appearancecues. TransactionsonCognitiveandDevelopmentalSystems,9(2),100–112,
(2016).
ACKNOWLEDGEMENTS [24] Pablo Lanillos, Emmanuel Dean-Leon, and Gordon Cheng, ‘Enac-
tiveself:astudyofengineeringperspectivestoobtainthesensorimo-
This work was supported by the MSCA SELFCEPTION project torselfthroughenaction’,inDevelopmentalLearningandEpigenetic
(www.selfception.eu)EUH2020grantno.741941andPALrobotics. Robotics,JointIEEEInt.Conf.on,(2017).
[25] RobertWMitchell,‘Kinesthetic-visualmatchingandtheself-concept
as explanations of mirror-self-recognition’, Journal for the theory of
REFERENCES socialbehaviour,27(1),17–39,(1997).
[26] Yukie Nagai, Yuji Kawai, and Minoru Asada, ‘Emergence of mirror
[1] JamesRAndersonandGordonGGallup,‘Mirrorself-recognition:are- neuronsystem:Immaturevisionleadstoself-othercorrespondence’,in
viewandcritiqueofattemptstopromoteandengineerself-recognition DevelopmentandLearning(ICDL),IEEEInt.Conf.on,volume2,pp.
inprimates’,Primates,56(4),317–326,(2015). 1–6,(2011).
[2] JamesRAndersonandGordonGGallupJr,‘Whichprimatesrecognize [27] Guillermo Oliver, Pablo Lanillos, and Gordon Cheng, ‘Active infer-
themselvesinmirrors?’,PLoSBiology,9(3),e1001024,(2011). encebodyperceptionandactionforhumanoidrobots’,arXivpreprint
[3] ChristopherMBishop,‘Mixturedensitynetworks’,Technicalreport, arXiv:1906.03022,(2019).
(1994). [28] JordiPages,LucaMarchionni,andFrancescoFerro,‘Tiago:themod-
[4] Sarah-JayneBlakemoreandJeanDecety,‘Fromtheperceptionofac- ularrobotthatadaptstodifferentresearchneeds’,inProc.oftheIROS
tiontotheunderstandingofintention’,Nat.Rev.Neurosci.,2(8),561, WorkshoponRobotModularity,(2016).
(2001). [29] AlexandrePitti,GannaPugach,PhilippeGaussier,andSotaroShimada,
[5] MatthewBotvinickandJonathanCohen,‘Rubberhands‘feel’touchthat ‘Spatio-temporaltoleranceofvisuo-tactileillusionsinartificialskinby
eyessee’,Nature,391(6669),756,(1998). recurrentneuralnetworkwithspike-timing-dependentplasticity’,Sci-
[6] ChristopherLBuckley,ChangSubKim,SimonMcGregor,andAnilK entificreports,7,(2017).
Seth,‘Thefreeenergyprincipleforactionandperception:Amathe- [30] RajeshPNRaoandDanaHBallard,‘Predictivecodinginthevisual
maticalreview’,JournalofMathematicalPsychology,(2017). cortex: a functional interpretation of some extra-classical receptive-
[7] Kurtland Chua, Roberto Calandra, Rowan McAllister, and Sergey fieldeffects’,Natureneuroscience,2(1),79–87,(1999).
Levine,‘Deepreinforcementlearninginahandfuloftrialsusingproba- [31] PhilippeRochat,‘Fivelevelsofself-awarenessastheyunfoldearlyin
bilisticdynamicsmodels’,inAdvancesinNeuralInformationProcess- life’,Consciousnessandcognition,12(4),717–731,(2003).
ingSystems,pp.4754–4765,(2018). [32] Cansu Sancaktar and Pablo Lanillos, ‘End-to-end pixel-based deep
[8] NicoleDavid,AlbertNewen,andKaiVogeley,‘The“senseofagency” active inference for body perception and action’, arXiv preprint
anditsunderlyingcognitiveandneuralmechanisms’,Consciousness arXiv:2001.05847,(2019).
andcognition,17(2),523–534,(2008). [33] Eero P Simoncelli, ‘Bayesian multi-scale differential optical flow’,
[9] Peter Dayan, Geoffrey E Hinton, Radford M Neal, and Richard S HandbookofComputerVisionandApplications,397–422,(1999).
Zemel,‘Thehelmholtzmachine’,Neuralcomputation,7(5),889–904, [34] AlexanderStoytchev,‘Self-detectioninrobots:amethodbasedonde-
(1995). tectingtemporalcontingencies’,Robotica,29(01),1–21,(2011).
[10] KarlFriston,‘Thefree-energyprinciple:aunifiedbraintheory?’,Na- [35] MatthisSynofzik,GottfriedVosgerau,andMartinVoss,‘Theexperi-
turereviewsneuroscience,11(2),127,(2010). enceofagency:aninterplaybetweenpredictionandpostdiction’,Fron-
[11] KarlJFriston,JeanDaunizeau,JamesKilner,andStefanJKiebel,‘Ac- tiersinpsychology,4,127,(2013).
tionandbehavior:afree-energyformulation’,Biologicalcybernetics, [36] DanielMWegner,Theillusionofconsciouswill,MITpress,2017.
102(3),227–260,(2010). [37] LorijnZaadnoordijk,TarekRBesold,andSabineHunnius,‘Amatch
[12] ShaunGallagher,‘Philosophicalconceptionsoftheself:implications does not make a sense: on the sufficiency of the comparator model
forcognitivescience’,TrendsCogn.Sci.,4(1),14–21,(2000). for explaining the sense of agency’, Neuroscience of consciousness,
[13] Yasmin Kim Georgie, Guido Schillaci, and Verena Vanessa Hafner, 2019(1),niz006,(2019).
‘Aninterdisciplinaryoverviewofdevelopmentalindicesandbehavioral
measuresoftheminimalself’,in2019JointIEEE9thInternational
Conference on Development and Learning and Epigenetic Robotics
(ICDL-EpiRob),pp.129–136.IEEE,(2019).