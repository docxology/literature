Fast Online Deconvolution of Calcium Imaging Data
JohannesFriedrich1,2,PengchengZhou1,3,LiamPaninski1,4
1GrossmanCenterfortheStatisticsofMindandDepartmentofStatistics,
ColumbiaUniversity,NewYork,NY
2JaneliaResearchCampus,Ashburn,VA
3CenterfortheNeuralBasisofCognitionandMachineLearningDepartment,
CarnegieMellonUniversity,Pittsburgh,PA
4KavliInstituteforBrainScience,andNeuroTechnologyCenter
ColumbiaUniversity,NewYork,NY,USA
j.friedrich@columbia.edu, pengchez@andrew.cmu.edu, liam@stat.columbia.edu
Abstract
Fluorescentcalciumindicatorsareapopularmeansforobservingthespikingactiv-
ityoflargeneuronalpopulations,butextractingtheactivityofeachneuronfrom
rawfluorescencecalciumimagingdataisanontrivialproblem. Wepresentafast
onlineactivesetmethodtosolvethissparsenon-negativedeconvolutionproblem.
Importantly,thealgorithmprogressesthrougheachtimeseriessequentiallyfrom
beginningtoend,thusenablingreal-timeonlineestimationofneuralactivityduring
theimagingsession.Ouralgorithmisageneralizationofthepooladjacentviolators
algorithm(PAVA)forisotonicregressionandinheritsitslinear-timecomputational
complexity. Wegainremarkableincreasesinprocessingspeed: morethanone
orderofmagnitudecomparedtocurrentlyemployedstateoftheartconvexsolvers
relyingoninteriorpointmethods. Unliketheseapproaches,ourmethodcanex-
ploit warm starts; therefore optimizing model hyperparameters only requires a
handfulofpassesthroughthedata. Aminormodificationcanfurtherimprovethe
qualityofactivityinferencebyimposingaconstraintontheminimumspikesize.
Thealgorithmenablesreal-timesimultaneousdeconvolutionofO(105)tracesof
whole-brainlarvalzebrafishimagingdataonalaptop.
1 Introduction
Calciumimaginghasbecomeoneofthemostwidelyusedtechniquesforrecordingactivityfrom
neuralpopulationsinvivo[1]. Thebasicprincipleofcalciumimagingisthatneuralactionpotentials
(or spikes), the point process signal of interest, each induce an optically measurable transient
response in calcium dynamics. The nontrivial problem of extracting the activity of each neuron
from a raw fluorescence trace has been addressed with several different approaches, including
template matching [2] and linear deconvolution [3, 4], which are outperformed by sparse non-
negative deconvolution [5]. The latter can be interpreted as the maximum a posteriori (MAP)
estimate under a simple generative model (linear convolution plus noise; Fig 1), whereas fully
Bayesianmethods[6,7,8]canprovidesomefurtherimprovements,butaremorecomputationally
expensive. Supervisedmethodstrainedonsimultaneously-recordedelectrophysiologicalandimaging
data[9,10]havealsorecentlyachievedstateoftheartresults, butaremoreblack-boxinnature;
Bayesianmethodsbasedonawell-definedgenerativemodelaresomewhateasiertogeneralizeto
morecomplexmulti-neuronalormulti-trialsettings[11,12,13].
Themethodsabovearetypicallyappliedtoimagingdataoffline,aftertheexperimentiscomplete;
however,thereisaneedforaccurateandfastreal-timeprocessingtoenableclosed-loopexperiments,a
Ashorterversionofthisarticlehasbeenpublishedaspartoftheproceedingsofthe30thConferenceonNeural
InformationProcessingSystems(NIPS2016),Barcelona,Spain.
7102
raM
61
]CN.oib-q[
3v93600.9061:viXra
powerfulstrategyforcausalinvestigationofneuralcircuitry[14]. Inparticular,observingandfeeding
backtheeffectsofcircuitinterventionsonphysiologicallyrelevanttimescaleswillbevaluablefor
directlytestingwhetherinferredmodelsofdynamics,connectivity,andcausationareaccurateinvivo,
andrecentexperimentaladvances[15,16]arenowenablingworkinthisdirection. Brain-computer
interfaces(BCIs)alsorelyonreal-timeestimatesofneuralactivity. WhereasmostBCIsystemsrely
onelectricalrecordings,BCIshavebeendrivenbyopticalsignalstoo[17],providingnewinsight
intohowneuronschangetheiractivityduringlearningonafinerspatialscalethanpossiblewith
intracorticalelectrodes. Finally,adaptiveexperimentaldesignapproaches[18,19,20]alsorelyon
onlineestimatesofneuralactivity.
Evenincaseswherewedonotrequirethestricttiming/latencyconstraintsofreal-timeprocessing,
westillneedmethodsthatscaletolargedatasetsasforexampleinwhole-brainimagingoflarval
zebrafish [21, 22]. A further demand for scalability stems from the fact that the deconvolution
problemissolvedintheinnerloopofconstrainednon-negativematrixfactorization(CNMF)[13],
thecurrentstateoftheartforsimultaneousdenoising,deconvolution,anddemixingofspatiotemporal
calciumimagingdata.
Inthispaperweaddressthepressingneedforscalableonlinespikeinferencemethods. Buildingon
previouswork,weframethisestimationproblemasasparsenon-negativedeconvolution. Current
algorithmsemployinteriorpointmethodstosolvetheensuingoptimizationproblemandarefast
enough to process hundreds of neurons in about the same time as the recording [5], but can not
handlelargerdatasetssuchaswhole-brainzebrafishimaginginrealtime. Furthermore,theseinterior
pointmethodsscalelinearlyinthelengthoftherecording,buttheycannotbewarmstarted[23],i.e.,
initializedwiththesolutionfromapreviousiterationtogainspeed-ups,anddonotrunonline.
Here we note a close connection between the MAP problem and isotonic regression, which fits
databyamonotonepiecewiseconstantfunction. Aclassicalgorithmforisotonicregressionisthe
pooladjacentviolatorsalgorithm(PAVA)[24,25],whichcanbeunderstoodasanonlineactive-set
optimizationmethod. WegeneralizedPAVAtoderiveanOnlineActiveSetmethodtoInferSpikes
(OASIS);thisnewapproachtosolvetheMAPproblemyieldsspeed-upsinprocessingtimebyatleast
oneorderofmagnitudecomparedtointeriorpointmethodsonbothsimulatedandrealdata. Further,
OASIScanbewarm-started,whichisusefulintheinnerloopofCNMF,andalsowhenadjusting
modelhyperparameters,asweshowbelow. Importantly,OASISisnotonlymuchfaster,butoperates
inanonlinefashion,progressingthroughthefluorescencetimeseriessequentiallyfrombeginningto
end. Theadvancesinspeedpairedwiththeinherentlyonlinefashionofthealgorithmenabletrue
real-timeonlinespikeinferenceduringtheimagingsession(oncethespatialshapesofneuronsinthe
fieldofviewhavebeenidentified),withthepotentialtosignificantlyimpactexperimentalparadigms.
2 Methods
Thissectionisorganizedasfollows. Thefirstsubsectionintroducestheautoregressive(AR(p))model
forcalciumdynamics.
InthesecondsubsectionwederiveanOnlineActiveSetmethodtoInferSpikes(OASIS)foran
AR(1)model. Thealgorithmisinspiredbythepooladjacentviolatorsalgorithm(PAVA,Alg1),
whichwereviewfirstandthengeneralizetoobtainOASIS(Alg2). Thisalgorithmrequiressome
hyperparametervalues;theoptimizationofthesehyperparametersisdescribednext,alongwithseveral
computationaltricksforspeedingupthehyperparameterestimation. Wefinallydiscussthresholding
approachesforreducingthenumberofsmallvaluesreturnedbytheoriginal(cid:96) -penalizedapproach.
1
Theresultingproblemisnon-convex,andsoweloseguaranteesonfindingglobaloptima,butwecan
easilyadaptOASIStoquicklyfindgoodsolutions.
InthethirdsubsectionwegeneralizetoAR(p)modelsofthecalciumdynamicsanddescribeadual
activesetalgorithmthatisanalogoustotheonepresentedfortheAR(1)case(Alg2). However,this
algorithmisgreedyifp>1andyieldsonlyagoodapproximatesolution. Wecanrefinethissolution
andobtaintheexactresultbywarm-startinganalternativeprimalactivesetmethodwecallONNLS
(Alg3). Finally,Alg4summarizesallofthesesteps.
2
2
1
0
0 150 300
Time
ecnecseroulF s c y
Figure 1: Generative autoregessive model for calcium dynamics. Spike train s gets filtered to
producecalciumtracec;hereweusedp = 2asorderoftheARprocess. Addednoiseyieldsthe
observedfluorescencey.
2.1 Modelforcalciumdynamics
WeassumeweobservethefluorescencesignalforT timesteps,anddenotebys thenumberofspikes
t
thattheneuronfiredatthet-thtimestep,t=1,...,T,cf.Fig1. Following[5,13],weapproximate
thecalciumconcentrationdynamicscusingastableautoregressiveprocessoforderp(AR(p))where
pisasmallpositiveinteger,usuallyp=1or2,
p
(cid:88)
c = γ c +s . (1)
t i t−i t
i=1
Theobservedfluorescencey ∈RT isrelatedtothecalciumconcentrationas[5,6,7]:
y =ac +b+(cid:15) , (cid:15) ∼N(0,σ2) (2)
t t t t
whereaisanon-negativescalar,bisascalaroffsetparameter,andthenoiseisassumedtobei.i.d.
zeromeanGaussianwithvarianceσ2. Fortheremainderweassumeunitssuchthata=1without
lossofgenerality. Webeginbyassumingb=0forsimplicity,butwewillrelaxthisassumptionlater.
(Wealsoassumethroughoutthatallparametersinsightarefixed;incaseofe.g.driftingbaselinesb
wecouldgeneralizethealgorithmsdiscussedheretooperateovershortertemporalwindows,butwe
donotpursuethishere.) Theparametersγ andσcanbeestimatedfromtheautocovariancefunction
i
andthepowerspectraldensity(PSD)ofyrespectively[13]. Theautocovarianceapproachassumes
thatthespikingsignalscomesfromahomogeneousPoissonprocessandinpracticeoftengivesa
crudeestimateofγ . Wewillimproveonthisbelow(Fig3)byfittingtheARcoefficientsdirectly,
i
whichleadstobetterestimates,particularlywhenthespikeshavesomesignificantautocorrelation.
Thegoalofcalciumdeconvolutionistoextractanestimatesˆoftheneuralactivitysfromthevector
ofobservationsy. Asdiscussedin[5,13],thisleadstothefollowingnon-negativeLASSOproblem
forestimatingthecalciumconcentration:
minimize 1(cid:107)cˆ−y(cid:107)2+λ(cid:107)sˆ(cid:107) subjectto sˆ=Gcˆ≥0 (3)
2 1
cˆ,sˆ
wherethe(cid:96) penaltyonsˆenforcessparsityoftheneuralactivityandthelowertriangularmatrixGis
1
definedas:
 1 0 ... ... ... ... 0


−γ1 1
... ... ... ...
0

  . . . ... ... ... ... ... . . .  
G=

−γp ... −γ1 1 0 ... 0

. (4)



0 −γp ... −γ1 1
...
0



 . .
.
... ... ... ... ... . .
.

0 ... 0 −γp ... −γ1 1
ThedeconvolutionmatrixGisbandedwithbandwidthpforanAR(p)process.Equivalently,s=c∗g
withgafiniteimpulseresponsefilteroforderp(p+1filtertaps)and∗denotingconvolution. To
produce calcium trace c, spike train s is filtered with the inverse filter of g, an infinite impulse
responseh,c = s∗h. (Althoughourmainfocusisontheautoregressivemodel,wewilldiscuss
moregeneralconvolutionalobservationmodelsbelowaswell,andtouchonnonlineareffectssuch
assaturationintheappendix.) Followingtheapproachin[5],notethatthespikesignalsˆisrelaxed
fromnon-negativeintegerstoarbitrarynon-negativevalues.
3
2.2 Derivationoftheactivesetalgorithm
Theoptimizationproblem(3)couldbesolvedusinggenericconvexprogramsolvers. Herewederive
themuchfasterOnlineActiveSetmethodtoInferSpikes(OASIS).Thealgorithmisinspiredbythe
pooladjacentviolatorsalgorithm(PAVA)[24,25],whichwereviewfirstforreadersnotfamiliarwith
thisclassicalgorithmbeforegeneralizingittothenon-negativeLASSOproblem.
2.2.1 PoolAdjacentViolatorsAlgorithm(PAVA)
Thepooladjacentviolatorsalgorithm(Alg1)isaclassicexactalgorithmforisotonicregression,
whichfitsdatabyanon-decreasingpiecewiseconstantfunction. Thisalgorithmisdueto[24]and
wasindependentlydiscoveredbyotherauthors[26,27]asreviewedin[25,28]. Itcanbeconsidered
asadualactivesetmethod[29]. Formally,the(convex)problemisto
minimize (cid:107)x−y(cid:107)2 subjectto x ≤...≤x . (5)
1 T
x
Wefirstpresentthealgorithminawaythatconveysitscoreideas(seeAlgS1intheAppendix),
then improve the algorithm’s efficiency by introducing “pools” of variables (adjacent x values)
t
which are updated simultaneously. We introduce temporary values x(cid:48) and initialize them to the
unconstrainedleastsquaressolution,x(cid:48) = y. Initiallyallconstraintsareinthe“passiveset”and
possibleviolationsarefixedbysubsequentlyaddingtherespectiveconstraintstothe“activeset”.
Starting at t = 2 the algorithm moves to the right until a violation of the constraint x(cid:48) ≥ x(cid:48)
τ τ−1
at some time τ is encountered. Now the monotonicity constraint is added to the active set and
enforcedbysettingx(cid:48) = x(cid:48) . (Supposingtheopposite,i.e.x(cid:48) > x(cid:48) ,wecouldmovex(cid:48) and
τ τ−1 τ τ−1 τ
x(cid:48) bysomesmall(cid:15)todecreasetheobjectivewithoutviolatingtheconstraints,yieldingaproofby
τ−1
contradictionthatthemonotonicityconstraintshouldbemade“active”here-i.e.,theconstraintholds
withstrictequality.)Weupdatethevaluesx(cid:48) =x(cid:48) atthetwotimestepstothebestpossiblefitwith
τ τ−1
constraints. Minimizingtheircontributiontotheresidual(y −x(cid:48) )2+(y −x(cid:48) )2bysetting
τ−1 τ−1 τ τ−1
thederivativewithrespecttox(cid:48) tozero,y −x(cid:48) +y −x(cid:48) = 0,amountstoreplacing
τ−1 τ−1 τ−1 τ τ−1
thevalueswiththeiraverage,x(cid:48) =x(cid:48) = yτ−1+yτ. However,thisupdatedvaluecanviolatethe
τ−1 τ 2
constraintx(cid:48) ≥x(cid:48) andweneedtoaddthisconstrainttotheactivesetandupdatex(cid:48) aswell,
τ−1 τ−2 τ−2
x(cid:48) =x(cid:48) =x(cid:48) = yτ−2+yτ−1+yτ,etc. Inthismannerthealgorithmcontinuestoback-average
τ−2 τ−1 τ 3
totheleftasneededuntilwehavebacktrackedtotimet(cid:48)wheretheconstraintx(cid:48) ≥x(cid:48) isalready
t(cid:48) t(cid:48)−1
valid. Solving
τ
(cid:88)
minimize (x(cid:48) −y )2 (6)
t(cid:48) t
x(cid:48)
t(cid:48) t=t(cid:48)
bysettingthederivativetozeroyieldsanupdatethatcorrespondstoaveraging
(cid:80)τ
y
x(cid:48) =x(cid:48) =...=x(cid:48) = t=t(cid:48) t . (7)
t(cid:48) t(cid:48)+1 τ τ −t(cid:48)+1
Theoptimalsolutionthatsatisfiesallconstraintsuptotimeτ hasbeenfoundandthesearchadvances
totherightagainuntildetectionofthenextviolation,backtracksagain,etc. Thisprocesscontinues
untilthelastvaluex isreachedandhavingfoundtheoptimalsolutionwereturnx=x(cid:48).
T
Algorithm1PoolAdjacentViolatorsAlgorithm(PAVA)forisotonicregression
Require: datay ∈yattimeofreading
t
1: initializesetofpoolsP ←{},dataindext←0,poolindexi←0
2: foryinydo (cid:46)readnextdatapointy
3: t←t+1
4: P ←P∪{(y,1,t)} (cid:46)addpool(v ,w ,t )
i+1 i+1 i+1
5: whilei>0andv <v do (cid:46)mergepoolsifnecessary
i+1 i
(cid:16) (cid:17)
6: P ← wivi+wi+1vi+1,w +w ,t
i wi+wi+1 i i+1 i
7: removeP
i+1
8: i←i−1
9: i←i+1
10: for(v,w,t)inPdo (cid:46)constructsolutionforallt
11: forτ =0,...,w−1dox ←v
t+τ
12: returnx
4
Inaworstcasesituationaconstraintviolationisencounteredateverystepoftheforwardsweep
throughtheseries. Updatingalltvaluesuptotimetyieldsoverall (cid:80)T t= T(T+1) −1updates
t=2 2
andanO(T2)algorithm. However,notethatwhenaviolationisencounteredtheupdatedtimepoints
allsharethesamevalue(theaverageofthedataatthesetimepoints,Eq7)anditsufficestotrack
thisvaluejustonceforalltheseupdatedtimepoints[30]. Theconstraintsx(cid:48) ≥x(cid:48) betweenthe
t t−1
updatedtimepointsholdwithequalityx(cid:48) =x(cid:48) ,andarepartoftheactiveset. Inordertoobtain
t t−1
amoreefficientalgorithm, cf.Algorithm1andVideoS1, weintroduce“pools”orgroupsofthe
form(v ,w ,t )withvaluev ,weightw andeventtimet whereiindicesthegroups. Initiallythe
i i i i i i
orderedsetofpoolsisempty. Duringtheforwardsweepthroughthedatathenextdatapointy is
t
initializedasitsownpool(y ,1,t)andappendedtothesetofpools. Adjacentpoolsthatviolatethe
t
constraintv ≥v arecombinedtoanewpool(wivi+wi+1vi+1,w +w ,t ). Wheneverpoolsi
i+1 i wi+wi+1 i i+1 i
andi+1aremerged,formerpooli+1isremoved. Itiseasytoprovebyinductionthattheseupdates
guaranteethatthevalueofapoolisindeedtheaverageofthecorrespondingdatapoints(seeS.3)
withouthavingtoexplicitlycalculateitusingEq(7). Thelatterwouldbeexpensiveforlongpools,
whereasmergingtwopoolshasO(1)complexityindependentofthepoollengths. Withpoolingthe
consideredworstcasesituationresultsinasinglepoolandonlyitsvalueandweightareupdatedat
everystepforward,yieldingO(T)complexity. Constructingtheoptimalsolutionx foralltinafinal
t
effortaftertheoptimalpoolpartitionhasbeenreachedisalsoO(T). Atconvergenceallconstraints
havebeenenforced;furthernotethatconvergencetotheexactsolutionoccursafterafinitenumberof
steps,incontrasttointeriorpoint-methodswhichonlyapproachtheoptimalsolutionasymptotically.
2.3 OnlineActiveSetmethodtoInferSpikes(OASIS)
Now we adapt the PAVA approach to problem (3). PAVA solves a regression problem subject to
theconstraintthatthevalueatthecurrenttimebinmustbegreaterthanorequaltothelast. The
AR(1)modelpositsamoregeneralbutverysimilarconstraintthatboundstherateofdecayinstead
ofenforcingmonotonicity. Thekeyinsightisthatproblem(3)isageneralizationofproblem(5): if
p = 1intheARmodelandwesetγ = 1(weskiptheindexofγ forasingleARcoefficient)and
λ=0inEq(3)weobtainEq(5). Thereforewefocusfirstonthep=1caseanddealwithp>1and
arbitrarycalciumresponsekernelsinthenextsection.
Webeginbyinsertingthedefinitionofsˆ(Eq3). Usingthatsˆisconstrainedtobenon-negativeyields
forthesparsitypenalty
T T T T
(cid:88)(cid:88) (cid:88) (cid:88)
λ(cid:107)sˆ(cid:107) =λ1(cid:62)sˆ=λ G cˆ =λ (1−γ+γδ )cˆ = µ cˆ =µ(cid:62)cˆ (8)
1 k,t t tT t t t
t=1k=1 t=1 t=1
withµ :=λ(1−γ+γδ )(withδdenotingKronecker’sdelta)bynotingthatthesumofthelast
t tT
columnofGis1,whereasallothercolumnssumto(1−γ).
Nowtheproblem
T T
1(cid:88) (cid:88)
minimize (cˆ −y )2+ µ cˆ subjectto cˆ ≥γcˆ ≥0 ∀t (9)
cˆ 2 t t t t t+1 t
t=1 t=1
sharessomesimilaritytoisotonicregressionwiththeconstraintcˆ ≥ cˆ (Eq5). However, our
t+1 t
constraintcˆ ≥γcˆ boundstherateofdecayinsteadofenforcingmonotonicity. Thusweneedto
t+1 t
generalizePAVAtohandletheadditionalfactorγ.
Forclaritywemimicourapproachfromthelastsection: wefirstpresentthealgorithminaway
thatconveysitscoreideas,andthenimprovethealgorithm’sefficiencyusingpools. Weintroduce
temporary values c(cid:48) and initialize them to the unconstrained least squares solution, c(cid:48) = y −µ.
Startingatt=2onemovesforwarduntilaviolationoftheconstraintc(cid:48) ≥γc(cid:48) atsometimeτ is
τ τ−1
detected(Fig2A).Updatingthetwotimestepsbyminimizing 1(y −c(cid:48) )2+1(y −γc(cid:48) )2+
2 τ−1 τ−1 2 τ τ−1
µ c(cid:48) +µ γc(cid:48) yieldsanupdatedvaluec(cid:48) . However,thisupdatedvaluecanviolatethe
τ−1 τ−1 τ τ−1 τ−1
constraintc(cid:48) ≥γc(cid:48) andweneedtoupdatec(cid:48) aswell,etc.,untilwehavebacktrackedsome
τ−1 τ−2 τ−2
∆tstepstotimet(cid:48) =τ −∆twheretheconstraintc(cid:48) ≥γc(cid:48) isalreadyvalid. Atmostoneneeds
t(cid:48) t(cid:48)−1
tobacktracktothemostrecentspike,becausec(cid:48) >γc(cid:48) atspiketimest(cid:48)(Eq1). Solving
t(cid:48) t(cid:48)−1
∆t ∆t
1(cid:88) (cid:88)
minimize (γtc(cid:48) −y )2+ µ γtc(cid:48) (10)
c(cid:48) 2 t(cid:48) t+t(cid:48) t+t(cid:48) t(cid:48)
t(cid:48) t=0 t=0
5
A moveforward7 B trackback3 C moveforward3 D moveforward3 E moveforward7
F trackback7 G trackback3 H moveforward3 I trackback3
. . .
Figure2: IllustrationofOASISforanAR(1)process(seeVideoS2). Redlinesdepicttruespike
times. Theshadedbackgroundshowshowthetimepointsaregatheredinpools. Thepoolcurrently
underconsiderationisindicatedbythebluecrosses. Aconstraintviolationisencounteredforthe
second time step (A) leading to backtracking and merging (B). The algorithm proceeds moving
forward(C-E)untilthenextviolationoccurs(E)andtriggersbacktrackingandmerging(F-G)as
longasconstraintsareviolated. Whenthemostrecentspiketimehasbeenreached(G)thealgorithm
proceedsforwardagain(H).Theprocesscontinuesuntiltheendoftheserieshasbeenreached(I).
Thesolutionisobtainedandpoolsspantheinter-spike-intervals.
bysettingthederivativetozeroyields
(cid:80)∆t (y −µ )γt
c(cid:48) = t=0 t+t(cid:48) t+t(cid:48) (11)
t(cid:48) (cid:80)∆t γ2t
t=0
and the next values are updated according to c(cid:48) = γtc(cid:48) for t = 1,...,∆t. Note the similarity
t(cid:48)+t t(cid:48)
of Eq (7) and (11), which differs by weighting the summands by powers of γ due to the altered
constraints,andbysubtractingµfromthedatayduetothesparsitypenalty. (Alongthewayitis
worthnotingthat,becauseaspikeinducesacalciumresponsedescribedbykernelhwithcomponents
h =γt,c(cid:48) couldbeexpressedinthemorefamiliarregressionformas h(cid:62) 1:∆t+1 (y−µ) t(cid:48):τ,where
1+t t(cid:48) h(cid:62)
1:∆t+1
h1:∆t+1
weusedthenotationv todescribeavectorformedbycomponentsitoj ofv.) Nowonemoves
i:j
forwardagain(Fig2C-E)untildetectionofthenextviolation(Fig2E),backtracksagaintothemost
recentspike(Fig2G),etc. Oncetheendofthetimeseriesisreached(Fig2I)wehavefoundthe
optimalsolutionandsetcˆ=c(cid:48).
Whilethisyieldsavalidalgorithm,itfrequentlyupdateseachvaluec(cid:48) andrecalculatesthefullsums
t
inEq(11)foreachstepofbacktracking. Asimilaralgorithmhasbeensuggestedby[31]forthe
problemwithoutsparsitypenalty. However,itpassesthroughthetimeseriesinreversedirection,
fromitsendtoitsbeginning,andisthusnotapplicabletoonlineprocessing. Itconsidersdirectlythe
deconvolvedactivitysˆandefficientlydoesnotupdatealltimestepsbutonlysuspectedspiketimes.
However,theiralgorithmusestheinefficientupdatesofEq11,renderingitanO(T2)algorithm.
AsinPAVA,nextweintroduce“pools"intothealgorithm;theseareofcriticalimportanceinorderto
obtainatrueO(T)algorithm. InPAVAthesepoolsserveassufficientstatisticssummarizingthedata
betweenjumpsintheestimatedoutputx ;herethepoolssummarizethedatabetweenestimatedspike
t
times,wheretheestimatedcalciumsignalcˆ jumps. Poolsarenowtuplesoftheform(v ,w ,t ,l )
t i i i i
withvaluev ,weightw ,eventtimet andpoollengthl . Hereweexplicitlytrackthepoollength,
i i i i
whichwasidenticaltoitsweightforPAVA.Initiallytheorderedsetofpoolsisempty. Duringthe
forwardsweepthroughthedatathenextdatapointy isinitializedasitsownpool(y −µ ,1,t,1)
t t t
andappendedtothesetofpools. Duringbacktrackingpoolsgetcombinedandonlythefirstvalue
v =c(cid:48) isexplicitlyconsidered,whiletheothervaluesaremerelydefinedimplicitlyviac(cid:48) =γc(cid:48).
i ti t+1 t
Theconstraintc(cid:48)
t+1
≥γc(cid:48)
t
translatestov
i+1
≥γliv
i
asthecriteriondeterminingwhetherpoolsneed
tobecombined. Theintroducedweightsallowefficientvalueupdateswheneverpoolsaremergedby
6
avoidingrecalculatingthesumsinEq(11). Valuesareupdatedaccordingto
v ←
w
i
v
i
+γliw
i+1
v
i+1 (12)
i w
i
+γ2liw
i+1
wherethedenominatoristhenewweightofthepoolandthepoollengthsaresummed
w ←w +γ2liw (13)
i i i+1
l ←l +l (14)
i i i+1
Wheneverpoolsiandi+1aremerged,formerpooli+1isremoved. Itiseasytoprovebyinduction
thattheupdatesaccordingtoEqs(12-14)guaranteethatEq(11)holdsforallvalues(seesectionS.3
intheappendix).
Analogous to PAVA, the updates solve Eq (9) not just greedily but optimally, finding the exact
solutiontotheconvexprobleminO(T). Oneimportantpoint(especiallyrelevantforonlineuse)is
thatthecomputationtimeperobservationtimestepisnotfixedbutrandom,sincewemighthaveto
backtracktoupdateanunpredictablenumberofpools. Wefoundempiricallythat,overawiderange
ofhyperparameters,inabout80%ofthecases0-1mergeoperationwasperformedperobservation
timestep. Withlessthan0.5%probabilityfourormoremergeswerenecessary;inallourexperiments
sofar,nevermorethansevenmergeswereneeded.
ThefinalalgorithmissummarizedinAlgorithm2andillustratedinFig2aswellasinVideoS2.
ComparingAlgorithm1with2clearlyrevealsthemodificationsmadeandshowsthatforγ =1and
λ=0thealgorithmreducestoPAVA.
Algorithm2FastonlinedeconvolutionalgorithmforAR1processeswithpositivejumps
Require: decayfactorγ,regularizationparameterλ,datay ∈yattimeofreading
t
1: initializesetofpoolsP ←{},timeindext←0,poolindexi←0,solutionsˆ←0
2: foryinydo (cid:46)readnextdatapointy
3: t←t+1
4: P ←P∪{(y−λ(1−γ+γδ ),1,t,1)} (cid:46)addpool(v ,w ,t ,l )
tT i+1 i+1 i+1 i+1
5: whilei>0andv
i+1
<γliv
i
do (cid:46)mergepoolsifnecessary
6: P
i
← (cid:16) wiv
w
i
i
+
+
γ
γ
li
2l
w
i
i
w
+
i
1
+
v
1
i+1,w
i
+γ2liw
i+1
,t
i
,l
i
+l
i+1
(cid:17) (cid:46)Eqs(12-14)
7: removeP
i+1
8: i←i−1
9: i←i+1
10: for(v,w,t,l)inPdo (cid:46)constructsolutionforallt†
11: forτ =0,...,l−1docˆ ←γτmax(0,v) (cid:46)enforcecˆ ≥0viamax
t+τ t
12: ift>1thensˆ ←cˆ −γcˆ
t t t−1
13: returncˆ,sˆ
†Foronlineestimatesofcˆandsˆthesolutioncanbeconstructedwithintheloopoverynotjustafterit.
2.3.1 Dualformulationwithhardnoiseconstraint
Theformulationabovecontainsatroublesomefreesparsityparameterλ(implicitinµ). Amore
robustdeconvolutionapproachchoosesthesparsityimplicitlybyinclusionoftheresidualsumof
squares (RSS) as a hard constraint and not as a penalty term in the objective function [13]. The
expectedRSSsatisfies(cid:104)(cid:107)c−y(cid:107)2(cid:105)=σ2T andbythelawoflargenumbers(cid:107)c−y(cid:107)2 ≈σ2T with
highprobability,leadingtotheconstrainedproblem
minimize (cid:107)sˆ(cid:107) subjectto sˆ=Gcˆ≥0 and (cid:107)cˆ−y(cid:107)2 ≤σˆ2T. (15)
1
cˆ,sˆ
(Asnotedabove,weestimateσusingthepowerspectralestimatordescribedin[13];seealso[8]for
asimilarapproach.)
Wewillsolvethisproblembyincreasingλinthedualformulationuntilthenoiseconstraintistight.
Westartwithsomesmallλ,e.g.λ=0,toobtainafirstpartitioningintopoolsP,cf.Fig3A.From
Eqs(11-13)alongwiththedefinitionofµ(Eq8)itfollowsthatgiventhesolution(v ,w ,t ,l ),
i i i i
7
2 Truth Estimate Data Correlation:0.734
0
σ2T
λ
0 λ∗
SSR
2 Correlation:0.737
λ−
0
2
0
ecnecseroulF Correlation:0.769
σ2T
γˆ
γˆ∗
SSR
A
runAlg2
B
C
runAlg2
D 2 Correlation:0.779
γˆ−
0
E 2 Correlation:0.792
runAlg2
0 .
.
.
IterateB–E
F
3iterations 2 trueγ γˆfromautocovariance Correlation:0.851
∼
toconverge
0
10 20 30 40
Time[s]
Figure 3: Optimizing sparsity parameter λ and AR coefficient ˆγ. (A) Running the active set
method,withconservativelysmallestimateγˆ,yieldsaninitialdenoisedestimate(blue)ofthedata
(gray)roughlycapturingthetruth(red). Wealsoreportthecorrelationbetweenthedeconvolved
estimate and true spike train as a direct measure for the accuracy of spike train inference. (B)
UpdatingsparsityparameterλaccordingtoEq(18)suchthatRSS= σ2T (left)shiftsthecurrent
estimatedownward(right,blue). (C)Runningtheactivesetmethodenforcestheconstraintsagain
andisfastduetowarm-starting. (D)Updatingγˆ byminimizingthepolynomialfunctionRSS(γˆ)
and(E)runningthewarm-startedactivesetmethodcompletesoneiteration,whichyieldsalready
adecentfit. (F)Afewmoreiterationsimprovethesolutionfurther. Theobtainedestimate(blue)
ishardlydistinguishablefromtheoneobtainedwithknowntrueγ (yellowdashedtrace,plottedin
addition to the traces in A-E, is on top of blue solid line). Note that determining γˆ based on the
autocovariance(additionallyplottedpurpletrace)yieldsacrudesolutionthatevenmissesspikes(at
24.6sand46.5s).
where
(cid:80)li−1(y −µ )γt (cid:80)li−1(y −λ(1−γ+γδ ))γt
v = t=0 ti+t ti+t = t=0 ti+t ti+t,T (16)
i (cid:80)li−1γ2t w
i
t=0
forsomeλ,thesolution(v(cid:48),w(cid:48),t(cid:48),l(cid:48))forλ+∆λis
i i i i
v(cid:48) =v −∆λ
(cid:80)l
t
i
=
−
0
1(1−γ+γδ
ti+t,T
)γt
=v −∆λ
1−γli(1−δ
iz
)
(17)
i i w i w
i i
where z is the index of the last pool and because pools are updated independently we make the
approximationthatnochangesinthepoolstructureoccur. InsertingEq(17)intothenoiseconstraint
(Eq15)resultsin
(cid:88) z l (cid:88)i−1(cid:18)(cid:18) v −∆λ 1−γli(1−δ iz ) (cid:19) γt−y (cid:19)2 =σˆ2T (18)
i w ti+t
i
i=1 t=0
andsolvingthequadraticequationfor∆λyields
(cid:112)
−β+ β2−4α(cid:15)
∆λ= (19)
2α
with α = (cid:80) ξ2, β = 2 (cid:80) χ ξ and (cid:15) = (cid:80) χ2 −σˆ2T where ξ = 1−γli(1−δiz)γt and
i,t it i,t it it i,t it it wi
χ =y −v γt.
it ti+t i
Thesolution∆λprovidesagoodapproximateproposalstepforupdatingthepoolvaluesv (using
i
Eq17). Sincethisupdateproposalisonlyapproximateitcangiverisetoviolatedconstraints(e.g.,
8
negativevaluesofv . TosatisfyallconstraintsAlgorithm2isruntoupdatethepoolstructure,cf.
i
Fig3C,butwithawarmstart: weinitializewiththecurrentsetofmerelyzpoolsP(cid:48)insteadoftheT
poolsforacoldstart(Alg2,line4). Thisstepreturnsasetofv valuesthatsatisfytheconstraints
i
andmaymergepools(i.e.,deletespikes);thentheprocedure(updateλthenrerunthewarm-started
Algorithm2)canbeiterateduntilnofurtherpoolsneedtobemerged,atwhichpointtheprocedure
hasconverged. Inpracticethisleadsto anincreasingsequenceof λvalues (correspondingtoan
increasinglysparsesetofspikes),andnopool-split(i.e.,add-spike)movesarenecessary. (Notethat
itispossibletocheaplydetectanyviolationsoftheKKTconditionsinacandidatesolution;ifsucha
violationisdetected,thecorrespondingpoolcouldbesplitandthewarm-startedAlgorithm2run
locallynearthedetectedviolations. However,aswenoted,duetotheincreasingλsequencewedid
notfindthissteptobenecessaryintheexamplesexaminedhere.)
Thiswarm-startingapproachbringsmajorspeedbenefits: aftertheresidualisupdatedfollowinga
λupdate,thecomputationalcostofthealgorithmislinearinthenumberofpoolsz,hencewarm
startingdrasticallyreducescomputationalcostsfromk T tok zwithproportionalityconstantsk
1 2 1
andk : ifnopoolboundaryupdatesareneededthenafterwarmstartingthealgorithmonlyneedsto
2
passoncethroughallpoolstoverifythatnoconstraintisviolated,whereasacoldstartmightinvolve
acouplepassesoverthedatatoupdatepools,sok istypicallysignificantlysmallerthank ,andzis
2 1
typicallymuchsmallerthanT (especiallyinsparsely-spikingregimes).
2.3.2 Additionalbaseline
Foreaseofexpositionwethusfarassumednooffsettingbaseline. Addingaknownbaselineb(cid:54)=0
theproblemreads
minimize 1(cid:107)b1+cˆ−y(cid:107)2+λ(cid:107)sˆ(cid:107) subjectto sˆ=Gcˆ≥0. (20)
2 1
cˆ,sˆ
For known baseline one merely needs to initialize OASIS by subtracting not only the sparsity
parameterµ(λ)fromthedatay,cf.Eq(11)andAlgorithm2,butalsothebaselineb.Thefluorescence
cˆdependsonlyonthesumφ=b1+µ.
Ifthebaselineisnotknown,wewanttooptimizeittoobysolvingthenoiseconstraineddualproblem
minimize (cid:107)sˆ(cid:107) subjectto sˆ=Gcˆ≥0 and (cid:107)ˆb1+cˆ−y(cid:107)2 ≤σˆ2T. (21)
1
ˆb,cˆ,sˆ
We denote all except the differing last component of µ by µ = λ(1 − γ) (Eq 8) and of φ by
φ = b+λ(1−γ). φisthetotalshiftappliedtothedata(exceptforthelasttimestep)duetothe
baselineandsparsitypenaltybeforerunningOASIS.Weincreaseφuntilthenoiseconstraintistight.
φcanbeinitializedbyminy orbetterbyasmallpercentileofy,e.g.15%. OnceOASIShasbeen
t
runwithsomeφthebaselineˆbisobtainedbyminimizingtheobjective(20)withrespecttoit,yielding
ˆb=(cid:104)y−cˆ(cid:105)= 1 (cid:80)T (y −cˆ),andthesparsityparameterisµ=φ−ˆb. Appropriatelyaddingˆb
T t=1 t t
toEq(18)
(cid:88) z l (cid:88)i−1(cid:18)(cid:18) v −∆φ 1−γli(1−δ iz ) (cid:19) γt−y +ˆb (cid:19)2 =σˆ2T (22)
i (1−γ)w ti+t
i
i=1 t=0
and plugging the analytic expression ˆb = 1 (cid:80)T (y − cˆ) =
T t=1 t t
1 (cid:80)z (cid:80)lj−1 (cid:16) y − (cid:16) v −∆φ1−γlj(1−δjz) (cid:17) γτ (cid:17) into Eq (22) to account for the changing
T j=1 τ=0 tj+τ j (1−γ)wj
baseline, we obtain an estimate of ∆φ using a block coordinate update of φ andˆb. Solving the
ensuingquadraticequationfor∆φ,yields
(cid:112)
−β+ β2−4α(cid:15)
∆φ= (23)
2α
with α = (cid:80) ξ2, β = 2 (cid:80) χ ξ and (cid:15) = (cid:80) χ2 −σˆ2T where ξ = 1−γli(1−δiz)γt −
i,t it i,t it it i,t it it (1−γ)wi
(cid:80)
(1−γlj(1−δjz))2
and χ = y − v γt − 1 (cid:80) (y − v γτ). All pools are updated
j T(1−γ)2wj it ti+t i T j,τ tj+τ j
accordingtov(cid:48) = v −∆φ1−γli(1−δiz),cf.Eq(17). TosatisfyallconstraintsAlgorithm2isrun,
i i (1−γ)wi
warm-startedbyinitializingwiththecurrentsetofpools.
9
2.3.3 OptimizingtheARcoefficient
Thusfartheparameterγhasbeenknownorbeenestimatedbasedontheautocovariancefunction. We
canimproveuponthisestimatebyoptimizingγˆaswell,whichisillustratedinFig3. Afterupdating
λ(andˆb)followedbyrunningAlgorithm2,weperformacoordinatedescentstepinγˆthatminimizes
theRSS,cf.Fig3D.TheRSSasafunctionofγˆisahighorderpolynomial,cf.Eq(11),andweneed
tosettlefornumericalsolutionsof
γˆ =argmin (cid:88) z l (cid:88)i−1(cid:32) ˆb+ (cid:80)l τ i = − 0 1(y ti+τ −µ ti+τ )γτ γt−y (cid:33)2 . (24)
γ
(cid:80)li−1γ2τ ti+t
i=1 t=0 τ=0
WeusedBrent’smethod[32]withbounds0≤γˆ <1tosolvethisproblem. Oneiterationconsists
nowofstepsB-EinFig3,whileforknownγonlyB-Cwerenecessary. Ifoptimizingthebaselinetoo,
weobtainedbetterresultsbyminimizingtheRSSjointlywithrespecttoγˆandˆbusingL-BFGS-B[33]
insteadofkeepingthebaselineˆbfixed.
2.3.4 Fasteroptimizationofhyperparameters
Wehavepresentedmethodstoestimatethehyperparametersλ, bandγ, whichrequireahandful
ofwarm-startediterationsofOASIS.Togainfurtherspeed-upstheseparameterscanbeestimated
on decimated data. When downsampling by a factor k, the average of k subsequent frames is
√
calculated,thenoiseσˆ dividedbyafactor kandtheinitialestimateoftheARcoefficientscaledto
γˆk. Alternatively,onecouldestimateσandγbasedonthedecimateddata. Oncethehyperparameters
havebeenobtained,thecorrespondinginversetransformationsareperformed: γˆ →γˆk 1,ˆb→ˆband
λ→λ 1−γˆ suchthattheshrinkageµ=λ(1−γˆ)duetothepenaltytermstaysinvariant. Thefinal
1−γˆ1/k
runofOASISonthefulldataiswarmstartedusingthesolutionobtainedonthedecimateddata. Data
pointsthatarenotintheproximityofaspikeofthedownsampledsolutionarealreadycombinedinto
largepools,insteadofinitializingeachdatapointasitsownseparatepool. Moreprecisely,ifthe
deconvolveddecimateddatahaspositivevaluesattimes{t },fordeconvolvingthefulldatatime
i
(cid:83)
steps {(k−1)t ,...,(k+1.5)t }areinitializedasindividualpools,whiletheremainingtimesteps
i i i
arepooledtogetherintobiggerpools,separatedfromeachotherbytheindividualones,withvalues
givenbyEq(11)andweightsbyitsdenominator.
In particular the estimation of the AR coefficient γ is computationally burdensome, because it
involvesexpensiverepeatedevaluationsoftheRSSinordertominimizeitasfunctionofγˆ(andˆb).
Thecomputingtimedependslinearlyonthenumberofpoolsz andwegainfurtherspeed-upsby
restrictingtheattentiontomerelyasubsetofpools. Inparticular,becauseγ canbewellestimated
basedonlargeisolatedcalciumevents,werestrictthecalculationoftheRSStothepoolswithlargest
productofvalueandlength. Alargevalueindicatesalargeeventandalongpoolanisolatedevent.
WepresentdetailedresultsintheResultssection,indicatingthataltogetherwecansaveaboutan
orderofmagnitudecomputationwiththegreatestsavingsobtainedbyreducingtheoptimizationofγˆ
fromO(z)toO(1).
Itisalsoworthnotingthatthehyperparameterestimationdiscussedaboveisperformedin‘batch’
mode,notonline. However,oncegoodhyperparametervaluesareobtainedonashortinitialbatchwe
canswitchintoonlinemode(withthehyperparametersheldfixed)andhandletheremainingdataina
stream.
2.3.5 Hardshrinkageand(cid:96) penalty
0
Itiswell-knownthat(cid:96) penalizationresultsin“soft-thresholding”[34],inwhichsmallvaluesare
1
zeroedoutandlargevaluesareshiftedtolowervalues(wherethesizeofthisshiftisproportional
to the penalty λ). We can perform hard instead of soft thresholding (avoiding this shrinkage of
largevalues)byreplacingthesparsitypenaltybyaconstraintontheminimumspikesizes . The
min
problem
minimize 1(cid:107)cˆ−y(cid:107)2 subjectto sˆ=Gcˆ with sˆ ≥s or sˆ =0 (25)
2 t min t
cˆ,sˆ
isnon-convexandwearenotguaranteedtofindtheglobalminimum.However,weobtainagoodlocal
minimumbymerelychangingtheconditiontomergepoolsfromv
i+1
<γliv
i
tov
i+1
<γliv
i
+s
min
,
modifyinglines3and5inAlgorithm2.
10
Nowwemustchooseavaluefors . Inmanycaseswefoundthatsimplysettings asasmall
min min
multipleofthenoiselevelledtogoodresults. Ifthescalingfactora(Eq2)relatingfluorescenceto
actionpotentialswasknown,wecouldproperlynormalizethespiketrainsuchthatsˆ =1corresponds
t
toonespikeandchooses =0.5,oraslightlyhighervaluetoavoidsplittingonespikeintotwo
min
ofsize0.5. However,oftenthefactorisunknownordifficulttoestimate,renderingthechoiceof
s cumbersome. Analogoustothevariationofλ,wecanstartwiths =0andincreaseituntil
min min
theRSScrossestheσ2T thresholdbysequentiallyremovingthesmallest‘spike’andmergingthe
poolsitusedtoseparate. Bymaximizings underthenoiseconstraintweminimizethenumberof
min
non-zerovaluesofsˆ. Defacto,wetrytofindaparsimoniousdescriptionofthedatabyminimizing
thenumberofnon-zerovaluesofsˆ,thussolvingasparsityproblemwith(cid:96) penalty:
0
minimize (cid:107)sˆ(cid:107) subjectto sˆ=Gcˆ≥0 and (cid:107)cˆ−y(cid:107)2 ≤σˆ2T (26)
0
cˆ,sˆ
Insteadofsequentiallyremovingthesmallest‘spike’weactuallyobtainedthebestperformanceby
sequentiallyaddingspikesatthehighestvaluesofthe(cid:96) -solutionsˆuntiltheRSSissmallerthanσˆ2T.
1
Whiletheupdatesresemblethoseofmatchingpursuit[35],inpracticewefoundthataddingspikesat
thepositionssuggestedbythe(cid:96) -solutionyieldsbetterresultsthanmatchingpursuit(whichadds
1
spikesatpositionsthatgreedilyleadtothehighestRSSreductionperstep). Specifically,wefound
thatoftenmatchingpursuitcannotresolvespikesincloseproximity,butinsteadresultsinerroneous
placementofonebigspikeasanexplanationforallnearbyspikes. Insteadofmergingpoolswenow
needtosplitpools. Denotingthetimewheretoaddaspikebyt ,i.e.thetimewherethe(cid:96) -solution
s 1
hasitshighestvalueafterrulingouttimeswherespikeshavealreadybeenadded,onesearchesforthe
pooliinwhichitfalls,i.e.t <t <t +l . Pooligetsupdatedasl(cid:48) =t −t ,w(cid:48) = (cid:80)l i (cid:48)−1 γ2t,and
i s i i i s i i t=0
v(cid:48) = (cid:80)l i (cid:48)−1 y γt/w(cid:48),whichfollowsdirectlyfromEq(11)withµ =0. Allpoolindicesgreater
i t=0 t+ti i t
thaniareincreasedbyoneandanewpoolisinsertedafterpooliwithl(cid:48) = l −l(cid:48),t(cid:48) = t ,
i+1 i i i+1 s
w(cid:48) = (cid:80)l i (cid:48) +1 −1 γ2t,andv(cid:48) = (cid:80)l i (cid:48) +1 −1 y γt/w(cid:48) .
i+1 t=0 i+1 t=0 t+ts i+1
Asisthecasewithalloptimizedhyperparameters,oncewehaveobtainedadecentestimateofs
min
onaninitialsubsetofthedatawecanswitchbackintoonlinemode. Inonlinemodeouralgorithmis
typicallyfasterthanmatchingpursuit,sincematchingpursuitrequiresupdatingO(∆)pointsofthe
residualwitheachupdate,where∆isthelengthofthecalciumtransient(innumberofframes).
2.4 GeneralizationbeyondtheAR(1)case
2.4.1 AgreedysolutionfortheAR(p>1)processes
AnAR(1)processmodelsthecalciumresponsetoaspikeasaninstantaneousincreasefollowedby
anexponentialdecay. Thisisagooddescriptionwhenthefluorescencerisetimeconstantissmall
comparedtothelengthofatime-bin,e.g.whenusingGCaMP6f[36]withaslowimagingrate. For
fast imaging rates and slow indicators such as GCaMP6s it is more accurate to explicitly model
thefiniterisetime. TypicallywechooseanAR(2)process,thoughmorestructuredresponses(e.g.
multipledecaytimeconstants)canalsobemodeledwithhighervaluesfortheorderp.
ForanAR(p)processthesparsitypenaltyλ(cid:107)sˆ(cid:107) canagainbeexpressedasµ(cid:62)cˆ,because
1
T T T min(p,T−t) T
(cid:88)(cid:88) (cid:88) (cid:88) (cid:88)
λ(cid:107)sˆ(cid:107) =λ1(cid:62)sˆ=λ G cˆ =λ (1− γ )cˆ = µ cˆ =µ(cid:62)cˆ, (27)
1 k,t t i t t t
t=1k=1 t=1 i=1 t=1
withµ := λ(1−
(cid:80)min(p,T−t)γ
),byevaluatingthecolumnsumsofG. Forp > 1thedynamics
t i=1 i
arenolongerfirst-orderMarkovandthenextvaluedependsnotonlyonthecurrentbutonpossibly
multipleprevioustimesteps. Nowfollowingalongthelinesoftheprevioussectionjustleadstoa
greedy,approximatesolution;wewillpresentanexactalgorithmlater. Weusematrix-andvector
notationtodescribethedynamicsofc . LetthetransitionmatrixA,multitimestepcalciumvectors
t
ζ ,andvectorebedefinedas
t
     
γ1 γ2 ... γp ct 1
A=  1 . .
.
. 0 .. . . . .. . 0 . .
.
  ζ t =  ct− . .
.
1   e=  0 . .
.
  (28)
0 ... 1 0 ct−p+1 0
11
Thecalciumdynamicsisgivenbyζ =Aζ +s e. AnalogouslytotheAR(1)casewederivean
t t−1 t
algorithmthatmovesthroughthetimeseriesuntilitfindsaviolationoftheconstraintc(cid:48) ≥e(cid:62)Aζ(cid:48)
τ τ−1
forsometimeτ,updatesc(cid:48) andc(cid:48) ,andbacktracksfurtheruntiltheupdatesdonotviolateany
τ τ−1
constraintsatprevioustimesteps. Notethatwealsoimplicitlyhaveconstraintsonζ ,enforcingthe
t
factthatζ ismostlyatime-shiftedversionofζ .
t+1 t
Assumingweneedtobacktrackby∆tstepsandintroducingagaint(cid:48) =τ −∆t,theobjectiveisto
minimize (cid:80)τ (1(c(cid:48) −y )2+µ c(cid:48))withrespecttoc(cid:48) undertheactiveconstraintsζ =Aζ for
t=t(cid:48) 2 t t t t t(cid:48) t t−1
t=t(cid:48)+1,...,τ. Pluggingintheconstraintsonthedynamicstheobjectivereads
∆t ∆t
1(cid:88) (cid:88)
minimize (e(cid:62)Atζ(cid:48) −y )2+ µ e(cid:62)Atζ(cid:48) . (29)
c(cid:48) 2 t(cid:48) t+t(cid:48) t+t(cid:48) t(cid:48)
t(cid:48) t=0 t=0
Settingthederivativewithrespecttoc(cid:48) tozeroandsolvingforc(cid:48) yields
t(cid:48) t(cid:48)
(cid:80)∆t (cid:0) y −µ − (cid:80)p (At) c(cid:48) (cid:1) (At)
c(cid:48) = t=0 t+t(cid:48) t+t(cid:48) k=2 1,k t(cid:48)+1−k 1,1 (30)
t(cid:48) (cid:80)∆t (At)2
t=0 1,1
where(At)2 denotesthesquareoftheentryinthefirstrowandcolumninthematrixobtainedas
1,1
t-thmatrixpowerofA. Again,notethattheseentriesdescribethecalciumkernelhwithcomponents
h = (At) . Eq(30)reducestoEq(11)forp = 1whereAisjusta1×1-matrixwithentryγ.
1+t 1,1
Thenextvaluesareupdatedaccordingtoc(cid:48) = (cid:80)p γ c(cid:48) fort=1,...,∆t.
t(cid:48)+t k=1 k t(cid:48)+t−k
Wederiveagainanefficientformulationofthealgorithmusingpools. Consideringthedenominator
inEq(30)asaweightinanalogytotheAR(1)caseandcalculatingtheweightedsumuponmerging
ofpoolsisnotvalidforp>1becauseingeneral(At) (Au) (cid:54)=(At+u) . Introducingpoolsis
1,1 1,1 1,1
stillusefulasitallowsustokeeptrackofonlyasmallnumberofpelementsineachpool. Whilefor
thecaseofAR(1)weonlykepttrackofeachgroup’sfirstelement,wenowkeeptrackofthefirst
aswellasthep−1lastelements. InordertospeeduptheupdateinEq(30),wecanprecompute
thepowersofAandstore(At) inmemory. Notethatonlythepowersuptothemaximalinter-
1,:
spike-intervalareneeded,whichcanbemuchsmallerthanT; ofcourse,forverylargevaluesof
t, (At) ≈ 0, by the stability of A; thus for high powers the entries of (At) can also be well
1,: 1,:
approximatedbyaquicklycomputableexponentialfunctionorsimplybetruncated. Analogousto
thecasep=1,wecanalsoimposeaconstraintontheminimumspikesizes attheexpenseof
min
havingtodealwithanon-convexproblembymerelychangingtheconditiontomergepoolsfrom
v
i+1
< (Ali)
1,1
v
i
+(Ali)
1,2
u
i−1
to v
i+1
< (Ali)
1,1
v
i
+(Ali)
1,2
u
i−1
+s
min
where v
i
and u
i
denotethefirstandlastvalueofpooli.
AccordingtoEq(30)thesolutionisalinearfunctionofµ, andhenceofλ. Thusthehardnoise
constraintfortheRSS(cid:107)c−y(cid:107)2 =σ2T isaquadraticequationinλ,thatcanbesolvedanalytically,
undertheassumptionofinvariantpoolstructureanalogoustoabovecaseofAR(1),butinvolving
morelengthyexpressionswhichwestateexplicitlyintheappendix(sectionS.5). Updatingallpools
independentlyaccordingtoEq(30)cangiverisetoviolatedconstraints,requiringustorerunthe
algorithm,warm-startedbyinitializingwiththecurrentsetofpools,asdescribedabove. After2-3
iterationsnopoolsneedtobemergedandthefinalsolutionhasbeenfound. Wecanagaininterleave
anupdatestepforoptimizingtheparametersγ ,asdescribedabove.
i
2.4.2 Onlinenon-negativeleastsquares(ONNLS)
WenotedabovethatEq(30)isnotfirst-orderMarkovian: itincludesadependencyonp−1previous
time steps and hence in general the previous pool. In updating only the first value within a pool
andusingthecurrentvaluesofthep−1lastvaluesofthepreviouspoolwithintheupdateEq(30),
weactuallyperformedgreedyupdates. Thesegreedyupdatescanyieldremarkablygoodresults,in
particularforlongpools,suchthatthelastvalueisalreadywellconstrainedbyanumberofdata
pointsandhardlyaffectedbythenextpool. Nonetheless,insomecasesthesegreedyupdatesleadto
errorsinthetimingofinferredactivity,inparticularwhentherisetimeofthecalciumresponseis
slowcomparedtotheframerate. Themethoddescribedinthissectioncanbeusedtocorrectthese
smallerrors. Itisagainanactivesetmethodthatcanberuninonlinemode;however,themethod
introducedaboveisadualactivesetmethod,whereasherewedescribeaprimalactivesetmethod.
Webeginbyreformulatingtheproblemas
minimize 1(cid:107)Ksˆ−y(cid:107)2+λ(cid:107)sˆ(cid:107) subjectto sˆ≥0 (31)
2 1
sˆ
12
Algorithm3Fastonlinedeconvolutionforarbitraryconvolutionkernels
Require: kernelh,regularizationparameterλ,windowsize∆,shiftsize∆ ,datasubsety ⊂yat
m t:t+∆−1
timeofreading
1: initializeK ←h for1≤u≤t≤∆,y←y−λK−(cid:62)1,A←K(cid:62)K,t←1
t,u 1+t−u
2: whilet+∆≤T do
3: sˆ ←NNLS(A,K(cid:62)y ,sˆ ) (cid:46)classicNNLSonsˆ ,butwarm-started†
t:t+∆−1 t:t+∆−1 t:t+∆−1 t:t+∆−1
4: y ←y −K sˆ (cid:46)peeloffcontributionofpreviousactivity
t:t+∆−1 t:t+∆−1 :,1:∆m t:t+∆m−1
5: t←t+∆
m
6: sˆ ←NNLS(A ,K(cid:62) y ,sˆ ) (cid:46)robustnessto T−∆ ∈/ N
t:T t+∆−T:∆,t+∆−T:∆ 1:T−t+1,1:T−t+1 t:T t:T ∆m
7: returnsˆ
†ThefunctionNNLSimplementsaminorvariationoftheclassicalgorithmof[37]tosolvemin (cid:107)y−Ksˆ(cid:107)2:
sˆ∈RT
+
K(cid:62)KandK(cid:62)yareprecomputedoutsidethefunction,toexploitthatNNLSiscalledseveraltimeswiththesame
K.Furthersˆiswarm-startedinsteadofinitializingitas0.
whereK =G−1istheconvolutionmatrixwithentriesK =h ift≥uelsezero;thekernel
t,u 1+t−u
vectorhcanbetakenasanarbitraryresponsekernelformostofthedevelopmentinthissection. As
notedearlier,h =(At) forthespecialcaseofanARprocess. Aswehaveseenpreviously,the
1+t 1,1
effectofthesparsitypenalty(togetherwiththenon-negativeconstraint)istoshiftthedatadownbya
vectorµ=λK−(cid:62)1,andtheproblemreducestoanon-negativeleastsquares(NNLS)problem.
minimize 1(cid:107)Ksˆ−(y−λK−(cid:62)1)(cid:107)2 subjectto sˆ≥0. (32)
2
sˆ
(NotethatthegradientofEq(32)isthesameasthegradientofEq(31),K(cid:62)(Ksˆ−(y−λK−(cid:62)1))=
K(cid:62)(Ksˆ−y)+λ1. Inaddition,K istriangularwithpositivenumbersonthemaindiagonal,hence
detK >0andK isinvertible.)
A classic algorithm for solving a NNLS problem is the active set method of [38] and [37]. This
algorithmalternatesbetweennormalequationmatrixsolvesinvolvingsub-matricesofK(cid:62)K and
updatesoftheactiveset. Anaiveapplicationofthisalgorithmwouldscalecubicallywiththenumber
ofspikes. Instead,weexploitthelocalityoftheproblem(thefactthatchangingaspikeheightat
timetdoesnotaffectthesolutionatverydistanttimess)andapplytheNNLSalgorithmintheinner
loopofasequentialcoordinateblockdescentmethod. Specifically,weapplywarm-startedNNLS
onblocksofsize∆(where∆isthelengthofthecalciumtransient),steppingtheblockinstepsof
size∆ <∆(wefound∆ = ∆ tobeeffectiveforofflineapplications;foronlineapplications∆
m m 2 m
wouldbesetsmaller)andapplyingNNLSwhileholdingthevaluesofsoutsidetheblockfixed. We
furtherexploittheToeplitzstructureofK toprecomputethenecessarysub-matricesofK(cid:62)K.
Theresultingalgorithm(Alg3)runsinO(T)time. Itinvolvessolvingaleastsquaresproblemforthe
timepointswithintheconsideredwindowwheresˆ >0;thusitscalescubicallywiththenumberof
t
spikesperwindowanddependsonthesparsityofsˆ. (Infact,forAR(p)models,therequiredmatrix
solvescanbeperformedusinglinear-time(notcubic-time)Kalmanfilter-smoothermethods,butthe
matrixsizesweresufficientlysmallintheexamplesexaminedherethattheKalmanimplementation
wasnotnecessary.) Furtherspeedupscanbeobtainedbyrestrictingthesetofpossiblespiketimes,
forexample,byrunningtheAR(1)versionofOASISonatemporallydecimatedversionofthesignal
tocrudelyidentifythesetofspiketimes,thenneverupdatingsˆawayfromzeroonthecomplement
ofthisset.
Tosummarize,wedescribeinAlgorithm4howthealgorithmicvariantsintroducedherearecombined
intoafinalfullalgorithmthatincludeshyperparameteroptimization,thevariantsforAR(1)orAR(2),
andsoft((cid:96) penalty)orhardshrinkage((cid:96) penalty).
1 0
3 Results
3.1 BenchmarkingOASIS
Wegenerateddatasetsof20fluorescencetraceseachforp = 1and2withadurationof100sat
aframerateof30Hz,suchthatT = 3,000frames. Thespikingsignalcamefromahomogeneous
Poissonprocess. Weusedγ = 0.95, σ = 0.3fortheAR(1)modelandγ = 1.7, γ = −0.712,
1 2
σ =1fortheAR(2)model. Figures4A-Carereassuringthatoursuggested(dual)activesetmethod
13
Algorithm4Fullalgorithmwithhyperparameteroptimization
Require: datay,orderpoftheAR-process,sparsitynormq
1: initialize
2: ARparametersγˆ ,...,γˆ usingautocorrelationofy
1 p
3: noiselevelσˆusingPSDofy
4: backgroundˆbusingpercentileofy
5: dualvariableλ←0
6: y˜←temporallydecimatebatchofy (cid:46)forfasterhyperparameteroptimization
7: rescalehyperparamatersduetodecimation
8: whilehyperparamatersnotconvergeddo (cid:46)optimizehyperparameters,cf.Fig3
9: Runwarm-startedAlg2ony˜withcurrenthyperparameters
10: Updatehyperparameters (cid:46)Eqs(19,23,24)
11: ifq=0thendetermines (cid:46)Sec.‘Hardshrinkageand(cid:96) penalty’
min 0
12: rescalehyperparamatersusingtheinversetransformationsofline7
13: cˆ,sˆ←runAlg2onfulldatay
14: ifp=1then
15: returnsˆ
16: else
17: sˆ←runwarm-startedAlg3onfulldatay
18: returnsˆ
yields indeed the same results as other convex solvers for an AR(1) process and that spikes are
extractedwell. ForanAR(2)processOASISisgreedyandyieldsgoodresultsthataresimilartothe
oneobtainedwithconvexsolvers(lowerpanelsinFig4BandC),withvirtuallyidenticaldenoised
fluorescencetraces(upperpanels).
Figures4D,Ereportthecomputationtime(±SEM)averagedoverall20tracesandtenrunspertrace
onaMacBookProwithIntelCorei52.7GHzCPU.Wecomparedtheruntimeofouralgorithm
toavarietyofstateoftheartconvexsolversthatcanallbeconvenientlycalledfromtheconvex
optimizationtoolboxCVXPY[39]: embeddedconicsolver(ECOS,[40]),MOSEK[41],splitting
conicsolver(SCS,[42])andGUROBI[43]. ECOSandMOSEKarethemostcompetitivemethods;
theseareinterior-pointmethodsthatcannotusewarmstarts. Withaknownsparsityparameterλ
(Eq3),OASISisabouttwomagnitudesfasterthananyothermethodforanAR(1)process(Fig4D,
bluedisks)andmorethanonemagnitudeforanAR(2)process(Fig4E).Whereasseveralofthe
othersolverstakealmostthesametimeforthenoiseconstrainedproblem(Eq15,Fig4D,E,green
x),ourmethodtakesaboutthreetimeslongertofindthevalueofthedualvariableλcomparedto
theformulationwheretheresidualispartoftheobjective;neverthelessitstilloutperformstheother
algorithmsbyahugemargin.
WealsoranthealgorithmsonlongertracesuptoalengthofT =300,000frames(Fig4F),confirming
thatOASISscaleslinearlywithT,whereweobtainedaproportionalityconstantof1µs/frame. For
anunknownhyperparameterλweobtaineditsvaluenotonlyonthefulldatabutonaninitialsmall
batch(1,000frames)andkeptitfixed,whichspedactivityinferenceupbyafactorofthreeonceT
issufficientlylarge(Fig4F,orangevsgreen)withoutcompromisingquality(correlationbetween
deconvolvedactivityandgroundtruthspiketrain0.882±0.001vs0.881±0.002forT =300,000).
Ouractivesetmethodmaintaineditsleadby1-2ordersofmagnitudeincomputingtime. Further,
comparedtoouractivesetmethodtheotheralgorithmsrequiredatleastanorderofmagnitudemore
RAM,confirmingthatOASISisnotonlyfasterbutmuchmorememoryefficient. Indeed,because
OASIScanruninonlinemodethememoryfootprintcanbeO(1),insteadofO(T).
Weverifiedtheseresultsonrealdataaswell. RunningOASISwiththehardnoiseconstraintand
p=2ontheGCaMP6sdatasetof14,400framescollectedat60Hzfrom [36,44]took0.101±0.005s
pertrace,whereasthefastestothermethodsrequired2.37±0.12s. Fig4Cshowstherealdatatogether
withtheinferreddenoisedanddeconvolvedtracesaswellasthetruespiketimes,whichwereobtained
bysimultaneouselectrophysiologicalrecordings[36].
Wealsoextractedeachneuron’sfluorescenceactivityusingCNMFfromanunpublishedwhole-brain
zebrafishimagingdatasetfromtheM.Ahrenslab. RunningOASISwithhardnoiseconstraintand
p=1(chosenbecausethecalciumonsetwasfastcomparedtotheacquisitionrateof2Hz)on10,000
tracesoutofatotalof91,478suspectedneuronstook81.5swhereasECOS,thefastestcompetitor,
14
2
0
.roulF
OASIS CVXPY Truth Data
1
0
0 25 50
ytivitcA
A
5
0
.roulF
1
0
0 30
Time[s]
ytivitcA
B C
0 30
Time[s]
1.0
0.5
0
OASIS ECOSMOSEK SCS GUROBI
Solver
]s[emiT
D
1
2
0.1
0.01
O. E. M. S. G. 1
0
OASIS ECOSMOSEK SCS GUROBI
Solver
]s[emiT
E
1 4
0.1
3
0.01
O. E. M. S. G. 2
1
0
102 103 104 105
Numberofframes
]sµ[emarfrepemiT
F
λgiven
λfittedonfulldata
λfittedonsmallbatch
Figure4: OASISproducesthesamehighqualityresultsasconvexsolversatleastanorderof
magnitudefaster. (A)RawandinferredtracesforsimulatedAR(1)data,(B)simulatedAR(2)and
(C)realdatafrom[36]fittedwithanAR(2)model. OASISsolvesEq(3)exactlyforAR(1)and
justapproximatelyforAR(2)processes,neverthelesswellextractingspikes. (D)Computationtime
forsimulatedAR(1)datawithgivenλ(bluecircles,Eq3)orinferencewithhardnoiseconstraint
(greenx,Eq15). GUROBIfailedonthenoiseconstrainedproblem. Theinsetshowsthesamedata
inlogarithmicscale. (E)ComputationtimeforsimulatedAR(2)data. (F)Normalizedcomputation
timeofOASISforsimulatedAR(1)datawithgivenλ(bluecircles,Eq3)andinferencewithhard
noiseconstraintonfulldata(greenx,Eq15)orsmallinitialbatchfollowedbyprocessinginonline
mode(orangecrosses).
needed2,818.1s. Forallneuronswewouldhenceexpect745sforOASIS,whichisbelowthe1,500s
recordingduration(3,000frames),andover25,780sforECOSandothercandidates.
OASISsolvesthenon-negativedeconvolutionproblemexactlyforanAR(1)process;however,as
discussedabove,forp>1thesolutionisonlyagood(greedy)approximation. Toobtaintheexact
solutionwerantheONNLSalgorithmonthesimulatedAR(2)tracesusingawindowsizeof200
frames,whichwasabouttentimeslargerthanthefluorescencedecaytime,andshiftingthewindow
by 100 frames. We obtained higher accuracy results than all the state of the art convex solvers
wecomparedto,requiringmerely27.8±0.4mspertraceforλ = 0and20.0±0.4mspertracefor
λ=30,thevaluethatensuresthatthehardnoiseconstraintistight. Thechoiceofλregulatedthe
sparsityofthesolution,whichaffectstheruntimeofONNLS.Thefasteststateoftheartconvex
solver (ECOS) required 305±9ms and was thus an order of magnitude slower. It took merely
8.56±0.04mstoobtainanapproximategreedysolutionusingOASIS,independentofthechoice
ofsparsityparameterλ. Thoughobtainingtheexactsolutionrequiresmorecomputingtime,itis
wellwithinthesameorderofmagnitude. Incontrast,runningbatchNNLSwassignificantlyslower,
requiring 2,430±53ms for λ = 0 and 1,620±37ms for λ = 30. Solving the noise constrained
15
problembyiteratingwarm-startedONNLStoobtainthecorrespondingvalueofthedualvariableλ
took73±1ms. However,wecanimproveonthatbyfirstrunningthefastbut(forp>1)approximate
dualmethodtoobtainagoodestimateofλaswellass,andthenswitchingtotheslowerbutexact
primalmethod. RunningOASISandexecutingwarm-startedONNLSjustoncerequiredcollectively
merely23±1ms,similarlytocold-startedONNLSwithgivenλ. RunningONNLSnotjustonce,but
untilthevalueofλhasbeenfurthertunedsuchthatthenoiseconstraintholdsnotapproximatelybut
exactly,tookaltogether31±1ms.
3.2 Hyperparameteroptimization
WehaveshownthatwecansolveEq(3)andEq(15)fasterthaninteriorpointmethods. TheAR
coeffientγ waseitherknownorestimatedbasedontheautocorrelationintheaboveanalyses. The
latterapproachassumesthatthespikingsignalcomesfromahomogeneousPoissonprocess,which
doesnotgenerallyholdforrealisticdata. Thereforewewereinterestedinoptimizingnotonlythe
sparsity parameter λ, but also the AR(1) coeffient γ. To illustrate the optimization of both, we
generatedafluorescencetracewithspikingsignalfromaninhomogeneousPoissonprocesswith
sinusoidalinstantaneousfiringrate(Fig3). Weconservativelyinitializedγˆtoasmallvalueof0.9.
Thevalueobtainedbasedontheautocorrelationwas0.9792andlargerthanthetruevalueof0.95.
TheleftpanelsinFigures3BandDillustratetheupdateofλfromthepreviousvalueλ− toλ∗ by
solvingaquadraticequationanalytically(Eq18)andtheupdateofγˆbynumericalminimizationof
ahighorderpolynomialrespectively. Notethataftermerelyoneiteration(Fig3E)agoodsolution
isobtainedandafterthreeiterationsthesolutionisvirtuallyidenticaltotheoneobtainedwhenthe
truevalueofγ hasbeenprovided(Fig3F).Thisholdsnotonlyvisually,butalsowhenjudgedbythe
correlationbetweendeconvolvedactivityandgroundtruthspiketrain,whichwas0.869compared
tomerely0.773ifγˆwasobtainedbasedontheautocorrelation. Theoptimizationwasrobusttothe
initialvalueofγˆ,aslongasitwaspositiveandnot,oronlymarginally,greaterthanthetruevalue.
Thevalueobtainedbasedontheautocorrelationwasconsiderablygreaterandpartitionedthetime
seriesintopoolsinawaythatmissedentirespikes.
Afterillustratingthehyperparameteroptimizationwenextquantifythecomputingtimeandquality
of spike inference for various optimization scenarios. We generated 20 fluorescence traces with
sinusoidalinstantaneousfiringrateasusedintheillustration(Fig3),againhavingadurationof100s
ataframerateof30Hz,suchthatT = 3,000frames,howeverweoffsetthedatabyanadditional
positivebaselinebthatcanbepresentinrealdata. Thisbaselinecanbeoptimizedtogetherwith
the sparsity parameter λ, as shown in Methods (subsection “Additional baseline"). The fastest
deconvolutionmethodistomerelyestimateallparametersandrunOASISjustonce,cf.firstrowin
Table1whichshowsthemean(±SEM)forcomputingtimeaswellascorrelationoftheinferred
spiketrain. Asabaselineestimateweusedthe15%percentileofthefluorescencetrace. Thesparsity
penaltywassettoλ = 0. Abetterchoiceofλisactuallyobtainedbyoptimizingit,suchthatthe
hardnoiseconstraint(cid:107)b1+cˆ−y(cid:107)2 =σˆ2T holds,cf.secondrowinTable1. Thenextrowsshow
Table1: Costandqualityofspikeinferencewithparameteroptimization.
optimize accelerate Time[ms] Correlation
- - 3.25±0.03 0.831±0.006
λ - 9.2 ±0.1 0.849±0.006
λ,b - 8.4 ±0.2 0.857±0.007
λ,b,γ - 48.4 ±2.3 0.875±0.006
λ,b,γ use10pools 16.0 ±0.4 0.875±0.006
λ,b,γ use 5pools 14.2 ±0.3 0.875±0.006
λ,b,γ decimate 29.4 ±1.3 0.878±0.006
λ,b,γ decimate,use10pools 12.1 ±0.2 0.878±0.006
λ,b,γ decimate,use 5pools 10.6 ±0.2 0.877±0.006
Thefirstcolumnshowsthequantitiesthathavebeenoptimized,thesecondmethodsusedtoaccelerate
theparameteroptimization,thethirdthecomputingtimepertrace(±SEM)andthelastshowsthe
performanceofspiketraininferenceusingthecorrelationbetweeninferredactivityandtruespike
train. Weused20simulatedfluorescencetraceswithaspikingsignalcomingfromaninhomogeneous
Poissonprocessandadurationof100sataframerateof30HzsuchthatT =3,000frames.
16
2
0
.roulF
L1 Thresh. Truth Data
L1
Thresh.
Truth
1.0
0.5
0
0 5 10
Time[s]
s
nim
A 5
0
B
C
.roulF
L1
Thresh.
Truth
1.0
0.5
0
0 5 10
Time[s]
s
nim
D
E
F
Figure5: Thresholdingcanimprovetheaccuracyofspikeinference. (A)InferredtraceusingL1
penalty(L1,blue)andthethresholdedOASIS(Thresh.,green). Thedata(gray)aresimulatedwith
AR(1)model. (B)Inferredspikingactivity. (C)ThedetectedeventsusingthresholdedOASISdepend
ontheselectionofs . Thegroundtruthisshowninred. (D,E,F),sameas(A,B,C),butthedata
min
aresimulatedwithAR(2).
thatoptimizingbfurtherimprovestheresult,asdoesaddingγ. However,theincreasednumberof
optimizedparametersresultsinextracomputationalcost. Thecomputationtimecanbereducedby
estimatingγ notusingthefulldatabutonlyalimitednumberofpools,whichdoesnotaffectthe
qualityoftheresult,cf.rowfiveandsixinTable1. Notethatbyrestrictingtheoptimizationtoa
fixednumberofpools,itscomputationalloaddoesnotincreasewiththedurationoftherecording,
hencethegainwouldbeevenmoredramaticforlongertimeseries. Furtherspeedupsareobtained
byestimatingtheparametersonadecimatedversionofthedata,asthelastrowsinTable1illustrate.
Herewedecimatedthefluorescencetracesbyafactoroften,withoutharmingtheinferencequality.
3.3 Hardthresholding
OASISsolvesaLASSOproblemresultinginsoftshrinkage. Thedeconvolvedtracesˆtypicallyhas
valuessmallerthan1andoftenshows“partialspikes”inneighboringbinsreflectingtheuncertainty
regardingtheexactpositionofaspike,cf.Fig4. Whilethisinformationcanbeuseful,onesometimes
wantstomerelycommittooneeventwithinatimebininsteadandgetridofremainingsmallvalues
in sˆ. We ran a slightly modified version of the algorithm that replaces the sparsity penalty by a
constraint on the minimal spike size s , yielding sparser solutions but rendering the problem
min
non-convex. Althoughwearenotguaranteedtofindtheglobalminimum,weobtainedgoodresults,
cf. Fig 5. To quantify directly the similarity between the inferred deconvolved trace and ground
truthspiketrainwecalculatedthecorrelationbetweenthetwo. Thebestresultswereobtainedfor
s =0.5yieldingcorrelation0.899±0.009withthetruespiketraincomparedto0.879±0.006
min
forthesolutionoftheproblemwithhardnoiseconstraint(Eq15). However,inapracticalapplication
thescalingfactorbetweencalciumfluorescenceandasinglespike,whichis1foroursimulateddata,
isoftenunknown,renderingitimpossibletosimplysetthethresholds tothehalfofit. Instead,
min
wecanvarythethresholduntiltheRSScrossesthethresholdσ2T. Theorderinwhichthepoolsare
mergedorsplitmattersforthisnon-convexcaseandsequentiallyaddingspikesatthehighestvalues
ofthe(cid:96) -solutionyieldedthebestperformancewithcorrelation0.888±0.007.
1
Fig5alsoshowsresultswithaconstraintontheminimalspikesizeforanAR(2)process. Addingthe
constrainthelpswhenpressedforabinarydecisionwhethertoassignaspikeornot,yieldingvisually
excellent results. However, with a finite rise time of the calcium response the onset detection is
notoriouslydifficult,becauseforalowthresholdtherearealotoffalsepositivesduetonoise,whereas
forahighthreshold,closertothepeakofthecalciumkernel,theonsethasalreadyoccurredearlier.
Indeed,thegreedymethodforanAR(2)processtendstoregisterspikestoolate,whichisfurther
exacerbatedwhenathresholdonthespikesize(s = 0.5)isintroduced,leadingtolowvalues
min
17
ofspikesimilarity(correlation0.419±0.016)comparedtothesolutionofbasispursuitdenoising
(Eq15)(correlation0.497±0.013). Wecanincorporateacorrectionstepthatwheneveranewspike
is added, slightly jitters the previous one and calculates the change in the optimization objective
in order to determine the optimal placement of the spike. For simplicity and low computational
burden,werestricttheconsiderationofthechangingRSStothepoolspriorandafterthejitteredspike,
whichimprovesthespikedetection(correlation0.462±0.015)whileonlymarginallyincreasing
computationalcost(from8.65msto11.65ms). Furtherimprovementscanbeobtainedbyfollowing
upwith(O)NNLS.ThesolutionobtainedbyOASISwiththresholdontheminimalspikesizeand
jittering can be used to restrict (O)NNLS to have non-zero values only in close proximity to the
spikesofthegreedilyobtainedsolution. Thisprocessingstepincreasedtheperformanceofspike
inferencetocorrelation0.530±0.010,whichisbetterthanthealreadymentionedoneobtainedfor
exactlysolvingtheconvexproblem(Eq15). Hence,thoughimposingaminimalspikesizerenders
theproblemnon-convex,atractableapproximatesolutiontothisproblemcanimproveovertheexact
solutionoftheconvexbasispursuitdenoisingproblem.
IntheAR(2)casetheexactsolutions(ONNLSwithλorONNLSwithsupportonlyintheproximity
of the thresholded solution) consistently improved over the faster greedy methods, as measured
byspiketraincorrelation. Theperformancewashardlyaffectedbywhetherthepenalizedorthe
thresholdedversionwaschosen. Spiketraincorrelationharshlypenalizesspikesthataredetected
but at an incorrect time, no matter how close; therefore the activity plots and correlation values
conveysomewhatcomplementaryinformationaboutthequalityoftheinference. Weattributethe
performancegapbetweengreedyandexactsolutionstogreedymethodsmissingtheexacttimestep
moreoften. However, theoptimallyattainabletimeresolutionisalreadylimitedbylowSNR,in
particulariftherisetimeofthecalciumindicatorisfinite. Indeed,beingmorelenientregardingthe
exactspiketimingwecalculatedthecorrelationsafterconvolvingthespiketrainswithaGaussian
withstandarddeviationofonebinwidth. Thecorrelationvaluesincreasedto0.731±0.008forthe
greedythresholdedsolutionandto0.800±0.007iffollowedupbyONNLS,butdidnotincrease
furtherforwiderGaussiankernels. ThisindicatesthatintheconsideredSNRregimesingletimebin
resolutionisoutofreach,butspiketimescanbeinferredwithanuncertaintyofaboutonetimebin
width.
3.4 Onlinespikeinferencewithlimitedlag
Foranexactsolutionofthenon-negativedeconvolutionproblemofanAR(1)processOASISneeds
to backtrack to the most recent spike. (For an AR(2) process the solution is greedy and merely
approximate. ONNLSyieldsanexactsolutioninthiscasebutconsidersanevenwidertimewindow.)
Such delays could be too long for some interesting closed loop experiments; therefore we were
interestedinhowwellthemethodperformsifbacktrackingislimitedtojustafewframes. Wevaried
thelagintheonlineestimator,i.e.thenumberoffuturesamplesobservedbeforeassigningaspikeat
timezero,fordifferentsignal-to-noiseratios(SNR).Foreachlagwechosethesparsityparameter
λ such that the noise constraint (cid:107)cˆ−y(cid:107)2 ≤ σ2T was tight. This yielded increasing values of λ
forsmallerlags,compensatingforthefactthatlimitingbacktrackingtofewerframesalsoimposes
fewer constraints (cˆ ≥ γcˆ ) on the dynamics. In the case of hard thresholding, better results
t t−1
wereobtainedwithhighers forsmallerlagstoo,inordertoavoidthatonespikeissplitintwo.
min
We used a hand-chosen value of s = 0.5+0.175e−τ where τ is the lag, that asymptotically
min
approachesthe0.5forbatchprocessing. TheobtainedresultsaredepictedinFig6. ForrealisticSNR
(3-5,though[36]reportevenhighervalues,cf.Fig4C)andsamplerates(30Hz),lagsof2-5yielded
virtuallythesameresultsasofflineestimation. Theexactnumberdependsonthenoise;however,the
maineffectofnoisewastoreducetheoptimalperformanceattainableevenwithbatchprocessing,as
theasymptoticvaluesinFig6AandBreveal.
4 Conclusion
Wepresentedanonlineactivesetmethodforspikeinferencefromcalciumimagingdata. Weassumed
thattheforwardmodeltogenerateafluorescencetracefromaspiketrainislinear-Gaussian. Further
developmentwillextendthemethodtononlinearmodels[45]incorporatingsaturationeffectsanda
noisevariancethatincreaseswiththemeanfluorescencetobetterresemblethePoissonianstatistics
ofphotoncounts. IntheAppendix(sectionS.2)wealreadyextendourmathematicalformulationto
includeweightsforeachtimepointasafirststepinthisdirection.
18
1.0
0.8
0.6
0 5 10
Lag[frames]
noitalerroC
A
Noise
Correlationwith 0.1
-horizonsolution 0.2
 groundtruth 0.3
1.0
0.8
0.6
0 5 10
Lag[frames]
noitalerroC
B
Noise
Correlationwith 0.1 1
-horizonsolution 0.2
 groundtruth 0.3
0
0 25 50
Time[s]
ytivitcaderrefnI
C Lag 0 1 2 5 10 20
Figure6: Variedlagintheonlineestimator. (A,B)Performanceofspikeinferenceasfunctionof
lagforvariousnoiselevels(i.e.,inverseSNR)without(A)andwithpositivethresholds (B).We
min
usedcorrelationoftheinferredspiketrainassimilaritymeasureandcomparedtogroundtruthas
wellastotheoptimallyrecoverableactivitywhenthelagisunlimitedasinofflineprocessing. (C)
Inferredtracewithpositivethresholds forincreasinglagusingthedatadepictedinFig4Awith
min
highnoiselevel(σ =0.3). Thegraylinesindicatethetruespiketimes.
Ourmethodconsideredspikeinferenceasasparsenon-negativedeconvolutionproblem. Wefocused
on the formulation that imposes sparsity using an (cid:96) penalty that renders the problem convex.
1
Using this problem formulation for spike inference has already long standing success within the
neuroscientific community. We were able to speed it up by an order of magnitude compared to
previously employed interior point methods and derived an algorithm that lends itself to online
applications. However,recentlyseveralinvestigators[46,47,48]haveadvocatedsparsermethods,
e.g.byusingan(cid:96) -normwithq <1insteadofq =1[46]orbyenforcingrefractoriness[47](see
q
also[13]forsomefurtherdiscussionofsparseningbeyond(cid:96) penalization). Theyreportimproved
1
results,howeverinsomecasesattheexpenseofnon-convexity,thuslosingtheguaranteeoffinding
the global optimum. We leave it to future work to incorporate refractoriness into the methods
developedhere,butwedidslightlymodifythesparsenon-negativedeconvolutionproblembyadding
theconstraintthatpositivespikesneedtobelargerthansomeminimalvalue. Aminormodification
to our algorithm enabled it to find an (approximate) solution of this non-convex problem, which
canbemarginallybetterthanthesolutionobtainedwith(cid:96) regularizer. The(cid:96) -penalizedsolution
1 1
reflectstheuncertaintyregardingtheexactpositionofaspikebydistributingitas“partialspikes”
overneighboringbins. Thethresholdedsolutionletsgoofthispotentiallyusefulinformationand
insteadcommitstooneeventwithinthelocallyoptimaltimebin. Weleaveituptotheuserwhich
approachtochoose.
CodeAvailability
WeprovidePythonandMATLABimplementationsofouralgorithmonline(https://github.com/j-
friedrich/OASISandlinkedrepositoriestherein). Thecodeisreadilyusableonnewdataandincludes
examplescriptsthatproduceallfiguresandTable1ofthisarticle.
Herewefocusedontemporaldata,i.e.noisyneuralfluorescencedatathathasbeenextractedand
demixed fromrawpixeldata. WefurtheraddedOASISasdeconvolutionsubroutinetoCaImAn
(https://github.com/simonsfoundation/CaImAn)[49],whichimplementsCNMFforsimultaneous
denoising,deconvolution,anddemixingofspatio-temporalcalciumimagingdata.
Acknowledgments
WewouldliketothankMishaAhrensandYuMuforprovidingwhole-brainimagingdataoflarval
zebrafish. WethankJohnCunninghamandEftychiosPnevmatikakisforhelpfulconversationsaswell
asScottLindermanandDanielSoudryforvaluablecommentsonthemanuscript.
19
PartofthisworkwaspreviouslypresentedattheThirtiethAnnualConferenceonNeuralInformation
ProcessingSystems(NIPS,2016)[50].
Funding for this research was provided by Swiss National Science Foundation Research Award
P300P2_158428(JF),NIH2R01MH064537andR90DA023426(PZ),SimonsFoundationGlobal
BrainResearchAwards325171and365002(JF,LP),AROMURIW911NF-12-1-0594,NIHBRAIN
InitiativeR01EB22913andR21EY027592,DARPAN66001-15-C-4032(SIMPLEX),andaGoogle
FacultyResearchaward(LP);inaddition,thisworkwassupportedbytheIntelligenceAdvanced
ResearchProjectsActivity(IARPA)viaDepartmentofInterior/InteriorBusinessCenter(DoI/IBC)
contractnumberD16PC00003,D16PC00008(LP),andD16PC00007(PZ).Thefundershadnorole
instudydesign,datacollectionandanalysis,decisiontopublish,orpreparationofthemanuscript.
TheU.S.GovernmentisauthorizedtoreproduceanddistributereprintsforGovernmentalpurposes
notwithstandinganycopyrightannotationthereon. Disclaimer: Theviewsandconclusionscontained
hereinarethoseoftheauthorsandshouldnotbeinterpretedasnecessarilyrepresentingtheofficial
policiesorendorsements,eitherexpressedorimplied,ofIARPA,DoI/IBC,ortheU.S.Government.
SupplementaryMaterial
S.1 Algorithmforisotonicregressionwithoutpooling
ForeaseofexpositionAlgS1showsthepseudocodeoftheisotonicregressionalgorithmusedto
conveythecoreidea. However,thisnaïveimplementationlackspooling,renderingitinefficient. It
repeatedlyupdatesallvaluesx ,...,x duringbacktrackingandcalculatestheupdatedvalueusing
t(cid:48) τ
Eq(7)withoutexploitingthatpartofthesuminthenumeratorhasalreadybeencomputedasan
earlierresult. ItisthusmerelyO(T2),whereasintroducingpoolsaddressesbothissuesandyieldsan
O(T)algorithm.
AlgorithmS1Isotonicregressionalgorithmwithoutpools(inefficientO(T2))
Require: datay
1: initializex←y
2: forτ in2,...,T do (cid:46)moveforwarduntilend
3: t(cid:48) ←τ
4: whilet(cid:48) >1andx t(cid:48) <x t(cid:48)−1 do (cid:46)trackback
5: t(cid:48) ←t(cid:48)−1
6: foriint(cid:48),...,τ dox ← (cid:80)τ t=t(cid:48)yt (cid:46)Eq(7)
i τ−t(cid:48)+1
7: returnx
S.2 Weightedregression
Forsakeofgeneralityweconsiderthecaseofweightedregressionwithweightsθ.
1(cid:88) (cid:88)
minimize θ (cˆ −y )2+λ sˆ subjectto sˆ=Gcˆ≥0 (S1)
cˆ,sˆ 2 t t t t
t t
Thisgeneralizationisnotonlyoftheoreticalinterest. Theseweightscouldbeusedtogivelower
weighttotimepointswithhighervarianceforheteroscedasticdata,forexampleforthePoissonian
statisticsofphotoncountswherethevarianceofthefluorescenceincreaseswithitsmean. Further,
insteadofthelinearrelationshipbetweenfluorescenceandcalciumconcentration(Eq2)wecould
haveanonlinearobservationmodel
y =f(c )+(cid:15) (S2)
t t t
where the nonlinear function f can include saturation effects. This is often taken to be the Hill
equation,i.e.,f(c)= acn +b,withHillcoefficientn,dissociationconstantk ,scalingfactora
cn+kd d
andbaselineb[45]. ApplyingNewton’salgorithmtooptimizeforsˆ(orequivalentlycˆ)resultsfor
eachNewtonstepinaweightedconstrainedregressionproblemasinEq(S1),whichcanbesolved
efficientlywithOASIS.Hence,incorporatingOASISintoNewton’salgorithmenablesthealgorithm
tohandlenonlinearandnon-Gaussianmeasurements.
20
ForanAR(1)processintroducingweightschangesEq(10)to
∆t ∆t
1(cid:88) (cid:88)
minimize θ (γtc(cid:48) −y )2+ µ γtc(cid:48) (S3)
c(cid:48) 2 t+t(cid:48) t(cid:48) t+t(cid:48) t+t(cid:48) t(cid:48)
t(cid:48) t=0 t=0
anditssolutionisamodificationofEq(11)byaddingtheweights
(cid:80)∆t (θ y −µ )γt
c(cid:48) = t=0 t+t(cid:48) t+t(cid:48) t+t(cid:48) (S4)
t(cid:48) (cid:80)∆t θ γ2t
t=0 t+t(cid:48)
Wemerelyneedtoinitializeeachpoolas(v ,w ,t ,l )=(y − µt,θ ,t,1)foreachtimesteptand
t t t t t θt t
theupdatesaccordingtoEqs(12-14)guaranteethatEq(S4)holdsforallvaluesv =c(cid:48) asweprove
i ti
inthenextsection.
ForanAR(p)processintroducingweightschangesEq(30)to
(cid:80)∆t (cid:0) θ (cid:0) y − (cid:80)p (At) c(cid:48) (cid:1) −µ (cid:1) (At)
c(cid:48) = t=0 t+t(cid:48) t+t(cid:48) k=2 1,k t(cid:48)+1−k t+t(cid:48) 1,1 (S5)
t(cid:48) (cid:80)∆t θ (At)2
t=0 t+t(cid:48) 1,1
andthesamemodifiedinitializationholds.
S.3 Validityofupdatesaccordingtoequations(12-14)
Theorem1. TheupdatesaccordingtoEqs(12-14)guaranteethatEqs(11,S4)holdforallvalues
v =c(cid:48) .
i ti
Proof. Weproceedbyinduction.
Assumption: LetforthedenominatorandnumeratorofEq(S4)hold
l (cid:88)i−1
w = θ γ2t (S6)
i t+ti
t=0
and
l (cid:88)i−1
w v = (θ y −µ )γt (S7)
i i t+ti t+ti t+ti
t=0
Basecase: Poolsareinitializedas(v ,w ,t ,l )=(y − µt,θ ,t,1)foreachtimesteptsuchthat
t t t t t θt t
Eqs(S6,S7)hold.
Inductionstep: Considertwopools(v ,w ,t ,l )and(v ,w ,t ,l )thatsatisfyEqs(S6,
i i i i i+1 i+1 i+1 i+1
S7)andaremergedtopool(v(cid:48),w(cid:48),t(cid:48),l(cid:48))accordingtoEqs(12-14).
i i i i
l (cid:88)i−1 li(cid:88)+1−1
w(cid:48) =w +γ2liw = θ γ2t+ θ γ2liγ2t
i i i+1 t+ti t+ti+1
t=0 t=0
li+
(cid:88)
li+1−1 l
(cid:88)i
(cid:48)−1
= θ γ2t = θ γ2t
t+ti t+t(cid:48)
i
t=0 t=0
whereweusedthecontingencyofthepools,t =t +l . ThusaftertheupdateEq(S6)holdsfor
i+1 i i
themergedpooltoo. Itremainstoshowthisalsoforthevalues:
w(cid:48)v(cid:48) =w v +γliw v
i i i i i+1 i+1
=
l (cid:88)i−1
(θ y −µ )γt+
li(cid:88)+1−1
(cid:0) θ y −µ (cid:1) γliγt
t+ti t+ti t+ti t+ti+1 t+ti+1 t+ti+1
t=0 t=0
=
li+
(cid:88)
li+1−1
(θ y −µ )γt =
l
(cid:88)i
(cid:48)−1
(cid:0) θ y −µ (cid:1) γt
t+ti t+ti t+ti t+t(cid:48)
i
t+t(cid:48)
i
t+t(cid:48)
i
t=0 t=0
21
S.4 Initialcalciumfluorescence
Thusfarwehavenotexplicitlytakenaccountofelevatedinitialcalciumfluorescencelevelsdueto
previousspikingactivity. Forthecasep=1positivefluorescencevaluesc captureinitialcalcium
1
fluorescencethatdecaysexponentially. Positivevaluesc leadvias = Gctoapositivespikes .
1 1
Insteadofattributingtheelevatedfluorescencetoaspikeattimet = 1,apositives morelikely
1
accountsforpreviousspikingactivity. Thereforeweremovetheinitialspikebysettings =0(Alg2,
1
line12).
Forp = 2wecanmodeltheeffectofpriorspikingactivityasanexponentialdecay,too. Because
thevalidityoftheconstraintc ≥
(cid:80)p
γ c canonlybeevaluatedift > p,forp > 1thefirst
t i=1 i t−i
poolstaysthusfarmerelyatitsinitialization(y −µ ,y −µ ,1,1),andthenoisyrawdatavalue
1 1 1 1
istakenastruec . Instead,wesuggesttousethefirstpooltomodeltheexponentialdecaydueto
1
previousspikingactivity. Givenc =v thefluorescencevaluesc fort=1,...,l arethengivenby
1 1 t 1
dt−1c withdecayvariable
1
(cid:113)
d= 1(γ + γ2+4γ ) (S8)
2 1 1 2
aswellknownintheAR/linearsystemsliterature[51]. Thefirstpoolismergedwiththesecondone
whenevertheconstraintv
2
≥dl1v
1
isviolated.
S.5 ExplicitexpressionsofthehyperparameterupdatesforAR(2)
We solve the noise constrained problem by increasing λ in the dual formulation until the noise
constraintistight. Westartwithsomesmallλ,e.g.λ=0,toobtainafirstpartitioningintopoolsP.
Wedenoteallexceptthedifferinglasttwocomponentsofµbyµ = λ(1−γ −γ )(Eq27)and
1 2
expressthecomponentsofµasµ =µκ with
t t

1 if t=T
1−γ1−γ2
κ = 1−γ1 if t=T −1 (S9)
t

1−γ1−γ2
1 else.
Givensomeµ(λ),thevalueofthefirstpoolusedtomodeltheinitialcalciumfluorescenceis(using
Eq11)
(cid:80)l1 (y −µκ )dt−1
cˆ = t=1 t t (S10)
1 (cid:80)l1−1d2t
t=0
withdecayfactorddefinedinEq(S8). Theothervaluesinthisfirstpoolareimplicitlydefinedby
cˆ =dcˆ for t=2,...,l . (S11)
t t−1 1
ThevaluesoftheotherpoolsareaccordingtoEq(30)
(cid:80)li−1(y −µκ −(At) cˆ )(At)
cˆ = t=0 ti+t ti+t 1,2 ti−1 1,1 (S12)
ti (cid:80)li−1(At)2
t=0 1,1
Theothervaluesinthepoolareimplicitlydefinedby
cˆ =γ cˆ +γ cˆ for t=1,...,l −1. (S13)
ti+t 1 ti+t−1 2 ti+t−2 i
Altogethertheseequationsdefinecˆ(µ)asfunctionofµ. Thesolutioncˆ(cid:48) =cˆ(µ(cid:48))foranupdatedvalue
µ(cid:48) =µ+∆µislinearin∆µ
cˆ(cid:48) =cˆ−∆µf (S14)
whichpluggedinaboveEqs(S10-S13)yieldsthatf canbeevaluatedusingthefollowingequations
byplugginginthenumericalvaluesofγ ,γ ,d,κ,Aand{l }
1 2 i
(cid:80)l1 κ dt−1
f = t=1 t (S15)
1 (cid:80)l1−1d2t
t=0
f =df for t=2,...,l (S16)
t t−1 1
(cid:80)li−1(κ −(At) f )(At)
f = t=0 ti+t 1,2 ti−1 1,1 for i=2,...,z (S17)
ti (cid:80)li−1(At)2
t=0 1,1
f =γ f +γ f for t=1,...,l −1 (S18)
ti+t 1 ti+t−1 2 ti+t−2 i
22
where z is the index of the last pool and because pools are updated independently we make the
approximationthatnochangesinthepoolstructureoccur. InsertingEq(S14)intothenoiseconstraint
(Eq15)anddenotingtheresidualasr =cˆ−yresultsin
(cid:107)cˆ(cid:48)−y(cid:107)2 =(cid:107)cˆ−∆µf −y(cid:107)2 =(cid:107)r−∆µf(cid:107)2 =(cid:107)f(cid:107)2∆µ2−2r(cid:62)f∆µ+(cid:107)r(cid:107)2 = ! σˆ2T (S19)
andsolvingthequadraticequationfor∆µyields
(cid:112)
r(cid:62)f + (r(cid:62)f)2−(cid:107)f(cid:107)2((cid:107)r(cid:107)2−σˆ2T)
∆µ= . (S20)
(cid:107)f(cid:107)2
Ifwejointlywanttooptimizethebaselinetoo,wedenoteagainthetotalshiftappliedtothedata
(exceptforthelasttwotimesteps)duetobaselineandsparsitypenaltyasφ=b+µ. Weincreaseφ
untilthenoiseconstraintistight. Theoptimalbaselineˆbminimizestheobjective(20)withrespectto
it,yieldingˆb=(cid:104)y−cˆ(cid:105)= 1 (cid:80)T (y −cˆ). Appropriatelyaddingˆbtothenoiseconstraintyields
T t=1 t t
(cid:107)ˆb(cid:48)1+cˆ(cid:48)−y(cid:107)2 =(cid:107)(cid:104)y−cˆ+∆φf(cid:105)1+cˆ−∆φf −y(cid:107)2 (S21)
=(cid:107)ˆb1+cˆ−y−∆φ(f −(cid:104)f(cid:105)1)(cid:107)2 = ! σˆ2T (S22)
(cid:124) (cid:123)(cid:122) (cid:125) (cid:124) (cid:123)(cid:122) (cid:125)
r f¯
where we used Eq (S14), the current value of the baseline ˆb = (cid:104)y −cˆ(cid:105) and the updated value
ˆb(cid:48) =(cid:104)y−cˆ+∆φf(cid:105). Solvingthequadraticequationfor∆φyields
(r(cid:62)f¯+ (cid:112) (r(cid:62)f¯)2−(cid:107)f¯(cid:107)2((cid:107)r(cid:107)2−σˆ2T)
∆φ= . (S23)
(cid:107)f¯(cid:107)2
S.6 Supplementaryvideos
VideoS1
ThesupplementaryvideoillustratesPAVA.Thepoolcurrentlyunderconsiderationisindicatedby
thebluecrosses. Thealgorithmsweepsthroughthetimeseriesandenforcestheorderconstraints
x ≤...≤x .
1 T
VideoS2
ThesupplementaryvideoillustratesOASISforanAR(1)process. AsinFigure2,redlinesdepict
truespiketimesandtheshadedbackgroundshowshowthetimepointsaregatheredinpools. The
poolcurrentlyunderconsiderationisindicatedbythebluecrosses. Theupperpanelshowshowthe
calciumfluorescencetracec(cid:48)developswhilethealgorithmruns,cf.Figure2. Thevideoadditionally
showsthedeconvolvedtraces(cid:48) =Gc(cid:48)(Eq.3)inthelowerpanel. Thealgorithmsweepsthroughthe
timeseriesandenforcestheconstraints(cid:48) ≥0.
References
[1] CGrienbergerandCKonnerth. Imagingcalciuminneurons. Neuron,73(5):862–885,2012.
[2] BFGrewe,DLanger,HKasper,BMKampa,andFHelmchen. High-speedinvivocalcium
imaging reveals neuronal network activity with near-millisecond precision. Nat Methods,
7(5):399–405,2010.
[3] EYaksiandRWFriedrich. Reconstructionoffiringratechangesacrossneuronalpopulations
bytemporallydeconvolvedCa2+imaging. NatMethods,3(5):377–383,2006.
[4] T F Holekamp, D Turaga, and T E Holy. Fast three-dimensional fluorescence imaging of
activityinneuralpopulationsbyobjective-coupledplanarilluminationmicroscopy. Neuron,
57(5):661–672,2008.
[5] J T Vogelstein, A M Packer, T A Machado, T Sippy, B Babadi, R Yuste, and L Paninski.
Fastnonnegativedeconvolutionforspiketraininferencefrompopulationcalciumimaging. J
Neurophysiol,104(6):3691–3704,2010.
23
[6] JTVogelstein,BOWatson,AMPacker,RYuste,BJedynak,andLPaninski. Spikeinference
fromcalciumimagingusingsequentialmontecarlomethods. BiophysJ,97(2):636–655,2009.
[7] EAPnevmatikakis,JMerel,APakman,andLPaninski. Bayesianspikeinferencefromcalcium
imagingdata. AsilomarConferenceonSignals,SystemsandComputers,2013.
[8] T Deneux, A Kaszas, G Szalay, G Katona, T Lakner, A Grinvald, B Rózsa, and I Vanzetta.
Accuratespikeestimationfromnoisycalciumsignalsforultrafastthree-dimensionalimaging
oflargeneuronalpopulationsinvivo. NatCommun,7,2016.
[9] T Sasaki, N Takahashi, N Matsuki, and Y Ikegaya. Fast and accurate detection of action
potentialsfromsomaticcalciumfluctuations. JNeurophysiol,100(3):1668–1676,2008.
[10] L Theis, P Berens, E Froudarakis, J Reimer, M R Rosón, T Baden, T Euler, A S Tolias,
andMBethge. Benchmarkingspikerateinferenceinpopulationcalciumimaging. Neuron,
90(3):471–482,2016.
[11] YMishchencko,JTVogelstein,andLPaninski. Abayesianapproachforinferringneuronal
connectivityfromcalciumfluorescentimagingdata. AnnApplStat,pages1229–1261,2011.
[12] MAPicardo,JMerel,KAKatlowitz,DVallentin,DEOkobi,SEBenezra,RCClary,EA
Pnevmatikakis, L Paninski, and M A Long. Population-level representation of a temporal
sequenceunderlyingsongproductioninthezebrafinch. Neuron,90(4):866–876,2016.
[13] E A Pnevmatikakis, D Soudry, Y Gao, T A Machado, J Merel, D Pfau, T Reardon, Y Mu,
CLacefield,WYang,MAhrens,RBruno,TMJessell,DSPeterka,RYuste,andLPaninski.
Simultaneous denoising, deconvolution, and demixing of calcium imaging data. Neuron,
89(2):285–299,2016.
[14] L Grosenick, J H Marshel, and K Deisseroth. Closed-loop and activity-guided optogenetic
control. Neuron,86(1):106–139,2015.
[15] JPRickgauer,KDeisseroth,andDWTank. Simultaneouscellular-resolutionopticalperturba-
tionandimagingofplacecellfiringfields. NatNeurosci,17(12):1816–1824,2014.
[16] AMPacker,LERussell,HWPDalgleish,andMHäusser. Simultaneousall-opticalmanip-
ulationandrecordingofneuralcircuitactivitywithcellularresolutioninvivo. NatMethods,
12(2):140–146,2015.
[17] KBClancy,ACKoralek,RMCosta,DEFeldman,andJMCarmena. Volitionalmodulation
ofopticallyrecordedcalciumsignalsduringneuroprostheticlearning. NatNeurosci,17(6):807–
809,2014.
[18] JLewi,RButera,andLPaninski. Sequentialoptimaldesignofneurophysiologyexperiments.
NeuralComput,21(3):619–687,2009.
[19] MParkandJWPillow. Bayesianactivelearningwithlocalizedpriorsforfastreceptivefield
characterization. InAdvNeuralInfProcessSyst,pages2348–2356,2012.
[20] BShababo,BPaige,APakman,andLPaninski. Bayesianinferenceandonlineexperimental
designformappingneuralmicrocircuits. InAdvNeuralInfProcessSyst,pages1304–1312,
2013.
[21] MBAhrens,MBOrger,DNRobson,JMLi,andPJKeller. Whole-brainfunctionalimaging
atcellularresolutionusinglight-sheetmicroscopy. NatMethods,10(5):413–420,2013.
[22] NVladimirov,YMu,TKawashima,DVBennett,C-TYang,LLLooger,PJKeller,JFreeman,
andMBAhrens. Light-sheetfunctionalimaginginfictivelybehavingzebrafish. NatMethods,
2014.
[23] FAPotraandSJWright. Interior-pointmethods. JComputApplMath,124(1):281–302,2000.
[24] M Ayer, H D Brunk, G M Ewing, W T Reid, and E Silverman. An empirical distribution
functionforsamplingwithincompleteinformation. AnnMathStat,26(4):641–647,1955.
[25] REBarlow,DJBartholomew,JMBremner,andHDBrunk. Statisticalinferenceunderorder
restrictions: Thetheoryandapplicationofisotonicregression. WileyNewYork,1972.
[26] CvanEeden. TestingandEstimatingOrderedParametersofProbabilityDistributions. PhD
thesis,UniversityofAmsterdam,1958.
[27] REMiles. Thecompleteamalgamationintoblocks,byweightedmeans,ofafinitesetofreal
numbers. Biometrika,46(3/4):317–327,1959.
24
[28] PMair,KHornik,andJdeLeeuw. IsotoneoptimizationinR:pool-adjacent-violatorsalgorithm
(PAVA)andactivesetmethods. JStatSoftw,32(5):1–24,2009.
[29] MJBestandNChakravarti.Activesetalgorithmsforisotonicregression;aunifyingframework.
MathProg,47(1-3):425–439,1990.
[30] SJGrotzingerandCWitzgall. Projectionsontoordersimplexes. ApplMathOptim,12(1):247–
270,1984.
[31] K Podgorski and K Haas. Fast non-negative temporal deconvolution for laser scanning mi-
croscopy. JBiophotonics,6(2):153–162,2013.
[32] RPBrent. AlgorithmsforMinimizationWithoutDerivatives. CourierCorporation,1973.
[33] JNocedalandSWright. Numericaloptimization. SpringerScience&BusinessMedia,2006.
[34] DLDonoho. De-noisingbysoft-thresholding. IEEETransInfTheory,41(3):613–627,1995.
[35] S.G.MallatandZ.Zhang. Matchingpursuitswithtime-frequencydictionaries. IEEETrans
SignalProcessing,41(12):3397–3415,1993.
[36] T-WChen, TvJWardill, YSun, SRPulver, SLRenninger, ABaohan, ERSchreiter, RA
Kerr,MBOrger,VJayaraman,andLLLooger. Ultrasensitivefluorescentproteinsforimaging
neuronalactivity. Nature,499(7458):295–300,2013.
[37] RBroandSDeJong.Afastnon-negativity-constrainedleastsquaresalgorithm.JChemometrics,
11(5):393–401,1997.
[38] CLLawsonandRJHanson. Solvingleastsquaresproblems,volume15. SIAM,1995.
[39] SDiamondandSBoyd. CVXPY:APython-embeddedmodelinglanguageforconvexopti-
mization. JMachLearnRes,17(83):1–5,2016.
[40] ADomahidi,EChu,andSBoyd. ECOS:AnSOCPsolverforembeddedsystems. InEuropean
ControlConference(ECC),pages3071–3076,2013.
[41] EDAndersenandKDAndersen. TheMOSEKinteriorpointoptimizerforlinearprogramming:
animplementationofthehomogeneousalgorithm. InHighperformanceoptimization,pages
197–232.Springer,2000.
[42] BO’Donoghue,EChu,NParikh,andSBoyd. Conicoptimizationviaoperatorsplittingand
homogeneousself-dualembedding. JOptimTheoryAppl,pages1–27,2016.
[43] GurobiOptimizationInc. Gurobioptimizerreferencemanual,2015.
[44] GENIE project, Janelia Research Campus, HHMI; Karel Svoboda (contact). Simultaneous
imagingandloose-sealcell-attachedelectricalrecordingsfromneuronsexpressingavarietyof
geneticallyencodedcalciumindicators. CRCNS.org,http://dx.doi.org/10.6080/K02R3PMN,
2015.
[45] T A Pologruto, R Yasuda, and K Svoboda. Monitoring neural activity and [Ca2+] with
geneticallyencodedCa2+indicators. JNeurosci,24(43):9572–9579,2004.
[46] T Quan, X Lv, X Liu, and S Zeng. Reconstruction of burst activity from calcium imaging
of neuronal population via Lq minimization and interval screening. Biomed Opt Express,
7(6):2103–2117,2016.
[47] ELDyer,CStuder,JTRobinson,andRGBaraniuk. Arobustandefficientmethodtorecover
neuraleventsfromnoisyandcorrupteddata. In6thIntIEEE/EMBSConfNeuralEng(NER),
pages593–596.IEEE,2013.
[48] MPachitariu,CStringer,SSchröder,MDipoppa,LFRossi,MCarandini,andKDHarris.
Suite2p: beyond10,000neuronswithstandardtwo-photonmicroscopy. bioRxiv,2016.
[49] A Giovannucci, J Friedrich, B Deverett, V Staneva, D Chklovskii, and E Pnevmatikakis.
CaImAn: Anopensourcetoolboxforlargescalecalciumimagingdataanalysisonstandalone
machines. CosyneAbstracts2017,SaltLakeCityUSA,2017.
[50] JFriedrichandLPaninski. Fastactivesetmethodsforonlinespikeinferencefromcalcium
imaging. InAdvNeuralInfProcessSyst29,pages1984–1992,2016.
[51] PJBrockwellandRADavis. Timeseries: theoryandmethods. SpringerScience&Business
Media,2013.
25