Relative representations for cognitive graphs
Alex B. Kiefer1,2 and Christopher L. Buckley1,3
1 VERSES Research Lab
2 Monash University
3 Sussex AI Group, Department of Informatics, University of Sussex
Abstract. Although the latent spaces learned by distinct neural net-
works are not generally directly comparable, even when model architec-
tureandtrainingdataareheldfixed,recentworkinmachinelearning[13]
has shown that it is possible to use the similarities and differences among
latent space vectors to derive “relative representations” with compara-
ble representational power to their “absolute” counterparts, and which
are nearly identical across models trained on similar data distributions.
Apart from their intrinsic interest in revealing the underlying structure
of learned latent spaces, relative representations are useful to compare
representations across networks as a generic proxy for convergence, and
for zero-shot model stitching [13].
In this work we examine an extension of relative representations to
discrete state-space models, using Clone-Structured Cognitive Graphs
(CSCGs) [16] for 2D spatial localization and navigation as a test case
in which such representations may be of some practical use. Our work
shows that the probability vectors computed during message passing can
be used to define relative representations on CSCGs, enabling effective
communication across agents trained using different random initializa-
tions and training sequences, and on only partially similar spaces. In the
process, we introduce a technique for zero-shot model stitching that can
be applied post hoc, without the need for using relative representations
during training. This exploratory work is intended as a proof-of-concept
for the application of relative representations to the study of cognitive
maps in neuroscience and AI.
Keywords: Clone-structuredcognitivegraphs · Relativerepresentations
· Representational similarity
1 Introduction
In this short paper we explore the application of relative representations [13] to
discrete (graph-structured) models of cognition in the hippocampal-entorhinal
system — specifically, Clone-Structured Cognitive Graphs (CSCGs) [16]. In the
first two sections we introduce relative representations and their extension to
discrete latent state spaces via continuous messages passed on graphs. We then
introduce CSCGs and their use in SLAM (Simultaneous Localization And Map-
ping). Finally, we report preliminary experimental results using relative repre-
sentations on CSCGs showing that (a) relative representations can indeed be
arXiv:2309.04653v1  [q-bio.NC]  9 Sep 2023
2 Kiefer and Buckley
applied successfully to model the latent space structure of discrete, graph-like
representations such as CSCGs, and more generally POMDPs such as those em-
ployed in discrete active inference modeling [1, 8, 19]; (b) comparison of agents
across partially disparate environments reveals important shared latent space
structure; and (c) it is possible to use the messages or beliefs (probabilities
over states) of one agent to reconstruct the corresponding belief distributions of
another via relative representations, without requiring the use of relative rep-
resentations during training. These examples illustrate an extension of existing
representational analysis techniques developed within neuroscience [10], which
we hope will prove applicable to the study of cognitive maps in biological agents.
2 Relative representations
Relative representation [13] is a technique recently introduced in machine learn-
ing that allows one to map the intrinsically distinct continuous latent space
representations of different models to a common shared representation identi-
cal (or nearly so) across the source models, so that latent spaces can be directly
compared, even when derived from models with different architectures. The tech-
nique is conceptually simple: given anchor pointsA = [x1, x2, ...,xN ] sampled
from a data or observation space and some similarity functionsim (e.g. cosine
similarity)4, the relative representationrM
i of datapointxi with respect to model
M can be defined in terms ofM’s latent-space embeddingseM
i = fencM (xi) as:
rM
i = [sim(eM
i , eM
a1 ), sim(eM
i , eM
a2 ), ..., sim(eM
i , eM
aN )] (1)
where eM
ai is the latent representation of anchori in M.
Crucially, the anchor pointsA must be matched across models in order for
their relative representations to be compatible. “Matching” is in the simplest
case simply identity, but there are cases in which it is feasible to use pairs of
anchors related by a mapg(x) → y (see below).
In [13] it is shown that the convergence of a modelMtarget during training
is well predicted by the average cosine similarity between its relative represen-
tations of datapoints and those of an independently validated reference model
Mref . This is to be expected, given that there is an optimal way of partitioning
the data for a given downstream task, and that distinct models trained on the
same objective approximate this optimal solution more or less closely, subject
to variable factors like random initialization and hyperparameter selection.
While relative representations were recently introduced in machine learning,
they take their inspiration in part from prior work on representational similarity
analysis (RSA) in neuroscience [10, 4]. Indeed, there is a formal equivalence be-
tween relative representations and the Representational Dissimilarity Matrices
(RDMs) proposed as a common format for representing disparate types of neuro-
scientific data (including brain imaging modalities as well as simulated neuronal
4 The selection of both suitable anchor points and similarity metrics is discussed at
length in [13]. We explain our choices for these hyperparameters in section 5.2 below.
Relative representations for cognitive graphs 3
activities in computational models) in [10]. Specifically, if a similarity rather
than dissimilarity metric is employed5, then each row (or, equivalently, column)
of the RDM used to characterize a representational space is, simply, a relative
representation of the corresponding datapoint.
Arguably the main contribution of [13] is to exhibit the usefulness of this
technique in machine learning, where relative representations may be employed
as a novel type of latent space in model architectures. Given a large enough sam-
ple of anchor points, relative representations bear sufficient information to play
functional roles similar to those of the “absolute” representations they model,
rather than simply functioning as an analytical tool (e.g. to characterize the
structure of latent spaces and facilitate abstract comparisons among systems).
The most obvious practical use of relative representations is in enabling “la-
tent space communication”: Moschella et al [13] show that the projection of
embeddings from distinct models onto the same relative representation enables
“zero-shot model stitching”, in which for example the encoder from one trained
model can be spliced to the decoder from another (with the relative represen-
tation being the initial layer supplied as input to the decoder). A limitation of
this procedure is that it depends on using a relative representation layer dur-
ing training, precluding its use for establishing communication between “frozen”
pretrained models. Below, we make use of a parameter-free technique that al-
lows one to map from the relative representation space back to the “absolute”
representations of the input models with some degree of success.
3 Extending relative representations to discrete
state-space models
Despite the remarkable achievements of continuous state-space models in deep
learning systems, discrete state spaces continue to be relevant, both in machine
learning applications, where discrete “world models” are responsible for state-of-
the-art results in model-based reinforcement learning [6], and in neuroscience,
where there is ample evidence for discretized, graph-like representations, for
example in the hippocampal-entorhinal system [25, 18, 16] and in models of
decision-making processes that leverage POMDPs (Partially Observable Markov
Decision Processes) [19].
While typical vector similarity metrics such as cosine distance behave in a
somewhatdegeneratewaywhenappliedtomanytypesofdiscreterepresentations
(e.g., the cosine similarity between two one-hot vectors in the same space is 1 if
the vectors are identical and 0 otherwise), they can still be usefully applied in
this case (see section 5 below). More generally, the posterior belief distributions
inferred over discrete state spaces during simulations in agent-based models may
provide suitable anchor points for constructing relative representations.
Concretely, such posterior distributions are often derived using message-
passing algorithms, such as belief propagation [14] or variational message passing
5 See [10] fn.2.
4 Kiefer and Buckley
[27]. We pursue such a strategy for deriving relative representations of a special
kind of hidden Markov model (the Clone-Structured Hidden Markov Model or (if
supplemented with actions) Cognitive Graph [16]), in which it is simple to com-
pute forward messages which at each discrete time-step give the probability of
the hidden statesz conditioned on a sequence of observationso (i.e. P(zt|o1:t)).
The CSCG/CHMM is particularly interesting both because of its fidelity as a
model of hippocampal-entorhinal representations in the brain and because, as
in the case of neural networks, distinct agents may learn superficially distinct
CSCGs that nonetheless form nearly isomorphic cognitive maps, as shown below.
4 SLAM using Clone-Structured Cognitive Graphs
An important strand of research in contemporary machine learning and compu-
tational neuroscience has focused on understanding the role of the hippocampus
and entorhinal cortex in spatial navigation [20, 23, 25, 16], a perspective that
may be applicable to navigation in more abstract spaces as well [18, 21]. This
field of research has given rise to models like the Tolman-Eichenbaum machine
[25] and Clone-Structured Cognitive Graph [5, 16]. We focus on the latter model
in the present study, as it is easy to implement on toy test problems and yields a
suitablerepresentationforourpurposes(anexplicitdiscretelatentspacethrough
which messages can be propagated).
The core of the CSCG is a special kind of “clone-structured” Hidden Markov
Model (CHMM) [17], in which each of N possible discrete observations are
mapped deterministically to only a single “column” of hidden states by the like-
lihood function, i.e.p(o|z) =
(
1 if z ∈ C(o)
0 if z /∈ C(o), whereC(o) is the set of “clones”
of observationo. The clone structure encodes the inductive bias that the same
observation may occur within a potentially large but effectively finite number
of contexts (i.e. within many distinct sequences of observations), where each
“clone” functions as a latent representation ofo in a distinct context. This allows
the model to efficiently encode higher-order sequences [3] by learning transition
dynamics (“lateral” connections) among the clones. CSCGs supplement this ar-
chitecture with a set of actions which condition transition dynamics, creating in
effect a restricted form of POMDP.
The most obvious use of CSCG models (mirroring the function of the hip-
pocampal-entorhinal system) is to allow agents capable of moving in a space to
perform SLAM (Simultaneous Localization And Mapping) with no prior knowl-
edge of the space’s topology. Starting with a random transition matrix, CSCGs
trained on random walks in 2D “rooms”, in which each cell corresponds to an
observation, are shown in [16] to be capable of learning action-conditioned tran-
sition dynamics among hidden states that exhibit a sparsity structure precisely
recapitulating the spatial layout of the room (see Fig. 1).6
6 The training used to obtain this result is based on an efficient implementation of the
Baum-Welch algorithm for E-M learning, followed by Viterbi training — please see
[16] for details.
Relative representations for cognitive graphs 5
Fig. 1.Example of two cognitive graphs (B) learned by CSCG agents via distinct
random walks on the same room (A). Following the convention in [16], colors indicate
distinct discrete observations (in the room) or latent “clones” corresponding to those
observations (in the graphs). Code for training and producing plots is provided in the
supplementary materials for [16]. Note that the two graphs are obviously isomorphic
upon inspection (the left graph is visually rotated about 50 degrees clockwise relative
to the right one, and the node labels differ).
Given a sequence of observations, an agent can then infer states that cor-
respond to its location in the room, with increasing certainty and accuracy as
sequence length increases. Crucially, location is not an input to this model but
the agent’s representation of location is entirely “emergent” from the unsuper-
vised learning of higher-order sequences of observations.
Building on the codebase provided in [16], we examined the certainty of
agents’ inferred beliefs about spatial location during the course of a random
walk (see Figure 2.). Though less than fully confident, such agents are able to
reliably infer room location from observation sequences alone after a handful
of steps. Conditioning inference as well on the equivalent of “proprioceptive”
information (i.e., about which actions resulted in the relevant sequence of obser-
vations) dramatically increases the certainty of the agents’ beliefs. We explored
both of these regimes of (un)certainty in our experiments.
5 Experiments: Communication across cognitive maps
We investigate the extent to which common structure underlying the “cognitive
maps” learned by distinct CSCG agents can be exploited to enable communi-
cation across them. As in the case of neural networks trained on similar data,
CSCG agents trained on the same room but with distinct random initializations
and observation sequences learn distinct representations that are nonetheless
isomorphic at one level of abstraction (i.e. when comparing the structural rela-
tionships among their elements, which relative representations make explicit —
cf. Appendix B, Fig. 5).
We also explore whether partial mappings can be obtained across agents
trained on somewhat dissimilar rooms. We used two metrics to evaluate the
quality of cross-agent belief mappings: (1) recoverability of the maximuma pos-
teriori belief of one agent at a given timestep, given those of another agent
6 Kiefer and Buckley
Fig. 2.Maximum probability assigned to any hidden state of a CSCG over time (during
a random walk). The left panel shows confidence derived from messages inferred from
observations alone, and the right panel shows the case of messages inferred from both
actions and observations.
following an analogous trajectory; (2) cosine similarity between a given message
and its “reconstruction” via such a mapping. The main results of these prelimi-
nary experiments are reported in Table 1.
5.1 Mapping via permutation
We first confirmed that CSCG agents trained on distinct random walks of the
same room (and with distinct random transition matrix initializations) learn
functionally identical cognitive maps if trained to convergence using the proce-
dure specified in [16]. Visualizations of the learned graphs clearly demonstrate
topological isomorphism (see references as well as figure 1B), but in addition we
found that the forward messages for a given sequence of observations are identi-
cal across agents up to a permutation (i.e., which “clones” are used to represent
which observation contexts depends on the symmetry breaking induced by differ-
entrandomwalksandinitializations).Itisthuspossibleto“translate” acrosssuch
cognitive maps in a simple way. First, we obtain message sequencesM and M′
from the first and second CSCGs conditioned on the same observation sequence,
and extract messagesm and m′ corresponding to some particular observation
ot. We then construct a mappingsort_indexmot
(z) → sort_indexm′ot
(z′) from
the sort order of entriesz in m to that of entriesz′ in m′. Using this mapping,
we can predict the maximuma posteriori beliefs in M′ nearly perfectly given
those inM under ideal conditions (see the “Permutation (identical)” condition
in Table 1).7
7 This procedure does not work if the chosen message represents a state of high un-
certainty, e.g. at the first step of a random walk with no informative initial state
Relative representations for cognitive graphs 7
5.2 Mapping via relative representations
Though it is thus relatively simple to obtain a mapping across cognitive graphs
in the ideal case of CSCGs trained to convergence on identical environments,
we confirm that relative representations can be used in this setting to obtain
comparable results. A messagem′ from the second sequence (associated with
model B) can be reconstructed from message m in the first (model A’s) by
linearly combining model B’s embeddingsEB
A of the anchor points, via a softmax
(σ) function (with temperatureT) of the relative representationrA
m of m derived
from model A’s anchor embeddings:8
ˆm′ =
 
EB
A

σ
hrA
m
T
i
(2)
Intuitively, the softmax term scales the contribution of each vector in the
set of anchor embeddings to the reconstructionˆm′ in proportion to its relative
similarity to the input embedding, so that the reconstruction is a weighted su-
perposition (convex combination) of the anchor points. The reconstruction of
a sequence M′ of m d′-dimensional messages from an analogous “source” se-
quence M of d-dimensional messages, with the “batch” relative representation
operation9 RA
M ∈ Rm×|A| written out explicitly in terms of the matrix product
between M ∈ Rm×d and anchor embeddings EA
A ∈ R|A|×d, is then precisely
analogous to the self-attention operation in transformers:
ˆM′ = σ
hM

EA
A
T
T
i
EB
A (3)
Here, the source messagesM play the role of the queriesQ, model A’s anchor
embeddings EA
A act as keysK, and model B’s anchor embeddings act as values
V in the attention equation which computes outputZ = σ

QKT 
V.10
Since self-attention may be understood though the lens of its connection
to associative memory models [15, 12], this correspondence goes some way to-
ward theoretically justifying our choice of reconstruction method. In particular,
following [12], reconstruction via relative representations can be understood as
implementing a form of heteroassociative memory in which model A and B’s
anchor embeddings are, respectively, the memory and projection matrices.
Though empirical performance against a wider range of alternative methods
of latent space alignment remains to be assessed, we note a formal connection to
prior. The mapping also fails for many states since CSCGs, by construction, assign
zero probability to all states not within the clone set of a given observation, leading
to degeneracy in the mapping. We also found that accuracy of this method degrades
rapidly to the extent that the learned map fails to converge to the ground truth
room topology.
8 In practice, a softmax with a low temperature worked best for reconstruction.
9 If M = A, this term is a representational similarity matrix in the sense of [10].
10 In the present setting, one might even draw a parallel between the linear projection
of transformer inputs to the key, query and value matrices and the linear projection
of observations and prior beliefs onto messages via likelihood and transition tensors.
8 Kiefer and Buckley
regression-based approaches such as [22], in which a representationY of the data
is expressed as a mixture of “guesses” (linear projections of local embeddings)
from k experts, weighted according to the fidelity of each expert’s representation
of the input data X. This can be expressed as a system of linear equations
Y = UL in whichY, U and L play roles analogous to those ofˆM, σ

RA
M

and
EB
A above, with the “repsonsibility” terms (weights) introducing nonlinearity, as
the softmax does in our approach (see Appendix C for further details).
Not surprisingly, the results of our procedure improve with the number of
anchors used (see Appendix A, Figure 4). In our experiments, we usedN =
5000 anchors. We obtained more accurate mappings using this technique when
the anchor points were sampled from the trajectory being reconstructed, which
raises the probability of an exact match in the anchor set; for generality, all
reported results instead sample anchor points (uniformly, without replacement)
from distinct random walks. While it would be possible in the present setting
to use similarity metrics tailored to probability distributions to create relative
representations, we found empirically that replacing cosine similarity with the
negative Jensen-Shannon distance slightly adversely affected performance.
5.3 Mapping across dissimilar models
Table 1.Mapping across distinct CSCG models*
Max belief recovery Reconstruction accuracy
Condition % accurate (±SD) mean cosine similarity ( ±SD)
Baseline: AR† (identical) 0.01(±0.01) 0 .07(±0.07)
Permutation (identical) 84.09(±28.9) 0 .69(±0.01)
Permutation (shifted) 3.41(±1.48) 0 .69(±0.01)
Permutation (landmark) 20.70(±19.14) 0 .89(±0.003)
RR‡ (identical) 89.44(±1.84) 0 .99(±0.003)
RR (isomorphic) 41.0(±3.17) 0 .67(±0.02)
RR (expansion: large→ small) 97.42(±3.24) 0 .98(±0.02)
RR (expansion: small→ large) 47.47(±2.74) 0 .59(±0.02)
RR (shifted) 34.81(±3.81) 0 .63(±0.03)
RR (landmark) 34.13(±6.47) 0 .52(±0.06)
†Absolute Representations‡Relative Representations *For each condition, mean results
and standard deviation over 100 trials (each run on a distinct random graph) are
reported, for the more challenging case of messages conditioned only on observations.
For all but the (expansion) conditions, the results of mapping in either direction were
closely comparable and we report the mean.
Relative representations for cognitive graphs 9
Fig. 3.Schematic illustration of experimental conditions.A and B indicate distinct
rooms on which parallel models were trained, except for the “IDENTICAL” condition,
where multiple models are trained on a single room. Numbers within nodes illustrate
stochastic association of particular hidden state indices with positions in the learned
graphs. Graph sizes depicted here do not reflect those used in the experiments.
As shown in [13], relative representations can reveal common structure across
superficially quite different models — for example those trained on sentences in
distinct natural languages — via the use of “parallel” anchor points, in which the
anchors chosen for each model are related by some mapping (e.g. being transla-
tions of the same text). In the context of CSCGs, anchors (forward messages) are
defined relative to an observation sequence. To sample parallel anchors across
agents, we therefore require partially dissimilar rooms in which similar but dis-
tinct observation sequences can be generated.
We used four experimental manipulations to generate pairs of partially dis-
similar rooms (see Figure 3), which we now outline along with a brief discussion
of our results on each.
Isomorphism Any randomly generated grid or “room” of a given fixed size will
(if CSCG training converges) yield a cognitive map with the same topology. It
should thus be possible to generate parallel sequences of (action, observation)
pairs — and thus parallel anchor points for defining relative representations —
across two such random rooms, even if each contains a distinct set of possible
observations or a different number of clones, either of which would preclude the
use of a simple permutation-based mapping.
The relationships among observations will differ across such rooms, however,
which matters under conditions of uncertainty, since every clone of a given ob-
servation will be partially activated when that observation is received, leading
10 Kiefer and Buckley
to different conditional belief distributions. This effect should be mitigated or
eliminated entirely when beliefs are more or less certain, in which case “lateral”
connections (transition dynamics) select just one among the possible clones cor-
responding to each observation. Indeed, we found that it is possible to obtain
near-perfect reconstruction accuracy across models trained on random rooms
with distinct observation sets, provided that messages are conditioned on both
actions and observations; whereas we only obtained a< 50% success rate in this
scenario when conditioning on observations alone.
Expansion In this set of experiments, we generated “expanded” versions of
smaller rooms and corresponding “stretched” trajectories (paired observation
and action sequences) using Kroenecker products, so that each location in the
smaller room is expanded into a2 × 2 block in the larger room, and each step
in the smaller room corresponds to two steps in the larger one. We can then
define parallel anchors across agents trained on such a pair of rooms, by taking
(a) all messages in the smaller room, and (b) every other message in the larger
one. In this condition, the large→ small mapping can be performed much more
accurately than the opposite one, since each anchor point in the smaller (“down-
sampled”) room corresponds to four potential locations in the larger. Superior
results on the (large→ small) condition VS our experiments on identical rooms
may be explained by the fact that the “small” room containts fewer candidate
locations than the room used in the “Identical” condition.
Shifting In a third set of experiments, we generated rooms by taking overlap-
ping vertical slices of a wider room, such that identical sequences were observed
while traversing the rooms, but within different wider contexts. In this case only
the messages corresponding to overlapping locations were used as anchor points,
but tests were performed on random walks across the entire room. Under condi-
tions of certainty, mapping across these two rooms can be solved near-perfectly
by using all messages as candidate anchor points, since the rooms are isomorphic.
Without access to ground-truth actions, it was possible to recover the beliefs of
one agent given the other’s only∼ 35% of the time, even if anchors were sampled
from all locations. We hypothesize that this problem is more challenging than
the “Isomorphic” condition because similar patterns of observations (and thus
similar messages) correspond to distinct locations across the two rooms, which
should have the effect of biasing reconstructions toward the wrong locations.
Landmarks Finally, partially following the experiments in [16] on largely fea-
tureless rooms with unique observations corresponding to unique locations (e.g.
corners and walls), we define pairs of rooms with the same (unique) observations
assigned to elements of the perimeter, filled by otherwise randomly generated
observations that differed across rooms. Using only the common “landmark” lo-
cations as anchors, it was still possible to use relative representations to recover
an agent’s location from messages in a parallel trajectory in the other room with
some success.
Relative representations for cognitive graphs 11
Summary The results reported in Table 1 were obtained under conditions of
significant uncertainty, in which messages were conditioned only on observations,
without knowledge of the action that produced those observations. In this chal-
lenging setting, relative representations still enabled recovery (well above chance
in all experimental conditions, and in some cases quite accurate) of one agent’s
maximum a posteriori belief about its location from those of the other agent,
averaged across messages in a test sequence.11
In all settings, it was possible to obtain highly accurate mappings (> 99%
correct in most cases) by conditioning messages on actions as well as observa-
tions. This yields belief vectors sharply peaked at the hidden state corresponding
to an agent’s location on the map. In this regime, the reconstruction procedure
acts essentially as a lookup table, as a given messagem resembles a one-hot vec-
tor and this sparsity structure is reflected in the relative representation (which
is ∼ 0 everywhere except for dimensions corresponding to anchor points nearly
identical to m). The softmax weighting then simply “selects” the correspond-
ing anchor in model B’s anchor set.12 Conditioning messages on probabilistic
knowledge of actions (perhaps the most realistic scenario) can be expected to
greatly improve accuracy relative to the observation-only condition, and is an
interesting subject for a follow-up study.
6 Discussion
The “messages” used to define relative representations in the present work can be
interpreted as probability distributions, but they can also be interpreted more
agnostically as, simply, neuronal activity vectors. Recent work in systems neu-
roscience [2] has shown that it is possible to recover common abstract latent
spaces from real neuronal activity profiles. As noted above, relative representa-
tionswereanticipatedinneurosciencebyRSA,whichineffecttreatstheneuronal
responses, or computational model states, associated with certain fixed stimuli
as anchor points. This technique complements others such as the analysis of
attractor dynamics [26] as a tool to investigate properties of latent spaces in
brains, and has been shown to be capable of revealing common latent represen-
tational structure across not only individuals, but linguistic communities [28]
and even species [11, 7]. Consistent with the aims of [13] and [10], this paradigm
might ultimately provide fascinating future directions for brain imaging studies
of navigational systems in the hippocampal-entorhinal system and elsewhere.
Relative representations generalize this paradigm to “parallel anchors”, and
also demonstrate the utility of high-dimensional representational similarity vec-
11 It is worth noting that this is essentially a one-of-N classification task, with effective
valuesofNaround48inmostcases.Thisisbecause(following[16])mostexperiments
were performed on6×8 rooms, and there is one “active” clone corresponding to each
location in a converged CSCG.
12 There is a variation on this in which multiple matches exist in the anchor set, but
the result is the same as we then combinen identical anchor points.
12 Kiefer and Buckley
tors as latent representations in their own right, which can, as demonstrated
above, be used to establish zero-shot communication between distinct models.
Whiletheconditionsweconstructedinourtoyexperimentsareartificial,they
have analogues in more realistic scenarios. It is plausible that animals navigating
structurally homeomorphic but superficially distinct environments, for example,
should learn similar cognitive maps at some level of abstraction. Something anal-
ogous to the “expansion” setting may occur across two organisms that explore
the same space but (for example due to different sizes or speeds of traversal, and
thus sample rates) coarse-grain it differently. The idea of landmark-based navi-
gation is central to the SLAM paradigm generally, and the stability of landmarks
across otherwise different spaces may provide a model for the ability to navigate
despite changes to the same environment over time. Finally, while experiments
on partially overlapping rooms seem somewhat contrived if applied naively to
spatial navigation scenarios, they may be quite relevant to models of SLAM in
abstract spaces [18], such as during language acquisition, where different speak-
ers of the same language may be exposed to partially disjoint sets of stimuli,
corresponding to different dialects (or in the limit, idiolects).
Crucially, the common reference frame provided by these techniques might
allow for the analysis ofshared representations, which (when derived from well-
functioning systems) should embody an ideal structure that individual cognitive
systems in some sense aim to approximate, allowing for comparison of individual
brain-bound models against a shared, abstract ground truth. Such an abstracted
“ideal” latent space could be used to measure error or misrepresentation [9], or
to assess progress in developmental contexts.
7 Conclusion
In this work we have considered a toy example of the application of relative
representations to graph-structured cognitive maps. The results reported here
are intended mainly to illustrate concrete directions for the exploration of the
latent structure of cognitive maps using relative representations, and as a proof-
of-principle that the technique can be applied to the case of inferred posterior
distributions over discrete latent spaces. We have also introduced a technique for
reconstructing “absolute” representations from their relative counterparts with-
out learning.
In addition to further investigating hyperparameter settings (such as choice
of similarity function) to optimize performance in practical applications, future
work might explore the application of relative representations to more complex
models with discrete latent states, such as the discrete “world models” used in
cutting-edge model-based reinforcement learning [6], or to enable belief sharing
and cooperation in multi-agent active inference scenarios. Given the connection
to neural self-attention described above, which has also been noted in the context
of the Tolman-Eichenbaum Machine [24], it would also be intriguing to explore
models in which such a translation process occurs within agents themselves, as
a means of transferring knowledge across local cognitive structures.
Relative representations for cognitive graphs 13
Acknowledgements
Alex Kiefer is supported by VERSES Research. CLB is supported by BBRSC
grant number BB/P022197/1 and by Joint Research with the National Institutes
of Natural Sciences (NINS), Japan, program No. 0111200.
Code Availability
The CSCG implementation is based almost entirely on the codebase provided in
[16]. Code for reproducing our experiments and analysis can be found at:
https://github.com/exilefaker/cscg-rr
References
[1] Lancelot Da Costa et al. “Active inference on discrete state-spaces: A syn-
thesis”. In:Journal of Mathematical Psychology99 (2020), p. 102447.issn:
0022-2496. doi: https://doi.org/10.1016/j.jmp.2020.102447 . url:
https://www.sciencedirect.com/science/article/pii/S0022249620300857.
[2] Max Dabagia, Konrad P. Kording, and Eva L. Dyer. “Aligning latent repre-
sentations of neural activity”. In:Nature Biomedical Engineering7 (Apr.
2023), pp. 337–343. doi: https : / / doi . org / 10 . 1038 / s41551 - 022 -
00962-7.
[3] AntoineDedieuetal. Learning higher-order sequential structure with cloned
HMMs. 2019. arXiv:1905.00507 [stat.ML].
[4] Halle R. Dimsdale-Zucker and Charan Ranganath. “Chapter 27 - Repre-
sentational Similarity Analyses: A Practical Guide for Functional MRI Ap-
plications”. In:Handbook of in Vivo Neural Plasticity Techniques. Ed. by
Denise Manahan-Vaughan. Vol. 28. Handbook of Behavioral Neuroscience.
Elsevier,2018,pp.509–525. doi:https://doi.org/10.1016/B978-0-12-
812028-6.00027-6 . url: https://www.sciencedirect.com/science/
article/pii/B9780128120286000276.
[5] Dileep George et al. “Clone-structured graph representations enable flexi-
ble learning and vicarious evaluation of cognitive maps”. In:Nature com-
munications 12.1 (2021), p. 2392.
[6] Danijar Hafner et al. “Mastering Atari with Discrete World Models”. In:
CoRR abs/2010.02193 (2020). arXiv:2010.02193. url: https://arxiv.
org/abs/2010.02193.
[7] James V. Haxby, Andrew C. Connolly, and J. Swaroop Guntupalli. “De-
coding neural representational spaces using multivariate pattern analysis.”
In: Annual review of neuroscience 37 (2014), pp. 435–56. url: https :
//api.semanticscholar.org/CorpusID:6794418.
[8] ConorHeinsetal.“pymdp:APythonlibraryforactiveinferenceindiscrete
state spaces”. In:CoRR abs/2201.03904 (2022). arXiv:2201.03904. url:
https://arxiv.org/abs/2201.03904.
14 Kiefer and Buckley
[9] Alex Kiefer and Jakob Hohwy. “Representation in the Prediction Error
Minimization Framework”. In:The Routledge Companion to Philosophy of
Psychology: 2nd Edition. Ed. by Sarah K. Robins, John Symons, and Paco
Calvo. 2019, pp. 384–409.
[10] Nikolaus Kriegeskorte, Marieke Mur, and Peter Bandettini. “Representa-
tional Similarity Analysis – Connecting the Branches of Systems Neuro-
science”. In: Frontiers in systems neuroscience2 (Feb. 2008), p. 4.doi:
10.3389/neuro.06.004.2008.
[11] Nikolaus Kriegeskorte et al. “Matching Categorical Object Representations
in Inferior Temporal Cortex of Man and Monkey”. In:Neuron 60 (2008),
pp. 1126–1141. url: https://api.semanticscholar.org/CorpusID:
313180.
[12] Beren Millidge et al. “Universal Hopfield Networks: A General Frame-
work for Single-Shot Associative Memory Models”. In:Proceedings of the
39th International Conference on Machine Learning. Vol. 162. Baltimore,
Maryland, USA, July 2022, pp. 15561–15583.
[13] Luca Moschella et al.Relative representations enable zero-shot latent space
communication. 2023. arXiv:2209.15430 [cs.LG].
[14] Judea Pearl. “Reverend Bayes on Inference Engines: A Distributed Hier-
archical Approach”. In: Proceedings of the Second AAAI Conference on
Artificial Intelligence. AAAI’82. Pittsburgh, Pennsylvania: AAAI Press,
1982, pp. 133–136.
[15] Hubert Ramsauer et al. Hopfield Networks is All You Need. 2021. arXiv:
2008.02217 [cs.NE].
[16] Rajeev V. Rikhye et al. “Learning cognitive maps as structured graphs for
vicarious evaluation”. In:bioRxiv (2020). doi: 10.1101/864421 . eprint:
https://www.biorxiv.org/content/early/2020/06/24/864421.full.
pdf. url: https://www.biorxiv.org/content/early/2020/06/24/
864421.
[17] Rajeev V. Rikhye et al. “Memorize-Generalize: An online algorithm for
learninghigher-ordersequentialstructurewithclonedHiddenMarkovMod-
els”. In: bioRxiv (2019). doi: 10.1101/764456 . eprint: https://www.
biorxiv.org/content/early/2019/09/10/764456.full.pdf . url:
https://www.biorxiv.org/content/early/2019/09/10/764456.
[18] Adam Safron, Ozan Çatal, and Tim Verbelen.Generalized Simultaneous
Localization and Mapping (G-SLAM) as unification framework for natu-
ral and artificial intelligences: towards reverse engineering the hippocam-
pal/entorhinal system and principles of high-level cognition.Oct.2021. doi:
10.31234/osf.io/tdw82. url: psyarxiv.com/tdw82.
[19] Ryan Smith, Karl J. Friston, and Christopher J. Whyte. “A step-by-step
tutorial on active inference and its application to empirical data”. In:Jour-
nal of Mathematical Psychology107 (2022), p. 102632.issn: 0022-2496.
doi: https://doi.org/10.1016/j.jmp.2021.102632 . url: https://
www.sciencedirect.com/science/article/pii/S0022249621000973.
Relative representations for cognitive graphs 15
[20] Kimberly Stachenfeld, Matthew Botvinick, and Samuel Gershman. “The
hippocampus as a predictive map”. In: (July 2017).doi: 10.1101/097170.
[21] Sivaramakrishnan Swaminathan et al. Schema-learning and rebinding as
mechanisms of in-context learning and emergence. 2023. arXiv: 2307 .
01201 [cs.CL].
[22] Yee Teh and Sam Roweis. “Automatic Alignment of Local Representa-
tions”. In: Advances in Neural Information Processing Systems. Ed. by
S. Becker, S. Thrun, and K. Obermayer. Vol. 15. MIT Press, 2002.url:
https://proceedings.neurips.cc/paper_files/paper/2002/file/
3a1dd98341fafc1dfe9bcf36360e6b84-Paper.pdf.
[23] James Whittington et al. “How to build a cognitive map”. In:Nature Neu-
roscience 25 (Sept. 2022), pp. 1–16.doi: 10.1038/s41593-022-01153-y .
[24] James C. R. Whittington, Joseph Warren, and Timothy Edward John
Behrens. “Relating transformers to models and neural representations of
thehippocampalformation”.In: CoRR abs/2112.04035(2021).arXiv: 2112.
04035. url: https://arxiv.org/abs/2112.04035.
[25] James C.R. Whittington et al. “The Tolman-Eichenbaum Machine: Uni-
fying Space and Relational Memory through Generalization in the Hip-
pocampal Formation”. In: Cell 183.5 (2020), 1249–1263.e23. issn: 0092-
8674. doi: https://doi.org/10.1016/j.cell.2020.10.024 . url:
https://www.sciencedirect.com/science/article/pii/S009286742031388X.
[26] Tom J. Wills et al. “Attractor Dynamics in the Hippocampal Representa-
tion of the Local Environment”. In:Science 308.5723 (2005), pp. 873–876.
doi: 10.1126/science.1108905 . eprint: https://www.science.org/
doi/pdf/10.1126/science.1108905 . url: https://www.science.org/
doi/abs/10.1126/science.1108905.
[27] John Winn and Christopher M. Bishop. “Variational Message Passing”. In:
J. Mach. Learn. Res.6 (Dec. 2005), pp. 661–694.issn: 1532-4435.
[28] Benjamin D. Zinszer et al. “Semantic Structural Alignment of Neural Rep-
resentational Spaces Enables Translation between English and Chinese
Words”. In:Journal of Cognitive Neuroscience28 (2016), pp. 1749–1759.
url: https://api.semanticscholar.org/CorpusID:577366.
16 Kiefer and Buckley
Appendix A: Effect of anchor set size on reconstruction
Fig. 4.Average cosine similarity ( u·v
∥u∥∥v∥) between ground-truth CSCG beliefs (mes-
sages) and their reconstructions from those of a distinct CSCG model trained on the
same room and receiving the same sequence of observations, using the method in Equa-
tion 2, plotted against numberN of anchors used to define the relative representations.
We begin by settingN to the dimensionality of the model’s hidden state. The average
is across all 5000 messages in a test sequence.
Relative representations for cognitive graphs 17
Appendix B: Visualizing the correspondence of relative
representations across models
Fig. 5.Example representational similarity matrix comparing relative representations
of analogous message sequences (i.e. inferred from the same observation sequence)
from two distinct models trained on the same environment. This differs from the
(dis)similarity matrices typically used in RSA [10], as rows and columns in this case
represent distinct sets of first-order representations, i.e. cell(i, j) represents the cosine
similarity betweenrA
i and rB
j . Thus the diagonal symmetry illustrates the empirical
equivalence of these two sets of relative representations.
Appendix C: Comparison to LLC
Locally Linear Coordination (LLC) [22] is a method for aligning the embeddings
of multiple dimensionality-reducing models so that they project to the same
18 Kiefer and Buckley
global coordinate system. While its aims differ somewhat from the procedure
outlined in the present study, LLC is also an approach to translating multi-
ple source embeddings to a common representational format. As noted above,
there is an interesting formal resemblance between the two approaches, which
we explore in this Appendix.
The LLC representation
LLC presupposes a mixture model of experts trained onN D-dimensional input
datapoints X = [x1, x2, ...,xN ], in which each expertmk is a dimensionality re-
ducer that produces a local embeddingznk ∈ Rdk of datapointxn. The mixture
weights or “responsibilities” for the model can be derived, for example, as pos-
teriors over each expert’s having generated the data, in a probabilistic setting.
Given the local embeddings and responsibilities, LLC proposes an algorithm
for discovering linear mappingsLk ∈ Rd×dk from each expert’s embedding to a
common (lower-dimensional) output representationY ∈RN×d, which can then
be expressed as a responsibility-weighted mixture of these projections. That is
to say, leaving out bias terms for simplicity: each output imageyn of datapoint
xn is computed as
yn =
X
k
rnk
 
Lkznk

(4)
Crucially for what follows, with the help of a flattened (1D) index that spans
the “batch” dimensionN as well as the expertsk, we can express this in simpler
terms asY = UL. We define matricesU ∈ RN×P
k dk and L ∈ R
P
k dk×d in terms
of, respectively: (a) vectorsun, whereunj = rnk zi
nk (i.e. thejth element ofun
is the ith element ofk’s embedding ofxn scaled by its responsibility term) —
and (b) re-indexed, transposed columnslj = li
k of theLk matrices. Intuitively,
each rowun of U concatenates the experts’ responsibility-weighted embeddings
rnk znk of datapoint xn, while each ofL’s d columns is a concatenation of the
corresponding row of the projection matricesLk, so that the matrix productUL
returns a responsibility-weighted prediction foryn in each row (see Figure 6).
Relationship to our proposal
Ignoringthemotivationofdimensionalityreductionwhichisirrelevantforpresent
purposes,thereisapreciseconceptualandformalequivalencebetweenthismodel
and the procedure for reconstructing model B’s embeddings given those of model
A described above in Section 5.2.
Specifically, we can regard each of model A’s anchor embeddingseA
xk as an
"expert" in a fictitious mixture model, with an associated responsibility term
measuring its fidelity to the inputxi , which in this case is given by the cosine
similarity between the anchor embedding and the input embedding. Then like
the rows ofU, each row ofσ

RA
X

, which is a relative representationrA
i = EA
AeA
i
of input i after application of the softmax, acts as a responsibility-weighted
Relative representations for cognitive graphs 19
Fig. 6.Visual schematic of the computation of a single entry of the output of (A)
the projection of inputxn to output yn as in the Locally Linear Coordinates (LLC)
mapping procedure; (B) the reconstruction of a latent embeddingeB
n in model B’s
embedding space given inputxn to model A. The groupings in brackets in (A) illustrate
the concatenations of vector embeddings (scaled by responsibility termsrnk ) inun, and
of projection columns inlj. 1k in (B) denotes a row ofk 1s (wherek in this case denotes
the number of anchors, i.e. is set to|A|). Each entry in the column vector

EB
A
T
j is
the jth dimension of one of model B’s anchor embeddings.
mixture of multiple “views” of the input. Similarly, since the rows ofEB
A are
anchor embeddings in the output space, its columnsj act precisely as do the
columns ofL, i.e. as columns in a projection matrix, so thatσ[rA
i ] ·EB
Aj outputs
dimension j of the reconstructed target embeddingeB
i .
There is at least one important difference between LLC and our procedure:
in LLC each expert uses an internal transform to generate an input-dependent
embedding, which is then scaled by its responsibility term, which also depends
on the input. Reconstruction via relative representations instead employs fixed
stored embeddings, so that each “expert” contributes a scalar value rather than
an embedding vector to the final output. However, the expression of LLC in
terms of a linear index demonstrates that this makes no essential difference
mathematically (conceptually, these scalar “votes” are 1D vectors; cf. Figure 6).
The point is not that these two algorithms are doing precisely the same thing
(they are not, as LLC aims to align multiple embedding spaces by deriving a
mapping to a distinct common space, while our approach aims to recover the
contents of one embedding space from another). The use of LLC to reconstruct
input data X from its “global” embeddingY as in [22]is quite closely related
to our procedure, however, and at this level of abstraction the approaches may
be regarded as the same, with a difference in the nature of the “experts” used in
the mixture model and the attendant multiple “views” of the data. The relative
representation reconstruction procedure, while presumably not as expressive,
may compensate to some extent for the use of scalar “embeddings” by using a
large number of “experts”, and has the virtue of eschewing the need for a mixture
model to assign responsibilities, or indeed for multiple intermediate embedding
models, to perform such a mapping.