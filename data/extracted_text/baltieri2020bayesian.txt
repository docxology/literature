0202
yaM
41
]CO.htam[
2v88201.4002:viXra
A Bayesian perspective on classical control
Manuel Baltieri
Laboratory for Neural Computation and Adaptation, RIKEN Centre for Brain Science, Wako, Saitama, Japan
manuel.baltieri@riken.jp
Abstract—The connections between optimal control and (optimal) control theory that he also established [9], showing
Bayesian inference have long been recognised, with the field how both solutions require solving Riccati equations, forward
of stochastic (optimal) control combining these frameworks
in time for filtering (error covariance matrix) and backward
for the solution of partially observable control problems. In
in time for control (Hessian of the cost-to-go function). In
particular, for the linear case with quadratic functions and
Gaussian noise, stochastic control has shown remarkable results the following years, several results improved the treatment
in different fields, including robotics, reinforcement learning of stochastic optimal control problems, including for instance
and neuroscience, especially thanks to the established duality of the separation principle [4], [10]1 and its applications to the
estimationandcontrolprocesses.Followingthisideawerecently
treatment of regulation in the presence of uncertainty, i.e.,
introducedaformulationofPIDcontrol,oneofthemostpopular
for (linear) partially observable control problems. Due to methodsfromclassicalcontrol,basedonactiveinference,atheory
with roots in variational Bayesian methods, and applications in its analytical tractability and its combination of estimation
the biological and neural sciences. In this work, we highlight and control algorithms, the linear quadratic framework (i.e.,
the advantages of our previous formulation and introduce new stochastic optimal control for linear state-space models with
and more general ways to tackle some existing problems in
Gaussian white noise and quadratic cost functions) has since
current controller design procedures. In particular, we consider
then becomea standardapproachin differentfields, including
1) a gradient-based tuningrule for the parameters (or gains) of
a PID controller, 2) an implementation of multiple degrees of not only control theory and engineering [3], [4], but also
freedom for independent responses to different types of signals robotics [13] and neuroscience [14], [15].
(e.g., two-degree-of-freedom PID), and 3) a novel time-domain In recent years, the results based on the notion of duality
formalisation of the performance-robustness trade-off in terms
in the linear case have been extended to (some classes of)
oftunableconstraints(i.e.,priorsinaBayesianmodel)ofasingle
nonlinear systems [16]–[18], highlighting further connections
cost functional, variational free energy.
Index Terms—PID control, active inference, Bayesian infer- between control and estimation. Notably, these extended du-
ence, optimal control, optimal tuning, performance-robustness alities often rely on more efficient variational approximations
trade-off commonly used in problems of inference. For instance, rele-
vantadvancesin stochastic optimalcontroland reinforcement
I. INTRODUCTION learning have been driven by the use of methods commonly
adopted to approximate intractable problems of Bayesian
In the last few decades, the importance of probabilistic
inference, e.g., variational Bayes. These methods have been
approaches to optimal control theory has been highlighted
shown to outperform standard dynamic programming and
by different applications of Bayesian methods to problems of
reinforcement learning algorithms for the control of different
control. In his pioneering work, Bellman introduced Markov
classes of problems [6], [16], [19], [20]. Building on these
decision processes [1] as part of what is now known as
ideas, a similar approach has been proposed and adopted in
stochastic optimal control [2]–[6]. This formulation captured
neuroscience in an attempt to characterise brain function and
theintrinsicprobabilisticnatureofproblemsofoptimalcontrol
sensorimotorcontrolunderaunifyingprobabilisticframework:
and decision making, with state transitions, outcomes and
active inference. While a full treatment of this framework is
actions/decisions that cannot always be easily described in
beyond the scope of the present work (for some technical
purely deterministic terms. Bellman’s approach extended on
reviews see, for instance, [21], [22]), we highlighthow active
his own work on the dynamic programming method for
inference combines methods from machine learning (varia-
(deterministic)optimalcontrol,definingtheBellmanequation,
tionalBayes),controltheory(stochasticcontrol)andstatistical
its uses and limitations, including the idea of the curse of di-
inference (hierarchicaland empirical Bayes) to form a theory
mensionality[7].Shortlyafter,Kalmanintroducedthenotions
that includes several existing results from different fields as
of observability and controllability of a system [8], with the
specialcases,frompredictivecoding,totheinfomaxprinciple,
formerexpressingthe degreeto whichstates canbe estimated
to statistical models of learning, to risk-sensitive and KL-
fromnoisyobservations,andthelatterrepresentingthedegree
control [22]–[27].
of control over a system when different manipulations are
Mostoftheseresultsrely,atthemoment,ontheapplication
applied. Kalman also noticed that his filter was dual to the
of(approximate)Bayesianapproachestooptimalcontrol,with
linearquadraticregulator(LQR),anowwellknownmethodin
MB is a JSPSInternational Research Fellow supported by a JSPS Grant- 1Alsoknownineconometrics ascertainty equivalence property[11],[12],
in-AidforScientific Research(No.19F19809). butsee[4]forapossibledistinction.
almostnomentionofclassical controlmethods.While classi- active inference, we thus defined a more explicit generative
cal methods can be seen as a special case of optimal control, model to describe an underlying stochastic process produc-
the possible advantages specific to Bayesian formulations of ing PID control as a gradient descent of a cost functional,
classical algorithms such as Proportional-Integral-Derivative variationalfree energy.While these two approaches, [34] and
(PID),remainlargelyunexplored.Inthisworkwelookatclas- [29], share a number of features, they also present some core
sicalcontrollersfromtheperspectiveofapproximateBayesian technical differences. Our proposal in fact includes:
inference, discussing the implications of variational Bayesian • a more direct interpretation of the control matrix R,
methodsforthefutureof,in particular,PID control[28]. This commonly used as a weight for the cost of control in
perspective has previously been adopted in, for instance, [29] the value (or cost-to-go) function [3], [4],
where a new gradient-based gain tuning rule was derived in • a gradient-based algorithm to optimise R, and
closed-formforoptimalregulationneartheset-point/reference • a generalisationto (some classes of) nonlinearproblems.
goal. In the next sections we present three cases in support
As shown in [32], [34], the control matrix R is particularly
of a new (Bayesian) framework to design and study classical
relevant for the computation of the gains of PID controllers,
control methods that ought to be seen as complementary
heretreatedaspartofthefeedbackmatrixofalinearquadratic
to existing ones, e.g., optimal control and frequency-domain
controller. In active inference, such gains correspond to spe-
analysis. We will first, briefly, 1) recapitulate the previously
cific hyperparametrisations of the linear state space (genera-
derived results for gain tuning introducing new connections
tive) model used to approximate the dynamics of the system
to path integral control and estimation in the presence of
tocontrol,i.e.,the(expected)precision,orinversecovariance,
biases, then 2) present a more formal and in depth treatment
of the observation noise [29]. This result is closely related
of the connections between PID controllers with two degrees
to Kalman’s duality of inference and control [8], [18], [35],
of freedom and Bayesian inference schemes, and finally 3)
highlighting the mathematical correspondence between the
focus on the open challenge of framing different competing
processes of stochastic estimation and deterministic control,
constraints of the performance-robustness trade-off in PID
At the same time, the active inference formulation extends
control, here defined in terms of priors and hyperpriors on
this duality beyond simply noting mathematical similarities,
a probabilistic generative model.
in order to include an account of the dual role of action in
II. CASE 1:A BAYESIAN DERIVATION OF PIDGAINS AND the context of exploration/exploitation problems [36], [37].
Furthermore, given the role of R as (expected) precision in
THEIROPTIMISATION
the generative model, the gain parameters of PID controllers
PID controllers are the most popular choice for SISO
can be optimised via a gradient descent on the same cost
systemsregulationindifferentareasofengineering[30].Their
functional,i.e.,variationalfreeenergy[29],followingasecond
popularity is mainly due to their simplicity and relatively
orderschemeintroducedin[38]that,undersomeassumptions,
low number of tunable parameters. However, despite only
holds also for some classes of nonlinear problems [24], [38].
including a few key parameters, or gains, their tuning (or
optimisation) remains largely an open challenge [28], [31]. III. CASE 2:PID CONTROL WITH 2DOFIN ACTIVE
Existing tuning methods are often limited to specific cases
INFERENCE
or applications, relying on (ad-hoc) analytical rules, simple
In many applications of PID control, it is often desirable
heuristics, frequencydomainanalysis, optimisation(including
to build regulators that can respond to external disturbances
the use of artificial neural networks) or a combination of the
while avoiding large fluctuations (e.g., overshooting) due to
above (for a survey, see [31]), that hardly generalise across
changes of the target of the regulation process. In standard
different classes of problems. Here we report a more general
PID control, these requirements are shown to be conflicting
method than can be explicitly derived by taking a different,
[39], [40] thus leading, in the most general case, to a multi-
Bayesian perspective on control problems.
objectiveoptimisationproblemwhosesolutionslieonaPareto
Previous work relating classical control to optimal ob-
front defined by
servers, and thus indirectly to Bayesian methods, showed
that the integral component of PID controllers corresponds • changesinthecontroltarget(i.e.,set-pointresponse),and
to a process of estimation of unknown (but linear/constant • changes in the amplitude of a step disturbance (i.e.,
or step) perturbations, equivalent to a Kalman-Bucy filter disturbance response).
with augmentedstate for the inference of unknowninputs (or Toovercomethelimitationsinducedbythistrade-off,previous
biases) [32], [33]. Using the same approach, this connection work (see [28], [40] and references therein) introduced the
was thengeneralisedto higherorderpolynomialdisturbances, idea of controllers with two degrees of freedom, or 2DOF,
equivalent to controllers including further integration terms PID. Multiple degrees of freedom obtained by augmenting
[34], i.e., corresponding to PIID, PIIID, etc. controllers. In controllers with multiple internal loops of PI or PID control
[29], we derived a fully probabilistic version of PID control, (seealsoequivalentexamplessuchasPI-PDcontrol[28]),then
highlighting in particular some of the relationships between ensure that different constraints can be treated independently,
integral control and an emerging framework in computational using parameters from different sub-loops to encode separate
and cognitive neuroscience,active inference [25], [26]. Using desired behaviours [28], [40].
Our probabilisticderivationofPID controlvia a variational algorithmsfromestimationtheorysuchasKalman-Bucyfilters
approximation of Bayesian inference showcases a clear and [45], and equivalent to feedback and feedforward loops in
directinterpretationofthepresenceoftwodegreesoffreedom, 2DOF PID controllers [40]. In this set up, PID controlwith a
here derived using rather general arguments. Unlike previous single degree of freedom can be derived as the limit case for
proposals, one need not augment a controller with an extra fully observable states, i.e., y˜ = x˜ (cf. state feedback meth-
feedforward component that can separate the effects of a ods in [30]). The independence of set-point and disturbance
compensator for disturbances or set-point changes [40]. In responsescrucialfor 2DOF PID controllersthen corresponds,
active inference, the existence of two degrees of freedom is a in this framework, to a generative model having system and
simpleconsequenceoftheprobabilistic(Bayesian)description measurement noise independent of one another, a standard
of the generative model used to derive a controller [29]. This assumption for linear state space models.
becomes more obvious after looking at the variational free
IV. CASE 3:THE PERFORMANCE-ROBUSTNESS TRADE-OFF
energy (see equation (13) in [29]) here reported as2
FORPID CONTROLLERS UNDERACTIVE INFERENCE
1 2 ′ 2 The presence of conflicting criteria for the design of PID
F ≈ µ y˜−g(µ˜ ,µ˜ ) +µ µ˜ −f(µ˜ ,µ˜ )
2(cid:20) πz˜ (cid:16) x v (cid:17) πw˜ (cid:16) x x v (cid:17) (cid:21) controllerisawellknownissueinthecontroltheoryliterature
(1) [46], as partially highlighted in the previous section. This
conflict is often referred to as the performance-robustness
where y,µ ,µ are observations (or measurements), and ex-
x v
trade-off [28], [47], [48]. Controllers are usually designed to
pectedhiddenstates(theestimateofthestate ofthesystem to
optimise some given performance criteria while, at the same
regulate) and inputs (the set-point) respectively. Hyperparam-
time, attempting to maintain a certain level of robustness
eters µ ,µ are the expectedprecisionson observationand
πz πw
in face of uncertainty and unexpected conditions during the
system noise, and f(),g() are state transition and observation
regulationprocess.Theperformanceofacontrollerisnormally
functions. The tilde simply highlights a notation used to
assessedusingoneormoreofthefollowingcriteria[28],[47]:
group different derivatives, or rather embeddings orders, of
a variable, e.g., y˜ = {y,y′,y′′ }, see [29] for more details. • load disturbance response, or how a controller reacts to
changes in external inputs, e.g., a step input,
The simplified (i.e., under Gaussian assumptions) variational
free energy functional in (1) contains two sets of prediction • set-point response, or how a controller responds to dif-
ferent set-points over time,
errors,essentiallyinstantiatingtwodegreesoffreedomforthe
controller. Notice that unlike equation (13) in [29], here we • measurement noise response, or how noise on observa-
tions impacts the regulation process,
explicitly replaced π z˜,π w˜ with µ πz˜ ,µ πw˜ from the beginning,
to highlight the fact that hyperparameters µ ,µ are only while robustness is mainly evaluated based on:
πz˜ πw˜
estimates of some “true” hyperparameters π z˜,π w˜. This fol- • robustness to model uncertainty, or how uncertainty on
lows from a full Bayesian treatment of the control problem, plant/environmentdynamics affects the controller.
consideringallvariablestoberandomvariables[41](cf.tradi- Thegoalofageneralmethodologyforthedesignandtuningof
tional point-estimates in frequentist frameworks for statistical PID controllersis to bring together these (and possibly more)
learning).In ourcase, to simplifythe mathematicaltreatment, criteria into a formal, unified and tractable framework that
we treat them as Gaussian random variables with means can be applied to a large class of compensationproblems. An
µ πz˜ ,µ πw˜ (andcovariancestobediscussedinthenextsection). example in this direction is presented in [49] (see also [50]–
Importantly, these expectations are updated on a slower time [52] for other partial attempts). This methodology is based
scale [29], following schemes found in [23] and in particular on the maximisation of the integral gain (equivalent, near the
[38], emphasising how parameters and hyperparameters of a referencepoint,totheminimisationoftheintegraloftheerror
generative model ought to be considered as fixed quantities from the set-point [39]), subject to constraints derived from
over a certain (i.e., long) time scale. a frequency domain analysis related to the Nyquist stability
The two sets of prediction errors, µ y˜−g(µ˜ ,µ˜ ) and criterion applied to the controlled system [49]. Here, we
πz˜ x v
(cid:16) (cid:17) propose our Bayesian formulation as an alternative (and in
µ µ˜ ′ −f(µ˜ ,µ˜ ) weighted by hyperparametersµ and
πw˜ x x v πz˜ manycases complementary)frameworkfor the design of PID
µ ,(cid:16)represent likeli(cid:17)hood and prior of a Bayesian update
πw˜ controllers that leverages the straightforward interpretation of
scheme formulated using generative models under Gaussian
the performance-robustness trade-off for PID controllers in
assumptions, the Laplace [42] and the variational Gaussian
terms of uncertainty parameters (i.e., hyperparameters, pre-
[43] approximations (to clarify their role see discussion in
cisions or inverse covariances) in the variational free energy
Chapter 3 of [27]). The update equations minimising these
[29]. To highlight its potential, we discuss the four standard
predictionerrors[29] (also called recognitiondynamics[44]),
criteria listed above as part of performance-robustness trade-
are similar to the update and prediction steps of standard
offtoaddresswhatcanbegainedusingaBayesianperspective.
2Someterms in the free energy functional are hereby dropped forclarity. A. Load disturbance response
For the treatment of an extra set of terms important for the optimisation of
A classic design principle for PID controllers is based
PIDgains,see[29].Foramorecompletediscussionofothertermswhichare
constant duringtheoptimisation phase,see[21],[23],[38]. on the response of a controller to perturbations that drive
a process away from the target value [39]. Random, zero- ofk ,withoutanyconstraints,correspondstotheminimisation
i
meandisturbancesarecommonlymodelledaswhiteGaussian of the expected measurementvariance µ , such that t→∞,
σz
variables, and the parameters of the controller are simply
µ →0. (4)
tuned to reject such noise. Integralcontrolthen guaranteesan σz
appropriate response to step disturbances, equivalent to non- In practice, however, one should always consider a certain
zero-mean noise (or to a bias term [33]), by accumulating level of intrinsic, i.e., aleatoric, uncertainty whose variance
andcompensatingfortheensuingsteady-stateerror[32],[39], is fundamentallyirreducible.Even an optimal controller can’t
[53], [54]. The load disturbanceresponseis usually expressed overcomethe limited sensitivity of a sensor (here represented
intermsofaminimisationoftheIntegralAbsoluteError(IAE) by the “real” σ , as opposed to its estimate µ ), bringing
z σz
between the state of the system to regulate and its target: µ down to 0 is thus not possible if σ > 0. In other
σz z
proposals[49],thesamealeatoricuncertaintyσ iseffectively
∞ z
approximated with a measure that captures the levels of
IAE = |e(t)| dt (2)
Z controllabilityofasystemthroughthedefinitionofappropriate
o
sensitivity functions in the frequency domain.
or approximatedby the IntegralError (IE) for non-oscillating
Our Bayesian implementationalso extendsthe intuitionbe-
or oscillating but well-damped systems [39]:
hindtheintegralgainasaprecisionofobservationstotheother
two gains, k and k . In our formulation,these gains become
∞ p d
IE = e(t)dt (3) infactestimatedprecisionsofhigherembeddingordersofthe
Z o observations, y′,y′′, often also called generalised coordinates
of motion [23], [38]. These embedding orders essentially
The IE criterion is especially relevant because it gives a
represent a Taylor expansion (in time) of continuous random
straightforward intuition of the role of integral gain since,
variablesdefined according to a Stratonovich(rather than Ito)
under a few simplifying assumptions (including a system’s
interpretation,equivalentto non-Markovian(semi-Markovian,
initial state close to the target value), the IE is equal to the
of Markovian of order n) stochastic processes [24], [29],
inverse of k as t → ∞ [39]. This implies that for large
i [45]. In practice, for measurements taken at a high enough
(theoretically, infinite) integral gains, the IE is minimised.
frequency,andwithcontrollershavingashortenoughintrinsic
While useful for its straightforward interpretation of this free
timescale toregulatesuchhighfrequencymeasurements(i.e.,
parameter, practical and physical limitations often restrict the
atimescale approachingtheunderlyingcontinuousmodelsof
maximisation of the integral gain.
thesystemstoregulate),observationnoiseshouldbetreatedas
Our formulation builds on previous work showing how the
coloured,ratherthan white as in standarddelta-autocorrelated
use of integral control is optimal for unknown step pertur-
noise. Under these assumptions, the implementation of PID
bations applied to a system [32], [54]. In statistical terms,
control and its extensions (e.g., multiple I and D terms)
the presence of such disturbances can be formally seen as a
becomes simply a linear approximation of a measured non-
biasterminanestimationprocess[55],showinghowrejecting
Markovian trajectory. Perhaps in a more intuitive way, we
(step) perturbations is equivalent to estimating biases [33]. In
can see expected precisions µ = {µ ,µ ,µ } as
active inference we can extend this (exact) result for linear
πz˜ πz πz′ πz′′
simultaneously 1) representing the precision of a trajectory
systems and disturbances to nonlinear cases (not limited to
in the state-space (rather than the precision on a point) and
polynomial perturbations as in [34]), where a more general
2) regulating the convergence rate of measurements to a
(but often only approximate or limited to special classes of
set-trajectory (rather than point), specifying how quickly a
nonlinearities) duality of estimation and control is obtained
controller ought to respond to a sudden change in a set of
using variational and path integral formulations [16], [18], or
observations and their higher orders of motion.
via probability integral transforms in the form of hierarchical
generative models [24]. B. Set-point response
Furthermore, in our (Bayesian) formulation we gain a Following the load disturbance rejection property,a second
second and arguably deeper intuition on the role of the performance criterion used for the design of PID controllers
integral gain, which is now explicitly represented as one of is their set-point response, i.e., how controllers respond to
theexpectedprecisions(orinversecovariance)ofobservations variations in the set value used as a target to regulate a
y˜, i.e., µ , see [29]. This prescribes a simple and alternative system. Naively, this could be seen as closely related to load
πz
way of understanding why the maximisation of k is usually disturbances: rather than changes in the measurement, we
i
a goodheuristic for regulationproblemswhere PID controlis now have changes in the target value, both of them used to
used [28]: maximising k is in fact equivalent to minimising define some error term, e. In practice however, it is desirable
i
uncertainty on measurements y, by maximising (minimising) to decouple these two problems, creating a controller with
theexpectedprecisionµ (varianceµ )ofthemeasurements differentsensitivities to load disturbancesor set-pointupdates
πz σz
of the system to regulate. At the same time, this can also whenever necessary [39]. This requires a controller with two
explain some of the limitations of this heuristic, discussed in degreesof freedom,as discussed in more detail in section III,
the frequency domain for instance in [49]. The maximisation whichisaninherentfeatureoftheactiveinferenceformulation
where expectations of hidden states µ˜ are updated using a introducing informative priors on expected precisions µ ,
x πz˜
(Bayesian) scheme that balances (via a set of independent i.e.,hyperpriorsη 3 (ormorecomplicatedfunctionsh(η )),
πz˜ πz˜
expected precisions, or weights) prediction errors on both see [24] for a formal treatment. The variational free energy
functional then includes another set of prediction errors, (cf.
• observations, µ πz˜
(cid:16)
y˜ − g(µ˜ x ,µ˜ v )
(cid:17)
, where load distur-
(1)),
bances can appear as part of the measurements y˜, and
• system dynamics, µ πw˜ µ˜ ′ x − f(µ˜ x ,µ˜ v ) , where set- F ≈ 1 µ y˜−g(µ˜ ,µ˜ ) 2 +µ µ˜ ′ −f(µ˜ ,µ˜ ) 2
trajectories can be updat (cid:16) ed as inputs/prior (cid:17) s µ˜ v . 2(cid:20) πz˜ (cid:16) x v (cid:17) πw˜ (cid:16) x x v (cid:17)
2
Mirroring the role of µ for load disturbances, expected
πz˜ +µ µ −h(η ) (5)
precisions µ πw˜ on dynamic prediction errors effectively im-
pz˜
(cid:16)
πz˜ πz˜
(cid:17) (cid:21)
plement a response mechanism to set-trajectories updates,
with high expected precisions implying a fast response, and withµ pz˜ µ πz˜ −h(η πz˜ ) playingtheroleofL2(orTikhonov)
(cid:16) (cid:17)
low precisions entailing a slow one. Equivalently, from a regularisation terms for the ensuing recognition dynamics
probabilistic perspective this can be explained with the idea derived as a gradient descent on (5). Using these prediction
that the former describes a model with low uncertainty on errorsonecaneffectivelyencode,forinstance,constraintsthat
dynamics(high precision= low covariance)meaning that any reject strong high frequency noise by specifically targeting
variationfromsuchdynamicsshouldquicklybedealtwith;the frequentlargeinstantaneousfluctuationsofexpectedprecision
latter encodes, on the other hand, the fact that high expected µ , penalising them with a Gaussian hyperprior (an L2
πz˜
covariance allows for changes in set-trajectories, i.e., sudden regularisation term that affects “outliers”) centred at η .
πz˜
updatesarenotsurprising,thereforechangescanbeslow(and While such hyperpriorwouldcertainly then also influence the
in the limit for very large covariances, almost absent). responsetosparsestepchanges,expectedprecisionsµ could
πz˜
beupdatedbyslowlyshiftinghyperpriorsη toreflectbiases
πz˜
C. Measurement noise response
in measurements y˜ that persist over a long period of time.
A third common requirement for PID controllers is re- Importantly, while the cost functional presents in this case
lated to their performance in face of noisy or uncertain somenewterms,theunderlyingminimisationschemeremains
measurements. These may be due, for instance, to physical the same: the recognition dynamics will simply include extra
constraints/sensitivities of the sensors. In the literature, high regularisationtermswhilestillfollowingagradientdescenton
frequency measurement noise [30] is usually tackled via a the (augmented) variational free energy.
careful and ad-hoc controller design, including for example In the same way expected precisions µ regulate the re-
πz˜
pre-filteringofthe observeddata[47].IntheBayesian formu- sponsetochangesintheobservationsduetoloaddisturbances,
lation of PID controllers that we introduced,we have a direct expectedprecisionsonhigherorderstochasticproperties(e.g.,
measure of (the best estimate of) the measurement noise: the expected precisions on expected precisions, µ ) can then be
pz˜
expected precision or inverse covariance µ of the random seen as regulating how a controller adapts to varying levels
πz˜
variablez anditshigherordersofmotion.Measurementnoise of measurement noise covariance given some (informative)
is thus related to the same set of hyperparameters used to priors h(η ). For example, in cases where the variance
πz˜
explain load disturbances rejection which, on the other hand, of measurement noise changes over time, e.g., due to the
canbeseenaslowfrequencynoise.Thisshowsanothertrade- natural degradation of sensors, our formulation can include
off between design criteria, in this case related to the high mechanisms that take into account existing prior knowledge
frequency properties of measurement noise and the (usually) and that can be used by a controller to dynamically adapt
low frequency of external disturbances. to new levels of noise. More in general, in the presence of
The previously identified maximisation of expected preci- stochastic volatility (i.e., models where the covariances of
sion µ (integral gain k ) implies an increased cutoff fre- different random variables are themselves random variables
πz i
quencyofthelow-passfilterimplementedbylineargenerative [41]), one can easily encode prior knowledge of higher order
modelsof the kind we introducedto approximatePID control propertiesof random variablesby including extra hierarchical
[56].Thissuggeststhat,whilelow-frequencydisturbancescan layersonthegenerativemodelwe introducedforPIDcontrol.
be suppressed more quickly (even if at the cost of possibly
overshooting),this comesat the expensesof a “hypersensitiv- D. Robustness to model uncertainty
ity” to high-frequencynoise, i.e., not rejecting as much noise PIDcontrollersareusuallydesignedtowithstandsomelevel
as otherwise possible with slower load disturbance responses of model uncertainty, inherent in any system we observe,
(as shown in a simple model, for instance, in [56]). In our interact with and try to regulate. In control theory, this
framework, this can easily be noticed by looking at the role problemaffects compensatorsattempting to regulate a system
playedbyexpectedprecisionµ πz˜ inthetimedomain,encoding while having access only to a limited amount of information
expectedvariabilityinobserveddatawithoutacleardistinction regardingthedynamicsofthesystemitself.PIDcontrollersare
between rare perturbations and persistent noise. especiallypopularasa“modelfree”strategy,orrather,forthe
Atthesametime,however,theactiveinferenceformulation
can be used to treat this problem in a more principled way, 3Tomaintain anotation similartotheoneusedin[24],[29].
small number of tunable parameters that are necessary to af- V. DISCUSSION
fordrobust,althoughoftensuboptimal,control[46].Incontrol
The duality of estimation and control has long been recog-
problems,thisrobustnessissometimescapturedbysensitivity
nisedandexploitedinproblemsofregulationunderconstraints
functions[47],[49],providingaproxyfor,amongotherthings,
of partial observability, i.e., stochastic control [3], [4], [10],
the sensitivity of a feedback system to variations in models
[16], [18], [35]. This property relies on the mathematical
of process dynamics. In our derivation of PID control as a
equivalenceofsomeclassesofestimationandregulationprob-
process of Bayesian (active) inference, the uncertainty of the
lems, formulated as Bayesian inference and optimal control
dynamics is represented by the expected precisions of system
respectively. The applications of this duality have led to a
dynamics,µ ,inthelineargenerativemodeldefinedin[29].
πw˜ series of significant new results in different areas, such as
For instance, low expected precisions µ , expressing high
πw˜ reinforcement learning [20], robotics [59] and neuroscience
uncertainty/covariance,encodethe(Bayesian)beliefthatlarge
[14] where methods of approximate Bayesian inference are
fluctuations in the dynamics can be expected, while high ex-
nowoftenemployedtoimproveexistingsolutions.Inthiswork
pected precisions express the fact that dynamics should show
we built on some of these previous ideas, discussing possible
only small fluctuations. Moreover, using our formulation we
applicationsofBayesianinferencetheoriesandrelatedapprox-
candescribethebehaviourofaPIDcontrollersuchthatunder
imations to methods from classical control. In particular, we
controllability assumptions [4], [8], it effectively “imposes”
focused on PID control and on our previous implementation
its own (linear) dynamics/priors on a system through larger
of this method in terms of Bayesian active inference [29],
weighted prediction errors µ πw˜ µ˜ ′ x −f(µ˜ x ,µ˜ v ) , by forcing proposingthisas a generalunifyingframeworkfor the design
(cid:16) (cid:17)
it into an attractor encoded in the set-trajectory represented of PID controllers still largely missing to date [28], [31].
by the controller’s priors. The state of affairs of the world is In [29] we recently introduced a gradient-based procedure
only partially relevant to a PID controller, since as long as for gain tuning, using an interpretation of these parameters
conditionsofreachabilityandcontrollability[4]aremet,allit as stochastic properties (i.e., expected precisions, or inverse
doesistrytodrivea(controllable)systemtowardsthedesired variances) of the system to regulate. Here we expanded on
equilibrium encoded by its priors on a set-trajectory. this formulationby providingdirect links to Kalman’sduality
Asinthecaseofmeasurementnoise,ourformulationallows [8],[18],[35]andBayesianestimationinthepresenceofbias
for the constructionof an extra layer of hyperpriorsto handle terms, i.e., unknown step inputs [33].
modeluncertainty:in the active inference formulationwe can We then discussed standard problems such as the necessity
in fact include priorson expectedprecisions µ to represent of two degrees of freedom in order to afford independent
πw˜
existing information on the expected/desired dynamics of a responsestoloadandset-pointchanges[40].Usingtheproba-
system to regulate bilisticinterpretationgivenin[29],wethendrewacomparison
between a pragmatic introduction of two degrees of freedom
1 2 2 [40], represented by feedback and feedforward sub-loops in
′
F ≈ µ y˜−g(µ˜ ,µ˜ ) +µ µ˜ −f(µ˜ ,µ˜ )
2(cid:20) πz˜
(cid:16)
x v
(cid:17)
πw˜
(cid:16)
x x v
(cid:17)
standard 2DOF PID control, and the more principled formu-
lation of active inference, aligned with update and prediction
2
+µ µ −k(η ) (6) equationsoffilteringalgorithms(e.g.,Kalman-filters[9]),and
pw˜
(cid:16)
πw˜ πw˜
(cid:17) (cid:21) the use of priorand likelihooddensitiesin recursiveBayesian
update schemes [45].
Forinstance,itis nothardto imaginethat,followingstandard
Crucially, we then proposed to frame one of the major
hierarchicalorempiricalBayesmethodsinstatisticalinference
open challenges for methods like PID control, the general
[41], information on existing control problems could be used
performance-robustness trade-off due to the presence of con-
todefineclassesofsystemswhosesharedstatisticalproperties
flicting design criteria [28], [31], in terms of variational free
form generic priors η . These priors could then be used
πw˜ energy minimisation [17], [23], [29], [38], [60]4
to initialise our model in a suitable part of the state space
to ensure a desired level of robustness (and if a similar 1 2 ′ 2
F ≈ µ y˜−g(µ˜ ,µ˜ ) +µ µ˜ −f(µ˜ ,µ˜ )
approach were to be adopted for η
πz˜
, to guarantee some 2(cid:20) πz˜
(cid:16)
x v
(cid:17)
πw˜
(cid:16)
x x v
(cid:17)
desired performances). In such settings, expected precisions 2 2
+µ µ −h(η ) +µ µ −k(η ) (7)
µ
πw˜
can still be optimised via a simple gradientdescent, now pz˜
(cid:16)
πz˜ πz˜
(cid:17)
pw˜
(cid:16)
πw˜ πw˜
(cid:17) (cid:21)
L2-regularisedwith newly introducedpriorsenteringthe vari-
In this formulation, simple constraints (load disturbance re-
ationalfreeenergyequationintheformofweightedprediction
sponse and set-point change response) can easily be mapped
errors, µ µ −k(η ) . This approach, especially when
pw˜ πw˜ πw˜ to first order weighting parameters on the mean estimates of
(cid:16) (cid:17)
employing empirical Bayes, is similar in spirit to the clever
the state of the system to regulate. More complex ones, on
initialisation achieved in deep learning approaches via “pre-
the other hand, (measurement noise response and robustness
training”, where introducing an unsupervised learning phase
tomodeluncertainty)canbeintroducedin termsof stochastic
before supervised training showed substantial improvements
volatility [41], i.e., by treating second moments (expected
in the performance and generalisation properties of neural
networks [57], [58]. 4Thefollowing equation combines (5)and(6).
precisions, or hyperparameters) as random variable having gives an interpretation of a series of different constraints as
appropriatehyperpriorsencodedinthegenerativemodel.This first and second order properties of a generative model that
mapping provides an immediate understanding of different generatesaPIDcontrollerasagradient-basedminimisationof
desired statistical properties of the system to govern (see a single cost functional, variational free energy. In the future,
table I), now summarised in Table I. wewillfocusonsimulationstestingthecurrentproposalusing
standard control benchmarks and following a vast literature
TABLE I: Active inference as a general framework for PID on Bayesian models (see [24], [41] and references therein).
controllers design (adapted from [29] and here extended). We will then also draw more direct connections to modern
machine and reinforcement learning, combining the present
Criterion Mapped to Interpretation in Active Inference
workwithmethodsfrom[61],wherepreliminaryresultsbased
Load Expectedinversecovarianceoftheobserva- on these and other ideas are utilised in the field of deep
disturbance µπz˜ tions (i.e., precision), with low covariance
reinforcementlearningwith large neuralnetworksperforming
response implyingafastresponse,andviceversa
amortised inference.
Two degrees of freedom derived from the
Set-point presence of two sets of prediction errors,
change µπw˜ sensory and dynamics, mapping to likeli-
REFERENCES
response hood and priors of a Bayesian inference
[1] R.E.Bellman,“Amarkoviandecisionprocess,”JournalofMathematics
process
andMechanics, pp.679–684,1957.
Direct mapping of measurement noise to [2] K.J.A˚stro¨m,Introductiontostochasticcontroltheory. AcademicPress,
inversecovariance oftheobservations (i.e., 1970.
Measurement
(priorson) precision), with hyperpriors (priors on ex- [3] B. Anderson and J. B. Moore, Optimal control: linear quadratic
noise
response
µπz˜ pected precisions) introduced to differen- methods. Prentice-Hall, Inc.,1990.
tiate high frequency noise from low fre- [4] R. F. Stengel, Optimal control and estimation. Courier Corporation,
quencydisturbances 1994.
[5] E. Todorov, “Optimal control theory,” Bayesian brain: probabilistic
Direct mapping of model uncertainty to
approaches toneuralcoding,pp.269–298,2006.
expectedcovariancesofsystemfluctuations,
[6] H.J.Kappen,OptimalcontroltheoryandthelinearBellmanequation.
representing the hidden dynamics of the
CambridgeUniversity Press,2011,p.363387.
Robustness systemtocontrol,withhyperpriorsthatcan
(priorson) [7] R. E. Bellman, Dynamic Programming. Courier Dover Publications,
to model describe initial knowledge of, forexample,
uncertainty
µπw˜
aclassofsimilarregulationproblemstofa-
1957.
[8] R. E. Kalman, “Contributions to the theory of optimal control,” Bol.
cilitatetheoptimisationofstates/parameters
Soc.Mat.Mexicana, vol.5,no.2,pp.102–119,1960.
(similar to the role of unsupervised “pre-
[9] ——, “A new approach to linear filtering and prediction problems,”
training” indeeplearning [58])
JournalofbasicEngineering, vol.82,no.1,pp.35–45,1960.
[10] W.M.Wonham,“Ontheseparationtheoremofstochasticcontrol,”SIAM
JournalonControl,vol.6,no.2,pp.312–326, 1968.
[11] H.A.Simon,“Dynamicprogrammingunderuncertaintywithaquadratic
VI. CONCLUSION AND FUTURE WORK
criterion function,” Econometrica, Journal of the Econometric Society,
Inaninfluentialpaper,A˚stro¨mandHa¨gglundaskedwhether pp.74–81,1956.
[12] H. Theil, “A note on certainty equivalence in dynamic planning,”
PID control can play a role in the future of control theory Econometrica:JournaloftheEconometricSociety, pp.346–349,1957.
and engineering [28]. Despite being the most used controller [13] F. L. Lewis, D. M. Dawson, and C. T. Abdallah, Robot manipulator
control:theoryandpractice. CRCPress,2003.
in industry, the emergence of more specialised and better
[14] E.TodorovandM.I.Jordan,“Optimalfeedbackcontrolasatheoryof
performing methods over the years, such as model predictive
motorcoordination,”Natureneuroscience,vol.5,no.11,p.1226,2002.
control, cast doubts on its long term applications and uses. [15] E.Todorov,“Stochasticoptimalcontrolandestimationmethodsadapted
A˚stro¨mandHa¨gglundhoweverarguedthatduetoitscombined tothenoisecharacteristics ofthesensorimotorsystem,”Neuralcompu-
tation, vol.17,no.5,pp.1084–1108, 2005.
effectiveness and simplicity, PID is likely to remain relevant
[16] S. K. Mitter and N. J. Newton, “A variational approach to nonlinear
for the foreseeable future, perhaps in conjunction with other estimation,” SIAMjournal on control and optimization, vol. 42, no. 5,
methods. At the same time, they highlighted a series of pp.1813–1833, 2003.
[17] H. J. Kappen, “Linear theory for control of nonlinear stochastic sys-
existingproblemsandopenchallengesfacedbyPID,including
tems,”Physicalreviewletters, vol.95,no.20,p.200201, 2005.
a relativelylimited numberof theoreticalresultsin areassuch [18] E.Todorov,“General duality between optimal control and estimation,”
asgaintuningandgeneral(PID)controllerdesign.Inthiswork inDecision and Control, 2008. CDC 2008. 47th IEEEConference on.
IEEE,2008,pp.4286–4292.
webuiltonourpreviousformulationofPIDcontrolintermsof
[19] H.Attias,“Planningbyprobabilistic inference.”inAISTATS. Citeseer,
activeinference,amoderntheorycombiningstochasticcontrol 2003.
and probabilistic Bayesian inference under the umbrella of [20] E.Todorov,“Efficient computation ofoptimal actions,” Proceedings of
thenational academy ofsciences, vol. 106,no.28, pp.11478–11483,
variational free energy minimisation, to propose new appli-
2009.
cations of Bayesian methods to PID controllers in order to [21] C.L.Buckley,C.S.Kim,S.McGregor,andA.K.Seth,“Thefreeenergy
establish a more general design framework. After introducing principleforactionandperception:Amathematicalreview,”Journalof
Mathematical Psychology, vol.14,pp.55–79,2017.
anewpracticalimplementationofoptimalgaintuningin[29],
[22] L.DaCosta,T.Parr,N.Sajid,S.Veselic,V.Neacsu,andK.J.Friston,
here we extended our proposal highlighting the connections “Active inference on discrete state-spaces: a synthesis,” arXiv preprint
between different design principles for PID, from the impor- arXiv:2001.07203, 2020.
[23] K.J.Friston,N.Trujillo-Barreto,andJ.Daunizeau,“DEM:Avariational
tance of multiple degrees of freedom to optimal tuning with
treatmentofdynamicsystems,”NeuroImage,vol.41,no.3,pp.849–885,
conflicting performance-robustness criteria. This framework 2008.
[24] K. J.Friston, “Hierarchical models inthe brain,” PLoSComputational [52] R. T. O’Brien and J. M. Howe, “Optimal PID controller design using
Biology, vol.4,no.11,2008. standardoptimalcontroltechniques,”inProceedingsofthe2008Amer-
[25] ——, “The free-energy principle: a unified brain theory?” Nature icanControlConference. IEEE,2008,pp.4733–4738.
reviews.Neuroscience, vol.11,no.2,pp.127–138,2010. [53] B. A. Francis and W. M. Wonham, “The internal model principle of
[26] K.J.Friston,T.FitzGerald,F.Rigoli,P.Schwartenbeck,andG.Pezzulo, controltheory,”Automatica, vol.12,no.5,pp.457–465, 1976.
“Activeinference:aprocesstheory,”NeuralComputation,vol.29,no.1, [54] E.D.Sontag, “Adaptation andregulation withsignal detection implies
pp.1–49,2017. internalmodel,”Systems&controlletters, vol.50,no.2,pp.119–126,
[27] M. Baltieri, “Active inference: building a new bridge between control 2003.
theory and embodied cognitive science,” Ph.D. dissertation, University [55] B. Friedland, “Treatment ofbias inrecursive filtering,” IEEETransac-
ofSussex,2019. tionsonAutomaticControl, vol.14,no.4,pp.359–367,1969.
[28] K. J. A˚stro¨m and T. Ha¨gglund, “The future of PID control,” Control [56] B. W. Andrews, T.-M. Yi, and P. A. Iglesias, “Optimal noise filtering
in the chemotactic response of Escherichia coli,” PLoS Comput Biol,
engineering practice, vol.9,no.11,pp.1163–1175, 2001.
vol.2,no.11,p.e154,2006.
[29] M. Baltieri and C. L. Buckley, “PID control as a process of active
[57] I.HarveyandJ.V.Stone,“UnicyclinghelpsyourFrench:Spontaneous
inference with linear generative models,” Entropy, vol. 21, no. 3, p.
recoveryofassociations bylearningunrelated tasks,”NeuralComputa-
257,2019.
tion,vol.8,no.4,pp.697–704, 1996.
[30] K.J.A˚stro¨mandR.M.Murray,Feedbacksystems:anintroduction for
[58] Y.LeCun,Y.Bengio,andG.Hinton,“Deeplearning,”nature,vol.521,
scientists andengineers. Princeton university press,2010.
no.7553,pp.436–444, 2015.
[31] K.H.Ang,G.Chong,andY.Li,“PIDcontrolsystemanalysis,design,
[59] E. A. Theodorou, J. Buchli, and S. Schaal, “A generalized path inte-
and technology,” IEEE transactions on control systems technology,
gral control approach to reinforcement learning,” Journal of machine
vol.13,no.4,pp.559–576, 2005.
learningresearch,vol.11,no.Nov,pp.3137–3181,2010.
[32] C. D. Johnson, “Optimal control of the linear regulator with constant [60] E. A. Theodorou and E. Todorov, “Relative entropy and free energy
disturbances,” IEEETransactions onAutomaticControl, vol.13,no.4, dualities: Connections to path integral and kl control,” in 2012 IEEE
pp.416–421, 1968. 51stIEEEConference onDecision andControl (CDC). IEEE,2012,
[33] ——,“Onobserversforsystemswithunknownandinaccessibleinputs,” pp.1466–1473.
International journalofcontrol,vol.21,no.5,pp.825–831,1975. [61] A.Tschantz,M.Baltieri, A.Seth,C.L.Buckleyetal.,“Scalingactive
[34] ——,“Furtherstudyofthelinearregulatorwithdisturbances–Thecase inference,” arXivpreprintarXiv:1911.10601, 2019.
of vector disturbances satisfying a linear differential equation,” IEEE
Transactions onAutomaticControl, vol.15,no.2,pp.222–228,1970.
[35] R. E. Kalman, “On the general theory of control systems,” in Pro-
ceedingsFirstInternationalConferenceonAutomaticControl,Moscow,
USSR,1960.
[36] Y.Bar-ShalomandE.Tse,“Dualeffect,certaintyequivalence, andsep-
arationinstochasticcontrol,”IEEETransactionsonAutomaticControl,
vol.19,no.5,pp.494–500, 1974.
[37] M.BaltieriandC.L.Buckley,“OnKalman-Bucyfilters,linearquadratic
control andactive inference,” arXivpreprintarXiv:2005.06269, 2020.
[38] K. J. Friston, K. Stephan, B. Li, and J. Daunizeau, “Generalised
filtering,” Mathematical ProblemsinEngineering, vol.2010,2010.
[39] K. J. A˚stro¨m, PID controllers: theory, design and tuning. Research
TrianglePark,1995.
[40] M. Araki and H. Taguchi, “Two-degree-of-freedom PID controllers,”
InternationalJournalofControl,Automation,andSystems,vol.1,no.4,
pp.401–411, 2003.
[41] C.Robert,TheBayesianchoice:fromdecision-theoretic foundations to
computational implementation. Springer Science & Business Media,
2007.
[42] D. J. MacKay, Information theory, inference and learning algorithms.
Cambridge university press,2003.
[43] M.OpperandC.Archambeau,“ThevariationalGaussianapproximation
revisited,” Neuralcomputation, vol.21,no.3,pp.786–792,2009.
[44] C. S. Kim, “Recognition dynamics in the brain under the free-energy
principle,” NeuralComputation, vol.30,no.10,pp.2616–2659, 2018.
[45] A.H.Jazwinski,StochasticProcessesandFilteringTheory. Academic
Press,1970,vol.64.
[46] D.E.Rivera,M.Morari,andS.Skogestad,“Internalmodelcontrol:PID
controller design,” Industrial & engineering chemistry process design
anddevelopment, vol.25,no.1,pp.252–265,1986.
[47] K. J. A˚stro¨m and T. Ha¨gglund, Advanced PID control. ISA-The
Instrumentation, Systems, and Automation Society Research Triangle
Park,NC,2006.
[48] O. Garpinger, T. Ha¨gglund, and K. J. A˚stro¨m, “Performance and ro-
bustnesstrade-offsinPIDcontrol,”JournalofProcessControl,vol.24,
no.5,pp.568–577,2014.
[49] K. J. A˚stro¨m, H. Panagopoulos, and T. Ha¨gglund, “Design of PI
controllers based on non-convex optimization,” Automatica, vol. 34,
no.5,pp.585–601,1998.
[50] M. Zhuang and D. Atherton, “Automatic tuning of optimum PID
controllers,” inIEEProceedings D(Control Theory andApplications),
vol.140,no.3. IET,1993,pp.216–224.
[51] M.GrimbleandM.Johnson,“AlgorithmforPIDcontrollertuningusing
LQGcostminimization,” inProceedingsofthe1999AmericanControl
Conference, vol.6. IEEE,1999,pp.4368–4372.