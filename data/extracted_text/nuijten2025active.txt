Active Inference is a Subtype of Variational Inference
Wouter W. L. Nuijten1,2 Mykola Lukashchuk1∗
1Department of Electrical Engineering, Eindhoven University of Technology, the Netherlands
2Lazy Dynamics, Utrecht, the Netherlands
w.w.l.nuijten@tue.nl
Abstract
Automated decision-making under uncertainty requires balancing exploitation and
exploration. Classical methods treat these separately using heuristics, while Ac-
tive Inference unifies them through Expected Free Energy (EFE) minimization.
However, EFE minimization is computationally expensive, limiting scalability.
We build on recent theory recasting EFE minimization as variational inference,
formally unifying it with Planning-as-Inference and showing the epistemic drive
as a unique entropic contribution. Our main contribution is a novel message-
passing scheme for this unified objective, enabling scalable Active Inference in
factored-state MDPs and overcoming high-dimensional planning intractability.
1 Introduction
Automated decision-making under uncertainty is a central, long-standing challenge across control
theory and artificial intelligence. When the system dynamics are well-known and deterministic,
classical methods like Optimal Control [Bellman, 1954] and Model Predictive Control (MPC) [Cut-
ler and Ramaker, 1979] provide principled frameworks for determining optimal actions. These
approaches, focused primarily on minimizing a predefined cost function, have been elegantly uni-
fied under the Planning as Inference (PAI) paradigm [Toussaint, 2009, Attias, 2003], showing that
control can be cast as a variational inference problem on a factor graph [Todorov, 2008, Levine,
2018].
However, the real-world challenge lies in environments where dynamics are stochastic or partially
unknown. Popular methods that operate under unknown dynamics are rooted in Reinforcement
Learning [Sutton and Barto, 1998], which optimizes long-term utility through value function or
policy estimation. These methods attempt to inject epistemic behavior by treating exploration as
a distinct form of reward, as seen in Max-entropy Reinforcement Learning [Haarnoja et al., 2018,
2017].
Active Inference proposes an alternative approach to planning under uncertainty [Friston et al., 2015,
Parr and Friston, 2019, Da Costa et al., 2020]. This framework provides a neurobiological expla-
nation of intelligent behavior and posits that the optimal policy that balances exploitative and ex-
plorative behavior emerges when minimizing a quantity known as the Expected Free Energy (EFE)
[Friston et al., 2010, Da Costa et al., 2020]. However, the EFE is an objective that is defined over
sequences of actions and does therefore not define a variational objective over beliefs that we can
optimize.
Recently, an attempt has been made to redefine EFE-based planning as a standard Variational Free
Energy [De Vries et al., 2025] by adjusting the generative model by introducing epistemic priors.
In this paper, we will take a closer look at the objective defined by De Vries et al. [2025] and frame
it as a form of entropic inference, as defined by L ´azaro-Gredilla et al. [2024]. Afterwards, we will
∗Equal contribution between authors.
1st Workshop on Epistemic Intelligence in Machine Learning (EIML 2025) .
arXiv:2511.18955v1  [cs.AI]  24 Nov 2025
derive a message passing scheme that corresponds to the found formulation of Active Inference and
which can be locally minimized on a Factor Graph.
The main contributions of this paper are twofold:
• We formally reframe Active Inference’s EFE minimization as a form of entropy-corrected
variational inference, explicitly demonstrating that the epistemic drive corresponds to a
unique entropic contribution within the variational objective.
• We derive a message-passing scheme for this unified objective. Crucially, this scheme
introduces region-extended Bethe coordinates and anr-channel reparameterization coor-
dinate, which together turn a degenerate conditional entropy into a local cross-entropy
and render the overall objective computationally feasible for local optimization on a factor
graph.
The rest of the paper is structured as follows: in Section 2 we recover Active Inference as a form
of variational inference similar to how planning is recovered in L ´azaro-Gredilla et al. [2024]. This
illustrates that the epistemic drive introduced by Active Inference can be materialized as an entropic
contribution to the variational objective. In Section 3 we will derive a message passing scheme to
minimize the Active Inference objective, providing a method to implement scalable Active Infer-
ence.
For a definition of the terminology used in the rest of the paper, we refer the reader to Appendix A.
2 Active Inference as Entropy Corrected Inference
In this section, we will rewrite the Variational Free Energy of an adjusted generative model as a
form of entropy corrected inference, comparing it to other formulations of planning-as-inference
and posing Active Inference as a separate method on the variational inference landscape.
We will consider the following standard biased generative model
p(y,x, θ,u)∝p(θ)p(x 0)
TY
t=1
p(yt|xt, θ)p(xt|xt−1, ut, θ)p(ut)ˆpx(xt)ˆpy(yt).(1)
Here,yare observations,xare latent states,θare hidden parameters, anduis a sequence of control
signals or actions.ˆpx(xt)andˆpy(yt)represent goal priors on future states and observations, which
can be proportional to a prespecified reward but do not necessarily need to be.
The variational objective defined by De Vries et al. [2025] manipulates the Variational Free Energy
(VFE) of the model in (1) through the inclusion of epistemic priors. In this section, we demonstrate
that the framework of De Vries et al. [2025] extends beyond Active Inference by reformulating their
objective within the broader landscape of entropic inference introduced by L ´azaro-Gredilla et al.
[2024].
In this entropic inference framework, all inference types minimize a common VFE (A.1) while
differing only in their entropy corrections. Following this principle, Theorem 1 shows that the VFE
of the epistemic-prior-augmented generative model from (A.3) can be equivalently expressed as the
VFE of the original generative model plus specific entropy correction terms, thereby positioning
Active Inference within the unified variational inference landscape of Table 1.
Theorem 1.The variational objective presented in De Vries et al. [2025] (presented in subsec-
tion A.2) can be rearranged in the following way:
F˜p[q] =F p[q] +
TX
t=1
H[q(xt−1, ut)]−H[q(x t, xt−1, ut)] +H[q(y t, xt, θ)]−H[q(xt, θ)](2)
whereF p[q]is the Variational Free Energy associated with the generative model.
Proof.Given in Appendix B.
We are now in the position to compare Active Inference with other forms of entropic inference.
Interestingly, by Lemma 4, an adjusted generative model with only˜p(u t)as entropic prior recov-
ers a form of inference surprisingly similar to L ´azaro-Gredilla et al. [2024]. However, where the
2
y1
u1
xT
yT
uT
· · ·
x1
· · ·
fdyn,1
fθ
fu,1
fx
fy,1
fy,ˆp,1
fdyn,T
fy,T
fy,ˆp,T
fx,ˆp,T
fu,T
fx,ˆp,1
θ
x0
Figure 1: Factor graph representation of the generative model(1).Nodes (boxes) represent factors from the generative model:f θ is
the prior on parameters,f x0 is the initial state prior,f dyn,t represents the dynamicsp(x t|xt−1, θ, ut),f y,t represents observations
p(yt|xt, θ), andfu,t,f x,ˆp,t,f y,ˆp,trepresent action priors and goal priors respectively. Edges (lines) represent random variables:θ
(parameters),x t (states),y t (observations), andu t (actions). In the Bethe approximation, eachnodeamaintains a local beliefq a(sa)over
its scope (the variables connected to it), while eachedgeimaintains a singleton beliefq i(si). These local beliefs must satisfy consistency
constraints (5). This factorization enableslocaloptimization scheme (message passing): rather than optimizing a single global distribution
q(y, x, θ, u), we optimize a collection of local beliefs that communicate through messages.
planning-as-inference objective defines a degenerate optimization procedure, this objective admits
an optimization scheme. This point will be elaborated on in Section 3. We will refer to this type
of inference as Maximum Ambiguity (MaxAmb) planning, and with the inclusion of˜p(x t)and
˜p(yt, xt), recovers Active Inference. An overview of the different types of entropic inference is
given in Table 1.
Table 1:Positioning Active Inference within the variational inference landscape. Following L ´azaro-Gredilla et al. [2024], various inference
methods can be expressed as energy minimization with different entropy corrections. Active Inference emerges as a natural extension that
incorporates both planning and epistemic (ambiguity-reducing) terms. Note a slight difference from the exposition presented in [L ´azaro-
Gredilla et al., 2024, Table 1]: there, the entropy correction is presented for the so-called energy term, but these two frameworks are trivially
equivalent in the cases presented below. However, we find this table clearer when written as an entropic correction for VFE, because it becomes
much easier to determine the degenerate schemes (this point will be elaborated in detail in section 3).
Type of inference Entropy correction (relative to VFE)
Marginal 0
MAP H[q]
Planning PT
t=1 H[q(xt−1, ut)]−H[q(x t−1)](Appendix C)
MaxAmb planning PT
t=1 H[q(xt−1, ut)]−H[q(x t, xt−1, ut)]
Active Inference PT
t=1 H[q(xt−1, ut)]−H[q(x t, xt−1, ut)] +H[q(y t, xt, θ)]−H[q(xt, θ)]
Interestingly enough, the contributions from Lemma 3 and Lemma 5 contain the same terms with
their signs flipped, where all contributions from˜p(xt)are canceled out. This warrants a revision of
the epistemic priors˜p(xt)and˜p(yt, xt). In Appendix D we provide a proof that these two priors can
be replaced by˜p(xt, θ) = exp (−H[q(yt |x t, θ)])without changing the inference objective. This
re-arrangement is theoretically useful because it shows that parameters and states are actually not
distinguished by entropic priors, and the only possible distinction could come from the generative
model itself. With the landscape of entropic inference set up, we are in a position to derive a
message-passing procedure corresponding to Active Inference.
3 Deriving Message Passing
To obtain alocalobjective amenable to message passing, we replace the global VFE in Theorem 1
by its Bethe approximation presented in detail in subsection A.3. On tree-structured instances of
(1) this replacement isexact(for instance, aθ-free model); otherwise, it is a standard variational
approximation. But to define the Bethe objective, we need to identify our model with a factor graph
3
(shown in Figure 1). We start with the node setV
fθ(θ) =p(θ), f x0 (x0) =p(x 0),(3a)
fy,t(yt, xt, θ) =p(yt |x t, θ), f dyn,t(xt, xt−1, θ, ut) =p(x t |x t−1, θ, ut),(3b)
fu,t(ut) =p(u t), f x,ˆp,t(xt) = ˆpx(xt), f y,ˆp,t(yt) = ˆpy(yt).(3c)
With the natural set of edgesE
E:={θ, x 0} ∪
T[
t=1
{xt, yt, ut}.(4)
Each nodea∈ Vhas scopes a ⊆ E.
In Bethe terminology, each nodea∈ Vhas an associatedlocalbeliefq a(sa)over its scope. Addi-
tionally, to impose consistency constraints between nodes, we introduce singleton beliefsq i(si)for
each edgei∈ E. Together, these node beliefs{qa(sa)}a∈V and edge beliefs{q i(si)}i∈E form what
we call theBethe coordinates: a collection of normalized probability distributions that must satisfy
the local consistency constraints:
Z
qa(sa)dsa\i =q i(si)(5)
wheneveri∈s a.
With this notation, the Bethe Free Energy specialized to (1) takes the standard form
Ff [q] =
X
a∈V
D[qa(sa)||fa(sa)] +
X
i∈E
(di −1)H[q i(si)],
whose fully expanded expression andd i are given in Equation E.1 and Equation E.2 respectively.
But to make the objective from Theorem 1 local, we must express all its terms using local marginals;
otherwise, it is a global objective. Intuitively, this means we need to find a node in our factor graph
to which we can attach each new term. For instance,q(yt, xt, θ)can be attached to the nodefy,t and
be identified withq y,t Bethe coordinate.
However, the Bethe coordinates alone areinsufficientfor the adjusted objective in Theorem 1, be-
cause the entropic correction contains
−H[q(x t, θ)] +H[q(x t−1, ut)]−H[q(x t, xt−1, ut)].
These three entropy terms involve marginal distributions that are not Bethe coordinates:q(x t, θ),
q(xt−1, ut), andq(x t, xt−1, ut). None of these distributions correspond to the scope of any node in
our factor graph, nor are they singleton beliefs over edges. Note, the same exact reasoning applies
to Planning and MaxAbm Planning from Table 1.
To keep the objective local, we therefore introduce three auxiliaryregion beliefs:
qsep,t(xt, θ) :=
Z
qy,t(yt, xt, θ) dyt =
Z
qdyn,t(xt, xt−1, θ, ut) dxt−1dut,(6a)
qtrip,t(xt, xt−1, ut) :=
Z
qdyn,t(xt, xt−1, θ, ut) dθ,(6b)
qpair,t(xt−1, ut) :=
Z
qtrip,t(xt, xt−1, ut) dxt (6c)
with the natural projections (e.g.,
R
qtrip,t dxt =q pair,t,
R
qsep,t dxt =q θ) enforcing consistency
with existing beliefs. We will refer to this coordinate system as theregion-extended Bethe coordi-
nates. In the region-extended Bethe coordinates, the objective from Theorem 1 can be expressed as
follows
Ff [q] +
TX
t=1

H[qy,t]−H[q sep,t] +H[q pair,t]−H[q trip,t]

.
However, after adding the new region marginals, we obtain the local objective that is degenerate
because of the termH[q y,t]; we prove this supporting result Theorem 7 in subsection E.1. To have
4
both locality and full-identifiability, we augment the coordinates with a singlechannelvariable
ry|xθ,t(yt |x t, θ)with the natural normalization constraint
Z
ry|xθ,t(yt |x t, θ)dyt = 1(7)
and rewrite the global conditional entropy as a local cross-entropy,
H

q(yt |x t, θ)

= min
ry|xθ,t
Eqy,t(yt,xt,θ)

−logr y|xθ,t(yt |x t, θ)

.
Under this reparameterization,q sep,t(xt, θ)is no longer needed as a free coordinate in the objective:
the global termH[q(y t, xt, θ)]−H[q(x t, θ)]collapses into the conditional form and depends only
on(q y,t, ry|xθ,t)locally. The following theorem shows the stationary conditions in ther-adjusted
coordinate system. The proof of Theorem 2 is provided in Appendix E.
Theorem 2(The stationary scheme for Active Inference).Consider the Bethe objective(E.1)for
the model(1)augmented by the Active Inference correction of Theorem 1, and adopt the adjusted
coordinate system
n
qy,t(yt, xt, θ), qdyn,t(xt, xt−1, θ, ut), qsep,t(xt, θ),
qtrip,t(xt, xt−1, ut), qpair,t(xt−1, ut), ry|xθ,t(yt |x t, θ)
oT
t=1
with the projection constraints Equation 6 and the row–normalization Equation 7. Then any sta-
tionary point satisfies, for eacht= 1, . . . , T, the following local equations (all equalities are up to
normalizers):
qy,t(yt, xt, θ)∝p(yt |x t, θ)ry|xθ,t(yt |x t, θ) ˆpy(yt) exp{−Λ xθ(xt, θ)},(8)
ry|xθ,t(yt |x t, θ)∝ qy,t(yt, xt, θ)
qsep,t(xt, θ) (9)
exp{−Λxθ(xt, θ)} ∝
Z
p(yt |x t, θ)ry|xθ,t(yt |x t, θ) ˆpy(yt) dyt
qsep,t(xt, θ) .(10)
qdyn,t(xt, xt−1, θ, ut)∝p(x t |x t−1, θ, ut) exp{−Λ xθ(xt, θ)}exp{−Λtrip(xt, xt−1, ut)},(11)
exp{−Λtrip(xt, xt−1, ut)} ∝ qpair,t(xt−1, ut)
qtrip,t(xt, xt−1, ut).(12)
The region beliefs are tied by the projections
R
qdyn,t dθ=q trip,t and
R
qtrip,t dxt =q pair,t.
All remaining coordinates.Singletonsq xt, qyt, qut, qθ, qx0 and unary factor beliefs (including
ˆpx,ˆpy) satisfy the classical Bethe equations, i.e. the standard belief–propagation fixed–point condi-
tions on the generative model; equivalently, their multipliers/messages are exactly those of BP on
(1)(with degrees(E.2)) and are not modified by the entropic correction.
4 Discussion
While our theoretical framework provides principled planning with epistemic objectives, its compu-
tational implementation faces significant challenges that warrant careful analysis.
To implement our scheme, we must address the nontrivial factor graph structure shown in Figure 2.
This is a Forney-style factor graph [Forney, 2001] representing a single time slice, where variables
are represented on edges and factors are represented as nodes. Message passing algorithms are
generally implemented on factor graphs to leverage their locality [Bagaev and De Vries, 2023].
However, the factor graph corresponding to the scheme introduced in Section 3 is nontrivial. Unlike
standard factor graphs derived directly from generative models, our approach requires region-based
representations [Yedidia et al., 2005] with edges representing multiple variables. In Figure 2, we
5
p(ut)
yt
ut
ˆp(xt)
p(xt | xt−1,θ,u t)
p(yt | xt,θ)
xt,θ
ry|xθ,t(yt | xt,θ)
xt−1,θ
ˆp(yt)
qpair,t
qtrip,t
Figure 2:Time-slice factor graph corresponding to the scheme introduced in section 3. To form a full generative model to run inference, we
chainTof these slices to form a terminated factor graph.
see the edges representing(x t−1, θ)and(xt, θ). Furthermore, there are additional nodes (shown in
dotted lines in Figure 2) that are necessary to compute the new coordinates in our optimization pro-
cedure. The functional form of these nodes is currently unknown, but the messages that are sent are
defined by the schedule derived in Theorem 2. This means we cannot interpret what these nodes do
concretely, highlighting a gap between our theoretical framework and its practical implementation.
Previous attempts have been made to implement a minimization of the objective presented in
De Vries et al. [2025]. These attempts have also implemented a message-passing procedure on
a factor graph [Nuijten et al., 2025]. The scheme previously derived manually recomputes the epis-
temic priors for each iteration of the variational inference procedure. Still, the scheme can be viewed
as a linearization of the true message-passing scheme, which is derived in this work.
Beyond structural challenges, the computational complexity of our approach is quadratic in the state
space size. Previous derivations of Planning-as-Inference express the computational cost of the
procedure in terms of the number of variables [L ´azaro-Gredilla et al., 2024]. We argue that this
is a misleading way to express cost, as the cost of computing joint marginal distributions greatly
depends on the size and dimensionality of the state space. The scheme introduced in Section 3
warrants the computation ofq y,t(yt, xt, θ),qpair,t(xt−1, ut)andq trip,t(xt, xt−1, ut). In discrete
state and action spaces, the computational complexity of computing these quantities is polyno-
mial in the state and action spaces. The computation ofq trip,t(xt, xt−1, ut)is the most expensive,
since it takesO(|X| 2 · |U| ·DΘ)time, whereD Θ is the dimensionality of the parameter space.
Note that, if we would not localize the inference procedure and not introduce our message passing
scheme, the computational complexity would be exponential in the planning horizonT. Interest-
ingly enough, the scheme for Planning as Inference also requires this time complexity, as the same
qtrip,t(xt, xt−1, ut)is computed. The epistemic drive, however, elicits an additional complexity
cost. Computingq y,t(yt, xt, θ)takesO(|Y|·|X|·D Θ)time. This quadratic dependence on the state
space is limiting for interesting problems where the state space quickly grows with the size of the
system, such as Minigrid environments [Chevalier-Boisvert et al., 2023].
These complexity limitations suggest that for this approach to truly scale, hierarchical state-space
partitioning becomes essential. The scheme derived in this paper warrants a partition of the state-
space, hinting to a hierarchical generative model [Palacios et al., 2020, Beck and Ramstead, 2025].
Such hierarchical partitioning would allow us to avoid the quadratic complexity within state-space
partitions, dramatically reducing computational costs while maintaining the principled epistemic
objectives of our framework.
Acknowledgements
This publication is part of the project ROBUST: Trustworthy AI-based Systems for Sustainable
Growth with project number KICH3.LTP.20.006, which is (partly) financed by the Dutch Research
Council (NWO), GN Hearing, and the Dutch Ministry of Economic Affairs and Climate Policy
(EZK) under the program LTP KIC 2020-2023.
6
References
Hagai Attias. Planning by probabilistic inference. InInternational workshop on artificial intelli-
gence and statistics, pages 9–16. PMLR, 2003. URLhttps://proceedings.mlr.press/r4/
attias03a.html.
Dmitry Bagaev and Bert De Vries. Reactive Message Passing for Scalable Bayesian Inference.
Scientific Programming, 2023:1–26, May 2023. ISSN 1875-919X, 1058-9244. doi: 10.1155/
2023/6601690. URLhttps://www.hindawi.com/journals/sp/2023/6601690/.
Jeff Beck and Maxwell J. D. Ramstead. Dynamic Markov Blanket Detection for Macro-
scopic Physics Discovery, February 2025. URLhttp://arxiv.org/abs/2502.21217.
arXiv:2502.21217 [q-bio].
Richard Bellman. The theory of dynamic programming.Bulletin of the Ameri-
can Mathematical Society, 60(6):503–515, 1954. ISSN 0002-9904, 1936-881X. doi:
10.1090/S0002-9904-1954-09848-8. URLhttps://www.ams.org/bull/1954-60-06/
S0002-9904-1954-09848-8/.
Maxime Chevalier-Boisvert, Bolun Dai, Mark Towers, Rodrigo Perez-Vicente, Lucas
Willems, Salem Lahlou, Suman Pal, Pablo Samuel Castro, and Jordan Terry. Min-
igrid & miniworld: Modular & customizable reinforcement learning environments for
goal-oriented tasks.Advances in Neural Information Processing Systems, 36:73383–
73394, 2023. URLhttps://proceedings.neurips.cc/paper_files/paper/2023/hash/
e8916198466e8ef218a2185a491b49fa-Abstract-Datasets_and_Benchmarks.html.
Richard R. Cutler and B. L. Ramaker. Dynamic Matrix Control-A Computer Control Algorithm.
Proc. Joint Automatic Control Conference, 1979, 1979. URLhttps://cir.nii.ac.jp/crid/
1570291225777284224.
Lancelot Da Costa, Thomas Parr, Noor Sajid, Sebastijan Veselic, Victorita Neacsu, and Karl Friston.
Active inference on discrete state-spaces: A synthesis.Journal of Mathematical Psychology, 99:
102447, December 2020. ISSN 0022-2496. doi: 10.1016/j.jmp.2020.102447. URLhttps:
//www.sciencedirect.com/science/article/pii/S0022249620300857.
Bert De Vries, Wouter Nuijten, Thijs van de Laar, Wouter Kouw, Sepideh Adamiat, Tim Nisslbeck,
Mykola Lukashchuk, Hoang Minh Huu Nguyen, Marco Hidalgo Araya, Raphael Tresor, Thijs
Jenneskens, Ivana Nikoloska, Raaja Ganapathy Subramanian, Bart van Erp, Dmitry Bagaev, and
Albert Podusenko. Expected Free Energy-based Planning as Variational Inference, April 2025.
URLhttp://arxiv.org/abs/2504.14898. arXiv:2504.14898 [stat].
G. David Forney. Codes on graphs: Normal realizations.IEEE Transactions on Information
Theory, 47(2):520–548, 2001. URLhttps://ieeexplore.ieee.org/abstract/document/
910573/. Publisher: IEEE.
Karl Friston, Francesco Rigoli, Dimitri Ognibene, Christoph Mathys, Thomas Fitzgerald, and Gio-
vanni Pezzulo. Active inference and epistemic value.Cognitive Neuroscience, 6(4):187–214,
October 2015. ISSN 1758-8928, 1758-8936. doi: 10.1080/17588928.2015.1020053. URL
http://www.tandfonline.com/doi/full/10.1080/17588928.2015.1020053.
Karl J. Friston, Jean Daunizeau, James Kilner, and Stefan J. Kiebel. Action and behavior: a free-
energy formulation.Biological Cybernetics, 102(3):227–260, March 2010. ISSN 1432-0770.
doi: 10.1007/s00422-010-0364-z. URLhttps://doi.org/10.1007/s00422-010-0364-z.
Tuomas Haarnoja, Haoran Tang, Pieter Abbeel, and Sergey Levine. Reinforcement Learning with
Deep Energy-Based Policies. InProceedings of the 34th International Conference on Machine
Learning, pages 1352–1361. PMLR, July 2017. URLhttps://proceedings.mlr.press/
v70/haarnoja17a.html. ISSN: 2640-3498.
Tuomas Haarnoja, Aurick Zhou, Pieter Abbeel, and Sergey Levine. Soft Actor-Critic: Off-Policy
Maximum Entropy Deep Reinforcement Learning with a Stochastic Actor. InProceedings of the
35th International Conference on Machine Learning, pages 1861–1870. PMLR, July 2018. URL
https://proceedings.mlr.press/v80/haarnoja18b.html. ISSN: 2640-3498.
7
Sergey Levine. Reinforcement Learning and Control as Probabilistic Inference: Tutorial and Re-
view, May 2018. URLhttp://arxiv.org/abs/1805.00909. arXiv:1805.00909 [cs].
Miguel L´azaro-Gredilla, Li Yang Ku, Kevin P. Murphy, and Dileep George. What type of inference
is planning?, November 2024. URLhttp://arxiv.org/abs/2406.17863. arXiv:2406.17863.
Wouter W. L. Nuijten, Mykola Lukashchuk, Thijs van de Laar, and Bert de Vries. A Message
Passing Realization of Expected Free Energy Minimization, August 2025. URLhttp://arxiv.
org/abs/2508.02197. arXiv:2508.02197 [cs].
Ensor Rafael Palacios, Adeel Razi, Thomas Parr, Michael Kirchhoff, and Karl Friston. On Markov
blankets and hierarchical self-organisation.Journal of Theoretical Biology, 486:110089, February
2020. ISSN 0022-5193. doi: 10.1016/j.jtbi.2019.110089. URLhttps://www.sciencedirect.
com/science/article/pii/S0022519319304588.
Thomas Parr and Karl J. Friston. Generalised free energy and active inference.Biological Cyber-
netics, 113(5):495–513, December 2019. ISSN 1432-0770. doi: 10.1007/s00422-019-00805-w.
URLhttps://doi.org/10.1007/s00422-019-00805-w.
Richard S. Sutton and Andrew G. Barto.Reinforcement learning:
An introduction, volume 1. MIT press Cambridge, 1998. URL
https://www.cambridge.org/core/journals/robotica/article/
robot-learning-edited-by-jonathan-h-connell-and-sridhar-mahadevan-kluwer-boston-19931997-xii240-pp-isbn-0792393651-hardback-21800-guilders-12000-8995/
737FD21CA908246DF17779E9C20B6DF6.
Emanuel Todorov. General duality between optimal control and estimation. In2008 47th IEEE Con-
ference on Decision and Control, pages 4286–4292, December 2008. doi: 10.1109/CDC.2008.
4739438. URLhttps://ieeexplore.ieee.org/abstract/document/4739438. ISSN:
0191-2216.
Marc Toussaint. Robot trajectory optimization using approximate inference. InProceedings of
the 26th Annual International Conference on Machine Learning, pages 1049–1056, Montreal
Quebec Canada, June 2009. ACM. ISBN 978-1-60558-516-1. doi: 10.1145/1553374.1553508.
URLhttps://dl.acm.org/doi/10.1145/1553374.1553508.
Jonathan S. Yedidia, W.T. Freeman, and Y . Weiss. Constructing free-energy approximations and
generalized belief propagation algorithms.IEEE Transactions on Information Theory, 51(7):
2282–2312, July 2005. ISSN 0018-9448. doi: 10.1109/TIT.2005.850085.
˙Ismail S, en¨oz.Message Passing Algorithms for Hierarchical Dynamical Models. Phd Thesis 1
(Research TU/e / Graduation TU/e), Eindhoven University of Technology, Eindhoven, June 2022.
ISBN: 9789038655321.
A Background
A.1 Variational Inference and the Posterior Factorization
In standard Variational Inference, we minimize the Variational Free Energy (VFE) between a varia-
tional posteriorqand a generative modelp:
Fp[q] =
Z
q(y,x, θ,u) log q(y,x, θ,u)
p(y,x, θ,u)dydxdθdu.(A.1)
We are considering the factorized generative model defined in (1). Since (A.1) defines a functional
objective that we can minimize, we should also specify a familyQover which we are optimizing
the VFE. We will choose the elementsqof this family such that they decompose as follows
q(y,x, θ,u) =q(x 0, θ)
TY
t=1
q(yt |x t, θ)q(xt |x t−1, ut, θ)q(ut |x t−1, θ).(A.2)
This factorization of the posterior distribution is required for the definition of the augmented gener-
ative model in subsection A.2 [Nuijten et al., 2025].
8
A.2 The Epistemic-Prior-Augmented Generative Model
The key insight of De Vries et al. [2025] is that Active Inference can be recovered through an
adjustedoraugmentedgenerative model that includes additional factors calledepistemic priors.
From the generative model, an augmented model is constructed
˜p(y,x, θ,u) =p(y,x, θ,u)·
TY
t=1
˜p(xt)˜p(ut)˜p(yt, xt).(A.3)
Here, the additional˜pterms are epistemic priors, which are functions of the variational distribution
qitself, creating a self-consistent optimization problem. The epistemic priors take the following
forms:
˜p(ut) = exp (H[q(xt, xt−1|ut)]−H[q(x t−1|ut)])(action prior);(A.4a)
˜p(xt) = exp (−H[q(yt|xt)])(state prior);(A.4b)
˜p(yt, xt) = exp (DKL[q(θ|yt, xt)∥q(θ|xt)])(observation prior),(A.4c)
where the entropy of a distributionqover variablesz 1, . . . , zn definied as follows
H[q(z1, . . . , zn)] =−
Z
q(z1, . . . , zn) logq(z1, . . . , zn)dz1 . . .dzn,(A.5)
and the conditional entropy has the following functional form
H[q(z1, . . . , zn |ω)] =−
Z
q(z1, . . . , zn |ω) logq(z 1, . . . , zn |ω)dz 1 . . .dzn.(A.6)
The epistemic priors admit a practical interpretation: the action prior encourages actions that resolve
ambiguity, the state prior favors informative states, and the observation prior encourages observa-
tions that are informative about the parameters.
Theadjusted VFEis then defined in the following way:
F˜p[q] =
Z
q(y,x, θ,u) log q(y,x, θ,u)
˜p(y,x, θ,u)dydxdθdu.(A.7)
Crucially, De Vries et al. [2025] show that minimizing this adjusted VFE is equivalent to minimizing
a bound on the Expected Free Energy (EFE) objective from Active Inference [Friston et al., 2015].
A.3 Bethe Free Energy
Let(V,E)be the (Forney-style) factor graph of a positive functionf(s) = Q
a∈V fa(sa), wheres a
collects the variables incident on factora, and each edgei∈ Ecarries a variables i. TheBethe
variational familyconsists offactor beliefs{q a(sa)}a∈V andedge beliefs{q i(si)}i∈E constrained
to themarginal manifold:Z
qa(sa) dsa = 1∀a∈ V,(A.8a)
Z
qi(si) dsi = 1∀i∈ E,(A.8b)
Z
qa(sa) dsa\i =q i(si)∀a∈ V,∀i∈a,(A.8c)
wheres a\i denotes the variables ins a excepts i. Letd i be the number of factors incident on edgei
(the degree of variables i). TheBethe Free Energy(BFE) [Yedidia et al., 2005] is
Ff [q] =
X
a∈V
D[qa(sa)||fa(sa)] +
X
i∈E
(di −1)H[q i(si)],(A.9)
where
D[qa(sa)||fa(sa)] =
Z
qa(sa) log qa(sa)
fa(sa)dsa.(A.10)
TheBethe approximationtakeslogZ f ≈ −minq∈M Ff [q], whereMis the manifold (A.8). The
approximation isexactwhen the factor graph is a tree; on loopy graphs, stationary points of (A.9)
coincide with fixed points of (loopy) belief propagation [Yedidia et al., 2005]. We refer the reader
to S, en¨oz [2022] for a modern variational calculus exposition on the message passing algorithms
derivation from (A.9).
9
B Proof of Theorem 1
To prove the theorem, we will require three lemmas:
Lemma 3.Under the assumption that our posterior distribution factorizes as in Equation A.2, and
˜p(xt) = exp (−H[q(yt |x t)]):
−
Z
q(xt) log ˜p(xt)dxt =H[q(y t, xt)]−H[q(x t)](B.1)
Proof.
−
Z
q(xt) log ˜p(xt)dxt (B.2a)
=−
Z
q(xt)
Z
q(yt |x t) logq(yt |x t)dytdxt (B.2b)
=−
Z
q(yt |x t)q(xt) logq(yt |x t)dytdxt (B.2c)
=−
Z
q(yt, xt) log q(yt, xt)
q(xt) dytdxt (B.2d)
=−
Z
q(yt, xt) log q(yt, xt)
q(xt) dytdxt =H[q(y t, xt)]−H[q(x t)].(B.2e)
Lemma 4.Under the assumption that our posterior distribution factorizes as in Equation A.2, and
˜p(ut) = exp (H[q(xt, xt−1 |u t)]−H[q(x t−1 |u t)])the following identity holds:
−
Z
q(ut) log ˜p(ut)dut =H[q(x t−1, ut)]−H[q(x t, xt−1, ut)](B.3)
Proof.
−
Z
q(ut) log ˜p(ut)dut (B.4a)
=
Z
q(ut)
Z
q(xt, xt−1 |u t) logq(xt, xt−1 |u t)dxtdxt−1
−
Z
q(xt−1 |u t) logq(xt−1 |u t)dxt−1

dut (B.4b)
=
Z
q(ut)
Z q(xt, xt−1, ut)
q(ut) log q(xt, xt−1, ut)
q(ut) dxtdxt−1
−
Z q(xt−1, ut)
q(ut) log q(xt−1, ut)
q(ut) dxt−1

dut (B.4c)
=
Z
q(xt, xt−1, ut) log q(xt, xt−1, ut)
q(ut) dxtdxt−1dut −
Z
q(xt−1, ut) log q(xt−1, ut)
q(ut) dxt−1dut
(B.4d)
=
Z
q(xt, xt−1, ut) logq(xt, xt−1, ut)dxtdxt−1dut
| {z }
−H[q(xt,xt−1,ut)]
+
Z
q(xt, xt−1, ut) log 1
q(ut)dxtdxt−1dut
| {z }
H[q(ut)]
−
Z
q(xt−1, ut) logq(xt−1, ut)dx′
t−1dut
| {z }
−H[q(xt−1,ut]
−
Z
q(xt−1, ut) log 1
q(ut)dxtdxt−1dut
| {z }
H[q(ut)]
(B.4e)
=H[q(x t−1, ut)]−H[q(x t, xt−1, ut)](B.4f)
10
Lemma 5.Under the assumption that our posterior distribution factorizes as in Equation A.2, and
˜p(yt, xt) = expD KL[q(θ|y t, xt)||q(θ|x t)]:
−
Z
q(yt, xt,) log ˜p(yt, xt)dytdxt =H[q(y t, xt, θ)] +H[q(xt)]−H[q(y t, xt)]−H[q(x t, θ)]
(B.5)
Proof.
−
Z
q(yt, xt) log ˜p(yt, xt)dytdxt (B.6a)
=−
Z
q(yt, xt)
Z
q(θ|y t, xt) log q(θ|y t, xt)
q(θ|x t) dθ

dytdxt (B.6b)
=−
Z
q(yt, xt)
Z
q(θ|y t, xt) logq(yt, xt, θ)−logq(y t, xt)dθ

dytdxt
+
Z
q(yt, xt)
Z
q(θ|y t, xt) logq(θ, xt)−logq(x t)dθ

dytdxt (B.6c)
=−
Z
q(yt, xt, θ) logq(yt, xt, θ)dytdxtdθ
| {z }
H[q(yt,xt,θ)]
+
Z
q(yt, xt, θ) logq(yt, xt)dytdxtdθ
| {z }
−H[q(yt,xt)]
+
Z
q(yt, xt, θ) logq(xt, θ)dytdxtdθ
| {z }
−H[q(xt,θ)]
−
Z
q(yt, xt, θ) logq(xt)dytdxtdθ
| {z }
H[q(xt)]
(B.6d)
=H[q(y t, xt, θ)]−H[q(yt, xt)]−H[q(x t, θ)] +H[q(xt)](B.6e)
Now that we have our lemmas in place, we can continue with the proof of Theorem 1.
Proof.
˜F˜p[q] =
Z
q(y,x, θ,u) log q(y,x, θ,u)
˜p(y,x, θ,u)dydxdθdu(B.7a)
=
Z
q(y,x, θ,u) log q(y,x, θ,u)
p(y,x, θ,u)QT
t=1 ˜p(xt)˜p(ut)˜p(yt, xt)
dydxdθdu(B.7b)
=
Z
q(y,x, θ,u) log q(y,x, θ,u)
p(y,x, θ,u)dydxdθdu
| {z }
Fp[q]
+
Z
q(y,x, θ,u) log 1QT
t=1 ˜p(xt)˜p(ut)˜p(yt, xt)
dydxdθdu(B.7c)
=F p[q]−
TX
t=1
Z
q(y,x, θ,u) (log ˜p(xt) + log ˜p(ut) + log ˜p(yt, xt))(B.7d)
=F p[q] +
TX
t=1
−
Z
q(xt) log ˜p(xt)dxt −
Z
q(ut) log ˜p(ut)dut −
Z
q(yt, xt) log ˜p(yt, xt)dytdxt.
(B.7e)
11
Here, we can recognize the identities from Lemma 3, Lemma 4 and Lemma 5.
Fp[q] +
TX
t=1
−
Z
q(xt) log ˜p(xt)dxt −
Z
q(ut) log ˜p(ut)dut −
Z
q(yt, xt) log ˜p(yt, xt)dytdxt
(B.8a)
=F p[q] +
TX
t=1
H[q(yt, xt)]−H[q(x t)] +H[q(x t−1, ut)]−H[q(x t, xt−1, ut)]
+H[q(y t, xt, θ)] +H[q(xt)]−H[q(y t, xt)]−H[q(x t, θ)](B.8b)
=F p[q] +
TX
t=1
H[q(xt−1, ut)]−H[q(x t, xt−1, ut)] +H[q(y t, xt, θ)]−H[q(xt, θ)](B.8c)
C Additional Entropy Terms in Planning Objective
The adjusted inference objective in L´azaro-Gredilla et al. [2024] is phrased as a maximization prob-
lem including conditional entropies. In this appendix, we will rephrase the planning-as-inference ob-
jective into the vocabulary used in this paper. L´azaro-Gredilla et al. [2024] phrases their optimization
problem as a maximization of a variational bound, whereas we pose the problem as a minimization
of the Variational Free Energy. This means the entropy terms in L ´azaro-Gredilla et al. [2024] have
their sign flipped, as this entropy term is subtracted from the objective. Note that we also have a
slightly different indexing for actions, asu t leads tox t, instead of leading tox t+1 as is the notation
used by L ´azaro-Gredilla et al. [2024]. Here, we useH q[z|ω] =−
R
q(z, ω) logq(z|ω)dzdωas
12
the notation of the conditional entropy.
H[q(x0)] +
TX
t=1
Hq[xt |x t−1, ut](C.1a)
=H[q(x 0)] +
TX
t=1
−
Z
q(xt, xt−1, ut) logq(xt |x t−1, ut)dxtdxt−1dut (C.1b)
=H[q(x 0)] +
TX
t=1
−
Z
q(xt, xt−1, ut) log q(xt, xt−1, ut)
q(ut |x t−1)q(xt−1)dxtdxt−1dut (C.1c)
=H[q(x 0)] +
TX
t=1
−
Z
q(xt, xt−1, ut) log q(xt, xt−1, ut)
q(xt−1) dxtdxt−1dut
+
Z
q(xt, xt−1, ut) logq(ut |x t−1)dxtdxt−1dut (C.1d)
=H[q(x 0)] +
TX
t=1
−
Z
q(xt, xt−1, ut) logq(xt, ut |x t−1)dxtdxt−1dut
| {z }
Hq[xt,ut|xt−1]
+
TX
t=1
Z
q(xt−1, ut) log q(xt−1, ut)
q(xt−1) dxt−1dut (C.1e)
=H[q(x 0)] +
TX
t=1
Hq[xt, ut |x t−1]
| {z }
H[q]
+
TX
t=1
Z
q(xt−1, ut) logq(xt−1, ut)dxt−1dut
| {z }
−H[q(xt−1,ut)]
−
Z
q(xt−1) logq(xt−1)dxt−1
| {z }
−H[q(xt−1)]
(C.1f)
=H[q] +
TX
t=1
H[q(xt−1)]−H[q(x t−1, ut)](C.1g)
Since in our minimization scheme this entropy is subtracted from the objective, we subtract the addi-
tional terms in (C.1g) from the inference objective, and we obtainPT
t=1 H[q(xt−1, ut)]−H[q(xt−1)]
as a final additional term.
D Consolidating State and Observation Epistemic Priors
Lemma 6.Under the assumption that our posterior distribution factorizes as in Equation A.2, with
˜p(xt) = exp{−H[q(yt |x t)]},˜p(y t, xt) = expD KL

q(θ|y t, xt)∥q(θ|x t)

,
define˜p(xt, θ) = exp{−H[q(yt |x t, θ)]}. Then
−
Z
q(xt) log ˜p(xt) dxt −
Z
q(yt, xt) log ˜p(yt, xt) dyt dxt =−
Z
q(xt, θ) log ˜p(xt, θ) dxt dθ.
(D.1)
Proof.
St :=−
Z
q(xt) log ˜p(xt) dxt −
Z
q(yt, xt) log ˜p(yt, xt) dyt dxt (D.2a)
=H[q(y t, xt, θ)]−H[q(xt, θ)](by Lemmas 3 and 5) (D.2b)
.(D.2c)
13
On the other hand,
Rt :=−
Z
q(xt, θ) log ˜p(xt, θ) dxt dθ=
Z
q(xt, θ)H[q(yt |x t, θ)] dxt dθ(D.3a)
=−
Z
q(yt, xt, θ) logq(yt |x t, θ) dyt dxt dθ(D.3b)
=−
Z
q(yt, xt, θ)
 
logq(y t, xt, θ)−logq(x t, θ)

dyt dxt dθ(D.3c)
=H[q(y t, xt, θ)]−H[q(xt, θ)].(D.3d)
ThusS t =R t, which proves (D.1).
E Proof of Theorem 2
In this appendix, we establish the stationary conditions for the Active Inference message-passing
scheme presented in Theorem 2. The proof proceeds by deriving the first-order optimality conditions
for each coordinate in the adjusted system.
We begin by expanding the Bethe Free Energy for the generative model (1) and establishing the
necessary consistency constraints in (E.3). subsection E.1 demonstrates that the standard region
coordinates lead to a degenerate optimization problem (Theorem 7), motivating the introduction of
the channel variabler y|xθ,t. subsection E.2 and subsection E.3 then derive the stationary conditions
with respect to each coordinate—the observation factor beliefq y,t (Theorem 8), the channelr y|xθ,t
(Theorem 9), and the dynamics factor beliefq dyn,t (Theorem 10)—as well as the identifications of
the Lagrange multipliersΛ xθ (Theorem 11) andΛ trip (Theorem 12).
Theorem 2 follows directly from these results: equations (8)–(12) are simply the collected stationary
conditions established in Theorem 8–Theorem 12 below, expressed in the notation of the main text
with the goal priorsˆpy(yt)explicitly included.
BFE for the model (1) then reads
FBethe
p [q] =D[q θ(θ)||p(θ)] +D[q x0 (x0)||p(x0)]
+
TX
t=1
h
D[qy,t(yt, xt, θ)||p(yt |x t, θ)] +D[qdyn,t(xt, xt−1, θ, ut)||p(xt |x t−1, θ, ut)]
+D[q u,t(ut)||p(ut)] +D[q x,ˆp,t(xt)||ˆpx(xt)] +D[q y,ˆp,t(yt)||ˆpy(yt)]
i
+ (dθ −1)H[q θ(θ)] + (dx0 −1)H[q x0 (x0)]
+
TX
t=1
h
(dxt −1)H[q xt(xt)] + (dyt −1)H[q yt(yt)] + (dut −1)H[q ut(ut)]
i
.
(E.1)
The variable-node degrees implied by (1) and the factorization above are
dθ = 1 + 2T(prior,Tobs,Tdyn), d x0 = 2(prior, dynt=1),
dyt = 2(obs, goal prior ony t), d ut = 2(action prior, dynt),
dxt =
4,1≤t≤T−1(obst, dynt, dynt+1, goal prior onx t),
3, t=T(obsT, dynT, goal prior onx T ).
(E.2)
(For unary factorsf θ, fx0 , fu,t, fx,ˆp,t, fy,ˆp,twe identify the factor belief with the adjacent single-
ton.) With this notation, the Bethe Free Energy in (E.1) is the specialization of the general BFE in
subsection A.3 to (1).
Local consistency requires that, for every factoraand every variablei∈s a,
Z
qa(sa) dsa\i =q i(si).
14
Observation(y, t) :
Z
qy,t(yt, xt, θ) dxt dθ=q yt(yt),(E.3a)
Z
qy,t(yt, xt, θ) dyt dθ=q xt(xt),(E.3b)
Z
qy,t(yt, xt, θ) dyt dxt =q θ(θ).(E.3c)
Dynamics(dyn, t) :
Z
qdyn,t(xt, xt−1, θ, ut) dxt−1 dut dθ=q xt(xt),(E.3d)
Z
qdyn,t(xt, xt−1, θ, ut) dxt dut dθ=q xt−1 (xt−1),(E.3e)
Z
qdyn,t(xt, xt−1, θ, ut) dxt dxt−1 dθ=q ut(ut),(E.3f)
Z
qdyn,t(xt, xt−1, θ, ut) dxt dxt−1 dut =q θ(θ).(E.3g)
Unary priors/goals:q u,t(ut) =q ut(ut), q x,ˆp,t(xt) =q xt(xt), q y,ˆp,t(yt) =q yt(yt).
(E.3h)
(For unary factors we identify the factor belief with the adjacent singleton belief; the equality is
enforced by the corresponding consistency constraint.)
E.1 Degeneracy of the marginal scheme
Theorem 7(Degeneracy persists under the augmented region coordinates).Fixt. Consider the
Bethe-form objective specialized to(1), augmented by the Active Inference entropic correction
+H[q(y t, xt, θ)]−H[q(x t, θ)] +H[q(x t−1, ut)]−H[q(x t, xt−1, ut)].
Introduce the auxiliary region beliefsq sep,t(xt, θ)(defined in Equation 6) with the consistency con-
straints Z
qy,t(yt, xt, θ) dxt dθ=q yt(yt),(E.4a)
Z
qy,t(yt, xt, θ) dyt =q sep,t(xt, θ).(E.4b)
(Region beliefsq pair,t andq trip,t are tied to the dynamics block and do not appear in(E.4).) Then
any stationary point of the Lagrangian with respect to the observation-factor beliefq y,t(yt, xt, θ)
satisfies
−logp(y t |x t, θ) +λ y(yt) +λ sep(xt, θ) = 0,(E.5)
for some multipliersλ y(·),λ sep(·,·). Consequently:
1. Ifp(y t |x t, θ)is not separable asa t(yt)b t(xt, θ), the system is infeasible (no interior
solution forq y,t).
2. Ifp(y t |x t, θ) =at(yt)b t(xt, θ)is separable, the observation block is affine inq y,t (its
second variation w.r.t.qy,t vanishes), hence stationary points are non-unique (a flat face of
the feasible polytope).
Proof.Theq y,t-dependent part of the objective is
Z
qy,t log qy,t
p(yt |x t, θ) +H[q(y t, xt, θ)],
since−H[q(x t, θ)],+H[q(x t−1, ut)], and−H[q(x t, xt−1, ut)]do not depend onq y,t. TheR
qy,t logq y,t from the KL term cancels exactly with+H[q(y t, xt, θ)], leaving the linear func-
tional−
R
qy,t logp(y t |x t, θ). Add constraints (E.4a)–(E.4b) with multipliersλ y(·),λ sep(·,·).
Taking the functional derivative yields (E.5). Exponentiating shows that a solution exists only if
p(yt |x t, θ)∝e λy(yt)eλsep(xt,θ), i.e., it factorizes asa t(yt)bt(xt, θ). In the separable case, the ab-
sence of a
R
qy,t logq y,t term implies zero curvature in theq y,t-direction and thus non-uniqueness;
otherwise the system is infeasible.
15
Consequence.Theorem 7 shows that even after introducing the augmented region coordinates
(qsep,t, qpair,t, qtrip,t), the Active Inference correction leaves the observation block degenerate: fea-
sibility requires a separable likelihood iny t and(x t, θ), and otherwise the block is flat.
E.2 Stationary conditions in the condititonal adjusted system
Lemma 8(Stationary condition for the observation factor with channel augmentation).Fixtand
introduce the channelry|xθ,t(yt |x t, θ)with the normalization
R
ry|xθ,t(yt |x t, θ) dyt = 1. Assume
the separator consistency on the overlap(x t, θ),Z
qy,t(yt, xt, θ) dyt =q xθ(xt, θ) =
Z
qdyn,t(xt, xt−1, θ, ut) dxt−1dut,
and they t-singleton consistencyZ
qy,t(yt, xt, θ) dxt dθ=q yt(yt).
Consider the observation-block objective (holdingr y|xθ,t fixed):
Z
qy,t log qy,t
p(yt |x t, θ)+
Z
qy,t

−logr y|xθ,t(yt |x t, θ)

,
plus Lagrange terms for the two consistency constraints. Then the stationarity with respect to
qy,t(yt, xt, θ)is
logq y,t(yt, xt, θ)−logp(y t |x t, θ)−logr y|xθ,t(yt |x t, θ) +λy(yt) +λ xθ(xt, θ) = 0,(E.6)
for some multipliersλ y(·)andλ xθ(·,·). Equivalently,
qy,t(yt, xt, θ)∝p(y t |x t, θ)ry|xθ,t(yt |x t, θ) exp

−λy(yt)
	
exp

−λxθ(xt, θ)
	
,(E.7)
withλ y, λxθ chosen to satisfy the two projection constraints above.
Proof.Form the partial Lagrangian (omitting the redundant normalization ofq y,t):
L[qy,t] =
Z
qy,t log qy,t
p(yt |x t, θ) +
Z
qy,t

−logr y|xθ,t

+
Z
λy(yt)
Z
qy,t dxt dθ−q yt(yt)

dyt
+
ZZ
λxθ(xt, θ)
Z
qy,t dyt −q xθ(xt, θ)

dxt dθ.
Taking the functional derivative w.r.t.qy,t and setting it to zero yields
logq y,t −logp(y t |x t, θ)−logr y|xθ,t + 1 +λy(yt) +λ xθ(xt, θ) = 0,
where the constant+1can be absorbed into either multiplier. This is (E.6). Exponentiating gives
(E.7), and the multipliers are determined by enforcing the two linear projection constraints.
Lemma 9(Stationary condition for the observation channel).Fixt. Let the channelr y|xθ,t(yt |
xt, θ)satisfy the row–normalizationZ
ry|xθ,t(yt |x t, θ) dyt = 1for all(x t, θ),(E.8)
and assume separator consistency on the overlap(x t, θ):Z
qy,t(yt, xt, θ) dyt =q sep,t(xt, θ).(E.9)
Consider the channel objective (holdingq y,t andq sep,t fixed)
J[r] =
Z
qy,t(yt, xt, θ)

−logr y|xθ,t(yt |x t, θ)

dyt dxt dθ,(E.10)
subject to(E.8). Then a stationary point is given pointwise by
r⋆
y|xθ,t(yt |x t, θ) = qy,t(yt, xt, θ)
qsep,t(xt, θ) wheneverq sep,t(xt, θ)>0,(E.11)
with the convention that ifqsep,t(xt, θ) = 0, the entire rowry|xθ,t(· |xt, θ)can be chosen arbitrarily
as any probability distribution (it does not affectJ).
16
Proof.Form the Lagrangian with a row multiplierλ(x t, θ)enforcing (E.8):
L[r] =
Z
qy,t(yt, xt, θ)

−logr(y t |x t, θ)

+
ZZ
λ(xt, θ)
Z
r(yt |x t, θ) dyt −1

dxt dθ.
Taking the functional derivative and setting it to zero yields, pointwise in(yt, xt, θ),
−qy,t(yt, xt, θ)
r⋆(yt |x t, θ)+λ(x t, θ) = 0⇒r ⋆(yt |x t, θ) =qy,t(yt, xt, θ)
λ(xt, θ) .
Imposing the row–normalization (E.8) and using (E.9),
1 =
Z
r⋆(yt |x t, θ) dyt =
R
qy,t(yt, xt, θ) dyt
λ(xt, θ) = qsep,t(xt, θ)
λ(xt, θ) ,
soλ(x t, θ) =qsep,t(xt, θ), giving (E.11). Ifqsep,t(xt, θ) = 0, then the row ofqy,t is identically zero
andJis unaffected by the choice ofr(· |x t, θ).
Lemma 10(Stationary condition for the dynamics factor (minimal projections)).Fixt. Let
qdyn,t(xt, xt−1, ut, θ)be the dynamics–factor belief and introduce the region beliefsq xθ,t(xt, θ)
andq trip,t(xt, xt−1, ut)with projection constraints
Z
qdyn,t(xt, xt−1, θ, ut) dxt−1 dut =q xθ,t(xt, θ),(E.12a)
Z
qdyn,t(xt, xt−1, θ, ut) dθ=q trip,t(xt, xt−1, ut).(E.12b)
(Separately, enforce the pair–trip relation
R
qtrip,t(xt, xt−1, ut) dxt =q pair,t(xt−1, ut)in theq trip,t
block.) Theq dyn,t-dependent part of the objective is the KL term
Z
qdyn,t log qdyn,t
p(xt |x t−1, θ, ut) dxt dxt−1 dut dθ,
while the entropic corrections only involve the region beliefs. Form the partial Lagrangian with
multipliersΛ xθ(xt, θ)andΛtrip(xt, xt−1, ut)enforcing(E.12a)–(E.12b). Then the stationarity w.r.t.
qdyn,t is
logq dyn,t(xt, xt−1, θ, ut)−logp(x t |x t−1, θ, ut) + Λxθ(xt, θ) + Λtrip(xt, xt−1, ut) = 0,(E.13)
up to an additive constant, hence
qdyn,t(xt, xt−1, θ, ut)∝p(x t |x t−1, θ, ut) exp

−Λ xθ(xt, θ)
	
exp

−Λ trip(xt, xt−1, ut)
	
.
(E.14)
The multipliers are determined by the two projection constraints(E.12), while the consistencyR
qtrip,t dxt =q pair,t is enforced in theq trip,t variation and does not appear in(E.14).
E.3 Identification of the Lagrange multipliers
Lemma 11(Identification of the dynamics–side separator multiplier).Fixt. Assume the channel
ry|xθ,t(yt |x t, θ)is row–normalized and impose separator consistency
Z
qy,t(yt, xt, θ) dyt =q sep,t(xt, θ) =
Z
qdyn,t(xt, xt−1, θ, ut) dxt−1 dut.
At any stationary point of the observation block, there exists a slice–constantC t >0such that
exp

−Λ xθ(xt, θ)
	
=C t
Z
p(yt |x t, θ)ry|xθ,t(yt |x t, θ)e−λy(yt) dyt
qsep,t(xt, θ) ,(E.15)
whereλ y(·)is the Lagrange multiplier enforcing
R
qy,t(yt, xt, θ) dxt dθ=q yt(yt). Equivalently,
Λxθ(xt, θ) = logq sep,t(xt, θ)−log
Z
p(yt |x t, θ)ry|xθ,t(yt |x t, θ)e−λy(yt) dyt

+c t,
withc t =−logC t independent of(x t, θ).
17
Proof.From the observation–block stationarity (Lemma 8), there exists a slice–constantκ t >0
such that
qy,t(yt, xt, θ) =κt p(yt |x t, θ)ry|xθ,t(yt |x t, θ)e−λy(yt) e−λxθ(xt,θ).(E.16)
Integrate (E.16) overy t and use the left separator equality to obtain
qsep,t(xt, θ) =κt e−λxθ(xt,θ)
Z
p(yt |x t, θ)ry|xθ,t(yt |x t, θ)e−λy(yt) dyt
| {z }
=:I t(xt,θ)
.
Solve fore −λxθ(xt,θ):
e−λxθ(xt,θ) = qsep,t(xt, θ)
κt It(xt, θ).
On the other hand, varying the separatorq sep,t in the Lagrangian for the two equalities gives
λxθ(xt, θ) + Λxθ(xt, θ) = 0, hencee−Λxθ(xt,θ) =e λxθ(xt,θ). Combining the two displays,
e−Λxθ(xt,θ) =e λxθ(xt,θ) = κt It(xt, θ)
qsep,t(xt, θ) =C t
Z
p(yt |x t, θ)ry|xθ,t(yt |x t, θ)e−λy(yt) dyt
qsep,t(xt, θ) ,
withC t =κ t independent of(x t, θ). Taking logs yields the equivalent additive form withc t =
−logC t.
Lemma 12(Identification of the triplet multiplier from the dynamics-side entropic correction).Fix
t. Let the region beliefsq trip,t(xt, xt−1, ut)andq pair,t(xt−1, ut)satisfy the coupling constraintZ
qtrip,t(xt, xt−1, ut) dxt =q pair,t(xt−1, ut),(E.17)
and let the projection from the dynamics factor be enforced via the multiplierΛ trip(xt, xt−1, ut)
on
R
qdyn,t dθ−q trip,t = 0. Suppose the objective contains the dynamics-side entropic correction
+H[q pair,t]−H[q trip,t]. Then, at any stationary point, there exists a slice-constantC t >0such
that
exp

−Λ trip(xt, xt−1, ut)
	
=C t
qpair,t(xt−1, ut)
qtrip,t(xt, xt−1, ut) ,(E.18)
equivalently,
Λtrip(xt, xt−1, ut) = logq trip,t(xt, xt−1, ut)−logq pair,t(xt−1, ut) +c t,
withc t =−logC t independent of(x t, xt−1, ut).
Proof.Consider the part of the Lagrangian involvingq trip,t andq pair,t:
L=
Z
qtrip,t logq trip,t
| {z }
from−H[q trip,t]
−
Z
qpair,t logq pair,t
| {z }
from+H[q pair,t]
+
ZZ
Ξpair(xt−1, ut)
Z
qtrip,t dxt −q pair,t

dxt−1dut
−
Z
Λtrip qtrip,t
where the last term comes from the projection
R
qdyn,tdθ−q trip,t = 0. Varying w.r.t.qtrip,t gives
δL
δqtrip,t
: logq trip,t + 1 + Ξ pair(xt−1, ut)−Λ trip(xt, xt−1, ut) = 0.
Varying w.r.t.qpair,t yields
δL
δqpair,t
:−
 
logq pair,t+1

−Ξ pair(xt−1, ut) = 0⇒Ξ pair(xt−1, ut) =−
 
logq pair,t(xt−1, ut)+1

.
EliminatingΞ pair in the first equation gives
Λtrip(xt, xt−1, ut) = logq trip,t(xt, xt−1, ut)−logq pair,t(xt−1, ut) +c t,
where the slice-constantc t (absorbing the+1terms and any normalization) is independent of
(xt, xt−1, ut). Exponentiating yields (E.18) withC t =e −ct.
18