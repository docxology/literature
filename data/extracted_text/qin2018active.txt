1
Active Anomaly Detection with Switching Cost
Fengfan Qin, Da Chen, Hui Feng, Member, IEEE, Qing Zhao, Fellow, IEEE, Tao Yang, Member, IEEE,
and Bo Hu, Member, IEEE
Abstract
The problem of detecting a single anomalous process among multiple independent processes is considered. Under a constraint
on the number of processes that can be probed simultaneously, the decision maker should decide which processes to probe at each
time and when to terminate the probing. Compared with previous work considering only the observation costs, the switching costs
of switchings across processes also need to be taken into account in many practical scenarios. The objective is an active inference
strategy that minimizes the Bayesian risk taking into account of the sample complexity, switching cost, as well as detection errors.
Based on the framework of sequential design of experiments, we propose a low-complexity, low-switching deterministic policy
for two scenarios where the total switching cost is negligible and the total switching cost is comparable to the total observation
cost. We show that the proposed algorithm is asymptotically optimal in the former scenario and is order optimal in the latter
scenario. Simulation results demonstrate strong performance in the ﬁnite regime for both scenarios.
Index Terms
Active hypothesis testing, anomaly detection, switching cost.
I. I NTRODUCTION
C
ONSIDER the problem of detecting anomalous processes among multiple processes. At each time, only one process
can be probed and a noisy observation is obtained from the process. The objective is to ﬁnd an optimal inference
strategy consisting of a selection rule indicating which process to probe at each time, a stopping rule on when to terminate the
detection, and a decision rule on the ﬁnal result. The performance measure is the Bayesian risk that takes into account various
costs during procedure, such as the detection error, the sampling delay or switching cost, etc.
F. Qin, D. Chen, H. Feng, T. Yang and B. Hu are with the Research Center of Smart Networks and Systems, School of Information Science and Engineering,
Fudan University, Shanghai 200433, China. e-mail: ( {ffqin18, dachen16, hfeng, taoyang, bohu }@fudan.edu.cn,). A priliminary result was presented in the
ICASSP 2019-2019 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP) [1].
Q. Zhao is with School of Electrical and Computer Engineering, Cornell University. e-mail:qz16@cornell.edu
arXiv:1810.11800v3  [eess.SP]  14 Jan 2021
2
The anomaly detection problem studied in this paper relates to the sequential design of experiments problem ﬁrst studied by
Chernoff in 1959 [2] named as the Active Hypothesis Testing (AHT) problem. Differ from the classic sequential hypothesis
testing pioneered by Wald in [3] where the observation action under each hypothesis is ﬁxed, active hypothesis testing allows
the decision maker to choose different experiments to be conducted at each time and infer the state of the probed process. The
test developed by Chernoff (referred to as Chernoff test) is a randomized test that generates random actions based on historical
observations. The actions, consequently the test statistics of log likelihood ratio, thus become independent and identically
distributed over time, allowing asymptotic analysis of the stopping time on the test statistic.
Chernoff’s work has been extended in various directions. Bessler [4] generalized Chernoff’s work to general multiple
hypothesis testing in 1960. Naghshvar and Javidi in [5]–[9] studied this sequential problem from the perspective of minimizing
Bayesian risk considering the detection error and detection delay. In [10]–[12], more general models which considered
Markovian observations and non-uniform costs on actions were proposed. Recently, K. Cohen and Q. Zhao et al. studied
AHT for anomaly detection in [13]–[19]. In contrast to the random policies advocated in other works, they introduced a simple
deterministic model which offers the same asymptotic optimality yet with signiﬁcant performance gain in the ﬁnite regime and
considerable reduction in implementation complexity. More recent studies and applications of general active hypothesis testing
problem can be found in [20]–[23].
However, Chernoff test and subsequent studies do not consider switching cost. Incorporating switching cost into Bayesian
risk is motivated by a number of applications. For example, in many searching tasks, relocating the searching agent (eg.
rescuing ships or air-crafts) incurs considerable cost in terms of energy or delay. Another example is medical diagnostics,
where frequent and fast switching across drugs and medical procedures may carry high risk and side effects.
There are few studies considering the switching cost in AHT. Vaidhiyan developed a modiﬁed Chernoff test (referred to as
Sluggish policy) in [24] and introduced a switching parameter η which determines the switching probability, which can be
seen as an ε-greedy strategy. They claimed that Sluggish policy approaches the asymptotic performance of Chernoff test as
η→0. But this policy results in a higher observation cost in the ﬁnite regime as demonstrated in their simulations.
In this paper, we propose a low-complexity deterministic test for the above active hypothesis testing problem with switching
cost, referred to the Deterministic Bounded Switching (DBS) policy, which was ﬁrst formulated and studied in our prior
work [1]. The proposed policy explicitly speciﬁes the probing action at each time based on the history of observations, which
integrates all parameters affecting the Bayesian risk: the number of processes M, the single-switching cost s, the single-
observation cost c, and the corresponding Kullback-Liebler (KL) divergences between the observation distributions of normal
and anomalous processes. DBS policy partitions the problem space into two cases. In the ﬁrst case, the process that are most
3
likely to be abnormal will be probed. In the other case, DBS policy probes processes that are likely to be normal and eliminates
them one by one to reduce the number of switchings. In addition to the scenario studied in [1] where the single-switching cost
is of no greater order than the single-observation cost in the asymptotic regime of c→0, we further analyze the performance
of the DBS policy in the scenario where the total switching cost is negligible and the total switching cost is comparable to
the total observation cost. Then, we show that the DBS policy enjoys asymptotic optimality when the total switching cost is
negligible to the observation cost, i.e., s = o(−clog c) as c approaches 0, and strong performance in the ﬁnite regime are
demonstrated in simulation part of this paper. In addition, we also analyze the performance of the DBS policy when total
switching cost is comparable to the total observation cost, i.e., s= Ω(−clog c) as capproches 0, and draw the conclusion that
the DBS policy is order optimal in this scenario.
In this paper, Sec. II describes the system model for single anomaly detection problems. DBS policy is proposed to solve
it, and its optimality is proved in Sec. IV-A. In Sec. IV-B and Sec. IV-C we compare DBS with the deterministic DGF policy
in [13] and the Random Sequential Probability Ratio Test (R-SPRT) policy and analyze the impact of switching cost. In Sec.
V we provide numerical examples to illustrate the performance of the proposed policy compared with other algorithms. Sec.
VI concludes the paper.
II. SYSTEM MODEL AND PROBLEM FORMULATION
A. System Model
Consider the problem of detecting an anomalous process among a ﬁnite number (denoted by M) of processes. Each process
may be in a normal state or an abnormal state alternatively. Let Hm denote the hypothesis that the process mis in an abnormal
state. Let πm be the priori probability that Hm is true, where ∑M
m=1 πm = 1, and 0 <πm <1 for all m. At each given time,
only one process can be probed. When process m is probed at time n, an observation ym(n) is obtained and is independent
over time. If process m is in a normal state, ym(n) follows distribution f(y); if process m is in an abnormal state, ym(n)
follows distribution g(y). We focus on the case where the distributions f(y) and g(y) are known.
Let Pm be the probability measure under hypothesis Hm and Em be the operator of expectation concerning the measure Pm.
Let φ(n) ∈1,2,...,M be a selection rule indicating which process is probed at time n. The vector of selection rules is denoted
by φ = (φ(n),n ≥1). Let τ be a stopping time (or a stopping rule), which is the time when the decision maker ﬁnishes the
detecting procedure. Let τc and τs be the numbers of observations and switchings by the stopping time τ, respectively, we
have τ = τc + τs. Let δ ∈{1,2,...,M }be a decision rule, where δ = m if the decision maker declares that Hm is true at
time τ.
4
An admissible policy for the sequential anomaly detection problem is denoted by
Γ = (τ,δ, φ). (1)
B. Objective
Let Pe(Γ) ≜ ∑M
m=1 πmαm(Γ) be the probability of error under policy Γ, where αm(Γ) ≜ Pm(δ̸= m|Γ) is the probability
of declaring δ ̸= m when Hm is true. Let E(τ|Γ) ≜ ∑M
m=1 πmEm(τ|Γ) be the expected detection time under Γ, while
E(τc|Γ) ≜ ∑M
m=1 πmEm(τc|Γ) is the expected value of the total number of observations τc and E(τs|Γ) ≜ ∑M
m=1 πmEm(τs|Γ)
is the expected value of the total number of switchings τs respectively.
We adopt a Bayesian-like approach as in Chernoff’s original study [2] by assigning a cost of c for each observation, a unit
loss for a wrong declaration, and s be the switching cost for a single position switching.
The Bayesian risk of Γ under hypothesis Hm is given by
Rm(Γ) ≜ αm(Γ) + cEm(τ|Γ) + sEm(τs|Γ). (2)
The average Bayesian risk is
R(Γ) ≜
M∑
m=1
πmRm(Γ) = Pe(Γ) + cE(τ|Γ) + sE(τs|Γ). (3)
The objective is ﬁnding a policy that minimizes the Bayesian risk:
inf
Γ
R(Γ). (4)
C. Statistics
Since only one process can be probed at a time, let 1m(n) be the indicator function of whether process mis probed at time
n. 1m(n) = 1 if process m is probed at time n, and 1m(n) = 0 otherwise.
The log-likelihood ratio (LLR) of each process m is denoted as
lm(n) ≜ log g(ym(n))
f(ym(n)), (5)
which reﬂects the goodness-of-ﬁt of which distribution a certain region belongs to. Em(lm(n)) ≜ D(g||f) > 0 if the
observations of region m follows distribution g(y), and Em(lm(n)) ≜ −D(f||g) < 0 if the observations of process m
follows distribution f(y), where D(·||·) is the KL divergence between two distributions.
The sum log-likelihood ratio (SLLRs) of process m at time n is given by
5
Sm(n) ≜
n∑
t=1
lm(t)1m(t), (6)
which combines the observations of the process m at multiple times, and can be regarded as the score of whether the process
is in an abnormal state. After a period of observations, the sum-LLRs of different processes may be different. Under Hm,
Sm(n) is a random walk with positive expected increment Em(lm(n)) = D(g||f) >0, while Sj(n), for j ̸= m is a random
walk with negative expected increment Em(lj(n)) = −D(f||g) <0.
III. THE DBS POLICY
A. The DBS Policy
In this section, we propose a deterministic policy for the above active hypothesis testing problem, referred to as the DBS
policy. Our goal is to detect the only one anomalous process among multiple processes. Intuitively, there are two ways to solve
the detection problem. In one way, we can probe the processes that are more likely to be abnormal and conﬁrm them one by
one; In another way, we can probe the processes that are more likely to be normal and eliminate them one by one. Thus, the
proposed DBS policy partitions the problem space into two cases by comparing D(f||g)/(M−1) and D(g||f) +△(M), i.e.,
Case I: D(g||f) + △(M) ≥D(f||g)
M −1 ,
Case II: D(g||f) + △(M) < D(f||g)
M −1 ,
where
△(M) ≜ s(M −2)(M + 1)D(g||f)D(f||g)
−clog c(M −1) (7)
is the offset value caused by the switching cost which we will explain later. It should be noted thatD(g||f) and D(f||g)/(M−1)
determine the rates at which the state of abnormal process m and normal processes j ̸= m can be accurately inferred, where
D(g||f) represents the increasing slope of the test statistic Sm(n) of the normal process mand D(f||g) represents the decreasing
slope of the test statistics Sj of normal processes j ̸= m respectively. While the observation cost is mainly determined by
D(g||f), D(f||g)/(M −1) and c, the switching cost is mainly affected by M.
In Case I, DBS policy probes the process which is most likely to be abnormal. The selection rule, stopping rule and decision
rule are as follows:
φ(n) = m1(n), (8)
τ = min
{
n: Sm1(n)(n) >−log c
}
, (9)
δ= m1(τ), (10)
6
where m1(n) = arg maxmSm(n) is the index of the process owing the highest sum-LLRs (processes with the same sum-LLRs
can be ordered arbitrarily) among all the processes.
In Case II, DBS policy probes the process which is most likely to be normal and eliminates the normal processes one by
one. Speciﬁcally, let B(n) denote the set of processes that can be declared as normal at time n, i.e.,
B(n) = {m: Sm(n) <log c}. (11)
The selection rule, stopping rule, and decision rules of DBS policy in Case II are given by
φ(n) = m−1(n), (12)
τ = min {n: |B(n)|= M −1}, (13)
δ= M\B(τ), (14)
where m−1(n) = arg minm/∈B(n) Sm(n) is the index of the process with the lowest observation sum-LLRs among all processes
that have not been declared as normal at time n, and M= {1,2,...,M }is the set of all processes.
B. Explanation
In our policy, we deﬁne stage as the time when a certain process is determined as abnormal or normal. There are only 1
stage in Case I, however, the observation process will be divided into M −1 stages in Case II. Assume that process m is in
an abnormal state, i.e., Hm is true. The deterministic selection rule of the DBS policy can be intuitively explained as follows.
Since the observations ym(n) of process mfollow the distribution g(y), the expectation of the test statistic lm is Em(lm) =
D(g||f) >0. Therefore, as the number of observations increases, the sum-LLRs of process m increases gradually with high
probability. However, since the observations yj(n) of process j ̸= m follows the distribution f(y), the expectation of the test
statistics lj is Em(lj) = −D(f||g) <0, which means the sum-LLRs of process j decreases gradually with high probability as
the number of observations increases. At the beginning of the detection procedure, the sum-LLRs of all processes are zero and
the decision maker randomly selects a process to probe. Subsequently, the decision maker sorts all the processes according to
the sum-LLRs at each given time n and selects the process m1(n) with the highest sum-LLRs. As a result, the sum-LLRs of
process m will gradually increases and become m1(n) with high probability.
In Case I of DBS policy, the decision maker probes the process with the highest sum-LLRs at each given time. The test
is ﬁnalized once sufﬁcient information is gathered from the process, when the highest sum-LLRs exceeds the threshold of
−log c. Therefore, the asymptotic detection time approaches −log c/D(g||f) since the abnormal process can be probed with
higher probability than other processes at each time. In this case, the number of switching is bounded because the abnormal
7
process will quickly become the m1(n) process with high probability. In addition, the probability of switching decreases as
the time n increases, since the gap between m1(n) and m2(n) increases as n increases.
In Case II, the decision maker eliminates normal processes one by one and identiﬁes the abnormal process ﬁnally. As a
result, the detection procedure will be divided into M−1 stages. At each stage, the process m−1(n) which is most likely to
be normal is probed at each time and the asymptotic observation time of each stage approaches −log c
D(f||g) . The test is ﬁnalized
once |B(n)|= M −1. Thus the asymptotic observation time of entire detection procedure approaches −(M−1) logc
D(f||g) .
With the goal of minimizing the objective function (4), the selection rules of Case I and Case II are established as (7).
Considering the impact of switching on the strategy, we introduced an offset △(M) since there will be more switchings in
Case II which has M −2 more stages than Case I. It is worthy noting that the value of △(M) changes as the sample cost
c, the single-switching cost s or the number of processes M changes. On the one hand, △(M) increases as s
−clog c increases
when M is ﬁxed, which means that as s
−clog c increases, the decision maker is more inclined to choose Case I. The reason
is that the effect of switching cost on the objective function increases as s
−clog c increases, which leads the decision maker to
choose Case I with fewer switching times. On the other hand, △(M) increases as M increases when s
−clog c is ﬁxed, which
means that it’s more inclined to choose Case I as M increases, since there will be more stages in Case II as M increases, and
switching will occur at each stage which leads to an increase in switching cost.
C. Example
We illustrate the two cases of DBS policy in Fig. 1 with an example that ﬁnd the only abnormal process among M = 5
processes to clarify our idea.
Fig. 1 simulates the speciﬁcs of the DBS policy for Case I and Case II, respectively, when process 3 is an anomalous
process. For Case I, the decision maker probes the process m1(n) with the highest sum-LLR. At the beginning of the detection
procedure, since sum-LLRs of all processes are zero, a process is randomly selected to probe at t= 1. Suppose the decision
maker selects process 1. Since process 1 is in a normal state, the sum-LLR of process 1 will decreases, so at t= 2, the order
of sum-LLRs of all processes becomes {2,3,4,5,1}. Select process 2 to probe. In the same way, the sum-LLR of process 2
will also decrease, and the order of sum-LLRs of all processes may become {3,4,5,1,2}. Assume that the decision maker
selects process 3 to probe at t= 3. Since process 3 is in an abnormal state, the sum-LLR of process 3 increases and ranks ﬁrst,
i.e., m1(n) = 3 and Sm1(n)(n) >0. From then on, the decision maker will continue to probe process 3 with high probability
until Sm1(n)(τ) ≥−log c. Then the decision maker will stop the detection procedure and declares process 3 to be an anomaly.
For Case II, the decision maker probes process m−1(n) at each given time. Suppose the process 5 is randomly selected
to probe at the beginning of the detection procedure. Since process 5 is in a normal state, the sum-LLR of process 5 will
8
Fig. 1. Illustration the two cases of DBS Policy ( M = 5).
decreases and be ranked last. Thereafter, the decision maker will continue to probe process 5 until Sm−1(n)(n) < log c, and
then stop taking observations from process 5 and declare it as normal. Repeat this operation until all processes in normal state
are declared as normal.
IV. P ERFORMANCE ANALYSIS AND COMPARISON
In this section, we will analyze the performance of the DBS policy and compare DBS policy with DBS policy and R-SPRT
policy.
A. Performance Analysis
In this section, we analyze the performance of the DBS policy with different s and c. Theorem 1 and Theorem 2 are
presented to prove that the DBS policy is optimal in terms of minimizing the objective function as the observation cost c
approaches zero.
9
It is obvious that the order difference between s and c will affect the choice of strategy and the performance of the
corresponding policy. Considering the order relationship between the observation cost and switching cost, the problem is
divided into the following two scenarios:
Scenario 1: the single-switching cost s becomes insigniﬁcant relative to −clog c in the asymptotic regime of c →0, i.e.,
limc→0 s
−clog c = 0.
Scenario 2: the single-switching cost sis bounded below by −clog cin the asymptotic regime of c→0, i.e., limc→0 s
−clog c >
0.
According to the subsequent analysis, it is clear that the observation time E(τc) of DBS policy satisﬁes E(τc) = −log c
I∗(M) as
c→0. Thus, the observation cost can be denoted as cE(τc) = −clog c
I∗(M) , which is a function related to −clog c. Meanwhile, the
number of switchings is limited and the total switching cost can be denoted as a function related to s. Therefore, in order to
better analyze the performance of the DBS policy under the objective function in the form of Bayesian risk, the discussion is
based on the order of sand −clog c. Scenario 1 means that the total switching cost is much smaller than the total observation
cost and is negligible compared with the total observation cost. In Scenario 2 the total switching cost and total observation
cost are comparable.
We will analyze and prove the optimality of the DBS policy in two scenarios as c→0, respectively. The following theorems
show that DBS policy is asymptotically optimal or order optimal regarding minimizing the Bayesian risk as capproaches zero.
Theorem 1 will show that the Bayesian risk of DBS policy will be inﬁnitely close to the lower bound of Bayesian risk if
s= o(−clog c) as c→0. Theorem 2 will show that the Bayesian risk of the DBS policy is higher than the lower bound of
the Bayesian risk, but the ratio of the two is bounded.
Theorem 1 (Asymptotic Optimality of DBS Policy) . Let R(DBS) and R(Γ) be the Bayesian risks under the DBS policy and
any other policy Γ, respectively. If s= o(−clog c), then,
R(DBS) ∼−clog c
I∗(M) ∼inf
Γ
R(Γ) as c→0, (15)
where,
I∗(M) =



D(g||f), if Case I ,
D(f||g)/(M −1), if Case II .
Proof: For a detailed proof see Appendix A. We provide here a sketch. In the ﬁrst step, we prove that the objective
function based on Bayesian risk has an asymptotic lower bound infΓ R(Γ) and give the form of the asymptotic lower bound.
Then, we show that the Bayesian risk R under DBS policy approaches the asymptotic lower bound as c→0.
10
Based on the three perspectives of error probability, sampling cost and switching cost, the asymptotic behavior of Bayesian
risk is established. In Lemma 1, we show that the asymptotic lower bound on the total switching cost is ∑
k(k−1)πk, the
asymptotic lower bound on the sampling cost is −clog c
I∗(M) , and the error probability is O(c) following the same proof idea as in
[13].
The basic idea of proving that the DBS policy is asymptotic optimal is to prove that the Bayesian risk of the DBS policy
approaches the asymptotic lower bound as c approaches 0. In App.1, we prove that the asymptotic expected detection time
approaches −log c
I∗(M) while the error probability is O(c). In addition, we prove that the number of switching has an upper bound
which is independent of c.
Then, we analyze the expected number of observations and expected switching times of the DBS policy. Take the proof of
Case II as an example, we need split the testing into M−1 stage. Each stage is deﬁned according to the time when a certain
process is placed into set B. Then we analysis the three last passage times at every stage k, denote as τk
1 , τk
2 , τk
3 , where τk
1
is the time when region m−1(n) is always normal for all n ≥τk
1 , τk
2 is the time when region m−1(n) no longer changes
for all n ≥τk
2 , and τk
3 is the time when the region m−1(n) is placed into B. The switching only occurs during τk
1 and τk
2 ,
so the key point in our policy is to prove that there exist constants C >0 and γ >0 such that Pm(τk
1 > n) ≤Ce−γn and
Pm(τk
2 > n) ≤Ce−γn. Therefore, we can get the upper bound of the expected switching times as c →0, and denote d as
the upper bound. In addition, combining the above conclusion and the property of SPRT, we can draw the conclusion that
E(τk
3 ) ∼−log c/D(f||g) in Case II, so the asymptotic expected detection time approaches −log c/I∗(M).
Last but not Least, we will analyze the optimality of the DBS policy as capproaches zero based on the relationship between
sand c. Since limc→0 s
−clog c = 0, which means sis much smaller than −clog c, the ratio of expected number of switching to
the number of observations s·D·I∗(M)
−clog c approaches zero as c→0. Thus, the ratio of asymptotic lower bound of Bayesian risk
to the Bayesian risk of the DBS policy R(DBS)
infΓ R(Γ) is equal to 1 as c→0, which means the DBS policy is asymptotic optimal
as c→0.
Theorem 2 (Order Optimality of DBS Policy) . Let R(DBS) and R(Γ) be the Bayesian risks under the DBS policy and any
other policy Γ, respectively. If s= Ω(−clog c), then,
R(DBS) = O(inf
Γ
R(Γ)) as c→0 (16)
Proof: For a detailed proof see Appendix B. Theorem 2 can be proved in a similar way to theorem 1. Theorem 2 has the
same expected switching time and expected observation time as theorem 1. The difference between Theorem 2 and Theorem
1 is that the relationship between s and c is different. For Theorem 2, since limc→0 s
−clog c >0, the ratio of asymptotic lower
11
bound of Bayesian risk to the Bayesian risk of the DBS policy R(DBS)
infΓ R(Γ) is larger than 1 but bounded by positive inﬁnity as
c→0 , which means the DBS policy is order optimal as c→0.
In the following, we will analyze the DGF policy and the R-SPRT policy when they are applied to the anomaly detection
problem considering switching cost. The DGF policy has been shown to be an asymptotically optimal policy that minimizes
the detection time subject to an error probability constraint. And the R-SPRT policy is an optimal policy that minimizes the
number of switchings.
B. Comparison with the DGF Policy
As DBS policy is inspired by DGF policy in [13], we would like to highlight the difference between DBS policy and DGF
policy to explain how the Bayesian risk considering switching cost is reduced in DBS policy.
1) The DGF Policy: The DGF policy is a deterministic policy. At each time, the selection rule φ(n) of the DGF policy
chooses cells according to the order of their sum-LLRs which is similar to the DBS policy. Speciﬁcally, based on the relative
order of D(g||f) and D(f||g)/(M−1), either the process with the highest sum-LLRs or the process with the second highest
sum-LLRs are chosen, i.e.,
φ(n) =



m1(n), if D(g||f) ≥D(f||g)
M−1 ,
m2(n), if D(g||f) < D(f||g)
M−1 .
The stopping rule and decision rule under the DGF policy are given by:
τ = inf{n: m1(n) −m2(n) ≥−log c},
and,
δ= m1(n).
2) Comparison: In Case I, both the DBS policy and the DGF policy are to probe the process which is most likely to
be abnormal until the decision makers declare one process as abnormal. The selection rule of DGF policy is to probe the
m1(n) process at each time, which is the same as DBS policy. The stopping rule under DGF policy is associate with the
difference between the highest observed sum-LLRs Sm1(n)(n) and the second highest observed sum-LLRs Sm2(n)(n). Once
Sm1(n)(n)−Sm2(n)(n) ≥−log c, the decision maker of DGF policy ﬁnalizes the detection procedure. Meanwhile, the decision
maker of DBS policy stops the detection procedure once the highest observed sum-LLRs Sm1(n)(n) is greater than −log c.
Since there is only one anomalous process, the second highest observed sum-LLRs is less than 0 with high probability. Because
of the setting of the selection rule and stopping rule, DGF policy has fewer excepted observation times than DGF policy while
12
it has the same expected switching times as DBS policy, which makes the Bayesian risk of DGF policy slightly lower than
DBS policy. However, the Bayesian risk gap between DGF and DBS policy caused by the number of observations is small
enough to not affect the asymptotic optimality of the DGF policy.
However, in Case II, DGF policy probes the process with the second sum-LLRs at each time, and the testing is terminated
once the difference between the highest and the second highest observed sum-LLRs is greater than −log c. Since the sum-LLRs
of probed process m2(n) at time nwill decrease with high probability after current observation, the probed process will always
changes, which cause a large switching cost. In contrast, DBS policy always probe the process m−1(n) in Case II, since the
observed sum-LLRs of process m−1(n) at time n will decrease with high probability after current probing, DBS policy will
probe the same process with high probability until it has been declared. Thus, the number of switching times is reduced.
C. Comparison with the R-SPRT Policy
In this part, we will compare the difference between the DBS policy and the R-SPRT policy, which has the smallest expected
switching time.
1) The R-SPRT Policy: The R-SPRT policy has a random selection rule, where a series of SPRTs are performed until all
the abnormal process is tested in a random order. In other words, the decision maker selects one process to probe randomly
and performs SPRT test for the currently probed process until its state is declared. Once one process is declared as abnormal,
the detection procedure will be ﬁnished.
In R-SPRT, the stopping and decision rules are given by comparing the sum-LLRs Sm(n) with boundary values at each
time n. Thus, the R-SPRT test is carried out as follows:
• If Sm(n) ∈(log c,−log c), continue to take observations from process m.
• If Sm(n) ≤−log c, stop taking observations from process mand declare it as normal. In addition, select another process
whose state hasn’t been declared randomly to probe at the next time.
• If Sm(n) ≥−log c, stop taking observations from process mand declare it as abnormal. Then, ﬁnish the whole detection
procedure and τ = n.
Since the R-SPRT policy selects processes randomly, each process has same probability to be selected at each stage. The
expected switching time of the R-SPRT policy can be given by
E(τs|R-SPRT) = M −1
2 ,
while the expected observation time of the R-SPRT is
E(τc|R-SPRT) = −log c
( 1
D(g||f) + M −1
2D(f||g)
)
.
13
2) Comparison: In this part, we will compare the performance of the R-SPRT policy and the DBS policy on the objective
function (4). The Bayesian risks of the R-SPRT policy and the DBS policy can be given by:
R(R-SPRT) = cE(τc|R-SPRT) + sE(τs|R-SPRT)
= −clog c
( 1
D(g||f) + M −1
2D(f||g)
)
+ sM −1
2 ,
R(DBS) = c·E(τc|DBS) + s·E(τs|DBS)
= −clog c 1
I∗(M) + sE(τs|DBS),
where there exist M−1
2 <D< ∞such that M−1
2 <E (τs|DBS) <D.
Assume that R(DBS) is lower than R(R−SRPT ), i.e.,
R(DBS) ≤−clog c 1
I∗(M) + sD
<−clog c
( 1
D(g||f) + M −1
2D(f||g)
)
+ sM −1
2
= R(R-SPRT),
we can draw the conclusion as follow:
s
−clog c <
1
D(g||f) + M−1
2D(f||g) − 1
I∗(M)
D−M−1
2
.
In another words, when the order relationship between s and −clog c meets the above conditions, the DBS performs better
than the R-SPRT policy.
V. NUMERICAL RESULTS
In this section, we present numerical examples to illustrate the performance of DBS policy. We consider the case where
there is only one anomalous process among M processes. The DBS policy will be compared with Chernoff test [2], DGF
policy [13], Sluggish policy [13] and R-SPRT policy.
Chernoff test is a randomized policy, which works as below for anomaly detection problem in this case. When D(g||f) ≥
D(f||g)/(M −1), Chernoff policy selects the m1(n) process at each given time since there is only one abnormal process
and the m1(n) is most likely to be abnormal. When D(g||f) <D(f||g)/(M−1), the decision maker will select one process
randomly with equal probability from processes m̸= m1(n). As a result, the Chernoff test has a different selection rule with
the DBS policy.
Sluggish policy is an extended algorithm based on Chernoff test, which introduce costs for switching of actions. The Sluggish
policy merely slows down the switching of actions via an independent and identically distributed Bernoulli modulation process,
which performs well in the active hypothesis testing problem considering switching cost.
14
We set the simulations with the following parameters. When process m is probed at time n, an observation ym(n) is
independently drawn from a Poisson distribution f ∼Pois(λf) or g ∼Pois(λg), depending on whether the process is the
target or normal. It is easy to show that
D(g||f) = λf −λg + λglog( λg
λf
),
D(f||g) = λg −λf + λf log(λf
λg
).
(17)
Let Tc(Γ) be the number of observations under the policy Γ, and TLB
c = −log c
I∗(M) be the asymptotic lower bound on the
observation times as c→0. Deﬁne
T′
c(Γ) ≜ (Tc(Γ) −TLB
c )/TLB
c
as the relative ratio of observations under policy Γ compared to the asymptotic lower bound of observation.
Let R(Γ) be the Bayesian risks under the policy Γ, and RLB = −clog c
I∗(M) + s·∑
k(k−1)πk be the asymptotic lower bound
on the Bayesian risk as c→0. Deﬁne
L(Γ) ≜ (R(Γ) −RLB)/RLB (18)
as the Bayesian relative risk under policy Γ compared to the asymptotic lower bound, which serve as performance measures
of the tests in the ﬁnite regime. Following Theorems 1,2, we expect L(DBS) to approach 0 when s = o(−clog c)as c →0
and is bounded by positive inﬁnity when s= Ω(−clog c).
A. s/c is ﬁxed
First we consider the case where M = 5 and s= 2c, which means s
−clog c = 0 as c→0. In this case, the loss of a single
switch and a single observation is comparable, while the total switching cost is much smaller than the total observation cost.
For Sluggish policy [13], the switching probability is set to p= 0.1, which means switching occurs approximately every ten
observations. We set λf = 0.4, λg = 0.001 and obtained D(g||f) ≈0.39, D(f||g)/(M −1) ≈0.50. The performance of all
algorithms is presented in Fig. 2, which are the average of 1000 trials.
It is shown that Sluggish policy has the largest number of observations and DGF policy is the smallest in Fig. 2(a). In Fig.
2(b), we can ﬁnd that the switching number of R-SPRT policy is less than other policies. Regardless of the relative ratio of
observation as Fig. 2(a) or the number of switching as Fig. 2(b), the performance of the DBS strategy is both sub-optimal.
The dashed rectangular area of Fig. 2(a) and Fig. 2(b) shows that the observation delay and switching number of DBS policy
change suddenly around −log c= 70. The reason is that DBS policy chooses to probe the process with the largest sum-LLRs
since it is in Case I when −log c< 70. However, because of the change of c, DBS policy changes to Case II and chooses to
15
0 20 40 60 80 100 120 140 160 180 200
1
2
3
4
5
6
7Relative Number of observations
DGF Policy
Chernoff Policy
Sluggish Policy
DBS Policy
SPRT Policy
(a) The relative ratio of observations
0 20 40 60 80 100 120 140 160 180 200
0
50
100
150
200
250
300
350
400Number of Switchings
DGF Policy
Chernoff Policy
Sluggish Policy
DBS Policy
SPRT Policy
(b) Switching number
0 20 40 60 80 100 120 140 160 180 200
0
1
2
3
4
5
6Bayesian relative risk
DGF Policy
Chernoff Policy
Sluggish Policy
DBS Policy
SPRT Policy
(c) Bayes relative risk
Fig. 2. DBS Policy in M = 5, s= 2c, λf = 0.4, λg = 0.001
16
observe the M−1 normal processes when −log c> 70. The transition between cases increases the number of stages, leading
to an increase in the number of switchings and a decrease in the number of observations.As a result, the Bayes relative risks
will continuously decrease and approach to 0 as c→0.
B. s= o(−clog c)
In this section, we consider the scenario where s
−clog c = 5c, which means s
−clog c = 0 as c→0. In this case, total switching
cost is sufﬁciently small in comparison with the total observation cost. In addition, △(M) approaches 0 as c→0, so Case I
and Case II of DBS policy can be simpliﬁed to the following form,
Case I : D(g||f) ≥D(f||g)
M −1 ,
Case II : D(g||f) < D(f||g)
M −1 .
We set λf = 0.001,λg = 0.4 and obtained D(g||f) ≈0.39,D(f||g)/(M −1) ≈0.50, when DBS policy, DGF policy and
Chernoff policy are all in Case II and inclined to probe the normal processes. In this case, DBS policy selects process m−1(n)
at each given time n, while the decision maker of DGF policy selects process m2(n) at each given time. And the Chernoff test
draws one process randomly with equal probability from processes {m2(n),m3(n),...,m M(n)}at each given time n. Since
the test statistics from normal processes are less than zero with high probability, the LLR of normal process will be lower and
lower. Thus, the decision maker of DBS policy will probe the same process at each given time with high probability, while
the decision maker of DGF policy switches the observed process constantly. The performance of all algorithms is presented
in Fig. 3.
C. s= Ω(−clog c)
Then we consider the case where s
−clog c = 2, which means the single-switching cost sis large enough that the cost caused
by switching cannot be ignored. In addition, △(M) does not change with the change of c. We set λf = 0.4, λg = 0.001
and obtained D(g||f) ≈0.39, D(f||g)/(M −1) ≈0.50, D(g||f) + △(M) ≥7, DBS policy is in Case I for all values of c
while DGF policy is in Case II. The performance of all algorithms is presented in Fig. 4. It is shown that DGF policy has less
observations, but DBS policy has less switching. Fig. 4(c) shows that DBS policy is optimal among all algorithms.
VI. C ONCLUSION
The problem of detecting an anomalous process among multiple processes considering switching cost is studied. Due to the
resource constraints, only one process can be probed at each time, and the observations from each process follow two different
17
20 40 60 80 100 120 140 160 180 200
1
1.5
2
2.5
3
3.5
4
4.5Number of observations
DGF Policy
Chernoff Policy
Sluggish Policy
DBS Policy
SPRT Policy
(a) The relative ratio of observations
20 40 60 80 100 120 140 160 180 200
0
50
100
150
200
250
300
350
400Number of Switchings
DGF Policy
Chernoff Policy
Sluggish Policy
DBS Policy
SPRT Policy
(b) Switching number
20 40 60 80 100 120 140 160 180 200
0
0.5
1
1.5
2
2.5
3
3.5Bayesian relative risk
DGF Policy
Chernoff Policy
Sluggish Policy
DBS Policy
SPRT Policy
(c) Bayes relative risk
Fig. 3. DBS Policy in M = 5, s
−c log c = 5c, λf = 0.001, λg = 0.4
18
0 20 40 60 80 100 120 140 160 180 200
1
2
3
4
5
6
7Number of observations
DGF Policy
Chernoff Policy
Sluggish Policy
DBS Policy
SPRT Policy
(a) The relative ratio of observations
0 20 40 60 80 100 120 140 160 180 200
0
50
100
150
200
250
300
350
400Number of Switchings
DGF Policy
Chernoff Policy
Sluggish Policy
DBS Policy
SPRT Policy
(b) Switching number
0 20 40 60 80 100 120 140 160 180 200
0
20
40
60
80
100
120
140Bayesian relative risk
DGF Policy
Chernoff Policy
Sluggish Policy
DBS Policy
SPRT Policy
(c) Bayes relative risk
Fig. 4. DBS Policy in M = 5, s
−c log c = 5c, λf = 0.001, λg = 0.4
19
distributions, depending on whether the process is normal or abnormal. Each swithcing across processes incurs an additional
switching cost s and each observation incurs detection delay c, while a wrong declaration incurs a loss of 1. The objective is
to ﬁnd a search strategy that minimizes the expected detection time and the expected switching cost subject to error probability
constraint. Considering the order relationship between the detection delay and switching cost, we divided the problem into
two scenarios: the total switching cost is much smaller than the detection delay(i.e., s = o(−clog c) as c →0), or the total
switching cost is comparable with the detection delay(i.e., s= Ω(−clog c) as c→0). We propose a deterministic policy and
proved that our policy is asymptotically optimal when the total switching cost is much smaller than the total observation cost
and is order optimal when the total switching cost is comparable with the observation cost as capproaches zero. We also offers
better performance in the ﬁnite regime for different scenarios respectively. Our policy can also be applied to target detection,
fraud detection and other read-world scenarios.
Deriving optimal policies for the anomaly detection problem with switching cost considered in this paper requires the
assumption that only one process is in an abnormal state and the decision maker can probe only one process at each time. In
the future, we will further extend the problem to handle the case where multiple anomalous processes are present and multiple
processes can be probed simultaneously. In this paper, we also assume that the observation distributions under both hypothesis
are completely known. In further research, we expect that the policy can be extended to the situation where the distribution of
each process is heterogeneous or the number of processes is unknown.
APPENDIX
A. The Proof of Theorem 1
In this section, we will prove the asymptotic optimality of DBS policy in the situation where s= o(−clog c) as capproaches
0. In App A.1, we show that −clog c
I∗(M) + s·∑M
k=1(k−1)πk is an asymptotic lower bound on the Bayesian risk. Then, we show
in App A.2 that if s= o(−clog c), the Bayesian risk under DBS policy R(DBS) approaches the asymptotic lower bound as
c→0.
1) The Asymptotic Lower Bound of the Bayesian risk
Proposition 1. Let R(Γ) be the Bayesian risks under any policy Γ. Then,
R(Γ) ≥c·−log c
I∗(M) + s·
M∑
k=1
(k−1)π′
k as c→0, (19)
where π′
k denote the kth highest probability of the priori probability set {πm}M
m=1 and
I∗(M) =



D(g||f), if Case I ,
D(f||g)/(M −1), if Case II .
(20)
20
Proof: We divide the discussion about the asymptotic lower bound of Bayesian risk into the following three part: the
probability of error, the expected detection cost and the expected switching cost.
In App.A.1 of DGF Policy [13], it has been proved that −clog c
I∗(M) is an asymptotic lower bound on the Bayesian risk without
switching cost, which can be regarded as the asymptotic lower bound on the summation of the probability of error and the
expected detection cost, i.e.,
Pe(Γ) + cE(τc|Γ) ≥c·−log c
I∗(M) as c→0. (21)
Then, we will analyze the lower bound of the expected switching time. Assume that each process must be probed continuously
until its state is declared. In another words, switching across processes is allowed only when the state of the currently probed
process is declared, which is the minimal number of switchings during the detection procedure. Thus at most M−1 switchings
will occur and the expected switching time can be denoted as
E(τs) =
M−1∑
t=0
tP(τs = t),
where ∑
tP(τs = t) = 1.
Sorting {πm}M
m=1 in descending order, we get the set {π′
k}M
k=1, where π′
1 ≥π′
2 ≥···≥ π′
k ≥···≥ π′
M and π′
k denote the
k-th highest probability of the priori probability set {πm}M
m=1. Let π′
ik be the corresponding posterior probability at the i-th
choice. Let pi
k be the probability that process k is selected at the i-th choice. Then the probability of selecting the abnormal
process at the t-th choice can be expressed as
P(τs = t) = (1 −P(τs <t))
M∑
k=1
π′
tk ·pt
k.
It is known that P(τs = t) can be expressed as an expression independent of t. Thus, the problem of minimizing E(τs) can
be transformed into maximizing P(τs = t) for each t.
Then the probability of selecting the abnormal process at the ﬁrst choice, which means the number of switching is equal to
zero, is
P(τs = 0) =
M∑
k=1
π′
0k ·p1
k,
where π′
0k = π′
k. The solution for maximizing P(τs = 0) is to make p1
1 be 1 and the rest to be 0. Thus, P(τs = 0) ≤π′
1.
Then the probablity of selecting the abnormal process at the second choice is
P(τs = 1) = (1 −P(τs <1))
M∑
k=1
π′
tk ·pt
k
= (1 −P(τs = 0)) · 1
1 −π′
1
·
(π′
2 ·p2
2 + ··· + π′
k ·p2
k + ··· + π′
M ·p2
M).
21
The solution for maximizing P(τs = 1) is to make p2
2 be 1 and the rest to be 0. Thus, P(τs = 1) ≤π′
2.
Concequently, we can draw the conclusion that
E(τs) =
∞∑
t=0
tP(τs = t) ≥
M∑
k=1
(k−1)π′
k
Combining the above conclusions, the Bayesian risk considering switching cost in our problem is
R(Γ) = Pe(Γ) + cE(τ|Γ) + sE(τs|Γ)
≥−clog c
I∗(M) + s·
M∑
k=1
(k−1)π′
k,
(22)
where π′
k denote the kth highest probability of the priori probability set {πm}M
m=1.
2) Asymptotic Optimality of DBS Policy in Scenario 1
In the following part, ﬁrstly, Lemma 1 shows that the error probability Pe = O(c). Secondly, Lemma 2 to Leamma 5 shows
that the expected switching time of the DBS policy is upper bounded by a constant. Then, Lemma 6 shows that the expected
detection time under the DBS policy is upper bounded by −(1 + o(1)) log c
I∗(M) . Finally, We will prove that the asymptotic
Bayesian risk of DBS policy approaches the asymptotic lower bound.
Lemma 1. In the asymptotic regime, the error probability of DBS policy is upper bounded by:
Pe ≤(M −1)c. (23)
Proof: Let αm,j = Pm(δ = Hj) is the probability of declaring δ = Hj for all j ̸= m when Hm is true. Thus,
αm = ∑
j̸=mαm,j. Note that accepting Hj implies that Sj(n) ≥−log c in Case I or Si(n) ≤log c for all i̸= j in Case II.
The stopping rule of single process is the same as the stopping rule of SPRT [3]. According to the conclusion of SPRT [3],
we can show that for all Hj ̸= Hm,
αm =
∑
j̸=m
αm,j ⩽ (M −1)c. (24)
Hence, (23) follows.
Under Hypothesis Hm, Sm(n) is a random walk with positive expected increment Em(lm(n)) = D(g||f) >0 for m, while
Sj(n), is a random walk with negative expected increment Em(lj(n)) = −D(f||g) <0 for j ̸= m. As a result, in Case I, the
process mis observed with higher probability than other processes j when nis sufﬁciently large, and the situation is opposite
in Case II. Next, we deﬁne a random time τk
1 . In Case I, τk
1 is the last passage time when process m1(n) (the largest observed
sum-LLRs process) is always the abnormal process for all n ≥τk
1 at stage k. In Case II, τk
1 is the last passage time when
process m−1(n) (the smallest observed sum-LLRs process) is always normal for all n ≥τk
1 at stage k. It should be noted
that τk
1 is not a stopping time and the agent does not know whether τk
1 has arrived. In Lemma 2 below we show that τk
1 is
22
sufﬁciently small with high probability. We will use this result later to establish the upper bound of the actual stopping time
τ, the observations time τc and the switching time τs under DBS policy.
Deﬁnition 1. In Case I, denote τk
1 as the smallest integer such that m1(n) ̸= j for all normal process j and all n ≥τk
1 in
stage k. In Case II, denote τk
1 as the smallest integer such that m−1(n) ̸= m for the abnormal process m and all n≥τk
1 in
stage k.
Lemma 2. If the DBS policy has not been terminated, there exist ﬁnite constants D1 >0 and µ1 >0 such that
Pm(τk
1 >n) ≤D1e−µ1n
for all i= 1,2,...,M at the corresponding stage.
Proof: There is only one stage in Case I, our policy observes the m1(n) process and ﬁnalizes the stage once Sm1(n)(n) ≥
−log c. Note that
Pm(τk
1 >n) ≤Pm(max
j̸=m
sup
t≥n
Sj(t) −Sm(t) ≥0)
≤
∑
j̸=m
∞∑
t=n
Pm(Sj(t) ≥Sm(t)).
(25)
In each stage of Case II, our policy will choose to observe the m−1(n) process and ﬁnalizes the stage once Sm−1(n)(n) ⩽
log c. Note that
Pm(τk
1 >n) ≤Pm(min
j̸=m
inf
t≥n
(Sm(t) −Sj(t)) ≤0)
≤
∑
j̸=m
∞∑
t=n
Pm(Sj(t) ≥Sm(t)).
(26)
Therefore, it sufﬁces to show that there exist ﬁnite constants D′
1 >0 and µ′
1 >0 such that Pm(Sj(t) ≥Sm(t)) ≤D′
1e−µ′
1n
for both Case I and Case II. The [13, Lemma 7] has proved the conclusion for Case I, because the preconditions of DBS
policy is the same as the DGF policy [13] in Case I, the conclusion is still valid in this problem. Then, we focus on Case II
and show that there exit D> 0 and µ> 0 such that Pm(Sj(t) ≥Sm(t)) ≤De−µn.
Let Nj(n) ≜ ∑n
t=1 1j(n) be the number of times that process j has been observed up to time n. Each term in the summation
on the RHS of (26) can be upper bounded by
Pm(Sj(n) ≥Sm(n))
≤Pm(Sj(n) ≥Sm(n),Nj(n) ≥ρn)
+ Pm(Sj(n) ≥Sm(n),Nm(n) ≥ρn)
+ Pm(Sj(n) ≥Sm(n),Nj(n) <ρn,N m(n) <ρn),
(27)
23
where ρ= 1
16(M−2) and 0 <ρ ≤1/16. Speciﬁcally, applying ( [13], Lemma 7, (67)) to our model, we can draw the conclusion
that there exist ﬁnite constants γ1 >0 and C1 >0 such that
Pm(Sj(n) ≥Sm(n))
≤2C1e−γ1n + Pm(Sj(n) ≥Sm(n),Nj(n) <ρn,N m(n) <ρn)
≤2C1e−γ1n+
∑
r̸=j,m
Pm
(
˜Nr(n) > n(1 −2ρ)
M −2 ,Nj(n) <ρn,N m(n) <ρn
)
,
(28)
From the second last inequality to the last inequality, what needs note is that the event (Nj(n) < ρn,Nm(n) < ρn) implies
that processes j,m are not observed at least ˜n = n−Nj(n) −Nm(n) ≥n(1 −2ρ) times. Let ˜Nr(n) be number of times
when process r̸= j,m has been probed and process j,m have not been probed up to time n. We refer to each such time as
r̸=j,m-probing time. there exist a process r̸= j,m such that ˜Nr(n) ≥ ˜n
M−2 ≥n(1−2ρ)
M−2 .
It remains to show that the second term in the summation on the RHS of (28) decreases exponentially with n. Due to the
difference in the selection rules of DBS policy and DGF policy in Case II, it should be noted that at every r̸=j,m-probing
time, Sj(n) ≥Sr(n) and Sm(n) ≥Sr(n) must occur in Case II of DBS policy because the agent always observes the process
m−1(n). Let ˜tr
1,˜tr
2,··· ,˜tr
˜Nr(n) be the r̸= j,m-probing time indices and let ζ ≜ 1−2ρ
2(M−2) . The event ˜Nr(n) ≥n(1−2ρ)
M−2 implies
that at time ˜tr
ζn the inequalities Sj(˜tr
ζn) ≥Sr(˜tr
ζn) and Sm(˜tr
ζn) ≥Sr(˜tr
ζn) must occur. Since Nr(n) is the total number of
observations taken from process r up to time t, then Nr(˜tr
ζn) ≥ ˜Nr(˜tr
ζn) = ζn. Hence, each term in the summation on the
RHS of (28) can be upper bounded by
Pm
(
Nr(n) > n(1 −2ρ)
M −2 ,Nj(n) <ρn,N m(n) <ρn
)
≤Pm
(
˜Nr(n) >ζn,N j(n) <ρn
)
+
Pm
(
˜Nr(n) >ζn,N m(n) <ρn
)
≤
n∑
N′
r=ζn
Pm
(
Sj(˜tr
ζn) ≥Sr(˜tr
ζn),Nj(n) <ρn
)
+
n∑
N′r=ζn
Pm
(
Sm(˜tr
ζn) ≥Sr(˜tr
ζn),Nm(n) <ρn
)
.
(29)
24
Using the i.i.d. property of the LLRs across time we have
Pm
(
Nr(n) > n(1 −2ρ)
M −2 ,Nj(n) <ρn,N m(n) <ρn
)
≤
n∑
N′r=ζn
n∑
Nj=0
Pm


Nj∑
i=1
lj(i) ≥
N′
r∑
i=1
lr(i)

+
n∑
N′r=ζn
n∑
Nm=0
Pm


Nm∑
i=1
lm(i) ≥
N′
r∑
i=1
lr(i)


≤
n−ζn∑
q=0
ρn∑
Nj=0
Pm


Nj∑
i=1
lj(i) ≥
ζn+q∑
i=1
lr(i)

+
n−ξn∑
q=0
ρn∑
Nm=0
Pm
(Nm∑
i=1
lm(i) ≥
ξn+q∑
i=1
lr(i)
)
.
(30)
Then we need to bound each term in the summation on the RHS of (30). Note that
ζn+q∑
i=1
lr(i) +
Nj∑
i=1
−lj(i) =
ζn+q∑
i=1
˜lr(i) +
Nj∑
i=1
−˜lj(i) −D(f||g)(ζn+ q−Nj), (31)
where
˜lk(i) =



lk(i) −D(g||f),if k= m,
lk(i) + D(f||g),if k̸= m.
Then,
Pm


ζn+q∑
i=1
lr(i) ≤
Nj∑
i=1
lj(i)


≤Pm


ξn+q∑
i=1
˜lr(i) +
n′
∑
i=1
−˜lj(i) ≥D(f||g)(ζn+ q−Nj)


≤Pm


ξn+q∑
i=1
˜lr(i) +
n′
∑
i=1
−˜lj(i) ≥C1(ζn+ q)

.
(32)
Applying the Chernoff inequality and using the i.i.d. property of ˜lr(i),˜lj(i) across time,
Pm


ξn+q∑
i=1
˜lr(i) +
n′
∑
i=1
−˜lj(i) ≥C1(ζn+ q)


≤Em
(
e
s·
(∑ξn+q
i=1
˜lr(i)+∑n′
i=1 −˜lj(i)
))
·e−sC1(ζn+q)
≤
(
Em(es·˜lr(1))
)ξn+q
·
(
Em(e−s·˜lj(1))
)Nj
·e−sC1(ζn+q)
≤
(
Em(es·(˜lr(1)+C1))
)ξn+q
·
(
Em(es·(−˜lj(1)+C1))
)Nj
·e−sC1(ζn+q) ·e−sC1(ζn+q+Nj)
(33)
for all s <0 and C1 = D(f||g). Since Em(˜lr(1) + C1) = C1 > 0 and Em(−˜lj(1) + C1) = C1 > 0 are strictly positive,
differentiating the MGFs (Moment Generating Functions) of lj(i),lm(i) with respect to s yields strictly positive derivatives
25
at s= 0. As a result, there exist constants s <0 and γ2 >0 such that Em(es·(˜lr(1)+C1)) , Em(es·(−˜lj(1)+C1)) and esC1 are
strictly less than e−γ2 <1. Hence,
Pm


ζn+q∑
i=1
lr(i) ≤
Nj∑
i=1
lj(i)


≤
(
Em(es·(˜lr(1)+C1))
)ξn+q
·
(
Em(es·(−˜lj(1)+C1))
)Nj
·e−sC1(ζn+q) ·e−sC1(ζn+q+Nj)
≤e−γ2(ζn+q) ·e−γ2Nj ·e−γ2(ζn+q) ·e−γ2(ζn+q+Nj)
= e−γ2(3ζn+3q+2Nj).
(34)
Therefore,
n−ζn∑
q=0
ρn∑
Nj=0
Pm


Nj∑
i=1
lj(i) ≥
ζn+q∑
i=1
lr(i)


≤
n−ζn∑
q=0
ρn∑
Nj=0
e−γ2(3ζn+3q+2Nj)
≤e−γ2·3ζn · 1
1 −e−3γ2
· 1
1 −e−2γ2
= C3e−γ3n,
(35)
where C3 = 1
(1−e−3γ2)(1−e−2γ2) and γ3 = 3ζγ2.
Following the minor modiﬁcations, we can prove that there exist ﬁnite constants C4 >0 and γ4 >0 such that
n−ξn∑
q=0
ρn∑
Nm=0
Pm
(Nm∑
i=1
lm(i) ≥
ξn+q∑
i=1
lr(i)
)
≤C4e−γ4n. (36)
Thus, we complete the proof.
In what follows we deﬁne the second random time τk
2 , where τk
2 can be viewed as the last passage time when the switching
no longer occurs at stage k. It should be noted that τk
2 ≥τk
1 and the agent does not know whether τk
2 has arrived. In Lemma
3 we show that the total time between τk
1 and τk
2 is sufﬁciently small with high probability, which means that the number of
switching is limited.
Deﬁnition 2. In Case I, denote τk
2 as the smallest integer such that the value of m1(n) no longer changes for all n≥τk
2 in
stage k. In Case II, denote τk
2 as the smallest integer such that the value of m−1(n) no longer changes for all n≥τk
2 in stage
k.
Deﬁnition 3. nk
2 ≜ τk
2 −τk
1 denotes the total amount of time between τk
1 and τk
2 in stage k.
Lemma 3. If DBS policy has not been terminated, there exist D2 >0 and µ2 >0 such that
Pm(nk
2 >n) ≤D2e−µ2n
26
for all m= 1,2,...,M at the corresponding stage.
Proof: In Case I, we have only one anomalous process. It is obvious that τk
2 = τk
1 since there is only one stage, so the
conclusion of Lemma 2 also proves that there exist constants D2 >0 and µ2 >0 such that Pm(nk
2 >n) ≤D2e−µ2n.
In Case II, it can be veriﬁed that the M−1 normal processes are observed with higher probability than anomalous process
by Lemma 2. Sm−1(n)(n) is likely to be a random variable with negative expected increment E(lm−1(n)(n)) <0. It is obvious
that Sm−1(n)(n) ≤Sm−2(n)(n), so E(Sm−2(t)(t) −Sm−1(t)(t)) >0.
Note that,
Pm(nk
2 >n)
≤Pm(sup
t≥n
lm−1(t)(t+ 1) +Sm−1(t)(t) −Sm−2(t)(t) ≥0)
≤
∞∑
t=n
Pm
(
˜lm−1(t)(t+ 1) +Sm−1(t)(t) −Sm−2(t)(t) ≥D(f||g)
)
≤
∞∑
t=n
Em
(
es·(˜lm−1(t)(t+1)+Sm−1(t)(t)−Sm−2(t)(t)−ϵ))
·e−s(D(f||g)−ϵ)
(37)
for all s> 0 and 0 <ϵ<D (f||g).
The last equality follows by applying the Chernoff bound for each term in the summation on the RHS of the equality. Since
Em
(
(˜lm−1(t)(t+ 1) +Sm−1(t)(t) −Sm−2(t)(t) −ϵ
)
≤−ϵ< 0 are strictly negative, differentiating the MGFs of ˜lm−1(t)(t+
1) + Sm−1(t)(t) −Sm−2(t)(t) −ϵ with respect to s yields strictly negative derivatives at s= 0. Hence, there exist s> 0 and
γ >0 such that Em
(
(˜lm−1(t)(t+ 1) +Sm−1(t)(t) −Sm−2(t)(t) −ϵ
)
and e−sϵ are strictly less than e−γ < 1. Furthermore,
there exist γ′ > 0 such that each term in the summation on the RHS less or equal to e−γ′t. Thus, there exist C5 > 0 and
γ5 >0 such that
∞∑
t=n
Em
(
es·(˜lm−1(t)(t+1)+Sm−1(t)(t)−Sm−2(t)(t)−ϵ))
·e−s(D(f||g)−ϵ)
≤
∞∑
t=n
e−γ′t ≤C5e−γ5n,
(38)
which completes the proof.
According to the deﬁnition 1 and deﬁnition 2, we can know that the switchings between two different processes only occur
during τk
1 and τk
2 . Based on this, Lemma 4 will show that the time of switchings decreases exponentially with n.
27
Lemma 4. Assume that the DBS policy is implemented indeﬁnitely. Then, there exist ﬁnite constants D3 >0 and γ3 such that
Pm(τk
s >n) ≤D3e−γ3n
for all m= 1,2,...,M at the corresponding stage.
Proof: It should be noted that the switching only occurs during τk
1 and nk
2, therefore the times of switchings at each stage
follow that τk
s ≤τk
1 + nk
2. Thus, there exist constants D3 >0 and γ3 >0 such that,
Pm(τk
s >n) ≤Pm(τk
1 + nk
2 >n)
≤Pm(τk
1 > n
2 ) + Pm(nk
2 > n
2 )
≤D1e−γ1n + D2e−γ2n
≤D3e−γ3n,
(39)
which completes the proof.
Below, we diﬁne a random time τk
3 . In Case I, τk
3 is the time when sufﬁcient information for declaring process m1(n)
as abnormal process has been gathered. In Case II, denote τk
3 as the time when sufﬁcient information for declaring process
m−1(n) as normal process has been gathered.
Deﬁnition 4. In Case I, denote τk
3 as the smallest integer such that Sm1(τk
3 )(τk
3 ) ≥−log c. In Case II, denote τk
3 as the smallest
integer such that Sm−1(τk
3 )(τk
3 ) ≤log c.
Deﬁnition 5. nk
3 ≜ τk
3 −τk
2 denotes the total amount of time between τk
3 and τk
2 in stage k.
Combine the above deﬁnitions and conclusions, the DBS policy does not occurs switchings during τk
2 to τk
3 . For each
process, we will stop observing once |Sm(n)|≥− log c, it is equivalent to doing SPRT for each process during nk
3. Thus,
according to the conclusion of SPRT, we can draw the conclusion that,
Em(nk
3) ≤



−log c
D(g||f) , if Case I ,
−log c
D(f||g) , if Case II .
(40)
Next, we will analyze the expected times of switchings and observations of DBS policy in the asymptotic regime.
Lemma 5. Assume that the DBS policy is implemented indeﬁnitely. Then, there exists Ts ∈(0,∞) such that the expected
switching time of the DBS policy Em(τs|DBS) satisﬁes
Em(τs|DBS) ≤Ts. (41)
28
Proof: We ﬁrst focus on one stage in the entire detection procedure. Then,
Em(τk
s) =
∞∑
t=1
t·Pm(τk
s = t)
≤
∞∑
t=1
t·Pm(τk
s >t −1)
≤
∞∑
t=1
t·D3e−γ3(t−1)
= D3eγ3
∞∑
t=1
te−γ3t = D3(1 −e−γ3)2,
(42)
where 0 <D3 <∞and γ3 >0. Thus, there exist Ts ∈(0,∞) such that
Em(τs) = Em(
∑
k
τk
s) =
∑
k
Em(τk
s)
≤
∑
k
D3(1 −e−γ3)2 ≤Ts,
(43)
which completes the proof of Lemma 5.
It remains to show that the expected number of observations of the DBS policy.
Lemma 6. In the asymptotic regime, the expected detection time τc under the DBS policy is bounded by:
E(τc) ≤−(1 + o(1)) log c
I∗(M) as c→0. (44)
Proof: Following the above deﬁnitions, in Case I,
Em(τc) = Em(τ1
3 )
= Em(τ1
1 + n1
2) + Em(n1
3)
≤Ts + −log c
D(g||f)
≤−(1 + o(1)) log c
D(g||f) as c→0.
(45)
In Case II,
Em(τc) = Em
(M−1∑
k=1
τk
3
)
=
M−1∑
k=1
(
Em(τk
1 + nk
2) + Em(nk
3)
)
≤
M−1∑
k=1
(
Ts + −log c
D(f||g)
)
≤−(1 + o(1))(M −1) logc
D(f||g) as c→0.
(46)
Combine the deﬁnition of (20), we complete the proof.
Lemma 7. In the asymptotic regime, the Bayesian risk under the DBS policy is upper bounded by
Rm(DBS) ≤O(c) + (1 +o(1)) ·−clog c
I∗(M) + s·Ts (47)
29
for all m= 1,2,...,M .
Proof: Combining Lemmas 5, 6 completes the proof.
Combining Proposition 1 and Lemma 7 yields the asymptotic optimality of DBS policy, presented in Theorem 1,
lim
c→0
R(DBS)
infΓ R(Γ) ≤lim
c→0
c·−log c
I∗(M) + s·Ts
c·−log c
I∗(M) + s·∑M
k=1(k−1)πk
= lim
c→0
1 + s·(Ts −M−1
2 )
c·−log c
I∗(M) + s·∑M
k=1(k−1)πk
= lim
c→0
1 + Ts −M−1
2
−clog c
s · 1
I∗(M) + ∑M
k=1(k−1)πk
.
(48)
Note that s= o(−clog c) as conditioned by Theorem 1, we can know that limc→0
−clog c
s →∞. Then,
lim
c→0
R(DBS)
infΓ R(Γ) = lim
c→0
1 + Ts −M−1
2
−clog c
s · 1
I∗(M) + ∑M
k=1(k−1)πk
= 1 + Ts −M−1
2
∞· 1
I∗(M) + ∑M
k=1(k−1)πk
= 1,
(49)
which completes the proof.
B. The Proof of Theorem 2
The proof follows a similar line of arguments as in the proof of Theorem 1. Since the ratio of s/−clog c does not affect
the expected number of observations and switchings, the Lemma 6 and 5 still holds for Scenario 2 of the DBS policy. Thus,
lim
c→0
R(DBS)
infΓ R(Γ) ≤lim
c→0
c·−log c
I∗(M) + s·Ts
c·−log c
I∗(M) + s·∑M
k=1(k−1)πk
= lim
c→0
1 + s·(Ts −∑M
k=1(k−1)πk)
c·−log c
I∗(M) + s·∑M
k=1(k−1)πk
= lim
c→0
1 + Ts −∑M
k=1(k−1)πk
−clog c
s · 1
I∗(M) + ∑M
k=1(k−1)πk
.
(50)
Differ from the condition that s= o(−clog c) as c→0 in Scenario 1, we assume that s= Ω(−clog c) as c approaches 0 in
Scenario 2, which means that limc→0
−clog c
s ≥0. Thus,
lim
c→0
R(DBS)
infΓ R(Γ) = lim
c→0
1 + Ts −∑M
k=1(k−1)πk
−clog c
s · 1
I∗(M) + ∑M
k=1(k−1)πk
≤1 + Ts −∑M
k=1(k−1)πk
∑M
k=1(k−1)πk
≤ Ts
∑M
k=1(k−1)πk
<∞,
(51)
which completes the proof.
30
REFERENCES
[1] D. Chen, Q. Huang, H. Feng, Q. Zhao, and B. Hu, “Active anomaly detection with switching cost,” in ICASSP 2019-2019 IEEE International Conference
on Acoustics, Speech and Signal Processing (ICASSP) . IEEE, 2019, pp. 5346–5350.
[2] H. Chernoff, “Sequential design of experiments,” The Annals of Mathematical Statistics , vol. 30, no. 3, pp. 755–770, 1959.
[3] A. Wald, “Sequential analysis.” 1947.
[4] S. A. Bessler, “Theory and applications of the sequential design of experiments, k-actions and inﬁnitely many experiments. part i. theory,” Stanford Univ
CA Applied Mathematics and Statistics Labs, Tech. Rep., 1960.
[5] M. Naghshvar and T. Javidi, “Active m-ary sequential hypothesis testing,” in 2010 IEEE International Symposium on Information Theory . IEEE, 2010,
pp. 1623–1627.
[6] M. Naghshvar, T. Javidi et al., “Active sequential hypothesis testing,” The Annals of Statistics , vol. 41, no. 6, pp. 2703–2738, 2013.
[7] M. Naghshvar and T. Javidi, “Information utility in active sequential hypothesis testing,” in 2010 48th Annual Allerton Conference on Communication,
Control, and Computing (Allerton) . IEEE, 2010, pp. 123–129.
[8] M. Naghshvar and T. Javidi, “Performance bounds for active sequential hypothesis testing,” in 2011 IEEE International Symposium on Information
Theory Proceedings. IEEE, 2011, pp. 2666–2670.
[9] M. Naghshvar and T. Javidi, “Sequentiality and adaptivity gains in active hypothesis testing,” IEEE Journal of Selected Topics in Signal Processing ,
vol. 7, no. 5, pp. 768–782, 2013.
[10] S. Nitinawarat, G. K. Atia, and V . V . Veeravalli, “Controlled sensing for hypothesis testing,” in2012 IEEE International Conference on Acoustics, Speech
and Signal Processing (ICASSP) . IEEE, 2012, pp. 5277–5280.
[11] S. Nitinawarat, G. K. Atia, and V . V . Veeravalli, “Controlled sensing for multihypothesis testing,” IEEE Transactions on Automatic Control , vol. 58,
no. 10, pp. 2451–2464, 2013.
[12] S. Nitinawarat and V . V . Veeravalli, “Controlled sensing for sequential multihypothesis testing with controlled markovian observations and non-uniform
control cost,” Sequential Analysis, vol. 34, no. 1, pp. 1–24, 2015.
[13] K. Cohen and Q. Zhao, “Active hypothesis testing for anomaly detection,” IEEE Transactions on Information Theory , vol. 61, no. 3, pp. 1432–1450,
2015.
[14] K. Cohen, Q. Zhao, and A. Swami, “Optimal index policies for anomaly localization in resource-constrained cyber systems,” IEEE Transactions on
Signal Processing, vol. 62, no. 16, pp. 4224–4236, 2014.
[15] C. Wang, K. Cohen, and Q. Zhao, “Active hypothesis testing on a tree: Anomaly detection under hierarchical observations,” in International Symposium
on Information Theory (ISIT) . IEEE, 2017, pp. 993–997.
[16] K. Cohen and Q. Zhao, “Asymptotically optimal anomaly detection via sequential testing,” IEEE Transactions on Signal Processing , vol. 63, no. 11,
pp. 2929–2941, 2015.
[17] B. Huang, K. Cohen, and Q. Zhao, “Active anomaly detection in heterogeneous processes,” IEEE Transactions on Information Theory , vol. 65, no. 4,
pp. 2284–2301, 2018.
[18] A. Gurevich, K. Cohen, and Q. Zhao, “Sequential anomaly detection under a nonlinear system cost,” IEEE Transactions on Signal Processing , vol. 67,
no. 14, pp. 3689–3703, 2019.
[19] B. Hemo, T. Gafni, K. Cohen, and Q. Zhao, “Searching for anomalies over composite hypotheses,” IEEE Transactions on Signal Processing , vol. 68,
pp. 1181–1196, 2020.
[20] A. Tartakovsky, I. Nikiforov, and M. Basseville, Sequential analysis: Hypothesis testing and changepoint detection . Chapman and Hall/CRC, 2014.
31
[21] F. Cecchi and N. Hegde, “Adaptive active hypothesis testing under limited information,” in Advances in Neural Information Processing Systems , 2017,
pp. 4035–4043.
[22] D. Kartik, A. Nayyar, and U. Mitra, “Testing for anomalies: Active strategies and non-asymptotic analysis,” arXiv preprint arXiv:2005.07696 , 2020.
[23] M.-C. Chang and M. R. Bloch, “Evasive active hypothesis testing,” in 2020 IEEE International Symposium on Information Theory (ISIT) . IEEE, 2020,
pp. 1248–1253.
[24] N. K. Vaidhiyan and R. Sundaresan, “Active search with a cost for switching actions,” in 2015 Information Theory and Applications Workshop (ITA) .
IEEE, 2015, pp. 17–24.