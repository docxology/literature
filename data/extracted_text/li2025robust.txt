Robust Sampling for Active Statistical Inference
Puheng Li‚Ä† Tijana Zrnic‚Ä†,‚ãÑ Emmanuel J. Cand` es‚Ä†,‚ñ≥
‚Ä†Department of Statistics
3Stanford Data Science
‚ñ≥Department of Mathematics
Stanford University
Abstract
Active statistical inference [51] is a new method for inference with AI-assisted data col-
lection. Given a budget on the number of labeled data points that can be collected and
assuming access to an AI predictive model, the basic idea is to improve estimation accuracy
by prioritizing the collection of labels where the model is most uncertain. The drawback,
however, is that inaccurate uncertainty estimates can make active sampling produce highly
noisy results, potentially worse than those from naive uniform sampling. In this work, we
present robust sampling strategies for active statistical inference. Robust sampling ensures
that the resulting estimator is never worse than the estimator using uniform sampling. Fur-
thermore, with reliable uncertainty estimates, the estimator usually outperforms standard
active inference. This is achieved by optimally interpolating between uniform and active
sampling, depending on the quality of the uncertainty scores, and by using ideas from ro-
bust optimization. We demonstrate the utility of the method on a series of real datasets
from computational social science and survey research.
1 Introduction
Collecting high-quality labeled data remains a challenge in data-driven research, especially
when each label is costly and time-consuming to obtain. In response, many fields have embraced
machine learning as a practical solution for predicting unobserved labels, such as annotating
satellite imagery in remote sensing [46] and predicting protein structures in proteomics [24].
Prediction-powered inference [1] is a methodological framework showing how to perform valid
statistical inference despite the inherent biases in such predicted labels.
Active statistical inference [51] was recently introduced to further enhance inference by ac-
tively selecting which data points to label. The basic idea is to compute the model‚Äôs uncertainty
scores for all data points and prioritize collecting those labels for which the predictive model is
most uncertain. When the uncertainty scores appropriately reflect the model‚Äôs errors, Zrnic and
Cand` es [51] show that active inference can significantly outperform prediction-powered inference
(which can essentially be thought of as active inference with naive uniform sampling), meaning
it results in more accurate estimates and narrower confidence intervals. However, when uncer-
tainty scores are of poor quality, active inference can result in overly noisy estimates and large
confidence intervals. This is an important limitation, seeing that there is widespread recognition
1
arXiv:2511.08991v1  [stat.ML]  12 Nov 2025
1291 1471 1677 1912
1028
1206
1415
1660
1947
2285
Effective sample size
1291 1471 1677 1912
0.6
0.7
0.8
0.9
1.0
Coverage
nb
uniform active robust active
Figure 1:Effective sample size and coverage on Pew post-election survey data.We
compare uniform, active, and robust active sampling, for different values of the sampling budget
nb. The target of inference is the approval rate of a presidential candidate. We show the mean
and one standard deviation of the effective sample size estimated over 500 trials; in each trial we
independently sample the observed labels.
that measuring model uncertainty is challenging. Large language models, for example, are often
overconfident in their answers [10, 47, 48]. Miscalibrated uncertainty scores also arise when there
is a distribution shift between the training data and the test domain.
To illustrate the issue empirically, consider the problem of estimating the approval rate of a
presidential candidate:Œ∏ ‚àó =E[Y], whereY‚àà {0,1}is the binary indicator of approval, using Pew
post-election survey data [32]. Here, we have demographic covariatesX 1, . . . , Xn corresponding
tonpeople, but we do not observe the approval indicatorY i for everyone. Rather, we have
a budgetn b < non how many people we can survey and collect theirY i. In addition, we
have a machine learning modelfthat we can use to obtain a cheap predictionf(X i) ofY i
from the available covariates. Active inference suggests surveying those individuals wherefis
uncertain. For example, iff(X i) is obtained by thresholding a continuous scorep(X i)‚àà[0,1]
representing the probability the model assigns to the missing label taking on the value 1, this
could mean prioritizing the collection of labels wherep(X i) is close to 0.5. In Figure 1, we
show the effective sample size and coverage of prediction-powered inference (uniform sampling),
standard active inference, and our robust active inference method, for varying values of the
budgetn b. The effective sample size is formally defined in Section 4; it is the number of samples
the method that samples uniformly at random would need to use to achieve the accuracy of the
labeling method under study. To demonstrate a challenge for active inference, we trainfon a
small dataset, resulting in poorly estimated uncertainties. We see that active sampling results
in a smaller effective sample size and a much larger standard deviation than simple uniform
sampling. This is because the variance of the active sampling strategy is large, which is due to
some extreme values of sampling probability. Meanwhile, the robust method outperforms both
baselines. This is achieved by estimating the quality of the uncertainty scores and optimally
interpolating between uniform and active sampling. All three methods come with provable
validity guarantees, as confirmed by the achieved target coverage of 90%.
The source code for all experiments is available at:
https://github.com/lphLeo/Robust-Active-Statistical-Inference.
2
1.1 Related work
Our paper builds on active statistical inference [51], which itself builds on prediction-powered
inference [1] and, more generally, statistical inference assisted by predictive models [29, 40,
45]. There is a growing literature in this space, aimed at ensuring robustness against poor
predictions [2, 16, 19, 23, 30, 31], sample efficiency when there is no good pre-trained model
f[52], simplicity and applicability to more general estimation problems [25, 50], and handling
missing covariates [25, 31]. Notably, several works study adaptive label collection strategies
[3, 14, 17].
Zooming out further, at a technical level this line of work relates to semiparametric inference,
missing data, and causality [34, 35, 37, 44]. In particular, the prediction-powered and active
inference estimators closely resemble the augmented inverse probability weighting (AIPW) esti-
mator [35].
Our work also connects with many areas in machine learning and statistics that study adap-
tive data collection; most notably, active learning [36, 39] and adaptive experimental design
[13, 21]. We collect data based on model uncertainty, akin to active learning; however, our ob-
jective is statistical inference on typically low-dimensional parameters, rather than prediction.
Active testing [26] also involves adaptive data collection, but it pursues a different objective of
high-precision risk estimation for a fixed model and uses a distinct estimator. Our approach can
be seen as an adaptive design assisted by a powerful predictive model, with a robustness wrapper
for improved performance.
More distantly, our work also relates to robust statistics and robust machine learning [8, 20,
22, 33, 41, 42, 49]. In particular, our method provides a safeguard against poor uncertainty
estimation by solving a robust optimization problem [5, 6, 15].
1.2 Problem setup
We follow the problem setting from [51]. We observe unlabeled instancesX 1, . . . , Xn drawn
i.i.d. from a distributionP X, but we do not observe their labelsY i. We useP=P X √óP Y|X
to denote the joint distribution of (X i, Yi). Our goal is to perform inference for a parameterŒ∏ ‚àó
that depends on the distribution of the unobserved labels; that is, the parameter is a functional
ofP. In particular, we assume thatŒ∏ ‚àó can be written as:
Œ∏‚àó = arg min
Œ∏
E[‚Ñì Œ∏(X, Y)],where (X, Y)‚àºP.
Here,‚Ñì Œ∏ is a convex loss function. This is a broad class of estimands, known asM-estimation,
and it includes means, medians, linear and logistic regression coefficients, and more. We have a
budgetn b on the number of labels we can collect in expectation, and typicallyn b ‚â™n. To assist
in imputing the missing labels, we also have a black-box predictive modelfat our disposal.
2 Warm-up: robust sampling for mean estimation
Consider the case whereŒ∏ ‚àó is the label mean,Œ∏ ‚àó =E[Y]. The active inference estimator for
Œ∏‚àó is given by:
ÀÜŒ∏œÄ = 1
n
nX
i=1

f(X i) + (Yi ‚àíf(X i)) Œæi
œÄ(X i)

.(1)
3
Here,œÄ(¬∑) is any sampling rule that satisfiesE[œÄ(X)]‚â§ nb
n so that the budget constraint is met
on average, andŒæ i ‚àºBern(œÄ(X i)) is the indicator of whether the labelY i is sampled. Since
the number of labeled data points is a sum of independent Bernoullis, a standard Hoeffding
argument guarantees that the realized labeling rate will closely match the budget with high
probability. Specifically, the labeling ratio will not exceed nb
n +œµwith probability 1‚àíŒ¥, provided
thatn > log(1/Œ¥)
2œµ2 for anyœµ, Œ¥ >0. As shown in [51], the variance of this estimator is
Var

ÀÜŒ∏œÄ

= 1
n

Var(Y) +E

(Y‚àíf(X)) 2
 1
œÄ(X) ‚àí1

,(2)
and the optimal sampling rule isœÄ opt(Xi)‚àù
p
E[(Yi ‚àíf(X i))2|Xi]. In other words, it is optimal
to upsample where the modelfmakes the largest errors.
The most straightforward sampling rule that satisfies the budget constraint is the uniform
rule:œÄ unif(X) =n b/n. However, if we have access to a good measure of model uncertainty that
can serve as a proxy for the model error
p
E[(Yi ‚àíf(X i))2|Xi], then we can obtain a rule that is
closer toœÄ opt. For example, we might prompt a large language model for its uncertainty aboutXi
or look at the softmax output of a neural network, and upsample where the uncertainty is high.
The issue is that if we severely underestimate the model error, then the estimator‚Äôs variance can
blow up: clearly, ifœÄ(X i) is small when the actual error (Y i ‚àíf(X i))2 is large, the variance will
be large as well. This is the reason why we saw poor performance in Figure 1.
Given any initial sampling ruleœÄ, our approach is to find an improved,robustsampling rule
œÄrobust that is never worse than eitherœÄorœÄ unif. By that we mean that the resulting active
inference estimator will have a variance that is no worse that with eitherœÄorœÄ unif used for label
collection: Var( ÀÜŒ∏œÄrobust
)‚â§min{Var( ÀÜŒ∏œÄ),Var( ÀÜŒ∏œÄunif
)}.
2.1 Budget-preserving path
Since our goal is to find a sampling ruleœÄ robust that performs no worse thanœÄ unif and an
arbitrary givenœÄ, it is natural to consider a path that connectsœÄandœÄ unif, while preserving the
sampling budget along the path.
Definition 1(Budget-preserving path).We call a continuous pathœÄ (œÅ),œÅ‚àà[0,1], abudget-
preserving pathconnectingœÄandœÄ unif ifœÄ (0) =œÄ,œÄ (1) =œÄ unif, andE[œÄ (œÅ)(X)] =E[œÄ(X)] for
allœÅ‚àà[0,1].
Correspondingly, given a pointœÅalong the path, we compute the estimator ÀÜŒ∏œÄ(œÅ)
, obtained
as the active inference estimator (1) with sampling ruleœÄ (œÅ). The following are some examples
of valid budget-preserving paths.
Example 1(Linear path).œÄ (œÅ) = (1‚àíœÅ)œÄ+œÅœÄ unif.
Example 2(Geometric path).œÄ (œÅ) ‚àùœÄ 1‚àíœÅ(œÄunif)œÅ. The ‚Äú‚àù‚Äù hides the normalization factor
that ensuresE[œÄ (œÅ)(X)] =E[œÄ(X)] for allœÅ.
A natural family of budget-preserving paths can be recovered via the ‚Äúleast-action‚Äù principle,
yielding the definition of geodesic paths. See Appendix B for a general definition of geodesic
paths, details of how Examples 1 and 2 can be recovered as special cases, as well as further
examples.
4
Of course, if we consistently estimate the optimal pointœÅ ‚àó ‚àà[0,1] along the path, we are
guaranteed to find an estimator that outperforms naive active inference and uniform sampling.
Moreover, the resulting estimator is still asymptotically normal, which permits the construction
of valid confidence intervals. We formalize this key result below in whichœÉ 2
œÅ =nVar( ÀÜŒ∏œÄ(œÅ)
).
Theorem 1.SupposeœÄ (œÅ) is a budget-preserving path connectingœÄandœÄ unif. LetœÅ ‚àó =
arg min
œÅ
Var(ÀÜŒ∏œÄ(œÅ)
), and suppose ÀÜœÅ=œÅ ‚àó +o P (1). Then,
‚àön

ÀÜŒ∏œÄ(ÀÜœÅ)
‚àíŒ∏ ‚àó
 d
‚àí ‚Üí N
 
0, œÉ2
œÅ‚àó

,
whereœÉ 2
œÅ‚àó ‚â§min{œÉ 2
0, œÉ2
1}.
Theorem 1 shows that consistently estimatingœÅ ‚àó will result in an estimator that is no worse
than either endpoint. IfœÅ ‚àó is additionally unique and within (0,1), then the resulting sampling
will strictly outperform both active sampling withœÄand uniform sampling. The theoretical
results in this paper are asymptotic; however, validity in the finite-sample regime is shown
empirically in the experiments in Section 4.
It remains to explain how to estimate ÀÜœÅ. Recall from (2) that Var( ÀÜŒ∏œÄ(œÅ)
) = 1
n E[ e2(X)
œÄ(œÅ)(X) ] +C,
wheree 2(X) =E[(Y‚àíf(X)) 2|X] andCis a quantity that has no dependence onœÄ (œÅ). Therefore,
to fit ÀÜœÅ, we fit an error function ÀÜe2(¬∑)‚âàe 2(¬∑) and solve for theœÅthat minimizes the empirical
approximation of Var(ÀÜŒ∏œÄ(œÅ)
):
ÀÜœÅ= arg min
œÅ
1
n
nX
i=1
ÀÜe2(Xi)
œÄ(œÅ)(Xi).(3)
We can find the solution by performing a grid search overœÅ‚àà[0,1]. The error ÀÜe 2(¬∑) can be fit on
historical or held-out data, or it can be gradually fine-tuned during the data collection process.
Notice that, if the error estimation is consistent in the sense that‚à•ÀÜe 2(X)‚àíe 2(X)‚à•‚àû
p
‚Üí0 and if
œÅ‚àó is unique, then ÀÜœÅ
p
‚ÜíœÅ ‚àó, as assumed in Theorem 1. Here, the assumption that ÀÜeconverges toe
follows from classical arguments of uniform approximation of flexible estimators, and is common
in the field of semiparametric inference. For instance, the widely-used doubly robust estimator
[18, 35], which is closely related to our estimator, relies on consistent estimation of nuisance
functions.
2.2 Robustness to error function misspecification
Given a pathœÄ (œÅ), the previous discussion suggests finding ÀÜœÅthat minimizes an empirical ap-
proximation of the variance Var(ÀÜŒ∏œÄ(œÅ)
). This empirical approximation relies on an error estimate
ÀÜe(¬∑). If this function is severely misspecified, then the computed ÀÜœÅmight be far fromœÅ ‚àó; more
importantly, it might not even outperform uniform sampling.
To mitigate this concern, we instead consider a robust optimization problem that incorporates
the possibility of ÀÜebeing misspecified:
œÅrobust = arg min
œÅ
max
œµ‚ààC
1
n
nX
i=1
ÀÜe2(Xi) +œµ i
œÄ(œÅ)(Xi) .(4)
Here,œµ= (œµ 1, . . . , œµn) is the misspecification vector andCis the admissible set of misspecifications.
This method allows for settingœÄ (œÅ) close to uniform if the misspecification setCis permissive
5
enough. Solving this minimax problem is computationally efficient, as long asCis a convex set.
The outer problem can be solved via a one-dimensional grid search, while the inner problem is
tractable due to convexity.
Now, the question is how we should setCin practice. Our default will be to simply use
C={œµ:‚à•œµ‚à• 2 ‚â§c}, for some hyperparameterc >0. Empirically,ccan be set by cross-validation.
Other choices of the setCare possible, such as bounding other norms ofœµ, for example‚à•œµ‚à• 1 < c.
Empirically we found the‚Ñì 2 norm to work the best, and in illustrative theoretical examples we
reach the same conclusion; see Appendix C for details. We also tried relative misspecification,
in the sense thatœµ i = ÀÜe2(Xi)(1 +Œ∑ i), and constrained either the‚Ñì 1 or‚Ñì 2 norm of the relative
perturbationŒ∑. We found that this does not perform as well.
Zrnic and Cand` es [51] briefly discussed a robustness proposal with linear interpolation. It
assumes access to historical data, and otherwise it selects a default value for the coefficient,
which has no guarantee to outperform uniform and active sampling. Our analysis is far more
thorough and systematic, expanding the set of interpolating paths, not requiring historical data
but incorporating a burn-in period, and adding a robustness constraint. These are all crucial for
the practicality and reliability of the method; see Section 4 for details.
There are other potential optimization objectives to take into account robustness constraints.
For example, one may penalize small values ofœÅin the objective (3) with regularization, and
similarly use cross-validation to choose the penalty parameter. We leave the investigation of such
alternatives for future work.
3 Robust sampling for general M-estimation
Our sampling principle can be directly extended to general convex M-estimation, as consid-
ered in [51]. We explain this step-by-step for completeness.
Recall that we consider all inferential targets of the formŒ∏ ‚àó = arg minŒ∏ E[‚Ñì Œ∏(X, Y)], for
a convex loss‚Ñì Œ∏. Denote‚Ñì Œ∏,i =‚Ñì Œ∏ (Xi, Yi), ‚Ñìf
Œ∏,i =‚Ñì Œ∏ (Xi, f(Xi)), and define‚àá‚Ñì Œ∏,i and‚àá‚Ñì f
Œ∏,i
similarly. For an active sampling strategyœÄ, the general active inference estimator is defined as:
ÀÜŒ∏œÄ = arg min
Œ∏
LœÄ(Œ∏),whereL œÄ(Œ∏) = 1
n
nX
i=1

‚Ñìf
Œ∏,i +

‚ÑìŒ∏,i ‚àí‚Ñì f
Œ∏,i
 Œæi
œÄ(Xi)

.(5)
As before,Œæ i ‚àºBern(œÄ(X i)) is the indicator of whether the labelY i is sampled. Following [51],
we know that the asymptotic covariance matrix of ÀÜŒ∏œÄ equals:
Œ£œÄ =H ‚àí1
Œ∏‚àó Var

‚àá‚Ñìf
Œ∏‚àó +

‚àá‚ÑìŒ∏‚àó ‚àí ‚àá‚Ñìf
Œ∏‚àó
 Œæ
œÄ(X)

H‚àí1
Œ∏‚àó ,
whereH Œ∏‚àó is the HessianH Œ∏‚àó =‚àá 2E[‚Ñì Œ∏‚àó(X, Y)].
We again consider budget-preserving pathsœÄ (œÅ) and tune the parameterœÅsuch that we mini-
mize the variance of the resulting estimatorÀÜŒ∏œÄ(œÅ)
. Denote by Œ£0 and Œ£1 the asymptotic covariance
matrices of the active inference estimator (5) usingœÄ (0) =œÄandœÄ (1) =œÄ unif, respectively.
Theorem 2.SupposeœÄ (œÅ) is a budget-preserving path connectingœÄandœÄ unif. Given a coor-
dinatejof interest, letœÅ ‚àó = arg min
œÅ
Œ£œÄ(œÅ)
jj , and suppose ÀÜœÅ=œÅ ‚àó +o P (1). Suppose further that
6
ÀÜŒ∏œÄ(œÅ‚àó) p
‚àí ‚ÜíŒ∏‚àó. Then, ‚àön

ÀÜŒ∏œÄ(ÀÜœÅ)
‚àíŒ∏ ‚àó
 d
‚àí ‚Üí N(0,Œ£œÅ‚àó),
where Œ£œÅ‚àó,jj ‚â§min{Œ£ 0,jj ,Œ£ 1,jj }.
The consistency condition ÀÜŒ∏œÄ(œÅ‚àó) p
‚àí ‚ÜíŒ∏‚àó is standard; see the corresponding discussion in [51]
and [2]. For example, it is ensured whenL œÄ is convex, such as in the case of generalized linear
models (GLMs), or when the parameter space is compact.
As in the case of mean estimation, we fit ÀÜœÅby approximating the variance of the estimator
Œ£œÄ(œÅ)
and searching overœÅ. However, here the notion of errore 2(¬∑) we need to estimate is different.
In particular, given the form of Œ£ œÄ, we let
ÀÜœÅ= arg min
œÅ
1
n
nX
i=1
ÀÜe2(Xi)
œÄ(œÅ)(Xi),
where ÀÜe2(X) aims to approximatee 2(X) =E[((‚àá‚Ñì Œ∏‚àó ‚àí ‚àá‚Ñìf
Œ∏‚àó)‚ä§h(j))2|X] andh (j) is thej-th
column ofH ‚àí1
Œ∏‚àó . In the context of generalized linear models (GLMs), this error simplifies to
e2(X) =E[(Y‚àíf(X)) 2|X]¬∑(X ‚ä§h(j))2. Therefore, as for mean estimation, the problem essentially
reduces to estimating the errorE[(Y‚àíf(X)) 2|X]. As before, if ÀÜe2 consistently estimatese 2, then
ÀÜœÅconsistently estimatesœÅ‚àó.
Finally, to protect against poorly estimated errors ÀÜe, we can incorporate an uncertainty setC
around the error estimates just as before (4). Again, the only difference here is that the ÀÜe2(Xi)‚Äôs
are estimating a different notion of model error tailored to the inference problem at hand.
We summarize our generalrobust active inferencealgorithm in Algorithm 1.
Algorithm 1:Robust Active Inference
Input:unlabeled dataX 1, . . . , Xn, labeling budgetn b, predictive modelf, initial
sampling ruleœÄ, budget-preserving pathœÄ (œÅ), error estimator ÀÜe2(¬∑), robustness
constraintC
1Solve the minimax problemœÅ robust = arg min
œÅ‚àà[0,1]
max
œµ‚ààC
1
n
Pn
i=1
ÀÜe2(Xi)+œµi
œÄ(œÅ)(Xi)
2Sample labeling decisions according toœÄ (œÅrobust)(Xi):Œæ i ‚àºBern
 
œÄ(œÅrobust)(Xi)

, i‚àà[n]
3Collect labels{Y i :Œæ i = 1}
Output:estimator ÀÜŒ∏œÄ(œÅrobust)
= arg min
Œ∏
LœÄ(œÅrobust)
, as defined in Eq. (5)
4 Experiments
We turn to evaluating the performance of our robust sampling approach empirically. Each
of the following subsections is dedicated to a different experiment using social science research
data. Section 4.1 measures presidential approval, Section 4.2 analyzes US age‚Äìincome patterns,
and Section 4.3 applies language models to score text on social attributes such as political bias.
On each of these datasets, we use the following methods to collect labels: (1) uniform sampling,
which essentially recovers prediction-powered inference [1]; (2) standard uncertainty-based active
sampling [51]; and (3) our robust active method as per Algorithm 1. Each dataset will use a
different base predictive modelf, which we describe therein. We set the target coverage level to
be 0.9 throughout.
7
The main metric used for the comparison is effective sample size. To define this metric
formally, consider the baseline estimator that samples uniformly at random, i.e., according to
œÄunif. Its effective sample size is simply its budgetn b. For other estimators, we say that the
effective sample size is equal ton eff if the estimator achieves the same variance as the baseline
estimator with budgetn eff. For example, if given budgetn b = 100 the estimator achieves
the same variance as the baseline estimator with double the budget, then the estimator has
neff = 200. A largern eff indicates a more efficient estimator. In the case where the effective
sample size falls below the budget,n eff < nb, the estimator performs worse than the baseline.
We show one standard deviation around the effective sample size in all plots, estimated over 500
trials.
We also plot empirical estimates of the methods‚Äô coverage. We estimate the coverage by
resampling the data, constructing confidence intervals for each resampling, and calculating the
proportion of times the true parameter value (approximated by the full-data estimate of the
targetŒ∏ ‚àó) falls within the constructed intervals. This approach allows us to assess how reliably
each method achieves the target coverage level. We resample 500 times to estimate the coverage.
(We note that this approach yields conservative coverage estimates whenn b is large, because
we haven‚àín b ‚Äúfresh‚Äù labels to approximateŒ∏ ‚àó.) From the theory, we know that the coverage
should be exactly 0.9 for all baselines.
4.1 Post-election survey research
Following [51], we evaluate the different methods on survey data collected by the Pew Research
Center following the 2020 United States presidential election, aiming at gauging people‚Äôs approval
of the presidential candidates‚Äô political messaging [32]. We aim to estimate the approval rate
Œ∏‚àó =E[Y], whereY‚àà {0,1}is a binary indicator of approval of Biden‚Äôs political messaging.
We use a multilayer perceptron (MLP) as our predictive modelf. At the beginning, we have a
‚Äúburn-in‚Äù period where we collect all burn-in labelsY i and we use this burn-in data to estimate
the error function ÀÜe(¬∑). Afterwards, we use the fitted function to run robust active inference, as
per Algorithm 1. Naturally, the burn-in period counts towards the overall labeling budgetn b.
We study three questions: (1) the effect of tuningœÅalong the budget-preserving path, without
incorporating a robustness constraintC; (2) the effect of tuningœÅalong the path and the robust
optimization overCcombined; and (3) the performance of different budget-preserving paths.
Tuning along the budget-preserving path.First, we conduct an experiment without the
robustness setC, only tuning the parameter ÀÜœÅalong the budget-preserving path. We choose the
geometric path from Example 2. To implement active inference, we useœÄ(x)‚àùmin{f(x),1‚àí
f(x)}, in whichf(x) is the predicted probability that the label takes on the value 1, as considered
in [51]. See Figure 2 for the results. We consider two training dataset sizes used to trainf,
allowing us to see the results for a less accuratef(left) and a more accurate one (right). We find
that, even without robust optimization but only optimizing along the budget-preserving path,
robust active inference can lead to noticeable improvements in terms of power compared to naive
uncertainty-based active sampling and uniform sampling. The performance of standard active
inference crucially depends on the quality offand its uncertainties. We defer the corresponding
coverage plots to Appendix E.
8
1357 1597 1880
895
1061
1257
1490
1766
2093
2480Effective sample size
Training size = 2000
1357 1597 1880
960
1123
1313
1536
1796
2100
2456 Training size = 5000
nb
uniform active robust active
Figure 2:Effective sample size on Pew post-election survey data, for different dataset
sizes used to trainf. We compare uniform, active, and robust active sampling, for different
values of the sampling budgetn b. The target of inference is the approval rate of a presidential
candidate. We show the mean and one standard deviation (see Appendix E.1) of the effective
sample size estimated over 500 trials; in each trial we independently sample the observed labels.
Incorporating robustness.One strategy proposed by Zrnic and Cand` es [51] is to estimate ÀÜe
and setœÄproportional to ÀÜe. With this choice, without the additional step of robust optimization,
our robust sampling approach would trivially estimate ÀÜœÅ= 0 (a proof of this claim can be found
in Appendix A). We show that incorporating the robustness constraint resolves this issue when
œÄ(x)‚àùÀÜe(x). As in the previous case, we use the geometric path and an MLP as the predictive
model. The results are shown in Figure 3. Recall, ÀÜeis estimated from the burn-in data. Thus,
the longer the burn-in period, the better the fit ÀÜe. This is consistent with the observation that
active inference gradually outperforms uniform sampling as the burn-in period grows. However,
when there is little data to fit ÀÜe, active sampling leads to a significantly higher variance than
uniform sampling. Our robust sampling approach is never worse than either baseline, across all
burn-in data sizes. This is explained by the fact that, when the fit ÀÜeis poor, the constraint set
Cchosen via cross-validation is large, resulting in a largeœÅ robust, thus pushing the sampling rule
closer to uniform. In Figure 6 (left), we plot the optimized valueœÅ robust for different burn-in
sizes. As expected,œÅ robust decreases, which means that the optimal strategy gradually moves
from uniform sampling toward standard active sampling as the quality of ÀÜeimproves.
Choice of budget-preserving path.We have thus far used the geometric path as our budget-
preserving path. In Figure 4 we compare three budget-preserving paths: the linear path, the
geometric path, and the Hellinger path (see Appendix B). On the post-election survey dataset,
Figure 4 shows that the geometric path is the best of the three chosen paths, regardless of whether
or not robust optimization overCis used. Therefore, as a practical default, we recommend using
the geometric path. It has been stress-tested and has consistently demonstrated strong perfor-
mance in our evaluations. We believe this is a good tradeoff between simplicity and performance.
For improved performance with a better choice of path, the practitioner might want to tune it
in a data-driven way; for example, based on the estimated variance on a small held-out dataset.
9
871
1029
1216
1437
1698
2006
2371Effective sample size
Burn-in size = 606
1496
1659
1840
2041
2264
2512
2786
Burn-in size = 1213
2077
2231
2397
2574
2765
2970
3191
Burn-in size = 1819
2613
2754
2903
3060
3225
3399
3583
Burn-in size = 2426
3810
3904
4001
4100
4201
4305
4412
Burn-in size = 3639
1574 1775 2003
0.6
0.7
0.8
0.9
1.0
Coverage
2001 2216 2455 2515 2704 2906 2946 3108 3278 3968 4058 4151
nb
uniform active robust active
Figure 3:Effective sample size (top) and coverage (bottom) on Pew post-election
survey data, for varying burn-in dataset sizes with respect to different proportions of the data.
We compare uniform, active, and robust active sampling, for different values of the sampling
budgetn b. The target of inference is the approval rate of a presidential candidate. We show the
mean and one standard deviation of the effective sample size estimated over 500 trials; in each
trial we independently sample the observed labels.
2420 2609 2812
2113
2265
2428
2603
2790
2991
3206Effective sample size
Without robustness constraint
2420 2609 2812
2128
2279
2441
2615
2801
3000
3214 With robustness constraint
nb
hellinger geometric linear
Figure 4:Effective sample size for different budget-preserving paths on Pew post-
election survey data, without (left) and with (right) a robustness constraintC. In both cases,
the geometric path leads to the largest effective sample size. The target of inference is the same
as in Figure 3. We show the mean and one standard deviation (see Appendix E.1) of the effective
sample size estimated over 500 trials; in each trial we independently sample the observed labels.
10
1728 1958 2218
402
569
805
1140
1614
2284
3233Effective sample size
Burn-in size = 140
1443 1744 2109
542
737
1001
1361
1850
2515
3418
Burn-in size = 280
1576 1874 2230
723
938
1217
1579
2048
2657
3446
Burn-in size = 420
1478 1773 2127
831
1050
1327
1676
2118
2676
3382
Burn-in size = 560
1746 2036 2375
1102
1348
1649
2017
2467
3017
3691
Burn-in size = 840
nb
uniform active robust active
Figure 5:Effective sample size on US Census data, for varying burn-in dataset sizes. We
compare uniform, active, and robust active sampling, for different values of the sampling budget
nb. The target of inference is the relationship between age and income, estimated via a linear
regression. We show the mean and one standard deviation of the effective sample size estimated
over 500 trials; in each trial we independently sample the observed labels.
4.2 Census data analysis
We study the annual American Community Survey (ACS) Public Use Microdata Sample
(PUMS) collected by the US Census Bureau [12]. We are interested in investigating the rela-
tionship between age and income in survey data collected in California in 2019, controlling for
sex. We estimate the age coefficientŒ∏ ‚àó of the linear regression vector when regressing income
on age and sex. We use an XGBoost model [9] to predict incomeYfrom available demographic
covariates. As in the previous problem, we setœÄ(x)‚àùÀÜe(x), as in [51], and fit ÀÜeusing burn-in
data. We use the geometric path and incorporate the robust optimization overC. We show the
results in Figure 5. Again, we observe that the robust approach outperforms both standard active
sampling and uniform sampling for different qualities of the error estimate ÀÜe(¬∑), corresponding
to different burn-in dataset sizes. Standard active inference, on the other hand, is very sensitive
to the quality of ÀÜe. In Figure 6 (right), we plot the optimized valueœÅ robust for different burn-in
sizes. As in the previous example,œÅ robust decreases as the quality of ÀÜeimproves, as expected.
We include corresponding coverage plots in Appendix E.
4.3 Computational social science with language models
We study three text annotation tasks used for computational social science research. In each
task, we have text instancesX i and we seek to collect labelsY i related to the text‚Äôs sentiment,
political leaning, and so on. We wish to use a large language model (LLM)fto predict the
high-quality annotationsY i, which are typically collected through laborious human annotation.
A natural way of actively sampling human annotations is according to the confidence of the
language model [17, 27]. Tian et al. [43] propose prompting LLMs to verbalize their confidence
in the provided answer, and they find that this results in fairly calibrated confidence scores.
Gligori¬¥ c et al. [17] find that such scores can be useful in actively sampling human annotations.
We use GPT-4o annotations and confidences collected by Gligori¬¥ c et al. [17]. We apply active
inference withœÄ(X i)‚àù(1‚àíC i), whereC i is the collected confidence score of the language model
for promptX i. This can be a brittle strategy, since the scores are often overconfident and thus
11
1000 2000 3000
0.4
0.6
0.8
1.0robust
Post-election survey research
200 400 600 800
Census data analysis
Size of burn-in data
Figure 6:Optimized valueœÅ robust along the geometric pathas a function of the size of the
burn-in data for the post-election survey data (left) and US Census data (right).
result in very small sampling probabilities, which can blow up the estimator variance through
inverse probability weighting. For robust active inference, we use the geometric path and robust
optimization with an‚Ñì 2 constraint setC, as before.
Political bias.In the first task, the goal is to study the political leaning of media articles,
using the data curated by Baly et al. [4]. The labelsYare one ofleft,centrist, orright.
The inferential target is the prevalence of right-leaning articles:Œ∏ ‚àó =E[1{Y=right}].
Politeness.The next task is to estimate how certain linguistic devices impact the perceived
politeness of online requests. We use the dataset of requests from Wikipedia and StackExchange
curated by Danescu-Niculescu-Mizil et al. [11]. We study how the presence of hedging in the
request,X hedge ‚àà {0,1}, impacts whether a text is seen as polite,Y‚àà {0,1}. Formally,Œ∏ ‚àó is
this effect estimated via a logistic regression with an intercept: logit (P(Y= 1|X hedge )) =Œ∏ 0+
Œ∏‚àóXhedge .
Misinformation.Finally, we study the prevalence of misinformation in news headlines, using
the dataset collected by Gabrel et al. [15]. The labelsY‚àà {0,1}indicate whether a headline
contains misinformation. The inferential target is the prevalence of misinformation,Œ∏ ‚àó =E[Y].
We show the results in Figure 7. Across all tasks, the robust approach is essentially never
worse than uniform sampling or active inference, in cases even outperforming both by a large
margin. Standard active inference often leads to large intervals, given that sampling directly
according to the model‚Äôs verbalized uncertainty leads to instability through inverse probability
weighting. We include the corresponding coverage plots in Appendix E.
5 Conclusion
We presented robust sampling strategies for active inference: a principled hedge between
uniform and conventional active sampling. By selecting an optimal tuning parameterœÅalong a
12
908 1019 1142601
680
770
872
987
1117
1265Effective sample size
Political bias
1976 2378 28611404
1665
1975
2343
2779
3297
3911 Politeness
1010 1138 1281717
800
892
995
1110
1238
1381 Misinformation
nb
uniform active robust active
Figure 7:Effective sample size on social science text annotation datasets. We compare
uniform, active, and robust active sampling, for different values of the sampling budgetn b. The
targets of inference are (left to right) the prevalence of right-leaning political bias, the relationship
between hedging and politeness, and the prevalence of misinformation. We show the mean and
one standard deviation of the effective sample size estimated over 500 trials; in each trial we
independently sample the observed labels.
budget-preserving path, robust active inference ensures performance that is no worse than with
standard active sampling, and it reduces to near-uniform sampling when uncertainty scores are
unreliable. Furthermore, the estimator can even surpass standard active inference given reliable
uncertainties.
Many directions remain for future work. For example, it would be valuable to understand
how to optimally choose the constraint setC, or at least how to choose between several different
constraint sets. As presented, our procedure is sensitive to the choice ofCand may result in
sampling rules that are too close or too far from uniform if this set is chosen poorly. We also
leave investigations into the optimal budget-preserving path, and practical heuristics for how a
practitioner might effectively choose a good path in a data-driven way, for future work.
Acknowledgement
EJC was supported by the Office of Naval Research grant N00014-24-1-2305, the National
Science Foundation grant DMS-2032014, and the Simons Foundation under award 814641.
References
[1] Anastasios N Angelopoulos, Stephen Bates, Clara Fannjiang, Michael I Jordan, and Tijana
Zrnic. Prediction-powered inference.Science, 382(6671):669‚Äì674, 2023.
[2] Anastasios N Angelopoulos, John C Duchi, and Tijana Zrnic. PPI++: Efficient prediction-
powered inference.arXiv preprint arXiv:2311.01453, 2023.
[3] Ruicheng Ao, Hongyu Chen, and David Simchi-Levi. Prediction-guided active experiments.
arXiv preprint arXiv:2411.12036, 2024.
13
[4] Ramy Baly, Giovanni Da San Martino, James Glass, and Preslav Nakov. We can detect your
bias: Predicting the political ideology of news articles. InProceedings of the 2020 Conference
on Empirical Methods in Natural Language Processing (EMNLP), pages 4982‚Äì4991, 2020.
[5] A Ben-Tal. Robust optimization.Princeton University Press, 2:35‚Äì53, 2009.
[6] Hans-Georg Beyer and Bernhard Sendhoff. Robust optimization‚Äìa comprehensive survey.
Computer methods in applied mechanics and engineering, 196(33-34):3190‚Äì3218, 2007.
[7] Dmitri Burago, Yuri Burago, and Sergei Ivanov.A course in metric geometry, volume 33.
American Mathematical Society Providence, 2001.
[8] Davide Cacciarelli, Murat Kulahci, and John S√∏lve Tyssedal. Robust online active learning.
Quality and Reliability Engineering International, 40(1):277‚Äì296, 2024.
[9] Tianqi Chen and Carlos Guestrin. Xgboost: A scalable tree boosting system. InProceedings
of the 22nd acm sigkdd international conference on knowledge discovery and data mining,
pages 785‚Äì794, 2016.
[10] Prateek Chhikara. Mind the confidence gap: Overconfidence, calibration, and distractor
effects in large language models.arXiv preprint arXiv:2502.11028, 2025.
[11] Cristian Danescu-Niculescu-Mizil, Moritz Sudhof, Dan Jurafsky, Jure Leskovec, and Christo-
pher Potts. A computational approach to politeness with application to social factors. In
51st Annual Meeting of the Association for Computational Linguistics, pages 250‚Äì259. ACL,
2013.
[12] Frances Ding, Moritz Hardt, John Miller, and Ludwig Schmidt. Retiring adult: New datasets
for fair machine learning.Advances in neural information processing systems, 34:6478‚Äì6490,
2021.
[13] Valerii Vadimovich Fedorov.Theory of optimal experiments. Elsevier, 2013.
[14] Adam Fisch, Joshua Maynez, R Alex Hofer, Bhuwan Dhingra, Amir Globerson, and
William W Cohen. Stratified prediction-powered inference for hybrid language model eval-
uation.arXiv preprint arXiv:2406.04291, 2024.
[15] Virginie Gabrel, C¬¥ ecile Murat, and Aur¬¥ elie Thiele. Recent advances in robust optimization:
An overview.European journal of operational research, 235(3):471‚Äì483, 2014.
[16] Feng Gan, Wanfeng Liang, and Changliang Zou. Prediction de-correlated inference: A safe
approach for post-prediction inference.Australian & New Zealand Journal of Statistics, 66
(4):417‚Äì440, 2024.
[17] Kristina Gligori¬¥ c, Tijana Zrnic, Cinoo Lee, Emmanuel J Cand` es, and Dan Jurafsky.
Can unconfident llm annotations be used for confident conclusions?arXiv preprint
arXiv:2408.15204, 2024.
[18] Adam N Glynn and Kevin M Quinn. An introduction to the augmented inverse propensity
weighted estimator.Political analysis, 18(1):36‚Äì56, 2010.
[19] Jessica Gronsbell, Jianhui Gao, Yaqi Shi, Zachary R McCaw, and David Cheng. Another
look at inference after prediction.arXiv preprint arXiv:2411.19908, 2024.
14
[20] Yuejun Guo, Qiang Hu, Maxime Cordy, Mike Papadakis, and Yves Le Traon. Robust active
learning: Sample-efficient training of robust deep learning models. InProceedings of the
1st International Conference on AI Engineering: Software Engineering for AI, pages 41‚Äì42,
2022.
[21] Jinyong Hahn, Keisuke Hirano, and Dean Karlan. Adaptive experimental design using the
propensity score.Journal of Business & Economic Statistics, 29(1):96‚Äì108, 2011.
[22] Peter J Huber. Robust estimation of a location parameter. InBreakthroughs in statistics:
Methodology and distribution, pages 492‚Äì518. Springer, 1992.
[23] Wenlong Ji, Lihua Lei, and Tijana Zrnic. Predictions as surrogates: Revisiting surrogate
outcomes in the age of ai.arXiv preprint arXiv:2501.09731, 2025.
[24] John Jumper, Richard Evans, Alexander Pritzel, Tim Green, Michael Figurnov, Olaf Ron-
neberger, Kathryn Tunyasuvunakool, Russ Bates, Augustin ÀáZ¬¥ ƒ±dek, Anna Potapenko, et al.
Highly accurate protein structure prediction with alphafold.nature, 596(7873):583‚Äì589,
2021.
[25] Dan M Kluger, Kerri Lu, Tijana Zrnic, Sherrie Wang, and Stephen Bates. Prediction-
powered inference with imputed covariates and nonuniform sampling.arXiv preprint
arXiv:2501.18577, 2025.
[26] Jannik Kossen, Sebastian Farquhar, Yarin Gal, and Tom Rainforth. Active testing: Sample-
efficient model evaluation. InInternational Conference on Machine Learning, pages 5753‚Äì
5763. PMLR, 2021.
[27] Minzhi Li, Taiwei Shi, Caleb Ziems, Min-Yen Kan, Nancy Chen, Zhengyuan Liu, and Diyi
Yang. Coannotating: Uncertainty-guided work allocation between human and large language
models for data annotation. InProceedings of the 2023 Conference on Empirical Methods
in Natural Language Processing, pages 1487‚Äì1505, 2023.
[28] Matthias Liero, Alexander Mielke, and Giuseppe Savar¬¥ e. Optimal transport in competition
with reaction: The hellinger‚Äìkantorovich distance and geodesic curves.SIAM Journal on
Mathematical Analysis, 48(4):2869‚Äì2911, 2016.
[29] Zachary R McCaw, Sheila M Gaynor, Ryan Sun, and Xihong Lin. Leveraging a surrogate
outcome to improve inference on a partially missing target outcome.Biometrics, 79(2):
1472‚Äì1484, 2023.
[30] Jiacheng Miao and Qiongshi Lu. Task-agnostic machine-learning-assisted inference.arXiv
preprint arXiv:2405.20039, 2024.
[31] Jiacheng Miao, Xinran Miao, Yixuan Wu, Jiwei Zhao, and Qiongshi Lu. Assumption-lean
and data-adaptive post-prediction inference.arXiv preprint arXiv:2311.14220, 2023.
[32] Pew. American trends panel (ATP) wave 79, 2020. URLhttps://www.pewresearch.org/
science/dataset/american-trends-panel-wave-79/.
[33] Marco Ramoni and Paola Sebastiani. Robust learning with missing data.Machine Learning,
45:147‚Äì170, 2001.
[34] James M Robins and Andrea Rotnitzky. Semiparametric efficiency in multivariate regression
models with missing data.Journal of the American Statistical Association, 90(429):122‚Äì129,
1995.
15
[35] James M Robins, Andrea Rotnitzky, and Lue Ping Zhao. Estimation of regression coeffi-
cients when some regressors are not always observed.Journal of the American statistical
Association, 89(427):846‚Äì866, 1994.
[36] Nicholas Roy and Andrew McCallum. Toward optimal active learning through sampling
estimation of error reduction. InICML, volume 1, page 5. Citeseer, 2001.
[37] Donald B Rubin. Multiple imputation. InFlexible imputation of missing data, second
edition, pages 29‚Äì62. Chapman and Hall/CRC, 2018.
[38] Vivien Seguy and Marco Cuturi. Principal geodesic analysis for probability measures under
the optimal transport metric.Advances in Neural Information Processing Systems, 28, 2015.
[39] Burr Settles. Active learning literature survey. 2009.
[40] Shanshan Song, Yuanyuan Lin, and Yong Zhou. A general M-estimation theory in semi-
supervised framework.Journal of the American Statistical Association, 119(546):1065‚Äì1075,
2024.
[41] Robert G Staudte and Simon J Sheather.Robust estimation and testing. John Wiley &
Sons, 2011.
[42] Jacob Steinhardt.Robust learning: Information theory and algorithms. Stanford University,
2018.
[43] Katherine Tian, Eric Mitchell, Allan Zhou, Archit Sharma, Rafael Rafailov, Huaxiu Yao,
Chelsea Finn, and Christopher D Manning. Just ask for calibration: Strategies for eliciting
calibrated confidence scores from language models fine-tuned with human feedback. In
Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing,
pages 5433‚Äì5442, 2023.
[44] Anastasios A Tsiatis.Semiparametric theory and missing data, volume 4. Springer, 2006.
[45] Siruo Wang, Tyler H McCormick, and Jeffrey T Leek. Methods for correcting inference
based on outcomes predicted by machine learning.Proceedings of the National Academy of
Sciences, 117(48):30266‚Äì30275, 2020.
[46] Michael Xie, Neal Jean, Marshall Burke, David Lobell, and Stefano Ermon. Transfer learning
from deep features for remote sensing and poverty mapping. InProceedings of the AAAI
conference on artificial intelligence, volume 30, 2016.
[47] Mozhi Zhang, Mianqiu Huang, Rundong Shi, Linsen Guo, Chong Peng, Peng Yan, Yaqian
Zhou, and Xipeng Qiu. Calibrating the confidence of large language models by eliciting
fidelity.arXiv preprint arXiv:2404.02655, 2024.
[48] Kaitlyn Zhou, Dan Jurafsky, and Tatsunori Hashimoto. Navigating the grey area: How
expressions of uncertainty and overconfidence affect language models.arXiv preprint
arXiv:2302.13439, 2023.
[49] Abdelhak M Zoubir, Visa Koivunen, Yacine Chakhchoukh, and Michael Muma. Robust
estimation in signal processing: A tutorial-style treatment of fundamental concepts.IEEE
Signal Processing Magazine, 29(4):61‚Äì80, 2012.
[50] Tijana Zrnic. A note on the prediction-powered bootstrap.arXiv preprint arXiv:2405.18379,
2024.
16
[51] Tijana Zrnic and Emmanuel J Cand` es. Active statistical inference. InProceedings of the
41st International Conference on Machine Learning, pages 62993‚Äì63010, 2024.
[52] Tijana Zrnic and Emmanuel J Cand` es. Cross-prediction-powered inference.Proceedings of
the National Academy of Sciences, 121(15):e2322083121, 2024.
17
A Proofs
A.1 Proof of Theorem 1
By the definition of ÀÜŒ∏œÄ(œÅ)
, we have
ÀÜŒ∏œÄ(œÅ)
= 1
n
nX
i=1

f(X i) + (Yi ‚àíf(X i)) Œæi
œÄ(œÅ) (Xi)

.
From the assumption, we have ÀÜœÅ=œÅ‚àó +o P (1). By the continuity of the budget-preserving path
œÄ(œÅ), it follows thatœÄ (ÀÜœÅ)(Xi) =œÄ (œÅ‚àó)(Xi) +o P (1) for anyi‚àà {1, . . . , n}. This, as a result, gives
ÀÜŒ∏œÄ(ÀÜœÅ)
= ÀÜŒ∏œÄ(œÅ‚àó)
+o P (1) by the continuity of ÀÜŒ∏œÄ(œÅ)
.
It follows from Proposition 1 in [51] that we have
‚àön

ÀÜŒ∏œÄ(œÅ‚àó)
‚àíŒ∏ ‚àó
 d
‚àí ‚Üí N
 
0, œÉ2
œÅ‚àó

, œÉ 2
œÅ‚àó = Var(ÀÜŒ∏œÄ(œÅ‚àó)
).
Since ÀÜŒ∏œÄ(ÀÜœÅ) p
‚àí ‚ÜíÀÜŒ∏œÄ(œÅ‚àó)
, ‚àön

ÀÜŒ∏œÄ(ÀÜœÅ)
‚àíŒ∏ ‚àó
 d
‚àí ‚Üí N
 
0, œÉ2
œÅ‚àó

.
By the definition ofœÅ ‚àó,œÅ ‚àó = arg min
œÅ
Var(ÀÜŒ∏œÄ(œÅ)
), we have
œÉ2
œÅ‚àó = Var(ÀÜŒ∏œÄ(œÅ‚àó)
)‚â§min{Var( ÀÜŒ∏œÄ(0)
),Var( ÀÜŒ∏œÄ(1)
)}= min{œÉ 2
0, œÉ2
1}.
This completes the proof.
A.2 A sufficient condition forÀÜœÅ=œÅ ‚àó +o P (1)
Proposition 1.Suppose ÀÜe 2(X) =e 2(X) +o P (1), andœÅ ‚àó is unique. Suppose ÀÜe(X) is uniformly
upper bounded byM >0. Suppose further thatœÄ (œÅ)(X) is uniformly lower-bounded bym >0,
then we have ÀÜœÅ=œÅ‚àó +o P (1).
Proof.Denote
F=

fœÅ(x) = ÀÜe2(x)
œÄ(œÅ)(x) :œÅ‚àà[0,1]

.
We first show thatFis a P-Glivenko-Cantelli class.
SinceœÄ (œÅ) is continuous, and supported on [0,1], it is uniformly continuous on [0,1]. Hence
for anyŒ¥ >0, there existsŒ∑ >0 such that|œÄ (œÅ1)(X)‚àíœÄ (œÅ2)(X)| ‚â§m2
M2 Œ¥whenever|œÅ 1 ‚àíœÅ 2| ‚â§Œ∑.
Now, we cover [0,1] with a grid 0 =œÅ 0 < œÅ1 <¬∑¬∑¬∑< œÅ K = 1, whereœÅ k ‚àíœÅ k‚àí1 =Œ∑fork‚â§K‚àí1.
Then, for anyœÅ‚àà[œÅ k‚àí1, œÅk], we have
|fœÅ(x)‚àíf œÅk‚àí1 (x)|=

ÀÜe2(x)
œÄ(œÅ)(x) ‚àí ÀÜe2(x)
œÄ(œÅk‚àí1)(x)
 ‚â§ M2
m2
œÄ(œÅ)(x)‚àíœÄ (œÅk‚àí1)(x)
 ‚â§Œ¥.
18
Hence [fœÅk‚àí1 ‚àíŒ¥, fœÅk‚àí1 +Œ¥] is an 2Œ¥-bracket inL 1(P) that contains everyf œÅ withœÅ‚àà[œÅ k‚àí1, œÅk].
So the bracketing numberN [] is finite,N [](2Œ¥,F, L1(P))‚â§K‚â§ 1
Œ∑ + 1<‚àû.We thus conclude
from the Blum-DeHardt theorem thatFis a P-Glivenko-Cantelli class. Consequently, we have
sup
œÅ‚àà[0,1]

1
n
nX
i=1
ÀÜe2(Xi)
œÄ(œÅ)(Xi) ‚àíE ÀÜe2(X)
œÄ(œÅ)(X)

p
‚àí ‚Üí0.
This implies that  inf
œÅ‚àà[0,1]
1
n
nX
i=1
ÀÜe2(Xi)
œÄ(œÅ)(Xi) ‚àíinf
œÅ‚àà[0,1]
E ÀÜe2(X)
œÄ(œÅ)(X)

p
‚àí ‚Üí0.
By definition, ÀÜœÅ= arg min
œÅ
1
n
Pn
i=1
ÀÜe2(Xi)
œÄ(œÅ)(Xi) . DenoteS= arg min
œÅ
E ÀÜe2(X)
œÄ(œÅ)(X) . Then, by continu-
ity ofœÄ (œÅ)(X), we haved(ÀÜœÅ, S)
p
‚àí ‚Üí0, ford(ÀÜœÅ, S) = inf{|ÀÜœÅ‚àíÀÜœÅ‚àó|: ÀÜœÅ‚àó ‚ààS}.
Now, for any ÀÜœÅ‚àó ‚ààS, we have
E e2(X)
œÄ(ÀÜœÅ‚àó)(X) ‚â§E ÀÜe2(X) +o P (1)
œÄ(ÀÜœÅ‚àó)(X)
‚â§E ÀÜe2(X)
œÄ(œÅ‚àó)(X) +o P (1)E 1
œÄ(ÀÜœÅ‚àó)(X)
‚â§E e2(X) +o P (1)
œÄ(œÅ‚àó)(X) +o P (1)E 1
œÄ(ÀÜœÅ‚àó)(X)
=E e2(X)
œÄ(œÅ‚àó)(X) +o P (1)E
 1
œÄ(œÅ‚àó)(X) + 1
œÄ(ÀÜœÅ‚àó)(X)

=E e2(X)
œÄ(œÅ‚àó)(X) +o P (1).
Since
Var(ÀÜŒ∏œÄ(œÅ)
) =E
 e2(X)
œÄ(œÅ)(X)

+C,
whereCis a constant independent ofœÅ, we have
Var(ÀÜŒ∏œÄ(ÀÜœÅ‚àó)
)‚â§Var( ÀÜŒ∏œÄ(œÅ‚àó)
) +o P (1).
On the other hand, by the definition ofœÅ ‚àó,
Var(ÀÜŒ∏œÄ(ÀÜœÅ‚àó)
)‚â•Var( ÀÜŒ∏œÄ(œÅ‚àó)
)
also holds. Whence Var( ÀÜŒ∏œÄ(ÀÜœÅ‚àó)
)
p
‚àí ‚ÜíVar(ÀÜŒ∏œÄ(œÅ‚àó)
).
SinceœÅ ‚àó is the unique minimizer of Var( ÀÜŒ∏œÄ(œÅ)
), ÀÜœÅ‚àó p
‚àí ‚ÜíœÅ‚àó by continuity. Sinced(ÀÜœÅ, S)
p
‚àí ‚Üí0 and
ÀÜœÅ‚àó is an arbitrary element inS, we immediately conclude that
ÀÜœÅ
p
‚àí ‚ÜíœÅ‚àó.
19
A.3 Proof of Theorem 2
By the definition of ÀÜŒ∏œÄ(œÅ)
, we have
ÀÜŒ∏œÄ(œÅ)
= arg min
Œ∏
1
n
nX
i=1

‚Ñìf
Œ∏,i +

‚ÑìŒ∏,i ‚àí‚Ñì f
Œ∏,i
 Œæi
œÄ(œÅ)(Xi)

.
We assume ÀÜœÅ=œÅ‚àó +o P (1). By the continuity of the budget-preserving pathœÄ (œÅ), it follows that
œÄ(ÀÜœÅ)(Xi) =œÄ (œÅ‚àó)(Xi)+o P (1) for anyi‚àà {1, . . . , n}. This, as a result, givesÀÜŒ∏œÄ(ÀÜœÅ)
= ÀÜŒ∏œÄ(œÅ‚àó)
+oP (1)
by the continuity of‚Ñì f
Œ∏,i +

‚ÑìŒ∏,i ‚àí‚Ñì f
Œ∏,i

Œæi
œÄ(œÅ)(Xi) with respect toŒ∏.
Given the assumption that ÀÜŒ∏œÄ(œÅ‚àó) p
‚àí ‚ÜíŒ∏‚àó, from Theorem 1 in [51], we have
‚àön

ÀÜŒ∏œÄ(œÅ‚àó)
‚àíŒ∏ ‚àó
 d
‚àí ‚Üí N(0,Œ£œÅ‚àó),
where Œ£œÅ‚àó =H ‚àí1
Œ∏‚àó Var

‚àá‚Ñìf
Œ∏‚àó,i +

‚àá‚ÑìŒ∏‚àó,i ‚àí ‚àá‚Ñìf
Œ∏‚àó,i

Œæ
œÄ(œÅ‚àó)(Xi)

H‚àí1
Œ∏‚àó .
Since ÀÜŒ∏œÄ(ÀÜœÅ) p
‚àí ‚ÜíÀÜŒ∏œÄ(œÅ‚àó)
, ‚àön

ÀÜŒ∏œÄ(ÀÜœÅ)
‚àíŒ∏ ‚àó
 d
‚àí ‚Üí N(0,Œ£œÅ‚àó).
The definitionœÅ ‚àó = arg min
œÅ
Œ£œÄ(œÅ)
jj yields
Œ£œÅ‚àó,jj = Œ£œÄ(œÅ‚àó)
jj ‚â§min{Œ£ œÄ(0)
jj ,Œ£ œÄ(1)
jj }= min{Œ£ 0,jj ,Œ£ 1,jj }.
This completes the proof.
A.4 SettingœÄ‚àùÀÜeleads to a trivial choice ofÀÜœÅ= 0when not incorpo-
rating robustness constraint
Starting from the variance estimate used in the optimization objective
ÀÜœÅ= arg min
œÅ
1
n
nX
i=1
ÀÜe2(Xi)
œÄ(œÅ)(Xi),
by the Cauchy-Schwarz inequality, for anyœÄsuch that Pn
i=1 œÄ(X i) =n b (i.e. satisfying the
budget constraint), Pn
i=1
ÀÜe2(Xi)
œÄ(Xi) ‚â• (
Pn
i=1 ÀÜe(Xi))
2
Pn
i=1 œÄ(Xi) = (
Pn
i=1 ÀÜe(Xi))
2
nb
. The equality holds whenœÄ‚àùÀÜe,
which corresponds toœÄ (œÅ) withœÅ= 0.
B A natural family of budget-preserving paths
Among the diverse set of possible paths [28, 38], it is natural to considergeodesic paths, which
are a family of ‚Äúshortest paths.‚Äù
20
Definition 2(Geodesic [7]).A curveŒ≥:I‚ÜíMfrom an intervalI‚äÜRto a metric space
Mwith metricdis a geodesic if there is a constantv‚â•0 such that for anyœÅ‚ààIthere is a
neighborhoodJofœÅinIsuch that for anyœÅ 1, œÅ2 ‚ààJwe have
d(Œ≥(œÅ 1), Œ≥(œÅ2)) =v|œÅ 1 ‚àíœÅ 2|.
We revisit the examples from Section 2 and provide more geodesic paths.
In all the following examples, we assumePandQhave the same support.
Example 3(Linear path).The linear path,œÄ (œÅ) ‚àù(1‚àíœÅ)œÄ+œÅœÄ unif, is the geodesic path with
respect tod(P, Q) =‚à•P‚àíQ‚à•withv=‚à•œÄ‚àíœÄ unif‚à•. Here,‚à• ¬∑ ‚à•is any norm.
Example 4(Geometric path).The geometric path,œÄ (œÅ) ‚àùœÄ 1‚àíœÅ(œÄunif)œÅ, is the geodesic path
with respect tod(P, Q) =‚à•logP‚àílogQ‚à•withv=‚à•logœÄ‚àílogœÄ unif‚à•. Here, log is taken
element-wise.
Example 5(Hellinger path).The Hellinger path,œÄ (œÅ) ‚àù

(1‚àíœÅ) ‚àöœÄ+œÅ
‚àö
œÄunif
2
, is the
geodesic path with respect tod(P, Q) =‚à•
‚àö
P‚àí ‚àöQ‚à•withv=‚à• ‚àöœÄ‚àí
‚àö
œÄunif‚à•. Here, the
square root is taken element-wise.
Note (more examples).Some distance metrics may not have an analytical characterization
for their corresponding geodesic path, such as the Wasserstein and Jensen-Shannon distances.
However, it is computationally tractable to solve for a geodesic path numerically up to a tolerance
margin for many well-defined distance metrics. For example, when computing the geodesic for
the Jensen-Shannon distance, we can discretize the interval [0,1] intoNsegments so thatP 0 =P
andP N =Q, and we define a series of intermediate distributionsP 1, P2, . . . , PN‚àí1 . The task
is then cast as an optimization problem: we minimize the total path length computed as the
sum of the square roots of the Jensen-Shannon divergences between successive distributions, i.e.,PN‚àí1
i=0
p
JS(Pi, Pi+1). Here, JS(P‚à•Q) = 1
2 D(P‚à•M) + 1
2 D(Q‚à•M), whereM= 1
2 (P+Q). This
is a constrained optimization problem and can be solved by standard gradient-based methods.
B.1 Uniqueness ofœÅ ‚àó
In Section 2, we saw that the uniqueness of the optimalœÅ ‚àó and the consistency of ÀÜeare
sufficient conditions for the consistency of ÀÜœÅ. In the case of all three budget-preseving paths from
the previous section, it can be easily verified by computing the second derivative of Var( ÀÜŒ∏œÄ(œÅ)
)
that this variance is strictly convex and thusœÅ ‚àó is unique. We include the corresponding proofs
for completeness.
Linear path.We haveœÄ (œÅ)(X) = (1‚àíœÅ)œÄ(X) +œÅ nb
n . The problem of minimizing Var( ÀÜŒ∏œÄ(œÅ)
)
is equivalent to
arg min
œÅ
E
 (Y‚àíf(X)) 2
(1‚àíœÅ)œÄ(X) +œÅ nb
n

.
Denotingg(œÅ) =E
h
(Y‚àíf(X)) 2
(1‚àíœÅ)œÄ(X)+œÅ
nb
n
i
, we have
g‚Ä≤(œÅ) =E
"
‚àí(Y‚àíf(X)) 2  nb
n ‚àíœÄ(X)

 
(1‚àíœÅ)œÄ(X) +œÅ nb
n
2
#
,
21
and
g‚Ä≤‚Ä≤(œÅ) =E
"
2 (Y‚àíf(X)) 2  nb
n ‚àíœÄ(X)
2
 
(1‚àíœÅ)œÄ(X) +œÅ nb
n
3
#
.
Clearly,g ‚Ä≤‚Ä≤(œÅ)>0, which means thatg(œÅ) is convex. Hence, there is a unique optimal value
ofœÅin [0,1].
Notice thatg ‚Ä≤(1) = n2
n2
b
E

(Y‚àíf(X)) 2  
œÄ(X)‚àí nb
n

. Hence, ifE

(Y‚àíf(X)) 2œÄ(X)

>
nb
n E

(Y‚àíf(X)) 2
, theng ‚Ä≤(1)>0, which implies that the optimalœÅlies in [0,1).
Geometric path.Consider the pathœÄ (œÅ)(X)‚àùœÄ(X) 1‚àíœÅ(œÄunif)œÅ; in particular,œÄ (œÅ)(X) =
nb
n
œÄ(X)1‚àíœÅ
E[œÄ(X)1‚àíœÅ] .
Similar to the last example, we denoteg(œÅ) =E
h
(Y‚àíf(X)) 2
œÄ(œÅ)(X)
i
= n
nb
E
h
(Y‚àíf(X)) 2
œÄ(X)1‚àíœÅ
i
E

œÄ(X)1‚àíœÅ
.
Then, we have
g‚Ä≤(œÅ) = n
nb
E
(Y‚àíf(X)) 2
œÄ(X)1‚àíœÅ logœÄ(X)

E

œÄ(X)1‚àíœÅ
‚àí n
nb
E
(Y‚àíf(X)) 2
œÄ(X)1‚àíœÅ

E

œÄ(X)1‚àíœÅ logœÄ(X)

,
and
g‚Ä≤‚Ä≤(œÅ) = n
nb
E
(Y‚àíf(X)) 2
œÄ(X)1‚àíœÅ log2 œÄ(X)

E

œÄ(X)1‚àíœÅ
+ n
nb
E
(Y‚àíf(X)) 2
œÄ(X)1‚àíœÅ

E

œÄ(X)1‚àíœÅ log2 œÄ(X)

‚àí2 n
nb
E
(Y‚àíf(X)) 2
œÄ(X)1‚àíœÅ logœÄ(X)

E

œÄ(X)1‚àíœÅ logœÄ(X)

.
Since (Y‚àíf(X)) 2 ‚â•0,œÄ(X)>0, and log 2 œÄ(X)‚â•0, we have that
E
(Y‚àíf(X)) 2
œÄ(X)1‚àíœÅ log2 œÄ(X)

E

œÄ(X)1‚àíœÅ
+E
(Y‚àíf(X)) 2
œÄ(X)1‚àíœÅ

E

œÄ(X)1‚àíœÅ log2 œÄ(X)

‚â•2
s
E
(Y‚àíf(X)) 2
œÄ(X)1‚àíœÅ log2 œÄ(X)

E[œÄ(X) 1‚àíœÅ]E
(Y‚àíf(X)) 2
œÄ(X)1‚àíœÅ

E

œÄ(X)1‚àíœÅ log2 œÄ(X)

=2
s
E
(Y‚àíf(X)) 2
œÄ(X)1‚àíœÅ log2 œÄ(X)

E
(Y‚àíf(X)) 2
œÄ(X)1‚àíœÅ

E[œÄ(X) 1‚àíœÅ]E

œÄ(X)1‚àíœÅ log2 œÄ(X)

‚â•2
s
E2
(Y‚àíf(X)) 2
œÄ(X)1‚àíœÅ logœÄ(X)

E2 [œÄ(X)1‚àíœÅ logœÄ(X)]
=E
(Y‚àíf(X)) 2
œÄ(X)1‚àíœÅ logœÄ(X)

E

œÄ(X)1‚àíœÅ logœÄ(X)

.
The last inequality follows from the Cauchy-Schwarz inequality. Therefore, we haveg‚Ä≤‚Ä≤(œÅ)‚â•0.
Further, ifœÄ(X)Ã∏=œÄ unif, the inequality is strict, which meansg(œÅ) is convex. Thus, there is a
unique optimal value ofœÅin [0,1].
22
Hellinger path.SupposePandQare two discrete distributions. The Hellinger distance
betweenPandQisH(P, Q) = 1‚àö
2 ‚à•
‚àö
P‚àí ‚àöQ‚à•2. The geodesic connectingœÄ(X) andœÄ unif = nb
n
is:
œÄ(œÅ)(X) =
sin((1‚àíœÅ)Œ≤)
sinŒ≤
p
œÄ(X) + sin(œÅŒ≤)
sinŒ≤
rnb
n
2
,
whereŒ≤= arccos
Pn
i=1
q
œÄ(Xi)
n ¬∑n b

.
Similarly as above, minimizing the variance Var( ÀÜŒ∏œÄ(œÅ)
) amounts to minimizing the function
g(œÅ) =E
Ô£Æ
Ô£ØÔ£∞ (Y‚àíf(X)) 2

sin((1‚àíœÅ)Œ≤)
sinŒ≤
p
œÄ(X) + sin(œÅŒ≤)
sinŒ≤
pnb
n
2
Ô£π
Ô£∫Ô£ª
overœÅ. The derivativeg ‚Ä≤(œÅ) is given by
‚àí2E
"
(Y‚àíf(X)) 2
sin((1‚àíœÅ)Œ≤)
sinŒ≤
p
œÄ(X) + sin(œÅŒ≤)
sinŒ≤
rnb
n
‚àí3 
‚àíŒ≤ cos((1‚àíœÅ)Œ≤)
sinŒ≤
p
œÄ(X) +Œ≤ cos(œÅŒ≤)
sinŒ≤
rnb
n
#
,
while the secondg ‚Ä≤‚Ä≤(œÅ) is given by
E
"
(Y‚àíf(X)) 2
sin((1‚àíœÅ)Œ≤)
sinŒ≤
p
œÄ(X) + sin(œÅŒ≤)
sinŒ≤
rnb
n
‚àí4 "
6

‚àíŒ≤ cos((1‚àíœÅ)Œ≤)
sinŒ≤
p
œÄ(X)
+Œ≤ cos(œÅŒ≤)
sinŒ≤
rnb
n
2
+ 2Œ≤2
sin((1‚àíœÅ)Œ≤)
sinŒ≤
p
œÄ(X) + sin(œÅŒ≤)
sinŒ≤
rnb
n
2##
>0.
Therefore,g(œÅ) is strictly convex, and there is a unique optimal value ofœÅin [0,1].
C Perturbed model errors after robust optimization
It is natural to choose the constraintCby upper-bounding the norm ofœµ. Our default choice
is the‚Ñì 2 norm, i.e.‚à•œµ‚à• 2 ‚â§c. The‚Ñì 2 norm can be roughly thought of as controlling the variance
of the errors in ÀÜe2. In particular, imagine ÀÜe 2(Xi) can be viewed as a noisy version ofe 2(Xi):
ÀÜe2(Xi) =e 2(Xi) +Œæ i, where the (X i, Œæi) pairs are i.i.d. andŒæ i have mean zero. Then, by
concentration,‚à•œµ‚à• 2
2 ‚âà P
i Var(Œæi).
In Figure 8 we illustrate how robust optimization over the‚Ñì 2 setCrecovers errors ÀÜe2(Xi) +œµi
that are much closer toe 2(Xi) than simply using ÀÜe2(Xi).
D A toy example: choice ofC
A simple‚Ñì 2 norm constraint may not always be the most powerful choice ofC. Zooming out,
our method can in principle be combined withanychoice ofC, including one where we learn
regions of the space where scores are systematically overconfident or underconfident. At a high
23
/uni00000014/uni00000015/uni00000016/uni00000017/uni00000018/uni00000019/uni0000001a/uni0000001b/uni0000001c/uni00000014/uni00000013
/uni0000002c/uni00000051/uni00000047/uni00000048/uni0000005b
/uni00000013
/uni00000014
/uni00000015
/uni00000016
/uni00000017
/uni00000018
/uni00000019/uni00000028/uni00000055/uni00000055/uni00000052/uni00000055
/uni00000037/uni00000055/uni00000058/uni00000048/uni00000003/uni00000048/uni00000055/uni00000055/uni00000052/uni00000055
/uni00000035/uni00000052/uni00000045/uni00000058/uni00000056/uni00000057/uni00000003/uni00000048/uni00000055/uni00000055/uni00000052/uni00000055/uni00000003/uni0000000b/uni0000002f/uni00000015/uni0000000c
/uni00000028/uni00000056/uni00000057/uni0000004c/uni00000050/uni00000044/uni00000057/uni00000048/uni00000047/uni00000003/uni00000048/uni00000055/uni00000055/uni00000052/uni00000055
Figure 8:Perturbed errorsÀÜe 2(Xi) +œµ i vs naive errorsÀÜe2(Xi)with‚Ñì 2 constraintC.We
consider a regime where we underestimate the true error (for example, due to the model being
overconfident). We lete(X i)‚àº N(5,0.25) and ÀÜe(Xi)‚àº N(3,0.25), andœÄ (œÅ) is the linear path
withœÅ= 0.5. The robustness constraint isC={œµ:‚à•œµ‚à• 2 ‚â§50}. Each indexicorresponds to
one sampleX i. The robust error (green bar) is the error after perturbation, ÀÜe2(Xi) +œµi, and the
estimated error (blue bar) is the error before perturbation, ÀÜe2(Xi). The robust errors are much
closer to the estimated errors.
level, our method (1) learnsC(in our experiment, the ‚Äúlearning‚Äù is a simple fitting ofcthrough
cross-validation), and (2) solves a robust optimization problem withCin place. Your suggestion
is an interesting choice of step (1).
We developed a dataset featuring a central ‚Äúhard‚Äù region (|X| ‚â§2) flanked by two ‚Äúeasy‚Äù
regions (2<|X|<5). In the easy regions, error data was sampled fromN(2,0.05). In the hard
region, error was drawn fromN(1,0.25). The estimator of error, ÀÜœµ(X), is designed to underes-
timate the error in the hard region and overestimate the error in the easy region. Specifically,
ÀÜœµ(X) = 0.5 for|X| ‚â§2, and ÀÜœµ(X) = 2.5 otherwise.
Subsequently, we trained a meta-classifier, a gradient boost classifier,h(X), to identify these
regions solely based on the performance of ÀÜœµ(X), without prior knowledge of the region bound-
aries.
This approach proved highly effective, with the meta-classifier achieving over 99% accuracy in
identifying the regions. This demonstrates our success in learning the error regions and enables
us to separate the constraint setCbased on these distinctions. For instance,Ccan be defined
as‚à•œµ easy‚à•2 ‚â§c easy for the easy region (2<|X|<5) and‚à•œµ hard‚à•2 ‚â§c hard for the hard region
(|X| ‚â§2). Or even simpler, we can only optimize over hard regions, i.e.c easy = 0. While these
regions‚Äô dimensions are not fixed and depend onX, this presents no practical difficulties because
we have complete information aboutX.
Next, we compared this structured constraint with the global constraint. Here, for the struc-
tured constraint, we only optimize over the hard region. The following table shows the result
whenn= 7000,n h = 1400, andœÄ‚àùÀÜœµ.
We found that incorporating the structured constraint provided a slight gain in ESS over the
24
Method ESS ESS Gain (%)
Uniform 1400 0.00%
Active 1213 -13.3%
Robust active (global) 1491 6.5%
Robust active (structured) 1495 6.8%
global constraint while reducing the constraint size (c global = 85 vs.c hard = 75). This suggests
that a more focused perturbation can be beneficial when we have strong knowledge of confident
regions. However, we note that the global constraint remains a simple and practical approach
given the limited gain.
E Additional experimental results
E.1 Plots with coverage and standard deviation
In this subsection, we provide figures corresponding to the figures in the main text, where in
addition to the effective sample size we also plot coverage.
402
569
805
1140
1614
2284
3233Effective sample size
Burn-in size = 140
542
737
1001
1361
1850
2515
3418
Burn-in size = 280
723
938
1217
1579
2048
2657
3446
Burn-in size = 420
831
1050
1327
1676
2118
2676
3382
Burn-in size = 560
1102
1348
1649
2017
2467
3017
3691
Burn-in size = 840
1728 1958 2218
0.6
0.7
0.8
0.9
1.0
Coverage
1443 1744 2109 1576 1874 2230 1478 1773 2127 1746 2036 2375
nb
uniform active robust active
Figure 11:Effective sample size and coverage on US Census data, for varying burn-in
dataset sizes. We compare uniform, active, and robust active sampling, for different values of
the sampling budgetn b. The target of inference is the relationship between age and income,
estimated via a linear regression. We show the mean and one standard deviation of the effective
sample size estimated over 500 trials; in each trial we independently sample the observed labels.
25
895
1061
1257
1490
1766
2093
2480Effective sample size
Training size=2000
960
1123
1313
1536
1796
2100
2456 Training size=5000
5
51
98
144
191
238
284
Standard deviation 9
54
98
143
188
233
277
1357 1597 1880
0.6
0.7
0.8
0.9
1.0
Coverage
1357 1597 1880
nb
uniform active robust active
Figure 9:Effective sample size and coverage on Pew post-election survey data, for
different dataset sizes used to trainf. We compare uniform, active, and robust active sampling,
for different values of the sampling budgetn b. The target of inference is the approval rate of a
presidential candidate. We show the mean and one standard deviation of the effective sample
size estimated over 500 trials; in each trial we independently sample the observed labels.
26
2113
2265
2428
2603
2790
2991
3206Effective sample size
Without robustness constraint
2128
2279
2441
2615
2801
3000
3214 With robustness constraint
57
68
79
90
100
111
122
Standard deviation 73
84
95
105
116
127
138
2246 2420 2609 2812
0.6
0.7
0.8
0.9
1.0
Coverage
2420 2609 2812
nb
hellinger geometric linear
Figure 10:Effective sample size and coverage for different budget-preserving paths on
Pew post-election survey data, without (left) and with (right) a robustness constraintC. In
both cases, the geometric path leads to the largest effective sample size. The target of inference
is the same as in Figure 3. We show the mean and one standard deviation of the effective sample
size estimated over 500 trials; in each trial we independently sample the observed labels.
27
601
680
770
872
987
1117
1265Effective sample size
Political bias
1404
1665
1975
2343
2779
3297
3911 Politeness
717
800
892
995
1110
1238
1381 Misinformation
810 908 1019 1142
0.6
0.7
0.8
0.9
1.0
Coverage
1976 2378 2861 1010 1138 1281
nb
uniform active robust active
Figure 12:Effective sample size and coverage on social science text annotation
datasets. We compare uniform, active, and robust active sampling, for different values of the
sampling budgetn b. The targets of inference are (left to right) the prevalence of right-leaning
political bias, the relationship between hedging and politeness, and the prevalence of misinfor-
mation. We show the mean and one standard deviation of the effective sample size estimated
over 500 trials; in each trial we independently sample the observed labels.
943
1096
1274
1481
1722
2002
2327Effective sample size
Burn-in size = 606
1432
1605
1798
2014
2256
2527
2831
Burn-in size = 1213
2053
2216
2391
2581
2786
3007
3245
Burn-in size = 1819
2680
2812
2951
3097
3250
3411
3580
Burn-in size = 2426
3805
3906
4008
4114
4222
4334
4448
Burn-in size = 3639
1417 1578 1757
0.6
0.7
0.8
0.9
1.0
Coverage
2047 2191 2345 2417 2606 2808 2917 3052 3194 3986 4094 4204
nb
uniform active robust active (geometric) robust active (linear)
Figure 13:Effective sample size (top) and coverage (bottom) on Pew post-election
survey data, for varying burn-in dataset sizes with respect to different proportions of the data.
We compare uniform, active, and robust active sampling with geometric and linear paths, for
different values of the sampling budgetn b. The target of inference is the approval rate of a
presidential candidate. We show the mean and one standard deviation of the effective sample
size estimated over 500 trials; in each trial we independently sample the observed labels.
28
E.2 Burn-in size v.s. robustness constraintC
In addition to optimizedœÅ robust along the path, we also provided the optimized valuecin
the robustness constraintC={œµ:‚à•œµ‚à• 2 ‚â§c}. As expected, we observe a more conservative
constraint when the errors are poorly estimated.
500 1000 1500 2000 2500 3000 3500
Size of burn-in data
1
2
3
4c
 Post-election survey research
Figure 14:Optimized valuecalong the geometric pathas a function of the size of the
burn-in data for the post-election survey data.
E.3 Sensitivity to step size
When we solve the optimization problem (4), we employ a grid search forœÅin the outer loop.
We conducted experiments to explore different step sizes of the grid search and confirmed the
robustness of our results to step-size selection, as shown below. The gap in effective sample size
between these two estimators is minimal, and both significantly outperform uniform and active
baselines.
2945 3107 3277
2809
2953
3104
3263
3430
3605
Effective sample size
2945 3107 3277
0.6
0.7
0.8
0.9
1.0
Coverage
2945 3107 3277
7
36
64
93
122
150
179
Standard deviation of ESS
nb
uniform active robust active (step_size=0.01) robust active (step_size=0.1)
Figure 15:Effective sample size on Pew post-election survey data, for different step sizes
in grid search forœÅ. We compare uniform, active, and robust active sampling with grid search
step sizes of 0.01 and 0.1. The target of inference is the approval rate of a presidential candidate.
We show the mean and one standard deviation of the effective sample size estimated over 500
trials; in each trial we independently sample the observed labels.
29