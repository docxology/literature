arXiv:2502.12654v1  [cs.SI]  18 Feb 2025
Free Energy and Network Structure:
Breaking Scale-Free Behaviour Through
Information Processing Constraints
Journal Title
XX(X):
1– 14
©The Author(s) 2025
Reprints and permission:
sagepub.co.uk/journalsPermissions.nav
DOI: 10.1177/T oBeAssigned
www.sagepub.com/
SAGE
Peter R. Williams1,2 and Zhan Chen3
Abstract
In this paper we show how The Free Energy Principle (FEP) can p rovide an explanation for why real-world networks
deviate from scale-free behaviour, and how these character istic deviations can emerge from constraints on informatio n
processing. We propose a minimal FEP model for node behaviou r reveals three distinct regimes: when detection
noise dominates, agents seek better information, reducing isolated agents compared to expectations from classical
preferential attachment. In the optimal detection regime, super-linear growth emerges from compounded improvements
in detection, belief, and action, which produce a preferred cluster scale. Finally , saturation effects occur as limits on
the agent’s information processing capabilities prevent i ndeﬁnite cluster growth. These regimes produce the knee-
shaped degree distributions observed in real networks, exp laining them as signatures of agents with optimal informati on
processing under constraints. We show that agents evolving under FEP principles provides a mechanism for preferential
attachment, connecting agent psychology with the macrosco pic network features that underpin the structure of real-
world networks.
Keywords
Network formation; Information processing; Free Energy Pr inciple; Mechanistic modelling; Preferential attachment ;
Scale-free networks; Biological constraints; Agent-base d modelling; Collective behaviour; Complex systems
Introduction
Complex networks pervade natural and artiﬁcial systems,
from cellular interactions to social relationships (
Barab ´ asi
2016). A common feature in these networks is the frequent
emergence of power-law degree distributions, where the
probability of a node having k connections follows
P (k) ∝ k−γ (
Newman 2003b ). The canonical explanation
for such distributions is preferential attachment: new
nodes preferentially connect to highly connected existing
nodes (
Barab ´ asi and Albert 1999 ). While this mechanism
successfully describes network growth, it has faced critic ism
for lacking mechanistic underpinning ( Newman 2018 ). Some
researchers argue that power-law distributions might aris e
from alternative processes ( Clauset et al. 2009 ), suggesting
the need for deeper theoretical foundations.
Notably, many real-world networks exhibit systematic
deviations from pure power-law behaviour, often showing a
characteristic knee shape where moderate-degree nodes are
overrepresented relative to both low and high degrees, when
compared to the preferential attachment case. While variou s
mechanisms have been proposed to explain these deviations,
including aging effects (
Dorogovtsev and Mendes 2002 ) and
resource constraints ( Amaral et al. 2000 ), an explanation
based on information processing principles has not yet
emerged. Understanding these deviations is crucial, as the y
may reﬂect constraints on how agents process and act on
information in their environment.
Parallel to network science, a different theoretical frame -
work has emerged in cognitive science and neurobiology:
the Free Energy Principle (FEP) (
Friston 2010 ). This prin-
ciple posits that biological systems maintain their order b y
minimising a quantity called variational free energy, whic h
minimises the surprise (negative log probability) of their
sensory states (
Friston 2013 ). FEP provides a mathematical
framework for understanding how agents perceive, learn, an d
act in their environment ( Ramstead et al. 2018 ). Under this
principle, biological systems actively sample their envir on-
ment to conﬁrm their internal models, a process known as
active inference (
Friston et al. 2017 ).
Despite their separate development, these two
frameworks—– network formation and free energy
minimisation —–might share deeper connections.
Both describe systems organising themselves through
information-driven processes (
Lynn and Bassett 2020a ;
Kirchhoff et al. 2018 ). While preferential attachment
implicitly assumes agents can sense and respond to network
structure (
Newman 2003b ), FEP explicitly describes
how agents process and act on information ( Parr et al.
2020). This suggests that preferential attachment might
emerge as a results of more fundamental principles of
information processing, an idea supported by recent work
on information-theoretic approaches to network formation
(
V er Steeg 2019 ).
Recent studies have shown that FEP can explain diverse
biological phenomena, from cellular behaviour to neural
organisation (
Friston 2013 ; Constant et al. 2018 ). The prin-
ciple has been successful in bridging scales of organisatio n
1 Rinna KK, T okyo, Japan
2 Independent Researcher
3 Microsoft Japan, T okyo, Japan
Email: prw20042004@yahoo.co.uk
Prepared using sagej.cls [V ersion: 2017/01/17 v1.20]
2 Journal Title XX(X)
(Ramstead et al. 2018 ), although some researchers question
its universal applicability ( Colombo and Wright 2018 ). Sim-
ilarly, while preferential attachment has been observed in
many systems (
Jeong et al. 2003b ), from citation networks to
protein interactions, its mechanistic origins remain deba ted
(Medo et al. 2011 ).
A key challenge in both ﬁelds is understanding how local,
individual-level processes generate global, system-leve l
patterns ( Anderson 2018 ). In network science, this manifests
as the emergence of scale-free structures from individual
attachment decisions (
Bianconi and Barab ´ asi 2001 ). In FEP ,
it appears as the generation of adaptive behaviour from loca l
information processing ( Kirchhoff et al. 2018 ). This parallel
suggests an opportunity for theoretical synthesis, buildi ng
on recent work connecting information theory and network
formation (
Lynn and Bassett 2020a ).
Our work bridges these domains by showing that FEP
can provide a mechanistic foundation for network formation ,
revealing how deviations from pure preferential attachmen t
can emerge from information processing constraints. This
builds on previous attempts to ground network formation
in cognitive processes (
Papadopoulos et al. 2012a ) while
addressing criticisms of both preferential attachment’s l ack
of mechanism ( Newman 2018 ) and FEP’s explanatory
scope ( Colombo and Wright 2018 ). W e show that agents
following active inference can generate network structure s
with characteristic deviations from power-law distributi ons,
reﬂecting regimes of information processing.
The analysis focuses on a simple model where agents
move in a one-dimensional space, sensing and responding
to their neighbours according to FEP . This model was
selected to be sufﬁciently complex to include all of the key
behavioural processes, while staying simple enough to be
analytically tractable. Through this model, we identify th ree
distinct information processing regimes - noise-dominate d,
optimal detection, and saturation - that shape network
formation. While similar models have been used to study
collective behaviour (
Sumpter 2010a ), our work shows how
these regimes can emerge from principles of uncertainty
minimisation and create characteristic network structure s.
This synthesis has broad implications beyond network
science. It suggests that network structures in biological
and social systems reﬂect information processing constrai nts
rather than arbitrary rules or external limitations. The
identiﬁcation of distinct information processing regimes
provides new approaches to understanding and designing
networks across domains, from social media platforms to
networks of artiﬁcial agent systems. The framework offers
practical insights for network design while deepening our
understanding of how cognitive constraints shape collecti ve
structure.
In the following sections we develop this theoretical
framework. W e begin by examining the constraints that bio-
logical agents face when processing information about thei r
environment, showing how these create natural scales in net -
work formation. W e then derive how agents translate sensory
information into movement decisions through free energy
minimisation, leading to an attachment kernel that emerges
from rational inference under uncertainty. This kernel rev eals
three distinct regimes of information processing—noise-
dominated, optimal detection, and saturation—that shape
network structure in characteristic ways. W e show how
the interplay between these regimes can explain commonly
observed deviations from pure scale-free behaviour, parti c-
ularly the knee-shaped degree distributions found in many
real networks. This analysis connects microscopic infor-
mation processing constraints to the macroscopic network
structure, providing a mechanistic foundation for network
formation that bridges cognitive and collective behaviour .
W e conclude by exploring the implications of this framework
for understanding diverse systems, from biological networ ks
to artiﬁcial agent collectives, and suggest new approaches
for analysing and designing networks where information
processing plays an important role.
Mathematical Framework Connecting FEP
and Preferential Attachment
W e develop a minimal Active Inference model to understand
how simple agents learn from and interact with their
environment. Our model captures two key processes: how
agents update their internal model of the world based on
sensory data, and how they choose actions based on this
internal model. By using analytically tractable functiona l
forms, we can investigate the emergent properties of
collaboration networks that arise from these behavioural
patterns.
The Agent and its World
W e begin with a simple agent navigating a one-dimensional
world through basic left and right movements controlled
by velocity commands. The agent’s sensory capabilities are
limited: it can only detect nearby neighbours with a detecti on
probability that decreases with distance. Internally, the agent
maintains a single latent parameter b, which represents its
belief about the environmental resource gradient’s slope.
The agent model and one-dimensional environment are
intentionally minimal to isolate the core principles of
information processing constraints on network formation a nd
maintain analytical tractability. This simpliﬁcation all ows us
to clearly demonstrate how distinct information processin g
regimes emerge from FEP principles. W e acknowledge
that real-world agents and environments are far more
complex. Extending the model to higher-dimensional spaces
and incorporating richer agent representations would like ly
modify the quantitative scaling relationships observed.
However, we argue that the qualitative regimes – noise-
dominated information seeking, optimal detection and supe r-
linear growth, and saturation due to processing limits –
and the fundamental mechanism of information processing
constraints shaping network structure are likely to be
robust features that generalize beyond this simpliﬁed sett ing.
Future research could explore these extensions to assess th e
quantitative impact of increased complexity.
Markov Blanket and States The Markov blanket deﬁnes
the boundary between an agent and its environment. It
separates an agent’s internal states from external variabl es,
mediating all interaction and information ﬂow between them .
Thus the agent’s interaction with its environment can be
described through two key state types. The agent’s active
states represent motor outputs, that generate velocity vapplied
Prepared using sagej.cls
Williams and Chen 3
in the external world, based on the internal latent variable
b. This simpliﬁes how an agent’s brain states translate into
physical movement.
Its sensory states consist of binary detection events
(“neighbour detected on left” or “neighbour detected
on right”), providing noisy information about neighbour
positions. Beyond these states lie what we call the external
variables, including the agent’s true position and the actu al
resource distribution. These remain unknowable to the agen t,
existing outside its Markov blanket.
Choice of Prior The agent’s prior distribution π(b) on the
slope parameter b represents its baseline expectations about
typical resource gradient behaviour. In biological terms, this
prior might be genetically encoded through evolutionary
processes, developed during early learning phases, and
remain ﬁxed throughout the agent’s lifetime (for model
simplicity). While our current model assumes a static prior ,
future extensions could incorporate prior adaptation base d on
accumulated experience.
The Likelihood Function The likelihood function L(Obs |
b) serves as the bridge between external reality and
internal model, mapping how sensory readings arise from
hypothesised environmental states. Much like how an
eye transforms incoming photons into neural activity, this
function translates external states (neighbour detection ) into
the agent’s internal model (beliefs about resource gradien ts).
In our speciﬁc implementation, the agent processes
neighbour-detection events by counting detections over a
brief time window and compressing these counts into a
scalar statistic D (e.g., right-side detections minus left-side
detections). W e use D as the primary sensory reading, where
a large positive value suggests neighbour clustering in the
positive direction, showing a larger b through our likelihood
function deﬁnition.
A Continuously Updating V ariational Posterior The
recognition density, or variational posterior Q(b), represents
the agent’s current beliefs about the environmental gradie nt
after observing sensory data. This probability distributi on
over possible slope values b continuously updates as new
information arrives through the sensory apparatus. The
recognition density serves as a computationally tractable
approximation to the true Bayesian posterior, allowing the
agent to maintain and update beliefs in real-time without
requiring exhaustive computation of the complete posterio r
distribution.
The Free Energy and Minimisation The free energy F
originates from the principle of least action in statistica l
physics, generalised to biological systems. It represents the
difference between the agent’s internal model of reality
and the actual environmental dynamics. Through variationa l
calculus, we can derive the speciﬁc form relevant to our
model,
F
[
Q(b)
]
=
∫
Q(b) lnQ(b)
π(b) db −
∫
Q(b) lnL
(
Obs | b
)
db.
(1)
The ﬁrst term, known as the Kullback-Leibler divergence,
measures how far the current beliefs deviate from prior
expectations. The second term evaluates how well these
beliefs explain incoming sensory data.
Behaviourally, this creates a trade-off between maintain-
ing consistency with evolutionary and developmental knowl -
edge (ﬁrst term) and adapting beliefs about the environmen-
tal gradient based on new sensory information (second term) .
The agent updates its internal model by minimising F , which
involves adjusting Q(b) to balance prior knowledge with
new sensory evidence. When sensory data is uninformative,
the posterior stays close to the prior; when strong evidence
arrives, the posterior adapts to better explain the new obse r-
vations.
Action and External Movement The agent’s internal
belief about the environmental gradient, represented by th e
parameter b, guides its physical movement through the
environment. This translation from internal state to exter nal
action occurs through what we might think of as the agent’s
motor system. In this model, the action-generation process of
the agent involves generating a velocity based on its curren t
best estimate of the environmental gradient,
v = f
(
µb
)
, (2)
where f is a mapping function that converts the posterior
mean belief µb into a desired movement speed and direction.
This function represents the agent’s behavioural policy, i .e.
how it responds to its beliefs about the environment. For
example, a simple linear mapping would cause the agent to
move faster in environments where it believes the resource
gradient is steeper,
v = γµ b. (3)
Further reﬁnements may involve factoring in that perfect
execution of intended movements is impossible in biologica l
and non-biological systems. Motor noise, environmental
perturbations, and imperfect muscle control could all be
included here in a more complex model.
This action-generation process completes the active
inference loop: the agent’s internal beliefs about the grad ient
µb drive its physical movement v, which in turn changes
its position in the environment. This repositioning alters
the spatial relationships with neighbours, leading to new
patterns of detection events that update the agent’s belief s
through the free energy minimisation process described
earlier. Through this continuous cycle of perception and
action, the agent maintains an ongoing dynamic relationshi p
with its environment, constantly updating its model and
adjusting its behaviour in response to new evidence.
Closed-Form Expression of µb under Gaussian
Assumptions
T o derive tractable expressions for the free energy, we
make several assumptions about the functional forms of
our distributions. While these assumptions primarily serv e
mathematical convenience, they maintain plausibility wit h
biological agents while enabling analytical solutions to t he
free energy minimisation problem.
W e begin with the prior distribution π(b), which we model
as a Gaussian distribution
π(b) =N
(
b; µπ, σ 2
π
)
. (4)
The parameters of this distribution encode the agent’s
baseline expectations about environmental gradients. The
Prepared using sagej.cls
4 Journal Title XX(X)
mean µπ represents the expected slope magnitude, where
µπ = 0shows no prior belief in a gradient’s existence, while
µπ > 0 suggests an innate expectation of positive gradients.
The variance σ2
π quantiﬁes the ﬂexibility of these prior
beliefs. While the Gaussian form is not mandated by the
Free Energy Principle, it aligns with standard approaches
in variational Bayes and provides analytically tractable
solutions.
For the likelihood function, we approximate the distribu-
tion of the detection statistic D using a Gaussian whose mean
depends linearly on the slope parameter b,
L
(
Obs | b
)
= N
(
D; µD(b), σ 2
D
)
, (5)
where µD(b) =α b + β. This linear relationship captures
how larger environmental gradients lead to higher expected
detection counts. The coefﬁcient α determines the sensitivity
of the detection statistic to changes in the slope, while
β accounts for any baseline bias in the detection process.
The variance σ2
D represents various sources of uncertainty
in the sensory process, including imperfect detection
abilities, environmental noise, and ﬁnite sampling window s.
While more complex functional forms could model the
relationship between slope and detections, this linear
Gaussian approximation provides a reasonable balance
between biological realism and mathematical tractability .
Finally, we model the recognition density Q(b) as a
Gaussian distribution
Q(b) =N
(
b; µb, σ 2
b
)
. (6)
This distribution represents the agent’s current belief st ate
about the environmental gradient. The mean µb encodes
the agent’s best estimate of the slope. A large positive µb
indicates a belief in resources increasing in the positive x-
direction. The variance σ2
b quantiﬁes the agent’s uncertainty
about this estimate, with smaller values indicating greate r
conﬁdence. This Gaussian form for Q(b) enables the agent
to maintain a computationally efﬁcient representation of i ts
beliefs using just two parameters, µb and σ2
b , which update
as new sensory information arrives.
The combination of these Gaussian assumptions leads to
closed-form expressions for both terms in the free energy
functional. This mathematical convenience allows us to
derive explicit update equations for the recognition densi ty
parameters, making the model both analytically tractable a nd
biologically interpretable. While alternative distribut ional
choices could offer more precise models of biological reali ty,
our Gaussian assumptions capture the essential features of
belief updating while maintaining mathematical simplicit y.
Under these Gaussian assumptions for the prior, likeli-
hood, and recognition density, the free energy functional
admits an explicit closed form (see the Appendix at the end
of this paper for the complete derivation). The gradient of t he
free energy with respect to the agent’s current estimate of t he
slope takes the form
∂F
∂µ b
= µb − µπ
σ2π
+ − α (D − β) +α 2 µb
σ2
D
, (7)
where µb represents the agent’s current slope estimate, µπ
its prior expectation, and D the observed detection statistic.
Setting this gradient to zero yields the solution for the
optimal slope estimate
µb = (α/σ 2
D) (D − β) + µπ/σ 2
π
α 2/σ 2
D + 1/σ 2π
. (8)
This expression reveals how the agent balances prior
knowledge against sensory evidence when updating its
beliefs. The denominator terms α 2/σ 2
D and 1/σ 2
π act as
precision weights: when sensory noise σ2
D is large, the agent
relies more on its prior beliefs. Conversely, when prior
uncertainty σ2
π is large, it weights new evidence more. The
parameter α determines how sensitive the detection statistic
is to the environmental gradient: a larger α means that
changes in the slope produce larger changes in neighbour
detection patterns, amplifying the inﬂuence of sensory dat a
on belief updates. This mathematical structure implements
a form of optimal Bayesian updating that could plausibly
be approximated by neural circuits in biological systems,
but also provides a concrete example of how free energy
minimisation might be realised in a model agent.
While the assumption of Gaussian distributions for the
prior, likelihood, and recognition density is primarily mo ti-
vated by analytical tractability, it also possesses some pl au-
sibility. Aggregated sensory data, as considered in our det ec-
tion statistic, may indeed approach Gaussian distribution s
due to the central limit theorem. Furthermore, Gaussian
distributions provide a parsimonious and mathematically
convenient representation of uncertainty, which aligns wi th
variational Bayesian methods. However, we acknowledge
that real-world noise and belief distributions may deviate
from perfect Gaussianity, and future work could explore the
impact of non-Gaussian noise models on the quantitative
aspects of network formation.
Deriving the Attachment Kernel and
Information Processing Regimes
The emergence of network structure in our model can
be understood through how agents detect and respond to
clusters of neighbours. T o develop this understanding, we
ﬁrst analyse the detection process itself, then examine
how detection information shapes movement decisions, and
ﬁnally identify distinct regimes of information processin g
that characterise network formation.
From Detection to Movement
Consider ﬁrst how an agent detects a cluster of d nearby
agents. Each cluster member has a probability p of being
detected within the agent’s sensing window τ. These
detection events can be modeled as independent Bernoulli
trials, leading to a binomial distribution of detection
counts. For clusters above some critical size, the central
limit theorem implies these counts approach a Gaussian
distribution, giving our detection statistic
D ∼ N (αd, η 2) (9)
where α = p/τ represents the base detection rate per cluster
member and η2 captures both intrinsic sensing noise and
temporal ﬂuctuations in detection counts.
Prepared using sagej.cls
Williams and Chen 5
This detection signal feeds into the agent’s belief updatin g
process through our free energy minimisation framework.
For large clusters where the detection signal dominates,
αd ≫ η, the posterior mean belief about environmental
gradients approaches
µb ≈ (α 2/σ 2
D)d
α 2/σ 2
D + 1/σ 2π
≈ Cd (10)
where
C = α 2σ2
π
α 2σ2π + σ2
D
(11)
represents the coupling strength between cluster size and
belief formation.
These beliefs about environmental gradients drive
movement through the agent’s velocity control,
v = γµ b ∝ d. (12)
This creates a relationship: larger clusters generate stro nger
detection signals, leading to stronger gradient beliefs an d
faster directed movement.
Constraints in Biological Agents
Before examining how agents form networks through their
interactions, we must ﬁrst understand the inherent limitat ions
that any biological agent faces when processing and acting
on information. These constraints create natural scales in
network formation, shaping the degree distribution in ways
that deviate from pure preferential attachment.
Our agent faces three limitations. First, it cannot
maintain arbitrarily strong beliefs about its environment .
The Gaussian prior on environmental gradients π(b) =
N (b; µπ, σ 2
π) imposes this constraint: beliefs about gradients
much larger than σπ incur heavy penalties through the KL-
divergence term in the Free Energy formulation. This create s
an effective upper bound bmax on believable gradient values.
Second, the agent has ﬁnite sensory capabilities. No agent
can detect an unlimited number of neighbours or process
an inﬁnite stream of sensory information. Our agent model
captures this through ﬁnite detection ranges, which impose
a maximum kmax on the number of neighbours that can be
simultaneously detected in any direction.
Third, the agent cannot move at arbitrary speeds, even if
it detects a strong environmental gradient. The relationsh ip
between inference and action in our model v = γµ b
combines with the bound on believable gradients to create
a maximum achievable velocity vmax = γbmax .
These limitations manifest as characteristic scales in the
degree distribution. From the bound on believable gradient s,
we obtain dbelief ≈ bmax /C , beyond which additional cluster
members cannot produce proportionally stronger beliefs.
The sensory limitation creates a second scale dsensory =
kmax where detection saturates. The velocity bound gives
us a third scale dability = vmax /γC beyond which movement
speed cannot increase further.
Deriving the Attachment Kernel
T o understand how network structure emerges from indi-
vidual behaviour, we must connect an agent’s information
processing capabilities to its probability of joining clus -
ters of different sizes. This connection, which we call the
attachment kernel, provides the mechanistic link between
microscopic behaviour and macroscopic network structure.
From Detection to Belief Consider an agent encountering
a cluster of d agents. Each cluster member generates
detection events with probability p within the agent’s sensing
window τ. These independent detection events follow a
binomial distribution which, for clusters above a critical
size ( d ≳ 10), approaches a Gaussian by the central limit
theorem:
D ∼ N (αd, η 2) (13)
where α = p/τ represents the base detection rate and
η2 captures both intrinsic sensing noise and temporal
ﬂuctuations in the detection counts.
This detection statistic shapes the agent’s beliefs throug h
free energy minimisation. For large clusters where the
detection signal dominates ( αd ≫ η), we can substitute our
expression for D into Equation
7 to ﬁnd the posterior mean
belief about environmental gradients:
µb ≈ (α 2/σ 2
D)d
α 2/σ 2
D + 1/σ 2π
≈ Cd (14)
where
C = α 2σ2
π
α 2σ2π + σ2
D
(15)
represents the coupling between cluster size and belief
strength. This linear relationship between µb and d emerges
from: (i) the physics of neighbour detection, (ii) our Gauss ian
modelling assumptions, and (iii) the dominance of detectio n
signals for large clusters.
From Belief to Movement The agent’s belief about
environmental gradients drives movement through its
velocity control,
vintended = γµ b ∝ d (16)
where γ controls movement responsiveness. This creates a
behavioural pattern: agents move more quickly toward large r
clusters because stronger detection signals generate stro nger
beliefs about resource gradients in that direction.
From Movement to Attachment T o connect movement
with attachment probability, consider the time Tmove(d)
required for an agent to reach a cluster. This time depends
inversely on velocity,
Tmove(d) ≈ l
v ∝ 1
d (17)
where l represents a characteristic distance. The attachment
kernel P (attach | d), the probability that an agent success-
fully joins a cluster, should scale inversely with this conv er-
gence time,
P (attach | d) ∝ 1
Tmove(d) ∝ d. (18)
While our framework shares similarities with preferential
attachment in describing a “rich-get-richer” dynamic, it
is crucial to emphasize that it provides a mechanistic
foundation rooted in agent behavior and information
Prepared using sagej.cls
6 Journal Title XX(X)
processing, rather than positing preferential attachment as
an axiomatic rule. In our model, preferential attachment,
particularly the linear scaling regime, emerges as a
consequence of agents minimizing free energy under optimal
detection conditions. However, the key contribution of our
framework lies in explaining deviations from pure scale-
free behavior. The information processing constraints and
the resulting noise-dominated and saturation regimes are
what differentiate our approach from traditional preferen tial
attachment models, explaining the empirically observed
knee-shaped degree distributions as a modiﬁcation and
reﬁnement, rather than a complete break, from the scale-fre e
archetype.
Detection Time and Super-linearity The total time
to attach includes both detection and movement phases.
For a cluster of size d, the detection time scales as
Tdet (d) ∼ d−β/2 since signal-to-noise ratio improves as
√
d,
while movement time scales as Tmove(d) ∼ 1/d . The total
attachment time T (d) =Tdet (d) +Tmove(d) ∼ d−β/2 + 1/d
can thus decrease faster than 1/d when β ≥ 2, leading to
attachment probabilities P (attach | d) ∼ 1/T (d) that grow
super-linearly with d. This super-linear scaling emerges
from the compound effect of improved detection efﬁciency
and faster movement toward larger clusters, operating
most effectively in the intermediate regime between noise-
dominated detection and saturation.
This derivation reveals how in the absence of constraints
on the agent’s abilities, linear preferential attachment
emerges from biological information processing rather tha n
being imposed as an external rule. When agents follow free
energy minimisation principles, they generate the “rich ge t
richer” phenomenon: larger clusters create stronger detec tion
signals, leading to stronger gradient beliefs and faster
directed movement, producing attachment probabilities th at
scale linearly with cluster size.
This base linear scaling will be modiﬁed by the constraints
we identiﬁed earlier and the information processing
regimes we discuss next. However, understanding this core
mechanism, from detection through belief to movement and
ﬁnally attachment, provides the foundation for analysing
how network structure emerges from individual behaviour.
Characterising Information Processing Regimes
The FEP agent model identiﬁes three characteristic scales
arising from limitations:
dbelief ≈ bmax /C (prior belief constraint) (19)
dsensory = kmax (sensory limitation) (20)
dability = vmax /γC (velocity bound) . (21)
Using results from the previous section, these characteris tic
scales can be expressed in terms of the FEP model
parameters,
dbelief = bmax
C = σπ
α
(
1 + σ2
D
α 2σ2π
)
(22)
dsensory = kmax , (23)
dability = vmax
γC = vmax
γ
(
1 + σ2
D
α 2σ2π
)
, (24)
showing how these scales emerge from the interplay between
detection efﬁciency ( α ), measurement noise ( σD), prior
uncertainty ( σπ), and movement responsiveness ( γ). These
limitations deﬁne three distinct regimes:
Noise-Dominated: When d ≲ η/α , weak detection sig-
nals lead to high posterior uncertainty σ2
b . This uncer-
tainty drives exploratory behaviour through belief-depen dent
movement noise ηv ∼ N (0, σ 2
b ), causing agents to seek
better information to reduce their uncertainty.
Optimal Detection: For intermediate cluster sizes, the
three mechanisms
L(Obs | b) =N (αd + β, σ 2
D)
(linear detection scaling) , (25)
σ2
b =
( 1
σ2π
+ α 2
σ2
D
) −1
(improved precision), and (26)
v =γµ b + ηv, η v ∼ N (0, σ 2
b )
(accurate movement) (27)
compound. This creates a positive feedback loop, producing
super-linear growth in attachment probability.
Saturation: When d exceeds any of the limits
(dbelief , d sensory , d ability ), growth slows due to: sensory
saturation; inability to detect additional neighbours bey ond
kmax ; prior belief constraints; implausible gradients beyond
bmax ; and movement limitations; or velocities cannot exceed
vmax .
Degree Distribution Effects: These regimes create natural
preferred scales in the degree distribution. Information-
seeking in the noise-dominated regime reduces the number
of low-degree nodes compared to preferential attachment. A t
high degrees, the three limitations prevent indeﬁnite grow th,
reducing the number of high-degree nodes. These preferred
scales emerge from the information processing constraints
inherent in the FEP framework.
Network Structure Through the Lens of
Information Processing
The degree distribution that emerges from our free energy
minimising agents can be understood through how they can
process and act on information about their environment.
Three distinct information processing regimes create the
characteristic network structure we observe.
Information Sparsity In environments with small clusters,
agents face an information processing challenge. Their
detection statistics are dominated by noise, making it difﬁ cult
to form reliable beliefs about gradient direction. In this
regime, where αd ≲ η, agents must rely on their prior beliefs
to guide behaviour. These prior beliefs might encourage
more connections than pure preferential attachment would
predict, as agents seek to improve their ability to sense the ir
environment through increased connectivity. This explain s
why we observe fewer isolated nodes than the Barab ´ asi-
Albert model would suggest agents in information-poor
Prepared using sagej.cls
Williams and Chen 7
environments are driven to increase their degree beyond wha t
random chance would dictate.
Information Abundance As cluster sizes increase to
moderate levels, agents enter an information processing
“sweet spot. ” Here, the signal-to-noise ratio becomes
favourable, but clusters remain small enough that all senso ry
and cognitive mechanisms can operate effectively. In this
regime, agents can form strong, reliable beliefs about
environmental gradients and generate appropriate movemen t
responses. The enhanced certainty in this regime makes
such clusters attractive targets for attachment. This crea tes
a concentration of nodes around these optimal cluster sizes ,
forming the characteristic knee in the degree distribution .
This knee represents not just a mathematical feature but a
biological optimum where agents’ information processing
capabilities are best matched to their environment.
Information Saturation Finally, when clusters become
very large, agents enter a regime where they cannot process
all available information. Whether limited by sensory
capacity kmax , prior beliefs about plausible gradients bmax ,
or movement capabilities vmax , agents become unable to
respond proportionally to further increases in cluster siz e. In
this regime, the attachment probability grows more slowly
than cluster size, creating fewer highly connected nodes th an
pure preferential attachment would predict. This saturati on
reﬂects limitations in biological information processing
rather than a lack of information.
Emergence of Network Structure with Preferred Scales
These three information processing regimes: sparse, optim al,
and saturated, shape the network’s degree distribution. Th e
resulting structure shows fewer isolated nodes than pure
preferential attachment (as agents seek better informatio n),
a concentration of nodes around optimal cluster sizes (wher e
information processing works best), and fewer high-degree
nodes (where information processing saturates). This patt ern
emerges not from imposed rules but from principles of how
agents process and act on environmental information throug h
free energy minimisation.
Scale-Free Networks as Evidence of Different Informa-
tion Processing Dynamics The existence of true scale-free
networks provides an illuminating contrast to our framewor k.
When a network exhibits a pure power-law degree distribu-
tion, it tells us something fundamental about its nodes: the y
must operate outside the information processing constrain ts
(kmax , bmax, vmax ) that characterise biological agents. These
nodes somehow overcome the limitations that create satura-
tion effects in large clusters.
This observation suggests two mechanisms for the
emergence of scale-free structure. First, the nodes might
possess information processing capabilities that scale
with cluster size, pushing d∗ to arbitrarily large values.
Alternatively, the network’s growth might be driven by
factors independent of local information processing—for
instance, when attachment decisions rely on global rather
than local information, bypassing the constraints of direc t
neighbour detection and response.
Our framework thus reframes the distinction between
scale-free and biological networks in terms of information
processing. While biological networks emerge from agents
working within ﬁxed information processing constraints,
scale-free networks reﬂect dynamics that transcend these
limitations. This perspective suggests a testable predict ion:
if nodes in a biological network could enhance their
information processing capabilities—increasing kmax , bmax ,
and vmax —the resulting degree distribution should become
more scale-free as saturation effects diminish.
The Driving Power Law behaviour Underpinning
the Degree Distribution
The FEP framework predicts distinct attachment dynamics
in each information processing regime that drives the
formation of network structure. While analytical derivati on
of the complete degree distribution is intractable due to
the complex interplay between regimes, we can analyse
the driving attachment behaviour within each regime to
understand how they combine to shape network evolution.
While these driving behaviours do not manifest as observabl e
degree distributions, they shape how the network evolves
through their combined effects.
Noise-Dominated Regime: When detection noise dom-
inates ( αd ≲ η), agents cannot reliably sense cluster size,
leading to approximately random attachment behaviour
P (attach|k) ∼ const. (28)
This ﬂat scaling reﬂects agents exploring their environmen t
to gather better information rather than exhibiting strong size
preferences.
Optimal Detection Regime: In the intermediate regime
where information processing operates effectively, three
mechanisms compound to produce super-linear attachment
P (attach|k) ∼ kν , ν > 1 (29)
This super-linear scaling emerges from the linear increase in
detection signal strength with cluster size, improved beli ef
precision as more evidence accumulates, and more accurate
movement toward larger targets. The super-linearity reﬂec ts
how better detection enables more precise movement, which
facilitates more reliable detection - a positive feedback l oop
in information processing efﬁciency.
Saturated Regime: As cluster size approaches the lim-
itations ( kmax , bmax , vmax ), information processing saturates
at k⋆ = min(dbelief , d sensory , d ability ). From maximum entropy
principles, when a system has constrained resources, we
expect an exponential-like cutoff in attachment probabili ty
P (attach|k) ∼ e−k for k ≳ k⋆. (30)
Emergent Degree Distribution These three regimes of
attachment dynamics combine as agents encounter clusters
of different sizes. The observed degree distribution reﬂec ts
this continuous transition between regimes: from random
attachment at low degrees ( k0), through a congested
intermediate range where super-linear growth ( kν , ν > 1)
concentrates nodes that would otherwise remain at lower
degrees, to exponential suppression e−k at high degrees. This
progression produces the characteristic knee shape in the
degree distribution, deviating from pure scale-free behav iour
in ways that reveal the constraints on information processi ng
through the Free Energy Principle.
Prepared using sagej.cls
8 Journal Title XX(X)
Discussion
The analysis above provides a theoretical framework
that connects the Free Energy Principle (FEP) (
Friston
2010) to the emergence of network structures through
a process different from pure preferential attachment.
While preferential attachment has long been known
to generate power-law distributions in many systems
(
Barab ´ asi and Albert 1999 ; Newman 2003b ), our work
shows how biological information processing constraints
can lead to deviations from scale-free behaviour. By
demonstrating that network structures emerge from agents
minimising variational free energy, we offer an explanatio n
that links individual cognitive and perceptual processes t o
large-scale network topologies. This synthesis addresses
longstanding criticisms regarding the lack of mechanistic
foundations in network formation models (
Clauset et al.
2009), and bridges the gap between psychological or
cognitive principles and collective structural patterns
(
Anderson 2018 ).
Our derivation reveals how the gradients of free energy
drive agents toward information-rich regions through thre e
distinct regimes of information processing. In the noise-
dominated regime, agents seek better information, leading to
fewer isolated nodes than traditional preferential attach ment
would predict. In the optimal detection regime, a super-
linear growth mechanism emerges from the cascade
of improving detection statistics, belief precision, and
movement accuracy. This super-linearity, arising from fre e
energy minimisation rather than imposed rules, creates a
characteristic concentration of nodes around optimal clus ter
sizes. Finally, in the saturation regime, limitations in ag ents’
ability to process information prevent indeﬁnite cluster
growth, leading to fewer high-degree nodes than pure
preferential attachment would predict.
These ﬁndings align with empirical observations that real
networks often exhibit ﬁnite-size effects, exponential cu toffs,
and deviations from exact power laws (
Broido and Clauset
2019). Our framework shows these deviations are not
imperfections but signatures of how agents process and
act on environmental information. The characteristic “kne e-
shaped” degree distributions, where moderate-degree node s
are overrepresented relative to both low and high degrees,
emerge from the interplay between information seeking in
the sparse regime, super-linear growth in the optimal regim e,
and saturation at large scales.
Previous work has noted that information-based con-
straints may drive deviations from scale-free structure, p ar-
ticularly in biological and ﬁnancial networks. In neural sy s-
tems, network topology appears to reﬂect a trade-off betwee n
information transmission efﬁciency and the metabolic
costs of maintaining connections (
Lynn and Bassett 2020b ;
A vena-Koenigsberger et al. 2018 ). Similar patterns emerge
in ﬁnancial networks, where information processing capaci ty
constraints lead to characteristic deviations from pure po wer
laws ( Bardoscia et al. 2021 ). Studies of brain dynamics sug-
gest that local information processing limitations can hav e
substantial effects on global network structure ( Gollo et al.
2018). Our framework provides a novel perspective by show-
ing how these deviations can emerge from the process of free
energy minimisation, with no need to model communication
channels or metabolic constraints. The three information
processing regimes we identify—– noise-dominated, optima l
detection, and saturation—– provide a mechanistic explana -
tion for how individual cognitive constraints shape collec -
tive network structure, unifying observations across mult iple
domains through the lens of uncertainty minimisation.
Compared to existing explanations, many prior mod-
els rely on external constraints or additional parame-
ters. For instance, ﬁtness-based models endow nodes with
intrinsic attributes that modify attachment probabilitie s
(
Bianconi and Barab ´ asi 2001 ), while aging models reduce
the attractiveness of older nodes ( Dorogovtsev and Mendes
2002), and resource-limited models impose exogenous
capacities to induce truncation ( Amaral et al. 2000 ; Newman
2005). Although effective at reproducing empirical distri-
butions, these approaches often lack a direct link to the
internal, information-processing motivations of agents. Uur
FEP-based derivation places the origin of non-scale-free
degree distributions in principles of uncertainty minimis a-
tion, inference, and action selection.
This perspective helps reinterpret network structures
not simply as structural curiosities, but as emergent
consequences of cognition and perception operating under
uncertainty constraints. It aligns with the notion that
living systems exploit information for adaptive behaviour ,
connecting network organisation to questions about the
relationship between information and organisation in
biological systems (
England 2015 ). The identiﬁcation of
distinct information processing regimes suggests network
structure may serve as a signature of underlying cognitive
architectures, resonating with work suggesting that agent s
evolve to optimise their information processing capabilit ies
(
Friston 2013 ; Constant et al. 2018 ).
Our framework provides concrete, testable hypotheses
about how sensory noise η, detection efﬁciency α ,
and biological constraints d⋆ should inﬂuence network
formation. Empirical work could measure how changes
in these parameters affect network growth, potentially
testing these predictions in controlled biological or soci al
experiments. This offers a path toward bridging theory
and empiricism, moving beyond phenomenological ﬁts to
identify underlying principles that govern the formation
of complex networks. It also suggests that carefully
manipulating information processing parameters could
“engineer” desired network structures in artiﬁcial system s,
such as swarm robotics (
Hamann 2018 ) or distributed
computing ( Jelasity and Babaoglu 2007 ), particularly in
scenarios where optimal information processing is crucial .
Model Assumptions and Limitations
Our theoretical framework, while capturing key features of
network formation through free energy minimisation, relie s
on several key assumptions that warrant careful examinatio n.
The choice of Gaussian distributions for the prior π(b),
likelihood L(Obs | b), and recognition density Q(b) enables
analytical tractability but represents an idealisation of
real biological systems. While the central limit theorem
suggests that aggregated detection events may indeed
approach Gaussian distributions for large clusters, the tr ue
distributions, particularly in sparse networks or at small
scales, may exhibit signiﬁcant deviations from normality.
Prepared using sagej.cls
Williams and Chen 9
However, there is a robustness to the generalisable quality
to the constraints we identify: information sparsity at low
degrees, optimal processing at intermediate scales, and
saturation at high degrees emerge from basic principles of
uncertainty minimisation rather than speciﬁc distributio nal
choices. While Gaussian assumptions enable analytical
tractability, it is important to acknowledge that deviatio ns
from Gaussianity in real systems could inﬂuence quantitati ve
predictions, an area for future investigation.
The one-dimensional spatial model we employ represents
another important simpliﬁcation of real-world network
formation dynamics. While higher-dimensional spaces
would more accurately reﬂect the embedding of most natural
and social networks, the one-dimensional case captures
the essential features of gradient-following behaviour
under uncertainty. The key mechanisms we identify: the
relationship between cluster size and detection statistic s
D ∼ αd + η, the emergence of super-linear growth in the
optimal detection regime, and the existence of natural
saturation scales d⋆, generalise to higher dimensions, though
with modiﬁed scaling relationships. Indeed, the dimension al
reduction inherent in many real networks, where agents
often respond to scalar measures of connection quality or
social distance
Papadopoulos et al. (2012b), suggests that
our one-dimensional analysis may capture more of the
relevant physics than might at ﬁrst appear. Future work coul d
explore how the addition of spatial dimensions modiﬁes
the quantitative predictions while preserving the qualita tive
structure of our results.
Universal Features of Free Energy Networks
The three information processing regimes identiﬁed here,
noise-dominated, optimal detection, and saturation, can
emerge from the structure of free energy minimisation rathe r
than from the speciﬁc forms of our recognition density Q
or likelihood function L. This universality suggests that
similar behavioural patterns should appear whenever agent s
process information to guide actions under uncertainty,
regardless of the particular domain. While the mathematica l
details may vary, the core dynamics of seeking better
information in sparse environments, experiencing super-
linear beneﬁts in optimal regimes, and hitting processing
limits in dense regions appear to be general features of free
energy minimising systems.
This perspective offers new insights across diverse ﬁelds
where networked behaviour emerges from individual agents
processing and acting on information. In evolutionary
biology, the formation and size distribution of animal
groups has long puzzled researchers (
Couzin 2009 ).
Our framework suggests that observed patterns - from
bacterial colonies to ﬁsh schools to primate groups - may
reﬂect information processing constraints rather than jus t
environmental pressures. The tendency of many species to
maintain speciﬁc group sizes might represent an evolved
optimisation for the “sweet spot” regime, where social
information processing is most effective (
Sumpter 2010a ).
Similarly, the emergence of hierarchical structures in man y
animal societies could reﬂect natural solutions to informa tion
processing constraints as groups grow beyond the optimal
detection regime (
Flack 2012 ).
In economic networks, our framework offers a novel
perspective on classical questions of industrial organisa tion.
Coase’s ( Coase 1937 ) insight about transaction costs
determining ﬁrm boundaries might be reinterpreted through
the lens of information processing regimes. The observed
size distribution of ﬁrms, with its characteristic deviati ons
from power laws (
Axtell 2001 ), could reﬂect the interplay
between improved coordination in the optimal regime and
degraded information processing in the saturation regime.
This view also suggests new approaches to understanding
market structure evolution (
Jackson 2010 ) and the emergence
of supply chain networks ( Schweitzer et al. 2009 ), where
information processing constraints may shape network
topology as much as traditional economic factors.
Urban systems provide another domain where information
processing constraints appear to shape network formation.
The widely observed scaling laws in city growth and
structure (
Bettencourt 2013a ) might reﬂect transitions
between information processing regimes as cities grow .
The emergence of polycentric urban forms and the
limits to efﬁcient city size could be understood through
our framework’s prediction of saturation effects in large
networks. Transportation network design, too, might beneﬁ t
from considering how information processing constraints
affect human movement and interaction patterns (
Batty
2013).
In ecological networks, the framework offers insights into
species interaction patterns and ecosystem stability. The
observed structure of food webs and mutualistic networks,
which often deviate from pure scale-free topologies
(
Bascompte 2009 ), might reﬂect constraints on how agents
can process and respond to information about resource
availability and potential interactions. This perspectiv e could
help explain the emergence of modularity in ecological
networks (
Olesen et al. 2007 ) and provide new approaches
to understanding ecosystem resilience.
These applications highlight how the Free Energy Prin-
ciple can provide mechanistic explanations for widely
observed network phenomena. By focusing on the con-
straints of information processing rather than domain-
speciﬁc mechanisms, our framework offers a unifying per-
spective on network formation across scales and contexts.
This suggests that future research might beneﬁt from consid -
ering how information processing constraints shape networ k
evolution, potentially leading to more effective interven tions
in these various systems.
Empirical Support from Existing Studies
Our theoretical framework makes several key predictions
about network formation that ﬁnd substantial support in
empirical studies across multiple domains. The predicted
knee-shaped degree distribution has been well documented
in both biological and social networks. For instance,
Kossinets and W atts (2006) analysed a large-scale email
communication network ( n > 40, 000), ﬁnding degree
distributions that deviate from power-law behaviour in way s
that align with our predicted information processing regim es.
This knee-shape, with an overrepresentation of moderate-
degree nodes, directly aligns with our predicted outcome
of the optimal detection regime, where agents concentrate
connections around cluster sizes that best match their
Prepared using sagej.cls
10 Journal Title XX(X)
information processing capabilities. Similar patterns em erge
in protein interaction networks Jeong et al. (2003a), where
degree distributions show clear saturation effects at high
degrees.
The transitions between our predicted regimes ﬁnd
particular support in studies of collective animal behavio ur.
Sumpter (2010b)’s analysis reveals distinct phases in group
formation that parallel our theoretical predictions: an
initial noise-dominated phase where individuals seek grou p
membership, an optimal detection phase characterised by
rapid growth, and a saturation phase where group size
stabilises. Notably, many species maintain group sizes wit hin
speciﬁc ranges that may correspond to our predicted optimal
detection regime ( αd ≫ η but d ≪ d⋆), where information
processing effectiveness peaks.
Our framework provides mechanistic explanations for
well-documented social phenomena. Dunbar’s number
(
Dunbar 1992 , 2016a), the upper limit on stable social
relationships ( 150 individuals), aligns with our saturati on
regime predictions where information processing constrai nts
limit network growth. Beyond a certain network size,
information processing constraints, such as limited cogni tive
capacity, prevent further proportional growth in network
connectivity, resulting in a plateau and deviation from sca le-
free growth. The “six degrees of separation” phenomenon
(
Milgram 1967 ; W atts 1999 ) can be understood through our
optimal detection regime, where super-linear growth creat es
bridging connections between clusters, developing short
path lengths as nodes seek to maximise their information
processing capabilities.
This super-linear growth in the optimal detection regime
ﬁnds additional support in studies of scientiﬁc collaborat ion
networks
Newman (2003a) and urban scaling relationships
Bettencourt (2013b). These systems exhibit periods of
accelerated growth in connectivity that exceed linear
preferential attachment predictions before saturating. R ecent
studies of online social networks
Burke and Kraut (2016a)
further show that user engagement and relationship quality
follow patterns consistent with our predicted optimal
detection regime, before declining in ways that suggest
information processing saturation.
Our framework transforms qualitative insights into
precise, testable predictions through the mathematical ri gour
of the Free Energy Principle. While existing empirical
ﬁndings provide strong support, controlled experimental
tests remain an important direction for future research.
Particularly valuable would be experiments in artiﬁcial
networks where information processing constraints could
be varied while observing the resulting network formation
patterns.
Implications for Social Networks
Our results have implications for the design of social
networks, particularly for online platforms where users
routinely operate far beyond natural information process-
ing limits. The framework suggests that many of the
concerns associated with social media (
T wenge 2020 ;
Przybylski and W einstein 2017 ) may stem from forcing
users to function in the saturation regime ( d ≫ d⋆), where
their cognitive systems cannot process the volume of social
signals they receive. Modern platforms, with their continu -
ous feeds, frequent notiﬁcations, and follower counts in th e
thousands or millions, push users well beyond the “sweet
spot” where additional connections improve belief precisi on
(αd ≫ η but d ≪ d⋆). This aligns with recent ﬁndings show-
ing decreased quality of social relationships and increase d
anxiety with excessive social media use (
Hunt et al. 2018 ).
In this saturated state, more social connections no longer
enhance certainty about the social environment, poten-
tially explaining documented decreases in the quality of
online social interactions and decision-making (
Bakshy et al.
2015).
These insights suggest several concrete interventions
that could improve social network design. Platforms could
implement strict limits on the maximum number of
connections ( kmax ) that users can maintain, preventing
them from entering the saturation regime. While perhaps
controversial, such limits would align with known cognitiv e
constraints like Dunbar’s number (
Dunbar 2016b ) and
recent work on attention economics ( Wu 2016 ). More
subtle approaches might include “soft barriers” that keep
users operating in the optimal detection regime, similar to
successful interventions in digital well-being (
Lukoff et al.
2018). These could include capping daily interactions,
limiting feed sizes to processable chunks, or creating
natural breaking points in content consumption—strategie s
supported by research in cognitive load theory (
Sweller
2019) and information overload ( Jones et al. 2004 ).
The goal of such interventions would be to maintain
users in the super-linear growth regime, where information
processing is most effective. In this optimal zone,
social connections provide genuine improvements in
belief precision and action selection, possibly leading
to more meaningful and satisfying online interactions
(
Burke and Kraut 2016b ). This perspective suggests that
many apparent trade-offs between engagement and user
well-being may be false dichotomies – by aligning
platform design with basic principles of human information
processing, we might create social networks that are
both more engaging and more psychologically sustainable
(
Meier and Reinecke 2018 ). These insights suggest how
our theoretical framework can translate into practical
recommendations for improving the design of social
systems, bridging the gap between principles of biological
information processing and real-world applications in dig ital
social infrastructure (
Pennycook and Rand 2019 ).
Our framework generates testable predictions for social
network design. For instance, we predict that in online
environments characterized by higher sensory noise (e.g.,
overwhelming information ﬂow , algorithmic ﬁltering),
social networks will exhibit fewer isolated nodes than
predicted by pure preferential attachment, as users active ly
seek connections to reduce uncertainty. Conversely, in
environments designed to limit individual information
processing capacity (e.g., strict connection limits, atte ntion
management tools), we expect to observe fewer high-degree
hubs and a more pronounced saturation effect in the degree
distribution.
Prepared using sagej.cls
Williams and Chen 11
T owards Networks of AI Agents
Our theoretical framework offers insights for the emerging
ﬁeld of artiﬁcial agent networks, particularly as AI system s
transition from isolated reasoning engines to interconnec ted,
cooperative agents (
Dafoe et al. 2020 ). The identiﬁcation of
distinct information processing regimes suggests importa nt
design considerations for multi-agent AI systems. Just
as biological agents face constraints in processing social
information, artiﬁcial agents may encounter analogous
limitations in their ability to process and act on informati on
from their peers. Understanding these constraints could be
essential for creating stable and effective agent networks that
avoid the pitfalls observed in human social networks.
The super-linear growth regime identiﬁed in our model
has particular relevance for collaborative AI systems. Rec ent
work in multi-agent reinforcement learning has shown that
agent performance often scales non-linearly with the numbe r
of collaborative partners (
Baker et al. 2020 ), but saturates
or degrades with too many connections. Our framework
suggests this pattern may reﬂect information processing
constraints rather than mere implementation details. Just
as agents have an optimal detection regime where αd ≫ η
but d ≪ d⋆, artiﬁcial agents likely have an optimal zone of
collaboration where they can process and act on information
from their peers. This insight suggests that constraining
agent networks to operate within this regime might improve
collective performance and stability.
These principles could inform the design choices and
architecture of large-scale AI systems (
Battaglia et al. 2018 ).
Rather than allowing unrestricted connections between
agents, system designers might implement hierarchical
structures or connection limits that keep individual
agents operating in their optimal detection regime. Such
designs would mirror successful biological systems, where
information processing constraints have shaped network
topology through evolutionary processes (
Mitchell 2009 ).
Our framework suggests that the emergence of hub-and-
spoke architectures in artiﬁcial neural systems (
LeCun et al.
2015) might reﬂect not just computational efﬁciency but
principles of information processing under uncertainty.
As we move toward more complex systems of interacting
AI agents ( Shoham and Leyton-Brown 2008 ), understanding
these network formation dynamics becomes ever more
important. The principles identiﬁed here—– particularly t he
balance between information seeking in sparse regimes,
optimal processing in intermediate regimes, and saturatio n
in dense regimes—– could help prevent the emergence of
pathological network structures that might lead to cascadi ng
failures or undesirable emergent behaviours (
Russell 2019 ).
By considering information processing constraints in the
design of multi-agent systems, we might create more
robust and controllable artiﬁcial networks that maintain t heir
performance even as they scale to larger sizes.
In the context of multi-agent AI systems, our model
suggests that manipulating parameters related to informat ion
processing capacity, such as limiting the number of
detectable peers or introducing artiﬁcial “belief constra ints”
in AI agents, could be used to engineer desired network
structures. For example, reducing the information process ing
capacity of AI agents in collaborative tasks might,
counterintuitively, lead to more scale-free network struc tures
by mitigating saturation effects, allowing for the emergen ce
of larger hubs. Conversely, increasing sensory noise in the
agent’s environment is predicted to drive agents to form
denser, less hub-centric networks as they seek information
more broadly.
Conclusions
The analysis presented here suggests a connection between
the Free Energy Principle and the emergence of network
structures, through a process that both explains and
transcends traditional preferential attachment. W e have
shown that when agents act to minimise variational
free energy, they can generate network structures with
characteristics which can be attributed to preferential
attachment; but with systematic and meaningful deviations
that arise from information processing constraints. This
result bridges two separate theoretical frameworks: the
cognitive/biological framework of FEP (
Friston 2010 ) and
the network science framework of preferential attachment
(
Barab ´ asi and Albert 1999 ).
Our key theoretical results suggest that free energy
minimising agents exhibit three distinct regimes of networ k
formation. In the noise-dominated regime, where detection
statistics are weak compared to noise αd ≲ η, agents seek
better information, leading to fewer isolated nodes than
pure preferential attachment would predict. In the optimal
detection regime αd ≫ η but d ≪ d⋆, we have found
a super-linear growth mechanism that emerges from the
cascade of improving detection statistics, belief precisi on,
and movement accuracy. This creates a characteristic
concentration of nodes around optimal cluster sizes. Final ly,
in the saturation regime d ≳ d⋆, limitations in biological
information processing prevent indeﬁnite cluster growth,
leading to fewer high-degree nodes than pure preferential
attachment would predict. T ogether, these regimes explain
the observed knee-shaped degree distributions in real
networks as signatures of optimal information processing
under biological constraints.
Many open questions remain. Future research could
explore non-Gaussian noise models and richer observationa l
processes, or consider how multiple temporal and spatial
scales of inference interact to shape network growth. Exten d-
ing the theory to multiplex or multilayer networks could als o
yield new insights, as could exploring how environmental
non-stationarities alter the cognitive constraints and th us the
resulting degree distributions. More broadly, investigat ing
how additional external forces interact with FEP-driven
behaviour would clarify when and how exogenous factors
dominate over internal cognitive mechanisms.
The framework has relevant implications for understand-
ing complex systems across scales. Our results suggest that
deviations from pure scale-free structure in natural net-
works may be signatures of optimal information processing
under constraints, rather than imperfections or anomalies .
This perspective offers new approaches to analysing and
designing collective systems, from biological networks to
artiﬁcial swarms, by focusing on the information processin g
capabilities and limitations of their constituent agents.
The connection between FEP and network formation
points to a deeper principle: complex systems may organise
Prepared using sagej.cls
12 Journal Title XX(X)
themselves to optimise information processing across
scales. Wherever agents must process information to guide
behaviour, the interplay between noise, optimal detection ,
and saturation regimes may shape the resulting network
structures. This unifying perspective bridges individual
cognition and collective structure, suggesting new direct ions
for understanding emergence in complex systems.
Experimentally, our framework generates testable predic-
tions about how information processing constraints shape
network formation. Studies could measure the three key
parameters ( kmax , bmax , vmax ) in real systems and examine
how variations in these constraints affect resulting netwo rk
structure. Particularly valuable would be experiments wit h
artiﬁcial agent systems where information processing capa -
bilities could be varied.
Future work should focus on testing these theoretical
predictions in real systems and extending the framework to
more complex scenarios. The relationship between cognitiv e
parameters and network structure opens new avenues for
empirical research, while the theoretical framework provi des
tools for designing self-organising systems with desired
properties. Promising directions include applications to
social media design, artiﬁcial agent networks, and biologi cal
collective behaviour.
In conclusion, this synthesis between FEP and network
formation not only provides a mechanistic explanation for
network structure but also suggests underlying principles
governing the organisation of complex adaptive systems. By
grounding network formation in the principles of uncertain ty
minimisation and information processing, we establish a
theoretical foundation for understanding how cognitive
constraints shape collective structure, with implication s
ranging from biological organisation to artiﬁcial system
design.
Appendix: Closed Form Solutions for The
Free Energy
W e show here how the free energy in Equation
1 admits an
explicit closed-form when all distributions are chosen to b e
Gaussian. Recall that our model is deﬁned as
π(b) =N
(
b; µπ, σ 2
π
)
, (31)
L
(
Obs | b
)
= N
(
D; µD(b), σ 2
D
)
, (32)
µD(b) =α b + β, (33)
Q(b) =N
(
b; µb, σ 2
b
)
. (34)
The free energy
F
[
Q(b)
]
=
∫
Q(b) lnQ(b)
π(b) db
−
∫
Q(b) lnL
(
Obs | b
)
db, (35)
splits into two integrals that can be computed separately.
The ﬁrst integral is the Kullback–Leibler (KL) divergence
between two Gaussians which has a known form. For
N (b; µb, σ 2
b ) and N (b; µπ, σ 2
π) this is
KL
[
Q∥π
]
= 1
2
[
ln σ2
π
σ2
b
+ σ2
b + (µb − µπ)2
σ2π
− 1
]
. (36)
The second integral is the expected log-likelihood.
−EQ
[
ln L
]
= −
∫
Q(b) lnN
(
D; µD(b), σ 2
D
)
db (37)
Because the natural log term in the integral has a quadratic
dependence on µD(b) =αb + β, we can write
− ln N
(
D; µD(b), σ 2
D
)
=
(
D − µD(b)
) 2
2σ2
D
+ const. (38)
When Q(b) =N (b; µb, σ 2
b ), this can be computed with a
standard moment calculation.
Thus the combined expression for F is
F
[
Q(b)
]
= 1
2
[
ln σ2
π
σ2
b
+ σ2
b + (µb − µπ)2
σ2π
− 1
]
  
KL[ Q∥π ]
+ (D − β)2 − 2α (D − β)µb + α 2(
µ2
b + σ2
b
)
2σ2
D  
−EQ
[
ln L
]
+ const. (39)
This is the full variational free energy under Gaussian prio r,
likelihood, and posterior. The notation “const.” hides ter ms
that do not depend on µb. Minimising F with respect
to µb yields update rules that balance prior alignment
against ﬁtting the observed detection statistic D, under the
assumption that σb is held constant.
T o see how the agent updates its posterior mean µb, we
focus on the partial derivative ∂F/∂µ b. W e start from the
closed-form expression for F [Q(b)
]
, Equation 39, but note
that σ2
b must also be treated as a parameter to be optimised.
For simplicity here, we only derive ∂F
∂µb
and keep σ2
b ﬁxed;
the joint update for σ2
b could be derived similarly if required.
Differentiating Equation 39 with respect to µB gives
∂F
∂µ b
= µb − µπ
σ2π
+ − α (D − β) +α 2 µb
σ2
D
. (40)
Setting ∂F/∂µ b = 0and solving for µb yields the posterior
mean that locally minimises F . That closed-form solution is
µb = (α/σ 2
D) (D − β) + µπ/σ 2
π
α 2/σ 2
D + 1/σ 2π
. (41)
if σ2
b is held ﬁxed.
Acknowledgements
This research was carried out at Rinna K.K., T okyo, Japan.
References
Amaral LAN, Scala A, Barth´ el´ emy M and Stanley HE (2000)
Classes of small-world networks. Proceedings of the National
Academy of Sciences 97(21): 11149–11152.
Prepared using sagej.cls
Williams and Chen 13
Anderson PW (2018) More is different. Science 177: 393–396.
A vena-Koenigsberger A, Miˇ si´ c B and Sporns O (2018) Commun i-
cation dynamics in complex brain networks. Nature Reviews
Neuroscience 19(1): 17–33.
Axtell RL (2001) Zipf distribution of u.s. ﬁrm sizes. Science
293(5536): 1818–1820.
Baker B, Kanitscheider I, Markov T , Wu Y , Powell G, McGrew
B and Mordatch I (2020) Emergent tool use from multi-
agent autocurricula. International Conference on Learning
Representations .
Bakshy E, Messing S and Adamic LA (2015) Exposure to
ideologically diverse news and opinion on facebook. Science
348(6239): 1130–1132.
Barab´ asi AL (2016) Network Science . Cambridge: Cambridge
University Press.
Barab´ asi AL and Albert R (1999) Emergence of scaling in rand om
networks. Science 286: 509–512.
Bardoscia M, Caccioli F , Perotti JI, Vivaldo G and Caldarell i G
(2021) The physics of ﬁnancial networks. Nature Reviews
Physics 3(7): 490–507.
Bascompte J (2009) Disentangling the web of life. Science
325(5939): 416–419.
Battaglia PW et al. (2018) Relational inductive biases, dee p learn-
ing, and graph networks. arXiv preprint arXiv:1806.01261 .
Batty M (2013) The New Science of Cities . MIT Press.
Bettencourt LMA (2013a) The origins of scaling in cities. Science
340(6139): 1438–1441.
Bettencourt LMA (2013b) The origins of scaling in cities. Science
340(6139): 1438–1441.
Bianconi G and Barab´ asi AL (2001) Competition and multisca ling
in evolving networks. Europhysics Letters 54: 436–442.
Broido AD and Clauset A (2019) Scale-free networks are rare.
Nature Communications 10: 1017.
Burke M and Kraut RE (2016a) The relationship between facebo ok
use and well-being depends on communication type and tie
strength. Journal of Computer-Mediated Communication
21(4): 265–281.
Burke M and Kraut RE (2016b) The relationship between facebo ok
use and well-being depends on communication type and tie
strength. Journal of Computer-Mediated Communication
21(4): 265–281.
Clauset A, Shalizi CR and Newman MEJ (2009) Power-law
distributions in empirical data. SIAM Review 51: 661–703.
Coase RH (1937) The nature of the ﬁrm. Economica 4: 386–405.
Colombo M and Wright C (2018) First principles in the
life sciences: the free-energy principle, organicism, and
mechanism. Synthese 196: 5245–5267.
Constant A, Ramstead MJD, V eissi` ere SPL, Campbell JO and
Friston KJ (2018) A variational approach to niche construct ion.
Journal of the Royal Society Interface 15: 20170685.
Couzin ID (2009) Collective cognition in animal groups. Trends in
Cognitive Sciences 13(2): 36–43.
Dafoe A, Hughes E, Bachrach Y , Collins T , McKee KR, Leibo JZ,
Larson K and Graepel T (2020) Open problems in cooperative
AI. arXiv preprint arXiv:2012.08630 .
Dorogovtsev SN and Mendes JFF (2002) Evolution of networks.
Advances in Physics 51(4): 1079–1187.
Dunbar R (2016a) Human Evolution: Our Brains and Behavior .
Oxford University Press.
Dunbar R (2016b) Human Evolution: Our Brains and Behavior .
Oxford University Press.
Dunbar RIM (1992) Neocortex size as a constraint on group siz e in
primates. Journal of Human Evolution 22(6): 469–493.
England JL (2015) Dissipative adaptation in driven self-as sembly .
Nature Nanotechnology 10: 919–923.
Flack JC (2012) Multiple time-scales and the developmental
dynamics of social systems. Philosophical Transactions of the
Royal Society B 367(1597): 1802–1810.
Friston K (2010) The free-energy principle: a uniﬁed brain t heory?
Nature Reviews Neuroscience 11: 127–138.
Friston K (2013) Life as we know it. Journal of the Royal Society
Interface 10: 20130475.
Friston K, FitzGerald T , Rigoli F , Schwartenbeck P and Pezzu lo
G (2017) Active inference: A process theory . Neural
Computation 29: 1–49.
Gollo LL, Roberts JA and Cocchi L (2018) Mapping how
local perturbations inﬂuence systems-level brain dynamic s.
NeuroImage 160: 97–112.
Hamann H (2018) Swarm robotics: A formal approach. Springer
International Publishing .
Hunt MG, Marx R, Lipson C and Y oung J (2018) No more fomo:
Limiting social media decreases loneliness and depression .
Journal of Social and Clinical Psychology 37(10): 751–768.
Jackson MO (2010) Social and Economic Networks . Princeton
University Press.
Jelasity M and Babaoglu O (2007) T -man: Gossip-based overla y
topology management. Engineering Self-Organising Systems
3910: 1–15.
Jeong H, Mason S, Barab´ asi AL and Oltvai Z (2003a) Lethality and
centrality in protein networks. Nature 411: 41–42.
Jeong H, Mason SP , Barab´ asi AL and Oltvai ZN (2003b) Lethali ty
and centrality in protein networks. Nature 411: 41–42.
Jones Q, Ravid G and Rafaeli S (2004) Information overload an d the
message dynamics of online interaction spaces. Information
Systems Research 15(2): 194–210.
Kirchhoff M, Parr T , Palacios E, Friston K and Kiverstein J (2 018)
The markov blankets of life: autonomy , active inference and the
free energy principle. Journal of the Royal Society Interface 15:
20170792.
Kossinets G and W atts DJ (2006) Empirical analysis of an evol ving
social network. Science 311(5757): 88–90.
LeCun Y , Bengio Y and Hinton G (2015) Deep learning. Nature
521(7553): 436–444.
Lukoff K, Y u C, Kientz J and Hiniker A (2018) What makes
smartphone use meaningful or meaningless? Proceedings of
the ACM on Interactive, Mobile, W earable and Ubiquitous
T echnologies 2(1): 1–26.
Lynn CW and Bassett DS (2020a) The physics of brain network
structure, function and control. Nature Reviews Physics 1: 318–
332.
Lynn CW and Bassett DS (2020b) The physics of brain network
structure, function and control. Nature Physics 16(9): 965–976.
Medo M, Cimini G and Gualdi S (2011) T emporal effects in the
growth of networks. Physical Review Letters 107: 238701.
Meier A and Reinecke L (2018) Computer-mediated communi-
cation, social media, and mental health: A conceptual and
empirical meta-review . Communication Research 45(8): 1182–
1209.
Prepared using sagej.cls
14 Journal Title XX(X)
Milgram S (1967) The small-world problem. Psychology T oday
1(1): 61–67.
Mitchell M (2009) Complexity: A Guided T our . Oxford University
Press.
Newman ME (2003a) The structure and function of complex
networks. SIAM Review 45(2): 167–256.
Newman MEJ (2003b) The structure and function of complex
networks. SIAM Review 45: 167–256.
Newman MEJ (2005) Power laws, pareto distributions and zipf ’s
law . Contemporary Physics 46: 323–351.
Newman MEJ (2018) Networks. Oxford University Press.
Olesen JM, Bascompte J, Dupont YL and Jordano P (2007)
The modularity of pollination networks. Proceedings of the
National Academy of Sciences 104(50): 19891–19896.
Papadopoulos F , Kitsak M, Serrano MA, Bogu ˜ n´ a M and Kriouko v
D (2012a) Popularity versus similarity in growing networks .
Nature 489: 537–540.
Papadopoulos F , Kitsak M, Serrano M ´A, Bogu ˜ n´ a M and Krioukov
D (2012b) Popularity versus similarity in growing networks .
Nature 489(7417): 537–540.
Parr T , Da Costa L and Friston K (2020) Markov blankets, infor ma-
tion geometry and stochastic thermodynamics. Philosophical
Transactions of the Royal Society A 378: 20190159.
Pennycook G and Rand DG (2019) Fighting misinformation on
social media using crowdsourced judgments of news source
quality . Proceedings of the National Academy of Sciences
116(7): 2521–2526.
Przybylski AK and W einstein N (2017) A large-scale test of
the goldilocks hypothesis: Quantifying the relations betw een
digital-screen use and the mental well-being of adolescent s.
Psychological Science 28(2): 204–215.
Ramstead MJD, Badcock PB and Friston KJ (2018) Answering
schr ¨ odinger’s question: A free-energy formulation. Physics of
Life Reviews 24: 1–16.
Russell S (2019) Human Compatible: Artiﬁcial Intelligence and the
Problem of Control . Viking.
Schweitzer F , Fagiolo G, Sornette D, V ega-Redondo F , V espig nani
A and White DR (2009) Economic networks: The new
challenges. Science 325(5939): 422–425.
Shoham Y and Leyton-Brown K (2008) Multiagent systems: Algo -
rithmic, game-theoretic, and logical foundations. Cambridge
University Press .
Sumpter DJT (2010a) Collective animal behavior. Princeton
University Press .
Sumpter DJT (2010b) Collective animal behavior. Princeton
University Press .
Sweller J (2019) Cognitive load theory and educational tech nology .
Educational T echnology Research and Development 67: 1–16.
T wenge JM (2020) Why increases in adolescent depression may be
linked to the technological environment. Current Opinion in
Psychology 32: 89–94.
V er Steeg G (2019) Entropy and information in neural network s.
Physical Review Letters 123: 178301.
W atts DJ (1999) Small W orlds: The Dynamics of Networks between
Order and Randomness . Princeton University Press.
Wu T (2016) The Attention Merchants: The Epic Scramble to Get
Inside Our Heads . Knopf.
Prepared using sagej.cls