Towards Stochastic Fault-tolerant Control using
Precision Learning and Active Inference
Mohamed Baioumy1, Corrado Pezzato2, Carlos Hern´ andez Corbato2, Nick
Hawes1, and Riccardo Ferrari3
1 Oxford Robotics Institute, University of Oxford
{mohamed, nickh}@robots.ox.ac.uk
2 Cognitive Robotics, Delft University of Technology
3 Delft Center for Systems and Control, Delft University of Technology
{c.pezzato, c.h.corbato, r.ferrari, m.wisse}@tudelft.nl
Abstract. This work presents a fault-tolerant control scheme for sen-
sory faults in robotic manipulators based on active inference. In the ma-
jority of existing schemes a binary decision of whether a sensor is healthy
(functional) or faulty is made based on measured data. The decision
boundary is called a threshold and it is usually deterministic. Following
a faulty decision, fault recovery is obtained by excluding the malfunc-
tioning sensor. We propose a stochastic fault-tolerant scheme based on
active inference and precision learning which does not require a priori
threshold deﬁnitions to trigger fault recovery. Instead, the sensor preci-
sion, which represents its health status, is learned online in a model-free
way allowing the system to gradually, and not abruptly exclude a failing
unit. Experiments on a robotic manipulator show promising results and
directions for future work are discussed.
1 Introduction
Safety is paramount for autonomous systems designed for operating in
the real world. External dangers in the environment such as steep and
slippery terrain encountered by planetary rovers [15] can compromise
entire missions. In addition to external dangers, internal system compo-
nents can also fail and possibly lead to dangerous outcomes if a proper
fault-tolerant (FT) control scheme is not present. Building systems that
are robust to the presence of faulty components, such as sensors and ac-
tuators, is addressed in the FT literature [24,32,8]. Generally speaking,
FT control consists of fault detection, which provides a signal represent-
ing whether a system component is faulty;fault isolation, which identiﬁes
the exact faulty component, and fault recovery, which typically contains
a switching or a re-tuning procedure of the running controllers to accom-
modate for the fault.
Several methods are available for fault detection, but model-based meth-
ods are among the most powerful and appealing, as they provide theo-
retical guarantees [8]. These methods rely on monitoring system outputs
using mathematical models to generate ‘symptoms’ called residual sig-
nals. These signals are then compared to carefully designed detection
arXiv:2109.05870v1  [cs.RO]  13 Sep 2021
2 M. Baioumy et al.
thresholds: the sensor is ‘faulty’ if a threshold is exceeded or ‘healthy’
otherwise. To recover from a fault, the recovery actions are usually per-
formed through controller reconﬁguration, that entails adapting the con-
troller parameters, or switching to another controller or to backup sen-
sors and actuators [22]. When modelling external dangers or monitoring
faulty systems, robust detection thresholds are essential. Robust thresh-
olds used in existing work (such as [7] or [32]) are often deterministic,
but this is sub-optimal. For instance, if the safety threshold for a rover
on a slippery terrain slope is 15 degrees, this means that a slope of 14.9
is safe but 15.1 is unsafe. Additionally, a slope of 15.1 degrees and 40
degrees are ‘equally unsafe’.
In this paper we build upon two ideas in the literature. First, the usage of
a stochastic fault tolerant formulation (e.g. [9,30]). This allows the agent
to overcome the issues mentioned above. Additionally, we leverage an
unbiased active inference controller (u-AIC) [3], evolved from previous
active inference controllers (AIC) [6,1,25]. Active inference is a promising
framework for FT control which has already been shown to facilitate
fault-detection, isolation and recovery for robotic systems with sensory
faults [3,26].
Besides fault tolerance, active inference showed promising performance
in many control and state-estimation problems in robotics [16,17]. Par-
ticularly interesting are the works on robot arm control [25,23,29], which
highlighted the adaptive properties of active inference. Active inference
also shares similarities with the control as inference framework [18]. A
more extensive analysis of active inference and its relation to control as
inference can be found in [20,14].
The main contribution of this paper is a FT controller for robot ma-
nipulators with sensory faults based on unbiased active inference with
a stochastic decision boundary. Unlike previous work [3], here we model
the precision (inverse covariance) of each sensor in our system and de-
termine the probability of the sensor being healthy to be proportional to
its precision. Our approach allows for fault-tolerant behaviour without
needing any threshold deﬁnition a priori, and without the need to design
additional ad-hoc recovery mechanisms. Finally, this work can be used
stand-alone or in conjunction with other methods for fault-detection and
isolation in order to estimate the faults.
2 Problem statement and background
The FT scheme in this paper is derived for a class of systems, namely
serial robot manipulators equipped with sensors for joint position and
velocity, and end-eﬀector location. In the following, the problem and
the setup are described, and some background knowledge on u-AIC for
torque control from [3] is presented.
Problem Setup. Consider a robotic manipulator with state xcom-
prising of its joint positions and velocities x = [ q ˙q]⊤. The available
sensors provide noisy joint position and velocities yq, y˙q readings. In ad-
dition, the end-eﬀector Cartesian positionyv is available through a visual
Towards Stochastic FT Control. 3
sensor. The system’s output is represented by y = [yq, y˙q, yv] ∈Rd.
The proprioceptive sensors and the visual sensor are aﬀected by zero
mean Gaussian noise η= [ηq, η˙q, ηv]. Additionally, the visual sensor is
aﬀected by barrel distortion. The system is controlled through an u-AIC
[3] which steers the robot arm to a (changing) desired conﬁguration in
joint space µd, providing the control input u ∈Rm as torques to the
joints.
Background: Unbiased Active Inference controllerIn this
section we brieﬂy describe the u-AIC as introduced in [3], to which an
interested reader is referred for more details on the derivations of the
following equations. The novel FT method presented in this paper in
Sec. 3 builds upon the u-AIC, but instead of employing an ad-hoc hard
update of the precision of a faulty sensor after fault detection, it relies
on online precision learning during operations.
Let us consider x= [q ˙q]⊤and let us deﬁne a probabilistic model where
actions are modelled explicitly:
p(x,u,yv,yq,y˙q) = p(u|x)  
control
p(yv|x)p(yq|x)p(y˙q|x)  
observation model
p(x)
prior
(1)
Note that with the u-AIC the information about the desired goal to be
reached is encoded in the distribution p(u|x). In this paper, as in [1], we
assume that an accurate dynamic model of the system is not available
to keep the solution system agnostic and to highlight once again the
adaptability of the controller.
The u-AIC aims at ﬁnding the posterior over states as well as the poste-
rior over actions p(x,u|yv,yq). The posteriors are approximated using
a variational distribution Q(x,u). We can make use of the mean-ﬁeld
assumption (Q(x,u) = Q(x)Q(u)) and the Laplace approximation, and
assume the posterior over the state xGaussian with mean µx [13]. Sim-
ilarly for the actions, the posterior u is assumed Gaussian with mean
µu. By deﬁning the Kullback-Leibler divergence between the variational
distribution and the true posterior, one can derive an expression for the
so-called free-energy F as [3]:
F = −ln p(µu,µx,yv,yq,y˙q) + C (2)
Considering eq. (1) and assuming Gaussian distributions, F becomes:
F = 1
2(ε⊤
yq Σ−1
yq εyq + ε⊤
y˙q Σ−1
y˙q εy˙q + ε⊤
yv Σ−1
yv εyv
+ ε⊤
xΣ−1
x εx + ε⊤
uΣ−1
u εu + ln|ΣuΣyq Σy˙q Σyv Σx|) + C,
(3)
The terms εyq = yq−µ, εy˙q = y˙q−µ′, εyv = yv−gv(µ) are the sensory
prediction errors respectively for position, velocity, and visual sensory
inputs. The controller represents the states internally as µx = [µ, µ′]⊤.
The relation between internal state and observation is expressed through
the generative model of the sensory input g= [gq, g˙q, gv]. Position and
velocity encoders directly measure the state, thus gq and g˙q are linear
(identity) mappings. To deﬁne gv, instead, we use a Gaussian Process
4 M. Baioumy et al.
Regression (GPR). This is particularly useful because we can model the
noisy and distorted sensory input from the camera, and at the same
time we can compute a closed form for the derivative of the process with
respect to the beliefs µ, required for the state update laws. For details,
see [3].
Additionally, εu is the prediction error on the control action while εx
is the prediction error on the state. The latter is computed considering
a prediction of the state ˆx at the current time-step such that εx =
(µx −ˆx). The prediction is a deterministic value ˆx= [ˆq ˆ˙q]⊤ which can
be computed in the same fashion as the prediction step of, for instance,
a Kalman ﬁlter. The prediction is approximated propagating forward in
time the current state belief using the following simpliﬁed discrete time
model:
ˆxk+1 =
[I I∆t
0 I
]
µx,k (4)
where I represents an unitary matrix of suitable size. This form assumes
that the position of each joint is thus computed as the discrete time inte-
gral of the velocity, using a ﬁrst-order Euler scheme. This approximation
can be avoided if a better dynamic model of the system is available, and
in that case predictions can be made using the model itself. Finally, by
choosing the distribution p(u|x) to be Gaussian with mean f∗(µx,µd),
we can steer the systems toward the target µd without biasing the state
estimation. This results in εu = (µu −f∗(µx,µd)).
In the u-AIC state-estimation and control are achieved using gradient
descent the free-energy. This leads to:
˙µu = −κu
∂F
∂µu
, ˙µx = −κµ
∂F
∂µx
, (5)
where κu and κµ are the gradient descent step sizes.
3 Precision Learning for fault-tolerant control
In previous work [3], the u-AIC is used in combination with an estab-
lished FT approach to achieve fault detection and recovery. In particular,
the sensory prediction errors in the free-energy are used as residual sig-
nals for fault detection purposes. The statistical properties of the residu-
als are analysed oﬄine and healthy boundaries are deﬁned. At runtime,
a healthy residual set is computed and if the current residual is out-
side the admissible set, the relative sensor is marked as faulty. When a
fault is detected, the precision (or inverse covariance) of the sensor is
abruptly set to zero, that is P = Σ−1 = 0, to exclude that sensor from
the optimization of the free-energy. This idea is summarised in Fig. 1.
In this work, we propose a diﬀerent approach to achieve fault recov-
ery through online precision learning with u-AIC instead ad-hoc hard
switches in the controller’s parameters. Fig. 2 shows thee diﬀerence with
respect to [3].
Towards Stochastic FT Control. 5
Fig. 1.Fault-tolerant pipeline from [3]. The term Σ−1
f represents the precision of the
detected faulty sensor.
Fig. 2.New fault-tolerant pipeline with precision learning, in contrast to previous work
[3] from Fig. 1.
Learning sensory precision. For a sensor y, we can update an
inverse precision matrix Σ−1
y using gradient descent on F as done in
[2,1]:
˙Σ−1
y = −κσ
∂F
∂Σ−1
y
. (6)
However, we need to ensure that precision remains a positive number.
Performing gradient descent does not inherently guarantee that.
First, consider a one-dimensional problem where state xand observation
y are scalars. The observations is aﬀected by zero-mean Gaussian noise
with a variance of σ2 (also a scalar). The scalar precision is deﬁned as
the inverse varianceω= 1/σ2. As explained, performing gradient descent
on the free-energy with respect to ω may result in it being negative. A
simple solution is to perform a reparameterization with a strictly positive
function such as an exponential. I.e. we assume that ω = exp ζ and we
perform gradient descent on ζ:
˙ζ = −κζ
∂F
∂ζ (7)
where κζ is the gradient step-size. Another way is to set a lower bound
on the variance (as done in [5]). Both methods ensure the variance being
positive.
Diagonal precision matrix.
Guaranteeing a positive semi-deﬁnite matrix in an n-dimensional case is
not as straightforward. However, in the context of a robotic manipulator,
one can reasonably assume that the observation noise on each sensor is
6 M. Baioumy et al.
independent [23,25,1]. This means that the covariance (and precision)
matrices are diagonal.
P =


ω1
ω2
...
ωn


Given this assumption, every element on the diagonal is positive and can
be updated in the same fashion as the scalar case (Eq. (7)).
Fault-tolerant control as precision learning.Consider the sum
of the sensory prediction errors in the free-energy from eq. (3):
F = 1
2(ε⊤
yq Σ−1
yq εyq + ε⊤
y˙q Σ−1
y˙q εy˙q + ε⊤
yv Σ−1
yv εyv + ...) + C, (8)
Intuitively, when a sensor is faulty, the related sensory prediction error
will necessarily be higher since sensory readings and internal beliefs will
drift away. After a fault, the estimated precision through our precision
learning scheme will be much lower than the original P = Σ−1. Thus
its weight in the free-energy F, and so in the state-estimation and con-
trol equations as in eq. (5) will naturally become lower than the other
healthy sensors. Its weight essentially adjustsproportionally to the degree
of the sensor being faulty. Note that this allows for automatic fault re-
covery but it does not provide explicit fault detection. In case the latter
is needed for a potential user or an additional supervisory system, tradi-
tional techniques can be used as the one presented in [3] in conjunction
with precision learning.
FT control for sensory faults can now be done using precision learning
in several ways. The ﬁrst way is to use it as a stand-alone and acti-
vate precision learning for all sensors during operation. In this case, no
other methods are needed, no thresholds are designed and the recovery
emerges naturally. As mentioned before, the drawback is that the users
can not be ‘alerted’ for the presence of a fault (since there is no explicit
fault-detection). The second way, which addresses this issue, is to use an
established algorithm for fault detection (such as the one presented in
[3]) and then, only after a fault is detected, allow precision update.
Interestingly, performing precision learning as presented in this section
can make the state-estimation noisier since the agents only relies on
the current observation (rather than a batch of last k observations) for
the update and both the uncertainty of the state and precision are not
quantiﬁed. An additional approach would then be to consider the last k
observations for the update, but this is out of the scope of this work.
To summarise, the precision learning in this paper can either be activated
at all times or only after a fault is detected. Activating the precision
learning at all times with a small step-size for the gradient seems to
work best.
Towards Stochastic FT Control. 7
4 Results
We apply the methods in Sec. 3 on a 2-DOF robotic manipulator. We test
three scenarios: a) precision learning at all times, b) precision learning
only when a fault is detected and c) a deterministic update as done in [3].
Note that the latter has access to a model and uses data to determine a
threshold oﬄine. This is not the case for the ﬁrst two options where only
model-free precision learning is performed. The results are summarized in
the Table 1. In the simulations, the sensors are injected with zero-mean
Joints with
encoder fault
Joints without
encoder fault
No fault-tolerance 0.0036 0.0020
PL at all time 5.422 e-5 4.527 e-5
PL + fault-detection 6.097 e-5 4.134 e-5
Deterministic fault recovery 0.5946 e-5 0.3579 e-5
Table 1.Mean Squared Error (MSE) for diﬀerent methods of fault-tolerant control.
PL indicates precision learning
Gaussian noise. The standard deviation of the noise for encoders and
velocity sensors is set to σq = σ˙q = 0.001, while the one for the camera
is set to σv = 0.01. The camera is also aﬀected by barrel distortion with
coeﬃcients K1 = −1.5e−3, K2 = 5e−6, K3 = 0 (values are similar to
work from [19,28]).
The agents starts in conﬁguration x0, then moves to the targets x1 and
x2. At t = 8 s a fault is injected. The encoder fault is such that the
output related to the ﬁrst joint freezes. For a discrete stepkit holds then
yq(k) = [q1(kf), q2(k)]⊤for k≥kf and kf = 8. The fault detection and
recovery of such a fault, as well as the system’s response, are reported
below in Fig. 3.
As seen in Fig. 3, the system is not able to reach the set-point after
the occurrence of the fault if online precision update is not allowed. The
robot arm reaches a diﬀerent conﬁguration to minimise the free-energy,
which is built fusing the sensory information from the (faulty) encoders
and the (healthy) camera. However, when the faulty encoder is adjusted
using precision learning, the agent is able to reach the ﬁnal conﬁguration.
Fig. 3 reports the results when precision learning is being done during the
full operational time. Alternatively, one could only use precision leaning
when a fault is detected. This yields a response that is almost identical.
The Mean Squared Error (MSE) between the belief and the true position
(µx−x) is computed on a sample of test runs and reported in the Table 1.
The results are reported for both the joint whose encoder is faulty, and
joints with healthy encoders. In both cases, hard update of the precision
to zero has the lowest MSE; however, the approaches based on precision
learning do not require any previous information or a threshold deﬁnition
thus it is simpler to implement. Yet, precision learning has a satisfactory
performance while accommodating a sensory fault.
8 M. Baioumy et al.
Fig. 3.System’s response in the case of encoder fault with and without precision
learning applied at all times. The fault is injected at t = 8 s and indicated with a
dot-dashed line.
5 Improving precision learning: a discussion
In this paper, we perform a simple modiﬁcation to the unbiased active
inference controller: adding precision learning for all sensors. We show
that this results in stochastic fault-tolerance to sensory faults, i.e. the
precision of a faulty sensor will decrease automatically making its rela-
tive weight in the control and estimation laws smaller. This eliminates
the need to learn a threshold from data oﬄine. Additionally, no ah-hoc
recovery action is required. The controller automatically adjusts to the
new precision.
In the experiments, we compared precision learning to a state-of-the-art
method. Precision learning was an order of magnitude worse in perfor-
mance but still satisfactory. Note that precision learning did not require
any data or training oﬄine to determine thresholds or recovery strate-
gies. Finally, precision learning performs stochastic fault-detection rather
than deterministic.
Most importantly, this approach based on precision learning can be im-
proved in many ways. First, rather than computing a point-mass esti-
mate, we can explicitly model the precision as a random variable and
perform inference on it.
We can perform Bayesian inference by modelling the precision as a ran-
dom variable and computing a posterior over it. In the one dimensional
case we use a Gamma prior on the precision ω as
Γ(ω; a,b) = ba
Γ(a)ωa−1e−ωb.
Given that the observation model is Gaussian, this choice is beneﬁcial
since it is the conjugate prior [4,21], where aand bare the parameters of
Towards Stochastic FT Control. 9
the distribution and Γ(a) = (a−1)! is a factorial function. For example,
Γ(5) = 4! = 24. Now to compute the posterior, we multiply the prior
with the Gaussian likelihood model of p(y|ω) and obtain the posterior
which is also a Gamma distribution as shown below.
p(ω) = Γ(ω; a,b) ∝ωa−1e−ωb
p(ω|y) ∝p(y|ω)p(ω) ∝ω0.5+a−1e−ω(b+ (y−C)2
2 )
p(ω|y) = Γ(ω; a+ 1
2,b + (y−C)2
2 )
The last equation shows a simple update rule to modify the belief over
the precision for every data point. In the optimization for the state, the
following quantities are used: expected precision E[ω] = a/b, Mode[ω] =
(a−1)/band Var[ω] = a/b2. In the n-dimensional case, the same proce-
dure can be done but with a Wishart distribution rather than a Gamma.
Additionally, we could use a batch of k observation to learn the pre-
cision rather than just one observation. Many approaches for covari-
ance/precision estimation have been successful in robotics e.g. [33,27,34,31].
Additionally, many other approaches within the active inference litera-
ture can be used for eﬀective precision learning such as dynamic expecta-
tion maximization (DEM) [12,11]. These will be explored and compared
in future work.
6 Conclusions
This paper presents a fault-tolerant controller based on active inference.
We model the precision (inverse covariance) of each sensor in our system
and determine the probability of the sensor being healthy to be propor-
tional to its precision. Rather than reasoning about whether a sensor is
faulty or not, we reason about the degree to which the sensor is faulty. We
present gradient based approaches to approximate the precision matrices
of the system. The results show that the precision learning is a promis-
ing approach for fault-tolerant control. It allows for robust behaviour
without needing any threshold deﬁnition a priori, without designing ad-
ditional ad-hoc recovery mechanisms, and can be used stand-alone or
in conjunction with other methods. The results using precision learning
was satisfactory but an order of magnitude away from the to state-of-
the-art. However, precision learning was not trained on data oﬄine and
performs a stochastic update. Bayesian methods can be used to improve
the performance of the approach. Additionally, in all cases regarding pre-
cision learning, the performance can be improved by considering the last
k observations rather than just one. Future work will address this.
References
1. Baioumy, M., Duckworth, P., Lacerda, B., Hawes, N.: Active inference for inte-
grated state-estimation, control, and learning. In: Proc of IEEE Int. conference on
robotics and automation (ICRA) (2021)
10 M. Baioumy et al.
2. Baioumy, M., Mattamala, M., Duckworth, P., Lacerda, B., Hawes, N.: Adaptive
manipulator control using active inference with precision learning. In: UKRAS
(2020)
3. Baioumy, M., Pezzato, C., Ferrari, R., Corbato, C.H., Hawes, N.: Fault-tolerant
control of robotic systems with sensory faults using unbiased active inference. In:
European Control Conference (ECC) (2021)
4. Bishop, C.M.: Pattern recognition and machine learning. springer (2006)
5. Bogacz, R.: A tutorial on the free-energy framework for modelling perception and
learning. Journal of mathematical psychology 76, 198–211 (2017)
6. Buckley, C.L., Kim, C.S., McGregor, S., Seth, A.K.: The free energy principle for
action and perception: A mathematical review. Journal of Mathematical Psychol-
ogy 81, 55–79 (2017)
7. Budd, M., Lacerda, B., Duckworth, P., West, A., Lennox, B., Hawes, N.: Markov
decision processes with unknown state feature values for safe exploration using
gaussian processes. In: IEEE/RSJ International Conference on Intelligent Robots
and Systems (IROS) (2020)
8. Chen, J., Patton, R.J.: Robust model-based fault diagnosis for dynamic systems.
Springer Science & Business Media, LLC (1999)
9. Fang, S., Blanke, M., Leira, B.J.: Mooring system diagnosis and structural relia-
bility control for position moored vessels. Control Eng. Practice 36, 12–26 (2015)
10. Fox, C.W., Roberts, S.J.: A tutorial on variational bayesian inference. Artiﬁcial
intelligence review 38(2), 85–95 (2012)
11. Friston, K., Stephan, K., Li, B., Daunizeau, J.: Generalised ﬁltering. Mathematical
Problems in Engineering 2010 (2010)
12. Friston, K.J., Trujillo-Barreto, N., Daunizeau, J.: Dem: a variational treatment of
dynamic systems. Neuroimage 41(3), 849–885 (2008)
13. Friston, K., Mattout, J., Trujillo-Barreto, N., Ashburner, J., Penny, W.: Variational
free energy and the Laplace approximation. Neuroimage 34(1), 220–234 (2007)
14. Imohiosen, A., Watson, J., Peters, J.: Active inference or control as inference? a
unifying view. In: International Workshop on Active Inference. pp. 12–19. Springer
(2020)
15. Inotsume, H., Kubota, T., Wettergreen, D.: Robust path planning for slope travers-
ing under uncertainty in slip prediction. IEEE Robotics and Automation Letters
5(2), 3390–3397 (2020)
16. Lanillos, P., Cheng, G.: Adaptive robot body learning and estimation through
predictive coding. In: IROS (2018)
17. Lanillos, P., G.Cheng: Active inference with function learning for robot body
perception. In: Int. Workshop on Continual Unsupervised Sensorimotor Learning
(ICDL-Epirob) (2018)
18. Levine, S.: Reinforcement learning and control as probabilistic inference: Tutorial
and review. arXiv preprint arXiv:1805.00909 (2018)
19. Marshall, M., Lipkin, H.: Kalman ﬁltering visual servoing control law. In: IEEE
Procs. of Int. Conference on Mechatronics and Automation (2014)
20. Millidge, B., Tschantz, A., Seth, A.K., Buckley, C.L.: On the relationship between
active inference and control as inference. In: International Workshop on Active
Inference. pp. 3–11. Springer (2020)
21. Murphy, K.P.: Machine learning: a probabilistic perspective. MIT press (2012)
22. Narendra, K.S., Balakrishnan, J.: Adaptive control using multiple models. IEEE
Trans. on Autom. Control (1997)
Towards Stochastic FT Control. 11
23. Oliver, G., Lanillos, P., Cheng, G.: An empirical study of active inference on a
humanoid robot. IEEE Transactions on Cognitive and Developmental Systems
pp. 1–1 (2021). https://doi.org/10.1109/TCDS.2021.3049907
24. Paviglianiti, G., Pierri, F., Caccavale, F., Mattei, M.: Robust fault detection and
isolation for proprioceptive sensors of robot manipulators. Mechatronics 20(1),
162–170 (2010)
25. Pezzato, C., Ferrari, R., Corbato, C.H.: A novel adaptive controller for robot ma-
nipulators based on active inference. IEEE Robotics and Automation Letters 5(2),
2973–2980 (2020)
26. Pezzato, C., Baioumy, M., Corbato, C.H., Hawes, N., Wisse, M., Ferrari, R.: Active
inference for fault tolerant control of robot manipulators with sensory faults. In:
Springer (ed.) 1st Int. Workshop on Active Inference, ECML PKDD. Communica-
tions in Computer and Information Science, vol. 1326 (2020)
27. Pfeifer, T., Lange, S., Protzel, P.: Dynamic covariance estimation—a parameter
free approach to robust sensor fusion. In: 2017 IEEE International Conference on
Multisensor Fusion and Integration for Intelligent Systems (MFI). pp. 359–365.
IEEE (2017)
28. Piepmeier, J., McMurray, G., Lipkin, H.: Uncalibrated dynamic visual servoing.
In: IEEE Trans. on Robotics and Automation. vol. 20, pp. 143–147 (2004)
29. Pio-Lopez, L., Nizard, A., Friston, K., Pezzulo, G.: Active inference and robot
control: a case study. Journal of The Royal Society Interface 13(122) (2016)
30. Rostampour, V., Ferrari, R.M., Teixeira, A.M., Keviczky, T.: Privatized distributed
anomaly detection for large-scale nonlinear uncertain systems. IEEE Trans. on
Autom. Control (2020)
31. Shetty, A., Gao, G.X.: Covariance estimation for gps-lidar sensor fusion for uavs. In:
Proceedings of the 30th International Technical Meeting of The Satellite Division
of the Institute of Navigation (ION GNSS+ 2017). pp. 2919–2923 (2017)
32. Van, M., Wu, D., Ge, S., Ren, H.: Fault diagnosis in image-based visual servo-
ing with eye-in-hand conﬁgurations using Kalman ﬁlter. IEEE Trans. Industrial
Electronics 12(6), 1998–2007 (2016)
33. Vega-Brown, W., Bachrach, A., Bry, A., Kelly, J., Roy, N.: Cello: A fast algorithm
for covariance estimation. In: 2013 IEEE International Conference on Robotics and
Automation. pp. 3160–3167. IEEE (2013)
34. Vega-Brown, W., Roy, N.: Cello-em: Adaptive sensor models without ground truth.
In: 2013 IEEE/RSJ International Conference on Intelligent Robots and Systems.
pp. 1907–1914. IEEE (2013)