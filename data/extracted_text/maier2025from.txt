Research Article Journal of Optical Communications and Networking 1
From Artificial Intelligence to Active Inference:
The Key to True AI and 6G World Brain [Invited]
MARTIN MAIER 1,*
1Optical Zeitgeist Laboratory, INRS, Montréal, QC, Canada
*Corresponding author: martin.maier@inrs.ca
Compiled May 19, 2025
In his opening OFC plenary talk back in 2021, Alibaba Group’s Yiqun Cai notably added in the follow-up
Q&A that today’s complex networks are more than computer science – they grow, they are life. This
entails that future networks may be better viewed as techno-social systems that resemble biological
superorganisms with brain-like cognitive capabilities. Fast-forwarding, there is now growing awareness
that we have to completely change our networks from being static into being a living entity that would act
as an AI-powered network ‘brain’, as recently stated by Bruno Zerbib, Chief Technology and Innovation
Officer of France’s Orange, at the Mobile World Congress (MWC) 2025. Even though AI was front and
center at both MWC and OFC 2025 and has been widely studied in the context of optical networks, there
are currently no publications on active inference in optical (and less so mobile) networks available. Active
inference is an ideal methodology for developing more advanced AI systems by biomimicking the way
living intelligent systems work, while overcoming the limitations of today’s AI related to training, learning,
and explainability. Active inference is considered the key to true AI: Less artificial, more intelligent. It is a
biomimetic mathematical framework that is premised on first principles of statistical physics found in
self-organizing/evolving complex adaptive systems, whether natural, artificial, or hybrid cyborganic ones.
The goal of this paper is twofold. First, we aim at enabling optical network researchers to conceptualize
new research lines for future optical networks with human-AI interaction capabilities by introducing them
to the main mathematical concepts of the active inference framework. Second, we demonstrate how to
move AI research beyond the human brain toward the 6G world brain by exploring the role of mycorrhizal
networks, the largest living organism on planet Earth, in the AI vision and R&D roadmap for the next
decade and beyond laid out by Karl Friston, the father of active inference. © 2025 Optical Society of America
http://dx.doi.org/10.1364/ao.XX.XXXXXX
1. INTRODUCTION
This paper expands on my OFC 2025 invited paper titled “From
Artificial Intelligence to Active Inference: “Natural Intelligence”
– the Future of AI-Native 6G” [1], whose closing sentence states
that, in the end, the acronym AI might actually not stand for
artificial intelligence, but active inference – the key to true AI.
While artificial intelligence was front and center at OFC 2025,
it is worthwhile to mention that there was only one single pa-
per inquiring into active inference. I have borrowed the closing
statement above from a widely read WIRED article on Karl Fris-
ton, the world’s most frequently cited neuroscientist as well as a
friend and former colleague of cognitive psychologist and com-
puter scientist Geoffrey Hinton – the ‘Godfather of AI’ and recip-
ient of the 2024 Nobel Prize in Physics [2]. Active inference was
pioneered by Karl Friston premised on the so-called Free-Energy
Principle (FEP), a first principle of statistical physics. In stark
contrast to the monstrous scaling energy demands of today’s
AI systems (e.g., large language models like ChatGPT), active
inference facilitates the most energy efficient form of learning
with no big data requirement necessary for training. Although
active inference is still relatively young, it has a growing impact
on various disciplines [3]. As we shall see, it is considered an
ideal methodology for developing more advanced AI systems
by biomimicking the way natural intelligence works. Or, as the
cover page of the aforementioned WIRED issue has titled: Less
Artificial, More Intelligent.1
The goal of this paper is twofold, which we shall call thePoint
Alpha (short-term goal) and the Point Omega (long-term goal)
henceforth, respectively denoting the beginning and end of the
active inference ‘Genesis’ in optical networks in general and 6G
1Speaking of Less Artificial, More Intelligent – to some, including the author of
this article, it comes largely unsurprising that the WIRED article mentions that
Karl Friston, a neuroscientist studying also mental disorder, doesn’t have a mobile
phone. There is now a growing awareness of the dangers of today’s phone-based
childhood in lieu of the analog play-based offline one, a topic in and of itself [4].
arXiv:2505.10569v1  [q-bio.NC]  29 Apr 2025
Research Article Journal of Optical Communications and Networking 2
Fig. 1. Ericsson’s 6G vision of co-creating a cyber-physical
world: AI-native 6G is anticipated to move to a cyber-physical
continuum between the connected physical world of senses,
actions, and experiences and its programmable digital rep-
resentations [9]. Note the similarity of the observe and act in
real-time cycle of AI-native 6G networks (bottom) to the action-
perception cycle of active inference (to be described shortly),
though the term active inference itself has not been mentioned
in any Ericsson document up to date, indicating a certain de-
gree of unawareness.
networks in particular in this new Age of AI [5]:
Point Alpha – Active Inference & Optical Networks: To my
best knowledge, there are currently no publications on
active inference in optical networks available, even though
artificial intelligence and machine learning (AI/ML) have
been widely studied in the context of optical networks,
see, e.g., [ 6] and [ 7] and references therein. Generally
speaking, AI/ML excels at all sorts of pattern recognition
related tasks in optical networks, ranging from quality
of transmission (QoT) estimation of optical channels to
anomaly detection in optical performance monitoring
(OPM) systems. In recent years, AI/ML has become one of
the key methods to automate a variety of optical network
operations with the overarching goal of cost reductions
and efficiency gains by removing the human out of the
loop. At the downside, without the human in the loop, it
will be difficult to fully capitalize on human-AI interaction, a
nascent research field of utmost importance not only for
co-creating Ericsson’s 6G vision of a cyber-physical world
(see Fig. 1) but also for scientific discovery in general, e.g.,
AI-powered drug discovery [8]. Further, according to [7],
key AI research challenges remain open: (i) Training: Lack
of available training datasets from real-world network
deployments, (ii) Learning: Lack of lifelong (i.e., continual)
learning, including AI degradation detection and model
adaptation to progressive distribution shift, and ( iii)
Explainability: Lack of trustworthy explainable AI (XAI)
due to insufficient transparency of blackbox AI.
What’s more, some liken the role of optical networks in to-
day’s high-speed networks to that of engines in high-speed
cars. A car without a powerful engine will go nowhere. In
fact, there is a wide consensus that 5G let alone 6G will go
nowhere without suitable fiber backhaul infrastructures in
place. The flip side of this analogy, however, is that optical
network research might have reached its limits, similar to
today’s combustion engine whose efficiency has reached
almost 100%, leaving space for only incremental progress,
unless new research lines are opened up, e.g., electrifica-
tion of vehicles or, in the case of 6G, intelligentization of
networks – that is, the ubiquitous deployment of AI to in-
creasingly replace communication with computation. To
see this, take the prime example of edge computing, which
has been widely deployed for reducing network latency
and/or predicting network traffic (in lieu of transmitting
it). By introducing active inference as the key to true AI,
this paper aims at enabling optical network researchers
to tackle the aforementioned open key AI challenges of
training, learning, and explainability, and arguably more
importantly, providing them with a powerful framework to
conceptualize new research lines for future optical networks
with human-AI interaction capabilities premised on the so-
called Markov blanket, an important concept for modelling
and designing interfaces between active inference agents in-
teracting with each other in their surrounding environment
(to be explained in more detail below).
Point Omega – Active Inference & 6G World Brain: In his
opening OFC 2021 plenary talk, Alibaba Group’s Yiqun Cai
notably added in the follow-up Q&A that today’s complex
networks are more than computer science – they grow, they
are life. This entails that future networks such as 6G, Next G,
and the 3D Metaverse – the anticipated successor of today’s
mobile Internet – may be better viewed as techno-social
systems that resemble biological superorganisms with
brain-like cognitive capabilities [ 10]. This view has been
recently echoed by Bruno Zerbib, Chief Technology and
Innovation Officer of France’s Orange, at the Mobile World
Congress (MWC) 2025. In [ 11], Zerbib argues that we
have to completely change our networks from being static
into being a living entity. Zerbib goes on by saying that
Orange is working on an AI-powered orchestration layer
that would act as a network ‘brain’, which is not expected to
be fully formed at birth, but evolves over time.
Since several years, we have been focusing on using AI
to improve the intelligence and transmission performance
and to reduce the complexity of communication systems,
which is regarded as AI for communication network (AI4Net).
AI4Net belongs to 5G and 5.5G. In the future, communi-
cation networks will be an integrated part of AI for per-
formance optimization, in addition to data collection and
transmission, which is known as communication network for
AI (Net4AI). Net4AI is the mainstay for 6G and beyond [12].
In fact, it is anticipated that AI-native 6G will play a signifi-
cant role in advancing Nikola Tesla’s prophecy that“when
wireless is perfectly applied, the whole Earth will be converted
into a huge brain” [13].
Towards realizing this vision of a 6G world brain in the new
Age of AI, we are going to explore which role Charles Dar-
win’s “root-brain” hypothesis – which has been forgotten in
the literature until 2005 and fills a gap in the all-embracing
Living Systems Theory of James Grier Miller and is also in
accord with Sir Jagadish Chandra Bose’s Unity of Life – may
play in advanced human-AI interaction of natural and artifi-
cial intelligences networked into a cyber-physical ecosystem
premised on active inference.
Research Article Journal of Optical Communications and Networking 3
The remainder of the paper is structured as follows. Sec-
tion 2 briefly reviews the latest paradigm shifts in brain research,
highlighting the major differences between outdated computer
science and up-to-date neuroscience brain models. Section 3
then delves into the several limitations of today’s AI and what
it can become according to the AI vision and R&D roadmap for
2030 and beyond recently outlined by Karl Friston et al., explain-
ing what life is and how living systems in general learn, adapt,
and self-evolve based on the FEP principle. Next, Section 4 de-
scribes the active inference mathematical framework in more
detail to provide the reader with a sufficient understanding of
its main concepts, including but not limited to the aforemen-
tioned Markov blanket and generative model. In Section 5, we
introduce the largest living system on planet Earth – forests’
underground mycorrhizal networks – highlighted in Friston’s
AI vision and R&D roadmap as a prime example of advancing
future AI research beyond the human brain, which we subse-
quently investigate in light of the 6G world brain in Section 6.
Finally, Section 7 concludes the paper.
2. THE BRAIN: COMPUTER SCIENCE VS. NEURO-
SCIENCE
For decades, it has been the dominant metaphor to view the
brain as a computer, drawing analogies from computer science
such as that the brain processes input information and then
makes a decision. This old “outside-in” strategy of the brain
is now replaced with a new “inside-out” paradigm in modern
neuroscience, where the brain does not process information: it cre-
ates it [14]. In this new neuroscience dictum, the brain acts as
a probabilistic prediction machine (rather than a determinis-
tic processing machine) that predicts sensory inputs by means
of action-oriented predictive processing. More specifically, the
brain uses a generative model to generate actions and predicts the
sensory consequences in an “inside-out” manner of embodied
action, while processing the actual sensory inputs as prediction
errors. Or, put differently, the predictive brain creates a “realm
of possibilities” (i.e., hallucinations) to perform a “preplay of
the future” and then uses perception to control its hallucinations
via action-based grounding (i.e., matching with reality). It’s this
action-perception loop, briefly mentioned above in Fig. 1, how
living organisms continuously learn through active inference,
which naturally lends itself to lifelong learning, a capability that
is completely lacking in today’s AI.
DeepSeek, whose R1 model was launched recently in January
2025, seems to have realized how important the “inside” of the
brain actually is, after the role of the brain’s subcortex known
as white matter has been long underestimated. For decades neu-
roscientists showed little interest in white matter, which is un-
derneath the gray matter – the “topsoil” of the brain – and its
densely packed neurons. While gray matter makes up only 15%
of the human brain, white matter fills nearly half of it. Neurosci-
entists considered the white matter’s millions of communication
cables, each coated with a white substance called myelin, for
interconnecting neurons in one region of the brain with those in
other regions little more than passive passageways, very much
like the trunk lines that connect telephones in different parts of
a country or, for the sake of a more modern example, network
lanes in AI centers. Although scientists have long thought that
white matter is passive tissue, new work shows that it actively
affects how the brain learns and dysfunctions (lack of myelin
causes mental illnesses such as autism, schezophrenia, and mul-
tiple sclerosis). For instance, it was shown that nerve impulses
Fig. 2. White matter of the brain’s subcortex: “The subway
of the brain.” (Source: https://blogs.biomedcentral.com/on-
biology)
race down myelin-coated axons on the order of 100 times faster;
without myelination, the signal would leak and dissipate. That’s
the reason why white matter is sometimes referred to as “the
subway of the brain,” as illustrated in Fig. 2. Moreover, when
learning a complex skill (e.g., playing piano), noticeable changes
occur in white matter during interactions with an enriched en-
vironment. It was shown that a higher development of white
matter structure correlates directly with a higher IQ. Further
discoveries of white matter, buried deep underneath the gray
matter “topsoil,” await unearthing by future experts [15].
Similar to white matter’s role of coordinating how well brain
regions work together, DeepSeek has put a particular focus on
interconnecting AI GPUs through a high degree of parallelism
with regard to model, data, pipeline, tensor, and experts. Due to
the high degree of parallelism, DeepSeek didn’t need to rely on
Nvidia’s advanced AI GPUs (recall that the US government has
imposed sanctions on exporting Nvidia’s advanced AI GPUs to
China) for dramatically lowering the training costs of their R1
model down to $6 million, as compared to OpenAI GPT-4’s $100
million. Importantly, DeepSeek’s different approach has sent
out shockwaves with the largest loss ($600 billion) in US stock
market history in their wake, making experts wonder whether
there are better ways of advancing AI other than throwing ever
increasing computation power at it, including its concomitant
massive power consumption.
3. TODAY’S AI AND WHAT IT CAN BECOME: AI VISION
AND R&D ROADMAP FOR 2030 AND BEYOND
A. Free-Energy Principle
In a panel at the 2024 World Economic Forum, two of the biggest
names in AI – computer scientist Yann LeCun and neuroscientist
Karl Friston – agreed that today’s AI is profoundly lacking the
key elements found in living intelligent systems in terms of per-
ception, memory, reasoning, and generating actions [16]. Where
they differ was in how to get there. LeCun, a pioneer in Deep
Learning (DL), argues that we don’t know how to do learning or
train systems any other way than DL, an engineering approach
to AI invented decades ago. Conversely, Friston, the father of
active inference, challenges the reliance on DL by advocating a
new and better alternative, rooted in the Free-Energy Principle
(FEP), which was briefly introduced above in Section 1. The FEP
is a unifying theory of brain function explaining how neurons
and biological systems in general learn, adapt, and self-evolve
Research Article Journal of Optical Communications and Networking 4
in nature [17]. It is essentially a mathematical formulation of
how biological systems resist a natural tendency to disorder in
the face of a constantly changing environment.
B. Negative Entropy: Paradoxically Something Very Positive
The FEP provides the answer to a fundamental question: How
do self-organizing adaptive systems avoid surprising states for
the sake of their survival? They can do this by minimizing their
free energy, which can be shown to be an upper bound on the
surprise of sensory states (see Section 4 below for details). This
means that the probability distribution of sensory states must
have low entropy, a measure of uncertainty denoting the average
surprise (i.e., there is a high probability that a biological system
will be in any of a small number of states, and a low probability
that it will be in the remaining states). In other words, living
systems are unique among natural systems because they manage
somehow to resist the second law of thermodynamics, which
states that entropy increases or remains constant. All other self-
organizing systems, from snowflakes to solar systems, follow an
inevitable and irreversible path to disorder.
The FEP answer’s Erwin Schrödinger’s famous question
What is Life? by asserting that all living systems actively reduce
disorder (i.e., entropy) of their sensory and physiological states
by minimizing their free energy. In [18], Schrödinger elaborated
on the concept of entropy and the role it plays in the behavior
of living organisms. By default, living organisms keep increas-
ing their entropy until they approach maximum entropy, which
corresponds to the dangerous state of death. However, living
organisms are able to free themselves from the entropy they keep
producing by drawing negative entropy from their environment
thru metabolism, i.e., exchange with environment. Paradoxically,
negative entropy may be viewed as something very positive:
Living organisms feed upon negative entropy, they can only stay
alive by continually drawing negative entropy from their envi-
ronment, i.e., extracting order from the environmnet – or, as put
by Schrödinger, by “drinking orderliness from a suitable envi-
ronment.” According to [19], the challenge lies in translating the
theory of FEP into productive scientific practice and applying it
to species without a brain, like fungi and flora(to be further explored
below in Section 5).
C. AI Vision and R&D Roadmap: From Artificial to Natural
Intelligence
In stark contrast to the monstrous scaling energy demands of
today’s AI systems (e.g., large language models like ChatGPT),
both LeCun and Friston agree on the fact that the FEP – based
on a principle of least action – facilitates the most energy effi-
cient form of learning with no big data requirement necessary
for training. Unsurprisingly, active inference is considered an
ideal methodology for developing more advanced AI systems
by biomimicking the way natural intelligence works in order to
bridge the gap between artificial and natural intelligence. At the
downside, however, LeCun remarks that “we don’t know how
to do this today with AI systems. That’s the problem we need to
solve over the next few years.”
Recently, Fristonet al. laid out an AI vision and R&D roadmap
premised on active inference for the next decade and beyond [20].
Friston reiterated that the design of AI should be informed by,
and aligned with, nature’s time-tested methods and design prin-
ciples demonstrated across systems of nested intelligences, ca-
pable of achieving multi-scale homeostasis (i.e., equilibrium)
via nature’s incredible coordination and communicative power.
While acknowledging neuroscience as a key inspiration for AI
research, Friston argues that we must move beyond brains and
embrace the active and nested characteristics of natural intelli-
gence in living organisms. Specifically, Friston mentions forests’
underground mycorrhizal networks, which create a mutually ben-
eficial symbiosis between fungi and flora both briefly mentioned
above, as a prime example to facilitate communication, learning,
and memory in trees (to be described in more detail below in
Section 5). He suggests that artificial general intelligence (AGI)
and artificial super intelligence (ASI) will emerge from the inter-
action of intelligences networked into a cyber-physical ecosystem
of artificial and natural intelligence, in which humans are integral
participants – what he calls “shared intelligence.” Key to such
an ecosystem will be the dyadic interaction between artificial
and natural intelligence, giving rise to human-AI interaction, a
nascent research field of utmost importance not only for creat-
ing Ericsson’s 6G vision of a cyber-physical world but also for
scientific discovery in general (see Section 1).
4. ACTIVE INFERENCE: LESS ARTIFICIAL, MORE INTEL-
LIGENT
Active inference formalizes the predictive and enactive views
of the brain and living organisms in general. Although active
inference is still relatively young, it has a growing impact across
various disciplines, e.g., human-AI interaction or more gener-
ally human-computer interaction (HCI), where both human and
computer are modelled as mutually interacting active inference
agents [21]. In this section, we describe the active inference
mathematical framework in more detail to provide the reader
with a sufficient understanding of its main concepts, including
but not limited to the Markov blanket and generative model
briefly mentioned in Section 1. For additional information and
more technical details, the interested reader is referred to [ 22]
for a recent overview of the history and future of active infer-
ence. For readers interested in using active inference in their
own research, an outstanding step-by-step tutorial requiring a
minimal background in mathematics and programming, includ-
ing supplementary code for building active inference models
from scratch, can be found in [23].
A. Markov Blanket: Interface for Interaction & Metamorphosis
The concept of Markov blanket forms the interface for inter-
action between an active inference agent and its surrounding
environment by creating a coupling via action and perception
states. It mathematically formulates the action-perception loop
of an active inference agent via a Markov blanket b given by
b = (u, y), (1)
where u denotes the action states and y denotes the perception
states, respectively. The concept of Markov blanket was origi-
nally introduced in Judea Pearl’s groundbreaking book Proba-
bilistic Reasoning in Intelligent Systems: Networks of Plausible Infer-
ence [24]. Similar to the Markov process underlying the widely
studied Poisson traffic in networks research, the Markov blan-
ket exhibits the Markov property, i.e., the memoryless property
of a stochastic process where only the present state influences
the probability distribution of future states. A Markov blanket
generalizes the Markov property from the one-dimensional time
domain of Poisson traffic to the three-dimensional space dimen-
sion of active inference agents interacting with their surrounding
environment, including other active inference agents.
For illustration, Fig. 3 shows a physical-digital (phygital) envi-
ronment (e.g., Ericsson’s 6G vision of a co-created cyber-physical
Research Article Journal of Optical Communications and Networking 5
Fig. 3. Action-perception loop in a physical-digital (phygital) environment involving the dyadic interaction between human and
digital active inference (AIF) agents, each with its own Markov blanket: A Markov blanket is a set of action and perception states
that mediate all interactions between an AIF agent and its environment. Without Markov blanket, an AIF agent would dissolve into
the environment, resulting in maximum entropy (i.e., death). Any living organism must enjoy some separation and autonomy from
the environment by exchanging entropy with the environment to resist the second law of thermodynamics (i.e., negative entropy).
world in Fig. 1), which hosts two active inference (AIF) agents,
one human in the real world and another one in virtual worlds.
The later one is assumed to be an advanced type of digital AIF
agent referred to ascyberfungi, which will be further investigated
below in Section 5. Note that each AIF agent is characterized by
its own Markov blanket, which separates the internal states of
a given AIF agent from the external states of the surrounding
environment, including other AIF agents. More complex AIF
agents could also have multiple Markov blankets nested within
one another (e.g., brains, organisms, communities), resulting in
hierarchical Markov blankets with temporal and spatial depth.
Any Markov blanketed system can be shown to engage in active
inference [25].
Markov blankets can grow and shrink depending on the
mode of interaction, entailing a transition from Markov blan-
ket states to processes. Active inference agents knit their own
Markov blankets in ways that can change over time, leading
to the concept of metamorphic agents. Where metamorphosis
occurs, the young life-stages do not look or behave in anything
like the same way as the adult or mature life-stages. A familiar
example of such metamorphic agents is the transformation of
a caterpillar into a butterfly. Metamorphic insects account for
at least 40% of the world’s total animal populations. Note that
as an evolutionary strategy, metamorphosis works – it is not a
rare or exceptional solution to the problem of adaptive success
thru a series of changes across the lifespan. In fact, metamor-
phosis has adaptive value because it allows younger and older
living systems to share the same territory without consuming
the same resources or being exposed to the same predators. Hu-
man beings are nature’s experts at constantly re-configuring
their own cognitive, bodily, and sensory boundaries of our socio-
technological cocoon , which enables us to re-invent a Markov
blanket wherever new technologies interface with the old biolog-
ical systems [26]. Recent examples include virtual/augmented
reality (V/AR) head-mounted devices for accessing the emerg-
ing 3D spatial Internet (also known as Metaverse) or novel types
of human-AI interaction for the genesis of homo technicus, a hu-
man species that may, in the new Age of AI briefly mentioned
in Section 1, live in symbiosis with machine technology (to be
further explored below in Section 6).
It is important to note that fungi, briefly mentioned in our
above discussion of negative entropy, are metamorphic agents
as well. As we shall see in Section 5, fungi connect the roots of
plants (flora) via underground pathways, though they may turn
into mushrooms to entreat the visible more-than-fungal world
above ground. Mushrooms are fungi’s fruiting bodies, which
let fungi embody themselves in the visible world. They are also
the place where fungi produce spores to disperse themselves.
Similar to nature’s fungi, digital cyberfungi active inference
agents should be able to entreat the visible more-than-virtual
world (i.e., embodiment) and disperse themselves in the real
world (i.e., agency), giving rise to embodied AI and enactive AI.
B. Generative Model: Belief Update via Bayesian Inference
Defining the Markov blanket for an active inference agent en-
sures that we know what is being inferred (the agent’s external
states outside its Markov blanket) and what is doing the infer-
ring (the agent’s generative model inside its Markov blanket).
The generative model lies at the heart of active inference. Getting
it right is the big challenge of active inference. The challenge is
not to emulate the brain, but to find the generative model that
describes the problem the brain is trying to solve. Once this is
appropriately formalized in terms of a generative model, the
solution to the problem emerges under active inference. Active
inference can operate on different kinds of generative models.
Therefore, the challenge is to specify the most appropriate form
of the generative model for the problem at hand [3].
Research Article Journal of Optical Communications and Networking 6
Fig. 4. At the heart of active inference lies a generative model: Getting the probabilistic generative model p(s, o) right for updating
an active inference agent’s belief about the true state s∗ via Bayesian inference of state s (i.e., cause a in Bayes’ theorem) from obser-
vation o (i.e., consequence b in Bayes’ theorem) is the big challenge of active inference (Bayes’ theorem is shown in light grey) [27].
In active inference, it is important to distinguish between the
generative model and the generative process that describes the
dynamics of the world external to the active inference agent. As
illustrated in Fig. 4, the generative process corresponds to the
process that determines the active inference agent’s observation
o. In many practical applications, the active inference agent’s
generative model is assumed to closely biomimic the generative
process that generates its observations [ 3]. As a result of its
Markov blanket, an active inference agent is separated from ex-
ternal states, including the true state s∗ of the generative process
that creates observation o. However, the agent can infer the hid-
den true state s∗ from its observation o by using the well-known
Bayes’ theorem thru a process known as Bayesian inference (see
Fig. 4). The inferred state s after making observation o is given
by
p(s|o) = p(o|s)p(s)
p(o) , (2)
where p(s) denotes the prior belief (encoded as probability dis-
tribution p) of different possible states s before making a new
observation o. Whereas p(s|o) denotes the posterior belief, which
encodes what an active inference agent’s new belief (i.e., updated
probability distribution p) optimally should be after making a
new observation o. Due to the fact that the internal states of
any biological system are statistically insulated from the envi-
ronment that generates sensory observations, an agent must
engage in Bayesian inference about the hidden causes of its sen-
sory states to behave optimally. In essence, Bayesian inference
describes the optimal belief update of an active inference agent
in light of a new observation (i.e., new sensory perception), not
incorporating any action yet. Bayesian inference stands for the
term ‘inference’ in active inference.
It is important to keep in mind that Bayes’ theorem is compu-
tationally intractable for anything but the simplest distributions.
This is due to the fact that the number of all possible states and
and their caused observations increases exponentially, render-
ing it intractable to compute p(o|s) and p(o) in Eq. (2). As a
consequence, approximation techniques are required that allow
for approximate Bayesian inference. This is where free energy
minimization is crucial, as explained in the next subsection.
Recall that the generative model lies at the heart of active in-
ference. Typically, generative models use the concept ofpartially
observable Markov decision process (POMDP), which offers a fairly
expressive structure to model discrete state-space environments
by means of parameters that can be expressed as tractable cat-
egorical distributions. A POMDP can be formally defined as a
tuple of finite sets and matrices (S, O, U, A, B) [28]:
• s ∈ S: Set S of states s causing observations o.
• o ∈ O: Set O of observations o, where o = s∗ in fully observ-
able settings (i.e., without Markov blanket) and o = f (s)
in partially observable settings (i.e., with Markov blanket);
f (s) correspond to perception states y of the Markov blan-
ket (see Eq. (1)), since generally perception differs from true
state of reality.
• u ∈ U: Set U of actions u of Markov blanket (see Eq. (1)).
• A: Matrix A encodes likelihood p(oτ|sτ) at time τ; an im-
portant thing to note here is that τ indexes the time points
about which an agent has beliefs – this is distinct from the
below variable t, which denotes the time points at which a
new observation is presented. Matrix has one column per
state at τ and one row per possible observation at τ.
• B: Matrix B encodes one-step transition dynamics
p(st|st−1, ut−1), i.e., probability that when action ut−1 is
taken while being in state st−1 at time t − 1 results in st at
time t. It has one column per state at t − 1 and one row per
state at t.
Now, instead of passively inferring what caused observations
without exerting any actions on the environment, active infer-
ence agents actively infer by using the available actions in U of
their POMDP-based generative model. Note that these actions
stand for the term ‘active’ in active inference. Also note that
apart from the aforementioned POMDP matrices A and B, a
generative model may comprise additional matrices, including
matrix C for preferred outcomes, D for prior beliefs about each
possible state at initial time point τ = 1, and E for prior beliefs
about habits.
Figure 5 provides an overview of active inference via the
functional brain anatomy implicit in belief updating, highlight-
ing the action-perception loop (large arrow outside the brain,
rendering outcomes dependent upon actions) and biologically
plausible (i.e., neuroscientifically measurable) message passing
between different functional areas inside the brain. As shown
in the figure, all the heavy lifting in active inference is done by
minimizing free energy, which comes in two flavors: Variational
free energy F and expected free energy G, as explained next.
C. Free Energy Minimization via Self-Evidencing
The above described Bayesian belief update in active inference
is where learning emerges. More precisely, the underlying gener-
ative model enables active inference agents to learn the causal
Research Article Journal of Optical Communications and Networking 7
Fig. 5. Functional brain anatomy of belief updating in active
inference: Action-perception loop (large arrow outside the
brain) and biologically plausible message passing (arrows
inside the brain) [29].
structures of their worlds instead of merely correlations, endow-
ing them with a so-called world model, a capability largely absent
in alternative AI/ML algorithms (e.g., reinforcement learning).
To see this, it’s crucial to better understand the role of variational
and expected free energy in active inference.
Recall from above that exact Bayesian inference is often com-
putationally intractable in practical applications of active infer-
ence, calling for approximate Bayesian inference instead. Free
energy minimization converts an intractable computation prob-
lem into an optimization problem that can be solved in a com-
putationally efficient manner. We will show how variational
free energy F can be used to solve the POMDP within a given
generative model and how expected free energy G extends this
approach to infer optimal choices. Simply put, F is a measure of
the free energy of the present (implicitly the past thanks to the
Markovian property of Markov blankets), while G is a measure
of the free energy of the future. Put differently, F and G provide
the retrospective view (“how good has this action plan turned
out so far?”) and prospective view (“how good do I expect
things to go if I continue to follow this action plan”) on pursuing
a certain policy π (i.e., sequence of actions), respectively.
More formally, an active inference agent aims at finding be-
liefs in its generative model for which observations provide
the most evidence, a process known as self-evidencing. Model
evidence can be expressed as the sum of the probabilities
of observations for every combination of states and policies:
p(o) = ∑s,π p(o, s, π). Next, one can multiply and divide the
joint distribution p(o, s, π) by an initially arbitrary distribution
over states and policies q(s, π) that is iteratively updated to
match the true posterior distribution p(s, π|o) as closely as pos-
sible. For mathematical convenience, one can take the negative
logarithm of the resulting term, leading to
−ln p(o) =−ln ∑
s,π
p(o, s, π)q(s, π)
q(s, π) = −ln Eq(s,π)
 p(o, s, π)
q(s, π)

,
(3)
where Eq(s,π)[x] denotes the expected value or expectation of a
distribution x with each value weighted by q(s, π). The term
−ln p(o), i.e., negative log model evidence, is called surprisal
in information theory, or often surprise for short. Using Jensen’s
inequality, which states that the expectation of a logarithm is
always less than or equal to the logarithm of an expectation, we
arrive at the following definition of variational free energy F:
−ln p(o) = −ln Eq(s,π)
 p(o, s, π)
q(s, π)

(4)
≤ −Eq(s,π)

ln p(o, s, π)
q(s, π)

(5)
= Eq(s,π)

ln q(s, π)
p(o, s, π)

(6)
= DKL [q(s, π) || p(o, s, π)] =F, (7)
where DKL denotes the Kullback-Leibler (KL) divergence, also
sometimes called relative entropy, between the two distributions
q(s, π) and p(o, s, π). DKL is a non-negative measure of their
dissimilarity. It is equal to zero ifq(s, π) =p(o, s, π), and greater
than zero otherwise. As a consequence, F places an upper bound
on surprise. The approximate distributionq(s, π) that minimizes
F is the one that best approximates the true posterior distribu-
tion p(o, s, π). Hence, free energy minimization helps an active
inference agent to maximize model evidence (i.e., DKL = 0) and
minimize surprise of its observations, given that evidence is the
inverse of surprise.
To see this, a common way to express variational free energy
as placing an upper bound on surprise for a given policy π uses
the product rule of probability p(o, s|π) = p(s|π)p(o|s, π) to
obtain:
F(π) = Eq(s|π)

ln q(s|π)
p(o, s|π)

(8)
= Eq(s|π) [ln q(s|π) − ln p(o, s|π)] (9)
= Eq(s|π) [ln q(s|π) − ln p(s|π)] −
Eq(s|π) [ln p(o|s, π)] (10)
= DKL [q(s|π) || p(s|π)]| {z }
Divergence
−ln p(o|π)| {z }
Evidence
(11)
= DKL [q(s|π) || p(s|π)]| {z }
Divergence
+ [−ln p(o|π)]| {z }
Surprise
(12)
For decision-making, expected free energy G also needs to be
calculated relative to preferences for some sequences of future
states and observations that have not yet occurred for each possi-
ble policy π. In active inference, this is formally accomplished by
equipping the generative model not only with prior beliefs about
states but also with prior expectations over observations, p(o|C)
(see above discussion of C in POMDP). These prior expectations
over observations play the role of preferences C definitive of a
living organism’s phenotype, e.g., seeking warmth when cold,
or water when thirsty. Note that this is a central move within
active inference: An active inference agent seeks to find policies
that are expected to produce those preferred observations C. To
score each possible π in this way, expected free energy can be
expressed as follows:
G(π) =DKL [q(o|π) || p(o|C)]| {z }
Divergence
+ Eq(s|π)[H[p(o|s)]]
| {z }
Expected Entropy
, (13)
where H[p(o|s)] = − ∑o|s p(o|s)ln p(o|s) =−Ep(o|s)[ln p(o|s)]
denotes the entropy of distribution p(o|s). Note that the term
expected entropy in Eq. (13) denotes the average surprise of
future observations for a given policy π.
Research Article Journal of Optical Communications and Networking 8
5. ADVANCING AI: MOVING BEYOND BRAINS
In this section, we elaborate on those mycorrhizal networks that
Friston has mentioned as a prime example for developing more
advanced AI systems by moving beyond brains, as outlined in
his AI vision and R&D roadmap in Section 3.C. We pay particular
attention to the mutually beneficial symbiosis between fungi
and flora, since both are species without a brain and thus pose
a challenge to translating the theory of FEP into productive
scientific practice, as indicated in Section 3.B.
A. Mycorrhizal Networks
Forests all over the world regulate their natural ecosystems via
complex, symbiotic mycorrhizal networks that communicate,
nourish, and sustain vast ecosystems. They represent nature’s
underground Internet popularized under the moniker the wood-
wide web [30, 31]. The wood-wide web is formed through mycor-
rhizal networks by connecting the roots of plants – belonging to
the same or different species – via underground fungal networks.
Mycorrhizal networks are able to mediate plant-plant interac-
tions. Plants acquire carbon from these underground fungal
networks by means of exchange of resources between different
plants. However, it is important to note that recent outlets in
popular media (e.g., high-profile books, newspapers, magazines,
documentaries, films, TED talks, podcasts, and even television
series) about mycorrhizal networks in forests are not based on
scientific evidence and therefore don’t help further our under-
standing of important characteristics of the structure and function
of mycorrhizal networks (to be further investigated below in
Section 6). Even though the transfer of carbon through under-
ground pathways is in line with Simard’s seminal paper on the
wood-wide web [32], the role of underground pathways other
than mycorrhizal networks is often disregarded. Nonetheless,
there remain plenty of research opportunities to experimentally
investigate the structure and function of mycorrhizal networks
in forests. Among others, a deeper understanding of which
role the topology of mycorrhizal networks plays in the growth
of trees and the resilience of underground fungal networks is
needed [33].
The wood-wide web is a rather problematic term since it
equates organisms with machines. As a result, we misinterpret
organisms as such. Unlike the Internet, the wood-wide web is
made up of fungal links that act like active fiber-optic cables,
i.e., fungi have a life of their own. The fact that fungi are active
participants makes a huge difference, especially in the light of
active inference. It positions fungi as brokers of entanglement
that are able to mediate symbiotic interactions between flora and
fungi. The number of fungi species is estimated to be six to ten
times larger than flora species in the world. In fact, fungi are
the largest living organisms on planet Earth, whereby some are
estimated to be as old as 2,400 years. And, importantly, they
exhibit the following salient characteristics:
• Growth of Mycelium – Hyphae & Homing: Mycelium is
the most common habit of fungi and is better thought of
as a process rather than thing. It may be best viewed as an
exploratory, irregular tendency. The vast majority of fungi
create networks consisting of cells referred to as hyphae,
which are only a single cell thick (similar to thin strands of
optical fiber). Hyphae are thin structures that tangle into
mycelium. The growth of mycelium involves the following
two steps: (i) First, hyphae branch, and then (ii) they fuse.
Without fusion, hyphae would be unable to form complex
networks. Prior to fusing, hyphae have to find each other
by attracting one another. This process is called homing,
which might be viewed as a process of reducing disorder
(i.e., reducing entropy) by feeding upon negative entropy.
• Transfer of Resources – From Areas of Abundance to Ar-
eas of Scarcity: Fungi are decentralized organisms. As a
result, coordination in the mycelium happens everywhere
at once and nowhere in particular. In many fungal networks,
the transfer of resources is done downhill , i.e., from areas of
abundance to areas of scarcity. In doing so, they create
an equilibrium (characterized by increased entropy). Fur-
thermore, larger plants transfer resources to smaller plants.
Note that this behavior presents a puzzle. It’s not obvious
why plants would give resources to a fungus, which in turn
gives them to another plant, which may become a potential
competitor.
• Mushrooms & Spores – Entreating the Visible More-Than-
Fungal World: Hyphae make mycelium, but they also make
mushrooms, which are fungi’s fruiting bodies. They are also
the place where fungi produce spores, which they use to
disperse themselves. Fungi use mushrooms to access the
more-than-fungal world above ground, thereby rendering
fungi visible (by acting as metamorphic agents). Hence,
mushrooms enable the embodiment of fungi to help them
engage in a certain agency, i.e., sporulating, in the real world
(to be revisited in the context of cyberfungi as embodied,
enactive AI below in Section 6).
It is interesting to note that nature’s underground pathways
bear some resemblance to the brain’s subcortex, “the subway
of the brain” in Fig. 2. Similar to myelin, mycelium intercon-
nects different forest (rather than brain) regions and also has the
appearance of white matter.
B. The “Root-Brain” Hypothesis
The structure of fungal networks in forests resembles that of
the neural networks in human brains. Like neurotransmitters
are sent in neural networks, carbon is transmitted in fungal
networks between trees. From both neural and fungal net-
works emerge communication, connection, cohesion, and hu-
mans/trees use them to perceive their environment. These simi-
larities have given rise to the so-called “root-brain” hypothesis.
The “root-brain” hypothesis was remarked for the first time
by Charles Darwin and his son Francis in their revolutionary
book The Power of Movements in Plants , which departed from
the classical and still dominant view of plants as organisms
which had no need of movements that were based on sensory
perceptions or a brain-like organ – a view which traces back to
Aristotle’s concept of placing plants outside the realm of cogni-
tive, animated, animal living systems. The Darwins’ “root-brain”
hypothesis has been forgotten in the literature until 2005, when it
was discussed at the first symposium on plant neurobiology held
in Florence, Italy. It has been slowly penetrating mainstream
research since then, as recent advances in plant molecular biol-
ogy unmasked plants as sensory and communicative organisms
characterized by active, problem-solving behavior. The “root-
brain” hypothesis claims that the brain-like root apices mon-
itor and integrate numerous parameters simultaneously and
then translate these sensory experiences into complex motoric
responses, e.g., crawling-like searching movements. This animal-
like sensory-motoric circuit allows adaptive behavior (similar to
the action-perception loop in active inference). Simply put, the
“root-brain” hypothesis states that plants are anchored in the soil
Research Article Journal of Optical Communications and Networking 9
by their brains, while exposing their sexual organs to the air and
to prospective pollinators, e.g., bees. More importantly, it fills
a gap in the all-embracing Living Systems Theory of James Grier
Miller and is also in accord with Sir Jagadish Chandra Bose’s
Unity of Life [34].
In the following section, we are going to explore which role
the “root-brain” hypothesis may play in realizing the vision of a
6G world brain by advancing AI beyond the human brain.
6. TOWARD THE 6G WORLD BRAIN: FROM HOMO TECH-
NICUS TO INTERBEING
We have seen that active inference is a normative framework to
characterize Bayes-optimal behavior. However, it is important
to note that the design of the right generative model depends
on the desired behavioral outcomes. Each generative model
should be associated with different sorts of behavior. As such,
more complex behaviors associated with a suitable agency may
be accounted for by specifying different generative models that
are capable of modelling alternative futures, or different ways in
which events might play out in the future, and then selecting
among them [3].
In the remainder of this paper, we are going to develop a gen-
erative model that allows us to knit our own socio-technological
cocoon for the human-AI co-evolution of homo technicus to be-
come a metamorphic active inference agent of the future 6G
world brain and global mind.
A. Homo Technicus & Interbeing: The Human Strategy
In the new Age of AI, briefly mentioned in Section 1, the human-
AI co-evolution of homo technicus will lead to a human species
that may live in symbiosis with machine technology [5]. In con-
ceptually unlocking the possibility of a cyborganic entanglement
of these two species – one synthetic, the other organic – reveals
the need for creating a world in which AI becomes more like
us, or one in which we become more like AI. In its evolutionary
speed and diversification, AI’s development will be akin to the
Cambrian explosion: the emergence of a wide variety of hybrid
cyborganic lifeforms within a single, highly compressed period
of time relative to the preceding epoch.
To help homo technicus cope with emerging advanced AIs,
he or she ought to applythe human strategylaid out by MIT’s Alex
Pentland [35]. Pentland suggests that today’s AI is as far from
Norbet Wiener’s original notion of cybernetics as you can get,
because it is not contextualized; it is – what he calls – a little idiot
savant. Conversely, humans can perceive things in a broadly
competent way and thus have a commonsense understanding of
the real world that they bring to most problems. So what would
happen if we replaced AI neurons with people? Pentland calls this
the human strategy. According to Pentland, on the horizon is a
next-generation AI vision of how we can make humanity more
intelligent by building a human AI, where social interactions
such as social learning (i.e., spreading ideas and transforming
those ideas into behaviors) are the primary forces driving the
evolution of collective intelligence. This conclusion is echoed
by Max Borders through his concept of the human hive mind [36].
According to Borders, more and more, humans act as neurons
with decentralized blockchain technologies acting as connective
tissue to create programmable incentives, which are technically
known as blockchain tokens.
Recently, in [37], we have elaborated on the importance of
a rich techno-social environment that triggers shared, collec-
tive experiences of the human hive mind, where a group has
the feeling that they are moving together toward the same or
complementary goals. We have put a particular focus on the
unifying design of virtual, embodied, intelligent cross-reality en-
vironments based on the mutually beneficial symbiosis between
Inter(net) and (human) being, giving rise to the powerful concept
of Interbeing.2 Interbeing enables active agents such as homo
technicus to interact in a dynamic human-AI-cybernetic organ-
isms environment. In the following, we are going to demonstrate
how the concept of Interbeing may be leveraged for realizing
the dyadic interaction between human and cyberfungi active
inference agents introduced above in Fig. 3, while adhering to
the human strategy to foster the human-AI co-evolution of homo
technicus, tying the real and virtual worlds of the future phy-
gital environments such as the 3D Metaverse tighter together,
all in an attempt in incentivizing desired behavioral outcomes
and alternative futures via purpose-driven tokens (purpose free
to be chosen by active inference agents, see below for example
of social learning via spreading ideas and actuating tokens by
transforming those ideas into desirable new social norms).
B. Symbiogenesis & Circular Causality: Teleology
Recall from Section 1 that in the face of the growing complex-
ity of today’s communication networks we have to completely
change them from being static into being a living entity equipped
with a network ‘brain’ by applying 6G’s mainstay approach of
Net4AI (i.e., network for AI). Figure 6 illustrates our envisioned
transformation of Earth into the 6G world brain and global mind
by mimicking nature’s more-than-human intelligence (see ar-
row at bottom of figure). The left-hand side of Fig. 6 depicts the
“root-brain” as well as the metamorphic fungi-turned-mushroom,
entreating the more-than-fungal world above ground to disperse
themselves via spores. Flora-fungi mutualism, i.e., the mutually
beneficial symbiosis between flora and fungi, exemplifies the
evolutionary process of symbiogenesis which merges two sepa-
rate organisms to form a single new organism. Biomimicking the
evolution of new, more complex integrated organisms via sym-
biosis of Internet and human being (Interbeing) toward a single,
higher-level organism is particularly promising, an approach
known as symbiomimicry.
Here, we are interested in forming the new cyborganic entity
of homo technicus and their human-AI co-evolution via our pro-
posed human-cyberfungi mutualism premised on active infer-
ence. According to [3], active inference is closely related to cyber-
netic ideas about the purposeful, goal-directed nature of behav-
ior and the importance of feedback-based agent-environment
interactions. Specifically, we are interested in applying circu-
lar causality as the fundamental principle for the control and
management of complex adaptive systems such as the emerging
Metaverse (see center of Fig. 6). Norbert Wiener introduced cir-
cular causality as the core concept of cybernetics, which he used
as a generalized feedback mechanism for feedback-controlled
purpose, referred to as teleology (from Greek télos: Purpose, goal,
or ultimate end). Hence, it denotes a purpose-driven (teleologi-
cal) mechanism. Circular causality takes the observed outcomes
of actions as feedbacks for steering subsequent actions in sup-
port of maintaining particular conditions such as homeostasis
of systems. It is worth mentioning that Wiener introduced cir-
cular causality as a teleological mechanism for regulatory and
2Interbeing is a word that was originally coined by the Buddhist monk Thich
Nhat Hanh to describe the mutual interdependence in human relationship and
humanity’s relationship to the natural world—a connection to what many refer to
as the life force, a higher power or purpose. In The Art of Living, Thich Nhat Hanh
states that the word is not in the dictionary yet.
Research Article Journal of Optical Communications and Networking 10
Fig. 6. 6G transformation of Earth into World Brain/Global Mind by mimicking nature (i.e., biomimicry) via human-AI interaction
of natural and artificial intelligence networked into a cyber-physical ecosystem of real and virtual worlds: Forests regulate their nat-
ural ecosystems via underground mycorrhizal fungal networks for the exchange of resources between trees. Circular causality – the
core concept of cybernetics (see center of figure) – is used to biomimic the “root-brain” and metamorphic fungi-turned-mushroom
for the mutually beneficial symbiosis between Inter(net) and (human) being, giving rise to the powerful concept of Interbeing [37].
purposed systems in both machines and living organisms.
C. 6G World Brain: Metamorphic Generative Model for Knitting
Our Own Socio-Technological Cocoon
As shown on the right-hand side of Fig. 6, in future 6G net-
works humans may continue to engage in conventional human-
to-human audiovisual communications, involving the senses of
sound and sight. They may also remotely steer robots thru haptic
human-to-robot communications involving the sense of touch,
leading to embodied communications. Both human-to-human
and human-to-robot interactions are illustrative examples of
direct communications. In addition, humans may partake in
indirect communications mediated through stigmergic commu-
nications by mimicking the senses of taste and smell via virtual
pheromones in the online environment. For further technical
details on haptic and stigmergic communications in 6G, we re-
fer the interested reader to our JOCN special issue OFC 2021
paper [10].
Building on our previous work on embodied (human-to-
robot) interaction, the focus of this paper lies on demonstrating
more advanced human-AI interactions networked into a cyber-
physical ecosystem of artificial and natural intelligence, in which
humans are integral participants, as envisioned by Friston et al.
in Section 3. Human-in-the-loop/AI interactions let humans in-
teract with different types of AI, ranging from intelligent smart
contracts operating on simple if-then programming to more ad-
vanced generative AI, which in turn will pave the way to future
life-like digital organisms, as indicated by the arc of evolution in
Fig. 6 (see right-hand side of figure).
Here, we are interested in adapting and extending generative
AI to help us implement our proposed metamorphic cyberfungi
active inference agent, briefly introduced in Fig. 3, as an early
example of future cybernetic organisms. Specifically, we adapt
and extend OpenAI’s improved Denoising Diffusion Probabilistic
Model (DDPM)3 to biomimic the salient features of mycorrhizal
networks, paying particular attention to their two important
characteristics of structure and function, as explained in Sec-
tion 5.A. Recall that in active inference, the generative model is
supposed to closely biomimic the underlying generative process
found in forests (see also Fig. 4). To do so, we use the forward dif-
fusion process of DDPM to biomimic the branching process and
exploratory, irregular tendency of hyphae, while the backward
denoising process of DDPM is used to to biomimic the fusing
and homing process of hyphae to create complex mycelium-like
networks. Note that the use of generative AI diffusion mod-
els such as DDPM allows us to create not only an increase in
entropy (diffusion) but also decrease or reverse-time entropy
(denoising), which may be viewed as negative entropy. Recall
from Section 4 that entropy denotes the average surprise, which
needs to be minimized in active inference. Importantly, we ex-
tend OpenAI’s improved DDPM – which in its original form is
a completely disembodied AI – to let our cyberfungi entreat the
physical more-than-cyberfungal world in order to dissiminate
cybernetic spores (i.e., teleological tokens), similar to their meta-
3OpenAI improved Denoising Diffusion Probabilistic Model (DDPM) codebase
available at: https://github.com/openai/improved-diffusion
Research Article Journal of Optical Communications and Networking 11
Fig. 7. Schematic illustration of proposed metamorphic gener-
ative model for cyberfungi active inference agent symbiomim-
icking mediated interactions between plant and mushroom
life cycles for enactive, embodied AI: (i) Structure: Genera-
tive model dynamically couples pairs of humans via halluci-
nated scale-free networks with small-world properties that
are widely found in biological, social, and man-made systems;
and (ii) Agency: Similar to cross-pollination among plants,
pairs of directly linked humans spread a desirable new social
norm incentivized by reciprocal rewards in the form of teleo-
logical (purpose-driven) tokens, which are dispersed into the
physical more-than-cyberfungal world.
morphic fungi-turned-mushroom counterparts (see right-hand
side of Fig. 6). As a result, DDPM becomes an embodied AI as
well as enactive AI, which are two main characteristics of active
inference agents (see Section 4.A).
Figure 7 schematically illustrates our proposed metamorphic
generative model for cyberfungi, putting a particular focus on
explaining their underlying network structure and the resulting
networked agency (i.e., function), two important characteristics
of mycorrhizal networks in need for further understanding (see
Section 5.A). Towards this end, we exploit DDPM’s well-known
capability of hallucination.4 More specifically, we let our cyber-
fungi generative model hallucinate so-called scale-free networks
with small-world properties to couple the biomimicked life cy-
cles of plants and mushrooms. Now, it’s important to note that
scale-free networks can be widely found in nature, including
our human brain. The nodal degree distribution of scale-free
networks follows a power law, whereby a few hubs have many
connections that provide these networks with the so-called small-
world property, which is a quantifiable characteristic widespread
in biological (e.g., neuronal networks), social (e.g., social net-
works), and man-made systems (e.g., world wide web). The
resultant small-world, scale-free networks have an increased
4Hallucinate is Cambridge Dictionary’s Word of the Year 2023, following a year-
long surge in interest in generative AI with public attention shifting towards its
limitations and whether they can be overcome through ‘grounding’ by means of
human feedback. Clearly, the importance of human ‘grounding’ calls for human-
in-the-loop/AI interactions.
wiring efficiency and are therefore biologically more economical
than random networks, often with important dynamical con-
sequences such as different forms of biological contagion (and
social contagion, as we shall see shortly). The study of scale-free
networks with small-world property also plays an instrumental
role in the emergence of spontaneous order, i.e., the transition from
randomness to order, in self-organizing organisms widely found
in nature [38]. In our comprehensive search of over 7,000 net-
work datasets, we haven’t found a single dataset for small-world,
scale-free networks. Hence, we used NetworkX to generate a
dataset consisting of 1,304,483 unique tensors, each defining a
different small-world, scale-free synthetic network, for training
OpenAI’s improved DDPM.5
As for the agency emerging from these underlying scale-free
networks with small-world properties, the generative model lets
human beings and cyberfungi – both metamorphic agents (see
Section 4.A) – engage in novel types of human-AI interaction
to knit our own socio-technological cocoon for the human-AI co-
evolution of the 6G world brain, where humans and cyberfungi
act as neurons networked into a cyber-physical ecosystem of
artificial and natural intelligence to form the new cyborganic en-
tity homo technicus premised on human-cyberfungi mutualism,
a new research field as shown in Fig. 6 (see right-hand side of
figure). Circular causality is used to take the observed outcomes
of human behavior as feedbacks for steering subsequent cyber-
fungi actions in support of driving the evolution of collective
intelligence by incentivizing social learning, i.e., spreading ideas
and transforming those ideas into desirable new social norms.
Toward this end, our proposed metamorphic generative
model facilitates human-cyberfungi mutualism by biomimick-
ing the agency of the plant and mushroom life cycles. While the
plant life cycle produces pollen for cross-pollination between
plants, the mushroom life cycle disperses spores that need to
be actuated in order to germinate (see Fig. 7). To do so, humans
interact with cyberfungi by connecting to their created small-
world, scale-free networks such that one human performing a
desirable new social norm (e.g., planting trees) cross-pollinates
other connected humans such that the new social norm starts
spreading from human to human with a certain spreading prob-
ability denoted by 0 ≤ r ≤ 1 (a social innovation phenomenon
known as social contagion). Each human who starts adapting
the new social norm is rewarded with cybernetic spores, which
get actuated by the human’s action. These cybernetic spores can
be any type of teleological tokens such as purpose-driven tokens
widely used in decentralized blockchain networks. This human-
cyberfungi mutualism consisting of the cyclic cross-pollination
of social norms and actuation of teleological tokens (cybernetic
spores) continuously repeats itself. In doing so, it (re)wires the
emerging 6G world brain comprising interacting human and
cyberfungi active inference agents. Note that social norms act
as entropy-reducing devices for humans pursuing a desirable
purpose by reducing behavioral chaos, as intended by active
inference as normative framework to characterize Bayes-optimal
behavior.
Figure 8 demonstrates the beneficial role our cyberfungi play
in acting as brokers of cyborganic entanglement and mediating
mutually beneficial human-AI interactions. In general, an infor-
mation cascade is needed to create all sorts of collective behavior
outbreak, whereby small-world networks are particularly suited
5NetworkX is a Python package that lets users create, manipulate, and study the
structure, functions, and dynamics of complex networks, whose nodes and edges
can be attributed with arbitrary data (e.g., weights or time series). For further
details, please visit: https://networkx.org.
Research Article Journal of Optical Communications and Networking 12
Fig. 8. Impact of cyberfungi generative model on entropy,
which denotes the average surprise that needs to be mini-
mized in active inference: Adopted DDPM allows to create
not only an increase in entropy (diffusion) but also decrease
or reverse-time entropy (denoising), which may be viewed
as negative entropy living organisms feed upon (see Erwin
Schrödinger in Section 3.B). The forward diffusion process
of DDPM is adopted to biomimic the branching process and
exploratory, irregular tendency of hyphae, while the backward
denoising process of DDPM is adopted to to biomimic the
fusing and homing process of hyphae for the hallucination of
complex mycelium-like network structures.
to foster social contagion. The x-axis of Fig. 8 depicts the num-
ber of diffusion steps of the forward process (i.e., from left to
right) and the number of hallucination steps of the backward
process (i.e., from right to left), respectively. For illustration,
let us consider a regular 64-node ring lattice that the adopted
DDPM diffuses into a random network by increasing its entropy
(disorder). We assume that initially only one node, connecting
a single human or a cluster of multiple humans to the network,
adapts a desirable new social norm (e.g., planting trees). A node
that is directly linked to that initial node copies the new social
norm with spreading probability r ∈ {0.5, 0.75, 1.0}during each
time unit. The left-hand y-axis denotes the required number of
time units it takes until the new social norm propagates through-
out the entire population of all 64 nodes as a function of diffu-
sion/hallucination steps. Figure 8 depicts that the initial regular
64-node ring lattice (without any diffusion/hallucination) re-
quires up to 25 time units, depending on the value of r. Clearly,
for increasing r the number of required time units decreases,
reaching 16 time units for r = 1.0. The diffusion forward process
reduces the number of required time units until it reaches the
minimum of 2 after roughly 500 diffusion steps for all values of
r. Interestingly, in the backward process, the cyberfungi halluci-
nate scale-free networks with small-world properties such that
the number of required time units to achieve social contagion of
all nodes remains constantly low at the minimum of 2, indepen-
dently of the actual value of spreading probability r. This is due
to the superior wiring efficiency of the hallucinated small-world,
scale-free networks favoring social contagion.
While the spreading of a desirable new social norm may be
viewed as a value per se, the right-hand y-axis of Fig. 8 de-
notes the number of actuated teleological tokens (cybernetic
spores) each pair of nodes receives from our cyberfungi genera-
tive model as a reward for adopting the new social norm. That
is, each pair of directly linked nodes that successfully spread the
social norm for a given value ofr is reciprocally rewarded with a
couple of teleological tokens, one for each node. Figure 8 shows
that the forward diffusion process increases the number of ac-
tuated teleological tokens until it reaches a certain maximum,
which differs for varying values of r. Note that the initial reg-
ular 64-node ring lattice (without any diffusion/hallucination)
yields a rather small number of actuated teleological tokens of
roughly 300 or less. Conversely, the backward hallucination pro-
cess is able to achieve a significantly larger number of actuated
teleological tokens up to almost 2,500 for r = 1.0, thus clearly
demonstrating a significantly increased number of embodied AI
actions entreating the physical more-than-cyberfungal realm.
7. CONCLUSIONS
To cope with the unprecedented growth in complexity of today’s
networks, two opposing paradigm shifts have been emerging.
One perceives AI/ML techniques as a paradigm shift that allows
us to discover hidden relations by inferring, from data obtained
by various types of monitors, useful characteristics that could
not be easily or directly measured (see excellent overview in [6]
for details). However, this approach may eventually backfire
since AI/ML adds yet another man-made layer to our man-made
networks, potentially further increasing their overall complexity,
especially in light of unresolved open key AI challenges related
to training, learning, and explainability. More importantly, to-
day’s passive AI is profoundly lacking the key elements found in
living intelligent systems. Conversely, the alternative paradigm
shift of active inference not only resolves the open key AI chal-
lenges but also advocates anactive AI that views today’s complex
networks as living organisms rather than man-made machines.
This paper introduced the biomimetic mathematical frame-
work of active inference as a key to true AI and 6G world brain
by bridging the gap between artificial and natural intelligence.
We showed which role Charles Darwin’s “root-brain” hypoth-
esis, which has been forgotten in the literature until 2005, may
play in advanced human-AI interaction of natural and artifi-
cial intelligences networked into a cyber-physical ecosystem
premised on active inference. Further, we elaborated on the
free-energy principle as a unifying theory of brain, life, and be-
havior as well as Markov blanketed systems found in nature for
the interface design of active inference agents and their meta-
morphosis, while paying close attention to the central role of
entropy in knitting our own socio-technological cocoon for the
genesis and evolution of homo technicus, a human species that
lives in symbiosis with emerging AIs. We demonstrated how to
tackle the central challenge of active inference by developing a
generative model that does not emulate the human brain, but
describes the problem at hand: Modelling alternative futures
for the human-AI co-evolution of homo technicus to become
a metamorphic agent of the future 6G world brain, where AI
neurons are replaced with humans and cybernetic organisms.
In the new Age of AI, the authors of [5] – including the two
eminent technologists Craig Mundie (former chief research and
strategy officer of Microsoft) and Eric Schmidt (former CEO and
chairman of Google) – argue that the best path forward for the
development of machine intelligence depends on whether AI’s
structures continue to resemble the structures of the human brain
or whether “the human brain, therefore, becomes not the goal, and
not a blueprint, but a midpoint and an inspiration toward something
greater.” The 6G world brain?
Research Article Journal of Optical Communications and Networking 13
ACKNOWLEDGEMENT
The author would like to thank Nika Hosseini for her contribu-
tion to the numerical work.
FUNDING
Natural Sciences and Engineering Research Council of Canada
(NSERC) (Discovery Grant 2021-03224).
REFERENCES
1. M. Maier, “From Artificial Intelligence to Active Inference: “Natural
Intelligence” – the Future of AI-Native 6G [Invited],” in Optical Fiber
Communications Conference, (OPTICA, 2025), pp. 1–3.
2. S. Raviv, “The Genius Neuroscientist Who Might Hold the Key to True
AI,” WIRED 26, 1–20 (2018).
3. T. Parr, G. Pezzulo, and K. J. Friston,Active Inference: The Free Energy
Principle in Mind, Brain, and Behavior (The MIT Press, 2022).
4. J. Haidt, The Anxious Generation: How the Great Rewiring of Child-
hood Is Causing an Epidemic of Mental Illness (Penguin Press, 2024).
5. H. A. Kissinger, C. Mundie, and E. Schmidt, Genesis: Artificial Intelli-
gence, Hope, and the Human Spirit (John Murray, 2024).
6. F . Musumeci, C. Rottondi, A. Nag, I. Macaluso, D. Zibar, M. Ruffini,
and M. Tornatore, “An Overview on Application of Machine Learning
Techniques in Optical Networks,” IEEE Commun. Surv. & Tutorials21,
1383–1408 (2019).
7. C. Natalino, A. Panahi, N. Mohammadiha, and P . Monti, “AI/ML-as-
a-Service for optical network automation: use cases and challenges
[Invited],” J. Opt. Commun. Netw. 16, A169–A179 (2024).
8. H. Wang et al., “Scientific discovery in the age of artificial intelligence,”
Nature. 620, 47–60 (2023).
9. Ericsson, “Co-creating a cyber-physical world,” White Paper GFTL-
24:000856 Uen (2024).
10. M. Maier, A. Ebrahimzadeh, A. Beniiche, and S. Rostami, “The Art
of 6G (TAO 6G): how to wire Society 5.0 [Invited],” J. Opt. Commun.
Networking, OFC 2021 Special Issue 14, A101–A112 (2022).
11. Iain Morris, “Orange is working on an AI network ‘brain’ to run 5G,”
Light Reading (2025).
12. W. Tong and G. Y . Li, “Nine Challenges in Artificial Intelligence and
Wireless Communications for 6G,” IEEE Wirel. Commun. 29, 140–145
(2022).
13. E. C. Strinati, S. Barbarossa, J. L. Gonzalez-Jimenez, D. Ktenas,
N. Cassiau, and L. Maret, “6G: The Next Frontier: From Holographic
Messaging to Artificial Intelligence Using Subterahertz and Visible Light
Communication,” IEEE Veh. Technol. Mag.14, 42–50 (2019).
14. G. Buzsáki, The Brain From Inside Out (Oxford University Press, 2019).
15. R. D. Fields, “White Matter Matters,” Sci. Am. 298, 42–49 (2008).
16. Y . LeCun, K. Friston, and O. Oullier, “Beyond the Hype Cycle: What
AI is Today, and What It Can Become,” World Economic Forum (WEF)
(2024).
17. K. Friston, “The free-energy principle: a unified brain theory?” Nat.
Rev. Neurosci. 11, 127–138 (2010).
18. E. Schrödinger, What is Life? (Cambridge University Press, 1968).
19. M. J. D. Ramstead, P . B. Badcock, and K. J. Friston, “Answering
Schrödinger’s question: A free-energy formulation,” Phys. Life Rev.
24, 1–16 (2018).
20. K. J. Friston et al., “Designing ecosystems of intelligence from first
principles,” Collect. Intell. 3, 1–19 (2024).
21. R. Murray-Smith, J. H. Williamson, and S. Stein, “Active Inference and
Human-Computer Interaction,” arXiv:2412.14741 (2024).
22. G. Pezzulo, T. Parr, and K. Friston, “Active inference as a theory of
sentient behavior,” Biol. Psychol. 186, 1–9 (2024).
23. R. Smith, K. J. Friston, and C. J. Whyte, “A step-by-step tutorial on
active inference and its applications to empirical data,” J. Math. Psychol.
107, 1–60 (2022).
24. J. Pearl, Probabilistic Reasoning in Intelligent Systems: Networks of
Plausible Inference (Morgan Kaufmann Publishers Inc., 1988).
25. M. Kirchhoff, T. Parr, E. Palacios, K. Friston, and J. Kiverstein, “The
Markov blankets of life: autonomy, active inference and the free energy
principle,” J. Royal Soc. Interface186, 1–9 (2018).
26. A. Clark, Philosophy and Predictive Processing, 3 (MIND Group, Frank-
furt am Main, Germany, 2017), chap. How to Knit Y our Own Markov
Blanket: Resisting the Second Law with Metamorphic Minds, pp. 1–19.
27. Oleg Solopchuk, “Tutorial on Active Inference,” Medium (2018).
28. A. Paul, N. Sajid, L. D. Costa, and A. Razi, “On efficient computation in
active inference,” Expert. Syst. With Appl. 253, 1–14 (2024).
29. K. Friston, T. FitzGerald, F . Rigoli, P . Schwartenbeck, J. O. Doherty,
and G. Pezzulo, “Active inference and learning,” Neurosci. Biobehav.
Rev. 68, 862–879 (2016).
30. D. Read, “The ties that bind,” Nature. 388, 517–518 (1997).
31. J. Whitfield, “Underground networking,” Nature. 449, 136–138 (2007).
32. S. W. Simard, D. A. Perry, M. D. Jones, D. D. Myrold, D. M. Durali,
and R. Molina, “Net transfer of carbon between ectomycorrhizal tree
species in the field,” Nature. 388, 579–582 (1997).
33. J. Karst, M. D. Jones, and J. D. Hoeksema, “Positive citation bias and
overinterpreted results lead to misinformation on common mycorrhizal
networks in forests,” Nat. Ecol. & Evol.7, 501–511 (2023).
34. F . Balu˘ska, S. Mancuso, D. Volkmann, and P . W. Barlow, “The ‘root-
brain’ hypothesis of Charles and Francis Darwin: Revival after more
than 125 years,” Plant Signal. & Behav.4, 1121–1127 (2009).
35. A. Pentland, Social Physics: How Good Ideas Spread—The Lessons
from a New Science (Penguin Press, 2014).
36. M. Borders, The Social Singularity: A Decentralist Manifesto (Social
Evolution, 2018).
37. M. Maier, N. Hosseini, and M. Soltanshahi, “INTERBEING: On the
Symbiosis Between INTERnet and Human BEING,” IEEE Consumer
Electron. Mag. 13, 98–106 (2024).
38. S. H. Strogatz, Sync: The Emerging Science of Spontaneous Order
(Theia, 2003).
AUTHOR BIOGRAPHY
Martin Maier is a full pro-
fessor with INRS, Montréal,
Canada. He was educated at
the Technical University of
Berlin, Germany, and received
MSc and PhD degrees both
with distinctions (summa
cum laude) in 1998 and 2003,
respectively. In 2003, he
was a postdoc fellow at the
Massachusetts Institute of
Technology (MIT), Cambridge,
MA. He was a visiting pro-
fessor at Stanford University,
Stanford, CA, 2006 through
2007. He was a co-recipient
of the 2009 IEEE Communi-
cations Society Best Tutorial Paper Award. Further, he was
a Marie Curie IIF Fellow of the European Commission from
2014 through 2015. In 2017, he received the Friedrich Wilhelm
Bessel Research Award from the Alexander von Humboldt
(AvH) Foundation in recognition of his accomplishments in
research on FiWi-enhanced mobile networks. In 2017, he
was named one of the three most promising scientists in
the category “Contribution to a better society” of the Marie
Sklodowska-Curie Actions (MSCA) 2017 Prize Award of the
European Commission. In 2019/2020, he held a UC3M-Banco
de Santander Excellence Chair at Universidad Carlos III de
Madrid (UC3M), Madrid, Spain. Recently, in December 2023,
he was awarded with the 2023 Technical Achievement Award
Research Article Journal of Optical Communications and Networking 14
of the IEEE Communications Society (ComSoc) Tactile Internet
Technical Committee for his contribution on 6G/Next G and
the design of Metaverse concepts and architectures as well
as the 2023 Outstanding Paper Award of the IEEE Computer
Society Bio-Inspired Computing STC for his contribution
on the symbiosis between INTERnet and Human BEING
(INTERBEING). Based on Stanford University’s list of “World’s
Top 2%” most cited scientists, he ranks among the top 2% of
all scientists worldwide and has been recently awarded 2024
Highly Ranked Scholar Lifetime status by ScholarGPS as #2
worldwide in the area of access network (top 0.05%). He is
co-author of the book “Toward 6G: A New Era of Convergence”
(Wiley-IEEE Press, January 2021) and author of the sequel
“6G and Onward to Next G: The Road to the Multiverse”
(Wiley-IEEE Press, February 2023).