Bounded rationality for relaxing best response and mutual
consistency: The Quantal Hierarchy model of decision-making
Benjamin Patrick Evans∗ Mikhail Prokopenko
Centre for Complex Systems, The University of Sydney, Sydney, NSW 2006, Australia
Abstract
While game theory has been transformative for decision-making, the assumptions made can be
overly restrictive in certain instances. In this work, we investigate some of the underlying assump-
tions of rationality, such as mutual consistency and best response, and consider ways to relax these
assumptions using concepts from level- k reasoning and quantal response equilibrium (QRE) respec-
tively. Speciﬁcally, we propose an information-theoretic two-parameter model called the Quantal
Hierarchy model, which can relax both mutual consistency and best response while still approximat-
ing level-k, QRE, or typical Nash equilibrium behavior in the limiting cases. The model is based
on a recursive form of the variational free energy principle, representing higher-order reasoning as
(pseudo) sequential decision-making in extensive-form game tree. This representation enables us to
treat simultaneous games in a similar manner to sequential games, where reasoning resources deplete
throughout the game-tree. Bounds in player processing abilities are captured as information costs,
where future branches of reasoning are discounted, implying a hierarchy of players where lower-level
players have fewer processing resources. We demonstrate the eﬀectiveness of the Quantal Hierarchy
model in several canonical economic games, both simultaneous and sequential, using out-of-sample
modelling.
1 Introduction
A crucial assumption made in Game Theory is that all players behave perfectly rationally. Nash Equi-
librium (Nash, 1951) is a key concept that arises based on all players being rational and assuming other
players will also be rational, requiring correct and consistent beliefs amongst players. However, despite
being the traditional economic assumption, perfect rationality is incompatible with many human pro-
cessing tasks, with models of limited rationality better matching human behaviour than fully rational
models (G¨ achter, 2004; Camerer, 2010; Gabaix et al., 2006). Further, if an opponent is irrational, then it
would be rational for the subject to play “irrationally” (Raiﬀa and Luce, 1957). That is, “[Nash equilib-
rium] is consistent with perfect foresight and perfect rationality only if both players play along with it.
But there are no rational grounds for supposing they will” (Koppl and Barkley Rosser Jr, 2002). These
assumptions of perfect foresight and rationality often lead to contradictions and paradoxes (Cournot,
1838; Morgenstern, 1928; Hoppe, 1997; Glasner, 2020).
Alternate formulations have been proposed that relax some of these assumptions and model bound-
edly rational players, better approximating actual human behaviour and avoiding some of these para-
doxes (Simon, 1976). For example, relaxing mutual consistency allows players to form diﬀerent beliefs of
other players (Stahl and Wilson, 1995; Camerer et al., 2004) avoiding the inﬁnite self-referential higher-
order reasoning which emerges as the result of interaction between rational players (Knudsen, 1993)
(I have a model of my opponent who has a model of me ... ad inﬁnitum (Morgenstern, 1935)) and
non-computability of best response functions (Rabin, 1957; Koppl and Barkley Rosser Jr, 2002). The
ability to break at various points in the higher-order reasoning chain can be considered as “partial self-
reference” (L¨ ofgren, 1990; Mackie, 1971). Importantly, rather than implicating negation (Prokopenko
et al., 2019), this type of self-reference represents higher-order reasoning as a logically non-contradictory
chain of recursion (reasoning about reasoning...). Hence, bounded rationality arises from the ability to
break at various points in the chain, discarding further branches. “Breaking” the chain on an other-
wise potentially inﬁnite regress of reasoning about reasoning can be seen as the players limitations in
information processing, determining when to end the recursion.
∗benjamin.evans@sydney.edu.au
1
arXiv:2106.15844v5  [cs.GT]  15 Mar 2023
Another example of bounded rationality based on information processing constraints is the relaxation
of the best response assumption of players, which allows for erroneous play, with deviations from the
best response governed by a resource parameter (Haile et al., 2008; Goeree et al., 2005).
In this work, we adopt an information-theoretic perspective on reasoning (decision-making). By
enforcing potential constraints on information processing, we are able to relax both mutual consistency
and best response, and hence, players do not necessarily act perfectly rational. The proposed approach
provides an information-theoretic foundation for level- k reasoning and a generalised extension where
players can make errors at each of the k levels.
Speciﬁcally, in this paper, we focus on three main aspects:
• Players reasoning abilities decrease throughout recursion in a wide variety of games, motivating an
increasing error rate at deeper levels of recursion. That is, it becomes more and more diﬃcult to
reason about reasoning about reasoning ... (necessitating a relaxation in best response decisions).
• Finite higher-order reasoning can be captured by discounting future chains of recursion and ul-
timately discarding branches once resources run out. This representation introduces an implicit
hierarchy of players, where a player assumes they have a higher level of processing abilities than
other players, motivating relaxation of mutual consistency.
• Existing game-theoretic models can be explained and recovered in limiting cases of the proposed
approach. This ﬁlls an important gap between methods relaxing best response and methods relaxing
mutual consistency.
The proposed approach features only two parameters, β and γ, where β quantiﬁes relaxation of
players’ best response, and γ governs relaxation of mutual consistency between players. In the limit,
β →∞ best response can be recovered, and in the limit γ = 1 mutual consistency can be recovered.
Equilibrium behaviour is recovered in the limit of both β →∞,γ = 1. For other values of β and γ,
interesting out-of-equilibrium behaviour can be modelled which concurs with experimental data, and
furthermore, in repeated games that converge to Nash equilibrium, player learning can be captured in
the model with increases in β and γ. Importantly, we also show how ﬁtted values of β and γ also
generalise well to out-of-sample data.
The remainder of the paper is organised as follows. Section 2 analyses bounded rationality in the
context of decision-making and game theory, Section 3 introduces information-theoretic bounded rational
decision-making, Section 4 extends the idea to capture higher-order reasoning in game theory. We then
use canonical examples highlighting the use of information-constrained players in addressing bounded
rational behaviour in games in Section 5. We draw conclusions and outline future work in Section 6.
2 Background and Motivation
While a widespread assumption in economics, perfect rationality is incompatible with the observed
behaviour in many experimental settings, motivating the use of bounded rationality (Camerer, 2011).
Bounded rationality oﬀers an alternative perspective, by acknowledging that players may not have a
perfect model of each other or may not play perfectly rationally. In this section, we explore some
common approaches to modelling bounded rational decision-making.
2.1 Mutual Consistency
Equilibrium models assume mutual consistency of beliefs and choices (Camerer et al., 2003; Camerer,
2003), however, this is often violated in experimental settings (Polonio and Coricelli, 2019) where “dif-
ferences in belief arise from the diﬀerent iterations of strategic thinking that players perform” (Chong
et al., 2005).
Level-k reasoning (Stahl and Wilson, 1995) is one attempt at incorporating bounded rationality by
relaxing mutual consistency, where players are bound to some levelkof reasoning. A player assumes that
other players are reasoning at a lower level than themselves, for example, due to over-conﬁdence. This
relaxes the mutual consistency assumption, as it implicitly assumes other players are not as advanced
as themselves. Players at level 0 are not assumed to perform any information processing, and simply
choose uniformly over actions (i.e., a Laplacian assumption due to the principle of insuﬃcient reason),
although alternate level-0 conﬁgurations can be considered (Wright and Leyton-Brown, 2019). Level-1
players then exploit these level-0 players and act based on this. Likewise, level-2 players act based on
2
other players being level-1, and so on and so forth for level- k players acting as if the other players are at
level-(k−1). Various extensions have also been proposed (Levin and Zhang, 2019).
A similar approach to level- k is that of Cognitive Hierarchies (CH) (Camerer et al., 2004), where
again it is assumed other players have lower reasoning abilities. However, rather than assuming that the
other players are at k−1, players can be distributed across the klevels of cognition according to Poisson
distribution with mean and variance τ. The validation of the Poisson distribution has been provided
in Chong et al. (2005), where an unconstrained general distribution oﬀered only marginal improvement.
Again, various extensions have been proposed (Chong et al., 2016; Koriyama and Ozkes, 2021) and there
are many examples of successful applications of such depth-limited reasoning in literature, for example,
Goldfarb and Xiao (2011).
Endogenous depth of reasoning (EDR) is a similar approach to level- k and CH, but it separates the
player’s cognitive bounds from their beliefs of their opponent’s reasoning (Alaoui and Penta, 2016). EDR
captures player reasoning as if they are following a cost-beneﬁt analysis (Alaoui and Penta, 2022), with
cognitive abilities (costs) and payoﬀs (beneﬁts).
One fundamental similarity across these methods is that they all maintain best-response. That is,
they best respond based on the lower-level play assumptions. The following section introduces methods
that instead maintain mutual consistency, but relax the best-response assumption.
2.2 Best response
Alternate approaches assume that a player may make errors when deciding which strategy to play, rather
than playing perfectly rationally. That is, they relax the best response assumption. Quantal Response
Equilibrium (McKelvey and Palfrey, 1995, 1998) (QRE) is a well-known example, where rather than
choosing the best response with certainty, players choose noisily based on the payoﬀ of the strategies
and a resource parameter controlling this sensitivity. Another method of capturing this erroneous play
is Noisy Introspection (Goeree and Holt, 2004). Utility proportional beliefs (Bach and Perea, 2014) is
another method that relaxes the best response assumption, where the authors note that “possibly, the
requirement that only rational choices are considered and zero probability is assigned to any irrational
choice is too strong and does not reﬂect how real world [players] reason”, giving merit to the relaxation of
best-response. By allowing for errors in decision-making, these methods oﬀer a more realistic perspective
on how individuals make choices.
2.3 Inﬁnite-Regress
When considering reasoning about reasoning, inﬁnite regress can emerge Knudsen (1993). The problem
of inﬁnite regress can be formulated as a sequence
A,f(A),f(f(A)),f(f(f(A)))
where the player is ﬁrst confronted with an initial choice of an action a from the set of actions A, or a
computation f(A). If the action is chosen, the decision process is complete. If, instead, the computation
is chosen, the outcome of f(A) must be calculated, and the player is then faced with another choice
between the obtained result or yet another computation. This process is repeated until the player
chooses the result, as opposed to performing an additional computation. Lipman (1991) investigates
whether such sequence converges to a ﬁxed point. A similar approach by Mertens and Zamir (1985)
formally approximates Harsanyi’s inﬁnite hierarchies of beliefs (Harsanyi, 1967, 1968) with ﬁnite states.
2.4 Contributions of our work
In contrast to existing works, we propose an information-theoretic approach to higher-order reasoning,
where each level or hierarchy corresponds to additional information processing for the player. While
Alaoui and Penta (2016) capture the trade-oﬀ between additional reasoning and payoﬀ, by measuring
the ﬁrst intersection of the players’ payoﬀ improvement (fromkto k+1), and the cost of performing this
additional reasoning c(k+ 1). This cost function chas to be determined (for all c(k)), for example, with
maximum likelihood estimation to estimate the average cost of performing this extra level of reasoning
(Alaoui and Penta, 2022). In contrast, we propose capturing this trade-oﬀ with information processing
costs by using the Kullback-Leibler divergence to constrain the overall change in action probabilities at
each stage of reasoning.
3
Our approach constrains the overall amount of information processing available to the players, leading
to potential errors at each stage of reasoning, which is not present in existing level- k type approaches.
By doing so, we establish a foundation for “breaking” the chain of higher-order reasoning based on the
depletion of players’ information processing resources.
This results in a principled information-theoretic explanation for decision-making in games involving
higher-order reasoning. Best response is relaxed with β <∞(linking to Quantal Response Equilibrium)
and mutual consistency is relaxed with γ <1 (linking to level-ktype models). Best response and mutual
consistency are recovered with β →∞ and γ = 1. This contributes to the existing literature on game
theory and decision-making by adopting an information-theoretic perspective on bounded rationality,
quantiﬁed by information processing abilities. A key beneﬁt of the proposed approach is while level- k
models relax mutual consistency, but retain best response, and QRE models relax best response but retain
mutual consistency (Chong et al., 2005), the proposed approach is able to relax either assumption through
the introduction of two tunable parameters. We apply this model to various games, demonstrating the
usefulness of the proposed approach for capturing human behaviour when compared to these existing
approaches.
3 Technical Preliminaries: Information-Theoretic Bounded Ra-
tionality
Information theory provides a natural way to reason about limitations in player cognition, as it abstracts
away speciﬁc types of costs (Wolpert, 2006; Harr´ e, 2021). This means that we can assume the existence of
cognitive limitations without speculating about the underlying behavioural foundations. As pointed out
by Sims (2003), an information-theoretic treatment may not be desirable for a psychologist, as this does
not give insights to where the costs arise from, however, for an economist, reasoning about optimisation
rather than speciﬁc psychological details may be preferable, for example, in the Shannon model (Caplin
et al., 2019). Such models have seen considerable success in a variety of areas for information processing,
for example, embodied intelligence (Polani et al., 2007), self-organisation (Ay et al., 2012) and adaptive
decision-making of agents (Tishby and Polani, 2011) based on the information bottleneck formalism
(Tishby et al., 1999).
In this work, we adopt the information-theoretic representation of bounded rational decision-making
proposed by Ortega and Braun (2013), which has been further developed in (Ortega and Braun, 2011;
Braun and Ortega, 2014; Ortega and Stocker, 2016; Gottwald and Braun, 2019). This approach has
a solid theoretical foundation based on the (negative) free energy principle and has been successfully
applied to several tasks (Evans and Prokopenko, 2021). We begin by providing an overview of single-
step decisions and then sequential decisions, before discussing extensions for capturing the relationship
between processing limitations and higher-order reasoning.
3.1 Single-step Decisions
A boundedly-rational decision maker who is choosing an action a ∈A with payoﬀ U[a] is assumed to
follow the following negative free energy diﬀerence when moving from a prior belief p[a], e.g., a default
action, to a (posterior) choice f[a], given by:
−∆F[f[a]] =
∑
a∈A
f[a]U[a] −1
β
∑
a∈A
f[a] log
(f[a]
p[a]
)
(1)
The ﬁrst term represents the expected payoﬀ, while the second term represents a cost of information
acquisition that is regularised by the parameter β. Formally, the second term quantiﬁes information
acquisition as the Kullback-Leibler (KL) divergence from the prior belief p[a]. Parameter β, therefore,
serves as the resource allowance for a decision-maker.
By taking the ﬁrst order conditions of Eq. (1) and solving for the decision function f[a], we obtain
the equilibrium distribution:
f[a] = 1
Zp[a]eβU[a] (2)
where Z = ∑
a′∈Ap[a′]eβU[a′,x] is the partition function. This representation is equivalent to the logit
function (softmax) commonly used in QRE models, and relates to control costs derived in economic
literature (Stahl, 1990; Mattsson and Weibull, 2002).
4
The parameter β serves as a resource allowance for the decision-maker, modulating the cost of in-
formation acquisition from the prior belief. Low values of β correspond to high costs of information
acquisition (and high error play), while as β →∞, information becomes essentially free to acquire, and
the perfectly rational homo economicus player is recovered.
3.2 Sequential Decisions
This free energy deﬁnition can be extended to sequential decision-making by considering a recursive
negative free energy diﬀerence, as described in (Ortega and Braun, 2013, 2014). This corresponds to
a nested variational problem, and involves introducing new inverse temperature parameters βk for K
sequential decisions, which allows for diﬀerent reasoning at diﬀerent depths of recursion to choose a
sequence of K actions a≤K.
Therefore, for sequential decision-making, Eq. (1) can be represented as:
−∆F[f] =
∑
a≤K
f[a≤K]
K∑
k=1
(
U[ak |a<k] − 1
βk
log f[ak |a<k]
p[ak |a<k]
)
(3)
where a<k abbreviates the history ao,..,a k−1 of decisions. We can expand the sum:
=
∑
a1
f[a1]
(
U[a1] − 1
β1
f[a1] log f[a1]
p[a1] +
∑
a2
f[a2 |a1]
(
U[a2 |a1] − 1
β2
f[a2 |a1] log f[a2 |a1]
p[a2 |a1] +
...
+
∑
aK
f[aK |a<K]
(
U[aK |a<K] − 1
βK
f[aK |a<K] log f[aK |a<K]
p[aK |a<K]
))
(4)
which we can see as ﬁrst choosing an action a1 at k = 1, while considering that in order to choose this
action, we must consider the future stages by analysing the result at k = 2 given the choice a1, and so
forth. To compute this, we can solve the innermost sum ﬁrst:
f[aK |a<K] = 1
ZK
p[aK |a<K]eβKU[aK|a<K] (5)
which recovers Eq. (2) with the introduction of conditioning on decision histories. This represents the
base-case for recursion. For steps where k <K, we get the following equilibrium solution for sequential
decisions:
f[ak |a<k] = 1
Zk
p[ak |a<k] exp
(
βk(U[ak |a<k] + 1
βk+1
log Zk+1)
)
= 1
Zk
p[ak |a<k]  
Prior Belief
× Zβk/βk+1
k+1  
Future Contribution
×eβkU[ak|a<k]
  
Current Payoﬀ
(6)
where decisions are now dependent on the history of decisions as well as on a recursive component based
on the future contribution of each decision. Here
Zk =
∑
ak
p[ak |a<k]Zβk/βk+1
k+1 eβkU[ak|a<k] (7)
where ZK = 1, i.e., the base-case for recursion at the ﬁnal level.
3.3 Extension
With this formal and generic treatment of information-processing costs for sequential decision-making,
it is desirable to use this to capture bounded rational reasoning of an agent making sequential or simul-
taneous decisions in games. By representing reasoning as an extensive-form game tree, these two can
be captured in a similar manner. Simultaneous decisions can be treated as if they are pseudo-sequential
decisions, considering possible repercussions for various choices.
5
To model higher-order reasoning, we extend the information-theoretic formulation for sequential de-
cisions discussed in Section 3.2. This involves representing reasoning as a (pseudo) sequence of decisions,
where each decision corresponds to a ”level” of reasoning. At each level, players may play incorrectly,
producing a level- k play that is modulated by βk. A high βk corresponds to an exact level- k thinker,
while a low βk corresponds to an error-prone level- k thinker. We can formalise this chain of reasoning
as an extensive-form game tree, where at the root node, a player is faced with a decision to choose from
a set of available options A or perform additional processing f(A) to acquire new information on the
beliefs and repercussions of each choice. If the player chooses not to process additional information, each
branch is terminated early, and the player makes a decision based solely on the immediately available
information. However, if the player chooses to process additional information, each action branch is (po-
tentially) extended to analyze the possible repercussions of taking an action, and a higher level thinker
can examine these repercussions. This process continues until the player runs out of processing resources
or, in a ﬁnite problem, converges to a solution. For example, in the p-beauty contest analyzed in later
sections, convergence occurs once the guess hits 0.
This extensive-form game tree representation means reasoning about simultaneous decisions can
be treated in the same manner as decisions in sequential games. However, the key issue here is the
requirement of Eq. (6) to have K information processing parameters for each step or level of reasoning.
In order to analyse the purpose of these parameters, we consider a simple case, setting βk = β for all k,
giving discrete control (Braun et al., 2011):
f[ak |x,a<k] = 1
Zk
p[ak |a<k]Zk+1eβU[ak,x|a<k] (8)
which clariﬁes that the boundedness applies to the computation of payoﬀU, but the depth of reasoning (or
recursion-depth) is dependent on the length of the sequence (or level) K, not on β. To represent higher-
order reasoning more succinctly, it would be desirable to implicitly base the sequence length K on the
resource parameter βrather than keeping them separate. This would allow us to treat recursive reasoning
in information-theoretic terms. For instance, when β →∞, K →∞, which captures (potential) inﬁnite-
regress, while β = 0 would imply K = 0, leaving the player with no information processing abilities.
In order to achieve this, β must be reduced at each level k. This reduction in β at each level
is related to the relaxation of mutual consistency, reﬂecting how a player perceives other (lower-level)
players’ reasoning about the problem. In the next section, we outline our proposed approach for modelling
this. This extension allows us to reason directly about resource constraints instead of sequential level- k
thinking.
4 Proposed Approach
The proposed approach implicitly enforces the assumption that, in sequential games, it becomes more
diﬃcult to reason to later stages in the game (e.g. in chess, it is diﬃcult to reason 5 steps-ahead), and
likewise in simultaneous games, it is diﬃcult to perform the level of higher-order reasoning required to
arrive at the equilibrium solution. The further a player mentally tries to reason, the more likely an error
is to occur, as the processing resources deplete. This assumption is captured under the proposed model
in a generic information-theoretic sense.
The key concept is that it becomes more diﬃcult to reason about reasoning, that is the further one
tries to explore through the extensive-form tree. This overall process is visualised Fig. 1, where the
players reasoning error increases throughout the steps of reasoning. This representation can be thought
of as a hierarchy of players noisily responding to lower level players, or as a sequential decision with
increasing noise at each step. Once a player’s resources deplete, the later depths simply echo the prior
beliefs as the noise obstructs the payoﬀs.
4.1 Quantal Hierarchy Model
To model higher-order reasoning with processing costs, we propose a more ﬂexible and succinct ap-
proach than simply setting a maximum depthK and corresponding parameters βk in a pseudo-sequential
decision-making task. Instead, we introduce an overall information processing parameter β, which cap-
tures the available information processing resources for a player, and a discount parameter γ ∈[0,1],
which controls the reduction in player rationality throughout the reasoning chain. This approach allows
for heterogeneous bounds on player reasoning, relaxing the assumptions of best response and mutual
6
Depth 1 Depth 2 Depth 3 Depth K...
Figure 1: The eﬀect of discounting resources over time. In the beginning, the player has β resources and
may make some error (red bars). Parameter γ controls how this error grows over time and, implicitly,
how the player believes lower-level players will respond. A low γ means the errors increase drastically
at each level, assuming opponents with much lower reasoning abilities. As βγk →0, the noise increases,
and the recursion eventually stops once the utilities become indistinguishable (i.e., the player can not
reason any deeper).
consistency. We refer to this approach as the Quantal Hierarchy (QH) model, as it shares formal sim-
ilarities with Quantal Response Equilibrium and Cognitive Hierarchy models, as discussed in previous
sections.
4.1.1 Formulation
We represent reasoning as information-constrained sequential decision-making. The proposed formula-
tion features only two parameters, β and γ ∈[0,1] (as opposed to the vector βk and number of levels
K). Reasoning resources are then set as
βk = βγk
i.e., βk is β discounted based on γ and the current depth of reasoning. This can be represented by the
following recursive free energy diﬀerence:
−∆F[f] =
∑
a≤K
f[a≤K]
∞∑
k=0
(
U[ak |a<k] − 1
βγk log f[ak |a<k]
p[ak |a<k]
)
(9)
where we have represented the sequence as an inﬁnite-sum. The sum converges due to the discount
parameter as the later (inner-most sums) simply echo the prior beliefs once the player’s computational
resources are exhausted. This formalisation draws parallels with the reinforcement learning (RL) meth-
ods, where such representations are common for reasoning about future states for the player. In RL, γ is
used to discount future timesteps. Here, γ is used to discount future chains of reasoning about reasoning
(i.e., the depth of recursion is governed by β discounted by γ), and to represent the limited resources
that we believe other players have. We have represented this as in inﬁnite sum with k→∞, however, in
various problems (such as sequential games) K can be assumed to be ﬁnite. The solution for the decision
function f[ak |a<k] with the discounted β becomes:
f[ak |a<k] =



1
Zk
p[ak |a<k]  
Prior Belief
, if βγk ≈0
1
Zk
p[ak |a<k]  
Prior Belief
×eβU[ak|a<k]
  
Current Payoﬀ
, if γ = 0
1
Zk
p[ak |a<k]  
Prior Belief
× Z1/γ
k+1
Future Contribution
×eβγkU[ak|a<k]
  
Current Payoﬀ
, otherwise
(10)
which aims to capture decisions based on the beliefs of other players reasoning at later stages. With the
assumption of a discount rate γ, we can see the recursion is now depth-bound based on the (discounted)
7
resource parameter. Once βγk →0 1, the recursion will stop since the result will simply echo the prior
belief as no focus will be placed on the payoﬀ, becoming the base case for recursion (the “naive” player).
This means that in the new implicit limit K 2 (denoted by the case where βk ≈0), reasoning about the
future provides no new information, which recovers the original form of Eq. (5) (when γ = 1) with the
introduction of conditioning on histories.
With the proposed representation, what was previously thought of in the context of sequential deci-
sions, can be extended and modiﬁed to think about hierarchies of beliefs. The informationally constrained
players “break” the chain of reasoning due to depleting their cognitive or computational capabilities as
bounded by β and γ. Formally, this is represented as a (potentially) inﬁnite-sum that converges based
on γ. By discounting future computation in a chain of recursion, we can approximate higher-order
reasoning, where players become increasingly limited as the reasoning chain progresses, making it more
challenging to reason about reasoning.
4.1.2 Parameters
Resource Parameter The resource parameter β quantiﬁes the amount of processing a player can
perform. Perfect utility maximisation behaviour is recovered with β →∞. With β <∞, players are
assumed to be limited in computational resources and must now balance the trade-oﬀ between their
computation cost and payoﬀ. With β →0, players have no processing resources, and choose based on
their prior beliefs (default actions). Anti-rational (or adversarial) play can be modelled with β →−∞.
Discount ParameterThe discount parameter γ quantiﬁes other players mental processing abilities
in terms of level- k thinking. A high γ assumes other players play at a relatively similar cognitive level,
whereas a low γ assumes other players have less playing ability. With γ <1, Eq. (10) is guaranteed to
converge to a ﬁnite sequence of decisions, where the ability to process information decreases the further
we get through the sequence. This captures the belief about play at later stages of reasoning, where other
players are assumed to be less rational (and thus, more noisy) as governed byγ. The case γ <1 implicitly
relaxes mutual consistency as lower-level thinkers are then governed by a lower resource parameter, and
allows for players to believe that players at later nodes behave more noisily. In the case of otherwise
inﬁnite regress (where backward induction can not be used), the limited foresight approach proposed
converges to a ﬁnite approximation of the sequence by relaxing the assumption of mutual consistency.
In tractable problems, we recover an approximation of backward induction where the player performing
such induction may make errors at each step due to limited computational processing abilities. With
γ = 1, we recover mutual consistency, as we assume other players are just as rational as ourselves, and in
the special case with uniform prior beliefs and γ = 1, we collapse to a logit form of agent QRE (McKelvey
and Palfrey, 1998; Turocy, 2010). The special case for γ = 0 exists in Eq. (10) as in this case, no future
processing will be performed.
In the limit, with β → ∞,γ = 1, perfect backward induction is recovered (see Appendix B.1).
Crucially, the proposed QH model allows for a general representation, relaxing the perfect rationality as-
sumption (with β <∞,γ <1), which can model out-of-equilibrium behaviour compatible with observed
experimental data. We explore the role of these parameter values in more detail in the following section.
Parameter Interactions In Fig. 2 we visualise how β and γ interact in a general setting. For
β → ∞and γ = 1, we approach payoﬀ maximisation behaviour, i.e., the perfectly rational (Nash
Equilibrium) player is recovered. For β →−∞ and γ = 1, payoﬀ minimisation behaviour (an adversarial
player) is recovered. In between, we can see how γ adjusts β. It is these values in between random play
(β = 0) and perfect payoﬀ maximisation behaviour which are particularly interesting, as they give rise
to out-of-equilibrium behaviour not predicted by traditional methods.
4.2 Explanation
We work through a generic example of the QH model on an extensive-form game tree. A player is
given decision-making resources, governed by β, to make a decision f. At each stage of reasoning k, the
player’s resources are discounted by γ. Ultimately, the player’s resources become depleted (at K, i.e.,
once βγk ≈0), and the game tree is considered terminated, and the naive player chooses based on their
prior belief (which we assume to be uniform). This decision is then propagated backwards, and becomes
the prior belief at the higher stage of reasoningp[aK−1], where the player has processing resourcesβγK−1,
and hence, noisily responds to the lower-level play based on these resources. This process is continued,
1e.g. when βγk <ϵ where ϵ is some small enough term where the payoﬀs become indistinguishable, here, ϵ= 10−8
2in contrast to level-k, here K indicates the level with the lowest resources
8
γ= 0 γ= 1
β→ ∞
β= 0
β→ − ∞
Anti Rational
Uniform
Perfectly Rational
Figure 2: A heatmap visualising the resulting players expected payoﬀ based on the values of β and γ.
The yellow colour represents the maximal expected payoﬀ, and the purple colour represents the minimum
expected payoﬀ. When either parameter is 0, the result is a random choice amongst the actions.
with noisy responses from the lower-level thinker captured by the resource constraint. Finally, once all
results have been recursively propagated, the higher-level players’ decision is made (which may still be
noisy, as captured by β). That is, their decision is made recursively, starting from the most basic level
of player reasoning (the naive player) and reasoning upwards.
4.2.1 Basic Example
To help illustrate the proposed approach, we will use a simpliﬁed version of the Ultimatum game (see
Appendix C.4) as a speciﬁc example. In this game, a player must decide what percentage of a pie to
take. We assume that there are uniform priors among the available options at each stage.
At the ﬁrst stage, Player 1 must request the percentage of the pie they want to take, denoted by
a1 ∈[0,100], with 100 giving the highest payoﬀ (i.e., they receive the entire pie). However, at the second
stage, Player 1 encounters a fairness calculator (Player 2). Player 2 decides whether or not to approve
Player 1’s request, denoted by A2 = {accept,reject}. The decisions are based on the following utilities:
U1[a1] = a1 ×f2[accept |a1]
U2[accept2 |a1] = 100 −a1
U2[reject2 |a1] = 50
(11)
where Un corresponds to Player n’s payoﬀ, and fn the probability with which Player n chooses the
action. A player who has no look-ahead, i.e., one who assigns zero weight to future decisions (or assumes
that their opponent has zero processing abilities), can be represented with β →∞ and γ = 0. Such a
player simply looks at the ﬁrst stage and sees that it is in their best interest to request 100% of the pie.
However, this player fails to take into account the repercussions of their chosen action, as they did not
consider the future decisions. They did not compute f2[a2 |a1], and thus assumed that f2[a2 |a1] is
uniform and that their opponent would be indiﬀerent to accepting or rejecting their request regardless
of the value of a1.
A perfectly rational player with unlimited computational resources, i.e., β = ∞and γ = 1, would
request 49 (assuming integer requests). They assign weight to the future of their actions, and can see
that for any a >50, the fairness calculator will deny their request, and they will be left with nothing
(at a= 50, the calculator will be indiﬀerent to accepting or rejecting their request). This corresponds to
the subgame perfect equilibrium, where the player performed backward induction. That is, the player
examined the future until they reached the end of the game and then reasoned backwards to request the
optimal choice.
A player with limited computational resources, i.e., β <∞, requests the best action they can subject
to their resource constraint. For example, they may only request a= 40, as they are unable to complete
the search for a= 49. A player with no information processing abilities, i.e., β = 0, cannot search for any
optimal choices and therefore chooses based on the prior distribution, which we assumed to be uniform.
Therefore, the player is equally likely to choose any a∈A.
An interesting question that arises is what if we assume that the ”fairness” calculator may make
errors, and that it is not necessarily deﬁned by a step function that rejects all requests above 50 and
9
accepts all below. For example, there may be a range where 100 will get rejected, but perhaps 75 would
not. This can be captured with βγ <∞, where the calculator is assumed to make errors for low values,
and for βγ → ∞, it is assumed to be perfectly rational. If the fairness calculator is broken and is
indiﬀerent to accepting or rejecting values, this can be represented with γ = 0, which gives 0 processing
ability to the calculator. This means f2[accept2 |a1] = f2[reject2 |a1] = 0.5, and therefore, a rational
Player 1 should request a1 = 100.
This example shows the usefulness of the proposed approach, and how modifying βand γ can capture
a variety of heterogeneous behaviours between the two players.
5 Results
In this section, we perform out-of-sample comparisons across various canonical economic games, including
both sequential and simultaneous games. We compare the proposed Quantal Hierarchy model against
well-known approaches to capturing bounded rational reasoning, including QRE, level- K and Cognitive
Hierarchy, as well as the Nash equilibrium predicted solutions. To assess the performance of each method,
we ﬁt the corresponding parameter values to experimental data and then evaluate the performance on
hold-out data. For the Quantal Hierarchy method, these parameter values are β and γ. For QRE, the
parameter value is λ, which serves a similar purpose as β in our approach, i.e., relaxing best response.
For level-k, the parameter value is the steps of reasoning k. For Cognitive Hierarchy, the parameter value
is τ, corresponding to the Poisson distribution of level- k thinkers. Further information on model ﬁtting
is given in Appendix A.
We show how the proposed approach convincingly captures human behaviour and generalises beyond
the training examples, outperforming existing approaches on a wide range of games.
5.1 Performance on Canonical Games
For this work, we use various experimental data from canonical economic sequential and simultaneous
games. Speciﬁcally, for simultaneous games, we analyse market entrance and beauty contest games, and
for sequential games, centipede, and bargaining games.
For market entrance games, we use the data of Camerer (2011), originally presented in (Sundali et al.,
1995). For the beauty contest game, we use p-beauty contest results from (Bosch-Domenech et al., 2002).
For the Centipede games, we use the four and six-level data from (McKelvey and Palfrey, 1992). For
the sequential bargaining games, we use the Ultimatum game and two-stage game from Binmore et al.
(2002) (Game 1 and 3 in their paper). Further discussion on game speciﬁcs, utilities, and experimental
analysis is given in Appendix C.
For each game, we perform 5x2 repeated cross-fold validation (Dietterich, 1998), analysing the out-
of-sample performance. This analysis ensures that the inclusion of an additional parameter does not
overﬁt to the original training data, and instead, ensures the approach generalises well to unseen data.
We present the average RMSE on the unseen data and the resulting rankings (Demˇ sar, 2006) of each
method in Table 1. The rankings account for the independence of the games, and the inability to
compare errors directly across game classes. A visualisation of the resulting ranks in Fig. 3. By using
these evaluation metrics, we are able to determine the eﬀectiveness of the proposed method in comparison
to existing approaches for predicting (out-of-sample) human behaviour on a range of canonical games.
The proposed Quantal Hierarchy method consistently performs well across the various games trialled,
resulting in the best (lowest) overall rank (Table 1), as well as the most consistent (narrowest distribution
of results, Fig. 3), always performing in the top 2. These results validate the modelling assumption that
it becomes more diﬃcult to reason at deeper levels of reasoning, and thus, the reasoning process becomes
more erroneous. This motivates the usage of the Quantal Hierarchy model for capturing human decision-
making in a wide-range of settings.
In the following subsections, we analyse the game results in more detail.
5.2 Simultaneous Games
Market Entrance In the market entrance game, players must simultaneously decide whether to enter
or stay out of a market, where the payoﬀ depends on the decisions of the other players and market
capacity c (see Appendix C.1). Experimental data show that player behaviour in market games is
inconsistent with either mixed or pure Nash equilibria, although, with repeated play, players begin to
approach the mixed strategy equilibrium (Duﬀy and Hopkins, 2005).
10
Quantal
Hierarchy Level-k Cognitive
Hierarchy
Quantal Response
Equilibrium Nash
Market EntranceBlock 1 0.565 (2) 1.503 (5) 0.725 (3) 0.564 (1) 1.242 (4)
Block 2 0.426 (1) 2.115 (5) 1.077 (4) 0.442 (2) 0.726 (3)
Block 3 0.387 (1) 2.230 (5) 1.283 (4) 0.406 (2) 0.548 (3)
Block 4 0.493 (2) 2.344 (5) 1.365 (4) 0.431 (1) 0.559 (3)
Block 5 0.489 (1) 2.513 (5) 1.387 (4) 0.519 (2) 0.574 (3)
Average Rank 1.4 5 3.8 1.6 3.2
Beauty ContestLab 0.020 (1) 0.191 (4) 0.175 (3) 0.027 (2) 0.194 (5)
Classroom 0.042 (2) 0.188 (4) 0.162 (3) 0.019 (1) 0.190 (5)
Take Home 0.056 (2) 0.188 (4) 0.162 (3) 0.020 (1) 0.192 (5)
Internet 0.053 (2) 0.180 (4) 0.149 (3) 0.024 (1) 0.181 (5)
Newspaper 0.061 (2) 0.186 (4) 0.149 (3) 0.024 (1) 0.187 (5)
Theorists 0.071 (2) 0.171 (4) 0.135 (3) 0.040 (1) 0.172 (5)
Average Rank 1.83 4 3 1.17 5
Centipede 4-level Centipede 0.469 (1) 1.774 (4) 0.611 (3) 0.606 (2) 3.715 (5)
6-level Centipede 0.350 (1) 1.950 (4) 0.439 (2) 1.120 (3) 2.837 (5)
Average Rank 1 4 2.5 2.5 5
Bargaining Ultimatum
- (10, 10) 0.051 (1.5) 0.098 (3.5) 0.098 (3.5) 0.051 (1.5) 0.197 (5)
- (10, 60) 0.030 (1) 0.093 (3.5) 0.093 (3.5) 0.057 (2) 0.192 (5)
- (70, 10) 0.048 (2) 0.090 (3.5) 0.090 (3.5) 0.047 (1) 0.187 (5)
Two-stage Bargaining
-D=0.9 0.040 (1) 0.096 (3.5) 0.096 (3.5) 0.084 (2) 0.198 (5)
-D=0.8 0.054 (1) 0.095 (3.5) 0.095 (3.5) 0.076 (2) 0.198 (5)
-D=0.7 0.048 (1) 0.099 (3.5) 0.099 (3.5) 0.075 (2) 0.197 (5)
-D=0.6 0.067 (1) 0.128 (3.5) 0.128 (3.5) 0.095 (2) 0.197 (5)
-D=0.5 0.037 (1) 0.111 (3.5) 0.111 (3.5) 0.054 (2) 0.190 (5)
-D=0.4 0.030 (1) 0.105 (3.5) 0.105 (3.5) 0.039 (2) 0.191 (5)
-D=0.3 0.024 (1.5) 0.081 (3.5) 0.081 (3.5) 0.024 (1.5) 0.192 (5)
-D=0.2 0.052 (2) 0.117 (3.5) 0.117 (3.5) 0.050 (1) 0.196 (5)
Average Rank 1.27 3.5 3.5 1.73 5
Overall Rank 1.37 4.12 3.2 1.75 4.55
Table 1: Average out-of-sample (5x2-fold cross-validation) error. Resulting ranks are indicated in brack-
ets. In both cases, lower is better. Tied values receive the average rank between the ranks which would
have been achieved had there been no ties. The overall rank is determined as the mean rank of the
average rank across the game classes, meaning each game has an equal weighting in the overall rank,
and the number of experiments for a game class does not aﬀect this overall weight.
These deviations from equilibrium are captured well by the proposed Quantal Hierarchy model
(Fig. 4). We see that in the beginning (before learning, Fig. 4a), the players overestimate for low c
and underestimate for high c. Towards the ﬁnal rounds (after learning, e.g. Fig. 4e), the behaviour
approaches equilibrium, and the proposed QH model approximates this well using an increase in pro-
cessing resources β and/or γ (see Table 2) to capture this player “learning”. These changes highlight an
important property of the QH model. If a player is learning, i.e., becoming closer to rational, this should
correspond to an increase in β (and/or an increase in γ).
The level-k model fails to capture the overall trend, and in fact, is best ﬁtted with k= 0, performing
worse than the mixed strategy equilibrium (and all other alternatives). The reason for this is simple.
Level-k (k ≥1) implies a step function, where for c > Twhere T is some threshold, the player enters
with certainty, and for c≤T, the player stays out with certainty. The distance to the experimental data
from this step function is greater than the uniform case ( k = 0), so the uniform case is chosen. The
cognitive hierarchy model improves upon level-k, by ﬁtting a distribution of kthinkers, able to “smooth”
out this step function, with the line shown in Fig. 4. While this captures the qualitative trend (over
entry for low c, under entry for high c, near equilibrium for mid c), quantitatively, the approach is not
as strong as QRE, Quantal Hierarchy, or even the mixed-strategy equilibrium in most cases.
The QRE model is also a good ﬁt here, however, due to the representation is constrained to linear
lines. In contrast, the QH representation can capture such “S” shape curves, better approximating the
experimental data in 3 out of the 5 blocks. QRE and QH signiﬁcantly outperform the approaches which
just relax mutual consistency (level- k and CH), motivating the relaxation of best-response in addition
11
Quantal
Hierarchy
Level-k Cognitive
Hierarchy
Quantal
Response
Nash
Equilibrium
1.0
2.0
3.0
4.0
5.0
Figure 3: Overall rankings for out-of-sample errors across the various game classes trialled. The bars
indicate the range of achieved ranks (worst achieved to best achieved ranking), with the middle bar
indicating the median ranking. A lower ranking is better (with 1=best).
Quantal
Hierarchy
β, γ
Level-k
k
Cognitive
Hierarchy
τ
Quantal Response
Equilibrium
λ
Nash
Market EntranceBlock 1 0.43, 0.24 0.0 0.72 10.39
Block 2 0.67, 0.18 0.0 0.68 34.56
Block 3 0.62, 0.28 0.0 0.65 59.44
Block 4 0.32, 0.54 0.0 0.69 83.51
Block 5 0.75, 0.19 0.2 0.72 80.8
Beauty ContestLab 0.08, 0.76 1.2 5.45 1.21
Classroom 0.1, 0.69 1.7 5.52 1.9
Take Home 0.06, 0.79 2.4 5.36 2.2
Internet 0.07, 0.72 3.3 5.67 2.31
Newspaper 0.08, 0.64 6.3 5.76 2.8
Theorists 0.05, 0.67 5.6 5.84 3.02
Centipede 4-level Centipede 12.43, 0.22 0.0 1.82 2.09
6-level Centipede 19.1, 0.14 0.3 2.3 1.09
Bargaining Ultimatum
- (10, 10) 0.08, 0.92 0.0 4.36 0.08
- (10, 60) 0.2, 0.32 0.0 4.84 0.09
- (70, 10) 0.06, 0.88 0.0 3.68 0.06
Two-stage Bargaining
-D=0.9 0.24, 0.13 0.0 4.07 0.04
-D=0.8 0.2, 0.22 0.0 4.29 0.05
-D=0.7 0.22, 0.28 0.0 3.73 0.06
-D=0.6 0.52, 0.2 0.0 3.89 0.08
-D=0.5 0.2, 0.36 0.0 2.97 0.11
-D=0.4 0.19, 0.38 0.0 3.78 0.1
-D=0.3 0.13, 0.49 0.0 3.69 0.08
-D=0.2 0.17, 0.52 0.0 8.02 0.11
Table 2: Average ﬁtted parameter values for each approach. Explanation of the parameters and the
ﬁtting procedure is given in Appendix A.
to mutual consistency.
p-Beauty contest In the p-beauty contest (Moulin, 1986), players must try and guess p times the
average guess (in the range [0 ,100]) of other competitors (see Appendix C.2). The Nash equilibrium is
for all players to guess 0, however, experimentally, we see large deviations from this behaviour.
Analysing the experimental results (Fig. 5), we see very strong performance for the QH model when
modelling the less experienced players, e.g. in the Lab experiments. The QH model ﬁts the data well,
12
1 3 5 7 9 11 13 15 17 190.0
0.2
0.4
0.6
0.8
1.0
qh
ch
level-k
qre
nash
target
(a) Block 1
1 3 5 7 9 11 13 15 17 190.0
0.2
0.4
0.6
0.8
1.0
 (b) Block 2
1 3 5 7 9 11 13 15 17 190.0
0.2
0.4
0.6
0.8
1.0
 (c) Block 3
1 3 5 7 9 11 13 15 17 190.0
0.2
0.4
0.6
0.8
1.0
 (d) Block 4
1 3 5 7 9 11 13 15 17 190.0
0.2
0.4
0.6
0.8
1.0
 (e) Block 5
Figure 4: Market Entrance Game. The darker lines indicate the mean result from the 5x2 cross-validation.
The shaded regions indicate ±one standard deviation. The out-of-sample data are shown as the black
circles. The proposed Quantal Hierarchy model is the purple line. Quantal Response Equilibrium is the
orange line, level- k is the blue line, and Cognitive Hierarchy is the green line. The Nash equilibrium
solution is indicated as the diagonal dashed grey line.
capturing the overall distribution and achieving the lowest error rate. However, for the other experiments
composed of more experienced players or players with more time (take home, newspaper), we see the
distribution is better approximated by QRE.
The reason for this performance is because under the proposed approach, as a player becomes more
rational, the distribution of choices narrows in to the optimal choice (see Fig. 6). However, under these
experimental settings, even in the theorist case, there is bounded rational (and in fact, anti-rational)
behaviour. These deviations are captured well by QRE. However, it is diﬃcult for the QH model to
capture the wide distribution of choices, as well as the bulk probability mass around the optimal case.
For example, in Fig. 6 we show the proposed approach approximating level- k. As k increases, the
distribution narrows. Here, this narrowing of the distribution makes it diﬃcult to capture the entire
prediction range for the more advanced subjects, due to the fact there are many sub-rational choices
mixed in. As a result, we see similar ﬁtted models for each case, despite the fact that the theorists
clearly have a higher level of reasoning. If, instead, we tried to approximate the average player for each
case, we could capture this increase in reasoning eﬀort, and it would reﬂect an increase in β and/or γ as
expected.
Nevertheless, in all cases, the model still signiﬁcantly outperforms level- k, Cognitive Hierarchy, and
the mixed strategy equilibrium. The level- k model predicts some of the representative spikes in the
experimental data (e.g., with k = 1 guesses of 33, k = 2 of 22, etc.). However, we can see that the
players do not necessarily choose according to level- k, and may make errors around the best response
suggested by level- k reasoning. Level- k thinking presupposes that players will predict a multiple of p,
i.e., with p= 2
3 , we get p×50,p2 ×50,...,p k ×50, as the players at each level are best responding to
lower-level players. In the proposed QH model, level- k reasoning can be recovered if βt = ∞for t ≤k
and βt = 0 for t > k. However, with βt < ∞, the proposed QH model produces a distribution around
these best-responding values anticipating potential errors in player reasoning, with these errors growing
throughout the chain of reasoning.
The cognitive hierarchy model can improve upon the level-k approach here by weighting the “spikes”
of the level- k model diﬀerently, however, this still fails to capture the underlying distribution. A large
reason for this is that certain predictions in the p-beauty contest are considered irrational, for example,
any prediction over 67. However, we can see experimentally that such predictions occur, for example,
in Fig. 5. If a player believes that other players would choose the maximal oﬀer of 100, then the player
should choose 2
3 100 = 67. Level- kor cognitive hierarchy models cannot capture such irrational behaviour
where players choose >67. That is, there is no distribution of level- k thinkers that would predict 100.
However, this feature can be captured directly under the proposed QH and QRE models due to the errors
in play, again motivating the usefulness of relaxing best response in addition to mutual consistency.
In summary, we see that under the lab experiment, the QH approach is the best ﬁt. However, QRE
is a better ﬁt in other cases of the beauty contest game.
13
0 20 40 60 80 100
0.000
0.005
0.010
0.015
0.020
0.025
qh
qre
target
nash
(a) Lab
0 20 40 60 80 100
0.000
0.005
0.010
0.015
0.020
0.025 (b) Classroom
0 20 40 60 80 100
0.000
0.005
0.010
0.015
0.020
0.025
0.030 (c) Internet
0 20 40 60 80 100
0.000
0.005
0.010
0.015
0.020
0.025
0.030
(d) Newspaper
0 20 40 60 80 100
0.000
0.005
0.010
0.015
0.020
0.025
0.030 (e) Take Home
0 20 40 60 80 100
0.000
0.005
0.010
0.015
0.020
0.025
0.030
0.035 (f) Theorists
Figure 5: Beauty contest games. The darker lines indicate the mean result from the 5x2 cross-validation.
The shaded regions indicate ±one standard deviation. The out-of-sample data are shown as the black
line. The proposed Quantal Hierarchy model is the purple line. Quantal Response Equilibrium is the
orange line. The level- k and Cognitive Hierarchy plots are shown in Fig. 12 due to the large diﬀerence
in scales, distorting the ﬁgure. The Nash equilibrium solution is indicated as the diagonal dashed grey
line.
0 10 20 30 40 50
0.0
0.1
0.2
0.3
0.4
Level-1. β=  27 , γ= 0.01
Level-2. β=  26 , γ= 0.22
Level-3. β=  59 , γ= 0.32
Level-4. β=  64 , γ= 0.46
Level-5. β=  95 , γ= 0.52
Level-6. β=  93 , γ= 0.61
Level-7. β=  99 , γ= 0.73
Level-8. β=  99 , γ= 0.85
Figure 6: Example comparing the decisions of level- k (dashed vertical lines) to the proposed QH model
(solid lines) in the p-beauty contest for various settings.
5.2.1 Sequential Games
Centipede Games In the centipede game (see Appendix C.3), “two players alternately get a chance
to take the larger portion of a continually escalating pile of money. As soon as one person takes, the
game ends with that player getting the larger portion of the pile, and the other player getting the smaller
portion” (McKelvey and Palfrey, 1992).
The subgame perfect equilibrium of the centipede game is for each player to immediately take the
pot without proceeding to any further rounds, however, we see this is not the case experimentally, where
players behave far from the subgame perfect equilibrium (Fig. 14). In general, many players take towards
the middle of the game. The proposed QH model can capture this trend well, with QRE and Cognitive
Hierarchy generally over-weighting the earlier nodes and under-weighting the later modes (Fig. 7).
The Quantal Hierarchy model provides the best ﬁt for both the four and six-level centipede games,
capturing realistic beliefs. When modelling this reasoning process, the player believes they are reasoning
at a higher level than their opponent, but in addition, it is as if the player overestimates how noisy
their own play will be when faced with a decision at later nodes. This overestimation is because once
actually faced with the decision, there will be a smaller game tree for the player to consider. This
reasoning process was shown to approximate the experimental results well, motivating the discounting of
information processing resources for capturing future beliefs. When comparing the resulting parameters
(β and γ) from the four and six-level variants (Table 2), we note that the six-level variant results in
additional information processing costs for the player (larger β and γ). The additional processing costs
14
1 2 3 4 50.0
0.2
0.4
0.6
0.8
1.0
 qh
qre
level-k
ch
nash
(a) Four Move.
1 2 3 4 5 6 70.0
0.2
0.4
0.6
0.8
1.0
 qh
qre
level-k
ch
nash (b) Six Move.
Figure 7: Four and Six-level Centipede Games. The darker lines indicate the mean result from the
5x2 cross-validation. The shaded regions indicate ±one standard deviation. The out-of-sample data
are shown in the dark grey bars. The proposed Quantal Hierarchy model is the purple line. Quantal
Response Equilibrium is the orange line, level- k is the blue line, and Cognitive Hierarchy is the green
line. The Nash equilibrium solution is indicated as the light grey bar at the ﬁrst move.
result from the longer chain of reasoning, requiring higher processing resources.
The signiﬁcantly improved performance over quantal response equilibrium on both games motivates
the usefulness of relaxing mutual consistency in addition to best response. By relaxing mutual consis-
tency, we captured the perceived “lapse” in reasoning when considering the full extensive form game tree
by reducing the information processing resources the further the player tries to reason through the tree.
Bargaining Games In bargaining games, players alternately bargain over how to divide a sum (see
Appendix C.4). We examine two types, single-stage (Ultimatum) and two-stage bargaining games. These
are extensions of the example game considered in Section 4.2.1.
Ultimatum The results are presented in Fig. 8 for the ultimatum game. We see the QH model
explains important features of the observed experimental behaviour. For example, with higher V1, Player
1 is likely to make a larger initial request (Fig. 8c vs Fig. 8a). Perfect rationality does not capture this
(with the Nash equilibrium remaining unchanged), whereas the QH model suggests higher initial requests
(due to higher V1 if the request is rejected). The QRE model and the QH model behave similarly here.
The reason for this similar behaviour is because the ultimatum game is nearly a single-stage decision,
meaning the QH model “collapses” to QRE. This is also conﬁrmed in the ﬁtted parameters Table 2, with
the (10,10) and (70,10) having almost identical values for β and λ, and QH having relatively high values
of γ, meaning the diﬀerences between Player 1 and Player 2 processing resources are small. However,
something interesting happens in the (10 ,60) case, where QRE cannot capture the distribution. For
example, if we look to the right of the rational rejection region for Player 2 (Fig. 16), we do not see
any acceptances in (10,10) or (70,10). Whereas, if we look in the rational rejection region of (10,60),
we see several acceptances. This behaviour is irrational, because if the player rejected the request, they
would have received a higher payoﬀ. In contrast, Player 1’s initial requests are relatively rational, with
the peak occurring around the rational request of 40. This mismatch in player rationality is captured
under the proposed model with a small γ, i.e., a large discount in processing resources. This mismatch
in rationality cannot be captured with the standard QRE, which assumes a ﬁxed β for both players.
These results motivate the discounting of player resources, which can capture heterogeneous information
processing resources between the two players. Alternate forms of QRE, such as Heterogenous QRE have
also been proposed to deal with such dilemmas (Rogers et al., 2009), however, this is captured natively
by the QH model.
The level-k model fails to capture any of the trends, with the uniform level-0 case being the best ﬁt.
The cognitive hierarchy model predicts a representative spike at the rational capacity in the (70,10) and
(10,60) cases, however, it is still clearly outperformed by both QRE and QH.
These results conﬁrm the usefulness of QH. When both players behave with similar levels of rationality,
this can be captured with γ →1, and the model acts the same as QRE. However, when there is a
mismatch in player rationality, this heterogeneity can be captured directly with γ <1, which became
most pronounced in the (10 ,60) case.
Two-stage While we saw similar behaviour between QRE and QH in the ultimatum game, under the
two-stage game, the diﬀerences between the approaches become more pronounced due to the longer game
15
0 20 40 60 80 100
0.000
0.005
0.010
0.015
0.020
0.025
0.030
target
qh
qre
level-k
ch
nash
(a) (10,10)
0 20 40 60 80 100
0.000
0.005
0.010
0.015
0.020
0.025
0.030
0.035 (b) (10,60)
0 20 40 60 80 100
0.000
0.005
0.010
0.015
0.020
0.025
0.030
0.035 (c) (70,10)
Figure 8: Ultimatum game. The darker lines indicate the mean result from the 5x2 cross-validation. The
shaded regions indicate ±one standard deviation. The out-of-sample data are shown as the black line.
The proposed Quantal Hierarchy model is the purple line. Quantal Response Equilibrium is the orange
line, level-k is the blue line, and Cognitive Hierarchy is the green line. The Nash equilibrium solution is
indicated as the vertical dashed grey line.
0 20 40 60 80 100
0.000
0.005
0.010
0.015
0.020
0.025
0.030
0.035 target
qh
qre
level-k
ch
nash
(a) D=0.9
0 20 40 60 80 100
0.000
0.005
0.010
0.015
0.020
0.025
0.030
0.035 (b) D=0.8
0 20 40 60 80 100
0.000
0.005
0.010
0.015
0.020
0.025
0.030
0.035 (c) D=0.7
0 20 40 60 80 100
0.00
0.01
0.02
0.03
0.04
0.05
0.06
0.07 (d) D=0.6
0 20 40 60 80 100
0.00
0.01
0.02
0.03
0.04
(e) D=0.5
0 20 40 60 80 100
0.00
0.01
0.02
0.03
0.04 (f) D=0.4
0 20 40 60 80 100
0.000
0.005
0.010
0.015
0.020
0.025
0.030 (g) D=0.3
0 20 40 60 80 100
0.00
0.01
0.02
0.03
0.04
0.05
0.06 (h) D=0.2
Figure 9: Two-stage bargaining game. The darker lines indicate the mean result from the 5x2 cross-
validation. The shaded regions indicate ±one standard deviation. The out-of-sample data are shown as
the black line. The proposed Quantal Hierarchy model is the purple line. Quantal Response Equilibrium
is the orange line, level-kis the blue line, and Cognitive Hierarchy is the green line. The Nash equilibrium
solution is indicated as the vertical dashed grey line.
tree. Under such conditions, the usefulness of discounting future paths (and relaxing mutual consistency)
becomes more noticeable. The QH model convincingly outperforms QRE across the experimental results
with the small disagreement penalties 3 (i.e., D >0.5), and still generally outperforms QRE for the
larger disagreement penalties (i.e., D≤0.5), although the two methods become closer.
With the larger disagreement penalties (i.e. smaller D), the experimental data are closer to the
perfectly rational case, as indicated with the peaks corresponding roughly to the rational request in
Fig. 9. This distribution around the rational request is precisely the premise QRE is founded on, so
QRE achieves adequate performance. However, with the smaller disagreement penalties (larger D, top
row of Fig. 9), the distribution is not centred around the rational request, meaning QRE struggles to
capture such phenomena. In contrast, the QH approach is robust to this shift due to the relaxation
of mutual consistency, and is able to capture the varying distributions regardless of whether they are
approximating the best-response case.
5.3 Results Summary
The Quantal Hierarchy method consistently performed well out-of-sample in all games, ranking the
best overall and achieving either the ﬁrst or second position in every game. The results analysis was
categorised into two game types: sequential and simultaneous games, where reasoning is represented as an
3These are referred to as “discount” rates in Binmore et al. (2002). We have used the term disagreement penalties to
avoid confusion with the information processing “discount” parameter γ.
16
extensive-form game tree with depleting information-processing resources. Although the representation
worked well in both game types, it showed more improvement over alternative methods in sequential
games. This improvement in sequential games can be attributed to the discount parameter that captures
the heterogeneity of players, allowing for diﬀerent information processing resources between the players
at each stage, relaxing mutual consistency, which was crucial in bargaining games.
On the other hand, in simultaneous games, the approach aims to ﬁt a representative distribution
of the entire group, but it can struggle to capture the entire distribution of players, particularly when
they exhibit widely varying levels of rationality, as in certain versions of the beauty-contest game. This
highlights a potential limitation of the approach when attempting to capture multimodal distributions
with varying levels of rationality, such as a bi-modal distribution with beginners and experts. To address
this limitation, multiple versions of the model may need to be ﬁtted, such as one for beginners and
one for experts, as modelling more rational play narrows the distribution to the rational prediction and
modelling less rational play widens the distribution to account for larger errors, as demonstrated in
Fig. 6. However, despite this potential limitation, the method still performed exceptionally well overall.
6 Discussion and Conclusions
The assumption of perfect rationality amongst players is violated in numerous experimental settings,
particularly in non-repeated games. In this work, we utilised experimental datasets for several games,
showing that the equilibrium behaviour is often a poor predictor of the observed actions. The proposed
Quantal Hierarchy model oﬀers a concise alternative representation, relaxing some traditional game-
theoretic assumptions underlying rationality. The model is a good ﬁt for experimentally observed be-
haviour on a range of canonical economic games, outperforming existing bounded rationality approaches
on out-of-sample validation.
In the QH model, we represent higher-order reasoning as pseudo-sequential decision-making. At each
level, players may reason erroneously, and this error grows the deeper one reasons (i.e., it becomes more
diﬃcult to reason about reasoning). The magnitude of the errors is governed by β, with β = 0, players
do not perform any reasoning, and with β →∞ players reason perfectly. Parameter β, therefore, relaxes
the best response assumption of players at each level of reasoning.
Decreasing β at each level of reasoning was shown to work well on a wide variety of games, rein-
forcing the assumption that players cognitive abilities decrease throughout the depth of reasoning. This
reduction in player cognition is captured with γ, introducing an implicit hierarchy of players, relaxing
the mutual consistency assumption. Representing this hierarchy of players as extensive-form game trees
allowed for an information-theoretic representation, where lower-level players are assumed to make more
signiﬁcant playing errors (constrained by lower information processing resources). With a single-step
decision, this recovers the Quantal Response Equilibrium model. With multi-stage decisions, we recover
an approximation of a generalised level- k formulation, where at each step, players are assumed to have
higher resources and reasoning ability than players below themselves, but may still play erroneously.
Similar to QRE, the resource parameterβis problem dependent, and depends on the payoﬀ magnitude
(McKelvey et al., 2000). This opens an area of research analysing whether a normalised β can be used
to measure problem diﬃculty, or whether some relationship holds between the the experimentally ﬁtted
β and the β which corresponds to the Nash solution. For example, a question arises if a normalised β
can provide insights across games, and if so, can this average distance to the Nash solution be generally
useful across games. A similar consideration is given to whether such payoﬀ perturbations in QRE can
be related across diﬀerent games (Haile et al., 2008), and whether the boundedness parameter can be
endogenised (Friedman, 2020).
There is a clear relationship between the decision-making components proposed in this work and the
decision-making in multi-agent systems, such as agent-based models (ABMs) and multi-agent reinforce-
ment learning (RL) approaches. For example, Wen et al. (2020) outline a novel framework for hierarchical
reasoning RL agents, which allows agents to best respond to other less sophisticated agents based upon
level-ktype models. Likewise,  Latek et al. (2009) propose a recursion based bounded rationality approach
for ABMs. Replacing the agents in these multi-agent approaches with the informationally constrained
agents presented in our work provides a distinct area of future research, where we could examine the
resulting dynamics and out-of-equilibrium behaviour from heterogeneous QH agents.
In summary, we proposed an information-theoretic model for capturing higher-order reasoning for
boundedly rational players. Bounded rationality is achieved in the model by the relaxation of two central
assumptions underlying rationality, namely, mutual consistency between players and best response deci-
sions. Through relaxing these assumptions, we showed how the predictions from the proposed Quantal
17
Hierarchy model align well with the experimentally observed human behaviour in a variety of canonical
economic games.
References
Alaoui, L. and Penta, A. (2016). Endogenous depth of reasoning. The Review of Economic Studies ,
83(4):1297–1333.
Alaoui, L. and Penta, A. (2022). Cost-beneﬁt analysis in reasoning. Journal of Political Economy ,
130(4):881–925.
Anufriev, M., Duﬀy, J., and Panchenko, V. (2022). Learning in two-dimensional beauty contest games:
Theory and experimental evidence. Journal of Economic Theory , 201:105417.
Arthur, W. B. (1994). Inductive reasoning and bounded rationality. The American economic review ,
84(2):406–411.
Aumann, R. J. (1992). Irrationality in game theory. Economic analysis of markets and games , pages
214–227.
Ay, N., Bernigau, H., Der, R., and Prokopenko, M. (2012). Information-driven self-organization: the
dynamical system approach to autonomous robot behavior. Theory in Biosciences, 131(3):161–179.
Bach, C. W. and Perea, A. (2014). Utility proportional beliefs. International Journal of Game Theory ,
43(4):881–902.
Bergstra, J., Yamins, D., and Cox, D. (2013). Making a science of model search: Hyperparameter
optimization in hundreds of dimensions for vision architectures. InInternational conference on machine
learning, pages 115–123. PMLR.
Binmore, K. (1987). Modeling rational players: Part I. Economics & Philosophy , 3(2):179–214.
Binmore, K. (1988). Modeling rational players: Part II. Economics & Philosophy , 4(1):9–55.
Binmore, K., McCarthy, J., Ponti, G., Samuelson, L., and Shaked, A. (2002). A backward induction
experiment. Journal of Economic theory , 104(1):48–88.
Bosch-Domenech, A., Montalvo, J. G., Nagel, R., and Satorra, A. (2002). One, two,(three), inﬁnity,...:
Newspaper and lab beauty-contest experiments. American Economic Review, 92(5):1687–1701.
Botev, Z. I., Grotowski, J. F., and Kroese, D. P. (2010). Kernel density estimation via diﬀusion. The
annals of Statistics , 38(5):2916–2957.
Braun, D. A. and Ortega, P. A. (2014). Information-theoretic bounded rationality and ε-optimality.
Entropy, 16(8):4662–4676.
Braun, D. A., Ortega, P. A., Theodorou, E., and Schaal, S. (2011). Path integral control and bounded
rationality. In 2011 IEEE symposium on adaptive dynamic programming and reinforcement learning
(ADPRL), pages 202–209. IEEE.
Breitmoser, Y. (2012). Strategic reasoning in p-beauty contests. Games and Economic Behavior ,
75(2):555–569.
Camerer, C., Ho, T., and Chong, K. (2003). Models of thinking, learning, and teaching in games.
American Economic Review, 93(2):192–195.
Camerer, C. F. (2003). Behavioral game theory: Plausible formal models that predict accurately. Be-
havioral and Brain Sciences , 26(2):157–158.
Camerer, C. F. (2010). Behavioural game theory. In Behavioural and Experimental Economics , pages
42–50. Springer.
Camerer, C. F. (2011).Behavioral game theory: Experiments in strategic interaction. Princeton university
press.
18
Camerer, C. F., Ho, T.-H., and Chong, J.-K. (2004). A cognitive hierarchy model of games.The Quarterly
Journal of Economics , 119(3):861–898.
Caplin, A., Dean, M., and Leahy, J. (2019). Rational inattention, optimal consideration sets, and
stochastic choice. The Review of Economic Studies , 86(3):1061–1094.
Challet, D., Marsili, M., Zhang, Y.-C., et al. (2013). Minority games: interacting agents in ﬁnancial
markets. OUP Catalogue.
Chong, J.-K., Camerer, C. F., and Ho, T.-H. (2005). Cognitive hierarchy: A limited thinking theory
in games. In Zwick, R. and Rapoport, A., editors, Experimental Business Research, pages 203–228,
Boston, MA. Springer US.
Chong, J.-K., Ho, T.-H., and Camerer, C. (2016). A generalized cognitive hierarchy model of games.
Games and Economic Behavior , 99:257–274.
Cournot, A. A. (1838). Recherches sur les principes math´ ematiques de la th´ eorie des richesses . L.
Hachette.
Demˇ sar, J. (2006). Statistical comparisons of classiﬁers over multiple data sets.The Journal of Machine
learning research, 7:1–30.
Dietterich, T. G. (1998). Approximate statistical tests for comparing supervised classiﬁcation learning
algorithms. Neural computation, 10(7):1895–1923.
Duﬀy, J. and Hopkins, E. (2005). Learning, information, and sorting in market entry games: theory and
evidence. Games and Economic behavior , 51(1):31–62.
Evans, B. P. and Prokopenko, M. (2021). A maximum entropy model of bounded rational decision-making
with prior beliefs and market feedback. Entropy, 23(6):669.
Friedman, E. (2020). Endogenous quantal response equilibrium. Games and Economic Behavior ,
124:620–643.
Gabaix, X., Laibson, D., Moloche, G., and Weinberg, S. (2006). Costly information acquisition: Exper-
imental analysis of a boundedly rational model. American Economic Review, 96(4):1043–1068.
G¨ achter, S. (2004). Behavioral game theory.Blackwell handbook of judgment and decision making , pages
485–503.
Georgalos, K. (2020). Comparing behavioral models using data from experimental centipede games.
Economic Inquiry, 58(1):34–48.
Glasner, D. (2020). Hayek, Hicks, Radner and four equilibrium concepts: Perfect foresight, sequential,
temporary, and rational expectations. The Review of Austrian Economics , pages 1–23.
Goeree, J. K. and Holt, C. A. (2004). A model of noisy introspection. Games and Economic Behavior ,
46(2):365–382.
Goeree, J. K. and Holt, C. A. (2005). An explanation of anomalous behavior in models of political
participation. American political science Review, 99(2):201–213.
Goeree, J. K., Holt, C. A., and Palfrey, T. R. (2005). Regular quantal response equilibrium.Experimental
Economics, 8(4):347–367.
Goeree, J. K., Holt, C. A., and Palfrey, T. R. (2016). Quantal response equilibrium. In Quantal Response
Equilibrium. Princeton University Press.
Goldfarb, A. and Xiao, M. (2011). Who thinks about the competition? managerial ability and strategic
entry in us local telephone markets. American Economic Review, 101(7):3130–61.
Gottwald, S. and Braun, D. A. (2019). Bounded rational decision-making from elementary computations
that reduce uncertainty. Entropy, 21(4):375.
Haile, P. A., Horta¸ csu, A., and Kosenok, G. (2008). On the empirical content of quantal response
equilibrium. American Economic Review, 98(1):180–200.
19
Harr´ e, M. S. (2021). Information theory for agents in artiﬁcial intelligence, psychology, and economics.
Entropy, 23(3):310.
Harsanyi, J. C. (1967). Games with incomplete information played by “Bayesian” players. Part I. The
basic model. Management science, 14(3):159–182.
Harsanyi, J. C. (1968). Games with incomplete information played by “Bayesian” players. Part II.
Bayesian equilibrium points. Management Science, 14(5):320–334.
Ho, T.-H. and Su, X. (2013). A dynamic level-k model in sequential games. Management Science ,
59(2):452–469.
Hoppe, H.-H. (1997). On certainty and uncertainty, or: how rational can our expectations be? The
Review of Austrian Economics , 10(1):49–78.
Johnson, E. J., Camerer, C., Sen, S., and Rymon, T. (2002). Detecting failures of backward induction:
Monitoring information search in sequential bargaining. Journal of Economic Theory , 104(1):16–47.
Kawagoe, T. and Takizawa, H. (2012). Level-k analysis of experimental centipede games. Journal of
Economic Behavior & Organization , 82(2-3):548–566.
Ke, S. (2019). Boundedly rational backward induction. Theoretical Economics, 14(1):103–134.
Keynes, J. M. (1937). The general theory of employment. The quarterly journal of economics, 51(2):209–
223.
Keynes, J. M. (2018). The general theory of employment, interest, and money . Springer.
Knudsen, C. (1993). Rationality and the problem of self-reference in economics! Rationality, Institutions,
and Economic Methodology, 2:133.
Koppl, R. and Barkley Rosser Jr, J. (2002). All that I have to say has already crossed your mind.
Metroeconomica, 53(4):339–360.
Koriyama, Y. and Ozkes, A. I. (2021). Inclusive cognitive hierarchy. Journal of Economic Behavior &
Organization, 186:458–480.
Krockow, E. M., Pulford, B. D., and Colman, A. M. (2018). Far but ﬁnite horizons promote cooperation
in the centipede game. Journal of Economic Psychology , 67:191–199.
 Latek, M., Axtell, R., and Kaminski, B. (2009). Bounded rationality via recursion. In Proceedings of
Eighth International Conference on Autonomous Agents and Multi-Agent Systems (AAMAS 2009) ,
pages 457–464.
Levin, D. and Zhang, L. (2019). Bridging level-k to nash equilibrium.Review of Economics and Statistics,
pages 1–44.
Lipman, B. L. (1991). How to decide how to decide how to...: Modeling limited rationality.Econometrica:
Journal of the Econometric Society , pages 1105–1125.
L¨ ofgren, L. (1990).On the partiality of self-reference, pages 47–64. Gordon and Breach Science Publishers.
Mackie, J. (1971). What can we learn from the paradoxes? part II. Cr´ ıtica: Revista Hispanoamericana
de Filosof´ ıa, pages 35–54.
Mattsson, L.-G. and Weibull, J. W. (2002). Probabilistic choice and procedurally bounded rationality.
Games and Economic Behavior , 41(1):61–78.
McKelvey, R. D. and Palfrey, T. R. (1992). An experimental study of the centipede game. Econometrica:
Journal of the Econometric Society , pages 803–836.
McKelvey, R. D. and Palfrey, T. R. (1995). Quantal response equilibria for normal form games. Games
and economic behavior, 10(1):6–38.
McKelvey, R. D. and Palfrey, T. R. (1998). Quantal response equilibria for extensive form games.
Experimental economics, 1(1):9–41.
20
McKelvey, R. D., Palfrey, T. R., and Weber, R. A. (2000). The eﬀects of payoﬀ magnitude and het-
erogeneity on behavior in 2 ×2 games with unique mixed strategy equilibria. Journal of Economic
Behavior & Organization , 42(4):523–548.
Mertens, J.-F. and Zamir, S. (1985). Formulation of Bayesian analysis for games with incomplete infor-
mation. International Journal of Game Theory , 14(1):1–29.
Morgenstern, O. (1928). Wirtschaftsprognose: Eine Untersuchung ihrer Voraussetzungen und
M¨ oglichkeiten. Springer.
Morgenstern, O. (1935). Vollkommene voraussicht und wirtschaftliches gleichgewicht. Zeitschrift f¨ ur
National¨ okonomie/Journal of Economics, pages 337–357.
Moulin, H. (1986). Game theory for the social sciences . NYU press.
Nagel, R. (1995). Unraveling in guessing games: An experimental study. The American Economic
Review, 85(5):1313–1326.
Nash, J. (1951). Non-cooperative games. Annals of mathematics , pages 286–295.
Ortega, D. A. and Braun, P. A. (2011). Information, utility and bounded rationality. In International
Conference on Artiﬁcial General Intelligence , pages 269–274. Springer.
Ortega, P. A. and Braun, D. A. (2013). Thermodynamics as a theory of decision-making with information-
processing costs. Proceedings of the Royal Society A: Mathematical, Physical and Engineering Sciences,
469(2153):20120683.
Ortega, P. A. and Braun, D. A. (2014). Generalized Thompson sampling for sequential decision-making
and causal inference. Complex Adaptive Systems Modeling , 2(1):1–23.
Ortega, P. A. and Stocker, A. A. (2016). Human decision-making under limited time. In Advances in
Neural Information Processing Systems, pages 100–108.
Polani, D., Sporns, O., and Lungarella, M. (2007). How information and embodiment shape intelligent
information processing. In 50 Years of Artiﬁcial Intelligence , pages 99–111. Springer.
Polonio, L. and Coricelli, G. (2019). Testing the level of consistency between choices and beliefs in games
using eye-tracking. Games and Economic Behavior , 113:566–586.
Prokopenko, M., Harr´ e, M., Lizier, J., Boschetti, F., Peppas, P., and Kauﬀman, S. (2019). Self-referential
basis of undecidable dynamics: From the liar paradox and the halting problem to the edge of chaos.
Physics of life reviews , 31:134–156.
Rabin, M. O. (1957). Eﬀective computability of winning strategies. Contributions to the Theory of
Games, 3(39):147–157.
Raiﬀa, H. and Luce, R. D. (1957). Games and Decisions: Introduction and Critical Survey . John Wiley,
New York.
Rapoport, A., Seale, D. A., Erev, I., and Sundali, J. A. (1998). Equilibrium play in large group market
entry games. Management Science, 44(1):119–141.
Rogers, B. W., Palfrey, T. R., and Camerer, C. F. (2009). Heterogeneous quantal response equilibrium
and cognitive hierarchies. Journal of Economic Theory , 144(4):1440–1467.
Scott, D. W. (2015). Multivariate density estimation: theory, practice, and visualization . John Wiley &
Sons.
Silverman, B. W. (2018). Density estimation for statistics and data analysis . Routledge.
Simon, H. A. (1976). From substantive to procedural rationality. In 25 years of economic theory , pages
65–86. Springer.
Sims, C. A. (2003). Implications of rational inattention. Journal of monetary Economics, 50(3):665–690.
21
Stahl, D. O. (1990). Entropy control costs and entropic equilibria.International Journal of Game Theory,
19(2):129–138.
Stahl, D. O. (1993). Evolution of smart players. Games and Economic Behavior , 5(4):604–617.
Stahl, D. O. and Wilson, P. W. (1995). On players’ models of other players: Theory and experimental
evidence. Games and Economic Behavior , 10(1):218–254.
Sundali, J. A., Rapoport, A., and Seale, D. A. (1995). Coordination in market entry games with
symmetric players. Organizational behavior and Human decision processes , 64(2):203–218.
Tishby, N., Pereira, F. C., and Bialek, W. (1999). The information bottleneck method. In Proc. of the
37-th Annual Allerton Conference on Communication, Control and Computing , pages 368–377.
Tishby, N. and Polani, D. (2011). Information theory of decisions and actions. In Perception-action
cycle, pages 601–636. Springer.
Turocy, T. L. (2010). Computing sequential equilibria using agent quantal response equilibria. Economic
Theory, 42(1):255–269.
Webster, T. J. (2013). A note on the ultimatum paradox, bounded rationality, and uncertainty. Inter-
national Advances in Economic Research, 19(1):1–10.
Wen, Y., Yang, Y., and Wang, J. (2020). Modelling bounded rationality in multi-agent interactions by
generalized recursive reasoning. In Bessiere, C., editor, Proceedings of the Twenty-Ninth International
Joint Conference on Artiﬁcial Intelligence, IJCAI-20 , pages 414–421. International Joint Conferences
on Artiﬁcial Intelligence Organization. Main track.
Wolpert, D. H. (2006). Information theory—the bridge connecting bounded rational game theory and
statistical physics. In Complex Engineered Systems, pages 262–290. Springer.
Wright, J. R. and Leyton-Brown, K. (2019). Level-0 models for predicting human behavior in games.
Journal of Artiﬁcial Intelligence Research , 64:357–383.
22
A Model Fitting
Each model is ﬁt to the training portion of the data (from 5x2 cross-fold validation), using Bayesian
hyperparameter optimisation (Bergstra et al., 2013). Every model is given 1000 evaluations for a fair
comparison. With level- k, due to the integer parameter, rather than Bayesian optimisation, we instead
perform an exhaustive search for k ∈[0,1,..., 100], noting that this is an extensive range of k, easily
capturing standard k’s reported in the literature. The ﬁtted parameter values with the lowest mean
squared error between the predictions and the training values are selected. The out-of-sample (testing)
portion is never seen by the optimisation process and is only used for evaluation after the parameter
optimisation has been complete.
For Quantal Response Equilibrium and Quantal Hierarchy, we sample from the range 0 ≤β <100.
While β is unbounded, we ﬁnd this upper bound to be more than enough with no ﬁtted values coming
close to this upper threshold. For γ, this is bounded 0 ≤γ ≤1. For Cognitive Hierarchy, we sample
from the range 0 ≤τ <10, which despite τ being unbounded, again provides a more than suﬃcient
range for the experimental data, and covers common τ’s reported in literature (Camerer, 2010; Camerer
et al., 2004).
For the beauty contest games, as well as the bargaining games, due to the large action space ( a ∈
[0,..., 100]), rather than using the raw data directly, a ﬁtted Gaussian kernel density estimate of the
training and testing data is used to account for the large action space and the relatively small number
of observations. Scott’s rule is used to determine the bandwidth automatically (Scott, 2015), and we
validate the robustness of this rule choice in Appendix D.2. The same kernel density estimates are
used across all methods to ensure fair comparisons. For the remaining game classes, the action space is
suﬃciently well sampled from the observations, so no density approximation is required.
B Special Cases
B.1 Backwards Induction
Backwards induction can be recovered as a limiting case of the proposed model. We can see this as
follows from Eq. (10) (and the expansion process from Eq. (4)), noting that softmax eβU[a]/Z converges
to arg max with β →∞:
f[ak |a<k] = 1
Zk
× Z1/γ
k+1
Future Contribution
×eβγkU[ak|a<k]
  
Current Payoﬀ
= arg max
ak∈Ak

U[ak |a<k]  
Current Payoﬀ
+ Vk+1
Future Contribution


(12)
where Vk+1 is derived recursively based on choosing ak. Backward induction assumes that all future
decisions will be rational, i.e., at each stage, players choose rationally.
C Canonical Games and Experimental Data
C.1 Market Entrance/El Farol Bar Problem
The market entrance game was outlined in the context of cognitive hierarchies in Camerer et al. (2004),
and has also been considered in prior studies, e.g., Rapoport et al. (1998). This game is fundamentally
similar to the El Farol bar problem of Arthur (1994), and minority games of Challet et al. (2013). A
player will proﬁt (enjoy) in the market (bar) if less than d×N,d ∈[0,1] players also enter the same
market (bar).
For this work, we use the experimental data from Camerer (2011), speciﬁcally the results originally
presented in Sundali et al. (1995). The payoﬀ for staying out is ﬁxed
U[stay outk] = 1 (13)
23
However, the payoﬀs for entering are dependent on the total demand from the other (lower-level) players
and a preferential capacity c= d×N:
U[enterk] = 1 + 2(c−f[enterk+1]) (14)
There were N = 20 subjects, and various c’s trialled c∈[1,3,5 ..., 19].
C.1.1 Comparison Methods
We can represent this pseudo-sequential structure (Camerer et al., 2004) as an extensive-form game,
with each level of reasoning forming a new node in the game tree.
Level-k Under this conﬁguration, a level-0 player is assumed to randomise, i.e., enter or stay out with
equal probability (the same level-0 conﬁguration is used for the naive player in the QH model). A level-1
player exploits this and attends the bar if d >0.5, or stay home with d <0.5, at d = 0.5 the player
is indiﬀerent and would attend with 50% probability. Level-2 players then base their decision assuming
other players are level-1, and enter only if the level-1 players underestimated the expected capacity.
Likewise, level-3 players base their decision on reasoning about level-2. Level- k behaviour necessitates
step functions in the response, where players only enter at a capacity cif they believe lower-level thinkers
have over or under entered.
Cognitive Hierarchy Rather than assuming all players are at k−1, the cognitive hierarchy model ﬁts
a distribution to these k players, and best responds according to this distribution of lower level thinkers.
Following Camerer et al. (2004), we use the Poisson distribution.
Quantal Response Equilibrium To derive the (mixed strategy) quantal response equilibrium, we use
the logistic function of the diﬀerences in payoﬀs (between enter and stay out) as the distribution function,
with numeric estimations for the ﬁxed-point solution since no analytical solution exists, following Goeree
et al. (2016) (Section 2.2.2 and Section 8) and Goeree and Holt (2005).
5 10 150.0
0.2
0.4
0.6
0.8
1.0
(a) Block 1
5 10 150.0
0.2
0.4
0.6
0.8
1.0 (b) Block 2
5 10 150.0
0.2
0.4
0.6
0.8
1.0 (c) Block 3
5 10 150.0
0.2
0.4
0.6
0.8
1.0 (d) Block 4
5 10 150.0
0.2
0.4
0.6
0.8
1.0 (e) Block 5
Figure 10: Market Entrance game at various blocks using the experimental data from Sundali et al.
(1995). We see over time, the experimental data becomes closer to the equilibrium of perfect attendance
(dotted gray line).
C.2 Beauty Contest
Keynes (1937, 2018) originally formulated the beauty contest game as follows. Contestants are asked
to vote for the six prettiest faces out of a selection of 100. The winner is the contestant who most
closely picks the overall consensus. A naive (level-0) strategy is to choose based on personal preference.
A level-1 strategy is to choose as if everyone is choosing on personal preference, so the player chooses
whom they think others will ﬁnd most desirable. A level-2 strategy is then for players to choose whom
they think that others will think others will choose, and so on (with Keynes believing there are players
who “practise the fourth, ﬁfth, and higher” levels). The game was originally outlined to highlight how
investors are not necessarily driven by fundamentals but rather by anticipating the thoughts of others.
An extension of the game is the p-beauty contest of Moulin (1986), where contestants are asked to
guess fraction p ∈[0 ... 1] (commonly p = 2
3 ) of the average value of the other competitors guesses
24
within the range [0 ,... 100]. The Nash equilibrium dictate that every player should choose 0. However,
experimentally this is not the case, and players act boundedly rational (Nagel, 1995). Such a game shows
out-of-equilibrium behaviour and motivates the modelling of such decisions in a ﬁnite-depth manner
(Aumann, 1992; Stahl, 1993; Binmore, 1987, 1988).
We use the experimental data provided by Bosch-Domenech et al. (2002) with p= 2
3 . The resulting
guesses are visualised in Fig. 11.
The utilities are represented as follows:
gk = p×
∑
ak+1
ak+1 ×f[ak+1]
∑
ak+1
f[ak+1]
U[ak] = |ak −gk|
(15)
where gk represents the predicted goal, i.e., 2 /3’s of the average weighted prediction of the lower level
thinkers. The utilities for each choice then become the distance to the goal.
C.2.1 Comparison Methods
Level-k Level-0 competitors are assumed to guess randomly between [0 ,100] (the same level-0 conﬁg-
uration is used for the naive player in the QH model). Level-1 players then anticipate this and guess
p×50 (50 being the average from the level-0 players), level-2 players then guess p×(p×50) and so forth.
As the levels increase, the guesses, therefore, approach 0, coinciding with the perfectly rational choice.
Cognitive Hierarchy Rather than assuming all players are at k−1, the cognitive hierarchy model ﬁts
a distribution to these k players, and best responds according to this distribution of lower level thinkers.
Again, following the convention of Camerer et al. (2004), we use the Poisson distribution.
Quantal response equilibrium For the quantal response equilibrium, we use the logit rule following
Breitmoser (2012) estimated using ﬁxed point iteration (see also Section F4.1 of the supplementary
material for Anufriev et al. (2022)).
0 20 40 60 80 100
Guess
0.00
0.02
0.04
0.06
0.08Proportion
Avg=35.14
(a) Lab
0 20 40 60 80 100
Guess
0.00
0.02
0.04
0.06
0.08
0.10
0.12
0.14Proportion
Avg=26.82 (b) Classroom
0 20 40 60 80 100
Guess
0.00
0.02
0.04
0.06
0.08
0.10
0.12
0.14
0.16Proportion
Avg=22.16 (c) Internet
0 20 40 60 80 100
Guess
0.00
0.01
0.02
0.03
0.04
0.05
0.06Proportion
Avg=23.05
(d) Newspaper
0 20 40 60 80 100
Guess
0.00
0.01
0.02
0.03
0.04
0.05
0.06
0.07Proportion
Avg=25.18 (e) Take Home
0 20 40 60 80 100
Guess
0.000
0.025
0.050
0.075
0.100
0.125
0.150
0.175
0.200Proportion
Avg=17.14 (f) Theorists
Figure 11: Visualisation of various experimental p-beauty contests. The dotted vertical line indicates
the average for the given dataset. Datasets source: Bosch-Domenech et al. (2002).
C.3 Centipede Game
With perfectly rational backward induction, the subgame perfect equilibrium of the centipede game is
for each player to immediately take the pot without proceeding to any further rounds. However, this is
a poor predictor of what happens experimentally (Ho and Su, 2013), where players are shown to “grow”
25
0 20 40 60 80 100
0.000
0.025
0.050
0.075
0.100
0.125
0.150
0.175 ch
level-k
target
nash
(a) Lab
0 20 40 60 80 100
0.000
0.025
0.050
0.075
0.100
0.125
0.150
0.175 (b) Classroom
0 20 40 60 80 100
0.0
0.2
0.4
0.6
0.8
1.0 (c) Internet
0 20 40 60 80 100
0.000
0.025
0.050
0.075
0.100
0.125
0.150
(d) Newspaper
0 20 40 60 80 100
0.0
0.2
0.4
0.6
0.8
1.0 (e) Take Home
0 20 40 60 80 100
0.000
0.025
0.050
0.075
0.100
0.125
0.150 (f) Theorists
Figure 12: Beauty contest games (extended). The darker lines indicate the mean result from 5x2 cross-
validation. The shaded regions indicate ±one standard deviation. The out-of-sample data are shown as
the black line. The level- k model is shown as the blue line. The Cognitive Hierarchy model as the green
line. The Nash equilibrium solution is indicated as the diagonal dashed grey line.
0.4 
0.1 
0.2 
0.8 
1.6 
0.4 
0.8 
3.2 
6.4 
1.6 
T AKE T AKE T AKE T AKE 
P ASS P ASS P ASS 
3.2 
12.8 
25.6 
6.4 
T AKE T AKE T AKE 
P ASS P ASS P ASS 
Figure 13: The six move extensive-form centipede Game. Green (orange) circles highlight Player 1(2)’s
turn, and the top (bottom) row of the boxes highlights Player 1(2)s payoﬀ. The four-move game is
equivalent until the fourth node, however, the payoﬀs for the ﬁfth node become the “PASS” payoﬀs for
Node 4.
the money pile by playing for several rounds before taking (Ke, 2019). Again, there are multiple reasons
proposed to explain players deviation from the predicted unique subgame equilibrium (Kawagoe and
Takizawa, 2012; Krockow et al., 2018; Georgalos, 2020).
In this work, we use the experimental data of McKelvey and Palfrey (1992) (from their Appendix C)
for four and six-level centipede games. The utilities are represented as:
U1[take1] = 0.4
U1[pass1] = 0.2 ×f[take2] + V1 ×f[pass2]
U2[take2] = 0.8
U2[pass2] = 0.4 ×f[take3] + V2 ×f[pass3]
...
(16)
where V1,V2 are derived as the average expected return for the remainder of the moves. These payoﬀs
are also visualised in Fig. 13. The conditioning on the history of decisions is implicit here, as to take an
action an at n> 1, all previous actions must have been to pass (otherwise the game would have ended).
26
1 2 3 4 5
Move
0.0
0.2
0.4
0.6
0.8
1.0Proportion
(a) Four Move.
1 2 3 4 5 6 7
Move
0.0
0.2
0.4
0.6
0.8
1.0Proportion (b) Six Move.
Figure 14: Four and six-level Centipede Games using the dataset from McKelvey and Palfrey (1992).
C.3.1 Comparison Methods
Level-k Under the level- k framework, we assume a level-0 agent is equally as likely to take or pass
at each stage of the game (the same conﬁguration is used as the naive player under the proposed
Quantal Hierarchy approach). A level-1 player then takes at the node which maximises the expected
utility subject to this, and so on and so forth. A full analysis of level- k framework in centipede games
is presented in Kawagoe and Takizawa (2012), but this conﬁguration used (referred to as Random
Behavioral strategy (RBS) in Kawagoe and Takizawa (2012)) was shown to be the best speciﬁcation for
matching the experimental data (for both level- k and cognitive hierarchy).
Cognitive Hierarchy Rather than assuming all players are at k−1, the cognitive hierarchy model ﬁts
a distribution to these k players, and best responds according to this distribution of lower level thinkers.
Again, the Poisson distribution was used, which was shown to be the best experimental ﬁt in Kawagoe
and Takizawa (2012).
Quantal Response Equilibirum An agent-form of the QRE (McKelvey and Palfrey, 1998) is used
here , where at each node, the agent choices nosily based on resource parameter β, and assuming their
opponent is also operating under the same resource constraint β. This is calculated recursively following
(McKelvey and Palfrey, 1998).
C.4 Sequential Bargaining
We examine the experimental results of the Ultimatum Game (one-stage) and two-stage alternating-
oﬀer bargaining games (Binmore et al., 2002), which consistently demonstrate violations of backward
induction (Webster, 2013), even when accounting for “fairness” in the system (Johnson et al., 2002).
C.4.1 Ultimatum Game
For the ultimatum game, we use the experimental data of Game 1 from Binmore et al. (2002). In the
ultimatum game, the players are faced with the following payoﬀs:
U1[a1] = a1 ×f[accept |a1] + V1 ×f[reject |a1]
U2[accept2 |a1] = 100 −a1
U2[reject2 |a1] = V2
(17)
where V1,V2 are the rejection payoﬀs for Player 1 and Player 2.
If opponents (Player 2) are rational, then Player 1, being rational, should request no more than their
opponent’s rejection payoﬀ V2. However, if opponents are not believed to be rational, then there is
potential for Player 1 to exploit this fact and request higher (or lower) amounts. That is, it becomes
rational for Player 1 to play as if Player 2 is not perfectly rational.
A rational opponent implies a step function, where for a1, with payoﬀ 100 −a1 > V2 the player
accepts with probability 1, and for payoﬀs below V2 the player reject with certainty as shown in Fig. 16.
However, from Fig. 16 we can see deviations from rationality in the observed play. This is directly
27
x
100-x
REJECT ACCEPT 
V1
V2
x0 100
(a) Ultimatum (One-stage)
x 
100-x 
REJECT ACCEPT 
x 0 100 
Dy 
D(100-y) 
REJECT ACCEPT 
y 0 100 
0 
0 (b) Two-Stage
Figure 15: Example extensive-form sequential bargaining games. In the ultimatum game (Fig. 15a),
Player 1 makes a request x ∈[0,100]. If Player 2 accepts the request, Player 2 receives a payoﬀ of
100 −x, and Player 1 receives x. If Player 2 declines the request, they each receive the rejection payoﬀ
(V1 or V2). In the two-stage game, if Player 2 rejects, they can come back with a counteroﬀer y. Now
the process repeats, and it is up to Player 1 to accept or reject. If Player 1 accepts, Player 2 gets a
disagreement penalised ( D) payoﬀ of D(100 −y), and Player 1 gets a payoﬀ of Dy. However, if both
decline they each get a payoﬀ of 0.
shown by non-deterministic outputs, where the players may or may not accept the request based on
the requested value, as well as violations where the players reject or accept with probability 1 even if a
rational actor would do the opposite.
0 20 40 60 80 100
Player 1 Request
0.0
0.2
0.4
0.6
0.8
1.0Player 2 Rejection Probability
(a) (V1=10, V2=10)
0 20 40 60 80 100
Player 1 Request
0.0
0.2
0.4
0.6
0.8
1.0Player 2 Rejection Probability (b) (V1=10, V2=60)
0 20 40 60 80 100
Player 1 Request
0.0
0.2
0.4
0.6
0.8
1.0Player 2 Rejection Probability (c) (V1=70, V2=10)
Figure 16: Observed rejection rates from experimental data of Binmore et al. (2002). A rational opponent
is governed by the step function (black line), where a rational player would reject in the red area and
accept in the green area. The observed points show deviations from rationality.
Now, knowing the opponent has potential bounds on their rationality, a rational player would respond
accordingly. Fig. 17 plots the distribution of Player 1 requests. We observe that Player 1’s request
still deviates from perfect rationality. Perfect rationality would imply a Dirac delta function with the
probability mass situated at the optimal request. The observed deviation from rationality may be due
to uncertainty in their opponent’s abilities (reﬂected in the probabilities from Fig. 16), or limitations of
Player 1’s reasoning.
C.4.2 Two-stage Bargaining
Next, we examine a two-stage bargaining game (shown in Fig. 15b). Now, if Player 2 rejects Player
1’s request, they can come back with a counteroﬀer of their own. If the players can not come to an
agreement, they both receive 0. It is, therefore, in both players best interest to reach an agreement. This
28
0 20 40 60 80 100
Request
0
1
2
3
4
5
6
7Count
(10, 10)
Equilibrium
(a) (V1=10, V2=10)
0 20 40 60 80 100
Request
0
2
4
6
8
10Count
(10, 60) (b) (V1=10, V2=60)
0 20 40 60 80 100
Request
0
1
2
3
4
5
6Count
(70, 10) (c) (V1=70, V2=10)
Figure 17: Player 1 requests in the Ultimatum game, with experimental data from Binmore et al. (2002).
The black line indicates the perfectly rational choice (when assuming opponent is perfectly rational), i.e.,
a rational opponent would reject any lower request (left of the black line), and would accept any value
above their rejection payoﬀ (right of the black line).
is represented with the following utilities:
U1[a1] = a1 ×f[accept |a1] + V1 ×f[reject |a1]
U2[accept2 |a1] = 100 −a1
U2[reject2 |a1] = V2
U2[a3] = D(100 −a3) ×f[accept |a3]
U1[accept4 |a3] = D×a3
U1[reject4 |a3] = 0
(18)
where now V1 and V2 are derived from the expected payoﬀ of the rejection branch. Conditioning on
past decisions are excluded from U2[a3] as it is implicit that this can only occur when Player 2 rejects
Player 1’s request. We use experimental data of Game 3 from Binmore et al. (2002), considering all
disagreement penalties D ∈[0.2,0.3,..., 0.9]. For discussion sake, here we assume D = 0 .9. With
perfect rationality, it is in Player 1’s best interest to accept any counteroﬀer greater than the rejection
payoﬀ of 0 (see Fig. 15b). Therefore, if prompted, Player 2 should provide a counteroﬀer of y= 1, which
gives Player 2 a payoﬀ of D(100 −y) = 89 .1, and Player 1 a payoﬀ of Dy = 0.9. Since Dy >0 (the
rejection payoﬀ), Player 1 should prefer this to the alternative and accept. With this in mind, Player 1
now knows the payoﬀ for the rejection branch for Player 2 is 89 .1, so if they request x >10 (assuming
integer requests), Player 2 will reject this request since 100 −x< 89.1 if x> 10. Therefore, the rational
Player 1 requests x= 10, maximising their payoﬀ, assuming Player 2 is rational.
0 20 40 60 80 100
0 20 40 60 80 100
Player 1 Request
0.0
0.2
0.4
0.6
0.8
1.0Player 2 Rejection Probability
Rational Player 1 Request
Irrational Player 1 Request
Perfectly Rational Player 1 Request
Rational Counteroffer
Figure 18: Two-stage Bargaining with disagreement penalty D= 0.9. Initial requests are shown as black
circles. The y-position gives the rejection rate of these requests. For rejected requests, the counteroﬀers
are shown as a purple star (linked to their original request by a line), where again, the y-position shows
the rejection rate of the counteroﬀer. The perfectly rational initial request would be x= 10 (black line),
as any requests in the red region would be rejected by a rational opponent. After a rejection, the perfectly
rational counteroﬀer would be y= 1 (purple line). Deviations from the subgame perfect equilibrium are
clear, with no player performing perfect backward induction.
However, from Fig. 18 which summarises results from the experiments presented by Binmore et al.
(2002), we can see substantial deviations from the subgame perfect equilibrium for both players. No
29
0 20 40 60 80 100
Player 1 Request
0.0
0.5
1.0
1.5
2.0
2.5
3.0Count
Equilibirum
(a) Player 1 Requests
0 20 40 60 80 100
Player 1 Request
0
20
40
60
80
100Player 2 Counteroffer
Experimental Counteroffers
Equilibirum Counteroffer (b) Player 2 Counteroﬀers
Figure 19: Initial requests and counteroﬀers in the two-stage bargaining game with D= 0.9.
Player 1 requests x< 10 or the perfectly rational request x= 10. Furthermore, no Player 2 requests the
rational counteroﬀer of y= 1. The distribution of initial and counteroﬀers is visualised in Fig. 19.
C.4.3 Comparison Methods
Level-k Under the level- k model, level-0 players are assumed to be indiﬀerent to all choices, and
chooose uniformly. Level-1 players exploit this, and choose based on their opponent being a level-0
player, and so on.
Cognitive Hierarchy Similar to the other game classes, again rather than assuming all players are at
k−1, the cognitive hierarchy model ﬁts a distribution to these k players, and best responds according
to this distribution of lower level thinkers. Again, the Poisson distribution is used.
Quantal Response Equilibrium For the Quantal Response Equilibrium, again, an agent form of
QRE is used to account for players noisily responding at each level, which is calculated recursively from
the ﬁnal step.
D Sensitivity
To ensure the method’s robustness, we check the sensitivity of the proposed results to various fac-
tors that may aﬀect the outcome. Speciﬁcally, we carried this testing out with respect to the conver-
gence/termination parameter ϵ and the ﬁtted density estimates.
D.1 Termination parameter
For the bargaining and centipede games, the reasoning naturally ends at the end of the extensive-
form game. However, for the market entry and beauty contest games (with no deﬁned end point), the
reasoning continues until the resources are depleted, i.e., βγk <ϵ. We have used the threshold ϵ= 10−8
to determine termination. To check the robustness of the method to ϵ, here we perform sensitivity
analysis across the range 10 −7 < ϵ <10−9, i.e. ±one order of magnitude from the default value. We
sample 1000 points uniformly from this range, presenting the results in Fig. 20.
In both cases, we can see the approach is robust to these large changes in ϵ, with an order of mag-
nitude change only having slight eﬀects on the resulting outcomes. These results show that ϵ does not
need to be treated as a hyperparameter to optimise (as β/γ), but rather as a ﬁxed parameter to deter-
mine “convergence” towards 0 and termination, the choice of which depends on computational/numeric
requirements. We recommend using as small value as possible (e.g. ϵ ≤10−8) while still achieving
reasonable convergence speed.
D.2 Density Estimates
We evaluate how the resulting rankings would change with diﬀerent density estimation methods. Specif-
ically, we analyse the resulting average (out-of-sample) ranks when using Scott’s rule (Scott, 2015) (as
presented), Silverman’s rule (Silverman, 2018), and the (improved) Sheather & Jones (Botev et al., 2010)
30
0 20 40 60 80 100
0.005
0.010
0.015
0.020
ϵ= 10−7
ϵ= 10−8
ϵ= 10−9
(a) Beauty Contest
0 2 4 6 8
0.1
0.2
0.3
0.4
0.5
0.6
0.7
0.8
0.9 (b) Market
Figure 20: Termination parameter ϵsensitivity. The outcome for the default value is displayed as the red
line. The outcome for the upper (lower) threshold is the dashed blue (green) bar. Intermediary values
are displayed as light grey lines.
for automatic bandwidth identiﬁcation. While this does not provide an exhaustive list, it covers the most
common rules used in literature. Density estimates are only used for the bargaining and beauty contest
games, so these are the two game classes analysed here.
In Table 3, we see no change in average ranking between Scott’s and Silverman’s rules for the beauty
contest games. However, when using Sheather & Jones, the rankings between Level- k and Nash change,
going from 4 and 5, respectively, to 4.33 and 4.67. This rank change does not alter any of the claims
made within the paper, so we can conﬁrm the robustness of the resulting rankings to density estimates
for the beauty game.
For the bargaining games, we see slight improvement for the proposed method when comparing Scott’s
rule with Silverman’s and Sheather & Jones—in both cases, going from 1.27 with Scott’s rule to 1.23. At
the same time, QREs rank worsens from 1.73 to 1.77. The remaining methods keep the same ranking.
These rank changes strengthen the claims made in the paper, showing not only robustness to the rule
used but also improvements for the proposed approach when utilising alternative rules for bandwidth
estimation.
Table 3: Robustness to changes in density estimation. Average rankings are computed using the results
from various automatic bandwidth determination methods. Scott’s is the method we present in the
paper.
Quantal Hierarchy Level-k Cognitive Hierarchy QRE Nash
Beauty Contests
Scott’s 1.83 4.00 3.00 1.17 5.00
Silverman’s 1.83 4.00 3.00 1.17 5.00
Sheather & Jones 1.83 4.33 3.00 1.17 4.67
Bargaining Games
Scott’s 1.27 3.50 3.50 1.73 5.00
Silverman’s 1.23 3.50 3.50 1.77 5.00
Sheather & Jones 1.23 3.50 3.50 1.77 5.00
31