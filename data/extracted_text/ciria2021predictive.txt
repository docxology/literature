1
Predictive Processing in Cognitive Robotics: a Review
1 2 3 4
AlejandraCiria, GuidoSchillaci ,GiovanniPezzulo ,VerenaV.Hafner
5
and Bruno Lara
1
FacultaddePsicolog´ıa. UniversidadNacionalAuto´nomadeMe´xico.
2
TheBioRoboticsInstitute. ScuolaSuperioreSant’Anna. Italy.
3
InstituteofCognitiveSciencesandTechnologies. NationalResearchCouncil. Italy.
4
Adaptive Systems Group. Department of Computer Science. Humboldt-Universita¨t zu
Berlin. Germany.
5
Laboratorio de Robo´tica Cognitiva. Centro de Investigacio´n en Ciencias. Universidad
Auto´nomadelEstadodeMorelos. Mexico
Keywords: Cognitiverobotics,predictiveprocessing,activeinference
Abstract
Predictive processing has become an influential framework in cognitive sciences. This
framework turns the traditional view of perception upside down, claiming that the main flow
ofinformationprocessingisrealizedinatop-downhierarchicalmanner. Furthermore,itaims
at unifying perception, cognition, and action as a single inferential process. However, in the
relatedliterature,thepredictiveprocessingframeworkanditsassociatedschemessuchaspre-
dictive coding, active inference, perceptual inference, free-energy principle, tend to be used
interchangeably. In the field of cognitive robotics there is no clear-cut distinction on which
schemeshavebeenimplementedandunderwhichassumptions. Inthispaper,workingdefini-
tions are set with the main aim of analyzing the state of the art in cognitive robotics research
workingunderthepredictiveprocessingframeworkaswellassomerelatednon-roboticmod-
els. The analysis suggests that, first, both research in cognitive robotics implementations
and non-robotic models needs to be extended to the study of how multiple exteroceptive
modalities can be integrated into prediction error minimization schemes. Second, a relevant
distinctionfoundhereisthatcognitiveroboticsimplementationstendtoemphasizethelearn-
ing of a generative model, while in non-robotics models it is almost absent. Third, despite
the relevance for active inference, few cognitive robotics implementations examine the is-
suesaroundcontrolandwhetheritshouldresultfromthesubstitutionofinversemodelswith
proprioceptivepredictions.
Finally, limited attention has been placed on precision weighting and the tracking of pre-
diction error dynamics. These mechanisms should help to explore more complex behaviors
1202
naJ
22
]OR.sc[
2v11660.1012:viXra
andtasksincognitiveroboticsresearchunderthepredictiveprocessingframework.
1 Introduction
Predictiveprocessinghasbecomeaninfluentialframeworkinthecognitivesciences. Adefin-
ing characteristic of predictive processing is that it “...depicts perception, cognition, and ac-
tion as the closely woven product of a single kind of inferential process.” (Clark, 2018, p.
522). This idea has caused a profound effect on the models and theories in different re-
search communities, from neuroscience to psychology, computational modelling and cogni-
tive robotics. In the literature, terms such as “predictive processing”, “hierarchical predictive
processing”, “active inference”, “predictive coding” and “free energy principle” are often
used interchangeably. Scholars refer to them either as theories or frameworks, occasionally
interweavingtheircoreideas.
In cognitive robotics, a number of architectures and models have claimed to follow the
postulates of these frameworks. Research in embodied cognitive robotics focuses on under-
standing and modeling perception, cognition, and action in artificial agents. It is through
bodily-interactions with their environment that agents are expected to learn and then be ca-
pable of performing cognitive tasks autonomously (Lara et al., 2018; Schillaci et al., 2016a).
Theaimofthisarticleistosetworkingdefinitionsanddelimitthemainideasforeachofthese
frameworks, so as to be able to analyze the literature of cognitive robotics and the different
implementationsintheliterature. Thisshouldhelptohighlightwhathasbeendoneandwhat
ismissing,andaboveall,whattherealimpactoftheseframeworksintheareaofroboticsand
artificialintelligenceis. Finally,this manuscript setstheissuesandchallengesthatthesenew
frameworksbringonthetable.
Thestructureofthispaperisasfollows. Section2setstherelevantworkingdefinitions. In
Section3different modelsandarchitecturesareanalyzed inthelightof theabovementioned
frameworks. Section4closesthepaper.
2 Working definitions
For the purpose of this article, predictive processing is considered to be the most general
set of postulates. Predictive processing proposes to turn the traditional picture of perception
upside down (Clark, 2015). The standard picture of perceptual processing is dominated by
thebottom-upflowofinformationwhichistransducedfromsensoryreceptors. Inthispicture
of perception, as information flows upwards, a progressively richer picture of the world is
then constructed from a low-level feature layer processing perceptual input to a high-level
semantics layer interpreting information (Marr, 1982). All together, predictive processing
claims to unify perception, cognition and action under the same explanatory scope (Clark,
2013;Hohwy,2013).
Thepredictiveprocessingviewofperceptionstatesthatagentsareconstantlyandactively
predictingsensorystimulationandthatonlydeviationsfromthepredictedsensoryinput(pre-
diction errors) are processed bottom-up. Prediction error is newsworthy sensory information
which provides corrective feedback on top-down predictions and promotes learning. There-
fore, in this view of perception, the core flow of information is top-down and the bottom-up
2
flow of sensory information is replaced by the upward flow of prediction error. The core
function of the brain is minimizing prediction error. This process has become known as Pre-
diction Error Minimization (PEM). In a general sense, PEM has been a scheme used in
manymachinelearningalgorithmswheretheerrorbetweenthedesiredoutputandtheoutput
generated by the network is used for learning (see, for instance, backpropagation algorithms
for training neural networks). Different strategies of PEM have been used in models for per-
ceptionandactioncontrolinartificialagents(seeSchillacietal.(2016a)forareview).
Going further, predictive processing suggests that the brain is an active organ that con-
stantly generates explanations about sensory inputs and then tests these hypotheses against
incoming sensory information (Feldman and Friston, 2010) – in a way that is coherent with
Helmholtz’sviewofperceptionasanunconsciousformofinference.
Figure 1: Schematic representation of hierarchical neuronal message under the predictive
processingpostulates.
Recurrentneuronalinteractionswithdescendingpredictionsandascendingpredictioner-
rors following the predictive processing postulates are illustrated in a simplified segment of
thecorticalhierarchyinFigure1.A.Neuronalactivityofdeeppyramidalcells(representedin
black)athigherlayersofthecortexencodepriorbeliefsabouttheexpectedstatesofthesuper-
ficial pyramidal cells (represented in red) at lower layers. At each cortical level, prior beliefs
encode the more likely neuronal activity at lower levels. Superficial pyramidal cells compare
descending predictions with the ascending sensory evidence resulting in what is known as
prediction error. The prediction error at superficial pyramidal cells is sent to deep pyramidal
cells for belief updating (posterior belief). In Figure 1.B descending modulation determines
the relative influence of prediction errors at lower levels of the hierarchy on deep pyramidal
cells encoding predictions. Precision beliefs are encoded by a descending neuromodulatory
gating or gain control (green) of superficial pyramidal cells. In Bayesian inference, beliefs
3
about precision have a great effect on how posterior beliefs are updated. Precision beliefs
are considered an attentional mechanism which weightens predictions and sensory evidence
depending on how certain or useful these are for a given task and context. Figure 1.C shows
a particular example of active inference for prediction error minimization. Perceptual infer-
ences about grasping a cup generate visual, cutaneous, and proprioceptive prediction errors
that are then minimized by movement. Descending proprioceptive predictions should be ful-
filled by being highly weighted to incite movement. Then, proprioceptive prediction errors
are generated at the level of the spinal cord and minimized at the level of peripheral reflexes.
At the same time, when the movement trajectory to grasp the cup is performed, visual and
cutaneouspredictionerrorsareminimizedatalllevelsofthecorticalhierarchy.
Humansandotherbiologicalagentshavetodealwithaworldfullofsensoryuncertainty.
In humans, there is psychophysical evidence that shows how Bayesian models can account
forperceptualandmotorbiasesbyencodinguncertaintyintheinternalrepresentationsofthe
brain(KnillandPouget,2004).
There are several Bayesian approaches centered on the idea that perceptual and cogni-
tive processes are supported by internal probabilistic generative models (Clark, 2013, 2015;
Friston, 2010a; Hohwy, 2013; Rao and Ballard, 1999). A generative model is a probabilistic
model (joint density), mapping hidden causes in the environment with sensory consequences
from which samples are generated (Friston, 2010a). It is usually specified in terms of the
likelihood probability distribution of observing some sensory information given its causes,
and a prior probability distribution of the beliefs about the hidden causes of sensory infor-
mation (before sampling new observations) (Badcock et al., 2017). A posterior density is a
posterior belief generated by combining the prior and the likelihood weighted according to
theirprecision,definedastheinversevariance(Adamsetal.,2013b). Aposteriordensitycan
becalculatedusingtheBayestheorem:
p(O|s)p(s)
p(s|O) = (1)
p(O)
wherep(s|O),alsoknownastheposteriorbelief,istheprobabilityofhypothesisswitha
given evidence or observation O. Prior beliefs are updated (thus becoming posterior beliefs)
when sensory evidence (likelihood) is available. p(O|s) is the likelihood relating the sensory
observation to the hidden causes, this is, the probability of the specific evidence O. P(s) is
thepriordistributionofanyhypothesissorpriorbeliefanditcanbeseenasthepredictionof
states. P(O)istheprobabilityofencounteringthisevidenceorobservation.
This calculation is often practically intractable, and variational Bayes is then used for
approximately calculating the posterior. This method introduces an optimization problem
which requires an auxiliary probability density termed as the recognition density (Buckley
etal.,2017).
Prediction error is the difference between the mean of the prior belief and the mean of
the likelihood in their respective probability distributions. Information gain is measured as
the KL divergence between the prior belief and the posterior belief. The prior and likelihood
distributions have an expected precision, which is encoded as the inverse of their respective
variance. Thisprecisionwillbiastheposteriorbeliefupdate. Inparticular,theposteriorbelief
is updated biased towards the prior belief given its higher expected precision as compared to
the low expected precision on sensory evidence (see Figure 2A). On the contrary, when the
expected precision on prior belief is low and the expected precision on sensory evidence is
4
high, the prediction is more uncertain or unreliable, having less of an impact on how the
posterior belief is updated than the sensory evidence (see Figure 2B). In both examples in
Figure2,althoughthemagnitudeofthepredictionerrorisequivalent,theinformationgainis
greaterinBduetothegreaterdivergencebetweenthepriorandtheposteriorbeliefs.
Figure2: RelevanceoftheprecisionofprobabilitydistributionsinBayesianinference.
InBayesianinference,therearebeliefsaboutbeliefs(empiricalpriors)intermsofhaving
expectations about the beliefs’ precision or uncertainty (Adams et al., 2013b). Here, atten-
tion is seen as a selective sampling of sensory information, in such a way that predictions
about the confidence of the signals are made to enhance or attenuate prediction errors from
different sensory modalities. In order to attain this sampling, this framework proposes a
mechanismknownasprecisionweighting. Theinformationcomingfromdifferentmodalities
are weighted according to the expected confidence given a certain task in a certain context
(ParrandFriston,2017;Fristonetal.,2012a;Donnarummaetal.,2017).
Importantly,precisionweightsarenotonlyassignedaccordingtotheirreliability,butalso
by their context-varying usefulness, and are thus considered to be a mechanism for behavior
control (Clark, 2020). In the brain, precision weighting might be mediated by a neuromod-
ulatory gain control which can be conceived as a Bayes-optimal encoding of precision at a
synaptic level of neuronal populations encoding prediction errors (Friston et al., 2014). Pre-
dictionerrorswithhighprecisionhaveagreatimpactonbeliefupdating,andpriorswithhigh
precisionarerobustinthefaceofnoisyorirrelevantpredictionerrors.
Bayesianbeliefsaretreatedasinferencesabouttheposteriorprobabilitydistribution(recog-
nition density) via a process of belief updating (Ramstead et al., 2020). The recognition den-
sity is an approximate probability distribution of the causes of sensory information which
encodes posterior beliefs as a product of inverting the generative model (Friston, 2010a).
According to the Bayesian brain hypothesis, prior beliefs are encoded as neuronal represen-
tations, and in light of the new evidence beliefs are updated (posterior density) to produce
a posterior belief following Bayes’ rule (Friston et al., 2014). This means that the brain en-
codes Bayesian recognition densities within its neural dynamics, which can be conceived as
5
inferences of the hidden causes to find the best ‘guess’ of the environment (Demekas et al.,
2020).
According to Friston et al. (2006), predictive processing must be situated within the con-
textofthefree-energyprinciple(Williams,2018),giventhat’predictionerrorminimization’,
under certain assumptions, corresponds to minimizing free energy (Friston, 2010b). Predic-
tive processing can be seen as a name for a family of related theories, where the free energy
principle (FEP) provides a mathematical framework to implement the above ideas. The free-
energy principle is a biological and a neuroscientific framework in which prediction error
minimization is conceived as a fundamental process of self-organizing systems to maintain
their sensory states within their physiological bounds in the face of constant environmental
changes(Adamsetal.,2013a;Friston,2009,2010b).
Essentially, the free-energy principle is a mathematical formulation of how biological
agents or systems (like brains) resist a natural tendency to disorder by limiting the repertoire
of their physiological and sensory states that define their phenotypes (Friston, 2010b). In
other words, to maintain their structural integrity, the sensory states of any biological system
must have low entropy. Entropy is the negative log-probability of an outcome or the average
‘surprise’ of sensory signals under the generative model of the causes of the signals (Friston
etal.,2011).
Therefore, biological systems are obliged to minimize their sensory surprise (and im-
plicitly entropy) in order to increase the probability of remaining within their physiological
boundsoverlongtimescales(Friston,2009).
The main aim of minimizing free energy is to guarantee that biological systems spend
most of their time in their valuable states, those which they expect to frequent. Prior expec-
tations prescribe a primary repertoire of valuable states with innate value, inherited through
geneticandepigeneticmechanisms(Friston,2010b).
Agents are constantly trying to maximize the evidence for the generative model by min-
imizing surprise. The FEP claims that because biological systems cannot minimize surprise
directly, they need to minimize an upper bound called ‘free energy’ (Buckley et al., 2017).
Free energy can be expressed as the Kullback-Leibler divergence between two probability
distributions, subtracted by the natural log of the probability of possible states. As stated in
Sajidetal.(2020),freeenergycanalwaysbewrittenintermsofcomplexityandaccuracy:
F = D (Q(s)||P(s|o))−lnP(o)
KL
(2)
= D (Q(s)||P(s)))−E [lnP(o|s)]
KL Q
WhereQ(s)istherecognitiondensityorapproximateposteriordistribution,andencodes
the prior beliefs an agent possesses about the unknown variables. The conditional density
P(s|o) is the probability of some (hidden) state (s) given a certain observation (o), and is
refereed to as the generative model. The first writing in Eq. 2 can be read as evidence bound
minuslogevidenceordivergenceminussurprise. Rewrittenasinthesecondlineitisreadas
complexity,whichisthedifferencebetweentheposteriorbeliefsandpriorbeliefsbeforenew
evidenceisavailableandaccuracy,theexpectedloglikelihoodofthesensoryoutcomesgiven
someposterioraboutthecausesofthedata(Sajidetal.,2020).
The recognition density (coded by the internal states) and the generative model are nec-
essary to evaluate free energy (Friston, 2010a). Variational free energy (VFE) provides an
6
upper bound on surprise, and it is formally equivalent to weighted prediction error (Buckley
et al., 2017). VFE is a statistical measure of the surprise under a generative model. Negative
VFEprovidesalowerboundonmodelevidence. MinimizingVFEwithrespecttotherecog-
nition density will also minimize the Kullback-Leiber divergence between the recognition
density and the true posterior. Therefore, minimizing VFE makes the recognition density,
the probabilistic representation of the causes of sensory inputs, an approximate of the true
posterior(Friston,2010a). Optimizingtherecognitiondensitymakesitaposteriordensityon
thecausesofsensoryinformation.
Biological agents can minimize free energy by means of two strategies: changing the
recognition density or actively changing their internal states. Changing the recognition den-
sity minimizes free energy and thus, reduces the perceptual divergence. This is a relevant
componentofthefreeenergyformulationwhenexpressedascomplexityminusaccuracy.
Minimizing perceptual divergence increases the complexity of the model, defined as the
difference between the prior density and the posterior beliefs encoded by the recognition
density (Friston, 2010a). This first strategy is known as perceptual inference, this is, when
agents change their predictions to match incoming sensory information. Given that sensory
information can be very noisy and ambiguous, perceptual inferences are necessary to make
theinputcoherentandmeaningful.
The second strategy is the standard approach to action in predictive processing, known
as active inference (Adams et al., 2013a; Brown et al., 2013), which consists of an agent
changing sensory inputs through actions that conform to predictions. This is the same as
minimizing the expected free energy (Kruglanski et al., 2020). When acting on the world,
free energy is minimized by sampling sensory information that is consistent with prior be-
liefs. An action can be defined as a set of real states that change hidden states in the world,
which are closely related to control states inferred by the generative model to explain the
consequencesofaction(Fristonetal.,2012b). Therefore,actionsdirectlyaffecttheaccuracy
of the generative model, defined as the surprise about sensory information expected under
the recognition density (Friston, 2010a). For survival, valuable actions are those which are
expectedtoprovideagentswiththecapabilitytoavoidstatesofsurprise.
Every action serves to maximize the evidence of the generative model in such a way that
policies are selected to minimize complexity. The expected action consequences include the
expected inaccuracy or ambiguity, and the expected complexity or risk, which are combined
into the expected free energy (Kruglanski et al., 2020). Thus, expected free energy is the
valueofapolicy,describingitspragmatic(instrumental)andepistemicvalue. Inotherwords,
actions are valuable if they maximize the utility by exploitation (fulfilling preferences), and
if they minimize uncertainty by exploration on model parameters (information gathering, as
in intrinsic motivation strategies) (Seth and Tsakiris, 2018). Maximizing epistemic value is
associatedwithselectingactionsthatincreasemodelcomplexitybychangingbeliefs,whereas
maximizing pragmatic value is associated with actions that change internal states that align
with beliefs (Tschantz et al., 2020). Consequently, the minimization of expected free energy
occurswhenpragmaticandepistemicvaluearemaximized.
Priors are constantly optimized because they are linked hierarchically and informed by
sensory data in such a way that learning occurs when a system effectively minimizes free
energy (Friston, 2010b). Here, motor commands are proprioceptive predictions, as specific
muscle movements (internal frame of reference) are mapped onto an external frame of refer-
ence(e.g. vision).
7
Furthermore,ithasbeensuggestedthatforbiologicalsystems“...itbecomesimportantnot
only to track the constantly fluctuating instantaneous errors, but also to pay attention to the
dynamics of error reduction over longer time scales.” (Kiverstein et al., 2019, p. 2856). Rate
of change in prediction error is relevant for epistemic value and novelty seeking situations.
In other words, this mechanism permits an agent to monitor how good it is in performing
an action, and it has been suggested as the basis for intrinsic motivation and value related
learning (Kiverstein et al., 2019; Kaplan and Friston, 2018). Therefore, prediction error and
its reduction rates might signal the expectations on the learnability of particular situations
(VandeCruys,2017).
Currently,predictivecodingisthemostacceptedcandidatetomodelhowpredictivepro-
cessing principles are manifested in the brain, namely those laid out by the FEP (Friston,
2009; Buckley et al., 2017). It is a framework for understanding redundancy reduction and
efficient coding in the brain (Huang and Rao, 2011) by means of neuronal message passing
among different levels of cortical hierarchies (Rao and Ballard, 1999). ’Hierarchical predic-
tive coding’ suggests that the brain predicts its sensory inputs on the basis of how higher-
levels provide predictions about lower-levels activation until eventually making predictions
about incoming sensory information (Friston, 2002, 2005). Active inference enables pre-
dictive coding in a prospective way, where actions attempt to fulfill sensory predictions by
minimizingpredictionerror(Fristonetal.,2011).
Inthisframework,theminimizationofpredictionerroroccursthroughrecurrentmessage
passing within the hierarchical inference (Friston, 2010b). Therefore, the changes in higher-
levels are driven by the forward flow of the resultant prediction errors in the lower-level to
optimizetop-downpredictionsuntilthepredictionerrorisminimized(Friston,2002,2010b).
Predictive coding is closely related to Bayes formulations, from the explanation of how
“hierarchicalprobabilisticgenerativemodels”areencodedinthebraintothemannerinwhich
the whole system deals with uncertainty. Furthermore, the PEM hypothesis suggests that the
braincanbeconceivedasbeing“literallyBayesian”(Hohwy,2013,p. 17).
However, there is an increasing number of predictive coding variants, for example, there
are differences in the algorithms and in the type of generative model they use (Spratling,
2017), and in the excitatory or inhibitory properties of the hierarchical connections (e.g. Rao
and Ballard (1999); Spratling (2008), among others). “These issues matter when it comes to
finding definitive empirical evidence for the computational architectures entailed by predic-
tivecoding”(Friston,2019,p. 3).
Alloftheseframeworksprovidenewwaystosolvetheperception-actioncontrolproblem
incognitiverobotics(Schillacietal.,2016a). Inthelastcoupleofdecades,thestandardsolu-
tion was the use of paired inverse-forward models in what is known as Optimal Control The-
ory(OCT).InOCT,acopyofamotorcommandpredictedbyaninversemodelorcontrolleris
passedtoaforwardmodelthatinturn,predictsthesensoryconsequencesoftheexecutionof
the movement (D M Wolpert and Jordan, 1995; Wolpert and Kawato, 1998; Kawato, 1999).
This leads to multiple implementations using artificial agents with different computational
approaches(DemirisandKhadhouri,2006;Mo¨llerandSchenck,2008;Escobar-Jua´rezetal.,
2016; Schillaci et al., 2016b). OCT presents a number of difficult issues to solve, such as the
ill-posedproblemoflearninganinversemodel.
On the other hand, in predictive processing, optimal movements are understood in terms
of inference and beliefs, and not by the optimization of a value function of states as being
the causal explanation of movement (Friston, 2011). Therefore, there are no desired conse-
8
quences, because experience-dependent learning generates prior expectations, which guide
perceptualandactiveinference(Fristonetal.,2011). ContrarytoOCT,inpredictiveprocess-
ing there are no rewards or cost functions to optimize behavior. Optimal behavior minimizes
variational free energy, and cost functions are replaced by priors about sensory states and
their transitions (Friston et al., 2012b). Understanding movement as a matter of beliefs for
generatinginferencesremovestheproblemoflearninganinversemodel.
Therefore, predictive processing suggests that there is no need for an inverse model and,
thus, for any efference copy of the motor command as input to a forward model. The mere
existence of the efference copy of the motor command is nowadays a controversial issue
(Dogge et al., 2019; Pickering and Clark, 2014). The core mechanism in predictive process-
ing is an Integral Forward Model (Pickering and Clark, 2014), or better known as a genera-
tive model, in which motor commands are replaced by proprioceptive top-down predictions,
mapping prior beliefs to sensory consequences (Friston, 2011; Clark, 2015; Friston et al.,
2012b). Top-down predictions can be seen as control states based on an extrinsic frame of
reference (world-centered-limb position) that are translated into intrinsic muscle-based co-
ordinates which are then fulfilled by the classical reflex arcs (Friston, 2011). Minimizing
proprioceptive prediction error brings the action about, which is enslaved to fulfill sensory
predictions(Fristonetal.,2011).
3 Implementations
In this section, we review implementation studies inspired on the models and frameworks
describedintheprevioussection. Differentreviewpaperscanbefoundintheliterature. This
work focuses mostly on robotics research, which has been developing quite rapidly in the
last couple of years. We review also a number of non-robotic studies, in particular those
havingimportantaspectsthathavenotreceivedenoughexplorationinrobotics. Byhighlight-
ing them, this work aims at encouraging new experimental research in embodied cognitive
robotics.
We are certain that there could be work which is not mentioned in this article. The omis-
sion is not intentional. Articles have been selected under two criteria. First, the authors
mention in their work any of the frameworks described in the previous section. Second, al-
though the authors do not explicitly mention these frameworks, it is our understanding that
these works could well enter the discussion and bring interesting topics and questions to the
table. This includes also some non-robotic works. Deriving from the descriptions in the pre-
vious section, the following items have been considered as relevant to analyze the literature
incognitiverobotics:
• (Bay) Bayesian/Probabilistic framework. Does the study adopt a Bayesian or proba-
bilisticformalization?
• (PW) Precision weights. Top down predictions and bottom-up prediction errors are
dynamicallyweightedaccordingtotheirexpectedreliability.
• (FofI) Flow of information. Predictions flow top-down while the difference between
predictions and real sensory information – i.e., prediction error – flows bottom-up in
themodel.
9
• (HP) Hierarchical processing. The model presents a hierarchical structure for the pro-
cessingofinformation.
• (IM) Inverse model. The work discusses the benefits or challenges of using an inverse
model,asitisthecaseinOCT.
• (Mod)Modalities. Whichmodalitiesaretackledintheproposedmodel.
• (BC)Beyondmotorcontrolandestimationofbodystates. Mostofthereviewedstudies
adopts predictive processing frameworks to control robot movements. This attribute
is defined to highlight those studies that make a step further by addressing aspects
of the framework that may help understanding or implementing higher-level cognitive
capabilities.
The selected studies are summarized in Tables 1 and 2. In particular, Table 1 classifies
eachstudyaccordingtotheattributesmentionedabove. Table2providesanoverviewofsome
implementationdetailsoftheseworks:
• Training: the generative model used in the study is either pre-coded or trained. If
applicable, this specifies what type of learning algorithm (i.e., online or off-line) has
beenemployed;
• Datageneration: ifapplicable,thisspecifieshowthetrainingdatahasbeengenerated;
• Agent: whattypeofartificialsystemhasbeenusedintheexperiment;
• Generativemodel: the name,or acronym,of thegenerative modelthat hasbeen imple-
mented in the study. Some studies may have not implemented any generative model,
butusedinsteadtheforwardkinematicsprovidedbytherobotmanufacturer.
• Aim: whatcognitiveormotortaskhasbeenmodelled.
3.1 Robotic implementations
The analysis of the literature starts with one of the first robotic implementations of predic-
tive processing. Tani and Nolfi (1999) present a two-layers hierarchical architecture that
self-organizes expert modules. Each expert module is a Recurrent Neural Network (RNN).
The bottom layer of RNNs is trained and responds to different types of sensory and motor
inputs. The upper set of experts serves as a gating mechanism for the lower level RNNs.
The computational model has been deployed onto a simulated mobile robot for a navigation
task.The architecture is trained in an on-line fashion. After a short period of time, the gating
experts specialize in navigating through corridors, right and left turns and T-junctions. The
free parameters of the architecture are trained on-line using the back-propagation through
time algorithm (Rumelhart et al., 1986). However, as the authors point out, a limitation of
the architecture is that it only uses the bottom-up flow of information, without integrating
top-down predictions to modulate the activation of lower levels. Tani (2019) provides a thor-
ough review of related neurorobotics experiments, many of which carried out in the authors’
laboratory. A very interesting implementation is described in Hwang et al. (2018), which the
10
Article Bay PW FofI HP IM Mod BC Aim
Roboticstudies
TaniandNolfi(1999) - - - (cid:88) - V - Safenavigation
AhmadiandTani(2019) (cid:88) - (cid:88) (cid:88) - PV - Movementimitation
AhmadiandTani(2017) - - (cid:88) (cid:88) - PV - Movementimitation
BaltieriandBuckley(2017) (cid:88) (cid:88) (cid:88) - (cid:88) L - Gradientfollowing
Hwangetal.(2018) - - (cid:88) (cid:88) - PV - Gestureimitation
Ideietal.(2018) (cid:88) (cid:88) (cid:88) - - PV (cid:88) Simul.ofautisticbehav.
LanillosandCheng(2018) (cid:88) - (cid:88) - - PV(T) - Bodyposeestimation
Lanillosetal.(2020) (cid:88) - (cid:88) - - PV (cid:88) Self-otherdistinction
Murataetal.(2015) (cid:88) - (cid:88) (cid:88) - PV - Human-robotinteract.
OhataandTani(2020) (cid:88) - (cid:88) (cid:88) (cid:88) PV (cid:88) Multimodalimitation
Oliveretal.(2019) (cid:88) - (cid:88) - - PV - Visuo-motorcoordin.
Parketal.(2018) - - (cid:88) (cid:88) - PV - Armcontrol
Pezzatoetal.(2020) (cid:88) - (cid:88) - (cid:88) P - Armcontrol
Pio-Lopezetal.(2016) (cid:88) (cid:88) (cid:88) (cid:88) (cid:88) PV - Controlandbodyestim.
SancaktarandLanillos(2019) (cid:88) - (cid:88) - - PV - Controlandbodyestim.
Schillacietal.(2020a) - - - - (cid:88) PV (cid:88) Goalregulation,emotion
Annabietal.(2020) (cid:88) - - - (cid:88) PV - Simul.armcontrol
Zhongetal.(2018) - - (cid:88) (cid:88) - PV - Movementgeneration
Nonroboticstudies
Allenetal.(2019) (cid:88) (cid:88) (cid:88) - - IV (cid:88) Emotionalinference
BaltieriandBuckley(2019) (cid:88) - (cid:88) - (cid:88) P - 1DoFControl
Fristonetal.(2015) (cid:88) (cid:88) (cid:88) (cid:88) - RO (cid:88) Explorat.vsexploitat.
HuangandRao(2011) (cid:88) - (cid:88) (cid:88) - V - Visualperception
Olivaetal.(2019) (cid:88) (cid:88) - - - V (cid:88) PWdevelopment
PhilippsenandNagai(2019) (cid:88) (cid:88) - - - V (cid:88) PW&represent.drawing
Tschantzetal.(2020) (cid:88) - (cid:88) - - RO (cid:88) Epistemicbehaviours
Table 1: Legend. Bay: Bayesian/probabilisticframework;PW:implementsprecision-weighting;FofI:tacklesbottom-up/top-down
flowsofinformation;HP:implementshierarchicalprocessing;IM:discussesabouttheneedofinversemodels;Mod:modalitiesaddressed
intheexperiment(P:proprioception,V:visual;T:tactile;I:interoceptive;L:luminanceaschemo-trail;RO:simulatedrewardsandobser-
vation);BC:thestudygoesbeyondmotorcontrolandestimationofbodystates.
11
Article Train Datageneration Agent Generativemodel
Roboticstudies
TaniandNolfi(1999) On-line Directlearning Mobile.ag. RNN
AhmadiandTani(2019) Off-line Directteaching Humanoid PV-RNN
AhmadiandTani(2017) Off-line Directteaching Humanoid MTRNN
BaltieriandBuckley(2017) On-line Exploration Mobile.ag. Agentdynamics
Hwangetal.(2018) Off-line Directteaching Simul.hum. VMDNN
Ideietal.(2018) Off-line Recordedsequences Humanoid S-CTRNNwithPB
LanillosandCheng(2018) Off-line Randommovements Humanoid GaussianProcessRegress.
Lanillosetal.(2020) Re-train left-rightarmmov. Humanoid Mixt.Dens.Net.,DLclass.
Murataetal.(2015) Off-line Motionese Humanoid S-CTRNN
OhataandTani(2020) Off-line Humandemonstrations Humanoid MultiplePV-RNN
Oliveretal.(2019) None N.A. Humanoid Forwardkinematics
Parketal.(2018) Dev.learn. Setsofactions Humanoid RNNPB
Pezzatoetal.(2020) None N.A. Industr.rob. Set-points
Pio-Lopezetal.(2016) None N.A. Humanoid Forwardkinematics
SancaktarandLanillos(2019) Off-line Rand.expl.,directteach. Humanoid Convolutionaldecoder
Schillacietal.(2020a) On-line Goal-directedexpl. Simul.robot Conv.AE,SOM,DeepNN
Annabietal.(2020) Off-line Exploration Simul.arm SOM,RNN
Zhongetal.(2018) Off-line Recordedsequences Simul.robot ConvolutionalLSTM
Nonroboticstudies
Allenetal.(2019) None N.A. Minim.agent MarkovDecisionProcess
BaltieriandBuckley(2019) On-line N.A. 1DoFagent Systemdynamics
Fristonetal.(2015) None N.A. Simul.rat POMDP
HuangandRao(2011) Off-line Imagedataset - Hierarchicalneuralmodel
Olivaetal.(2019) Off-line Pre-codedtrajectories Sim.drawing S-CTRNN
PhilippsenandNagai(2019) Off-line Humandemonstrations Sim.drawing S-CTRNN
Tschantzetal.(2020) On-line RLexploration OpenAIsim Gaussian,Laplaceapprox.
Table 2:
Legend. Training: whichtypeoftraining–ifapplicable–hasbeenperformedonthegenerativemodel;DataGeneration:
howthetrainingdatahasbeengenerated; Agent: whichtypeofartificialsystemhasbeenused; Generativemodel: thenameofthe
machinelearningtool–ifapplicable–thathasbeenadoptedfortrainingthegenerativemodel;Aim: whichcognitiveormotortaskhas
beenmodelled.N.A.:notapplicable.
12
authors refer to as a predictive coding model. The adopted network is a multi-layer hierar-
chical architecture encoding visual and proprioceptive information. Although the work is far
fromtheformulationslaidinthefree-energyprinciple(Friston,2009),theVMDNN(Predic-
tive Visuo-Motor Deep Dynamic Neural Network) performs very similar operations. These
include the generation of actions following a prediction error minimization scheme and the
usage of the same model structure for action generation and recognition. Authors claim that
“the proposed model provides an online prediction error minimization mechanism by which
the intention behind the observed visuo-proprioceptive patterns can be inferred by updating
theneurons’internalstatesinthedirectionofminimizingthepredictionerror”(Hwangetal.,
2018,pp. 3). Itisworthnotingthatsuchanupdatedoesnotrefertomodelweightsbutonlyto
the state of the neurons. The training of the model is performed in a supervised fashion. The
errorbeingminimizedisthedifferencebetweenasignalgeneratedthroughkinestheticteach-
ing(i.e.,whereahumanexperimentermanuallydirectsthemovementsoftherobotlimb)and
the model predictions. A very interesting aspect of the network are the lateral connections
betweenmodalitiesateachlayerofthehierarchy.
Another relevant work from the same group (Ahmadi and Tani, 2019) stands out for its
formulation of active inference and a training strategy based on variational Bayes Recurrent
NeuralNetworks.
Finally, Ahmadi and Tani (2017) propose a multiple timescale recurrent neural network
(MTRNN) which consists of multiple levels of sub-networks with specific temporal con-
straints on each layer. The model processes data from three different modalities and is capa-
ble of generating long-term predictions in both open-loop and closed-loop fashions. During
closed-loop output generation, internal states of the network can be inferred through error
regression. The network is trained in an open loop manner, modifying free parameters using
theerrorbetweendesiredstatesandrealactivationvalues.
Acommoncharacteristicoftheimplementationsreviewedsofaristhatlearningandtest-
ing are decoupled. During the testing phase, prediction errors flow bottom-up and the net-
work’s “internal state is modified in the direction of minimizing prediction error via error
regression” (Ahmadi and Tani, 2017, pp. 4). This implies that network’s weights are not
modifiedafter training. In mostoftheirworks, Taniandcolleagues usemathematicalformu-
lationsbasedonconnectionistnetworksanddifferentfromthoseproposedbyFriston(2009);
nonetheless,theworkisconceptuallyveryrelatedtopredictivecodingandactiveinference. In
morerecentworks(e.g. (MatsumotoandTani,2020;Jungetal.,2019)),authorsuseexplicitly
variational inference. An illustrative architecture, that comprises most of the characteristics
ofthenetworksusedbytheseauthorscanbeseeninFigure1inHwangetal.(2018).
AsimilarapproachispresentedbyMurataetal.(2015),whoproposeaRNN-basedmodel
named stochastic continuous-time RNN (S-CTRNN). The framework integrates probabilis-
tic Bayesian schemes in a recurrent neural network. Networks training is performed off-line
usingtemporalsequencesundertwolearningconditions,i.e.,withandwithoutpresentingac-
tions that reveal distinctive characteristics amplifying or exaggerating meaning and structure
withinbodilymotions(alsonamedmotionese(Brandetal.,2002)). Trainingdataisobtained
throughkinestheticteachingontherobotdirectedbyanexperimenter. Thelossfunctionofthe
optimization process considers the sum of log-uncertainty and precision-weighted prediction
error. Thisisformallyequivalenttofreeenergyasproposedinactiveinference.
Intryingtoexplaintheunderlyingmechanismscausingdifferenttypesofbehavioralrigid-
ity of the autism spectrum, Idei et al. (2018) adopt a S-CTRNN with parametric bias (PB) as
13
the computational model for simulating aberrant sensory precision in a humanoid robot. In
this study, S-CTRNN learn to estimate sensory variance (precision) and to adapt to differ-
ent environments using prediction error minimization schemes. Learning is performed in an
off-line fashion using pre-recorded perceptual sequences. ”The objective of the learning is
to find the optimal values of the parameters (synaptic weights, biases, and internal states of
PB units) minimizing negative log-likelihood, or precision weighted prediction error”. Once
trained, the network is capable of reproducing target visuo-proprioceptive sequences. In the
test phase following the learning one, only the internal states of the PB units are updated in
anonlinefashion,whilekeepingtheotherparametersasfixed. Thestudysimulatesincreased
and decreased sensory precision by altering estimated sensory variance (inverse of their pre-
cision). Thisisperformedbymodulatingaconstantintheactivationfunctionofthevariance
units of the trained model. Interestingly, the authors report abnormal behaviors in the robot,
such as freezing and inappropriate repetitive behaviors, correlated to specific modulation of
the sensory variance. In particular, increased sensory variance reduces the precision of pre-
dictionerror,thusfreezingthePBstatesofthenetworkand,consequently,therobotbehavior.
Decreasingsensoryvariance,instead,leadstounlearnedrepetitivebehavior,likelyduetothe
fixationofthePBstatesonsub-optimallocalsolutionduringpredictionerrorminimization.
Ohataand Tani(2020)extends thePredictivecoding-inspired VariationalRecurrentNeu-
ralNetwork(PV-RNN)presentedbyAhmadiandTani(2019)inamultimodalimitativeinter-
action experiment with a humanoid robot.Modalities (proprioception and vision) – each en-
codedwithamulti-layeredPV-RNN–areconnectedthroughanassociativePV-RNNmodule.
The associative module generates the top-down prior, which is then fed to both the proprio-
ceptionandvisionmodules. Eachsensorymodulealsogeneratestop-downpriorsconditioned
by the other flows. Authors show how meta-priors assigned to the proprioception and vision
modulesimpactthelearningprocessandtheperformanceoftheerrorregression. Modulating
theKullback-Leiblerdivergence(KLD)termintheerrorminimizationschemeleadstoabet-
ter regulation of multimodal perception, which would be otherwise biased towards a single
modality. StrongerregulationoftheKLDtermalsoleadtohigheradaptivityinahuman-robot
imitationexperiment.
Park et al. (2012) proposes an architecture based on self-organizing maps and transition
matricesforstudyingthreedifferentcapabilitiesandphenomena,i.e.,performingtrajectories,
object permanence and imitation. Interestingly, the architecture features a hierarchical self-
organized representation of state spaces. However, no bidirectional (top-down/bottom-up)
flow of information as in the previous studies is implemented. Moreover, the models are in
partpre-coded.Inamorerecentstudy,Parketal.(2018)adoptarecurrentneuralnetworkwith
parametricbias(RNNPB)withrecurrentfeedbackfromtheoutputlayertotheinputlayer. As
in(Tani,2019),trainingandtestingaredecoupledandtheoptimizationisbasedontheback-
propagation through time algorithm. The optimization of the network parameters uses the
prediction error between a generated motor action and a reference action. Remarkably, this
work analyses the developmental dynamics of the parameter space in terms of prediction
error. Experimentsarecarriedoutonasimulatedtwodegrees-of-freedomrobotarmandona
Naohumanoidrobot,wheregoal-directedactionsaregeneratedusingtheRNNPB.
An interesting series of studies has been produced by Lanillos and colleagues. Lanillos
and Cheng (2018) present an architecture that combines generative models and a probabilis-
tic framework inspired on some of the principles of predictive processing. The architecture
is employed to estimate body configurations of a humanoid robot, using three modalities
14
(proprioceptive, vision and touch). In the literature, the way how the brain integrates multi-
modal streams in similar error minimization schemes is still under debate. Some authors
suggest that the integration of different streams of unimodal sensory surprise occurs in hier-
archically higher multimodal areas (Limanowski and Blankenburg, 2013; Apps and Tsakiris,
2014; Clark, 2013; Pezzulo et al., 2015), and therefore multimodal predictions and predic-
tion errors would be generated (Friston, 2012). Lanillos and Cheng (2018) apply an additive
formulation of unimodal prediction errors: (i) prior error, i.e. the ”...error between the most
plausible value of the body configuration and its prior belief”; (ii) proprioceptive error, i.e.
thedistancebetweenjointanglereadingsandjointanglesamplesgeneratedbyaNormaldis-
tribution;(iii)visualerror,i.e. thedistancebetweenobservedend-effectorimagecoordinates
andthosepredictedbyavisualgenerativemodel.
The proposed minimization scheme adjusts the prior on body configuration by summing
uptheadditivemultimodalerror,whilethesystemisexposedtomultimodalobservations. As
in Tani’s work, training and testing are decoupled. The generative models are pre-trained us-
ing Gaussian Process Regression. In particular, a visual forward model maps proprioceptive
data(positionofthreejoints)tovisualdata(imagecoordinatesoftheendeffector),whereasa
proprioceptivemodelgeneratesjointanglesfromaNormaldistributionrepresentingthejoint
states. Trainingdataisrecordedofflinefromahumanoidrobotexecutingrandomtrajectories.
Anothergenerativemodeliscreatedforthetactilemodalityasafunctionofthevisualgener-
ativemodel. Thismodelisusedinasecondexperimenttotranslatetheend-effectorpositions
tothespatiallocationsontherobotarmtouchedbyanexperimenter,inordertocorrectvisual
estimations.
A follow-up work (Oliver et al., 2019) applies an active inference model for visuomotor
coordination in the humanoid robot iCub. The framework controls two sub-systems of the
robot body, i.e., the head and one arm. An attractor model drives actions towards goals.
Goals are specified in a visual domain – encoded as linear velocity vectors towards a goal,
whose 3D position is estimated using stereo vision and a color marker – and transformed
using a Moore-Penrose pseudoinverse Jacobian matrix into linear velocities in the 4D joint
space of the robot. Similarly, visual goals are transformed into joint velocity goals for the
head sub-system. Authors assume normally distributed noise in the sensory inputs. Sensor
variances and action gains are pre-tuned and fixed during the experiments. Although no
generative models are trained in this experiment (iCub’s forward kinematics functions are
used), authors show that minimizing Laplace-encoded free energy through gradient descent
leads to reaching behaviours and visuo-motor coordination. Similarly, Pezzato et al. (2020)
presentanactiveinferenceframeworkusingapre-codedcontrollerandagenerativefunction.
The study aims at controlling the movements of an industrial robotic platform using active
inference and at comparing its adaptivity and robustness to another state-of-the-art controller
forroboticmanipulators,namelythemodelreferenceadaptivecontroller(MRAC).
Lanillosetal.(2020)extendtheactiveinferenceimplementationpresentedinOliveretal.
(2019). In this study, the visual generative model is pre-trained using a probabilistic neu-
ral network (Mixture Density Network, MDN). Inverse mapping is performed through the
backward pass of the MDN of the most plausible Gaussian kernel. The system re-trains the
networkfromscratchwheneverthesensoryinputsaretoofarfromitspredictions. Differently
from (Oliver et al., 2019), visual inputs consist of movements estimated through an optical
flow algorithm. The generative model thus maps joint angles to the 2D centroid of a mov-
ing blob detected from the camera. A deep learning classifier is then trained to label joint
15
velocitiesandopticalflowinputsasself-generatedornot.
Sancaktar and Lanillos (2019) apply a similar approach on the humanoid robot Nao. The
minimization scheme uses a pre-trained generative model for the visual input, i.e., a convo-
lutional decoder-like neural network. Training data are collected through a combination of
random babbling and kinesthetic teaching. The generative model maps joint angles to visual
inputs, as in to Lang et al. (2018). When computing the likelihood for the gradient descent,
thedensitydefiningthevisualinputiscreatedasacollectionofindependentGaussiandistri-
butionscentered at eachpixel. Inthe minimization scheme,thevisual predictionerrormulti-
plied by the inverse of the variance is calculated by applying a forward pass and a backward
pass to the convolutional decoder. The approach is interesting, but studies have pointed at
questionableaspectsaboutthebiologicalplausibilityofback-propagatingerrors. Thisrefers,
in particular, to the lack of local error representations in ANNs and at the symmetry between
forwardsandbackwardsweights,whichisnotalwayspresentincorticalnetworks(Whitting-
ton and Bogacz, 2019). As in the previous series of experiments, active inference is used to
controltherobotarmmovementinareachingexperiment.
Pio-Lopez et al. (2016) present a proof-of-concept implementation of a control scheme
based on active inference using the 7 degrees-of-freedom arm of a simulated PR2 humanoid
robot. The control scheme is adopted to perform trajectories towards predefined goals. Au-
thors highlight that such a scheme eliminates the need of an inverse model for motor control
as “action realizes the (sensory) consequences of (prior) causes” (Pio-Lopez et al., 2016, pp
9). A generative model maps causes to actions, where causes are seen as ”forces that have
somedesiredfixedpointororbit”(Pio-Lopezetal.,2016,pp9),assensedbyproprioception.
Proprioceptivepredictionsarethusrealizedinanopen-loopfashion,bymeansofreflexarcs.
This framework – which employs a hierarchical generative model – minimizes the KL-
divergence between the distribution of the agent’s priors and that of the true posterior distri-
bution, which represents the updated belief given the evidence. Authors point out that more
complexbehavioursrequirethedesignofequationsofmotion. Thequestiononthescalability
ofsuchanapproachforcognitiveroboticsremainsopen.
Although not adopting an active inference approach, Schillaci et al. (2020a) present a
study where intrinsically motivated behaviors are driven by error minimization schemes in
a simulated robot. The proposed architecture generates exploratory behaviors towards self-
generated goals, leverages computational resources and regulates goal selection and the bal-
ance between exploitation and exploration through a multi-level monitoring of prediction
error dynamics. The work is framed within the study of the underlying mechanisms of mo-
tivation and the emergence of emotions that drive behaviors and goal selection to promote
learning. Scholars such as Van de Cruys (2017), Kiverstein et al. (2019) and Hsee and Abel-
son (1991) argue that what motivates engagement in a behavior is not just the final outcome,
1
but the satisfaction that emerges from the pattern and the velocity of an outcome over time .
“If one [...] assumes that people not only passively experience satisfaction, but actively seek
satisfaction, then one can infer an interesting corollary from the velocity relation: People
engage in a behavior not just to seek its actual outcome, but to seek a positive velocity of
1
Here we intend the desired outcome of an event or of an activity. As for the velocity of an outcome, we
intendthevelocity,ortherate,atwhichsuchdesiredgoalisachieved. Inthecontextoflearning,agoalcould
bemerelythereductionofpredictionerror. Thevelocityoftheoutcomeherewouldcorrespondtotherateof
reductionofthepredictionerror,i.e.,howfastorslowispredictionerrorminimised.
16
outcomesthatthebehaviorcreatesovertime”(HseeandAbelson,1991,pp,346).
The system proposed by Schillaci et al. (2020a) monitors prediction error dynamics over
timeandatdifferentlevels,drivingbehaviourstowardsthosegoalsthatareassociatedtospe-
cific patterns of prediction error dynamics. The system also modulates exploration noise and
leverages computational resources according to the dynamics of the overall learning perfor-
mance. Learningisperformedinanonlinefashion,whereimagefeatures–compressedusing
apre-trainedconvolutionalautoencoder–arefedintoaself-organizingneuralnetworkforun-
supervisedgoalgenerationandintoaninverse-forwardmodelspairformovementgeneration
andpredictionerrormonitoring. Themodelsareupdatedinanonlinefashionandanepisodic
memory system is adopted to reduce catastrophic forgetting issues. Actions are generated
towardsgoalsassociatedwiththesteepestdescentinlow-levelpredictionerrordynamics.
A similar approach for the self-generation of goals has been employed by Annabi et al.
(2020) in a simulated experiment where a two degrees-of-freedom robotic arm has to learn
howtowritedigits. Theproposedarchitecturelearnssequencesofmotorprimitivesbasedon
afreeenergyminimizationapproach. Thesystemcombinesrecurrentneuralnetworksfortra-
jectoriesencodingwithaself-organisingsystemforgoalestimation,whichistrainedondata
generated through random behaviours. In the experiments, the system incrementally learns
motor primitives and policies, using a predefined generative forward model. Free energy
minimizationisusedforactionselection.
Zhongetal.(2018)presentahierarchicalmodelconsistingofaseriesofrepeatedstacked
modules to implement active inference in simulated agents. Each layer of the network con-
tains different modules, including generative units implemented as convolutional recurrent
networks(LongShort-TermMemorynetworks,LSTM).Inthehierarchicalarchitecture,pre-
dictions and prediction errors flow in top-down and bottom-up directions, respectively. Gen-
erativeunitsaretrainedinanoff-linelearningsessionduringtwosimulatedexperiments.
It is worth noting that all the works reviewed in this section make use of different forms
ofpredictionerrorminimizationschemestoobtainworkingmodelsandcontrollers.
3.2 Non-robotic implementations
Awideamountofnon-roboticstudiesonpredictiveprocessinghavebeenproducedduringthe
lastyears. Thissectionopensonlyasmallwindowonthisliterature. Nevertheless,promising
directions for cognitive robotics research on predictive processing can be characterised from
thefewsamplesreportedhere.
TheissueofscalabilityhighlightedontheactiveinferencestudyofPio-Lopezetal.(2016)
isalsoapparentintheworkofBaltieriandBuckley(2019),wheretheauthorsdesignanactive
inference based linear quadratic Gaussian controller to manipulate a one degree-of-freedom
system. The study aims at showing that such a controller can achieve goal positions without
theneedofanefferencecopy,asinoptimalcontroltheory(OCT).
Similar basic proofs-of-concept are presented by Tschantz et al. (2020) and Baltieri and
Buckley (2017), where active inference is used to model bacterial chemo-taxis in a mini-
mal simulated agent. Tschantz et al. (2020) focus on an action-oriented model that employ
goal-directed (instrumental) and information-seeking (epistemic) behaviors when learning a
generativemodel. Differenterrorminimizationstrategiesaretested,generatingepistemic,in-
strumental,randombehavioursorexpectedfreeenergydrivenones. Authorsshowthatactive
inferencebalancesexplorationandexploitationandsuggestthat“[they]arebothcomplemen-
17
tary perspectives of the same objective function – the minimization of expected free energy.”
(Tschantz et al., 2020, pp.19). The model is not hierarchical, but it fully exploits the propos-
alsofactiveinference. Intheotherinterestingproof-of-concept,BaltieriandBuckley(2017)
present a Braitenberg-like vehicle where behaviors are modulated according to predefined
precisionweights.
Friston et al. (2015) also addresses the exploration-exploitation dilemma. Authors argue
that, when adopting Bayes optimal behavior under the free energy principle, epistemic, in-
trinsic value is maximized until there is no further information gain, after which exploitation
is assured through maximization of extrinsic value, i.e., the utility of the result of an action.
In fact, epistemic actions can bring the agent far from a goal. Nonetheless, they can be used
toplanapathtoagoalwithgreaterconfidence. Adoptingtheformalismofpartiallyobserved
Markovdecisionprocesses,authorspresentasimulatedexperimentwhereanagent,i.e.,arat,
navigates through a T-shaped maze, to show the role of epistemic value in resolving uncer-
tainty about goal-directed behavior. Moreover, the authors discuss an aspect of the Bayesian
framework,thatis,theroleoftheprecision–i.e.,theinverseofthevariance–oftheposterior
belief – which is estimated from the prior belief and the likelihood of the evidence – about
2
control states as a message passing channel. Under this view, precision is associated with
dopaminergic responses, which has been interpreted in terms of changes in expected value
(e.g. rewardpredictionerrors). Inbrief,changesinprecisionwouldcorrelatewithchangesin
exploratoryorexploitativebehaviors.
In a follow-up study, Schwartenbeck et al. (2019) present an architecture that has an im-
plicit weighting of the exploitation and (goal-directed) exploration tendencies, determined
by the precision of prior beliefs and the degree of uncertainty about the world. Two mecha-
nismsforgoal-directedexplorationareimplementedintherat-within-a-mazesimulatedsetup:
modelparameterexplorationandhiddenstateexploration. Intheformeractivelearningstrat-
egy, the agents forage for information about the correct parameterization of the observation
model, in the study represented as a Markovian model. Here, parameters are the set of ar-
raysencodingtheMarkoviantransitionprobabilities,i.e.,themappingbetweenhiddenstates
and observations and the transition between hidden states. In the latter active inference strat-
egy, agents aim at gathering information about the current (hidden) state of the world, for
example the current context. In particular, they sample the outcomes that are associated
with a high uncertainty, only when these are informative for the representation of the task
structure. Similarly to a standard intrinsic motivation approach, authors appeal to the need
of random sampling when the uncertainty about model parameters and hidden states (goal-
exploration strategies) fails to inform behavior. The aim of this work is to understand “the
generative mechanisms that underlie information gain and its trade-off with reward maxi-
mization” (Schwartenbeck et al., 2019, pp. 45), but, as authors notice, how to scale up these
mechanismstomorecomplicatedtasksisstillanopenchallenge.
Precisionweightingisalsooneofthemainfocusesofthepredictivecodingstudycarried
out by Oliva et al. (2019). Interestingly, the authors analyze the variations of the precision of
prior prediction of a recurrent (S-CTRNN) generative model over a developmental process.
The model learns to estimate stochastic time series (two-dimensional trajectory drawings),
2
Inthegenerativemodel,acontrolstatecorrespondstothehiddencauseofanaction. “Thismeanstheagent
has to infer its behavior by forming beliefs about control states, based upon the observed consequences of its
action”(Fristonetal.,2015,pp. 190).
18
thus providing an estimate of the variance of the input data. The framework “shares cru-
cial properties with the developmental process of humans in that it naturally switches from
a strong reliance on sensory input at an early learning stage to a proper integration of sen-
sory input and own predictions at later learning stages” (Oliva et al., 2019, pp. 254). This is
correlated to a reduction of the prediction error and the estimated (prior) variance over time
during learning. Some formulations of the problem in this work are, however, problematic,
c¸in particular, in (Oliva et al., 2019) the posterior is computed naively by multiplying the
likelihoodandthepriorusingthebasicBayesianformula,andlearningisperformedonlyfor
maximizingthelikelihood. Inafollow-upwork(PhilippsenandNagai,2019),theframework
is applied to simulate the generation of representational drawings – i.e., drawings that rep-
resent objects – in infants and chimpanzees. Authors observe that stronger reliance on the
prior (hyper-prior) enables the network to perform representational drawings as those pro-
duced by children, whereas a weak reliance on the prior produces highly accurate lines but
fails to produce missing parts of the representational drawings, as observed in chimpanzees.
Results suggest that chimpanzees’ and humans’ “differences in representational drawing be-
haviormightbeexplainablebythedegreetowhichtheytakepriorinformationintoaccount”
(PhilippsenandNagai,2019,pp. 176).
Allenetal.(2019)studyactiveinferenceinamultimodaldomain,simulatinginteractions
between interoceptive cardiac cycle and exteroceptive (visual) perception. The work hypoth-
esizesthateffectsofcardiactimingonperceptioncouldariseasafunctionofperiodicsensory
attenuation. Thisstudydoesnotinvolveanyroboticimplementationnoranylearningorcon-
troltask. However,relatedimplementationsaremostlymissingintheliterature,thereforewe
believeitisworthbeingmentionedinthisreview.
4 Discussion
This work has reviewed a series of robotics and non-robotics studies that have adopted the
paradigm of predictive processing under different forms. Tables 1 and 2 provided a general
overviewofthemainaspectsaswellasthedifferencesofthesestudies.
It is certainly standing out to which length the robotics research and the non-robotics
models have addressed tasks that go beyond perception and motor control, which have been
traditionally the focus of predictive processing studies. Limited cognitive robotics research
has addressed the scaling up of the predictive processing paradigm towards higher cogni-
tive capabilities. Computational studies on minimal simulated systems have suggested that
specificaspects,suchasprecisionweighting,maybridgethisgap.
Embodied robotic systems seem to be the most appropriate experimental platforms not
onlyforstudyingcognitivedevelopmentwithinthepredictiveprocessingframework,butalso
forextendingthisframeworktoabroaderrangeofmodalitiesandbehavioralpossibilities. In
fact,anotheraspectoftheroboticsresearchesreviewedinthispaperworthhighlighting,isthat
3
almostthetotalityofthem addressonlyproprioceptionandasingleexteroceptivemodality,
i.e.,vision. Littleattentionintheroboticscommunityhasbeenposedonhowmultipleextero-
ceptivemodalities–forexample,vision,haptic,auditory,etc. –,aswellasinteroceptiveones
3
LanillosandCheng(2018)addressalsothetactilemodalityintheirstudy,butdonotfullyintegrateitinthe
errorminimizationscheme.
19
(SethandTsakiris,2018),canbeintegratedinpredictionerrorminimizationschemes. Studies
such as those from Tschantz et al. (2020), Friston et al. (2015), Schwartenbeck et al. (2019)
andSchillacietal.(2020a)havediscussedepistemicandemotionalvalue,homeostaticdrives
and intrinsic motivation that regulate behaviors. Interesting research directions for robotics
shouldincludeextendingthistomultimodalself-generatedgoalsandtocombinationsoffixed
homeostaticgoalsanddynamicones.
Another important point concerns precision weighting, as in predictive processing this
is assigned a prominent role in behavior and goal regulation, as well as in perceptual opti-
mization processes. Further cognitive robotics study should explore this path. Most of the
non-robotic implementations adopt a Bayesian or probabilistic formalization of error mini-
mizationschemes. Thisallowsanelegantformulationoftheprecisioninweightingschemes,
which consists of the inverse of the variance of the prior and posterior distributions. How-
ever, alternative strategies are available for implementing precision weighting-like processes
in non-probabilistic models, including the modulation of neuronal activation or of synaptic
weights in artificial neural networks, modulation of firing rates in spiking neural networks,
dopaminergic modulation, and the like. There is a wide literature on sensor fusion tech-
niquesinthemachinelearningcommunitywhichfocusesonveryrelatedchallenges,suchas
the learning and modulation of the relevance of single sensors in multimodal and predictive
settings(Fayyadetal.,2020).
A common denominator in all the reviewed implementations is the use of predictions
for guiding behavior. However, the implementations adopt different machine learning tools.
Works that follow strictly the active inference principles make use of Bayes as their main
tool. It is still an open question how all other approaches should be considered in the wider
predictive processing framework. So far, most robotics implementations make use of non-
variational deep networks as their main tool. However, the bias of using the Bayesian frame-
work, in non-robotics implementations, might hinder the search for other approaches that
could have advantages, importantly, in terms of computational cost and the complexity of
designinggenerativemodelstoproducecoherentandscaled-upbehaviors.
Predictive processing emphasizes the prediction-based learning of a generative model,
which predicts incoming sensory signals (Clark, 2015). In optimal control theory, a high
computational complexity is required for learning to predict sensory consequences by means
oftheefferencecopyandtheinversemodel. Inpredictiveprocessingaccounts,thiscomplex-
ity is mapped to the learning of a generative model during hierarchical perceptual and active
inference (e.g. Friston (2011); Friston et al. (2012b)). In this regard, it is still unclear how
generative models should be learned, due to the complexity that implies modeling the rich-
nessoftheentireenvironment(Tschantzetal.,2020). Action-orientedmodelsareacommon
approach to solve this issue by learning and generating inferences that allow adaptive behav-
ior, even when the world is not modelled in a precise manner (e.g. Tschantz et al. (2020);
Baltieri and Buckley (2017); Pezzulo et al. (2017)). It is worth highlighting that despite the
relevance of learning for belief updating, most non-robotic computational work focuses on
inferenceandnotonlearning. Actually,learningisalmostabsenthere.
The few non-robotic models that focus on learning of generative models are based on the
expected free energy formulations and use very simplified agents and behaviors (Tschantz
etal.,2020;BaltieriandBuckley,2017;Ueltzho¨ffer,2018;Millidge,2020). Onthecontrary,
some cognitive robotics implementations do have the emphasis slightly shifted towards the
learningofgenerativemodels(e.g. Lanillosetal.(2020);AhmadiandTani(2017);Ideietal.
20
(2018); Schillaci et al. (2020a,b)). Yet, learning and testing are decoupled in many of these
studies and, in particular, in those adopting probabilistic methods. This is likely due to the
challenges in implementing online learning of probabilistic models, especially in the context
ofhigh-dimensionalsensoryandmotorspaces.
It is worth pointing out that, in cognitive robotics, a variety of learning methods are used
and just few of these are equivalent to the free energy principle formulations. Nonetheless,
agentsandbehaviorsusedaremuchmorecomplex. Forcognitiverobotics,itisveryrelevant
to explore the reach and possibilities of using generative models for perception, action, and
planning. More importantly, there is a special interest on the tools and methods that can be
usedforthelearningofthesemodels,anareathathasbeenunattendedinnon-roboticmodels
usingpredictiveprocessingprinciples.
Finally, limited attention has been posed on the temporal aspect of prediction error dy-
namics(Kiversteinetal.,2019;Tschantzetal.,2020). Predictionerrorpatternsmaybeasso-
ciated with emotional experience (Joffily and Coricelli, 2013). In artificial systems, they are
essential components for implementing intrinsically motivated exploration behaviors and ar-
tificial curiosity (Oudeyer et al., 2007; Schillaci et al., 2020b; Baldassarre and Mirolli, 2013;
Graziano et al., 2011). Recent studies suggest that error dynamics may influence the regula-
tion of computational resources (Schillaci et al., 2020a) and the emotional valence of actions
(JoffilyandCoricelli,2013). Webelievethatpredictionerrordynamicsrepresentapromising
tool in the exploration of more complex behaviours and tasks in cognitive robotics under the
predictiveprocessingparadigm.
Acknowledgments
Guido Schillaci has received funding from the European Union’s Horizon 2020 research and
innovationprogrammeundertheMarieSklodowska-CuriegrantagreementNo. 838861(Pre-
dictive Robots). Predictive Robots is an associated project of the Deutsche Forschungsge-
meinschaft(DFG,GermanResearchFoundation)PriorityProgramme”TheActiveSelf”.
Verena Hafner has received funding from the Deutsche Forschungsgemeinschaft (DFG,
German Research Foundation) Priority Programme ”The Active Self” - 402790442 (Prereq-
uisitesfortheDevelopmentofanArtificialSelf).
Bruno Lara and Alejandra Ciria have received funding from the Alexander von Hum-
boldt Foundation from the project ”Predictive Autonomous Behaviour Internal Models and
PredictiveSelf-regulation”.
The authors would like to thank the anonymous reviewer for his/her thorough reading of
ourmanuscript. His/hercommentshelpedgreatlytoimprovethefirstversionsubmitted.
References
Adams, R. A., Shipp, S., and Friston, K. J. (2013a). Predictions not commands: active
inferenceinthemotorsystem. BrainStructureandFunction,218(3):611–643.
Adams, R. A., Stephan, K. E., Brown, H. R., Frith, C. D., and Friston, K. J. (2013b). The
computationalanatomyofpsychosis. Frontiersinpsychiatry,4:47.
21
Ahmadi, A. and Tani, J. (2017). How can a recurrent neurodynamic predictive coding model
cope with fluctuation in temporal patterns? robotic experiments on imitative interaction.
NeuralNetworks,92:3–16.
Ahmadi,A.andTani,J.(2019). Anovelpredictive-coding-inspiredvariationalrnnmodelfor
onlinepredictionandrecognition. Neuralcomputation,31(11):2025–2074.
Allen, M., Levy, A., Parr, T., and Friston, K. J. (2019). In the body’s eye: The computational
anatomyofinteroceptiveinference. BioRxiv,page603928.
Annabi, L., Pitti, A., and Quoy, M. (2020). Autonomous learning and chaining of motor
primitivesusingthefreeenergyprinciple. arXivpreprintarXiv:2005.05151.
Apps, M. A. and Tsakiris, M. (2014). The free-energy self: a predictive coding account of
self-recognition. Neuroscience&BiobehavioralReviews,41:85–97.
Badcock, P. B., Davey, C. G., Whittle, S., Allen, N. B., and Friston, K. J. (2017). The
depressedbrain: anevolutionarysystemstheory. TrendsinCognitiveSciences,21(3):182–
194.
Baldassarre, G. and Mirolli, M. (2013). Intrinsically motivated learning in natural and arti-
ficialsystems. Springer.
Baltieri,M.andBuckley,C.L.(2017). Anactiveinferenceimplementationofphototaxis. In
ArtificialLifeConferenceProceedings14,pages36–43.MITPress.
Baltieri, M. and Buckley, C. L. (2019). Active inference: Computational models of motor
controlwithoutefferencecopy. researchgate.
Brand, R. J., Baldwin, D. A., and Ashburn, L. A. (2002). Evidence for ‘motionese’: modifi-
cationsinmothers’infant-directedaction. DevelopmentalScience,5(1):72–83.
Brown, H., Adams, R. A., Parees, I., Edwards, M., and Friston, K. (2013). Active inference,
sensoryattenuationandillusions. Cognitiveprocessing,14(4):411–427.
Buckley, C. L., Kim, C. S., McGregor, S., and Seth, A. K. (2017). The free energy principle
for action and perception: A mathematical review. Journal of Mathematical Psychology,
81:55–79.
Clark, A. (2013). Whatever next? predictive brains, situated agents, and the future of cogni-
tivescience. Behavioralandbrainsciences,36(3):181–204.
Clark,A.(2015). Embodiedprediction. OpenMIND.FrankfurtamMain: MINDGroup.
Clark, A. (2018). A nice surprise? predictive processing and the active pursuit of novelty.
PhenomenologyandtheCognitiveSciences,17(3):521–534.
Clark, A. (2020). Beyond desire? agency, choice, and the predictive mind. Australasian
JournalofPhilosophy,98(1):1–15.
22
D M Wolpert, Z. G. and Jordan, M. (1995). An internal model for sensorimotor integration.
Science,269(5232):1880–1882.
Demekas,D.,Parr,T.,andFriston,K.J.(2020). Aninvestigationofthefreeenergyprinciple
foremotionrecognition. FrontiersinComputationalNeuroscience,14.
Demiris, Y. and Khadhouri, B. (2006). Hierarchical attentive multiple models for execution
andrecognitionofactions. RoboticsandAutonomousSystems,54(5):361–369. TheSocial
MechanismsofRobotProgrammingfromDemonstration.
Dogge,M.,Custers,R.,andAarts,H.(2019). Movingforward: Onthelimitsofmotor-based
forwardmodels. TrendsinCognitiveSciences,23(9):743–753.
Donnarumma, F., Costantini, M., Ambrosini, E., Friston, K., and Pezzulo, G. (2017). Action
perceptionashypothesistesting. Cortex,89:45–60.
Escobar-Jua´rez, E., Schillaci, G., Hermosillo-Valadez, J., and Lara-Guzma´n, B. (2016). A
self-organized internal models architecture for coding sensory–motor schemes. Frontiers
inRoboticsandAI,3:22.
Fayyad, J., Jaradat, M. A., Gruyer, D., and Najjaran, H. (2020). Deep learning sensor fusion
forautonomousvehicleperceptionandlocalization: Areview. Sensors,20(15):4220.
Feldman, H. and Friston, K. (2010). Attention, uncertainty, and free-energy. Frontiers in
humanneuroscience,4:215.
Friston, K. (2002). Functional integration and inference in the brain. Progress in neurobiol-
ogy,68(2):113–143.
Friston, K. (2005). A theory of cortical responses. Philosophical transactions of the Royal
SocietyB:Biologicalsciences,360(1456):815–836.
Friston,K.(2009). Thefree-energyprinciple: aroughguidetothebrain? Trendsincognitive
sciences,13(7):293–301.
Friston, K. (2010a). The free-energy principle: a unified brain theory? Nature reviews
neuroscience,11(2):127–138.
Friston,K.(2010b). Isthefree-energyprincipleneurocentric? NatureReviewsNeuroscience,
11(8):605.
Friston,K.(2011). Whatisoptimalaboutmotorcontrol? Neuron,72(3):488–498.
Friston,K.(2012). Prediction,perceptionandagency. InternationalJournalofPsychophysi-
ology,83(2):248–252.
Friston, K., Adams, R., Perrinet, L., and Breakspear, M. (2012a). Perceptions as hypotheses:
saccadesasexperiments. Frontiersinpsychology,3:151.
Friston,K.,Kilner,J.,andHarrison,L.(2006). Afreeenergyprincipleforthebrain. Journal
ofPhysiology-Paris,100(1-3):70–87.
23
Friston, K., Mattout, J., and Kilner, J. (2011). Action understanding and active inference.
Biologicalcybernetics,104(1-2):137–160.
Friston, K., Rigoli, F., Ognibene, D., Mathys, C., Fitzgerald, T., and Pezzulo, G. (2015).
Activeinferenceandepistemicvalue. Cognitiveneuroscience,6(4):187–214.
Friston,K.,Samothrakis,S.,andMontague,R.(2012b).Activeinferenceandagency: optimal
controlwithoutcostfunctions. Biologicalcybernetics,106(8-9):523–541.
Friston,K.J.(2019). Wavesofprediction. PLoSbiology,17(10).
Friston, K. J., Stephan, K. E., Montague, R., and Dolan, R. J. (2014). Computational psychi-
atry: thebrainasaphantasticorgan. TheLancetPsychiatry,1(2):148–158.
Graziano, V., Glasmachers, T., Schaul, T., Pape, L., Cuccu, G., Leitner, J., and Schmidhuber,
J.(2011). Artificialcuriosityforautonomousspaceexploration. ActaFutura,4:41–51.
Hohwy,J.(2013). Thepredictivemind. OxfordUniversityPress.
Hsee,C.K.andAbelson,R.P.(1991). Velocityrelation: Satisfactionasafunctionofthefirst
derivativeofoutcomeovertime. JournalofPersonalityandSocialPsychology,60(3):341.
Huang, Y. and Rao, R. P. (2011). Predictive coding. Wiley Interdisciplinary Reviews: Cogni-
tiveScience,2(5):580–593.
Hwang, J., Kim, J., Ahmadi, A., Choi, M., and Tani, J. (2018). Dealing with large-scale
spatio-temporal patterns in imitative interaction between a robot and a human by using
the predictive coding framework. IEEE Transactions on Systems, Man, and Cybernetics:
Systems.
Idei, H., Murata, S., Chen, Y., Yamashita, Y., Tani, J., and Ogata, T. (2018). A neurorobotics
simulation of autistic behavior induced by unusual sensory precision. Computational Psy-
chiatry,2:164–182.
Joffily, M. and Coricelli, G. (2013). Emotional valence and the free-energy principle. PLoS
ComputBiol,9(6):e1003094.
Jung, M., Matsumoto, T., and Tani, J. (2019). Goal-directed behavior under variational pre-
dictive coding: Dynamic organization of visual attention and working memory. arXiv
preprintarXiv:1903.04932.
Kaplan, R. and Friston, K. J. (2018). Planning and navigation as active inference. Biological
cybernetics,112(4):323–343.
Kawato, M. (1999). Internal models for motor control and trajectory planning. Current
OpinioninNeurobiology,9(6):718–727.
Kiverstein, J., Miller, M., and Rietveld, E. (2019). The feeling of grip: novelty, error dynam-
ics,andthepredictivebrain. Synthese,196(7):2847–2869.
24
Knill, D. C. and Pouget, A. (2004). The bayesian brain: the role of uncertainty in neural
codingandcomputation. TRENDSinNeurosciences,27(12):712–719.
Kruglanski,A.W.,Jasko,K.,andFriston,K.(2020). Allthinkingis‘wishful’thinking. Trends
inCognitiveSciences.
Lang,C.,Schillaci,G.,andHafner,V.V.(2018). Adeepconvolutionalneuralnetworkmodel
forsenseofagencyandobjectpermanenceinrobots. In2018JointIEEE8thInternational
ConferenceonDevelopmentandLearningandEpigeneticRobotics(ICDL-EpiRob),pages
257–262.IEEE.
Lanillos, P. and Cheng, G. (2018). Adaptive robot body learning and estimation through
predictive coding. In 2018 IEEE/RSJ International Conference on Intelligent Robots and
Systems(IROS),pages4083–4090.IEEE.
Lanillos, P., Cheng, G., et al. (2020). Robot self/other distinction: active inference meets
neuralnetworkslearninginamirror. arXivpreprintarXiv:2004.05473.
Lara, B., Astorga, D., Mendoza-Bock, E., Pardo, M., Escobar, E., and Ciria, A. (2018). Em-
bodied cognitive robotics and the learning of sensorimotor schemes. Adaptive Behavior,
26(5):225–238.
Limanowski,J.andBlankenburg,F.(2013). Minimalself-modelsandthefreeenergyprinci-
ple. Frontiersinhumanneuroscience,7:547.
Marr, D. (1982). Vision: A computational investigation into the human representation and
processingofvisualinformation. TheMITPress.
Matsumoto, T. and Tani, J. (2020). Goal-directed planning for habituated agents by active
inferenceusingavariationalrecurrentneuralnetwork. Entropy,22(5):564.
Millidge,B.(2020). Deepactiveinferenceasvariationalpolicygradients. JournalofMathe-
maticalPsychology,96:102348.
Mo¨ller, R. and Schenck, W. (2008). Bootstrapping cognition from behavior a computerized
thoughtexperiment. CognitiveScience,32(3):504–542.
Murata, S., Tomioka, S., Nakajo, R., Yamada, T., Arie, H., Ogata, T., and Sugano, S. (2015).
Predictive learning with uncertainty estimation for modeling infants’ cognitive develop-
ment with caregivers: A neurorobotics experiment. In 2015 Joint IEEE International
ConferenceonDevelopmentandLearningandEpigeneticRobotics(ICDL-EpiRob),pages
302–307.IEEE.
Ohata,W.andTani,J.(2020).Investigationofmultimodalandagentialinteractionsinhuman-
robot imitation, based on frameworks of predictive coding and active inference. arXiv
preprintarXiv:2002.01632.
Oliva, D., Philippsen, A., and Nagai, Y. (2019). How development in the bayesian brain
facilitateslearning. In2019JointIEEE9thInternationalConferenceonDevelopmentand
LearningandEpigeneticRobotics(ICDL-EpiRob),pages1–7.IEEE.
25
Oliver, G., Lanillos, P., and Cheng, G. (2019). Active inference body perception and action
forhumanoidrobots. arXivpreprintarXiv:1906.03022.
Oudeyer, P.-Y., Kaplan, F., and Hafner, V. V. (2007). Intrinsic motivation systems
for autonomous mental development. IEEE transactions on evolutionary computation,
11(2):265–286.
Park, J.-C., Kim, D.-S., and Nagai, Y. (2018). Learning for goal-directed actions using rn-
npb: Developmental change of “what to imitate”. IEEE Transactions on Cognitive and
DevelopmentalSystems,10(3):545–556.
Park, J.-C., Lim, J. H., Choi, H., and Kim, D.-S. (2012). Predictive coding strategies for
developmentalneurorobotics. Frontiersinpsychology,3:134.
Parr,T.andFriston,K.J.(2017). Workingmemory,attention,andsalienceinactiveinference.
Scientificreports,7(1):1–21.
Pezzato, C., Ferrari, R., and Corbato, C. H. (2020). A novel adaptive controller for robot
manipulatorsbasedonactiveinference.IEEERoboticsandAutomationLetters,5(2):2973–
2980.
Pezzulo, G., Donnarumma, F., Iodice, P., Maisto, D., and Stoianov, I. (2017). Model-based
approachestoactiveperceptionandcontrol. Entropy,19(6):266.
Pezzulo, G., Rigoli, F., and Friston, K. (2015). Active inference, homeostatic regulation and
adaptivebehaviouralcontrol. Progressinneurobiology,134:17–35.
Philippsen, A. and Nagai, Y. (2019). A predictive coding model of representational drawing
in human children and chimpanzees. In 2019 Joint IEEE 9th International Conference
on Development and Learning and Epigenetic Robotics (ICDL-EpiRob), pages 171–176.
IEEE.
Pickering, M. J. and Clark, A. (2014). Getting ahead: forward models and their place in
cognitivearchitecture. Trendsincognitivesciences,18(9):451–456.
Pio-Lopez, L., Nizard, A., Friston, K., and Pezzulo, G. (2016). Active inference and robot
control: acasestudy. JournalofTheRoyalSocietyInterface,13(122):20160616.
Ramstead, M. J., Kirchhoff, M. D., and Friston, K. J. (2020). A tale of two densities: Active
inferenceisenactiveinference. AdaptiveBehavior,28(4):225–239.
Rao, R. P. and Ballard, D. H. (1999). Predictive coding in the visual cortex: a functional
interpretationofsomeextra-classicalreceptive-fieldeffects. Natureneuroscience,2(1):79.
Rumelhart, D. E., Hinton, G. E., and Williams, R. J. (1986). Learning representations by
back-propagatingerrors. nature,323(6088):533–536.
Sajid, N., Parr, T., Hope, T. M., Price, C. J., and Friston, K. J. (2020). Degeneracy and
redundancyinactiveinference. CerebralCortex.
26
Sancaktar, C. and Lanillos, P. (2019). End-to-end pixel-based deep active inference for body
perceptionandaction. arXivpreprintarXiv:2001.05847.
Schillaci, G., Ciria, A., and Lara, B. (2020a). Tracking emotions: Intrinsic motivation
grounded on multi-level prediction error dynamics. Proceedings of the 10th Joint Inter-
nationalConferenceonDevelopmentandLearningandEpigeneticRobotics(IEEEICDL-
EpiRob2020).arXivpreprintarXiv:2007.14632.
Schillaci, G., Hafner, V. V., and Lara, B. (2016a). Exploration behaviors, body representa-
tions, and simulation processes for the development of cognition in artificial agents. Fron-
tiersinRoboticsandAI,3:39.
Schillaci, G., Pico Villalpando, A., Hafner, V. V., Hanappe, P., Colliaux, D., and Wintz,
T. (2020b). Intrinsic motivation and episodic memories for robot exploration of high-
dimensionalsensoryspaces. AdaptiveBehavior,page1059712320922916.
Schillaci, G., Ritter, C.-N., Hafner, V. V., and Lara, B. (2016b). Body representations for
robotego-noisemodellingandprediction.towardsthedevelopmentofasenseofagencyin
artificialagents. ArtificialLifeConferenceProceedings,(28):390–397.
Schwartenbeck, P., Passecker, J., Hauser, T. U., FitzGerald, T. H., Kronbichler, M., and Fris-
ton, K. J. (2019). Computational mechanisms of curiosity and goal-directed exploration.
Elife,8:e41703.
Seth, A. K. and Tsakiris, M. (2018). Being a beast machine: the somatic basis of selfhood.
Trendsincognitivesciences,22(11):969–981.
Spratling, M. W. (2008). Predictive coding as a model of biased competition in visual atten-
tion. Visionresearch,48(12):1391–1408.
Spratling, M. W. (2017). A review of predictive coding algorithms. Brain and cognition,
112:92–97.
Tani,J.(2019). Accountingfortheminimalselfandthenarrativeself: Roboticsexperiments
usingpredictivecoding. InAAAISpringSymposium: TowardsConsciousAISystems.
Tani, J. and Nolfi, S. (1999). Learning to perceive the world as articulated: an approach for
hierarchicallearninginsensory-motorsystems. NeuralNetworks,12(7-8):1131–1141.
Tschantz, A., Seth, A. K., and Buckley, C. L. (2020). Learning action-oriented models
throughactiveinference. PLoScomputationalbiology,16(4):e1007805.
Ueltzho¨ffer,K.(2018). Deepactiveinference. Biologicalcybernetics,112(6):547–573.
Van de Cruys, S. (2017). Affective value in the predictive mind. Johannes Gutenberg-
Universita¨tMainz.
Whittington, J. C. and Bogacz, R. (2019). Theories of error back-propagation in the brain.
Trendsincognitivesciences.
27
Williams,D.(2018). Predictiveprocessingandtherepresentationwars. MindsandMachines,
28(1):141–172.
Wolpert,D.M.andKawato,M.(1998). Multiplepairedforwardandinversemodelsformotor
control. NeuralNetw.,11(7-8):1317–1329.
Zhong, J., Cangelosi, A., Zhang, X., and Ogata, T. (2018). Afa-prednet: The action modula-
tion within predictive coding. In 2018 International Joint Conference on Neural Networks
(IJCNN),pages1–8.IEEE.
28