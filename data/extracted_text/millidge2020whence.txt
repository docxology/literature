0202
peS
82
]IA.sc[
5v82180.4002:viXra
WHENCE THE EXPECTED FREE ENERGY?
BerenMillidge AlexanderTschantz
SchoolofInformatics SacklerCenterforConsciousnessScience
UniversityofEdinburgh SchoolofEngineeringandInformatics
beren@millidge.name UniversitySussex
tschantz.alec@gmail.com
ChristopherLBuckley
EvolutionaryandAdaptiveSystemsResearchGroup
SchoolofEngineeringandInformatics
UniversityofSussex
C.L.Buckley@sussex.ac.uk
September30,2020
ABSTRACT
The Expected Free Energy (EFE) is a central quantity in the theory of active inference. It is the
quantitythatallactiveinferenceagentsaremandatedtominimizethroughaction,anditsdecompo-
sition into extrinsic and intrinsic value terms is key to the balance of explorationand exploitation
thatactiveinferenceagentsevince.Despiteitsimportance,themathematicaloriginsofthisquantity
anditsrelationtothe VariationalFreeEnergy(VFE) remainunclear. Inthispaper,weinvestigate
the originsof the EFE in detailand show that it is notsimply "the free energyin the future". We
presentafunctionalthatweargueisthenaturalextensionoftheVFE,butwhichactivelydiscourages
exploratorybehaviour,thusdemonstratingthatexplorationdoesnotdirectlyfollowfromfreeenergy
minimizationintothefuture. We thendevelopa novelobjective,theFree-EnergyoftheExpected
Future (FEEF), which possesses both the epistemic componentof the EFE as well as an intuitive
mathematicalgroundingasthedivergencebetweenpredictedanddesiredfutures.
1 Introduction
The Free-Energy Principle (FEP) (K.Friston, 2010; K.Friston&Ao, 2012a; K.Friston,Kilner,&Harrison, 2006)
is an emerging theory from theoretical neuroscience which offers a unifying explanation of the dynamics of self-
organising systems (K.Friston, 2019; Parr,DaCosta,&Friston, 2020). It proposes that such systems can be inter-
pretedasembodyingaprocessofvariationalinferencewhichminimizesasingleinformation-theoreticobjective–the
VariationalFree-Energy(VFE).Intheoreticalneuroscience,theFEPtranslatesintoanelegantaccountofbrainfunc-
tion(K.Friston,2003,2005,2008;K.J.Friston,2008;K.J.Friston,Trujillo-Barreto,&Daunizeau,2008),extending
theBayesianBrainhypothesis(Deneve,2005;Doya,Ishii,Pouget,&Rao,2007;Knill&Pouget,2004)bypostulating
thattheneuraldynamicsofthebrainperformvariationalinference.Undercertainassumptionsabouttheformsofthe
densitiesembodiedbytheagent,thistheorycanevenbetranslateddowntothelevelofneuralcircuitsintheformofa
A PREPRINT - SEPTEMBER 30, 2020
biologicallyplausibleneuronalprocesstheory(Bastosetal.,2012;K.Friston,2008;Kanai,Komura,Shipp,&Friston,
2015;Shipp,2016;Spratling,2008).
Actionisthensubsumedintothisformulation,underthenameofactiveinference(K.Friston,2011;K.Friston&Ao,
2012a; K.J.Friston,Daunizeau,&Kiebel, 2009) by mandating that agents act so as to minimize the VFE with re-
spect to action (Buckley,Kim,McGregor,&Seth, 2017; K.Fristonetal., 2006). This casts action and perception
as two aspects of the same imperative of free-energy minimization, resulting in a theoretical framework for con-
trol which applies to a variety of continuous-time tasks (Baltieri&Buckley, 2017, 2018; Calvo&Friston, 2017;
K.Friston,Mattout,&Kilner,2011;Millidge,2019c).
Recent work has extended these ideas to account for inference over temporally extended action sequences.
(K.Friston&Ao, 2012a; K.Friston,FitzGerald,Rigoli,Schwartenbeck,&Pezzulo, 2017a; K.Fristonetal.,
2016, 2015; Tschantz,Seth,&Buckley, 2019). Here it is assumed that rather than action minimis-
ing the instantaneous VFE, sequences of actions (or policies) minimise the cumulative sum over time
of a quantity called the Expected Free Energy (EFE) (K.Fristonetal., 2015). Active inference using
the EFE has been applied to a wide variety of tasks and applications, from modelling human and an-
imal choice behaviour (FitzGerald,Schwartenbeck,Moutoussis,Dolan,&Friston, 2015; K.Fristonetal.,
2015; Pezzulo,Cartoni,Rigoli,Pio-Lopez,&Friston, 2016), simulating visual saccades and other ‘epis-
temic foraging behaviour’ (K.J.Friston,Lin,etal., 2017; K.J.Friston,Rosch,Parr,Price,&Bowman, 2018;
Mirza,Adams,Mathys,&Friston, 2016;Parr&Friston, 2017a, 2018a), solvingreinforcementlearningbenchmarks
(Çatal,Verbelen,Nauta,DeBoom,&Dhoedt,2020;Millidge,2019a,2019b;Tschantz,Baltieri,Seth,Buckley,etal.,
2019; Ueltzhöffer, 2018; vandeLaar&deVries, 2019), to modelling psychiatric disorders as cases of aber-
rant inference (Cullen,Davey,Friston,&Moran, 2018; Mirza,Adams,Parr,&Friston, 2019; Parr&Friston,
2018b). Like the continuous-time formulation, active inference also comes equipped with a biologically plausi-
ble process theory with variational update equations which have been argued to be homologous with observed
neural firing patterns (K.Fristonetal., 2017a; K.Friston,FitzGerald,Rigoli,Schwartenbeck,&Pezzulo, 2017b;
K.J.Friston,Parr,&deVries,2017;Parr,Markovic,Kiebel,&Friston,2019).
A key property of the EFE is that it decomposes into both an extrinsic, value-seeking, and an intrinsic (epistemic),
information-seekingterm(K.Fristonetal.,2015). Thelattermandatesactiveinferenceagentstoresolveuncertainty
by encouraging the exploration of unknown regions of the environment, a property which has been extensively in-
vestigated (K.Fristonetal., 2017a, 2015; Schwartenbeck,FitzGerald,Dolan,&Friston, 2013; Schwartenbecketal.,
2019). Thefactthatintrinsicdrivesnaturallyemergefromthisformulationisarguedasanadvantageoverotherfor-
mulationsthattypicallyencourageexplorationbyaddingad-hocexploratorytermstotheirlossfunction(Burdaetal.,
2018; Mohamed&Rezende, 2015; Oudeyer&Kaplan, 2009; Pathak,Agrawal,Efros,&Darrell, 2017). While the
EFE is often described as a straightforward extension to the free energy principle that can account for prospective
policiesandistypicallyexpressedinsimilarmathematicalform(DaCostaetal.,2020;K.Fristonetal.,2017a,2015;
Parr&Friston, 2017b, 2019), its origin remainsobscure. Minimizationof the EFE is sometimes motivatedby a re-
ductioadabsurdumargumentfollowingfromtheFEP(K.Fristonetal.,2015;Parr&Friston,2019)inthatagentsare
driventominimizetheVFE,andthereforetheonlywaytheycanactistominimizetheirfree-energyintothefuture.
Sincethefutureisuncertain,however,insteadtheymustminimizetheexpectedfreeenergy.Centraltothislogicisthe
formalidentificationoftheVFEwiththeEFE.
In this paper, we set out to investigate the origin of the EFE and its relations with the VFE. We provide a broader
perspective on this question, showing that the EFE is not the only way to extend the VFE to account for action-
conditionedfutures.WederiveanobjectivewhichwebelievetobeamorenaturalanalogueoftheVFE,whichwecall
the Free Energy of the Future (FEF), and make a detailed side-by-sidecomparisonof the two functionals.Crucially,
weshowthattheFEFactivelydiscouragesinformation-seekingbehaviour,thusdemonstratingthatepistemictermsdo
notnecessarilyarisesimplyfromextendingtheVFEintothefuture. We theninvestigatetheoriginoftheepistemic
termoftheEFE,andshowthattheEFEisjusttheFEFminusthenegativeoftheepistemictermintheEFE,which
2
A PREPRINT - SEPTEMBER 30, 2020
thus providesa straightforward perspective on the relation between the two functionals. We then propose our own
mathematicallyprincipledstartingpointforaction-selectionunderactiveinference–thedivergencebetweendesired
andexpectedfutures,fromwhichweobtainanovelfunctionaltheFree-EnergyoftheExpectedFuture(FEEF),which
hascloserelationstothegeneralizedfreeenergy(Parr&Friston, 2019). Thisfunctionalhasa naturalinterpretation
in terms of the divergencebetween a veridicialand a biased generativemodel; it allows use of the same functional
for both inference and policy selection, and it naturally decomposes into an extrinsic value term and an epistemic
actionterm,thusmaintainingtheattractiveexploratorypropertiesofEFE-basedactiveinferencewhilealsopossessing
amathematicallyprincipledstartingpointwithanintuitiveinterpretation.
2 The VariationalFree Energy
The Variational Free Energy (VFE) is a core quantity in variational inference and constitutes a tractable
bound on both the log model evidence and the KL divergence between prior and posterior (Bealetal., 2003;
Blei,Kucukelbir,&McAuliffe, 2017; Fox&Roberts, 2012; Wainwright,Jordan,etal., 2008). For an in-depth mo-
tivationoftheVFEanditsuseinvariationalinference,seeAppendix9.
TheVFE,definedattimet,denotedbyF t,isgivenby,
F t =D KL [Q(x t |o t ;φ)||p(o t ,x t )]
Q(x |o ;φ)
=E ln t t (1)
Q(xt|ot;φ) p(o ,x )
(cid:2) t t (cid:3)
Theagentreceivesobservationso andmustinferthevaluesofhiddenstatesx . Theagentassumesthattheenviron-
t t
mentevolvesaccordingtoaMarkovprocesssothatthedistributionoverstatesatthecurrenttime-steponlydepends
on the state at the previous time-step, and that the observation generated at the current time-step depends only on
thestateatthecurrenttime-step. Givenadistributionoveratrajectoryofstatesandobservations,andunderMarkov
assumptionsit can be factorised as follows: p(o ,x ) = p(s ) T p(o |s )p(s |s ). In this paper, we also
0:T 0:T 0 t=0 t t t+1 t
consider inferenceover future states and observationswhich have yQet to be observed. Such future variablesare de-
noted o or x where τ > t. To avoid dealing with infinite sums, agents only consider futures up to some finite
τ τ
timehorizon,denotedT. Q(x |o ;φ)denotesanapproximateposteriordensityparametrisedbyφwhich,duringthe
t t
courseofvariationalinference,is fitas closelyas possibleto thetrue posterior. Note: thereis a slightdifferencein
notationherecomparedtothatusuallyusedinvariationalinference.Normallytheapproximateposterioriswrittenas
Q(x ;φ)withoutthedependenceonomadeexplicit. Thisisbecausethevariationalposteriorisnotadirectfunction
t
ofobservations,butrathertheresultofanoptimizationprocesswhichdependsontheobservations.Here,wemakethe
dependenceon o explicitto keep a clear distinction between the variationalposteriorQ(x |o ;φ), obtainedthrough
t t
optimizationofthevariationalparametersφ,andthevariationalpriorQ(x )=E [Q(s |o ;φ)],obtained
t p(st|st−1) t−1 t−1
bymappingthepreviousposteriorthroughthetransitiondynamics. Throughoutthispaper,weassumethatinference
isoccurringinadiscrete-timePartially-ObservedMarkovDecisionProcess(POMDP).Thisistoensurecompatibility
withtheEFEformulationlateron,whichisalsosituatedwithindiscrete-timePOMDPs. 1
The utility of the VFE for inference comes from the fact that the VFE is equal to the divergencebetween true and
approximateposteriorsuptoaconstant: F ≥ D [Q(x |o ;φ)||p(x |o )]. Thus,minimizingF withrespecttothe
t KL t t t t t
parametersofthevariationaldistributionmakesQ(x ;φ)agoodapproximationofthetrueposterior.
t
1ItisimportanttonotethattheoriginalFEPwasformulatedincontinuoustimewithgeneralisedcoordinates(K.Friston,2008;
K.Fristonetal.,2006)(wherethehiddenstatesareaugmentedwiththeirtemporalderivativesuptotheoreticallyinfiniteorder).The
generalisedcoordinatesmeanthattheagentiseffectivelyperformingvariationalinferenceoveraTaylor-expandedfuturetrajectory
instead of atemporally-instant hidden state(K.J.Friston, 2008;K.J.Fristonetal.,2008). Action isderived by minimizing the
gradientsoftheinstantaneousVFEwithrespecttoaction,whichrequirestheuseofaforwardmodel. Morerecentworkonactive
inferenceandtheFEPreturnstothecontinuous-timeformulation(K.Friston,2019;Parretal.,2020)andtheconclusionsdrawnin
thispapermaylookdifferentinthecontinuous-timedomain.
3
A PREPRINT - SEPTEMBER 30, 2020
OnecanalsomotivatetheVFEasatechniquetoestimatemodelevidence. Logmodelevidenceisakeyquantityin
Bayesianinferencebutisoftenintractable,meaningitcannotbecomputeddirectly.Intuitively,thelogmodelevidence
scoresthelikelihoodofthedataunderamodel,andthusprovidesadirectmeasureofthequalityofamodel.Underthe
freeenergyprinciple,minimizingthenegativelogmodelevidence(orsurprisal)istheultimategoalofself-organising
systems(K.Friston&Ao,2012a,2012b;K.Fristonetal.,2006). TheVFEprovidesanupperboundonthelogmodel
evidence. Thiscanbeshownbyimportancesamplingthemodelevidencewithrespecttotheapproximateposterior,
andapplyingJensen’sinequality:
−lnp(o )=−ln dx p(o ,x )
t Z t t t
Q(x |o ;φ)
t t
=−ln dx p(o ,x )
Z t t t Q(x |o ;φ)
t t
p(o ,x )
t t
≤− dx Q(x |o ;φ)ln
Z t t t Q(x |o ;φ)
t t
≤D [Q(x |o ;φ)||p(o ,x )]
KL t t t t
≤F
t
Since theVFE is anupperboundon thelogmodelevidence(orsurprisal), asthe VFE isminimized, itbecomesan
increasinglyaccurateestimateofthesurprisal. TogetafeelforthepropertiesoftheVFE,weshowcasethefollowing
decomposition:
F=D [Q(x |o ;φ)||p(o ,x )]
KL t t t t
Q(x |o ;φ)
=E ln t t
Q(xt|ot;φ) p(o ,x )
(cid:2) t t (cid:3)
=−E [lnp(o |x )]+D [Q(x |o ;φ)||p(x )] (2)
Q(xt|ot;φ) t t KL t t t
Accuracy Complexity
| {z } | {z }
ThisdecompositionistheonetypicallyusedtocomputetheVFEinpracticeandhasastraightforwardinterpretation.
Specifically, minimizing the negativeaccuracy(and thus maximizingaccuracy)ensuresthat the observationsare as
likely as possible under the states, x , predicted by the variational posterior while simultaneously minimizing the
t
complexityterm,whichisa KLdivergencebetweenthevariationalposteriorandtheprior. Thusthegoalistokeep
theposteriorasclosetotheprioraspossiblewhilestillmaximizingaccuracy.Effectively,thecomplexitytermactsas
animplicitregulariser,reducingtheriskofoverfittingtoanyspecificobservation.
3 The Expected Free Energy
Whilevariationalinferenceaspresentedaboveonlyallowsustoperforminferenceatthecurrenttimegivenobserva-
tions,itispossibletoextendtheformalismtoallowforinferenceoveractionsorpoliciesinthefuture.
To achieve this extension, a variationalobjective is requiredwhich can be minimized contingentupon future states
andpolicies,whichwillallowtheproblemofadaptiveactionselectiontobereformulatedasaprocessofvariational
inference. To do this, the formalism must be extended in two ways. First, the generative model is augmented to
include actions a , and policies, which are sequences of actions π = [a ,a ...a ]. The action taken at the current
τ 1 2 T
time can affect future states, and thus future observations. In order to transform action selection into an inference
problem,policiesaretreatedasaninferreddistributionQ(π)whichisoptimisedtomeettheagentsgoals.Thesecond
extension required is to translate the notion of an agent’s goals into this probabilistic framework. Active inference
encodesanagent’sgoalsasadesireddistributionoverobservationsp˜(o ). Wedenotethebiaseddistributionusinga
τ:T
tildeovertheprobabilitydensityp˜ratherthantherandomvariabletomakeclearthattherandomvariablesthemselves
4
A PREPRINT - SEPTEMBER 30, 2020
are unchanged, it is only the agent’s subjective distribution over the variables that is biased. 2 This distribution
is then incorporated into a biased generative model of the world p˜(o ,x ) ≈ p˜(o )Q(x |o ) 3, where we have
τ τ τ τ τ
additionally made the assumption that the true posterior can be well approximated with the variational posterior:
p(x |o )≈Q(x |o )whichsimplystatesthatthevariationalinferenceprocedurewassuccessful4. Activeinference
τ τ τ τ
proceeds by inferring a variational policy distribution Q(π) that maximizes the evidence for this biased generative
model. Intuitively,thisapproachturnstheactionselectionproblemonitshead. Insteadofsaying: Ihavesomegoal,
whatdoIhavetodotoachieveit? theactiveinferenceagentasks: Giventhatmygoalswereachieved,whatwould
havebeenthemostprobableactionsthatItook?
AfurthercomplicationofextendingVFEintothefuturecomesfromthefutureobservations.Whileagentshaveaccess
to current observations (or data) for planning problems, they must also reason about unknown future observations.
Thisisdealtwithbytakingtheexpectationoftheobjectivewithrespecttopredictedobservationso drawnfromthe
τ
generativemodel.
In the active inferenceframework,the goalis to infera variationaldistribution overbothhiddenstates and policies
thatmaximallyfittoabiasedgenerativemodelofthefuture.Theframeworkdefinesthevariationalobjectivefunction
tobeminimized,theExpectedFreeEnergy,fromtimeτ untilthetimehorizonT,whichisdenotedG:
G =E [lnQ(x ,π)−lnp˜(o ,x )]
Q(oτ:T,xτ:T,π) τ:T τ:T τ:T
A temporal mean-field factorisation of the approximateposterior and of the generative model is assumed such that
Q(x ,π)≈Q(π) T Q(x )andp˜(o ,x )≈ T p˜(o )Q(x |o ).Thisfactorisationneatlyseversthetemporal
τ:T τ τ τ:T τ:T t τ τ τ
dependencies betweeQn time-steps. Given these assuQmptions, inferring the optimal Q(π), turns out to be relatively
straightforward.
G =E lnQ(x ,π)−lnp˜(o ,x )
Q(oτ:T,xτ:T,π) τ:T τ:T τ:T
=E (cid:2) lnQ(x |π)+lnQ(π)−ln (cid:3) p˜(o ,x )
Q(oτ:T,xτ:T|π)Q(π) τ:T τ:T τ:T
(cid:2) (cid:3)
T
=E [lnQ(π)−E [lnQ(x )−lnp˜(o ,x )]
Q(π) Q(oτ:T,xτ:T|π) τ τ τ
(cid:2)X t (cid:3)
=D KL Q(π)ke−PT t Gτ(π)
(cid:2) (cid:3)
WhereG (π) = E [lnQ(x |π)−lnp˜(o ,x )]isdefinedtobetheEFEforasingletime–stepτ. Fromthe
τ Q(oτ,xτ|π) τ τ τ
KL-divergenceabove,itfollowsthattheoptimalvariationalpolicydistributionQ∗(π)issimplythepathintegralinto
thefutureoftheexpectedfreeenergiesforeachindividualtime-step:
T
Q∗(π)=σ( G (π)),
τ
X
t
whereσ(x)isasoftmaxfunction. Thisimpliesthattoinfertheoptimalpolicydistributionitsufficestominimizethe
sum of expected free energiesfor each time step into the future. Inferenceproceedsby using the generativemodel
2It is important to note that this encoding of preferences through a biased generative model is unique to active in-
ference. Other variational control schemes (Levine, 2018; K.Rawlik,Toussaint,&Vijayakumar, 2013; K.C.Rawlik, 2013;
E.Theodorou,Buchli,&Schaal,2010;E.A.Theodorou&Todorov,2012)insteadencodedesiresthroughbinaryoptimalityvari-
ablesandoptimizetheposteriorgiventhattheoptimalpathwastaken. Therelationbetweentheseframeworksisexploredfurther
in?.
3Somemorerecentwork(DaCostaetal.,2020;K.Friston,2019)prefersanalternativefactorisationofthebiasedgenerative
model intermsof an unbiased likelihood and abiased prior statedistributionp˜(oτ,xτ) = p(oτ|xτ)p˜(xτ). Thisleads toadif-
ferentdecompositionoftheEFEintermsofriskandambiguity(seeAppendix10)butwhichismathematicallyequivalenttothe
factorisationdescribedhere.
4Foradditionalinformationontheeffectofthisassumption,seeappendix12.
5
A PREPRINT - SEPTEMBER 30, 2020
torolloutpredictedfutures,computingtheEFEofthosefutures,andthenselectingpolicieswhichminimizethesum
of the expected free energies. Since under temporal mean field assumptions, trajectories decompose into a sum of
time-steps,itissufficientfortherestofthepapertoonlyconsiderasingletime-stepτ.
TogainanintuitionfortheEFE,weshowcasethefollowingdecomposition:
G (π)=E [lnQ(x |π)−lnp˜(o ,x )]
τ Q(oτ,xτ|π) τ τ τ
≈E [lnQ(x |π)−lnp˜(o )−lnQ(x |o )]
Q(oτ,xτ|π) τ τ τ τ
≈−E lnp˜(o ) −E D [Q(x |o )||Q(x |π)] (3)
Q(oτ,xτ|π) τ Q(oτ) KL τ τ τ
(cid:2) (cid:3)
ExtrinsicValue EpistemicValue
| {z } | {z }
While the EFE admits many decompositions, see Appendix 10 for a comprehensive overview, the one presented
in Equation 3 is perhaps the the most important because it separates the EFE into an extrinsic, goal-directed term
(sometimes also called ‘instrumentalvalue’ in the literature) and an intrinsic, information-seekingterm 5. The first
term requiresagentsto maximize the likelihoodof the desired observationsp˜(o ) underbeliefsaboutthe future. It
τ
thusdirectsanagenttoacttomaximizetheprobabilityofitsdesiresoccurringinthefuture. Itiscalledtheextrinsic
valuetermsinceitisthetermintheEFEwhichaccountsfortheagent’spreferences.
The second term in equation 3 is the expected information gain, which is often termed the ‘epistemic value’ since
it quantifies the amount of information gained by visiting a specific state. Since the information gain is negative,
minimizingtheEFE asa wholemandatesmaximizingtheexpectedinformationgain. Thisdrivesthe agentto maxi-
mizethedivergencebetweenitsposteriorandpriorbeliefs,thusinducingtheagenttotakeactionswhichmaximally
informtheir beliefsandreduceuncertainty. Itis thecombinationofextrinsicandintrinsicvaluetermswhichbelies
activeinference’sclaimtohaveaprincipledapproachtotheexploration-exploitationdilemma(K.Fristonetal.,2017a,
2015).
The idea of maximizing expected information gain or "Bayesian surprise" (Itti&Baldi, 2009) to drive exploratory
behaviourhasbeenarguedforinneuroscience(Baldi&Itti,2010;Ostwaldetal.,2012),andhasbeenregularlypro-
posed in reinforcement learning (Houthooftetal., 2016; Still&Precup, 2012; Sun,Gomez,&Schmidhuber, 2011;
Tschantz,Millidge,Seth,&Buckley, 2020). It is important to note however that in these prior works, information
gain has often been proposedas an ad-hocaddition to an already existing objectivefunctionwith only the intuitive
justificationofboostingexploration. Incontrast,expectedinformationgainfallsnaturallyoutoftheEFEformalism,
arguablylendingtheformalismadegreeoftheoreticalelegance.
4 Originsofthe EFE
Given the centrality of the EFE to the active inference framework, it is important to explore the origin and nature
of this quantity. The EFE is typically motivated through a reductio ad absurdum argument(K.Fristonetal., 2015;
Parr&Friston,2019)6. Thelogicisasfollows. Agentshavepriorbeliefsoverpoliciesthatdriveactionselection. By
the FEP, allstates of an organism,includingthose determiningpolicies, mustchangeso asto minimizefree energy.
Thus, the only self-consistent prior belief over policies is that the agent will minimize free-energy into the future
throughitspolicyselectionprocess. Iftheagentdidnothavesucha priorbeliefthenitwouldselectpolicieswhich
5Theapproximation inthefinal lineof equation(3) isthat weassumethat thetrueandapproximate posteriorsarethesame
Q(xτ|oτ) ≈ p(xτ|oτ). Without this assumption, you obtain an additional KL divergence between the true and approximate
posterior,whichexactlyquantifiesthediscrepancybetweenthem(seeappendixsection10and12formoredetail).
6Analternativemotivationexistswhichsituatestheexpectedfreeenergyintermsofanon-equilibriumsteadystatedistribution
(DaCostaetal., 2020; K.Friston, 2019; Parr, 2019). This argument reframes everything in terms of aGibbs free-energy, from
whichtheEFEcanbederivedasaspecialcase. Theproblembecomes,then,oneofthemotivationoftheGibbsfree-energyasan
objectivefunction.
6
A PREPRINT - SEPTEMBER 30, 2020
did not minimize the free-energyinto the future and would thus not be a free-energyminimizingagent. This logic
requiresawell-definednotionofthefree-energyoffuturestatesandobservationsgivenaspecificpolicy. Theactive
inference literature implicitly assumes that the EFE is the naturalfunctionalwhich fits this notion (K.Fristonetal.,
2017b,2015). Inthefollowingsection,wearguethattheEFEisnotinfacttheonlyfunctionalwhichcanquantifythe
notionofthefreeenergyofpolicy-conditionedfutures,andindeedweproposeadifferentfunctionalTheFreeEnergy
oftheFuture,whichweargueisamorenaturalextensionoftheVFEtoaccountforfuturestates.
4.1 TheFreeEnergyoftheFuture
We arguethat the naturalextensionof the freeenergyinto the futuremustpossess directanalogsto the two crucial
propertiesoftheVFE:itmustbeexpressibleasaKL-divergencebetweenaposteriorandagenerativemodel,suchthat
minimizingitcausesthevariationaldensitytobetterapproximatethetrueposterior. Secondly,itmustalsoboundthe
logmodelevidenceoffutureobservations. Boundingthelogmodelevidence(orsurprisal)isvitalsincethesurprisal
is the core quantity which, under the FEP, all systems are driven to minimize. If the VFE extended into the future
failedtoboundthesurprisal,thenminimizingthisextensionwouldnotnecessarilyminimizesurprisal,andthusany
agentwhichminimizedsuchanextensionwouldbeinviolationoftheFEP.Here,wepresentafunctionalwhichwe
claimsatisfiesthesedesiderata–theFreeEnergyoftheFuture(FEF).
Wewishtoderiveanexpressionforvariationalfreeenergyatsomefuturetimeτ thatisconditionedonsomepolicyπ.
Inotherwords,wewishtoquantifythefreeenergythatwilloccuratsomefuturetimepoint,givensomesequenceof
actions. Here,wederiveaformofthe‘variationalfreeenergyofthefuture’,denotedFEF (π),bykeepingthesame
τ
termsastheVFE(Equation1),butconditioningthevariationaldistributionsonourpolicyofinterestandrewritingfor
thefuturetime-pointτ. Additionally,sinceobservationsinthefutureareunknown,wemustevaluateourfreeenergy
undertheexpectationofourbeliefsaboutfutureobservations,asintheEFE.Wethusdefine:
FEF (π)=E [lnQ(x |o )−lnp˜(o ,x )]
τ Q(oτ,xτ|π) τ τ τ τ
SincethisequationissimplytheKL-divergencebetweenthevariationalposteriorandthegenerativemodel,itsatisfies
thefirstdesideratum. WenextinvestigatethepropertiesoftheFEFbyshowcasingonekeydecomposition. Aswith
the the VFE, we can then split the FEF into an energy and an entropy or an accuracy and complexity term, which
correspondtotheextrinsicandepistemicactiontermsintheEFE:
FEF (π)=E D [Q(x |o )||p˜(o ,x )]
τ Q(oτ|π) KL τ τ τ τ
≈−E lnp˜(o |x ) +E D [Q(x |o )||Q(x |π)]
Q(oτ,xτ|π) τ τ Q(oτ|π) KL τ τ τ
(cid:2) (cid:3)
Accuracy Complexity
| {z } | {z }
Unlike the EFE however, the expected information gain (complexity) term is positive while in the EFE term it is
negative.Sincetheobjectivefunction,whetherEFEorFEF,istobeminimized,weseethatusingtheFEFmandatesus
tominimizetheinformationgainwhiletheEFErequiresustomaximizeit(orminimizethenegativeinformationgain).
AnFEFagentthustriestomaximizeitsrewardwhiletryingtoexploreaslittleaspossible.Whilethissoundssurprising,
it is in factdirectly analogousto the complexityterm in the VFE, which mandatesmaximizingthe likelihoodof an
observation,whilealsokeepingtheposteriorascloseaspossibletotheprior7.
4.2 BoundsontheExpectedModelEvidence
WenextshowhowtheFEFcanbederivedasaboundontheexpectedmodelevidencesatisfyingtheseconddesidara-
tum. We define the expected model evidence to be a straightforwardextension of the model-evidenceto unknown
7An objective functional equivalent to the FEF – the "Predicted Free Energy" – has also been proposed in
(Schwöbel,Kiebel,&Markovic´,2018).Seesection14oftheappendixformoredetails.
7
A PREPRINT - SEPTEMBER 30, 2020
future states. The expected negative log model evidence for a trajectory from the currenttime-step t to some time
horizonT is:
−E lnp˜(o )
Q(ot:T|π) t:T
(cid:2) (cid:3)
Thisobjectivestatesthatwewishtomaximizetheprobability(minimizethenegativeprobability)ofbeinginadesired
trajectoryp˜(o ),expectedunderthedistributionofourbeliefsaboutourlikelyfuturetrajectoriesQ(o |π)undera
t:T t:T
specificpolicyπ. GivenaMarkovgenerativemodelp(o ,x |π) = T p(o |x )p(x |x |π),andassumingthat
1:T 1:T t t t t t−1
the approximate posterior factorises Q(x |o ) = T Q(x |o ), thQe expected model evidence factorises across
1:T 1:T t t t
time-steps, it suffices to show the derivation for a sinQgle time-step τ > t (see Appendix 11 for a full trajectory
derivation).WefurtherdefineQ(o ,x |π)=Q(o |π)Q(x |o )=p(o |x )Q(x |π). Wethereforetaketheexpected
τ τ τ τ τ τ τ τ
modelevidenceforasingletime-step,andshowthattheFEFisaboundonthisquantity.
−E lnp˜(o ) =−E ln dx p˜(o ,x ) (4)
Q(oτ|π) τ Q(oτ|π) Z τ τ τ
(cid:2) (cid:3) (cid:2) (cid:3)
Q(x |o )
=−E ln dx p˜(o ,x ) τ τ
Q(oτ|π) Z τ τ τ Q(x |o )
(cid:2) τ τ (cid:3)
p˜(o ,x )
≤−E dx Q(x |o ) ln τ τ
Q(oτ|π)Z τ τ τ Q(x |o )
(cid:2) τ τ (cid:3)
p˜(o ,x )
≤−E ln τ τ
Q(oτ,xτ|π) Q(x |o )
(cid:2) τ τ (cid:3)
Q(x |o )
≤E ln τ τ
Q(oτ,xτ|π) p˜(o ,x )
(cid:2) τ τ (cid:3)
≤E D [Q(x|o )||p˜(o ,x |π)]=FEF(π)
Q(oτ|π) KL τ τ τ
Crucially, this is an upper bound on expected model evidence which can be tightened by minimizing the FEF. By
contrast,returningtotheEFE,weseebelowthatsinceKLdivergencesarealways≥0,theexpectedinformationgain
isalwayspositive,andsotheEFEisalowerboundontheexpectedmodelevidence:
G (π)=E [lnQ(x |π)−lnp˜(o ,x )]
τ Q(oτ,xτ|π) τ τ τ
≈ −E lnp˜(o ) −E D [Q(x |o )||Q(x |π)]
Q(oτ,xτ|π) τ Q(oτ|π) KL τ τ τ
(cid:2) (cid:3)
NegativeExpectedLogModelEvidence ExpectedInformationGain
| {z } | {z }
Since the expected informationgain is an expected KL divergence, it must be ≥ 0, and thus the negativeexpected
informationgainmustbe≤ 0. SincetheEFEaimstominimizenegativeinformationgain(thusmaximizingpositive
informationgain),wecanseeminimizingtheEFEactuallydrivesitfurtherfromtheexpectedmodelevidence.8
We further investigate the EFE and its properties as a bound in Appendix 12. Additionally, in Appendix 13 we
reviewotherattemptsintheliteraturetoderivetheEFEasaboundontheexpectedmodelevidenceanddiscusstheir
shortcomings.
4.3 TheEFEandtheFEF
TogetastrongerintuitionforthesubtledifferencesbetweentheEFEandtheFEF,wepresentadetailedside-by-side
comparisonofthetwofunctionals.
FEF=E [lnQ(x |o )−lnp˜(o ,x )]
Q(oτ,xτ|π) τ τ τ τ
EFE=E [lnQ(x |π)−lnp˜(o ,x )]
Q(oτ,xτ|π) τ τ τ
8There is a slight additional subtlety here involving the fact that there isalso a posterior approximation error term which is
positive. IngeneraltheEFEfunctionsasanupperboundwhentheposteriorerrorisgreaterthantheinformationgainandalower
boundwhentheposteriorerrorissmaller.Sincethegoalofvariationalinferenceistominimizeposteriorerror,andEFEagentsare
driventomaximizeexpectedinformationgain,weexpectthislatterconditiontooccurrarely.FormoredetailseeAppendix12.
8
A PREPRINT - SEPTEMBER 30, 2020
While the two formulations might initially look very similar, the key difference is the variational term. The FEF,
analogouslytotheVFE,measuresthedifferencebetweenavariationalposteriorQ(x |o )andthegenerativemodel
τ τ
Q(x |π). TheEFE,ontheotherhand,measuresthedifferencebetweenavariationalpriorandthegenerativemodel.
τ
ItisthisdifferencewhichmakestheEFEnotastraightforwardextensiontotheVFEforfuturetime-steps,andunder-
writesitsuniqueepistemicvalueterm.
WenowdemonstratethatboththeEFEandtheFEFcanbedecomposedintoanexpectedlikelihood,associatedwith
extrinsicvalue,andanexpectedKL-divergencebetweenavariationalposteriorandavariationalprior,associatedwith
epistemicvalue. WefactorisethegenerativemodelintheFEFintothe(biased)likelihoodandavariationalprior,and
factorisethegenerativemodelintheEFEintoanapproximateposterior,anda(biased)marginal:
FEF=E [lnQ(x |o )−lnp˜(o |x )−lnQ(x |π)]
Q(oτ,xτ|π) τ τ τ τ τ
EFE=E [lnQ(x |π)−lnp˜(o )−lnQ(x |o )]
Q(oτ,xτ|π) τ τ τ τ
ThevariationalpriorandvariationalposteriorcanthenbecombinedinboththeFEFandtheEFEtoformepistemic
terms. Crucially, the epistemic value term is positive in the FEF and negative in the EFE, meaning that the FEF
penalizesepistemicbehaviorwhereastheEFEpromotesit:
FEF=−E lnp˜(o |x ) +E D [Q(x |o )||Q(x |π)] (5)
Q(oτ,xτ|π) τ τ Q(oτ|π) KL τ τ τ
(cid:2) (cid:3)
ExtrinsicValue EpistemicValue
| {z } | {z }
EFE=−E lnp˜(o ) −E D [Q(x |o )||Q(x |π)]
Q(oτ,xτ|π) τ Q(oτ|π) KL τ τ τ
(cid:2) (cid:3)
ExtrinsicValue EpistemicValue
| {z } | {z }
Equation 5. demonstratesthat the FEF and EFE can be decomposed in similar fashion. We note that the extrinsic
valuetermfortheFEFisalikelihoodandamarginalfortheEFE.Themostimportantdifference,however,liesinthe
signoftheepistemicvalueterm. SinceoptimizingeithertheFEFortheEFErequirestheirminimization,minimizing
theFEFmandatesustominimizeinformationgainwhiletheEFErequiresustomaximizeit. AnFEFagentthustries
tomaximizeitsextrinsicvaluewhiletryingtoexploreaslittleaspossible. Akeyquestionthenarises: wheredoesthe
negativeinformationgainintheEFEcomefrom?
Whilethisdifferenceinthesignoftheexpectedinformationgaintermmayspeaktosomedeepconnectionbetween
thetwoquantities,hereweofferapragmaticperspectiveonthematter. We showthatapossibleroutetotheEFEis
simplythatitistheFEFminustheexpectedinformation-gain. ThisimpliesthattheepistemicvaluetermoftheEFE
arisesnotfromsomeconnectiontovariationalinferencebutispresentbyconstruction:
Q(x |o ) Q(x |o )
FEF (π)−IG =E ln( τ τ )−E ln( τ τ )
τ τ Q(oτ,xτ|π) p˜(o ,x ) Q(oτ,xτ|π) Q(x |π)
τ τ τ
Q(x |o )Q(x |π)
=E ln( τ τ τ )
Q(oτ,xτ|π) p˜(o ,x )Q(x |o )
τ τ τ τ
Q(x |π)
=E ln( τ )
Q(oτ,xτ|π) p˜(o ,x )
τ τ
=EFE(π)
τ
WhilethisproofillustratestherelationbetweentheEFEandtheFEF,itistheoreticallyunsatisfyingasanaccountof
theoriginoftheEFE.AlargepartoftheappealoftheEFEisthatitpurportstoshowthatepistemicvaluearises‘natu-
rally’outofminimizingfree-energyintothefuture.Incontrast,herewehaveshownthatminimizingfree-energyinto
thefuturerequiresnocommitmenttoexploratorybehaviour. Whilethisdoesnotquestiontheusefulnessofusingan
9
A PREPRINT - SEPTEMBER 30, 2020
informationgaintermforexploration,ortheuseoftheEFEasalossfunction,itdoesraisequestionsaboutthemath-
ematicallyprinciplednatureoftheobjective.Itisthusnotstraightforwardtoseewhyagentsaredirectlymandatedby
theFEPtominimizetheEFEspecifically,asopposedtosomeotherfree-energyfunctional.Whilethisfactmayatfirst
appearconcerning,webelieveitultimatelyenhancesthepoweroftheformalismbylicensingtheextensionofactivein-
ferencetoencompassotherobjectivefunctionsinaprincipledmanner(Biehl,Guckelsberger,Salge,Smith,&Polani,
2018). Inthefollowingsection,weproposeanalternativeobjectivetotheEFE,whichresultsinthesameinformation-
seekingepistemicvalueterm,butderivesitinamathematicallyprincipledandintuitivewayasaboundonthediver-
gencebetweenexpectedanddesiredfutures.
5 Free Energy ofthe Expected Future
In this section, we propose a novel objective functional which we call The Free-Energy of The Expected Future
(FEEF)whichpossessesthesameepistemicvaluetermastheEFE,whileadditionallypossessingamorenaturalistic
and intuitivegrounding. We beginwith the intuitionthat, to act adaptively,agentsshouldact so as to minimize the
differencebetweenwhattheypredictwillhappen,andwhattheydesiretohappen. Putanotherway,adaptiveaction
foranagentconsistsofforcingrealitytounfoldaccordingtoits’preferences. Wecanmathematicallyformulatethis
objective as the KL divergence between the agent’s veridicial generative model of what is likely to happen, and a
biasedgenerativemodelofwhatitdesirestohappen.
π∗ =argmin D [Q(o ,x |π)||p˜(o ,x )]
KL t:T t:T t:T t:T
π
TheFEEFcanbeinterpretedasthedivergencebetweenaveridicialandabiasedgenerativemodel,andthusfurnishes
adirectintuitionofthegoalsofaFEEF-minimizingagent. Thedivergenceobjectivecompelstheagenttobringthe
biased and the veridicialgenerativemodelinto alignment. Since the predictionsof the biased generativemodelare
heavilybiasedtowardstheagent’sa-prioripreferences,theonlywaytoachievethisalignmentistoactsoastomake
theveridicialgenerativemodelpredictdesiredoutcomesinlinewiththebiasedgenerativemodel.TheFEEFobjective
encompassesthestandardactiveinferenceintuitionofanagentactingthroughbiasedinferencetomaximizeaccuracy
ofabiasedmodel. However,themaintenanceoftwoseparategenerativemodels(onebiasedandoneveridicial)also
helps finesse the conceptual difficulty of how the agent manages to make accurate posterior inferences and future
predictions about complex dynamics if all it has access to is a biased generative model. It seems straightforward
that the biased modelwould also bias these crucial parts of inference which need to be unimpairedfor the scheme
to function at all. However, by keeping both a veridicial generative model (the same one used at the present time
and learnt through environmentalinteractions), and a biased generative model (created by systematically biasing a
temporary copy of the veridicial model), we elegantly separate the need for both veridicial and biased inferential
componentsforfutureprediction9.
SimilarlytotheEFE,theFEEFobjectivecanbedecomposedintoanextrinsicandanintrinsicterm. Wecomparethis
directlytotheEFEdecomposition:
Q(o ,x |π)
FEEF(π) =E ln τ τ
τ Q(oτ,xτ|π) p˜(o ,x )
(cid:2) τ τ (cid:3)
=E D Q(o |x )kp˜(o ) −E D Q(x |o )kQ(x |π)
Q(xτ|π) KL τ τ τ Q(oτ|π) KL τ τ τ
(cid:2) (cid:3) (cid:2) (cid:3)
ExtrinsicValue IntrinsicValue
EFE= | −E l { n z p˜(o ) −E } D| [Q(x |o )|| { Q z (x |π)] }
Q(oτ,xτ|π) τ Q(oτ|π) KL τ τ τ
(cid:2) (cid:3)
ExtrinsicValue IntrinsicValue
| {z } | {z }
9Thisapproachbearsaresemblancetothattakenin(K.Friston,2019)whichseparatestheevolvingdynamicalpolicy-dependent
densityoftheagent,andadesiredsteadystatedensitywhichispolicy-invariant. Thisapproacharisesfromdeepthermodynamic
considerationsincontinuoustime,whileoursisapplicabletodiscretetimereinforcementlearningframeworks.
10
A PREPRINT - SEPTEMBER 30, 2020
The first thingto noteis that the intrinsicvalue termsof the FEEFand the EFE are identical, underthe assumption
thatthevariationalposteriorisapproximatelycorrectQ(x |o ) ≈ p(x |o )suchthatFEEF-minimizingagentswill
τ τ τ τ
necessarilyshowidenticalepistemicbehaviourtoEFE-minimizingagents. UnliketheEFE,however,theFEEFalso
possessesastrongnaturalisticgroundingasaboundonatheoreticallyrelevantquantity.TheFEEFcanmaintainboth
itsinformation-maximizingimperativeanditstheoreticalgroundingsinceitisderivedfromtheminimizationofaKL
divergenceratherthanthemaximizationofalogmodelevidence.
The key differencewith the EFE lies in the likelihood term. While the EFE simply tries to maximize the expected
evidenceofthedesiredobservations,theFEEFminimizestheKLdivergencebetweenthelikelihoodofobservations
predictedundertheveridicialgenerativemodel10andthemarginallikelihoodofobservationsunderthebiasedgener-
ativemodel. Thisdifferenceiseffectivelyequivalenttoanadditionalveridicialgenerativemodelexpectedlikelihood
entropytermH[Q(o |x )]subtractedfromtheEFE.Theextrinsicvaluetermthusencouragestheagenttochooseits
τ τ
actionssuch thatits predictionsoverstates lead to observationswhich are close to its preferredobservations, while
alsotryingmovetostateswherebytheentropyoverobservationsismaximized,thusleadingtheagenttomovetowards
states wherethe generativemodelis not as certain aboutthe likely outcome. In effect, the FEEF possesses another
exploratoryterm,inadditiontotheinformationgain,whichtheEFElacks.
AnotherimportantadvantageoftheFEEFisthatitismathematicallyequivalenttotheVFE(withabiasedgenerative
model)inthepresenttimewithacurrentobservation.Thisisbecausewhenwehavearealobservation,thedistribution
overthe possible veridicialobservationscollapses to a delta distribution, so that the outer expectationhas no effect
asE = Q(x |o )Q(o |π) = Q(x |o )δ(o−o¯) = Q(x |o¯ )whenarealobservationo¯isavailable.
Q(oτ,xτ|π) τ τ τ τ τ τ τ
Similarly,theveridRicialmodelcanbefactoRrisedasQ(o ,x ) = QR(x |o )Q(o )andwhentheobservationisknown
τ τ τ τ τ
the entropy of the observation marginalQ(o |π) is 0, thus resulting in the VFE. Simultaneously, biased likelihood
τ
is equivalentto the veridiciallikelihoodp˜(o¯ |x ) = Q(o¯ |x ), assuming that (barringcounterfactualreasoningca-
τ τ τ τ
pability), one cannot usefully desire things to be other than how they are at the present moment. This means that
theoreticallywecanconsideranagenttobebothinferringandplanningusingthesameobjective,whichisnottrueof
theEFE.TheEFE doesnotreducetotheVFE whenobservationsareknown,andthusrequiresaseparateobjective
functiontobeminimizedforplanningcomparedtoinference.Becauseofthis,itisactuallypossibletoarguethatFEEF
ismandatedbythefree-energyprinciple.Onthisviewthereisnodistinctionbetweenpresentandfutureinferenceand
bothfollowfromminimizingthesameobjectivebutunderdifferentinformationalconstraints.
Since the FEEF and the EFE are identicalin their intrinsic value term, and share deep similarities in their extrinsic
term,webelievethattheFEEFcanserveasarelativelystraightforward"plug-inreplacement"fortheEFEformany
activeinferenceagents.Moreover,ithasamuchmorestraightforwardintuitivebasisthantheEFE,isarguablyabetter
continuationof the VFE into thefuture, andpossesses a strongnaturalisticgroundingasa boundon the divergence
betweenpredictedanddesiredfutures.
6 Discussion
We believe it is valuable at this point to step back from the morass of various free-energiesand take stock of what
has been achieved. Firstly, we have shown that it is not possible to directly derive epistemic value from varia-
tional inference objectives which serve as a bound on model evidence. However, it is possible to derive epistemic
value terms from divergencesbetween the biased and veridicial generativemodels. A deep intuitive understanding
of why this is the case is an interesting avenue for future work. The intuition behind the FEEF as a divergence
between desired and expected future observations is also similar to probabilistic formulationsof the reinforcement
learningproblem(Attias, 2003; Kappen, 2005; Levine, 2018; Toussaint, 2009), which typically try to minimize the
10Theterm‘veridicial’needssomecontextualising. Wesimplymeanthatthemodel isnotbiasedtowardstheagent’sdesires.
Theveridicialgenerativemodelisnotrequiredtobeaperfectlyaccuratemapoftheagent’sentireworld,onlyofaction-relevant
sub-manifoldsofthetotalspace(Tschantz,Seth,&Buckley,2019).
11
A PREPRINT - SEPTEMBER 30, 2020
divergence between a controlled trajectory, and an optimal trajectory (Kappen, 2007; E.A.Theodorou&Todorov,
2012; Williams,Aldrich,&Theodorou, 2017). These schemes also obtain some degree of (undirected)exploratory
behaviour through their objective functionals which contain entropy terms and the FEEF can be seen as a way of
extendingthese schemes to partially-observedenvironments. Understandingprecisely how active inferenceand the
free-energyprinciplerelatemathematicallytosuchschemesisanotherfruitfulavenueforfuturework.
It seems intuitive that a Bayes-optimal solution to the exploration-exploitation dilemma should arise directly out
of the formulation of reward maximization as inference, given that sources of uncertainty are correctly quantified.
However,inthispaper,wehaveshownthatmerelyquantifyinguncertaintyinstatesandobservationsthroughmean-
field-factorisedtime-stepsisinsufficienttoderivesuchaprincipledsolutiontothedilemma,asseenbytheexploration-
discouragingbehaviouroftheFEF.WethereforebelievethattoderiveBayesoptimalexplorationpoliciesinthecontext
ofactive-learning–suchthatwehavetoselectactionsthatgiveusthemostinformationnowtousein thefutureto
maximizerewards–itislikelytorequirebothmodellingmultipleinterconnectedtime-steps,aswellasthemechanics
oflearningwithparametersandupdaterules,andcorrectlyquantifyingtheuncertaintiestherein. Thisisbeyondthe
scopeofthispaper,butisaveryinterestingavenueforfuturework.
ThecomparisonoftheFEEFandtheEFEalso raisesaninterestingphilosophicalpointaboutthenumberandtypes
ofgenerativemodelsemployedintheactive-inferenceformalism. OneinterpretationoftheFEEFisintermsoftwo
generativemodels, but other interpretationsare possible such as between a single unbiased generative modeland a
simpledensityofdesiredstatesandobservations. Itisalsoimportanttonotethatduetorequiringdifferentobjective
functionsforinferenceandplanning,theEFEalsoformulationappearstoimplicitlyrequiretwogenerativemodels–
thegenerativemodeloffuturestates,andthegenerativemodelofstatesinthefuture(K.Fristonetal.,2015).Whilethe
mathematicalformalismisrelativelystraightforward,thephilosophicalquestionofhowtotranslatethemathematical
objects into ontologicalobjects called ‘generative models’ is unclear and progress on this front would be useful in
determiningthephilosophicalstatus,andperhapsevenneuralimplementationofactiveinference.
The implications of our results for studies of active inference are varied. Nothing in what we have shown argues
directlyagainsttheuseoftheEFEasaobjectiveforanactiveinferenceagent. However,webelievewehaveshown
thattheEFEisnotthenecessarilytheonly,oreventhenatural,objectivefunctiontouse. Wethusfollow(Biehletal.,
2018) in encouragingexperimentationwith differentobjectivefunctionsfor active inference. We especially believe
that our objective, the FEEF futurehas promise due its intuitive interpretation, largelyequivalentterms to the EFE,
its straightforward use of two generative models rather than just a single biased one, and its close connections to
similarprobabilisticobjectivesusedinvariationalreinforcementlearning,whilealsomaintainingthecrucialepistemic
propertiesoftheEFE.Moreover,whileinthispaperwehavearguedfortheFEFinsteadoftheEFEasadirectextension
oftheVFE intothefuture,thelogicalrequirementsofexactlywhichfunctional(ifany)is, infact, mandatedbythe
free-energyprincipleremainsopen. Webelievethatelucidatingtheexactconstraintswhichthefree-energyprinciple
places upon a theory of variational action, and understanding more deeply the relations between the various free-
energies, could shed lighton deep questionsregardingnotionsof Bayes-optimalepistemic action in self-organising
systems.
Finally, it is important to note that although in this paper we have solely been concerned with the EFE and active
inferenceindiscrete-timePOMDPs,theoriginalintuitionsandmathematicalframeworkofthefree-energyprinciple
aroseoutofacontinuoustimeformulation,deeplyinterwovenwithconcernsfrominformationtheoryandstatistical
physics (K.Friston, 2019; K.Friston&Ao, 2012b; K.Fristonetal., 2006; Parretal., 2020). As such there may be
deepconnectionsbetweentheEFE,FEF, andlogmodelevidencewhichexistonlyinthecontinuoustimelimit,and
whichfurnishamathematicallyprincipledoriginofepistemicaction.
12
A PREPRINT - SEPTEMBER 30, 2020
7 Conclusion
Inthispaper,wehaveexaminedindetailthenatureandoriginoftheEFE.Wehaveshownthatitisnotadirectanalog
oftheVFEextendedintothefuture. Wethenderivedanovelobjective,theFEF,whichweclaimedisamorenatural
extensionandshownthatitlacksthebeneficialepistemicvaluetermoftheEFE.Wethenprovedthatthistermarises
in the EFE directly as a result of its non-standarddefinition since the EFE can be expressed as just the FEF minus
theexpectedinformationgain. Takingthisintoaccount,wethenproposedanotherobjective,theFreeEnergyofthe
ExpectedFuture(FEEF)whichattemptstogetthebestofbothworldsbypreservingthedesirableinformation-seeking
propertiesoftheEFE,whilealsomaintainingamathematicallyprincipledorigin.
8 Acknowledgements
BM is supported by an EPSRC funded PhD Studentship. AT is funded by a PhD studentship from the Dr. Mor-
timer and Theresa Sackler Foundation and the School of Engineering and Informatics at the University of Sussex.
CLBissupportedbyBBRSCgrantnumberBB/P022197/1. ATisgratefultotheDr. MortimerandTheresaSackler
Foundation,whichsupportstheSacklerCentreforConsciousnessScience.
References
Attias,H. (2003). Planningbyprobabilisticinference. InAistats.
Baldi, P., &Itti, L. (2010). Of bitsandwows: Abayesiantheoryofsurprisewithapplicationsto attention. Neural
Networks,23(5),649–666.
Baltieri,M.,&Buckley,C.L. (2017). Anactiveinferenceimplementationofphototaxis. InArtificiallifeconference
proceedings14(pp.36–43).
Baltieri, M., & Buckley, C. L. (2018). A probabilistic interpretation of pid controllers using active inference. In
Internationalconferenceonsimulationofadaptivebehavior(pp.15–26).
Bastos,A.M.,Usrey,W.M.,Adams,R.A.,Mangun,G.R.,Fries,P.,&Friston,K.J. (2012).Canonicalmicrocircuits
forpredictivecoding. Neuron,76(4),695–711.
Beal,M.J.,etal. (2003). Variationalalgorithmsforapproximatebayesianinference. universityofLondonLondon.
Biehl,M.,Guckelsberger,C.,Salge,C.,Smith,S.C.,&Polani,D. (2018). Expandingtheactiveinferencelandscape:
moreintrinsicmotivationsintheperception-actionloop. Frontiersinneurorobotics,12,45.
Blei,D.M.,Kucukelbir,A.,&McAuliffe,J.D. (2017). Variationalinference: Areviewforstatisticians. Journalof
theAmericanstatisticalAssociation,112(518),859–877.
Buckley,C.L.,Kim,C.S.,McGregor,S.,&Seth,A.K. (2017). Thefreeenergyprincipleforactionandperception:
Amathematicalreview. JournalofMathematicalPsychology,81,55–79.
Burda, Y., Edwards, H., Pathak, D., Storkey,A., Darrell, T.,& Efros, A. A. (2018). Large-scalestudyof curiosity-
drivenlearning. arXivpreprintarXiv:1808.04355.
Calvo,P.,&Friston,K. (2017). Predictinggreen: reallyradical(plant)predictiveprocessing. JournalofTheRoyal
SocietyInterface,14(131),20170096.
Çatal, O., Verbelen,T.,Nauta,J., DeBoom,C.,&Dhoedt,B. (2020). Learningperceptionandplanningwithdeep
activeinference. arXivpreprintarXiv:2001.11841.
Cullen,M.,Davey,B.,Friston,K.J.,&Moran,R.J. (2018). Activeinferenceinopenaigym:Aparadigmforcompu-
tationalinvestigationsintopsychiatricillness. Biologicalpsychiatry:cognitiveneuroscienceandneuroimaging,
3(9),809–818.
DaCosta,L.,Parr,T.,Sajid,N.,Veselic,S.,Neacsu,V.,&Friston,K.(2020).Activeinferenceondiscretestate-spaces:
asynthesis. arXivpreprintarXiv:2001.07203.
Deneve,S. (2005). Bayesianinferenceinspikingneurons. InAdvancesinneuralinformationprocessingsystems(pp.
353–360).
13
A PREPRINT - SEPTEMBER 30, 2020
Doya,K.,Ishii,S.,Pouget,A.,&Rao,R.P. (2007). Bayesianbrain:Probabilisticapproachestoneuralcoding. MIT
press.
FitzGerald,T.H.,Schwartenbeck,P.,Moutoussis,M.,Dolan,R.J.,&Friston,K. (2015). Activeinference,evidence
accumulation,andtheurntask. Neuralcomputation,27(2),306–328.
Fox,C.W.,&Roberts,S.J. (2012). Atutorialonvariationalbayesianinference. Artificialintelligencereview,38(2),
85–95.
Friston,K. (2003). Learningandinferenceinthebrain. NeuralNetworks,16(9),1325–1352.
Friston, K. (2005). A theory of cortical responses. Philosophical transactions of the Royal Society B: Biological
sciences,360(1456),815–836.
Friston,K. (2008). Hierarchicalmodelsinthebrain. PLoScomputationalbiology,4(11).
Friston,K. (2010). Thefree-energyprinciple:aunifiedbraintheory? Naturereviewsneuroscience,11(2),127–138.
Friston,K. (2011). Whatisoptimalaboutmotorcontrol? Neuron,72(3),488–498.
Friston,K. (2019). Afreeenergyprincipleforaparticularphysics. arXivpreprintarXiv:1906.10184.
Friston, K., & Ao, P. (2012a). Free energy, value, and attractors. Computational and mathematical methods in
medicine,2012.
Friston, K., & Ao, P. (2012b). Free energy, value, and attractors. Computational and mathematical methods in
medicine,2012.
Friston,K.,FitzGerald,T.,Rigoli,F.,Schwartenbeck,P.,&Pezzulo,G. (2017a). Activeinference: aprocesstheory.
Neuralcomputation,29(1),1–49.
Friston,K.,FitzGerald,T.,Rigoli,F.,Schwartenbeck,P.,&Pezzulo,G. (2017b). Activeinference: aprocesstheory.
Neuralcomputation,29(1),1–49.
Friston, K., FitzGerald, T., Rigoli, F., Schwartenbeck, P., Pezzulo, G., et al. (2016). Active inferenceand learning.
Neuroscience&BiobehavioralReviews,68,862–879.
Friston, K., Kilner, J., & Harrison, L. (2006). A free energy principle for the brain. Journal of Physiology-Paris,
100(1-3),70–87.
Friston, K., Mattout, J., & Kilner, J. (2011). Action understanding and active inference. Biological cybernetics,
104(1-2),137–160.
Friston,K.,Rigoli,F.,Ognibene,D.,Mathys,C.,Fitzgerald,T.,&Pezzulo,G. (2015).Activeinferenceandepistemic
value. Cognitiveneuroscience,6(4),187–214.
Friston,K.J. (2008). Variationalfiltering. NeuroImage,41(3),747–766.
Friston,K.J.,Daunizeau,J.,&Kiebel,S.J. (2009). Reinforcementlearningoractiveinference? PloSone,4(7).
Friston,K.J.,Lin,M.,Frith,C.D.,Pezzulo,G.,Hobson,J.A.,&Ondobaka,S. (2017). Activeinference,curiosity
andinsight. Neuralcomputation,29(10),2633–2683.
Friston,K.J.,Parr,T.,&deVries,B. (2017). Thegraphicalbrain: beliefpropagationandactiveinference. Network
Neuroscience,1(4),381–414.
Friston, K. J., Rosch, R., Parr, T., Price, C., & Bowman, H. (2018). Deep temporal models and active inference.
Neuroscience&BiobehavioralReviews,90,486–501.
Friston, K. J., Trujillo-Barreto, N., & Daunizeau, J. (2008). Dem: a variational treatment of dynamic systems.
Neuroimage,41(3),849–885.
Houthooft,R.,Chen,X.,Duan,Y.,Schulman,J.,DeTurck,F.,&Abbeel,P. (2016).Variationalinformationmaximiz-
ingexploration. AdvancesinNeuralInformationProcessingSystems(NIPS).
Itti,L.,&Baldi,P. (2009). Bayesiansurpriseattractshumanattention. Visionresearch,49(10),1295–1306.
Kanai,R.,Komura,Y.,Shipp,S.,&Friston,K. (2015). Cerebralhierarchies:predictiveprocessing,precisionandthe
pulvinar. PhilosophicalTransactionsoftheRoyalSocietyB:BiologicalSciences,370(1668),20140169.
Kappen,H.J. (2005). Pathintegralsandsymmetrybreakingforoptimalcontroltheory. Journalofstatisticalmechan-
ics: theoryandexperiment,2005(11),P11011.
Kappen,H.J. (2007). Anintroductiontostochasticcontroltheory,pathintegralsandreinforcementlearning. InAip
14
A PREPRINT - SEPTEMBER 30, 2020
conferenceproceedings(Vol.887,pp.149–181).
Knill, D. C., & Pouget, A. (2004). The bayesian brain: the role of uncertainty in neural coding and computation.
TRENDSinNeurosciences,27(12),712–719.
Levine,S. (2018). Reinforcementlearningandcontrolasprobabilisticinference:Tutorialandreview. arXivpreprint
arXiv:1805.00909.
Millidge,B. (2019a). Combiningactiveinferenceandhierarchicalpredictivecoding:Atutorialintroductionandcase
study.
Millidge,B. (2019b). Deepactiveinferenceasvariationalpolicygradients. arXivpreprintarXiv:1907.03876.
Millidge,B. (2019c). Implementingpredictiveprocessingandactiveinference:Preliminarystepsandresults.
Mirza,M.B.,Adams,R.A.,Mathys,C.D.,&Friston,K.J. (2016). Sceneconstruction,visualforaging,andactive
inference. Frontiersincomputationalneuroscience,10,56.
Mirza, M. B., Adams, R. A., Parr, T., & Friston, K. (2019). Impulsivityandactiveinference. Journalofcognitive
neuroscience,31(2),202–220.
Mohamed,S.,& Rezende, D.J. (2015). Variationalinformationmaximisationforintrinsicallymotivatedreinforce-
mentlearning. InAdvancesinneuralinformationprocessingsystems(pp.2125–2133).
Ostwald,D.,Spitzer,B.,Guggenmos,M.,Schmidt,T.T.,Kiebel,S.J.,&Blankenburg,F. (2012).Evidenceforneural
encodingofbayesiansurpriseinhumansomatosensation. NeuroImage,62(1),177–188.
Oudeyer,P.-Y.,&Kaplan,F. (2009).Whatisintrinsicmotivation?atypologyofcomputationalapproaches.Frontiers
inneurorobotics,1,6.
Parr,T. (2019). Thecomputationalneurologyofactivevision(Unpublisheddoctoraldissertation). UCL(University
CollegeLondon).
Parr,T.,DaCosta,L.,&Friston,K. (2020). Markovblankets,informationgeometryandstochasticthermodynamics.
PhilosophicalTransactionsoftheRoyalSocietyA,378(2164),20190159.
Parr,T.,&Friston,K.J. (2017a). Theactiveconstructionofthevisualworld. Neuropsychologia,104,92–101.
Parr,T.,&Friston,K.J. (2017b).Uncertainty,epistemicsandactiveinference.JournalofTheRoyalSocietyInterface,
14(136),20170376.
Parr,T.,&Friston,K.J.(2018a).Activeinferenceandtheanatomyofoculomotion.Neuropsychologia,111,334–343.
Parr,T.,&Friston,K.J. (2018b). Thecomputationalanatomyofvisualneglect. CerebralCortex,28(2),777–790.
Parr, T., & Friston, K. J. (2019). Generalised free energy and active inference. Biological cybernetics, 113(5-6),
495–513.
Parr,T.,Markovic,D.,Kiebel,S.J.,&Friston,K.J. (2019). Neuronalmessagepassingusingmean-field,bethe,and
marginalapproximations. Scientificreports,9(1),1–18.
Pathak,D.,Agrawal,P.,Efros,A.A.,&Darrell,T. (2017).Curiosity-drivenexplorationbyself-supervisedprediction.
InProceedingsoftheieeeconferenceoncomputervisionandpatternrecognitionworkshops(pp.16–17).
Pezzulo, G., Cartoni, E., Rigoli, F., Pio-Lopez, L., & Friston, K. (2016). Active inference, epistemic value, and
vicarioustrialanderror. Learning&Memory,23(7),322–338.
Rawlik, K., Toussaint, M.,& Vijayakumar,S. (2013). Onstochasticoptimalcontrolandreinforcementlearningby
approximateinference. InTwenty-thirdinternationaljointconferenceonartificialintelligence.
Rawlik,K.C. (2013). Onprobabilisticinferenceapproachestostochasticoptimalcontrol.
Schwartenbeck,P., FitzGerald, T., Dolan, R., & Friston, K. (2013). Exploration,novelty,surprise, and freeenergy
minimization. Frontiersinpsychology,4,710.
Schwartenbeck,P.,Passecker,J.,Hauser,T.U.,FitzGerald,T.H.,Kronbichler,M.,&Friston,K.J. (2019). Compu-
tationalmechanismsofcuriosityandgoal-directedexploration. Elife,8,e41703.
Schwöbel,S.,Kiebel,S.,&Markovic´,D. (2018). Activeinference,beliefpropagation,andthebetheapproximation.
Neuralcomputation,30(9),2530–2567.
Shipp,S. (2016). Neuralelementsforpredictivecoding. Frontiersinpsychology,7,1792.
Spratling,M.W. (2008). Reconcilingpredictivecodingandbiasedcompetitionmodelsofcorticalfunction. Frontiers
15
A PREPRINT - SEPTEMBER 30, 2020
incomputationalneuroscience,2,4.
Still,S.,&Precup,D. (2012). Aninformation-theoreticapproachtocuriosity-drivenreinforcementlearning. Theory
inBiosciences,131(3),139–148.
Sun, Y., Gomez,F., &Schmidhuber,J. (2011). Planningtobesurprised: Optimalbayesianexplorationindynamic
environments. InInternationalconferenceonartificialgeneralintelligence(pp.41–51).
Theodorou,E.,Buchli,J.,&Schaal,S.(2010).Ageneralizedpathintegralcontrolapproachtoreinforcementlearning.
journalofmachinelearningresearch,11(Nov),3137–3181.
Theodorou,E.A.,&Todorov,E. (2012). Relativeentropyandfreeenergydualities:Connectionstopathintegraland
klcontrol. In2012ieee51stieeeconferenceondecisionandcontrol(cdc)(pp.1466–1473).
Toussaint,M. (2009). Probabilisticinferenceasamodelofplannedbehavior. KI,23(3),23–29.
Tschantz, A., Baltieri, M., Seth, A., Buckley, C. L., et al. (2019). Scaling active inference. arXiv preprint
arXiv:1911.10601.
Tschantz, A., Millidge, B., Seth, A. K.,& Buckley,C. L. (2020). Reinforcementlearningthroughactiveinference.
arXivpreprintarXiv:2002.12636.
Tschantz,A.,Seth,A.K.,&Buckley,C.L.(2019).Learningaction-orientedmodelsthroughactiveinference.bioRxiv,
764969.
Ueltzhöffer,K. (2018). Deepactiveinference. Biologicalcybernetics,112(6),547–573.
vande Laar,T.W., &deVries, B. (2019). Simulatingactiveinferenceprocessesbymessagepassing. Frontiersin
RoboticsandAI,6(20).
Wainwright, M. J., Jordan, M. I., et al. (2008). Graphical models, exponentialfamilies, and variational inference.
FoundationsandTrends(cid:13)R inMachineLearning,1(1–2),1–305.
Williams,G.,Aldrich,A.,&Theodorou,E.A. (2017).Modelpredictivepathintegralcontrol:Fromtheorytoparallel
computation. JournalofGuidance,Control,andDynamics,40(2),344–357.
Yedidia,J.S.,Freeman,W.T.,&Weiss,Y.(2001).Generalizedbeliefpropagation.InAdvancesinneuralinformation
processingsystems(pp.689–695).
Yedidia,J.S.,Freeman,W.T.,&Weiss,Y. (2005). Constructingfree-energyapproximationsandgeneralizedbelief
propagationalgorithms. IEEETransactionsoninformationtheory,51(7),2282–2312.
9 VariationalInference
Tomotivatethevariationalfree-energy,andvariationalinferencemoregenerally,wesetupastandardinferenceprob-
lem. Letussayweareanagentthatexistsinapartiallyobservedworld. Wehavesomeobservationo ,andfromthis
t
wewishtoinferthehiddenstateoftheworldx . Thatis,wewanttocomputetheposteriorp(x |o ). Whilewedonot
t t t
knowthisposteriordirectly,wedopossessa generativemodeloftheworld. Thisisamodelthatmapsfromhidden
statestoobservations. Mathematically,wepossessp(o ,x ) = p(o |x )p(x ). Sincecomputingthetrueposteriorex-
t t t t t
actlyislikelyintractable,thestrategyinvariationalinferenceistotrytoapproximatethisdensitywithatractableone
Q(x |o ;φ)whichwepostulate,andthushavefullcontrolover.Whilethetrueposteriormightbearbitrarilycomplex,
t t
wemightdefineQ(x |o ;φ)tobeaGaussiandistribution: Q(x |o ;φ) = N(x;µ ,σ ),forinstance. Giventhatwe
t t t t φ φ
havethisvariationaldensityq,parametrisedbysomeparametersφ, thegoalistoadjusttheparameterstomakeqas
closeaspossibletothetrueposteriorp(x |o ). Mathematicallyspeaking,thismeanswewanttominimize:
t t
argmin D [Q(x |o ;φ)||p(x |o )]
φ KL t t t t
WhereD [QkP]istheKullback-Leiblerdivergence. Thisinitiallydoesn’tseemtohaveboughtusmuch. Wewish
KL
tominimizethedivergencebetweenthevariationaldensityqandthetrueposteriorp(x |o ). However,byassumption,
t t
wedonotknowthetrueposterior.Sohowcanwepossiblyminimizethisdivergenceifwedonotknowoneoftheparts?
Thisiswhereweusethekeytrickofvariationalinference. ByBayestheoremweknowthat: p(x |o )= p(ot|xt)p(xt)
t t p(ot)
16
A PREPRINT - SEPTEMBER 30, 2020
wewecanthussubstitutethisintotheKLdivergenceterm.
p(o |x )p(x )
argmin D [Q(x |o ;φ)||p(x |o )]=argmin D [Q(x |o ;φ)|| t t t ]
φ KL t t t t φ KL t t p(o )
t
Q(x |o ;φ)p(o )
=E ln( t t t )
Q(xt|ot;φ) p(o |x )p(x )
t t t
Q(x |o ;φ)
=E ln( t t )+E lnp(o )
Q(xt|ot;φ) p(o |x )p(x ) Q(xt|ot;φ) t
t t t
=D [Q(x |o ;φ)||p(o |x )p(x )]+lnp(o ) (6)
KL t t t t t t
Instep2wehaveappliedBayestheoremthetheposterior. Instep3wehavesimplyutilizedthedefinitionoftheKL-
divergenceD [Q||P]=E ln(Q). Instep4wehavethenappliedthepropertyoflogsthatln(a∗b)=ln(a)+ln(b).
KL Q P
Instep5wethenrecognisethattheremainingfirsttermisnowaKLdivergencebetweenthevariationalposteriorand
the generativemodel. We also recognisethat since the lnp(o ) term has no dependenceon x or φ, the expectation
t
E lnp(o )vanishesleavingjustthelnp(o )termalone.ItisimportanttonotethattheKLterminequation6
Q(xt|ot;φ) t t
isnowbetweentwothingswecanactuallycompute–thevariationalposterior,whichwecontrol,andthegenerative
model, which we assume that we know. The remaining lnp(o ) term is called the log model evidence and it is
t
incomputableingeneral. However,sinceitisnotaffectedbytheparametersφofthevariationaldensity,thenitdoes
notaffecttheminimizationandsoforthepurposesoftheminimizationprocesscanbeignored.Wecanthuswriteout
whatwehavedefinedas
D [Q(x |o ;φ)||p(x |o )]=D [Q(x |o ;φ)||p(o |x )p(x )]+lnp(o )
KL t t t t KL t t t t t t
⇒D [Q(x |o ;φ)||p(o |x )p(x )]≥D [Q(x |o ;φ)||p(x |o )]
KL t t t t t KL t t t t
ThisimpliesthattheKLdivergencebetweenthevariationaldensityandthegenerativemodelisalwaysgreaterthanor
equaltotheKLdivergencebetweenthetrueandvariationalposteriors.SincewecancomputethefirstKLdivergence,
we call it the variational free-energy F. Since it is an upper bound on the divergence between the true posterior
and the variationalposterior, which is what we really want to minimize, then if we minimize F, we are constantly
pushingthatboundlowerandthuslargelyminimizingthedivergencebetweenthetrueandvariationalposterior.Asan
additionalbonus,whenthetrueandvariationalposteriorsareapproximatelyequal: D [Q(x |o ;φ)||p(x |o )] ≈ 0
KL t t t t
thenD [Q(x |o ;φ)||p(o |x )p(x )]≈−lnp(o ),whichmeansthatthefinalvalueofthevariational-free-energyis
KL t t t t t t
thusequaltothenegativelogmodelevidence. Sincethelogmodelevidenceisaveryusefulquantitytocomputefor
Bayesianmodelselection,iteffectivelymeansthatoncewehavefinishedfittingourmodel,weareautomaticallyleft
withameasureofhowgoodourmodelis.
In effect the variational free energy is useful because it has two properties. The first is that it is an upper bound
on the divergencebetween the true and approximateposterior. By adjusting ourapproximateposteriorto minimize
thisbound,wedriveitclosertothetrueposterior,thusachievingmoreaccurateinference. Secondly,thevariational
free-energyisaboundonthelogmodelevidence. Thisisanimportanttermwhichscoresthelikelihoodofthedata
observedgivenyourmodelandsocanbeusedinBayesianmodelselection.
The log model evidence takes on an additional importancein terms of the free-energyprinciple, since the negative
log model evidence −lnp(o ) is surprisal, which all agents, it is propsed are driven to minimize (K.Fristonetal.,
t
2006). This is because the expected log model evidence is the entropy of observations, the minimisation of which
is postulated as a necessary condition for any self-sustaining organism to maintain itself as a unique system. The
free-enregyminimizationcomesaboutsincetheVFEis,aswehaveseenatractableboundonthelogmodelevidence,
orsurprisal.
TheVFEcanbedecomposedinthreeprincipleways,whicheachshowcasesadifferentfacetoftheobjective.
17
A PREPRINT - SEPTEMBER 30, 2020
F=D [Q(x |o ;φ)||p(o ,x )]
KL t t t t
Q(x |o ;φ)
=E ln t t
Q(xt|ot;φ) p(o ,x )
(cid:2) t t (cid:3)
=E [lnQ(x |o ;φ)]−E [lnp(o ,x )]
Q(xt|ot;φ) t t Q(xt|ot;φ) t t
Entropy Energy
| {z } | {z }
=−E [lnp(o |x )]+D [Q(x |o ;φ)||p(x )]
Q(xt|ot;φ) t t KL t t t
Accuracy Complexity
| {z } | {z }
= −lnp(o ) +D [Q(x |o ;φ)||p(x |o )]
t KL t t t t
NegativeLogModelEvidence PosteriorDivergence
| {z } | {z }
In the first entropy-energydecomposition, we simply split the KL divergenceusing the propertiesof logarithmsso
that the numerator of the fraction becomes the entropy term and the denominator becomes the energy term. If
we are seeking to minimize the variational-free-energythen this means we need to both minimize the negative en-
tropy(sinceentropyisdefinedas−E lnQ(x) andalsominimizethenegativeenergy(ormaximizetheenergy)
Q(x)
E [lnp(o ,x )]. Thiscanbeinter(cid:2)pretedas(cid:3)sayingwe requirethatthe variationalposteriorbeasentropicas
Q(xt|ot;φ) t t
possible while also maximizing the likelihood that the xs proposed as probable by the variationalposterior also be
judgedasprobableunderthegenerativemodel.
Theseconddecompositionintoaccuracyandcomplexityperhapshasamorestraightforwardinterpretation. Wewish
to minimize the negative accuracy (and thus maximize the accuracy), which means we want the actually observed
observationtobeaslikelyaspossibleunderthexspredictedbythevariationalposterior. However,wealsowantto
minimizethecomplexitytermwhichisaKLdivergencebetweenthevariationalposteriorandtheprior. Thatis, we
wish to keep yourposterior as close to our prioras possible while still maximizingaccuracy. The complexityterm
thenfunctionsasakindofimplicitregulariser,makingsurewedonotoverfittoanyspecificobservation.
ThefinaldecompositionspeaksthetheinferentialfunctionsoftheVFE.Itservesasanupperboundonthelogmodel
evidence, since the posterior divergence term, as a KL divergence, is always positive. Moreover, we see that by
minimizingthefree-energy,wemustalsobeminimizingtheposteriordivergence,whichisthedifferencebetweenthe
approximateandtrueposterior,andwearethusimprovingourvariationalapproximation.
10 Decompositions oftheEFE
InthissectionweprovideacomprehensiveoverviewofthemanydecompositionsoftheEFE.TheEFEisdefinedas:
G(π)=E [lnQ(x |π)−lnp˜(o ,x )]
Q(oτ,xτ|π) τ τ τ
The standard decomposition is into the extrinsic term (expected log likelihood of the desired observations) and an
epistemic term (the informationgain, or KL divergencebetween variationalprior and posteriorfrom the generative
model.
E [lnQ(x |π)−lnp˜(o ,x )]=E [−lnp˜(o )−lnp(x |o )+lnQ(x |π)]
Q(oτ,xτ|π) τ τ τ Q(oτ,xτ|π) τ τ τ τ
=−E lnp˜(o ) −E D [Q(x |o )||Q(x |π)]
Q(oτ,xτ|π) τ Q(oτ|π) KL τ τ τ
(cid:2) (cid:3) (cid:2) (cid:3)
ExtrinsicValue EpistemicValue
| {z } | {z }
SimilartotheVFE,itisalsopossibletosplititintoanenergyandanentropyterm. Whiletheenergytermissimilar
totheVFEastheexpectationofthegenerativemodel(albeitanexpectationoverthejointinsteadoftheposterior),the
18
A PREPRINT - SEPTEMBER 30, 2020
entropytermisdifferentasitistheentropyofthevariationalprior,nottheapproximateposterior,whichresults.
G(π)=E [lnQ(x |π)−lnp˜(o ,x )]
Q(oτ,xτ|π) τ τ τ
=E [lnQ(x |π)]−E [lnp˜(o ,x )]
Q(oτ,xτ|π) τ Q(oτ,xτ|π) τ τ
=−E H Q(x |π) −E [lnp˜(o ,x )]
Q(oτ|xτ) τ Q(oτ,xτ|π) τ τ
(cid:2) (cid:2) (cid:3)(cid:3)
Entropy Energy
Itisalsopossibletodecomposethebi|asedgenera{tizvemodelth}eot|herwayaro{uznd,thusin}linewiththatoftheVFEto
derive:
G(π)=E [lnQ(x |π)−lnp˜(o ,x )]
Q(oτ,xτ|π) τ τ τ
=E [lnQ(x |π)−lnp˜(o |x )−lnp(x )]
Q(oτ,xτ|π) τ τ τ τ
=−E lnp˜(o |x ) +E D Q(x |π)kp(x )
Q(oτ,xτ|π) τ τ Q(oτ|xτ) KL τ τ
(cid:2) (cid:3) (cid:2) (cid:2) (cid:3)(cid:3)
Accuracy Complexity
| {z } | {z }
UnliketheVFE,howeverthedivergenceisbetweenthevariationalpriorandthegenerativeprior,ratherthanbetween
the variationalposterior and the generative prior. Finally, the EFE can also be represented in observation space by
usingBayesruletoflipthelikelihoodsandpriors.
G(π)=E [lnQ(x |π)−lnp˜(o ,x )]
Q(oτ,xτ|π) τ τ τ
=E [lnQ(x |π)−lnp˜(o )−lnQ(x |o )]
Q(oτ,xτ|π) τ τ τ τ
=E [lnQ(x |π)−lnp˜(o )−lnQ(o |x )−lnQ(x |π)+lnQ(o )]
Q(oτ,xτ|π) τ τ τ τ τ τ
=E [−lnp˜(o )−lnQ(o |x )+lnQ(o )]
Q(oτ,xτ|π) τ τ τ τ
=E H Q(o |x ) −E D Q(o )kp˜(o )
Q(xτ|π) τ τ Q(xτ|oτ) KL τ τ
(cid:2) (cid:2) (cid:3)(cid:3) (cid:2) (cid:2) (cid:3)(cid:3)
PredictedUncertainty PredictedDivergence
| {z } | {z }
=−E lnp˜(o ) −E D Q(o |x )kQ(o )
Q(xτ|π) τ Q(xτ|π) KL τ τ τ
(cid:2) (cid:3) (cid:2) (cid:2) (cid:3)(cid:3)
ExtrinsicValue (Observation)InformationGain
Itisalsopossibletofactori|sethebia{szedgener}ativ|emodeltheother{wzayaroundinter}msofanunbiasedlikelihoodand
biasedstates: p˜(o ,x ) = p(o |x )p˜(x ). Thisdifferentfactorisationleadstoanewdecompositionintermsofrisk
τ τ τ τ τ
andambiguity,aswellaspotentiallydifferentbehaviourduetothechangefromdesiredobservationstodesiredstates
11.
G(π)=E [lnQ(x |π)−lnp˜(o ,x )]
Q(oτ,xτ|π) τ τ τ
=E [lnQ(x |π)−lnp(o |x )−lnp˜(x )]
Q(oτ,xτ|π) τ τ τ τ
=E H[p(o |x )] +D Q(x |π)kp˜(x |π)
Q(xτ|π) τ τ KL τ τ
(cid:2) (cid:3) (cid:2) (cid:3)
Ambiguity Risk
Here the agent is driven to minimiz|e the dive{rgzence betw}een|desired and{zprior expec}ted states, while also trying
to minimize the entropy of the observationsit receives. This drives the agent to try to sample observations with a
minimallyambiguous(ormaximallyprecise)mappingbacktostates.
Thisformulationismathematicallyequivalenttothepreviousdecompositionsdespitedefiningdesiredstatesinstead
ofdesiredobservations,ascanbeseenwiththefollowingmanipulations:
G(π)=E H[p(o |x )] +D Q(x )kp˜(x )
Q(xτ|π) τ τ KL τ τ
(cid:2) (cid:3) (cid:2) (cid:3)
Ambiguity Risk
| {z } | {z }
=E [lnQ(x |π)−lnp(o |x )−lnQ(x |o )−lnp˜(o )+lnp(o |x )]
Q(oτ,xτ|π) τ τ τ τ τ τ τ τ
=−E lnp˜(o ) −E D [Q(x |o )||Q(x |π)] =G(π)
Q(oτ,xτ|π) τ Q(oτ|π) KL τ τ τ
(cid:2) (cid:3) (cid:2) (cid:3)
ExtrinsicValue EpistemicValue
| {z } | {z }
11ForfurtherdetailonthisfactorizationseeDaCostaetal.(2020).
19
A PREPRINT - SEPTEMBER 30, 2020
Therisk-ambiguityformulationhasverycloserelationstoKLcontrol(K.Rawliketal.,2013),inthatitencompasses
KLcontrolwithanadditional"epistemic"ambiguityterm.
G(π)=E H[p(o |x )]+D Q(x |π)kp˜(x )
Q(xτ|π) τ τ KL τ τ
(cid:2) (cid:3)
KLControl
| {z }
ActiveInference
| {z }
11 Trajectory DerivationoftheExpected Model Evidence
Here we presentthe derivationof the freeenergyofthe future(FEF) fromthe expectedmodelevidenceforthe full
trajectorydistributionratherthanasingletime-step.Importantly,weshowthatwithatemporalmean-fieldapproxima-
tionontheapproximateposterior: p(x |o )≈ T p(x |o ),theassumptionthatdesiredrewardsareindependent
1:T 1:T t t t
intime: p(rˆ )≈ T p(rˆ),andgivenaMarkoviaQngenerativemodel,thenthetrajectorydistributionfactorisesinto
1:T t t
asumofindividualQtime-steps12,onlydependentonthepastthroughthepriortermp(x )=E p(x |x ).
t Q(xt−1|ot−1 t t−1
We namethisfinalapproximationthefactorizationapproximation,anditsimply statesthatyourprioratthe current
time-stepisbasedontheposterioroftheprevioustime-stepmappedthroughthetransitiondynamicsp(x |x ).
t t−1
argmin −E lnp˜(o )
p(π) Q(o1:T|π) 1:T
=−E ln dx p˜(o ,x )
Q(o1:T|π) Z 1:T 1:T 1:T
p˜(o ,x )Q(x |o )
=−E ln dx 1:T 1:T 1:T 1:T
Q(o1:T|π) Z 1:T Q(x |o )
1:T 1:T
T
p˜(o ,x )Q(x |o )
=−E ln dx t t t t
Q(o1:T|π) Z 1:T Q(x |o )
Y t t
t
T p˜(o |x )E p(x |x )Q(x |o )
=−E ln dx t t Q(xt−1|ot−1) t t−1 t t
Q(o1:T|π) Z 1:T Q(x |o )
Y t t
t
t p˜(o |x )−E p(x |x )Q(x |o )
=E ln dx t t Q(xt−1|ot−1) t t−1 t t
Q(o1:T|π) Z t Q(x |o )
X t t
t
t p˜(o |x )E p(x |x )
≥− E dx Q(x |o )ln t t Q(xt−1|rt−1) t t−1
Q(o1:T|π)Z t t t Q(x |o )
X t t
t
t p˜(o |x )E p(x |x )
≥− dx do Q(o ,x |π)ln
t t Q(xt−1|ot−1) t t−1
Z t Z 1:T 1:T t Q(x |o )
X t t
t
t p˜(o |x )E p(x |x )
≥− E ln t t Q(xt−1|ot−1) t t−1
Q(ot,xt|π) Q(x |o )
X t t
t
t t
≥− E lnp˜(o |x )− E D [p(x |o )||E p(x |x )]
Q(ot,xt|π) t t p(ot) KL t t Q(xt−1|ot−1) t t−1
X X
t t
t
≥− FEF
t
X
t
12Weassumediscretetimesothereisasumovertimesteps. Wealsoassumecontinuousstatessothereisanintegraloverstates
x.However,thederivationisidenticalinthecaseofdiscretestateswheretheintegralissimplyreplacedwithasum.
20
A PREPRINT - SEPTEMBER 30, 2020
ThetrajectoryderivationoftheFEEFfollowsanalmostidenticalschemetothatoftheFEF.Theonlydifferenceisthat
nowtheterminsidethelogalsocontainsanadditional−lnp˜(o),whichisthencombinedwiththelikelihoodfromthe
generativemodeltoformtheextrinsic-valueKLdivergence.
12 EFE Bound onthe NegativeLog Model Evidence
ItisimportanttonotethattheEFEisalsoaboundonthenegativelogmodelevidence,butalowerbound,notanupper
bound.Thismeansthatintheory,oneshouldwanttomaximizetheEFE,insteadofminimizeit,tomaketheboundas
tightaspossible.
Itisstraightforwardtoshowthebound,sincetheextrinsicvaluetermoftheEFEsimplyisthelogmodelevidence.
EFE=E [lnQ(x |π)−lnp˜(o ,x )]
Q(oτ,xτ|π) τ τ τ
≈E [lnQ(x |π)−lnQ(x |o )−lnp˜(o )]
Q(oτ,xτ|π) τ τ τ τ
≈ −E [lnp˜(o )] −E D [Q(x |o )kQ(x |π)]|
Q(oτ|π) τ Q(oτ|π) KL τ τ τ
NegativeExpectedLogModelEvidence InformationGain
| {z } | {z }
Thisderivationassumesthatthetrueandapproximateposteriorsareapproximatelyequalp(x |o )≈Q(x |o )such
τ τ τ τ
thatthisistrueonlyafteravariationalinferenceprocedureiscompleted.
We wish to minimize both log model evidence, and minimize the EFE. Since the information gain term is a KL
divergence,whichisalways≥0,andwehaveanegativeinformationgainterm,thismeansthattheEFEisalwaysless
thanthelogmodelevidenceandsoisalowerbound. However,thisboundbecomestightwhentheinformationgain
is0,sotomaximallytightentheboundwewishtoreducetheinformationgain,whiletheEFEdemandswemaximize
it. Ineffect,thismeansthattheEFEboundisthewrongwayaround.
WecanseethismoreclearlywhenweretracethelogicfortheFEF.Fromequation4,wehavethattheFEFisanupper
boundonthenegativelogmodelevidence.ThismeansthatminimizingtheFEFnecessarilytightensthebound,while
thisisnottrueoftheEFElowerbound,whereminimizingtheEFEcanactuallycauseittodivergefromthelogmodel
evidence.WecanseethisevenmoreclearlybydoingananalogousdecompositionoftheFEF.
FEF=E [lnQ(x |o )−lnp˜(o ,x )]
Q(oτ,xτ|π) τ τ τ τ
=E [lnQ(x |o )−lnp(x |o )−lnp˜(o )]
Q(oτ,xτ|π) τ τ τ τ τ
= −E [lnp˜(o )] +E D [Q(x |o )kp(x |o )]|
Q(oτ|π) τ Q(oτ|π) KL τ τ τ τ
NegativeExpectedLogModelEvidence PosteriorApproximationError
| {z } | {z }
Here,sincetheKLisbetweenthegenerativemodelandtheapproximateposterior,andthendecomposethegenerative
modelinto a true posterior and marginal, we can no longermake the assumption, made in the EFE derivation, that
thetrueandapproximateposteriorareapproximatelyequal,sincethatwouldleaveuswithonlythemodelevidence.
Therefore,insteadwegetaposteriorapproximationerrortermwhichistheKLdivergencebetweentheapproximate
andtrueposteriors. Whenthetrueandapproximateposteriorareequal,wearejustleftwiththelogmodelevidence.
Since, the posterior approximationerror is always ≥ 0, then the FEF is an upper bound on the negativelog model
evidence,andthusbyminimizingtheFEF,wemaketheboundtighter.Thislogicisessentiallyarepriseofthestandard
variationalinferencelogicfromaslightlydifferentperspective.
21
A PREPRINT - SEPTEMBER 30, 2020
Ifwe do notmaketheassumptionin theEFE thattheapproximateandtrue posteriorarethe same, wecan derivea
similarexpressiontotheEFEwhichwillshedmorelightontherelation.
EFE=E [lnQ(x |π)−lnp˜(o ,x )]
Q(oτ,xτ|π) τ τ τ
≈E [lnQ(x |π)−lnp(x |o )−lnp˜(o )]
Q(oτ,xτ|π) τ τ τ τ
≈E [lnQ(x |π)−lnp(x |o )−lnp˜(o )+lnQ(x |o )−lnQ(x |o )]
Q(oτ,xτ|π) τ τ τ τ τ τ τ τ
≈ −E [lnp˜(o )] +E D [Q(x |o )kp(x |o )]|−E D [Q(x |o )kQ(x |π)]|
Q(oτ|π) τ Q(oτ|π) KL τ τ τ τ Q(oτ|π) KL τ τ τ
NegativeExpectedLogModelEvidence PosteriorApproximationError InformationGain
| {z } | {z } | {z }
FEF
| {z }
Withoutthetrueposteriorassumption,wethusfindthattheEFEcouldbebothanupperoralowerboundonthelog
modelevidence,sincethetwoadditionalKLdivergencetermshaveoppositesigns.Iftheposteriorapproximationerror
islargerthantheinformationgain,thentheEFEfunctionscorrectlyasanupperbound. However,iftheinformation
gainislarger,thentheEFEwillbecomealowerboundandcoulddivergefromthelogmodelevidence.Moreover,this
lattersituationismorelikely,sincethegoalofvariationalinferenceistoreducetheapproximationerror,whileEFE
agentsseektomaximizeinformationgain.ThismeansthattheEFEonlyfunctionscorrectlyasanupperboundonlog
modelevidenceduringtheearlystagesofoptimizationwheretheposteriorapproximationispoor.Furtheroptimization
stepslikelydrivetheEFEfurtherawayfromthemodelevidence.Theboundistightwhentheinformationgainequals
theposteriorapproximationerror. WecanalsoseethatthefirsttwotermsoftheEFEissimplytheFEF,wehavethus
rederivedbyaratherroundaboutroute,thefactthattheEFEissimplytheFEFminustheinformationgain.
We thus see that the EFE as a bound on the log model evidence is shaky, since it dependson the informationgain
always being larger or smaller than the posterior approximationerror. Moreover, the boundingbehaviourseems to
emergedirectlyfromtherelationoftheEFEtotheFEFratherthantheintrinsicqualitiesoftheEFE,anditisprimarily
theinformation-seekingpropertiesoftheEFEwhichservetodamagethecleanboundingbehaviouroftheFEF.
ItcanbearguedthatalthoughthemathematicaljustificationoftheEFEasaboundmaybeshaky,thattheadditional
informationgain term may be beneficial, and the bound may be recoveredin the long run, since that as a result of
short-termactionstomaximizetheEFE,theepistemicvalueitselfgoesto0,andthustheEFEexactlyapproximates
thebound,whilealsopotentiallyincreasingtheultimateexpectedrewardachieved.Thisargumentisvalidheuristically
andisidenticaltothestandardjustificationsforad-hocintrinsicmeasurestermsintheliterature(Oudeyer&Kaplan,
2009)namelythatexplorationhurtsintheshortrunbuthelpsinthelongrun. Wedonotdisputethatargumentinthis
paper,insteadwesimplyshowthattheEFEcannotstraightforwardlybejustifiedmathematicallyasbeingaresultof
variationalinferenceintothefuture,orasaboundonmodel-evidence. Wedonotargueatallagainstitsheuristicuse
toencourageexplorationoftheenvironmentandthus(hopefully)betterperformanceoverall.
13 Attempts atNaturalisingthe EFE
Inthisappendix,wereviewseveralattemptstoderivetheEFEdirectlyfromtheexpectedmodelevidence.
SincewehavederivedtheFEFbyimportancesamplingtheexpectedmodelevidencewiththeapproximateposterior,
one obviousavenuewould be to importancesample on the variationalpriorinstead. Following this line of thought
22
A PREPRINT - SEPTEMBER 30, 2020
givesus:
−E lnp˜(o ) =−E ln dxp˜(o ,x )
Q(oτ|π) τ Q(oτ|π) Z τ τ
(cid:2) (cid:3) (cid:2) (cid:3)
Q(x |π)
=−E [ ln dx p˜(o ,x ) τ
Q(oτ|π) Z τ τ τ Q(x |π)
(cid:2) τ (cid:3)
p˜(o ,x )
≤−E dx Q(x |π)ln τ τ
Q(oτ|π) Z τ τ Q(x |π)
(cid:2) τ (cid:3)
p˜(o ,x )
≤−E ln τ τ
Q(oτ|π)Q(xτ|π) Q(x |π)
(cid:2) τ (cid:3)
≤−E [lnQ(x |π)−lnp˜(o ,x )]
Q(oτ|π)Q(xτ|π) τ τ τ
WhilethisapproachgetsthecorrectformoftheEFEinsidetheexpectation,theexpectationitselfistheproductofthe
twomarginalsratherthanthejointrequiredforthefullEFE.Whilethismayseemminor,thisdifferencemustunderpin
alltheotherdifferencesandrelationswehaveexploredthroughoutthispaper.
To gettothe fullEFEwe mustmakesomeassumptionto allowusto combinetheexpectationundertwo marginals
intoan expectationunderthe joint. Thefirstandsimplestassumptionis thattheysimplyare thesame suchthatthe
jointfactorisesintothetwomarginals–Q(o ,x |π)≈Q(o |π)Q(x |π). Thisassumptionisequivalenttoassuming
τ τ τ τ
independenceofobservationsandlatentstates,whichratherdefeatsthepointofalatentvariablemodel.
AsecondapproachistoassumethatthevariationalpriorequalsthevariationalposteriorQ(x |π) ≈ Q(x |o ). This
τ τ τ
allowsyouthentocombinethemarginalandposteriorintoajoint,givingtheEFEasdesired.Howeverthisassumption
hasseveralunfortunateconsequences. Firstly,iteliminatestheentireideaofinference,sincethepriorandposterior
areassumedtobethesame,thusnorealinferencecanhavetakenplace. Thisisnotnecessarilyanissueifweseparate
theinferenceandplanningstagesofthealgorithm,suchthattheyoptimizedifferentobjectivefunctions,howeveritis
moreelegant,astheFEEFdoes,isthatitenablestheoptimizationofthesameobjectivefunctionforbothinference
andplanning,thuscastingthemassimplydifferentfacetsofthesameunderlyingprocess. Moreover,amoreserious
issueisthatthisassumptionalsoeliminatestheinformationgainterminactiveinference–sincethepriorandposterior
arethesame,thedivergencebetweenthem(whichistheinformationgain),mustbezero.
A slightlydifferentapproachis takenin a proofin (Parr, 2019), whichbeginswith the KL divergencebetweentwo
distributions, one encoding beliefs about future states and observations, and the other being the biased generative
model.Bydefinition,thisKLdivergenceisalways≥0,whichallowsustowrite.
D [p(o ,x |π)kp˜(o ,x )]≥0
KL τ τ τ τ
=E D [p(x |o )kp˜(o ,x )]−E [lnp(o |π)]≥0
p(oτ|π) KL τ τ τ τ p(oτ|π) τ
⇒−E D [p(x |o )kp˜(o ,x )]≥−E [lnp(o |π)]
p(oτ|π) KL τ τ τ τ p(oτ|π) τ
⇒FEF≥−E [lnp(o |π)]
p(oτ|π) τ
Undertheassumptionthatp(x|o)≈Q(x|π),thisbecomes:
−E D [p(x |o )kp˜(o ,x )]≥−E [lnp(o |π)]
p(oτ|π) KL τ τ τ τ p(oτ|π) τ
≈E D [Q(x |π)kp˜(o ,x )]≥−E [lnp(o |π)]
p(oτ|π) KL τ τ τ p(oτ|π) τ
≈EFE≥−E [lnp(o |π)]
p(oτ|π) τ
Thisproofderivesthe FEFasa boundon, notthe expectedmodelevidencebyourdefinition,butonthe entropyof
expectedobservationsgivenapolicy. TheEFEisthenderivedfromtheFEFbyassumingthatthepriorandposterior
are the same, which comes with all the drawbacks explained above. This proof is primarily unworkable because
of the assumption that the prior and the posterior are identical. While this may be arguable in the continuoustime
23
A PREPRINT - SEPTEMBER 30, 2020
limit,whereitisequivalenttotheassumptionthatthat dQ(x|o) ≈0,whichiswhenthecontinuous-timeinferencehas
dt
reachedanequilibrium,itis definitelynottruein discretetime, wherealthoughthereisarelationbetweentheprior
in the currenttime-step and the posterior in the previousone, it must be mapped throughthe transition dynamics–
Q(x |π)=E [p(x |x ,π)].
t Q(xt−1|π) t t−1
OnecanalsoattemptarelatedproofbysplittingtheKLdivergencetheotherway. Thisgivesyou:
D [p(o ,x |π)kp˜(o ,x )]≥0
KL τ τ τ τ
=D [p(o ,x |π)kp˜(x |o )]−E [lnp˜(o )]≥0
KL τ τ τ τ p(oτ|π) τ
⇒−D [p(o ,x |π)kp˜(x |o )]≥−E [lnp˜(o )]
KL τ τ τ τ p(oτ|π) τ
⇒E [lnp(o |x )]+E D [p(x |o )kp˜(x |π)]≥−E [lnp˜(o )]
p(xτ|π) τ τ p(oτ|π) KL τ τ τ p(oτ|π) τ
⇒FEF≥−E [lnp˜(o )]
p(oτ|π) τ
WhichisjustanotherwayofshowingthattheFEFisaboundontheexpectedmodelevidence.
14 Related Quantites
Recently a new free-energy,the generalised free energy(GFE) (Parr&Friston, 2019), has been proposedin the lit-
erature as an alternative or an extension to the EFE. The GFE shares some close similarities with the FEEF. Both
fundamentallyextendtheEFEbyproposingaunifiedobjectivefunctionwhichisvalidforbothinferencceatthecur-
renttimeandplanningintothefuture,whereastheEFEcanonlybeusedforplanning.Moreover,bothGFEandFEEF
encode future observations as latent unobserved variables, over which posterior beliefs can be formed. Moreover
agentsmaintainpriorbeliefsoverthesevariableswhichencodeitspreferencesordesires13.
Thegeneralisedfreeenergyisdefinedas
GFE=E [lnQ(o )+lnQ(x )−lnp˜(o ,x )]
Q(oτ,xτ) τ τ τ τ
WhereastheFEEFisdefinedas
FEEF=E [lnQ(o ,x )−lnp˜(o ,x )]
Q(oτ,xτ) τ τ τ τ
TherearetwokeydifferencesmathematicallyandintuitivelybetweentheGFEandtheFEEF.ThefirstisthattheGFE
maintainsafactorisedposterioroverbeliefsandobservations,wheretheposteriorbeliefsofthetwoareseparatedbya
meanfieldapproximationandassumedtobeseparate.BycontrasttheFEEFmaintainsajointapproximatebeliefover
both observationsand states simultaneously. This jointin the case of the FEEF effectivelyfunctionsas a veridicial
generativemodelsinceQ(o|x) = p(o|x)andQ(x) = E p(x |x ). Thisismeansthatposteriorbeliefsof
Q(xt−1|π) t t−1
thefuturearecomputedsimplybyrollingforwardthegenerativemodelgiventhebeliefsaboutthecurrenttime.
A second and more important differences lies in the generative models. The GFE assumes that the agent is only
equipped with a single generative model with both veridicial and biased components. The preferences of an EFE
agentareencodedasaseparatefactorisablemarginaloverobservations. Thismeansthatthegenerativemodelofthe
GFEagentfactorisesasp˜(o,x) ∝ p(o|x)p(x)p˜(o). ThismeansthatfortheGFEthelikelihoodandthepriorare
GFE
unbiasedandthereissimplyanadditionalpriorpreferencesterminthefree-energyexpression.Bycontrast,theFEEF
eschewsthisunusualfactorisationofthegenerativemodelandinsteadpresupposesaseparatewarpedgenerativemodel
foruse in thefuturewhichis intrinsicallybiased. The FEEFgenerativemodelthusdecomposesasp˜(o,x) =
FEEF
p˜(o|x)p˜(x), which is the standard factorisation of the joint distribution in a generative model, but where both the
likelihoodandpriordistributionsarebiased towardsgeneratingmorefavourablestatesof affairsfortheagent. This
inherentoptimismbiasthendrivesaction.
13TohelpmakeclearthesimilaritybetweentheGFEandtheFEEF,wehavedefinedtheveridicialgenerativemodelasQ(oτ,xτ)
24
A PREPRINT - SEPTEMBER 30, 2020
A further free-energy proposed in the literature has been the Bethe free-energy and the Bethe approximation
(Schwöbeletal., 2018). This approach eschews the standard mean field assumption on the approximate posterior
in favourof a Bethe approximationfrom statistical physics(Yedidia,Freeman,&Weiss, 2001, 2005) which instead
representstheapproximateposteriorastheproductofpairwisemarginals,thuspreservingaconstraintofpairwisetem-
poralconsistencywhichthe mean-fieldassumptionlacks. Dueto thisgreaterrepresentationoftemporalconstraints
(theapproximateposteriorsateachtime-stepbeingnolongerassumedtobeindependent),theBethefree-energyhas
the potential to be significantly more accurate than the standard mean-field variational free energy (and is, in fact,
exactforfactorgraphswithoutcyclessuchasthestandardnon-hierarchicalPOMDPmodel). Inthispaper,wefocus
entirelyonthestandardmean-fieldvariationalfree-energyusedinthevastmajorityofactiveinferencepublications,
and thus the Bethe free-energyis out of scope for this paper. However, exploringthe nature of any intrinsic terms
whichmightarisefromtheBethefree-energyisaninterestingavenueforfuturework.Althoughprimarilyfocusedon
theBethefree-energy,(Schwöbeletal.,2018)alsointroduceda‘predictedfreeenergy’functional. Thisfunctionalis
equivalenttotheFEFaswehavedefinedithere,andsohasacomplexityinsteadofaninformationgainterm,leading
tominimizingtheprior-posteriordivergence.
Finally, (Biehletal., 2018) suggested that if the EFE is not mandated by the free-energyprinciple, which we have
argued for in this paper, then in theory any standard intrinsic measure, such as empowerment, could be used as an
objective. Webelievethatexploringtheeffectoftheseotherpotentiallossfunctionscouldbeaareaofgreatinterest
forfuturework.
25