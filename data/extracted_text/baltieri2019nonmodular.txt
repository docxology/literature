Nonmodular architectures of cognitive systems
based on active inference
Manuel Baltieri, Christopher L. Buckley
EASY group, Sussex Neuroscience - Department of Informatics
University of Sussex
Brighton, UK
m.baltieri@sussex.ac.uk, c.l.buckley@sussex.ac.uk
Abstract—Inpsychologyandneuroscienceitiscommontode- and action [5]–[7] respectively. In this context, the Kalman-
scribecognitivesystemsasinput/outputdeviceswhereperceptual Bucy filter is used as a model of perception [9], [11] while
and motor functions are implemented in a purely feedforward,
LQR (linear quadratic regulator) constitutes the basis of var-
open-loop fashion. On this view, perception and action are often
ious accounts of motor control [12], [13]. In previous work
seen as encapsulated modules with limited interaction between
them. While embodied and enactive approaches to cognitive [14] we claimed that the idea of modularity of action and
science have challenged the idealisation of the brain as an perception can be seen as an analogy of the separation prin-
input/outputdevice,wearguethateventhemorerecentattempts ciple in control theory [15]–[17]. According to this principle,
tomodelsystemsusingclosed-looparchitecturesstillheavilyrely
problems of estimation and control of a system can be solved
on a strong separation between motor and perceptual functions.
separatelyandtheirsolutionscanbeoptimallycombinedunder
Previously, we have suggested that the mainstream notion of
modularity strongly resonates with the separation principle of a set of assumptions. Following this, one can sequentially
control theory. In this work we present a minimal model of a combine a Kalman-Bucy filter and LQR to create the LQG
sensorimotor loop implementing an architecture based on the (linear quadratic Gaussian) architecture, used as a general
separation principle. We link this to popular formulations of
methodology for several models of sensorimotor loops, e.g.,
perception and action in the cognitive sciences, and show its
[6], [13], [18], [19]. The “classical sandwich” [3] of cognitive
limitations when, for instance, external forces are not modelled
by an agent. These forces can be seen as variables that an science thus survives, we claim, even in the forward/inverse
agent cannot directly control, i.e., a perturbation from the models formulation of perception and motor control.
environment or an interference caused by other agents. As an Thefieldsofembodiedandenactivecognitivescienceonthe
alternative approach inspired by embodied cognitive science, we other hand emphasise the deep integration of perception and
then propose a nonmodular architecture based on the active
action, seen as fundamentally intertwined [20]–[22]. In [14]
inference framework. We demonstrate the robustness of this
architecture to unknown external inputs and show that the we proposed to use a framework based on the formulation
mechanism with which this is achieved in linear models is of perception and action as estimation and control while not
equivalent to integral control. implementing the conditions for the separation principle, i.e.,
Index Terms—modularity, separation principle, active infer-
activeinference.Activeinferenceisaprocesstheorybasedon
ence, Bayesian inference, optimal control
the free energy principle [23] describing cognitive functions
(perception and action, but also learning and attention) as
I. INTRODUCTION
processesofminimisationofsensorysurprisal[23],[24].More
In cognitive science it is often assumed that agents can be precisely, since this quantity is not directly accessible by
describedasinput/outputsystems,anideabasedontraditional, an agent, it is thought that the variational free energy (an
computational accounts of cognition [1]–[3]. In these models, upper bound to sensory surprisal) is minimised in its place.
the emphasis is on internal models of the world, central In active inference, perceptual and motor processes are often
processing and the sense-model-plan-act framework, often described as entangled and inseparable [25]–[27] providing
neglecting embodiment, situatedness and feedback from the thus a new possible methodology combining estimation and
environment [4]. More recent attempts, e.g., [5]–[7], have control following embodied/enactive theories of the mind. We
proposed closed-loop descriptions of cognitive system using previously presented a conceptual account of active inference
internalforward/inversemodelsinanattempttoprovidebetter and its role for nonmodular architectures of cognitive systems
accounts of behaviour in living organisms. However in both [14]. Here we introduce a minimal agent model highlighting
theinput/outputandtheclosed-looparchitecturesadvocatedby the different implementations (LQG vs. active inference) es-
theseapproaches,theroleofperceptualandmotorprocessesis pecially in presence of unknown external stimuli affecting an
thought to be fundamentally modular [2], i.e., these functions agent’s observations.
can be described as nearly independent, (informationally)
encapsulated components with minimal interactions.
II. LQGANDTHESEPARATIONPRINCIPLE
In recent years, theories of estimation and control have The framework provided by LQG control and based on
become increasingly popular accounts of perception [8]–[10] the separation principle linearly combines two processes of 1)
9102
raM
22
]CN.oib-q[
1v24590.3091:viXra
estimationorinferenceofhiddenpropertiesoftheenvironment III. ACTIVEINFERENCE
and 2) control or regulations of variables of interest. The
Active inference is a process theory proposed to explain
estimation of hidden variables is based on the presence of
brain functioning and other functions of living systems based
a Kalman (for discrete time systems) or Kalman-Bucy (for
on Bayesian inference and optimal control theory [23], [24],
continuoustimesystems)filter,whilethecontrolofthedesired
[28]. In this section we establish its relations to the LQG
variables on LQR [15]–[17]. In particular, this combination is
architecture,startingbybuildinganactiveinferenceversionof
provably optimal according to a set of assumptions:
theregulationofalinearmultivariatesystem,andhighlighting
1) the estimator is implemented through a state-space differences, limitations and possible extensions proposed for
modelwhereonlylinearprocessdynamicsandobserva- the control problem. As with LQG control, we build an
tion laws describe the environment and its latent states estimator of the hidden states x. In this case however, we
2) uncertainty or noise in both dynamics and observations will give a variational account of the estimator in generalised
are represented by white, zero-mean Gaussian variables coordinates of motion that generalises the MLE/MAP deriva-
3) the properties of these random variables, in particular tion of Kalman-Bucy filters [29] using Variational Bayes with
their (co)variance matrices, are known a Laplace approximation [24], [30]. We start by defining a
4) the performance of the regulator can be evaluated using generative model for an agent capturing the dynamics of the
a quadratic cost function system to control and how these relate to observations and
5) alltheinputs/forcesappliedtotheagentareknown,e.g., represented in a generalised state-space form [24], [31]:
external disturbances and internal signals such as motor
actions. x(cid:48) =Aˆx(cid:48)+Bˆv+w y =Cˆx+z (4)
Following the separation principle, the LQG controller
wherethehatoverthematricessimplyrepresentsthefactthat
produces optimal estimation and optimal control for linear
the matrices used in the generative model don’t necessarily
systems, sequentially combining two separate sub-systems, a
mirrortheircounterpartsdescribingtheworlddynamics([32],
Kalman-Bucy filter and LQR, in an optimal (i.e., minimum-
[33]), as shown in our model later. The main difference with
variance)way[16],[17].TheKalman-Bucyfilterprovidesthe
respect to LQG however is that LQG explicitly mirrors (by
optimalstate-estimateofasignalandtheLQRcontrolleruses
construction in the linear case) the dynamics of the observed
such estimate (i.e., the mean) to implement the optimal deter-
system, thus including knowledge of inputs a. On the other
ministic controller: LQG control makes use of the estimated
hand, in active inference this vector is not explicitly modelled
mean and feeds it into an LQR controller.
byanagent,assumingthatsuchinformationisnotavailableto
A general linear system to be regulated in the presence of
a system, in accordance with evidence in motor neuroscience
noise on the observed state is described by:
suggesting the lack of knowledge of self-produced controls
(i.e., efference copy) [25], [34], [35]. It is in fact proposed
dx=Axdt+Badt+dw y =Cx+dz (1)
thatadeeperdualityofestimationandcontrolexistswhereby,
in the simplest case (i.e., a purely reflexive account), actions
where all the variables and parameters are the same as pre-
aresimplyresponsestothepresenceofpredictionerrorsatthe
viously defined for Kalman-Bucy filters and LQR. Using the
proprioceptive level, irrespectively of the cause of sensations
separation principle, it can then be shown that minimising the
(self-generated or external forces) [25], [33]. The vector v in
expected value of the cost-to-go is equivalent to minimising
the generative model encodes instead external or exogenous
the cost-to-go for the expected (estimated) state [17]
inputs in a state-space models context or, from a Bayesian
1 1 perspective, priors or “desired” outcomes generated by higher
c(x,a)=c(xˆ,a)= xˆTQxˆ+ aTRa (2)
2 2 layers in hierarchical (Bayesian) implementations [10], [31].
Inthislight,priorscanbeusedtoeffectivelybiastheestimator
where we replaced states x with their estimates xˆ, meaning
to“infer”desiredratherthanobservedstates,withacontroller
that the optimal control can be computed using only the
instantiating actions on the world to fulfil the “observed” (=
state estimate (i.e., the mean) xˆ rather than x. The combined
desired)statesofanagent.Variablesz,wmodeltherealnoise
problem of estimation and control in LQG terms is then
in the environment making, however, use of the definition of
implemented by the following system combining Kalman-
state space models in generalised coordinates of motion [30],
Bucy filter and LQR equations:
[31], where z,w are treated as analytical noise with non-zero
autocorrelation,generalisingthedefinitionofWienerprocesses
xˆ˙ =Axˆ+Ba+K(y−Cxˆ)
with Markov property.
a=−Lxˆ This state-space model can then be written down in a
K =PHT(Σ )−1 probabilistic form, mapping the measurements equation to a
z
L=R−1BTV likelihood P(y|xˆ) (no direct influence of inputs on observa-
tions), and a the dynamics to a prior P(xˆ,v) [24], [31], [32].
P˙ =Σ +AP +PAT −K(Σ )KT
w z ThetwomultivariateGaussianprobabilitiesdensitiescanthen
−V˙ =Q+ATV +VA−LTRL. (3) be combined and used in the general formulation of Laplace
encoded variational free energy defined in [24], [30] (without variable, variables are in a moving framework of reference
constants): where the minimisation is achieved for µ˙ = µ(cid:48) rather than
x x
(cid:12) µ˙ = 0. Action as expressed in (8) may appear similar to
F ≈−lnP(y,x,v)(cid:12) (5) x
(cid:12) the traditional LQR/LQG form, but is fundamentally different
x=µx,v=µv
since it depends explicitly on observations y rather than
the free energy for a generic linear multivariate system be-
estimated hidden states µ .
comes then: x
1 (cid:20)(cid:16) (cid:17)T (cid:16) (cid:17) IV. THEMODEL
F ≈ y−Cˆµ Π y−Cˆµ +
2 x z x Thedoubleintegratorisacanonicalexampleusedincontrol
(cid:16) (cid:17)T (cid:16) (cid:17) theory and represents one of the most fundamental problems
+ µ(cid:48) −Aˆµˆ −Bˆµ Π µ(cid:48) −Aˆµ −Bˆµ +
x x v w x x v inoptimalcontrol,modellingsingledegreeoffreedommotion
(cid:21) of different physical systems [37], [38]. In the case presented
(cid:12) (cid:12) (cid:12) (cid:12)
−ln(cid:12)Π z(cid:12)−ln(cid:12)Π w(cid:12)+(m+n)ln2π (6)
here,thiscouldbethoughtofasablockonfrictionlesssurface.
In motor neuroscience, this is the simplest model of single-
where we explicitly replaced x,v with their expectations
joint movement [39] and can, in some cases, be easily gener-
µ ,µ since under the Laplace assumption this represents
x v alised to multiple degrees of freedom [28]. The standard dou-
thebestestimateofx,v (i.e.,covariancesoftheapproximate,
ble integrator is usually described as a deterministic system.
variational density can be recovered analytically [24], [30]).
Thecontrolpolicyisthusdefinedusingafeedbacklawapplied
Variables m,n represent the length of vectors y and x
directly to the known dynamics, as the full state of the system
respectively. Expectations µ play the same role of estimates
x is measured with no uncertainty [37]. For the purposes of this
xˆ in LQG, we simply decided to use a notation consistent
work, where uncertainty and noise are crucial components,
with some of our previous work [24], [32], [36]. We also
we will introduce process and measurement noise into the
definedprecisionmatricesΠ ,Π astheinverseofcovariance
z w system,makingtheestimationofhiddenstatesnecessary.This
matrices Σ ,Σ and used |·| to define the determinant of
z w will then allow us to compare LQG and active inference in
a matrix. It is important to highlight that, in general, the
one of the simplest possible examples in the control theory
covariance matrices used in the generative model can be
literaturewithdirectapplicationstothestudyofmotorsystems
different from the ones used to describe the environment or
and behaviour 1. The double integrator is described by the
generative process [32], [33]. To simplify the already heavy
following state-space model:
notation we will however represent them in the same way.
The recognition dynamics, encoding perception and action x˙ =Ax+Ba+w y =Cx+z (9)
in a system minimising free energy [24], [30] and equivalent
where matrices A,B,C are defined as:
to estimation and control functions respectively, are imple-
(cid:20) (cid:21) (cid:20) (cid:21) (cid:20) (cid:21)
mentedinstandardactiveinferenceformulationsasagradient 0 1 0 0 1 0
A= B = C =
descentschememinimisingthefreeenergywithrespecttothe 0 0 0 1 0 1
variables µ for perception/estimation:
x and covariance matrices Σ ,Σ as:
z w
µ˙ =Dµ − ∂F =µ(cid:48) +CˆTΠ (cid:16) y−Cˆµ (cid:17) + (cid:20) exp(0) 0 (cid:21) (cid:20) 0 0 (cid:21)
x x ∂µ x x z x Σ z = 0 exp(0) Σ w = 0 exp(−1)
(cid:16) (cid:17)
+AˆTΠ µ(cid:48) −Aˆµ −Bˆµ
w x x v
A. The LQG solution to the double integrator
∂F (cid:16) (cid:17)
µ˙(cid:48) =Dµ(cid:48) − =µ(cid:48)(cid:48)−Π µ(cid:48) −Aˆµ −Bˆµ (7)
x x ∂µ(cid:48) x w x x v For LQG we implement (3) using the same matrices
x
A,B,C,Σ ,Σ specified above and furthermore define:
z w
and actions a for action/control, assuming only that actions
(cid:20) (cid:21) (cid:20) (cid:21)
have an effect on observations y [28]: 1 0 4 0
Q= R= (10)
0 1 0 4
∂F ∂F ∂y ∂yT (cid:16) (cid:17)
a˙ =− ∂a =− ∂y ∂a =− ∂a Π z y−Cˆµ x . (8) with no specific optimisation of these parameters since it is
beyond the scope of this work. For further analysis see for
The estimation expressed in (7) prescribes a generalisation of
instance[37]. AswecanseeinFig.2a,theblockiseffectively
Kalman-Bucy filters to trajectories with arbitrary embedding driven to the desired position x = 0 and velocity x(cid:48) = 0
orders where random variables are not treated as Markov
from a set of 5 randomly initialised conditions (position and
processes [30]. In (7), we also include an extra term Dµ
x velocity are sampled from zero-mean Gaussian distributions,
that represents the “mode of the motion” (also the mean
sd=300). In Fig. 2b we then show the actions over time of
for Gaussian variables) for the minimisation in generalised
the same 5 example agents, all converging to zero since the
coordinates of motion [24], [31], with D as a differential
agents effectively reach their desired target. The main feature
operator shifting the order of motion, i.e., Dµ =µ(cid:48) . More
x x of LQG, and from which active inference will depart, is the
intuitively, since we are now minimising the components of a
generalised state representing a trajectory rather than a static 1Thecodeisavailableathttps://github.com/mbaltieri/doubleIntegrator
Sliding block on a frictionless surface,
target: x = 0, x’ = 0
Force
applied
m =1kg
x= 0
Target
Fig. 1: The generative process, a double integrator. The
doubleintegratormodelsthemotionofasystemwithasingle
degree of freedom, corresponding to a block of mass=1kg
placedonasurfacewithnofriction.Theblockisinitialisedat (a)
a random position with a random velocity and needs to stop,
x(cid:48) =0, at position x=0.
100
75
reliability of estimates of both position and velocity (the red
line in the phase space), using a Kalman-Bucy filter. In LQG, 50
accurate estimates are necessary to then enact the LQR com- 25
ponent implementing a negative feedback mechanism based
0
on estimates xˆ rather than true hidden states x. In Fig. 3 we
introduced a new external force not modelled by the agents, 25
equivalenttoadisturbancefromtheenvironment(blacklinein
50
Fig. 3b). Fig. 3a then shows that the agents are incapable of
75
regulating their position/velocity against this unknown input
(blue lines), after an initial convergence towards the desired 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15
Time (s)
state, they in fact move away from it when the unexpected
force is introduced. Furthermore, these agents are incapable
of correctly inferring their trajectories, providing inaccurate
estimates of their sensed variables (red lines). In Fig. 3b we
see that all of these agents attempt to counteract the effects of
unexpectedstimuli(theyminimisetheirvelocityaftertheforce
is introduced), however the lack of an appropriate mechanism
to track their position correctly (e.g., integral action) pushes
them away from the target.
B. The double integrator with active inference
To solve the same control problem, active inference relies
on the generation of predictions of proprioceptive sensations
(position, velocity as in LQG, and also acceleration in this
case), followed by the implementation of actions in the world
via (trivial) reflex arcs. The proprioceptive modality is es-
sentially treated as other inputs (vision, audition, etc.) and
estimates/predictions are generated using the same generative
modeltakingadvantageofincomingproprioceptivesensations.
This produces a considerably different control system, with
state estimates and actions now created by the same model,
making it hard to clearly separate processes of perception
and action. The copy of motor control signals (cf. efference
copy [40]), necessary in standard LQG settings to meet the
observability constraints of Kalman-Bucy filters [16], [17] is
)2s/m(
a
,noitcA
Action of double integrator - LQG
Agent 1
Agent 2
Agent 3
Agent 4
Agent 5
(b)
Fig. 2: The double integrator solved using LQG. (a) Five
examples with different initial conditions showing in blue the
observed trajectories of different blocks in the phase-space
and in red the agent’s estimates of the same trajectories. (b)
Actions taken by the five agents.
not included in this formulation, as explained in section III.
Active inference postulates in fact that direct representations
ofthecausesoractionsaofself-generatedsensationsneednot
be discounted during the prediction of new incoming sensory
inputs. This could be seen as a limitation of active inference,
but in general this speaks to the robustness of this approach
in face of unknown inputs (i.e., motor actions produced by
an agent or exogenous forces from the environment), see
[36]. In this framework, inputs can also be estimated using
an appropriate generative model of the world dynamics [30],
a feature thought to be fundamental in biological systems
[41]. Simple and effective approximations are also possible,
for example with integral control, thought to be the most
basic heuristic dealing with the problem of uncertain inputs
in biological systems down to the unicellular level [41], [42]
andalreadyshowntobeconsistentwithformulationsofactive
Target
Trajectory
with ext. force
(a)
200
150
100
50
0
50
100
0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15
Time (s)
)2s/m(
a
,noitcA
Spring-mass-damper system
−α
1
x
m =1kg
−α
2
x′ 
x= 0
Fig.4:Thegenerativemodel.Toimplementtheregulationof
position and velocity, the agent implements a model whereby
animaginaryspringpullstheblockbacktotheorigin(x=0)
while an imaginary damper slows it down (x(cid:48) =0).
Action of double integrator - LQG, no external force in KBF
The agent implements beliefs of a world where it is pulled
Agent 1
Agent 2 back to the desired state x = x(cid:48) = 0 by an imaginary spring
Agent 3 and slows down thanks to an imaginary piston-like damper,
Agent 4
“designed” (in this case by us, but more in general one could Agent 5
Ext. force imagine evolutionary processes for biological system [28]) to
favour normative behaviour.
Following (6), the variational free energy for our controller
is then described by:
(cid:20)
1
F ≈ π (y−µ )2+π (y(cid:48)−µ(cid:48))2+π (y(cid:48)(cid:48)−µ(cid:48)(cid:48))2+
2 z x z(cid:48) x z(cid:48)(cid:48) x
(cid:21)
+π (µ(cid:48)(cid:48)−µ )2−ln(π π π π )+(3+2)ln2π
w(cid:48) x v z z(cid:48) z(cid:48)(cid:48) w(cid:48)
(b) (12)
Fig. 3: The double integrator solved using LQG. (a) Five where precisions π are taken from the diagonals of precision
examples with different initial conditions showing in blue the matricesΠ ,Π (inversecovariancesmatricesΣ ,Σ defined
z w z w
observed trajectories of different blocks in the phase-space in the generative model). After explicitly writing out the
and in red the agent’s estimates of the same trajectories. (b) equations derived from the matrix formulation in (7), we get
Actions taken by the five agents after an external force is the following formulation of perceptual inference:
introduced (black line).
µ˙ =µ(cid:48) +π (y−µ )+π (µ(cid:48) +αµ −βµ )
x x z x w x x v
µ˙(cid:48) =µ(cid:48)(cid:48)+π (y(cid:48)−µ(cid:48))+π (µ(cid:48)(cid:48)+αµ(cid:48) −βµ(cid:48))
x x z(cid:48) x w(cid:48) x x v
inference [36]. µ˙(cid:48)(cid:48) =µ(cid:48)(cid:48)(cid:48)+π (y(cid:48)(cid:48)−µ(cid:48)(cid:48))+π (µ(cid:48)(cid:48)+αµ(cid:48) −βµ(cid:48)) (13)
x x z(cid:48)(cid:48) x w(cid:48)(cid:48) x x v
Toderiveanactiveinferencesolutiontothedoubleintegra-
tor, we start by defining a generative model for the agent, i.e., and
the block:
µ˙(cid:48) =−π (µ(cid:48) +αµ −βµ )
x w x x v
x(cid:48) =Aˆx+Bˆv+w y =Cˆx+z (11) µ˙(cid:48)(cid:48) =−π (µ(cid:48)(cid:48)+αµ(cid:48) −βµ(cid:48)) (14)
x w(cid:48) x x v
where matrix Aˆ is: showing the lack of the Kalman gain K and an important
  difference derived from its absence: if K is non-diagonal as
0 1 0
Aˆ=−α
1
−α
2
0 in this case (one can simply verify this claim with standard
functions solving continuous Riccati equations, as in the
0 0 0
provided code), both orders of motion are present in the
whileBˆ isdiagonalwithexp(1)values,Cˆ iszeroeverywhere optimal filter problem in (3), but only one appears in (13)
but in C where the motor action is applied (with a value sincetheprecisionmatricesareassumedtobediagonalinour
2,2
of 1) and covariance matrices Σ ,Σ are also diagonal with, formulation. More in general, in active inference the Kalman
z w
respectively,exp(1)andexp(8)valuesonthemaindiagonals. gainK matrixisreplacedbylearningratessuchasinthiswork
or [32], or by clever implementations that allow for adaptive
update schemes with varying integration steps as in [30].
The action component is, however, the one most signif-
icantly different, starting from the assumption that direct
knowledge of motor signals is not available and thus not
modelled in the generative model (motor commands a are
replaced by inputs v acting as priors). This entails a new
approachtotheproblem,withactiveinferencesuggestingthat
the only information needed comes from observations y, see
(8). On this account, action reduces to
(cid:18) ∂y(cid:48)(cid:19)T
a˙ =− Π (y−Cˆµ ) (15) Target
∂a z x
and with the assumption that
∂y (cid:2) (cid:3)T
= 1 1 1
∂a (a)
the explicit, scalar version of action becomes
a˙ =−π (y−µ )−π (y(cid:48)−µ(cid:48))−π (y(cid:48)(cid:48)−µ(cid:48)(cid:48)), (16)
z x z(cid:48) x z(cid:48)(cid:48) x 500
replacing the LQR component in (3). This type of control
400
is equivalent to a PID controller, and is the “optimal” linear
300 solution when knowledge of inputs a is not available in the
generativemodel[36].Asinthecaseoffiltering,thefeedback 200
gain L is missing in the active inference formulation, once
100
again replaced by learning rates of the gradient descent or
0
by other approximations. In Fig. 5 we can see an example
implementationofthedoubleintegratorusingactiveinference. 100
Five agents are initialised at random position and velocity
200
(zero-mean Gaussian distributed, sd=300) and converge to
0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15
the target solution where the output actions are essentially Time (s)
zero (excluding some noise), as expected Fig. 5b. The most
striking feature is that estimates of both position and velocity
of the block are very inaccurate but the agent nonetheless
reaches the desired target in the phase space, Fig. 5a. These
differences are given by the generative implemented by the
agent,encodinganimaginaryspring-dampersystemthatpulls
it towards its desired state Fig. 4. Fig. 6 shows the robustness
of this implementation when an external force is introduced:
by implementing integral control [36], active inference can
in this case counteract the effects of unexpected inputs. The
presence of integral action perfectly counteracts the effects
of disturbances Fig. 6b (cf. Fig. 3b), and more importantly
allows for the desired regulation of the agents’ positions,
Fig.6a,whichisimpossibleinLQGaccountsassumingperfect
knowledge of the world (cf. Fig. 3a).
V. DISCUSSION
LQG-based architectures are modular in nature, with per-
ception and action seen as separate problems solved nearly
independently. According to this view, a system should ini-
tially find accurate estimates of the hidden properties of
its observations, and only once such estimates are available
should an agent attempt to regulate variables that are of
interest to achieve its goals, e.g., temperature, oxygen level,
etc.. On the other hand, we can define a framework based
)2s/m(
a
noitcA
Action of double integrator - Active inference
Agent 1
Agent 2
Agent 3
Agent 4
Agent 5
(b)
Fig. 5: The double integrator solved using active inference
(α = exp(2),α = exp(1)). Same layout as Fig. 2. (a)
1 2
Fiveexampleswithdifferentinitialconditionsshowinginblue
theobservedtrajectoriesofdifferentblocksinthephase-space
and in red the agent’s estimates of the same trajectories. (b)
Actions taken by the five agents.
on mathematical formulations of control problems where the
separation principle is not included or required. According to
one such proposal, that we identified in active inference [23],
[28], perception and action are combined in an inseparable
sensorimotorloopdescribedbytheminimisationofvariational
free energy for an agent. In this set up, action and perception
are seen as instances of a fundamentally unique process [20],
usingdifferentlabelsforour(i.e.,theobservers’)convenience.
In particular, the idea of precise inferences of world variables
is called into question [32], [43], to the point that inaccurate
perception is not only possible but becomes a pre-requisite
to act on the world [26], [33]. In architectures based on
the separation principle, the estimated state of a system is
thought of as a relevant account of real observations, e.g.,
theirmeansandcovariances.Conversely,inactiveinferenceit
Target
(a)
600
400
200
0
200
400
0 2 4 6 8 10 12 14
Time (s)
)2s/m(
a
noitcA
minimise, an agent becomes a simple mirror of its world with
no strong desire or even necessity to act [32], [33], [46].
In other words, depending on different precision weights an
agent can accurately estimate its observations without acting
or potentially discard its sensations to only pursue its desires,
generating all possible cases in between as a balanced mix of
weighted prediction errors [47].
VI. CONCLUSIONS
In recent years the more traditional understanding of per-
ceptualandmotorasnearlyindependentprocessesasbeenput
intodiscussionbydifferentauthors,especiallyinneuroscience
[48]–[50].Itisclearthatmanyexperimentalsetupsarelimited
[51], requiring new and ethologically meaningful paradigms
for an appropriate study of different aspects of living systems
[52]. In this context, we propose some new ideas that could
drive future experiments. These ideas are centred around a
criticalappraisalofLQGasamodelarchitectureforcognitive
Action of double integrator - Active inference
systems, focusing in particular on the assumptions made by
Agent 1 theuseofKalman-Bucyfilters,centraltotheseproposals[11],
Agent 2
[18], [53]. One of the key requirements for Kalman-Bucy
Agent 3
Agent 4 filterstogenerateanaccurateestimateofthehiddenstateofa
Agent 5 system is to have access to all the outputs (the observations)
Ext. force
andalltheinputs(forcesthataffectthestate)ofasystem.The
inputs, in particular, include both motor commands, which in
classical forward/inverse models are identified using the idea
of efference copy [40] (see for instance [5]–[7]), and external
forces/signalsfromtheenvironmentthatcannotbeinprinciple
accounted by an organism, i.e., a sudden change in weather
conditions or unexpected interactions with other agents.
In this work we focused on the latter, since the presence
of external unaccounted forces is often overlooked in many
(b)
experimentalset-upswithfixedorpredictableconditions(e.g.,
Fig. 6: The double integrator solved using active inference
the classic and still dominating two-alternative forced choice
(α = exp(2),α = exp(1)). Same layout as Fig. 2. (a)
1 2 paradigm). In more realistic and ethological scenarios, how-
Fiveexampleswithdifferentinitialconditionsshowinginblue
ever,oneshouldexpectthatexternalandunpredictablestimuli
theobservedtrajectoriesofdifferentblocksinthephase-space
constantly affect the behaviour of an agent [50]–[52]. In this
and in red the agent’s estimates of the same trajectories. (b)
case, introducing noise or varying experimental conditions
Actions taken by the five agents after an external force is
mayhelpintestingtherobustnessofLQG-basedarchitectures.
introduced (black line).
In practice, if some inputs are not known, one should expect
LQG to perform rather poorly until these inputs can be
estimated and adaptation (e.g., learning) to new conditions
becomes clear that estimates of latent variables of the world can take place. However, one should then explain how such
are deeply connected to the current goal of an agent, e.g., to forces can be described in LQG since Kalman-Bucy filters
regulate its observations, cf. [44]. To do so, its targets are cannot estimate inputs [29] (cf. DEM [30]). More in general,
encoded as prior expectations and used to bias inferential if a system is well adapted to deal with unpredictable stimuli,
processes toward its desires so that prediction errors are simple mechanisms such as integral control could be in place,
created as the mismatch of observations and the estimates of as shown formally in [41] and in experiments on chemotactic
hiddenvariables.Theseerrorsarethenminimisedbyactingon adaptation in E. Coli [42] for instance. More recently, some
the world [28], taking advantage of proprioceptive prediction promising results have been presented in [54], supporting
errors that enact reflex arcs to make observation better accord the idea that integral feedback control, unlike Kalman(-Bucy)
withexistingpredictions[26],[45].Moreingeneral,theactive filters, is a good model for adaptation in environments with
inference formulation allows also for accurate estimates of varying conditions. Integral control constitutes a linear ap-
the latent variables generating observations, see for instance proximation to problems of control with unknown forces
[30], but this modality fundamentally excludes the possibility affecting the observations of an agent [36], [38], providing a
of acting: if no prediction errors are generated for action to robust solution with fast responses to problems that otherwise
would require slower learning mechanisms [42], which may [27] G. Pezzulo, F. Donnarumma, P. Iodice, D. Maisto, and I. Stoianov,
be ineffective in fast-paced environments [55]. “Model-based approaches to active perception and control,” Entropy,
vol.19,no.6,p.266,2017.
VII. ACKNOWLEDGMENTS [28] K. J. Friston, J. Daunizeau, J. Kilner, and S. J. Kiebel, “Action and
behavior:Afree-energyformulation,”BiologicalCybernetics,vol.102,
This work was supported in part by a BBSRC Grant no.3,pp.227–260,2010.
[29] Z.Chen,“Bayesianfiltering:Fromkalmanfilterstoparticlefilters,and
BB/P022197/1.
beyond,”Statistics,vol.182,no.1,pp.1–69,2003.
[30] K.J.Friston,N.Trujillo-Barreto,andJ.Daunizeau,“DEM:Avariational
REFERENCES
treatmentofdynamicsystems,”NeuroImage,vol.41,no.3,pp.849–885,
[1] A.Newell,H.A.Simonetal.,Humanproblemsolving. Prentice-Hall 2008.
EnglewoodCliffs,NJ,1972,vol.104,no.9. [31] K. Friston, “Hierarchical models in the brain,” PLoS Computational
[2] J.Fodor,TheModularityofMind. MITPress,1983. Biology,vol.4,no.11,2008.
[3] S.Hurley,“Perceptionandaction:Alternativeviews,”Synthese,vol.129, [32] M.BaltieriandC.L.Buckley,“Anactiveinferenceimplementationof
no.1,pp.3–40,2001. phototaxis,”inProc.Eur.Conf.onArtificialLife,2017,pp.36–43.
[4] R.A.Brooks,“Newapproachestorobotics,”Science,vol.253,no.5025, [33] H. Brown, R. A. Adams, I. Parees, M. Edwards, and K. Friston, “Ac-
pp.1227–1232,1991. tiveinference,sensoryattenuationandillusions,”Cognitiveprocessing,
[5] M.Kawato,“Internalmodelsformotorcontrolandtrajectoryplanning,” vol.14,no.4,pp.411–427,2013.
Currentopinioninneurobiology,vol.9,no.6,pp.718–727,1999. [34] A.G.Feldman,“Newinsightsintoaction–perceptioncoupling,”Exper-
[6] D.M.WolpertandZ.Ghahramani,“Computationalprinciplesofmove- imentalBrainResearch,vol.194,no.1,pp.39–58,2009.
mentneuroscience,”Natureneuroscience,vol.3,no.11s,p.1212,2000. [35] ——,“Activesensingwithoutefferencecopy:referentcontrolofpercep-
[7] E. Todorov, “Optimality principles in sensorimotor control,” Nature tion,”Journalofneurophysiology,vol.116,no.3,pp.960–976,2016.
neuroscience,vol.7,no.9,pp.907–915,2004. [36] M. Baltieri and C. L. Buckley, “A probabilistic interpretation of pid
[8] D.C.KnillandW.Richards,PerceptionasBayesianinference. Cam- controllers using active inference,” in From Animals to Animats 15,
bridgeUniversityPress,1996. P.Manoonpong,J.C.Larsen,X.Xiong,J.Hallam,andJ.Triesch,Eds.
[9] R.P.RaoandD.H.Ballard,“Predictivecodinginthevisualcortex:a SpringerInternationalPublishing,2018,pp.15–26.
functionalinterpretationofsomeextra-classicalreceptive-fieldeffects,” [37] V.G.RaoandD.S.Bernstein,“Naivecontrolofthedoubleintegrator,”
Natureneuroscience,vol.2,no.1,pp.79–87,1999. IEEEControlSystems,vol.21,no.5,pp.86–97,2001.
[10] T.S.LeeandD.Mumford,“Hierarchicalbayesianinferenceinthevisual [38] K.J.A˚stro¨mandR.M.Murray,Feedbacksystems:anintroductionfor
cortex,”JOSAA,vol.20,no.7,pp.1434–1448,2003. scientistsandengineers. Princetonuniversitypress,2010.
[11] D. M. Wolpert, J. Diedrichsen, and J. R. Flanagan, “Principles of [39] G.L.Gottlieb,“Acomputationalmodelofthesimplestmotorprogram,”
sensorimotor learning,” Nature Reviews Neuroscience, vol. 12, no. 12, JournalofMotorbehavior,vol.25,no.3,pp.153–161,1993.
p.739,2011. [40] E. von Holst and H. Mittelstaedt, “Das reafferenzprinzip,” Naturwis-
[12] W. Li and E. Todorov, “Iterative linear quadratic regulator design for senschaften,vol.37,no.20,pp.464–476,1950.
nonlinearbiologicalmovementsystems.”inICINCO(1),2004,pp.222– [41] E.D.Sontag,“Adaptationandregulationwithsignaldetectionimplies
229. internalmodel,”Systems&controlletters,vol.50,no.2,pp.119–126,
[13] I.H.Stevenson,H.L.Fernandes,I.Vilares,K.Wei,andK.P.Ko¨rding, 2003.
“Bayesian integration and non-linear feedback control in a full-body [42] T.-M. Yi, Y. Huang, M. I. Simon, and J. Doyle, “Robust perfect
motortask,”PLoScomputationalbiology,vol.5,no.12,p.e1000629, adaptation in bacterial chemotaxis through integral feedback control,”
2009. Proceedings of the National Academy of Sciences, vol. 97, no. 9, pp.
[14] M. Baltieri and C. L. Buckley, “The modularity of action and percep- 4649–4653,2000.
tion revisited using control theory and active inference,” in The 2018 [43] A. Clark, “Radical predictive processing,” The Southern Journal of
ConferenceonArtificialLife:AHybridoftheEuropeanConferenceon Philosophy,vol.53,no.S1,pp.3–27,2015.
ArtificialLife(ECAL)andtheInternationalConferenceontheSynthesis [44] W. T. Powers, Behavior: The control of perception. Aldine Chicago,
and Simulation of Living Systems (ALIFE), T. Ikegami, N. Virgo, 1973.
O.Witkowski,M.Oka,R.Suzuki,andH.Iizuka,Eds.,2018,pp.121– [45] A. Clark, Surfing Uncertainty: Prediction, Action, and the Embodied
128. Mind. OxfordUniversityPress,2015.
[15] W. Wonham, “On the separation theorem of stochastic control,” SIAM [46] K.Friston,C.Thornton,andA.Clark,“Free-energyminimizationand
JournalonControl,vol.6,no.2,pp.312–326,1968. thedark-roomproblem,”Frontiersinpsychology,vol.3,p.130,2012.
[16] B. Anderson and J. B. Moore, Optimal control: linear quadratic [47] M.AllenandK.J.Friston,“Fromcognitivismtoautopoiesis:towards
methods. Prentice-Hall,Inc.,1990. acomputationalframeworkfortheembodiedmind,”Synthese,vol.195,
[17] R. F. Stengel, Optimal control and estimation. Courier Corporation, no.6,pp.2459–2482,2018.
1994. [48] E. Ahissar and E. Assa, “Perception as a closed-loop convergence
[18] E.TodorovandM.I.Jordan,“Optimalfeedbackcontrolasatheoryof process,”Elife,vol.5,p.e12830,2016.
motorcoordination,”Natureneuroscience,vol.5,no.11,p.1226,2002. [49] L.Busse,J.A.Cardin,M.E.Chiappe,M.M.Halassa,M.J.McGinley,
[19] S.-H.Yeo,D.W.Franklin,andD.M.Wolpert,“Whenoptimalfeedback T. Yamashita, and A. B. Saleem, “Sensation during active behaviors,”
control is not enough: Feedforward strategies are required for optimal JournalofNeuroscience,vol.37,no.45,pp.10826–10834,2017.
control with active sensing,” PLoS computational biology, vol. 12, [50] C. L. Buckley and T. Toyoizumi, “A theory of how active behavior
no.12,p.e1005190,2016. stabilises neural activity: Neural gain modulation by closed-loop envi-
[20] A. Clark, Being there: Putting brain, body, and world together again. ronmental feedback,” PLoS computational biology, vol. 14, no. 1, p.
MITpress,1998. e1005926,2018.
[21] M. Wilson, “Six views of embodied cognition,” Psychonomic bulletin [51] J. W. Krakauer, A. A. Ghazanfar, A. Gomez-Marin, M. A. MacIver,
&review,vol.9,no.4,pp.625–636,2002. andD.Poeppel,“Neuroscienceneedsbehavior:correctingareductionist
[22] E.DiPaolo,T.Buhrmann,andX.Barandiaran,SensorimotorLife:An bias,”Neuron,vol.93,no.3,pp.480–490,2017.
EnactiveProposal. OxfordUniversityPress,2017. [52] F. Najafi and A. K. Churchland, “Perceptual decision-making: A field
[23] K.Friston,“Thefree-energyprinciple:aunifiedbraintheory?”Nature inthemidstofatransformation,”Neuron,vol.100,no.2,pp.453–462,
reviews.Neuroscience,vol.11,no.2,pp.127–138,2010. 2018.
[24] C.L.Buckley,C.S.Kim,S.McGregor,andA.K.Seth,“Thefreeenergy [53] D. W. Franklin and D. M. Wolpert, “Computational mechanisms of
principleforactionandperception:Amathematicalreview,”Journalof sensorimotorcontrol,”Neuron,vol.72,no.3,pp.425–442,2011.
MathematicalPsychology,vol.14,pp.55–79,2017. [54] H. Ritz, M. R. Nassar, M. J. Frank, and A. Shenhav, “A control
[25] K. Friston, “What is optimal about motor control?” Neuron, vol. 72, theoreticmodelofadaptivelearningindynamicenvironments,”Journal
no.3,pp.488–498,2011.
ofcognitiveneuroscience,pp.1–17,2018.
[26] W.Wiese,“Actionisenabledbysystematicmisrepresentations,”Erken- [55] W. R. Ashby, An introduction to cybernetics. Chapman & Hall Ltd.,
ntnis,pp.1–20,2016. 1957.