arXiv:2506.21554v1  [q-bio.NC]  11 Jun 2025
Finding Similar Objects and Active Inference for Surprise
in Numenta Neocortex Model
Hajime Kawakami
Akita University, Akita, 010-8502, Japan
kawakami@math.akita-u.ac.jp, hjm.kwkm.07091210@gmail.com
June 11, 2025
Abstract
Jeff Hawkins and his colleagues in Numenta have proposed the thousand-brains system. This is
a model of the structure and operation of the neocortex and is under investigation as a new form
of artificial intelligence. In their study, learning and inference algorithms running on the system
are proposed, where the prediction is an important function. The author believes that one of
the most important capabilities of the neocortex in addition to prediction is the ability to make
association, that is, to find the relationships between objects. Similarity is an important example
of such relationships. In our study, algorithms that run on the thousand-brains system to find
similarities are proposed. Although the setting for these algorithms is restricted, the author
believes that the case it covers is fundamental. Karl Friston and his colleagues have studied the
free-energy principle that explains how the brain actively infers the cause of a Shannon surprise.
In our study, an algorithm is proposed for the thousand-brains system to make this inference.
The problem of inferring what is being observed from the sensory data is a type of inverse
problem, and the inference algorithms of the thousand-brains system and free-energy principle
solve this problem in a Bayesian manner. Our inference algorithms can also be interpreted as
Bayesian or non-Bayesian updating processes.
Keywords Neocortex ¬∑ Thousand Brains ¬∑ Similarity ¬∑ Active Inference ¬∑ Bayesian Inference ¬∑
non-Bayesian Inference ¬∑ Inverse Problem
1 Introduction
Conventionally, scientists state that the neocortex of the brain vertically comprises six layers.
Thus, the layers run parallel to the surface of the neocortex. The neocortex is horizontally
divided into several regions such as the visual and touch regions. For instance, the visual region
comprises several areas such as V1, V2, and V3. The neocortex, each region, and each area
comprise numerous cortical columns that penetrate the six layers. Numerous feedforward and
feedback connections exist between neurons in these cortical columns.
On pages 24 and 25 of [7], citing [15], Hawkins states:
Mountcastle is proposing that all the things we associate with intelligence, which on
the surface appear to be different, are, in reality, manifestations of the same under-
lying cortical algorithm. . . .So, what was Mountcastle‚Äôs proposal for the location of
the cortical algorithm ? He said that the fundamental unit of the neocortex, the unit
of intelligence, was a ‚Äúcortical column.‚Äù
1
However, Mountcastle did not propose any algorithm: how a cortical column does all the things
we associate with intelligence. Thus, Hawkins et al. in Numenta proposed such algorithms in [6],
[7], [9], [11], and [14]. We refer to these algorithms collectively as theNumenta (neocortex) model.
In these studies, prediction is considered as the most important capability of the neocortex,
and algorithms in the cortical columns for learning and inference, including prediction, have
been proposed (see Algorithms 3.1 and 3.2 described below). The cortical columns learn the
structure of objects using this learning algorithm, and infer the object under observation using
this inference algorithm with the sensory input. Hawkins named the system they created, which
included the Numenta model, the thousand-brains system. While writing this manuscript, the
paper [1] by Hawkins et al. was published. In this paper, Monty, the first instantiation of
the thousand-brains system, is proposed. Our study is based primarily on [9] and [14], which
explicitly describe the Numenta model algorithms, and it also refers to [1].
What are the other important capabilities of the neocortex in addition to prediction ? Section
2.4 of [1] lists the expected functions of a model of the neocortex. Related to this list, the
author believes that one of the important capabilities is making ‚Äúassociation,‚Äù that is, finding
the relationships between objects. Similarity between objects is an important example of such
relationships. The importance of ‚Äúassociation‚Äù has been highlighted by numerous scientists. For
instance, Polya [20] states the following on the list entitled ‚ÄúHow to Solve it‚Äù:
Find the connection between the data and the unknown.
and
Have you seen it before ? Or have you seen the same problem in a slightly different
form ?
P. A. M. Dirac states that:
With the mathematical procedure there are two main methods that one may follow,
(i) to remove inconsistencies and (ii) to unite theories that were previously disjoint.
on page 58 of [19]. Hawkins emphasizes the importance of similarities with respect to Mount-
castle‚Äôs idea (see Chapter 3 of [6] and Chapter 2 of [7]). He also states that:
When mathematicians see a new equation, they recognize it as similar to previous
equations they have worked with.
on page 82 of [7]. In this study, we propose algorithms (Algorithms 4.1 and 4.2) that run on
the Numenta model to find similarities. These algorithms are based on the Numenta inference
algorithm (Algorithm 3.2). The setting for these algorithms is restricted, and for more general
‚Äúassociations,‚Äù this setting is significantly limited. However, the author believes that the case
it covers is fundamental.
Friston et al. have studied the free-energy principle, for instance, [4], [5], and [18]. The free-
energy principle explains how the brain infers the cause for a Shannon surprise (informational
surprise). In our study, an algorithm (Algorithm 5.1) based on Algorithm 3.2 is proposed for the
Numenta model to obtain this inference. A relationship between the thousand-brains system
and free-energy principle has been investigated in studies such as [22]. Friston‚Äôs theory is based
on probability theory, specifically the Bayesian inference theory. Inference in the Numenta
model is refined by reducing the ambiguity based on successive observations. Therefore, this
inference can be considered to be Bayesian. The problem of inferring what is being observed
from the sensory data is a type of inverse problem, and the inference algorithms of the Numenta
model and free-energy principle solve this problem in a Bayesian manner. We also consider our
inference algorithms from the perspective of Bayesian inference.
2
The remainder of this manuscript is organized as follows: In ¬ß2 and ¬ß3, the Numenta neocor-
tex model and learning and inference algorithms (Algorithms 3.1 and 3.2) are reviewed. However,
these algorithms are slightly changed, primarily for simplicity. In ¬ß4 and ¬ß5, by slightly chang-
ing the Numenta inference algorithm, algorithms to find objects that are similar to a given
object (Algorithms 4.1 and 4.2) and an algorithm to actively infers surprise (Algorithm 5.1) are
proposed.
Although the proposed algorithms of this study are limited and are not based on brain
experimental results, the author hopes that they will contribute to future studies on the brain
or artificial intelligence. Real systems almost always encounter errors, and in the following,
the equations contain few of such errors, unless otherwise noted. It is believed that not only
neurons but also glial cells are important for the transmission of information in the brain (cf.
[3]). However, only neurons are considered in the Numenta model and this study.
2 Object, observation, learning, inference, and recognition
The Numenta model learns, infers, and recognizes objects. Figure 2.1 (A) shows an example of
such an object (see Figure 2 of [9] and Figure 5 of [14]). This object O comprises ten pairs of
locations and features, (location, feature), where ‚ãÜ, 2, and ‚ó¶ are the features. (Several cases of
more general objects are considered in [1]. In ¬ß3.1 of [1], it is stated that ‚Äú an object is a discrete
entity composed of a collection of one or more other objects .‚Äù Habitat objects, YCB object
dataset, and other datasets are listed in ¬ß6 as objects for simulation.) In the Numenta model,
time t is a discrete variable, t = 0, 1, 2, . . . ,and each cortical column of the model observes and
senses one pair of (location, feature) at each time step. Figure 2.1 (B) illustrates an example of
an observation of O. The first observation location is the starting point of the red arrow, and
the sensory feature is ‚ãÜ at this location. The next observation location is the end point of the
arrow, and the sensory feature is 2 at this location. Such an arrow is called a movement vector
in [9] and [14]. Thus, a cortical column of the Numenta model learns O by observing and sensing
pairs (location, feature) individually (by Algorithm 3.1).
Figure 2.1: An object and a movement vector
(A) (B)
‚ãÜ ‚ó¶
2 ‚ó¶ ‚ó¶
‚ãÜ 2 2 ‚ãÜ
‚ãÜ
‚ãÜ ‚ó¶
2 ‚ó¶ ‚ó¶
‚ãÜ 2 2 ‚ãÜ
‚ãÜ



 
O O
As described below, the inference is also performed by observing and sensing pairs (location,
feature) individually (by Algorithm 3.2). Assume that the model has already learned objects
O, O‚Ä≤, and O‚Ä≤‚Ä≤ of Figure 2.2, and then begins observing and inferring object O. In Figure 2.3
(A), the red arrow represents the first real movement vector. Then, both the first and second
sensory features are ‚ó¶, and this movement can not be distinguished from the other movements
3
Figure 2.2: Example of objects
‚ãÜ ‚ó¶
2 ‚ó¶ ‚ó¶
‚ãÜ 2 2 ‚ãÜ
‚ãÜ
2
‚ó¶ 2 2
‚ãÜ ‚ó¶ ‚ó¶ ‚ãÜ
‚ãÜ
‚Ä¢ ‚ó¶
2 ‚ó¶ 2
‚Ä¢ ‚ó¶ 2 ‚Ä¢
‚Ä¢
O O ‚Ä≤ O‚Ä≤‚Ä≤
Figure 2.3: Convergence onto a representation for O
(A)
‚ãÜ ‚ó¶
2 ‚ó¶ ‚ó¶
‚ãÜ 2 2 ‚ãÜ
‚ãÜ
-
?
6
2
‚ó¶ 2 2
‚ãÜ ‚ó¶ ‚ó¶ ‚ãÜ
‚ãÜ
-
?
6
‚Ä¢ ‚ó¶
2 ‚ó¶ 2
‚Ä¢ ‚ó¶ 2 ‚Ä¢
‚Ä¢
O O ‚Ä≤ O‚Ä≤‚Ä≤
?
6
(B)
‚ãÜ ‚ó¶
2 ‚ó¶ ‚ó¶
‚ãÜ 2 2 ‚ãÜ
‚ãÜ
-
6
2
‚ó¶ 2 2
‚ãÜ ‚ó¶ ‚ó¶ ‚ãÜ
‚ãÜ
6

‚Ä¢ ‚ó¶
2 ‚ó¶ 2
‚Ä¢ ‚ó¶ 2 ‚Ä¢
‚Ä¢
O O ‚Ä≤ O‚Ä≤‚Ä≤
(C)
‚ãÜ ‚ó¶
2 ‚ó¶ ‚ó¶
‚ãÜ 2 2 ‚ãÜ
‚ãÜ
-
6

2
‚ó¶ 2 2
‚ãÜ ‚ó¶ ‚ó¶ ‚ãÜ
‚ãÜ
‚Ä¢ ‚ó¶
2 ‚ó¶ 2
‚Ä¢ ‚ó¶ 2 ‚Ä¢
‚Ä¢
O O ‚Ä≤ O‚Ä≤‚Ä≤
4
represented by the blue vectors on O, O‚Ä≤, and O‚Ä≤‚Ä≤. Therefore, the model can not identify the
object that it has observed. In Figure 2.3 (B), the red arrows represent the first and second
real movement vectors. Then, these movements can not be distinguished from the movements
represented by the blue vectors on O‚Ä≤. Therefore, although the model is aware that it did not
observe O‚Ä≤‚Ä≤, it is unaware whether it has observed object O or O‚Ä≤. In Figure 2.3 (C), the red
arrows represent the first, second, and third real movement vectors. Then, the model is aware
that it has observed O, that is, it recognizes O. When this is the case, it is said that the
inference has converged onto a representation for the object O. The convergence property has
been investigated in detail in [9] and [14].
The inference by the Numenta model converges to an object, as the ambiguity regarding the
object under observation decreases. The problem of inferring an object using observed data is
an inverse problem. One of the well-known methods for solving inverse problems is successive
approximation such as gradient descent. By contrast, the inference of the Numenta model can
be considered as a Bayesian updating inference (see ¬ß5).
3 Numenta model of the neocortex
This section reviews the Numenta model of the structure of neocortex and learning and inference
algorithms operating on the neocortex, based on [9] and [14]. However, it is slightly changed,
mainly for simplicity (see Remarks 3.1 and 3.3). The neocortex comprises numerous cortical
columns that are stacked vertically next to each other. All the cortical columns have the same
structure and Figure 3.1 shows one of the cortical columns. Although each cortical column is
said to comprise six horizontal layers, the cortical column of Figure 3.1 comprises the following
three layers: the output, sensory, and location layers corresponding to layers 2/3, 4, and 6a,
respectively. The sensory layer is also called the input layer in [9]. The model depicted in Figure
3.1 is obtained by combining the models in [9] and [14]. The model in [9] comprises only the
output and sensory layers, and that in [14] comprises only the sensory and location layers. The
model of Figure 3.1 also corresponds to the learning module in [1] (see Figure 3 in [1]).
Each blue bullet in Figure 3.1 is an hierarchical temporal memory (HTM) neuron (see [8] and
[16]). HTM neurons are also called cells. Each cell can be in one of the following three states:
active, predictive, or inactive. The location layer comprises several grid cell modules, and each
module comprises several cells arranged in a triangular lattice. In Figure 3.1, only one module
is depicted. The number of modules in the location layer of each cortical column is denoted by
Nloc and the number of cells in each module by Mloc. In some simulations run in [14], Nloc = 10
and Mloc = 30 √ó 30 ‚Äì 40 √ó 40. The sensory layer comprises several mini-columns, and each
mini-column comprises several cells arranged in a line. In Figure 3.1, only one mini-column is
depicted. The number of mini-columns in the sensory layer of each cortical column is denoted
by Nin and the number of cells in each mini-column by Min. In the simulations run in [9] and
[14], Nin = 150 and Min = 16. The output layer has no internal structure such as modules or
mini-columns. In Figure 3.1, only seven cells are depicted. The number of cells in the output
layer of each cortical column is denoted by Nout. In the simulations run in [9], Nout = 4096.
The Numenta model is a discrete time model. The arrows in Figure 3.1 represents the flow
of information between the cells. In the inference, the one cycle of the ordered flow is ‚Éù1 ‚Üí ‚Éù2
‚Üí ‚Éù3 ‚Üí ‚Éù5 ‚Üí ‚Éù6 ‚Üí ‚Éù7 ‚Üí ‚Éù4 ‚Üí ‚Éù1 . In the model proposed by [14], it is ‚Éù1 ‚Üí ‚Éù2 ‚Üí ‚Éù3 ‚Üí ‚Éù4 ‚Üí
‚Éù1 , and in the model proposed by [9], it is ‚Éù2 ‚Üí ‚Éù3 ‚Üí ‚Éù5 ‚Üí ‚Éù6 ‚Üí ‚Éù7 ‚Üí ‚Éù2 . These two flows are
sub-flows of the flow shown in Figure 3.1. The information flows in learning are similar to the
above. Steps ‚Éù1 to ‚Éù4 correspond to the stages 1 to 4 in [14]. Arrow ‚Éù1 is called the motor input
in [14], and ‚Éù3 is called the sensory input in [9] and [14]. These inputs originate from outside
5
the cortical column, and the motor input is either conscious or unconscious. Arrow ‚Éù6 shows the
internal flow of the output layer of a cortical column and the flow between the output layers of
cortical columns. Figure 3.2 illustrates three cortical columns. Different cortical columns may
receive the same type of sensory inputs, and they may also receive different types of sensory
inputs, such as shape and color in vision. Therefore, the Numenta model can handle multimodal
sensory inputs.
Figure 3.1: Numenta cortical column
location
layer
sensory
layer
(input
layer)
output
layer
‚Ä¢
‚Ä¢
‚Ä¢
‚Ä¢
‚Ä¢
‚Ä¢
‚Ä¢
‚Ä¢
‚Ä¢
‚Ä¢
‚Ä¢
‚Ä¢
‚Ä¢
‚Ä¢
‚Ä¢
mini-column
@
 
@
 
@  
@ 
‚Éù1
‚Éù3
‚Éù2 ‚Éù4
Din
c,d
Dloc
Œ≥,d
Win
t
fijk
fijk
Dout
k,d Dout
k,d
‚Ä¢ ‚Ä¢ ‚Ä¢ ‚Ä¢
‚Ä¢ ‚Ä¢ ‚Ä¢ ‚Ä¢
‚Ä¢ ‚Ä¢ ‚Ä¢ ‚Ä¢
‚Ä¢ ‚Ä¢ ‚Ä¢ ‚Ä¢
module
@
 
‚Éù6 
@
@
 
‚Éù6 
@
@ 
 @
‚Éù5
‚Éù7
Let v be a vector or tensor. If each component of v is either 0 or 1, we refer to v as a binary
vector or tensor. For a binary vector or tensor v, the number of 1s in the components of v is
denoted by ‚ôÆv. The inner product of vectors u and v of the same dimension is denoted by u ‚Ä¢ v.
Let Nc be the number of the considered cortical columns. We assume that the values of Nloc,
Mloc, Nin, Min, and Nout are equal for all considered cortical columns. Let Din
c,d, Dloc
Œ≥,d, and
Dout
k,d be binary vectors, and F = (fijk) a binary tensor, where
dim Din
c,d = NlocMloc, dim Dloc
Œ≥,d = NinMin, dim Dout
k,d = NcNout, dim F = NinMinNout.
6
Vector Din
c,d represents a dendritic segment d of a cell c in the sensory layer, Dloc
Œ≥,d represents a
dendritic segment d of a cell Œ≥ in the location layer, Dout
k,d represents a dendritic segment d of a
cell k in the output layer, and fijk represents the pair of a cell j in mini-column i of the sensory
layer and a cell k in the output layer. The components of Din
c,d correspond to all the cells in
the location layer of the cortical column containing c, those of Dloc
Œ≥,d correspond to all the cells
in the sensory layer of the cortical column containing Œ≥, and those of F correspond to all the
pairs of the cells in the sensory and output layers in the same cortical column. The components
of Dout
k,d correspond to all the cells in the output layers of all considered cortical columns. Each
component of Din
c,d, Dloc
Œ≥,d, Dout
k,d , and F represents the connections between specified cells; for
instance, if and only if a component of Din
c,d is 1, a connection exists between the cell in the
location layer represented by this component and the segment d of cell c. All the capabilities of
the Numenta model are realized by these connections.
Figure 3.2: Numenta cortical columns
- - -
- - -
6 ? 6 ? 6 ?
6 ? 6 ? 6 ?
- - - -
   
??
In ¬ß3.1 and ¬ß3.2, we consider learning and inference/recognition algorithms for objects. Fig-
ure 2.1 shows an example of such an object. This object O comprises ten pairs of (location,
feature). When a cortical column observes or recalls O, the location is specified by active cells
in the location layer, and the feature is specified by active cells in the sensory layer. Each
module in the location layer acts as a reference frame (or coordinate frame) of the locations
on the object under consideration. This is emphasized in [7] and [14]. According to [7] and
[14], the information flow in the model proposed by [14] is fundamentally sufficient for learning,
inferring, and recognizing any (simple) object. If an object is complex to be recognized by only
one cortical column, the connections ‚Éù6 between the output layers of the cortical columns assist
in recognizing this object. According to [1], each learning module can recognize objects, and
multiple learning modules can recognize more complex objects at a faster rate through voting
and a hierarchical structure.
Algorithm 3.1 is a learning algorithm and Algorithm 3.2 is an inference algorithm, based
on [9] and [14]. In the author‚Äôs opinion, some steps omitted in the algorithms of [9] and [14]
are added to Algorithms 3.1 and 3.2, and some steps are changed, mainly for simplicity. In
7
Algorithms 3.1 and 3.2, Aloc
t and Ain
t are binary vectors such that
dim Aloc
t = NlocMloc, dim Ain
t = NinMin,
and the components of Aloc
t and Ain
t correspond to the cells in the location and sensory layers
of the considered cortical column at time t, respectively. If and only if a component of Aloc
t or
Ain
t is 1, the corresponding cell is active. In the following, Aloc
t and Ain
t are identified with the
sets of all cells in the location and sensory layers, respectively. When a location on an object is
observed, the feature f at this location provides a sensory input to the sensory layer, some mini-
columns in the sensory layer are selected, and some cells in these mini-columns are activated.
The set of such selected mini-columns is denoted by Win(f). Note that Win(f) is sparse, that
is, ‚ôØWin(f) is significantly lower than Nin, where ‚ôØS for a set S is the number of elements of
S. In [16], Win(f) is called the sparse distributed representation (SDR) of f. In Algorithms 3.1
and 3.2, Win(f) at time t is denoted by Win
t = Win
t (f).
3.1 Learning
Algorithm 3.1 is a learning algorithm obtained by combining such algorithms of [9] and [14].
Algorithm 3.1 learns an object O by observing and sensing pairs (location, feature) on O indi-
vidually.
Algorithm 3.1 (Numenta learning algorithm)
This algorithm runs on each cortical column. In this algorithm, steps 6 to 12 are repeated
from the second round onwards. If œÄin
c,t = 0 for every c in (3.4), steps 11 and 12 are the same
as step 5. The positive constant Œ∏in
b in (3.4) is a threshold. The symbol ‚Äú |‚Äù in (3.1), (3.2), and
(3.3) is designated as bitwise OR.
1. Set Din
c,d = 0 for every ( c, d), Dloc
Œ≥,d = 0 for every ( Œ≥, d), Dout
k,d = 0 for every ( k, d), and
fijk = 0 for every (i, j, k).
2. For the object O, select a binary vector Aout
O of dimension Nout at random, that is, the
values of the components of Aout
O are determined at random. However, Aout
O must be
sparse, that is, ‚ôÆAout
O must be much less than dim Aout
O . This Aout
O is fixed throughout
this algorithm. Denote by A
out
O the NcNout dimensional vector obtained by concatenating
Aout
O s of all considered cortical columns.
The components of Aout
O correspond to all cells of the output layer. If and only if a
component of Aout
O is 1, the corresponding cell is active. In the following, Aout
O is identified
with the set of all cells in the output layer.
3. For every active cell k ‚àà Aout
O , select a dendritic segment d of k at random and set Dout
k,d =
A
out
O . Vector Dout
k,d is fixed throughout this algorithm.
4. Set t = 0 and start observing O. From each module i in the location layer, randomly select
one cell and make it active. Thus, the initial value of the vector of Aloc
t is set.
The active cell in module i at time t represents a position vector ‚Éóœïi,t in the reference frame
given by module i. The set of vectors Œ¶t :=
n
‚Éóœïi,t
o
corresponds to the current observation
location on O.
8
5. This step is stage ‚Éù3 in Figure 3.1. Sense the feature of O at the location in step 4. For the
sensory input from the feature, select a set of mini-columns Win
t of the sensory layer as
follows. If the input has been observed in a previous learning, let Win
t be the mini-columns
selected then. If not, randomly select Win
t such that ‚ôØWin
t ‚â™ Nin. Select one cell from
each mini-column of Win
t at random and make this cell active. Thus, the initial value of
the vector of Ain
t is set.
6. This step is stage ‚Éù2 . For every active cell c in the sensory layer, select a dendritic segment
d of c at random. It is fixed throughout this algorithm. For every such pair ( c, d), update
Din
c,d by
Din
c,d := Din
c,d
Aloc
t . (3.1)
This is equation (9) of [14].
7. This step is stages ‚Éù5 and ‚Éù7 . For every active cell k ‚àà Aout
O , randomly select some active
cells {cij} in the sensory layer such that ‚ôØ{cij} < ‚ôØWin
t . Set Œ≥ijk = 1 and update fijk by
fijk := fijk |Œ≥ijk . (3.2)
8. This step is stage ‚Éù4 . For every active cellŒ≥ in the location layer, select a dendritic segment
d of Œ≥ at random. It is fixed throughout this algorithm. For every such pair ( Œ≥, d), update
Dloc
Œ≥,d by
Dloc
Œ≥,d := Dloc
Œ≥,d
Ain
t . (3.3)
This is equation (8) of [14].
9. If the observation of O is finished, stop this algorithm. Otherwise, set t := t + 1 and go to
the next step.
10. This step is stage ‚Éù1 . Change the observation location on O by motor input. This motor
input is represented by a vector ‚ÉóŒ¥i,t in each module i of the location layer, and we obtain
Œ¶t =
n
‚Éóœïi,t := ‚Éóœïi,t‚àí1 + ‚ÉóŒ¥i,t
o
,
where the addition ‚Éóœïi,t‚àí1 + ‚ÉóŒ¥i,t is considered on the torus made from the lattice of module
i. Make all cells in Œ¶ t active and the other cells inactive. Thus, Aloc
t is updated.
The active cell in module i represents a position vector ‚Éóœïi,t. The set Œ¶t corresponds to the
current observation location on O.
Not only a vector that represents a movement on an object, such as the red arrow in Figure
2.1, but also a vector in the location layer that represents a motor input, such as ‚ÉóŒ¥i,t, is
also called a movement vector.
11. This step is stage ‚Éù2 . For every cell c in the sensory layer, calculate
œÄin
c,t :=
(
1 ‚àÉd : Din
c,d ‚Ä¢ Aloc
t ‚â• Œ∏in
b
0 otherwise .
(3.4)
If and only if œÄin
c,t = 1, the cell c is predictive. If the current location is a location that has
not been visited before, then œÄin
c,t = 0 for almost all cells c.
9
12. This step is stage ‚Éù3 . Sense the feature of O at the location in step 10, get sensory input,
and select Win
t as in step 5. For every cell c = (ij) in the sensory layer (the j-th cell in
the i-th mini-column), calculate the activity of c:
ain
ij,t :=
Ô£±
Ô£¥Ô£≤
Ô£¥Ô£≥
1 if i ‚àà Win
t and œÄin
ij,t = 1
‚àó if i ‚àà Win
t and ‚àÄk ‚àà mini-column i, œÄin
ik,t = 0
0 otherwise ,
where ‚àó = 1 for only one cell j that is randomly selected from the i-th mini-column and
‚àó = 0 for the other every cell j. If and only if ain
ij,t = 1, the cell c = (ij) is active. Thus,
Ain
t is updated. Then, go back to step 6.
Remark 3.1 Compared with the learning algorithms in [9] and [14], Algorithm 3.1 is simpli-
fied as follows:
‚Ä¢ In the learning algorithm of [9], the synaptic permanence values are used for Din
c,d, Dout
k,d ,
and fijk based on Hebbian-style adaptation (see (6), (7), and (8) in [9]). In contrast,
in the learning algorithm of [14], they are not used for Din
c,d and Dloc
Œ≥,d as shown in (3.1)
and (3.3), respectively. For simplicity, Algorithm 3.1 does not use synaptic permanence
values for Din
c,d, Dout
k,d , and fijk either. In particular, learning Dout
k,d is performed only once,
at step 3. Note that, on page 5 in [9], the following is stated: ‚Äú The output layer learns
representations corresponding to objects. When the network first encounters a new object,
a sparse set of cells in the output layer is selected to represent the new object. These cells
remain active while the system senses the object at different locations. ‚Äù Based on this, we
maintain Aout
O fixed throughout learning.
‚Ä¢ In [14], the activity in the location layer is considered for not a cell but a bump of cells,
and the structure of the reference frame and the lengths and angles of movement vectors
are precisely defined. In the present study, the activity is considered only for a cell and
movement vector ‚ÉóŒ¥i,t is used for simplicity. The important ideas of the modules acting as
reference frames are explained in [7], [11], [13], and [14].
Remark 3.2 We make some remarks regarding Algorithm 3.1.
‚Ä¢ The Numenta model can handle multimodal information through connections between
cortical columns via {Dout
k,d }. Connections {Dout
k,d } and {fijk} realize associative memory.
‚Ä¢ For an object O, vector Aout
O is an SDR of O. Therefore, if O and O‚Ä≤ are different objects,
Aout
O ‚Ä¢ Aout
O‚Ä≤ is expected to be approximately zero. Additionally, learning a new object is
expected not to result in catastrophic forgetting.
‚Ä¢ In [9], ‚ôÆAout
O in step 2 typically satisfies 40 ‚â§ ‚ôÆAout
O ‚â™ dim Aout
O = 4096. In [9] and [10],
‚ôØWin
t in steps 5 and 12 and ‚ôØ{cij} in step 7 are constants throughout learning, and their
typical values are 10 = ‚ôØWin
t ‚â™ Nin = 150 and ‚ôØ{cij} = 5 ‚Äì 8 . In the present study, the
values of ‚ôÆAout
O , ‚ôØWin
t , and ‚ôØ{cij} are assumed to be equal for all objects, features, and
times.
‚Ä¢ In Algorithm 3.1, overlaps of the learned cells corresponding to different objects probably
exist because of random selections. In real learning, some noises that interfere with it
probably exist. See [9], [10], and [14] for the capacity for representing locations and
features, and noise robustness.
10
Figure 3.3: Learned connections between cells
location
layer
Win
t in
sensory
layer
Aout
O in
output
layer
‚Ä¢ ‚Ä¢ ‚Ä¢ ‚Ä¢ ‚Ä¢ ‚Ä¢ ‚Ä¢ ‚Ä¢
‚Ä¢ ‚Ä¢ ‚Ä¢ ‚Ä¢ ‚Ä¢ ‚Ä¢ ‚Ä¢ ‚Ä¢ ‚Ä¢ ‚Ä¢
‚Ä¢ ‚Ä¢ ‚Ä¢ ‚Ä¢
‚Ä¢ ‚Ä¢ ‚Ä¢ ‚Ä¢ ‚Ä¢
J
J
JJ





¬∑¬∑¬∑¬∑¬∑¬∑
totally connected
totally connected
totally connected











 
A
A
A
A
A
A
B
B
B
B
B
B B
A
A
A
A
A
A





 












 











B
B
B
B
B
B
B
B
B
B
BB
randomly selected
A
A
A
A
A
A
AA
B
B
B
B
B
B
BB














‚áë
‚áë
‚áì
‚áì
=‚áí
‚áê=
1
2
3
6
5
4
An example of the connections between cells obtained using the learning algorithm 3.1 is
illustrated in Figure 3.3. The figures of two cortical columns in Figure 3.3 represent the same
cortical column: on the left, information flows upwards, whereas on the right, information flows
downwards. In 1 and 6 , the four rectangles represent the modules, and the four red points
represent the cells corresponding to a location. The five rectangles in 2 and 5 represent the
mini-columns in Win
t for the feature sensed at the location of 1 and 6 . The five red points
represent the cells selected from each mini-column in Win
t . For each cell in Aout
O , three cells were
randomly selected from five active cells in Win
t . Algorithm 3.1 creates total connections between
all the cells representing the current location and all the cells representing the corresponding
feature. This algorithm also creates connections between all the cells in the output layer that
represent the same object. However, these connections are not required to be total connections
11
and probabilistic connections are also possible.
3.2 Inference, prediction and recognition
Algorithm 3.2 is an inference algorithm for objects learned by Algorithm 3.1. It is obtained
by combining such algorithms of [9] and [14]. Algorithm 3.2 makes inference by observing and
sensing pairs (location, feature) on an object O individually, in the same manner as in Algorithm
3.1. (In ¬ß2.2 of [1], it is stated that ‚Äúthere is no clear distinction between learning and inference.‚Äù)
Let Aout
t be an Nout-dimensional binary vector such that the components of Aout
t correspond to
the cells of the output layer at time t. If and only if a component of Aout
t is 1, the corresponding
cell is active. In the following, Aout
t is identified as the set of all cells in the output layer. The
NcNout-dimensional vector obtained by concatenating Aout
t s of all considered cortical columns
is denoted by A
out
t .
Algorithm 3.2 (Numenta inference algorithm)
O is an object learned by Algorithm 3.1. It is assumed that this object is observed in this
algorithm. This algorithm runs on each cortical column. The positive constants Œ∏out
p , Œ∏out
b , Œ∏in
p ,
Œ∏in
b , and Œ∏loc are thresholds. In this algorithm, steps 8 to 15 are repeated from the second round
onwards.
1. Set t = 0, Aloc
t = 0, Ain
t = 0, Aout
t = 0, and A
out
t = 0.
2. This step is stage ‚Éù1 in Figure 3.1. Select a location on O at random. However, it is
unknown which of the learned locations this location is.
3. This step is stage ‚Éù3 . Obtain Win
t from the sensory input at the location of step 2. For
every cell c = (ij) in the sensory layer (the j-th cell in the i-th mini-column), calculate
the activity of c:
ain
ij,t :=
(
1 if i ‚àà Win
t
0 otherwise .
4. This step is stage ‚Éù5 . For every cell k in the output layer, calculate
aout
k,t :=
Ô£±
Ô£≤
Ô£≥
1 if
X
i,j
fijk ¬∑ ain
ij,t ‚â• Œ∏out
p
0 otherwise .
(3.5)
Thus, Aout
t =

aout
k,t

and the concatenated vector A
out
t are obtained. Set
Wout
t :=

k : aout
k,t = 1
	
. (3.6)
5. This step is stage ‚Éù6 . For every cell k in the output layer, calculate
œÅout
k,t :=
(
1 ‚àÉd : A
out
t ‚Ä¢ Dout
kd ‚â• Œ∏out
b
0 otherwise
(3.7)
and
aout
k,t :=
 1 if k ‚àà Wout
t and œÅout
k,t = 1
0 otherwise .
Thus, Aout
t and A
out
t are updated.
12
6. This step is stage ‚Éù7 . For every cell c = (ij) in the sensory layer, calculate
œñin
ij,t :=
Ô£±
Ô£≤
Ô£≥
1 if
X
k
fijk ¬∑ aout
k,t ‚â• Œ∏in
p
0 otherwise,
(3.8)
and update the activity of c:
ain
ij,t :=
(
1 if ain
ij,t = 1 and œñin
ij,t = 1
0 otherwise .
(3.9)
7. This step is stage ‚Éù4 . For every cell Œ≥ in the location layer, calculate
œÄloc
Œ≥,t :=
(
1 ‚àÉd : Dloc
Œ≥,d ‚Ä¢ Ain
t ‚â• Œ∏loc
0 otherwise ,
(3.10)
where Ain
t :=

ain
ij,t

. Let ‚Éóœïih,t be the location vector of the h-th cell in the module i, and
set
Œ¶sense
i,t :=
Ô£±
Ô£≤
Ô£≥
n
‚Éóœïih,t : Œ≥ = (ih) satisfies œÄloc
Œ≥,t = 1
o
if ‚àÉŒ≥ = (ih) : œÄloc
Œ≥,t = 1
‚àÖ otherwise.
Note that the elements of Œ¶ sense
i,t may indicate not only the true location on O but also
other locations on O or locations on objects other than O. For example, in Figure 2.3 (A),
if the true location is the end point of the red vector, then this location and the locations
of the all end points of the blue vectors in O, O‚Ä≤, and O‚Ä≤‚Ä≤ are indicated by Œ¶sense
i,t .
8. Set t := t + 1.
9. This step is stage ‚Éù1 . Virtually or really, change the observation location on O by (imag-
inary) motor input (see Remark 3.4). This motor input is represented by a movement
vector ‚ÉóŒ¥i,t in each module i of the location layer, and we obtain
Œ¶move
i,t :=
n
‚Éóœït := ‚Éóœït‚àí1 + ‚ÉóŒ¥i,t : ‚Éóœït‚àí1 ‚àà Œ¶sense
i,t‚àí1
o
, (3.11)
where ‚Éóœï + ‚ÉóŒ¥i,t is considered on the torus made from the lattice of module i. Make all
cells corresponding to the elements of Œ¶ move
i,t active and the other cells inactive. Thus,
Aloc
t,move := Aloc
t is updated.
10. This step is stage ‚Éù2 . For every cell c in the sensory layer, calculate
œÄin
c,t :=
(
1 ‚àÉd : Din
c,d ‚Ä¢ Aloc
t,move ‚â• Œ∏in
b
0 otherwise .
(3.12)
Cell c is predictive if and only if œÄin
c,t = 1.
11. This step is stage ‚Éù3 . Move to a new observation location on O by the movement vector
‚ÉóŒ¥i,t in step 9. Then, obtain Win
t from the sensory input at this location. For every cell
c = (ij) in the sensory layer, calculate the activity of c:
ain
ij,t :=
Ô£±
Ô£¥Ô£≤
Ô£¥Ô£≥
1 if i ‚àà Win
t and œÄin
ij,t = 1
1 if i ‚àà Win
t and ‚àÄ cell k ‚àà mini-column i, œÄin
ik,t = 0
0 otherwise .
(3.13)
Thus, Ain
t is updated.
13
12. This step is stage ‚Éù5 . For every cell k in the output layer, calculate (3.5). Thus, Aout
t and
A
out
t are updated. Set Wout
t using (3.6).
13. This step is stage ‚Éù6 . For every cell k in the output layer, calculate (3.7) and the activity
of k:
aout
k,t :=
 1 if k ‚àà Wout
t and œÅout
k,t‚àí1 = œÅout
k,t = 1
0 otherwise . (3.14)
Thus, Aout
t and A
out
t are updated.
Stop this algorithm and we say that O is recognized, if only the object O is active in the
sense of Definition 3.1 described below. Otherwise, go to the next step.
14. This step is stage ‚Éù7 . For every cell c = (ij) in the sensory layer, calculate (3.8) and (3.9).
Thus, Ain
t is updated.
15. This step is stage ‚Éù4 . For each cell Œ≥ = (ih) in the location layer, calculate (3.10), and set
Œ¶sense
i,t :=
Ô£±
Ô£≤
Ô£≥
n
‚Éóœïih,t : Œ≥ = (ih) satisfies œÄloc
Œ≥,t = 1
o
if ‚àÉŒ≥ = (ih) : œÄloc
Œ≥,t = 1
Œ¶move
i,t otherwise.
(3.15)
Then, go to step 8.
Remark 3.3 Compared with the inference algorithms in [9] and [14], Algorithm 3.2 has the
following changes:
‚Ä¢ The condition œÅout
k,t = 1 in (3.14) is added by the author. In [9], the feedback stage ‚Éù7 ,
that is, the operation in steps 6 and 14, is optional and definite formulae are omitted. In
the present study, as such formulae, (3.8) and (3.9) are added as matches to (3.12) and
(3.13), respectively. Condition œÅout
k,t‚àí1 = œÅout
k,t = 1 and the feedback stage ‚Éù7 result in the
voting system described in ¬ß3.3.
‚Ä¢ In Algorithm 3.2, as in Algorithm 3.1, cells are used instead of bumps to represent the
activity in the location layer, which differs from the algorithm in [14].
Remark 3.4 As policies for selecting motor inputs in step 9, the paper [1] lists model-based
policies and model-free policies (see ‚Äúaction policy‚Äù in ¬ß3.4 and ¬ß11 in [1]). Model-based policies
enable principled movement, such as moving a sensor to a location that will minimize the
uncertainty of the currently observed object. In other words, the prediction can drive movement
(cf. ¬ß1.7 of [21]). One must be able to compare the likelihoods of candidates for the observed
object to achieve this minimization. The more candidates there exist, the costlier it becomes.
However, avoiding this remains unclear to the author. Model-free policies are useful for purely
sensory-based actions such as focusing on a prominent feature.
Algorithm 3.2 can be considered as a Bayesian (or non-Bayesian) updating process, where
object O is the unknown parameter. The conditional probability is denoted by P(¬∑|¬∑), a sensory
input by St, and a location on O at time t by Lt(O). As events, St implies ‚Äúthe sensory input
is St‚Äù and Lt(O) implies ‚Äúthe observation location is Lt(O).‚Äù Then, roughly speaking, the
correspondences between the steps in Algorithm 3.2 and probabilities calculated at each step
are considered as summarized in Table 3.1. These probabilities are based on the generative
model that the cortical columns have, and P(Lt+1(O)|St) essentially depends on the selection
mechanism of the motor input as described in Remark 3.4. The details of Table 3.1, including
the case of a non-Bayesian model, will be explained in ¬ß5.
14
Table 3.1: Correspondences between steps in Algorithm 3.2 and probabilities
steps 10, 11 steps 12 ‚Äì 15 step 9
P(St|Lt(O)) P(Lt(O)|St) P(Lt+1(O)|St)
likelihood posterior prior
3.3 Activity and selection of an object
On page 6 of [9], it is stated that ‚ÄúThe set of active cells in the output layer represents the objects
that are recognized by the network. During inference we say that the network unambiguously
recognizes an object when the representation of the output layer overlaps significantly with the
representation for correct object and not for any other object. ‚Äù Based on this concept, we define
the following (see step 8 of Algorithm 3.2).
Definition 3.1 Let Œ∏out
o and Œ∏
out
o be real numbers (thresholds) such that Œ∏out
o > 0 and 0 <
Œ∏
out
o < 1. Object O is active in cortical column C (more precisely, in the output layer of cortical
column C) at time t if
‚ôØ
 
k : k = 1 in Aout
O
	
‚à©

k : aout
k,t = 1 in (3.14)
	
‚â° ‚ôØ
 
k : k = 1 in Aout
O
	
‚à©

k : aout
k,t = 1 in (3.6)
	
‚à©

k : œÅout
k,t‚àí1 = œÅout
k,t = 1
	
‚â• Œ∏out
o
is satisfied in C. Furthermore, object O is active in the considered cortical columns at time t if
‚ôØ {cortical column C : O is active in C at time t} ‚â•Œ∏
out
o Nc
is satisfied.
If Algorithm 3.2 results in only one active object, O, then O is unambiguously recognized. In
Algorithm 3.2, the flow of information between different cortical columns is realized by (3.7) and
(3.14). The other information flows remain in each cortical column. Condition œÅout
k,t‚àí1 = œÅout
k,t = 1
causes and accelerates convergence of recognition, that is, convergence onto a representation for
object O. This system is a voting system among the cortical columns such that it combines the
sensory inputs received by the cortical columns into a single perception (see [11], [7], and [1]).
Throughout the duration of Algorithms 4.1 and 4.2, a specific object must be continuously
recognized. Additionally, in these algorithms, an object must be selected (randomly) from
multiple active objects. How should these processes be implemented ? The author considers
the following as one of the mechanisms for such an implementation: Let C1, C2, . . . , CI be the
cortical columns that store the considered objects O := {O1, O2, . . . , OJ }. Each object is stored
in one or more cortical columns. Let C be another cortical column with the following properties:
‚Ä¢ Let M1, . . . , Mm be the modules of the location layer of C. Each object is represented by
a set of cells {c1, . . . , cm} such that cj is selected from Mj as follows:
‚Äì For the object that is first recorded in C, cell cj is randomly selected from Mj.
‚Äì Cell c‚Ä≤
j for the second and subsequent object recorded in Mj is obtained by
‚àí ‚àí ‚Üícjc‚Ä≤
j = ‚Éó v,
where cj represents a recorded object O ‚àà Oand ‚Éó vis a movement vector. The object
O and the vector v are common to M1, . . . , Mm.
15
Connections exist between the cells representing an object O ‚àà Oin the output layers of
C1, . . . , CI and the cells {c1, . . . , cm} representing O in the location layer of C. Thus, the
set of cells {c1, . . . , cm} acts as a pointer to the cells representing O in the output layers
of C1, . . . , CI. For instance, as shown in Figures 4 and 5 in [1], C1, . . . , CI and C form a
hierarchical structure, and C belongs to the layer one level above C1, . . . , CI.
‚Ä¢ A movement vector in the location layer of C represents a movement from one object to
another.
‚Ä¢ The cells representing an object O ‚àà Oin the location layer of C are connected to some
cells in the sensory layer of C. These cells represent the features of O.
‚Ä¢ The output layer of C is optional.
We consider the following selection method for an object or objects from objects O1, . . . , OJ in
C. Only the selected object(s) in C1, . . . , CI and C are activated.
(S1) One of the cells representing objects stored in a module of the location layer of C is
randomly activated. If the activated cell c is one of the cells representing object O, then
the cells in the output layers of C1, ..., CI connected to c (the cells representing O) are also
activated, and the cells representing O in the location layer of C are activated. In this
way, one object is randomly selected.
(S2) A movement vector in the location layer of C starting from object O selected in (S1) results
in the selection of another object.
(S3) To select objects with desired features F, first the cells representing F in the sensory layer
of C are activated. Then, the objects in the location layer of C that are connected to these
cells are activated.
Furthermore, if a specific object O must be continuously recognized in C1, . . . , CI, it is realized
by activatingO in C continuously. Each object O stored in C can be considered as an abstraction
of the object stored in C1, . . . , CI. For instance, it may be assumed that C is storing a language
and O is the name of the object.
In (S1), initially only one cell is activated. This process is not robust to noise; however, if
more than one cell is randomly selected, a high probability that more than one object will be
selected exists.
3.4 Values of thresholds
We assume that relationships between the values of thresholds Œ∏out
p , Œ∏out
b , Œ∏out
o , Œ∏in
b , and Œ∏loc in
Algorithm 3.2 and the constants ‚ôØ{cij}, ‚ôÆAout
O , and Nloc are as follows (cf. Remark 3.2), where
the values in ( ) are used in [9] and/or [14]:
‚Ä¢ Œ∏out
p (= 3) ‚â§ ¬Øc := ‚ôØ{cij} (= 5‚Äì8),
‚Ä¢ Œ∏out
b (= 18) ‚â§ Œ∏out
o (= 30 ‚â§ 40) ‚â§ ‚ôÆA
out
O ,
‚Ä¢ Œ∏in
b (= 6‚Äì8) ‚â§ Nloc(= 10),
‚Ä¢ Œ∏loc(= 8) ‚â§ ¬Øc.
16
Note that Œ∏loc is only used in [14] and ¬Øc is only used in [9]. In [9], some permanence values used
during learning, and in [14], bumps are used to represent activity in the location layer. Although
these are not used in the present study, the values listed above are also consistent in this study.
Thresholds Œ∏
out
o in Definition 3.1 and Œ∏in
p in Algorithm 3.2 are not used in [9] and [14]. The value
of Œ∏
out
o should not be excessively small because when some overlap exists between the SDR of
the observed object O and that of another object O‚Ä≤, this O‚Ä≤ may also be active. The value of
Œ∏in
p is as follows. We set w := ‚ôØWin
t and a := ‚ôÆAout
O . For any cell cij in the sensory layer, define
a random variable Xij as the number of cells in the output layer such that they are connected
to cij by Algorithm 3.1. If the connections are generated independently of each other, then the
probability of Xij ‚â• Œ∏in
p is independent of ( ij) and is given by
P
 
Xij ‚â• Œ∏in
p

=
aX
r=Œ∏inp
 a
r
 ¬Øc
w
r 
1 ‚àí ¬Øc
w
a‚àír
.
Then, a criterion for selecting the value ofŒ∏in
p is that P
 
Xij ‚â• Œ∏in
p

‚â• p for the desired probability
p.
4 Finding similar objects
The set of learned and considered objects is denoted by ‚Ñ¶ . In this section, two algorithms are
proposed to find objects in ‚Ñ¶ similar to a given object O ‚àà ‚Ñ¶, based on Algorithm 3.2. Although
the setting for the proposed algorithms is restricted, the author believes that the case it covers
is fundamental. Each object comprises a set of (location, feature) pairs as described in ¬ß2.
Therefore, O and O‚Ä≤ are similar if and only if the (location, feature) pairs on O and O‚Ä≤ are
similar.
Each sensory feature f corresponds to the SDR Win
t = Win(f) in the sensory layer. Let F
be the set of all SDRs in the sensory layer. We introduce a distance function D on F such that
D(Win(f), Win(g)) is small if and only if features f and g are similar. For instance, colors with
similar wavelengths, such as blue and purple, are often considered as similar features. Then,
we assume that the brain knows that these are similar, that is, D(Win(blue), Win(purple)) is
small. Note that distance D does not necessarily represent the physical distance on the sensory
layer. Let d be a nonnegative number, and for W ‚àà F, define a neighborhood Nd(W) by
Nd(W) :=

W‚Ä≤ ‚àà F: D(W, W‚Ä≤) ‚â§ d
	
. (4.1)
If d = 0, then Nd(W) = {W}. We consider Nd(W) as a set of SDRs similar to W.
Algorithms 4.1 and 4.2 to find similar objects are based on Algorithm 3.2. The author believes
that it would be preferable to make as few changes as possible from Algorithm 3.2. In Algorithm
4.1, the only essential change is the replacement of Win
t with Nd(Win
t ), and several additional
changes exist in Algorithm 4.2. If d = 0, Algorithm 4.1 is essentially the same as Algorithm 3.2.
Algorithms 4.1 and 4.2 stop at a specified time. Algorithm 3.2 can also find objects similar to
the observed object O, provided that it stops before converging on the representation of O. Let
C1, . . . , CI, and C be the cortical columns described in ¬ß3.3, and let O and O‚Ä≤ be objects stored
in C1, . . . , CI. The similarity relationship between O and O‚Ä≤ obtained by these algorithms can be
recorded as the positional relationship between O and O‚Ä≤ in the location layer of C by arranging
or rearranging similar objects close together. This is learning the ‚Äúsimilarity‚Äù between objects.
17
Algorithm 4.1 (Finding objects in ‚Ñ¶ similar to the given object O)
T is a nonnegative integer and d is a nonnegative real number. Using Algorithm 3.2, the
object O has been recognized in the considered cortical columns. It is assumed that O can
always be referred to (see ¬ß3.3), and all the real movement vectors and observation locations are
on O.
1. Set t = 0, Aloc
t = 0, Ain
t = 0, Aout
t = Aout
O , and A
out
t = A
out
O because O has been already
recognized.
2. Select a location on O at random. Then, this location is recognized.
3. This step is the same as step 3 of Algorithm 3.2, except Win
t is replaced with Nd(Win
t ).
4 ‚Äì 10. These steps are the same as steps 4 to 10 of Algorithm 3.2.
11. This step is the same as step 11 of Algorithm 3.2, except Win
t is replaced with Nd(Win
t ).
12. This step is the same as step 12 of Algorithm 3.2.
13. For every cell k in the output layer, calculate (3.7) and (3.14). Thus, Aout
t and A
out
t are
updated.
If t = T, stop this algorithm. Otherwise, go to the next step.
When this algorithm stopped, randomly select an object O‚Ä≤ ‚àà ‚Ñ¶ such that it is active in
the sense of Definition 3.1 as an object similar to O (see ¬ß3.3). The end time T may be
determined dynamically. For example, when the number of active objects in the output
layer falls below a certain number, we set t := T.
14, 15. These steps are the same as steps 14 and 15 of Algorithm 3.2.
Algorithm 4.1 uses all the mechanisms for convergence onto the representation of object(s)
in Algorithm 3.2, that is, the mechanisms of the algorithms in [9] and [14]. Therefore, the
convergence property of Algorithm 4.1 is essentially the same as that of Algorithm 3.2.
According to [2], it is not possible for the brain to recognize multiple objects, simultaneously.
Therefore, if the brain executes Algorithm 4.1, most of it (particularly the selection in step 13)
would be executed unconsciously.
Figure 4.1: Example of objects (they are the same objects as in Figure 2.2)
‚ãÜ ‚ó¶
2 ‚ó¶ ‚ó¶
‚ãÜ 2 2 ‚ãÜ
‚ãÜ
E‚Ä≤ 2
‚ó¶ 2 2
‚ãÜ ‚ó¶ ‚ó¶ ‚ãÜ
‚ãÜ
‚Ä¢ ‚ó¶
2 ‚ó¶ 2
‚Ä¢ ‚ó¶ 2 ‚Ä¢
‚Ä¢
O O ‚Ä≤ O‚Ä≤‚Ä≤
In the following, a broken line connecting the locations through which movement vectors pass
is called a path. The starting point of a path is the starting point of the first movement vector,
18
whereas the end point of a path is the end point of the last movement vector. In Algorithm
4.1, once an object becomes inactive, it cannot become active again. Assume that, in Figure
4.1, features ‚ó¶ and 2 are similar. If the path is as shown in Figure 4.2 (A), O‚Ä≤ is active and
O‚Ä≤‚Ä≤ is inactive from the third step onwards. Next, assume that in Figure 4.1, features ‚ó¶ and 2
are similar, and features ‚ãÜ and ‚Ä¢ are similar. If the path is as shown in Figure 4.2 (B), O‚Ä≤‚Ä≤ is
active and O‚Ä≤ is inactive from the third step onwards, because all corresponding paths on O‚Ä≤ are
inactive (i.e., the third step locations of these paths do not exist or are inactive). One of the
reasons of this inactivity is that no location labeled E‚Ä≤ exists on O‚Ä≤.
As shown in the examples above, two cases exist in which an object becomes inactive:
(NL) No location exists on the object corresponding to the current location on O.
(NF) Although corresponding locations exist, the features on none of these locations are similar
to the feature on the location on O.
If the above inactivities are not acceptable, we can execute Algorithm 4.2, which is obtained by
modifying Algorithm 4.1. In this algorithm, if necessary, values of œÅout
k,t s and aout
k,t s are reset by
(4.2) and an additional process is performed in step 15. Therefore, in either case (NL) or (NF),
the location information of the object is not lost, and the object continues to be observed in the
next round.
Algorithm 4.2 (Finding objects in ‚Ñ¶ similar to the given object O)
T is a nonnegative integer and d is a nonnegative real number. Using Algorithm 3.2, the
object O has been recognized in the considered cortical columns. It is assumed that O can
always be referred to, and all the real movement vectors and observation locations are on O. For
O‚Ä≤ ‚àà ‚Ñ¶, Œ±t(O‚Ä≤) denotes a binary variable representing the activity ofO‚Ä≤ in the sense of Definition
3.1 at time t, 1 ‚â§ t ‚â§ T. Œì is a positive integer such that Œì ‚â§ T.
1, 2, 3. These steps are the same as steps 1, 2, and 3 of Algorithm 4.1.
4. This step is the same as step 4 of Algorithm 4.1. Set Œ≥0(O‚Ä≤) := 0 for every active O‚Ä≤ ‚àà ‚Ñ¶.
5 ‚Äì 12. These steps are the same as steps 5 to 12 of Algorithm 4.1.
13. For every cell k in the output layer, calculate (3.7) and (3.14). Thus, Aout
t and A
out
t are
updated. For every O‚Ä≤ that is active at time t ‚àí 1
‚Ä¢ set Œ±t(O‚Ä≤) := 1 if O‚Ä≤ is active, and set Œ±t(O‚Ä≤) := 0 if O‚Ä≤ becomes inactive,
‚Ä¢ calculate
Œ≥t(O‚Ä≤) := Œ≥t‚àí1(O‚Ä≤) +
 
1 ‚àí Œ±t(O‚Ä≤)

.
If Œ±t(O‚Ä≤) = 0 , Œ≥t(O‚Ä≤) < Œì, and O‚Ä≤ should be made active again, reset the activity of the
cells in A
out
O‚Ä≤ of each cortical column by resetting
œÅout
k,t := œÅout
k,t‚àí1 and aout
k,t := aout
k,t‚àí1 (4.2)
for every cell k in A
out
O‚Ä≤ . Thus, Aout
t and A
out
t are updated.
If t = T, stop this algorithm. Otherwise, go to the next step.
When this algorithm stopped, randomly select an active object O‚Ä≤ as an object similar to
O (see ¬ß3.3). The end time T may be determined dynamically.
19
14. This step is the same as step 14 of Algorithm 4.1.
15. If there exists no O‚Ä≤ reactivated in step 13, this step is the same as step 15 of Algorithm
4.1.
If there exists such an O‚Ä≤, add the end point of every current path on every such O‚Ä≤ that
satisfies (NF) or (NL) to Œ¶ sense
i,t in each cortical column. In case (NL), the set Œ¶ sense
i,t
contains such end points as virtual position vectors.
Then, go to step 8.
Remark 4.1 Algorithm 4.2 considers both (NF) and (NL); however, it could also consider
just one or the other. For instance, to consider only (NF), Algorithm 4.2 is changed as follows:
‚Ä¢ In step 13, reset the activity using (4.2) only if there exists a path on O‚Ä≤ such that it
satisfies (NF). Therefore, if no path on O‚Ä≤ satisfies (NF), O‚Ä≤ is not reactivated.
‚Ä¢ In step 15, perform processing only for (NF).
Remark 4.2 In the (NF) case, step 15 is implemented by rewriting step 14 as follows:
14‚Äô This step is the same as step 14 of Algorithm 4.1, except that for every objectO‚Ä≤ reactivated
in step 13, change (3.9) to
ain
ij,t :=
(
1 if œÄin
ij,t = 1 and œñin
ij,t = 1
0 otherwise .
Then, in step 15, the end point of every current path on O‚Ä≤ that satisfies (NF) is automatically
added to Œ¶ sense
i,t . In the (NL) case, implementing step 15 would require a mechanism for infor-
mation to pass directly from the output layer to the location layer. This requires making the
model shown in Figure 3.1 more complicated. It is unclear to the author whether Algorithm 4.2
can be rewritten to avoid this complication.
In step 13, Œ±t(O‚Ä≤) = 0 implies that
‚ôØ
 
k : k = 1 in Aout
O‚Ä≤
	
‚à©

k : œÅout
k,t‚àí1 = 1
	
‚â• Œ∏out
o
holds for Œ∏
out
o Nc or more cortical columns and
‚ôØ
 
k : k = 1 in Aout
O‚Ä≤
	
‚à©

k : œÅout
k,t‚àí1 = 1
	
‚à©

k : œÅout
k,t = 1
	
‚à©

k : aout
k,t = 1 in (3.6)
	
< Œ∏out
o
holds for

1 ‚àí Œ∏
out
o

Nc or more cortical columns.
We now provide some examples of how Algorithm 4.2 runs. Assume that ‚Ñ¶ = {O, O‚Ä≤, O‚Ä≤‚Ä≤}
as shown in Figure 4.1 and features ‚ó¶ and 2 are similar. As mentioned above, if the path is as
shown in Figure 4.2 (B) and Algorithm 4.1 is used, two paths on O‚Ä≤ are active at the end of
the second movement vector and both paths become inactive at the end of the third movement
vector. One of the end points is location E‚Ä≤. Suppose O‚Ä≤ is to be reactivated. Then, O‚Ä≤ becomes
active again by (4.2) and end point E‚Ä≤ on one of the two paths above is recorded as the virtual
end point of a vector in Œ¶ sense
i,t (t = 3) by step 15. In this step, the third and fourth movement
vectors in Figure 4.2 (B) on O, that is, the movement vectors in Figure 4.2 (C), are translated
20
to a movement vector on O‚Ä≤ as in Figure 4.2 (D). One of the two locations at time t + 1 = 4 is
the end point of this movement vector.
Algorithm 4.2 for Œì = 1 is nothing but Algorithm 4.1. As well as O‚Ä≤, suppose O‚Ä≤‚Ä≤ should also
be reactivated if it becomes inactive. Assume that features ‚ó¶ and 2 are similar. If T = 5, Œì = 3,
and the path is as shown in Figure 4.2 (B), then Œ≥T (O‚Ä≤) = 1 < Œì, Œ≥T (O‚Ä≤‚Ä≤) = 2 < Œì. Therefore,
both O‚Ä≤ and O‚Ä≤‚Ä≤ are active at time T, and one of them is selected as an object similar to O. If the
value of Œì is changed to 2, then O‚Ä≤ is active and O‚Ä≤‚Ä≤ is inactive at time T; thus, O‚Ä≤ is selected.
Figure 4.2: Example of movement vectors
(A)
‚ãÜ ‚ó¶
2 ‚ó¶ ‚ó¶
‚ãÜ 2 2 ‚ãÜ
‚ãÜ
O
?
@
@ R


 
?
(B)
‚ãÜ ‚ó¶
2 ‚ó¶ ‚ó¶
‚ãÜ 2 2 ‚ãÜ
‚ãÜ
O
6  
  	
 
  	
6
6
(C)
‚ãÜ ‚ó¶
2 ‚ó¶ ‚ó¶
‚ãÜ 2 2 ‚ãÜ
‚ãÜ
O
 
  	
6
(D)
2
‚ó¶ 2 2
‚ãÜ ‚ó¶ ‚ó¶ ‚ãÜ
‚ãÜ
E‚Ä≤
O‚Ä≤

For location L, the neighborhood Nd(L) in the location layer can be considered in the same
manner as in (4.1), where d is a value of a distance function (cf. ¬ß9.10 of [1]). In this case, the
‚Äúcorresponding location‚Äù in (NL) and (NF) can be considered to be the ‚Äúlocation L‚Ä≤ nearest to
the corresponding (virtual) location L with L‚Ä≤ ‚àà Nd(L),‚Äù and similarly for Algorithms 4.1 and
4.2.
For some simple cases, numerical experiments were conducted to obtain the probability of
an object being active at the end of Algorithm 4.2. It was assumed that no noise existed when
Algorithm 4.2 was executed. We considered a pair of observed object O and another object
O‚Ä≤ ‚àà ‚Ñ¶. In the experiments, 1000 randomly generated pairs of ( O, O‚Ä≤) were used for each of the
cases of T = 3, 4, 5 and Œì = 1, 2. The experimental settings were as follows:
‚Ä¢ Both objects O and O‚Ä≤ comprise 5 √ó 5 grid locations.
‚Ä¢ The number of types of groups of similar features is 5. These five types of features are
uniformly randomly placed in 25 locations on each of objects O and O‚Ä≤.
‚Ä¢ Let p be a path connecting T movement vectors on O such that each path p for T = 3, 4, 5
is as depicted in Figure 4.3. These paths are used in the experiment.
21
‚Ä¢ O‚Ä≤ should be reactivated if it becomes inactive. However, only movement vectors whose
end points remain inside O‚Ä≤ are considered for simplicity. Therefore, the operation for case
(NL) is not be executed. (See Remark 4.1.)
Let N(p) be the number of paths with the same shape as p on O‚Ä≤. Then, for T = 3 , 4, and
5, the values of N(p) are 40, 20, and 16, respectively. The results of experiments by using a
Java program are as summarized in Table 4.1. In this program, the Mersenne Twister random
number generator MTRandom.java was used (see [17]). The ‚Äúprobability‚Äù in this table refers
to the probability (percent) that O‚Ä≤ is active at the end of Algorithm 4.2.
Figure 4.3: Paths connecting movement vectors
- - - - - - - - - - - 6
T = 3 T = 4 T = 5
Table 4.1: Probability (percent) that O‚Ä≤ is active at the end of Algorithm 4.2
Œì Œì = 1 Œì = 2
T T = 3 T = 4 T = 5 T = 3 T = 4 T = 5
probability (%) 7.0 0.4 0.1 59.6 10.2 1.6
Figure 4.4: Example of movement vectors
(A)
‚ãÜ ‚ó¶
2 ‚ó¶ ‚ó¶
‚ãÜ 2 2 ‚ãÜ
‚ãÜ
O
?
? - 
  
6
(B)
2
‚ó¶ 2 2
‚ãÜ ‚ó¶ ‚ó¶ ‚ãÜ
‚ãÜ
E‚Ä≤
O‚Ä≤
 -
6
(C)
2
‚ó¶ 2 2
‚ãÜ ‚ó¶ ‚ó¶ ‚ãÜ
‚ãÜ
E‚Ä≤
O‚Ä≤
 
 
6
Remark 4.3 We provide some supplementary explanations for Algorithms 4.1 and 4.2.
‚Ä¢ Assume that features ‚ó¶ and 2 are similar, Œì = 2, T= 5, and the path is as shown in Figure
4.4 (A). Suppose O‚Ä≤ should be reactivated if it becomes inactive. The three red paths in
Figure 4.4 (B) are active at t = 2 and no active paths exist at t = T. In the red path
in Figure 4.4 (C), there exists only one location such that it corresponds to either (NL)
22
or (NF). This path appears to be active even at t = T when Œì = 2 . However, although
the paths in Figure 4.4 (B) are active even at the second step, the path in Figure 4.4
(C) becomes inactive at the second step. Therefore, the path in Figure 4.4 (C) remains
inactive after the second step. We can rewrite Algorithm 4.2 to avoid this; however, as it
would be complicated, we do not proceed it.
‚Ä¢ In Algorithms 4.1 and 4.2, any object that was not activated in step 4 will not be activated
thereafter. If it is a problem, we may rerun Algorithms 4.1 and 4.2. It is easy if T is a
small value.
5 Surprise and active inference
According to Friston‚Äôs free-energy principle, active inference caused by surprise is considered (see
[4], [5], and [18]). The surprise of sensory input St is defined by ‚àílog P(St), the negative log
evidence of St. Thus, the smaller P(St) is, the larger the surprise. In the present study, surprise
also refers to sensory input that is (mostly) not predicted. Thus, if in step 11 of Algorithm
3.2, most of mini-columns in Win
t satisfy the second condition of (3.13), then we consider that
St causing such a set Win
t is a surprise. As an active inference for surprise, we consider the
following two essentially identical types:
(I) Updating the prior to take the sensory input obtained at time t as the predicted sensory
input at time t + 1. An example of this active inference is when someone attempts to pour
coffee into a cup from a pot but pours water instead, and then updates her/his knowledge
about the contents of the pot.
(II) Action at time t + 1 to grasp the sensory input obtained at time t as the predicted sensory
input at time t+1. An example of this active inference is when someone sees something out
of the corners of her/his eyes that is not predicted and turns her/his eyes in that direction.
We propose Algorithm 5.1 as an algorithm such that it is a changed version of Algorithm 3.2
to actively infer in both cases (I) and (II). Condition œÅout
k,t‚àí1 = 1 in (3.14) interferes with this
active inference. Therefore, in Algorithm 5.1, the value of œÅout
k,t‚àí1 is set to 1 in (5.3) for the case
where (5.2) is satisfied.
Algorithm 5.1 (Active inference for surprise)
The constants Œ∏w, Œ∏‚Ä≤
w, and Œ∏‚Ä≤‚Ä≤
w are thresholds such that 0 < Œ∏w < 1, Œ∏‚Ä≤
w > 0, and 0 < Œ∏‚Ä≤‚Ä≤
w < 1,
where Œ∏w is close to 1 .
1 ‚Äì 10. These steps are the same as steps 1 to 10 of Algorithm 3.2.
11. This step is the same as step 11 of Algorithm 3.2, except at the end of this step, check
whether
‚ôØ

i ‚àà Win
t : ‚àÄk ‚àà mini-column i, œÄin
i,k,t = 0
	
‚â• Œ∏w ¬∑ ‚ôØWin
t ‚â• Œ∏‚Ä≤
w (5.1)
or not.
12. This step is the same as step 12 of Algorithm 3.2.
13. Check whether
(The number of cortical columns that satisfy (5.1)) ‚â• Œ∏‚Ä≤‚Ä≤
wNc, (5.2)
and perform the following.
23
The case where (5.2) is not satisfied .
13, 14, 15. These steps are the same as steps 13, 14, and 15 of Algorithm 3.2.
The case where (5.2) is satisfied .
13. For every cell k ‚àà Wout
t in (3.6), set
œÅout
k,t‚àí1 = 1. (5.3)
For every cell k in the output layer, calculate (3.7) and (3.14). Thus, Aout
t and A
out
t are
updated.
If there exist no active objects, stop this algorithm. Then, this inference is a failure.
14. This step is the same as step 14 of Algorithm 3.2.
15. Calculate Œ¶ sense
i,t by (3.15).
Because (5.2) is satisfied, probably this Œ¶ sense
i,t is very different from Œ¶ move
i,t .
Then, go to step 8 described below.
8. Set t := t + 1.
9. Let the vector ‚ÉóŒ¥i,t in (3.11) be ‚ÉóŒ¥i,t = 0. Then, the obtained locations correspond to the
sensory input Win
t‚àí1.
10. This step is the same as step 10 of Algorithm 3.2.
Then, go to step 11 described above.
Remark 5.1 We provide some supplementary explanations for Algorithm 5.1.
‚Ä¢ If condition (5.2) does not hold, then Algorithm 5.1 is the same as Algorithm 3.2. In this
case, although the activity in the second line of (3.13) may be reflected in (3.6), its effect
will usually disappear in (3.14).
‚Ä¢ In step 9, by setting ‚ÉóŒ¥i,t = 0, the active inference mapping Œ¶ move
i,t‚àí1 ‚Üí Œ¶move
i,t is realized.
Because the selection of ‚ÉóŒ¥i,t takes no time, this process is assumed to be instantaneous.
Remark 5.2 Let the current time be t. The setting of the value of œÅout
k,t‚àí1 in (5.3) contrasts
with that of the value of œÅout
k,t in (4.2). In (5.3) the value of œÅout
k,t‚àí1 is reset, whereas in (4.2) the
value of œÅout
k,t‚àí1 is reused. The set Œ¶ move
i,t+1 = Œ¶sense
i,t induced by the reset (5.3) causes a rewriting of
Lt(O) in Definition 5.1 below. In this case, the prior probability obtained from the information
prior to time t is lost, and only the second term in (5.6) remains.
In the following, we consider Algorithm 5.1 from a non-Bayesian (modified Bayesian) inference
perspective. The Bayesian updating process is defined as follows:
Pt(Œ∏|st) = P(st|Œ∏)Pt‚àí1(Œ∏|st‚àí1)P
Œ∏ P(st|Œ∏)Pt‚àí1(Œ∏|st‚àí1) (t = 1, 2, . . .),
24
where Œ∏ is the considered parameter, ( s1, s2, . . .) are the given data, P(¬∑|¬∑) is the conditional
probability, and P0(Œ∏|s0) := P(Œ∏). Thus, Pt‚àí1(Œ∏|st‚àí1) is the posterior to Œ∏ at time t ‚àí 1 and the
prior of Œ∏ at time t. In [12], the author considered the following non-Bayesian updating process:
Pt(Œ∏|st) = (1 ‚àí Œ≥t) P(st|Œ∏)Pt‚àí1(Œ∏|st‚àí1)P
Œ∏ P(st|Œ∏)Pt‚àí1(Œ∏|st‚àí1) + Œ≥t
P(st|Œ∏)P
Œ∏ P(st|Œ∏) (t = 1, 2, . . .), (5.4)
where 0 ‚â§ Œ≥t < 1. In [12], this updating rule is interpreted as an overreacting to the observations.
The second term on the right-hand side of (5.4) can be nonzero even if the prior Pt‚àí1(Œ∏|st‚àí1) is
zero. Thus, this term may be valid even if st‚àí1 is not predicted, that is, P(st‚àí1|Œ∏) = 0. From
this perspective, we consider the non-Bayesian formulation of Algorithm 5.1 as follows.
Let Lt(O) and St be as defined in ¬ß3.2, and ‚Ñ¶ be as defined in ¬ß4. Even if the brain is
conscious of the movement vector, we consider Lt(O) to be probabilistically determined. In the
following, the inequality P >0 means that P is sufficiently large to be distinguished from 0 . If
not P >0, then we set P = 0. We define
Œ≥t = Œ≥ (St) :=
 1 if (5.2) is satisfied
0 if (5.2) is not satisfied (5.5)
and
‚Ñ¶t,0 := {O ‚àà ‚Ñ¶ : Pt(Lt+1(O)|St) = 0},
‚Ñ¶t,+ := {O ‚àà ‚Ñ¶ : Pt(Lt+1(O)|St) > 0},
‚Ñ¶t,L := {O ‚àà ‚Ñ¶ : P(St|Lt(O)) > 0}.
Then, we define a non-Bayesian updating process. It is also a type of state-space model.
Definition 5.1 The stochastic process Lt(O) is called a non-Bayesian updating process with
discrete time t = 1, 2, . . .if it satisfies
Pt (Lt(O)|St) = (1 ‚àí Œ≥t) P(St|Lt(O)) ¬∑ Pt‚àí1(Lt(O)|St‚àí1)P
O‚àà‚Ñ¶t,L‚à©‚Ñ¶t‚àí1,+ P(St|Lt(O)) ¬∑ Pt‚àí1(Lt(O)|St‚àí1)
+Œ≥t
P(St|Lt(O))P
O‚àà‚Ñ¶t,L‚à©‚Ñ¶t‚àí1,0 P(St|Lt(O)) (5.6)
Pt (Lt(O)|St) ‚Üí Pt (Lt+1(O)|St) . (5.7)
The posterior Pt (Lt(O)|St) obtained by (5.6) is updated to the prior Pt (Lt+1(O)|St) as (5.7)
by the movement vector in step 9 of Algorithm 5.1 at time t + 1.
For consistency between Definition 5.1 and (5.5), we assume the following:
Assumption 5.1 Assume that for every O ‚àà ‚Ñ¶ and t, if Œ≥t = 1 and P(St|Lt(O)) > 0, then
Pt‚àí1(Lt(O)|St‚àí1) = 0.
From this assumption, we obtain that when Œ≥t = 1,
P(St|Lt(O)) ¬∑ Pt‚àí1(Lt(O)|St‚àí1) = 0
holds. This is consistent with the range of sum of the first term on the right-hand side of (5.6).
It is natural to make Assumption 5.1 when Œ∏w is sufficiently large. If Œ∏w is sufficiently large,
then no predicted objects probably exist if Œ≥t = 1. Assume Pt‚àí1(Lt(O)|St‚àí1) > 0. Then, object
25
O was probably active at time t ‚àí 1. Therefore, if P(St|Lt(O)) > 0, then we can believe that St
is predicted, which implies Œ≥t = 0. Thus, we have Assumption 5.1.
As described below, we consider Algorithm 5.1 to correspond to the non-Bayesian updating
process in Definition 5.1. This formulation is a different (non-)Bayesian type formulation from
Friston‚Äôs free-energy principle and it does not have the universality that Friston‚Äôs theory does.
However, it can make a description of surprises and active inferences such as those in (I) and
(II).
We illustrate the probabilistic aspects of Algorithm 5.1. The likelihood P(St|Lt(O)) corre-
sponds to steps 10 and 11. For instance, if we have no information regarding P(St|Lt(O)), we
consider
P(St|Lt(O)) =
Ô£±
Ô£≤
Ô£≥
1
‚ôØ‚Ñ¶t,L
if O ‚àà ‚Ñ¶t,L
0 if O Ã∏‚àà ‚Ñ¶t,L.
(5.8)
The posterior Pt(Lt(O)|St) and prior Pt(Lt+1(O)|St) correspond to steps 12 to 15 at time t and
step 9 at time t + 1, respectively. Depending on whether condition (5.2) holds, one of the terms
on the right-hand side of (5.6) is selected, and the probability Pt(Lt(O)|St) is obtained. Table
3.1 is based on this concept.
In both cases Œ≥t = 0 and Œ≥t = 1, the posterior Pt(Lt(O)|St) is updated byLt(O) ‚Üí Lt+1(O) in
step 9, Lt+1(O) = Lt(O) when Œ≥t = 1, and Pt(Lt+1(O)|St) becomes the prior. In [1], model-based
and model-free policies are provided as policies for determining the motor input as described
in Remark 3.4. In both learning and inference, both policies can work in concert. However,
the policies in the inference following learned connections in Figure 3.3, that is, inference by
Algorithm 3.2, will be primarily model-based. By contrast, the policies for the case Œ≥t = 1 and
(II) are considered to be primarily model-free. In step 13 of Algorithm 5.1 for the caseŒ≥t = 1, the
selection is assumed to be made uniformly random. Uniform randomness is also assumed in (5.8).
(The random policy is a special case of the model-free policy.) However, if the strength of the
sensory input, ‚ôØWt, differs for each object, this could be reflected in probabilities. Furthermore,
using information from multiple cortical columns would yield more precise probabilities.
6 Conclusion
In this study, we studied the Numenta neocortex model. In ¬ß2 and ¬ß3, the Numenta model
was reviewed. Algorithms that find objects similar to the given object O (Algorithms 4.1 and
4.2) and an algorithm that actively infers surprise (Algorithm 5.1) were proposed by slightly
changing the Numenta inference model (Algorithm 3.2).
An important aspect of these algorithms is how the motor input (movement vector) is se-
lected. As described in Remark 3.4 and ¬ß5, model-based and model-free policies to determine
the motor input were proposed by [1]. These policies enable the model to quickly identify the
observed object and react to the surprise. According to [2], [4], [5], and [18], the motor input
appears to be generated unconsciously in numerous cases, and according to [4], [5], and [18], un-
conscious processing is generally performed to minimize the variational free energy. The policies
proposed by [1] and Algorithm 3.2 could be deemed to be a method of performing this mini-
mization. However, it seems that implementing conscious selection of the motor input remains
unclear. This is an open problem for the author.
From the perspective of ‚Äúassociation,‚Äù the setting for the algorithms in ¬ß4 is significantly
limited. To improve this, it is expected that research on association, such as that described in
Chapter 6 of [7] and [23], which investigates association in feedforward artificial neural networks,
is useful. In Algorithms 4.1 and 4.2, the selection method of the motor input is important. This
26
selection in the inference depends on the learning results. Thus, the learning method of the
associations between objects is important. These are also open problems for the author.
Acknowledgements
This work was supported by JSPS KAKENHI Grant Number JP22K11916.
References
[1] Viviane Clay, Niels Leadholm, and Jeff Hawkins, The thousand brains project: a new
paradigm for sensorimotor intelligence, arXiv: 2412.18354v1, 2024
[2] Stanislas Dehaene, Consciousness and the Brain: Deciphering How the Brain Codes Our
Thoughts, Viking Penguin, 2014
[3] R. Douglas Fields, The Other Brain: The Scientific and Medical breakthroughs that will
hear our brains and revolutionize our health , Simon & Schuster Paperbacks, 2009.
[4] Karl Friston, The free-energy principle: A rough guide to the brain ?, Trends in Cognitive
Sciences, 13, 293-301, 2009
[5] Karl Friston, The free-energy principle: A unified brain theory ?, Nature Review Neuro-
science, 11, 127-138, 2010
[6] Jeff Hawkins with Sandra Blakeslee, On Intelligence: How to New Understanding of the
Brain Will Lead to the Creation of Truly Intelligent Machines , Times Books, 2004
[7] Jeff Hawkins, A Thousand Brains: A New Theory of Intelligence , Basic Books, 2022
[8] Jeff Hawkins and Subutai Ahmad, Why neurons have thousands of synapses, a theory of
sequence memory in neocortex, Frontiers in Neural Circuits, vol.10, article no.23, 2016
[9] Jeff Hawkins, Subutai Ahmad, and Yuwei Cui, A theory of how columns in the neocortex
enable learning the structure of the world, Frontiers in Neural Circuits, vol.11, article no.81,
2017
[10] Supplementary material of [9]
[11] Jeff Hawkins, Marcus Lewis, Mirko Klukas, Scott Purdy, and Subutai Ahmad, A framework
for intelligence and cortical function based on grid cells in the neocortex,Frontiers in Neural
Circuits, vol.12, article no.121, 2019
[12] Hajime Kawakami, Doob‚Äôs consistency of a non-Bayesian updating process, Statistics and
Probability Letters, 203, 109921, 2023
[13] Niels Leadholm, Marcus Lewis, and Subutai Ahmad, Grid cell path integration for
movement-based visual object recognition , The 32nd British Machine Vision Conference,
22nd - 25th November, 2021
[14] Marcus Lewis, Scott Purdy, Subutai Ahmad, and Jeff Hawkins, Locations in the neocortex:
A theory of sensorimotor object recognition using cortical grid cells, Frontiers in Neural
Circuits, vol.13, article no.22, 2019
27
[15] Vernon Mountcastle, An organizing principle for cerebral functions: The unit module and
the distributed system, in The Mindful Brain , edited by Gerald M. Edelman and Vernon
B. Mountcastle, 7-50, Cambridge, MA: MIT Press, 1978
[16] Numenta, Hierarchical Temporal Memory including HTM Cortical Learning Algorithms ,
2011.
https://hearingbrain.org/docs/HTM white paper.pdf
[17] Jonathan Passerat-Palmbach and David Beaumont, MTRandom.java,
http://www.math.sci.hiroshima-u.ac.jp/m-mat/MT/VERSIONS/JAVA/PATCH/MTRandom.java,
2011
[18] Thomas Parr, Giovanni Pezzulo, and Karl J. Friston, Active Inference: The Free Energy
Principle in Mind, Brain, and Behavior , MIT Press, 2022
[19] Abraham Pais, Maurice Jacob, and David I. Olive, Paul Dirac: The Man and His Work ,
Cambridge University Press, 1998
[20] George Polya, How to Solve It: A New Aspect of Mathematical Method , Princeton Uni-
versity Press, 1975
[21] Richard S. Sutton and Andrew G. Barto, Reinforcement Learning: An Introduction , 2nd
Edition, MIT Press, 2018
[22] Toon Van de Maele, Tim Verbelen, Ozan C ¬∏ atal, and Bart Dhoedt, Embodied object repre-
sentation learning and recognition, Frontiers in Neurorobotics, 16, 840658, 2022
[23] Rufin VanRullen and Ryota Kanai, Deep learning and the global workspace theory, Trends
in Neuroscience, 14, 2021
28