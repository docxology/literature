2202
nuJ
21
]IA.sc[
1v48650.6022:viXra
Knowledge as Fruits of Ignorance :
A kind of global free energy principle of our way of thinking
Thomas Cailleteau
Sant Job Skolaj-Lise, 42 Kerguestenen Straed, 56100 BroAnOriant, Breizh∗
(Dated: 6 Juin 2022)
In this second article, we show a simple use of the Ignorance as defined in a previous article
Jaynes & Shannon’s Constrained Ignorance and Surprise. By giving an example about thejourney
of a person, we believe to show some simple, obvious but mathematically encoded philosophical
implications about how we could think, learn and memorize. In this basic model we will separate
how we learn from Ignorance, and how we anticipate the world using Bayes formula, both should
howeverbemoreentangledtobestreflectreality. Infact,aswehaveseenafterachievingthiswork,
applyingignorance on thesystem constituting a person finally turnsout to bethe global approach
of its local counterpart on systems like neurons, cells and other complex probabilistic systems,
describedusingthefreeenergyprinciple,amuchmorecomplexeanddetailedapproach. Theaimof
thisarticle istherefore toshow, asseen from aperson, anotheraspect of theapplication of thefree
energy principle which represents theconstrained Shannon’s entropy,and leads to Bayes’formula.
Weshowthat,usingonlyignoranceasasinglequantity,anditsminimisationasthemainprocess,
we can take into account his understandings, assertions, doubts and assumptions about how he
perceives the world, by describing them mathematically. As in the following we will be assertive
and provocative on purpose, any comments are welcomed and would beappreciated.
Keywords: Entropy,Ignorance, Shannon, Jaynes,Bayes,FreeEnergyPrinciple
I. INTRODUCTION
Thiswork,groundedfirstinEdwinT.Jaynes’bookProbabilityTheory: TheLogicofScience [1],reliesonaprevious
article [2] Jaynes & Shannon’s Constrained Ignorance and Surprise about, what we call, Ignorance. As shown in [2],
from a probability tree and a simple mathematical definition, using constraints, of Ignorance (related to knowledge),
oneisabletoderiveShannon’sEntropyasinJaynes’maximumentropyprinciplebymaximizing/minimizingit. Using
Shannon’sEntropywithconstraintswasinfactusedbefore,indifferentapproachesbutwithmuchmoremathematical
details : see for instance [3] or [4], but also [5], [6] for its use in the framework of the Free Energy Principle, [7] for
a recent review and references within. At the time we were redacting this article, we were not aware about all of
this, but results are really similar, even if the way to achieve it is different. In fact, here, applying Ignorance on the
system constituting a person finally seems to turn out to be the global approach of its local counterpart on systems
like neurons, cells, ... and other complex probabilistic systems, described using the Free Energy Principle.
In our opinion, the framework of Ignorance leads to a more understandable way of seeing the entropy and its
consequences,aswestartonly fromatreeofpossibilities,andwhatweknow. Moreover,asitseemedtobe surprising
that Bayes formula appeared in the calculations in the articles previously cited, we think that here Bayes formula is
clearly seen, as it should be, using a probability tree.
Inthisarticle,wewillfollowthefootstepsofanIgnorantpersoncalledHoward,andstudythestagesofhislearning.
Taking some liberties, we assume that Howard has amnesia (in order to start from a simili zero blank state) but has
alsosomeprimaryknowledgethatheisnotawareof(hecana priori walk,move,listen,read,understandandspeak).
During this journey, we will discuss a mathematical construction with some possible applications on the global
(!) porcessus of learning and thinking, leading to, what we think are, philosophical consequences. We are also
deliberately vague about what ”things/stuffs” are, because we want to show mainly the learning process and its
philosophical implications, without going into other ontological philosophical aspects which go deeper in the way of
describing reality. Therefore, as it is not easy to describe what ”knowledge / to know” means, we will use common
sense and talk about it another time, with a more extended framework using what is shown here. However, about
whatconcernsushere,in[2],wehavedecidedtodescribemathematicallywhat weknows,bytakingtheoppositeview,
thatis,fromthe prismaboutwhat we ignore, aswe aremostlyIgnorant,usingprobabilities: becauseofourmemory,
its uncertainties but also those of our perceptions, we are never confident in our (relative) knowledge, and therefore
we should speak in terms of likelihood, plausibility, degree of confidence, ... in other words, in terms of probabilities
about our situation.
∗Electronicaddress: thomas.cailleteau@lpsc.in2p3.fr
2
II. AT FIRST HE KNOWS NOTHING EXCEPT THAT HE DOESN’T KNOW MUCH
Weknowwhatweknowbutdon’tknowwhatwedon’t... Letusassumethat,inacorridor,walksHoward,depicted
by a system S in a state Z (this state depends on the path took by Howard in his life, his knowledges and choices
that lead him, at this point in time and space, in this corridor). Therefore, all what he will learn will be through his
perceptionsandrelativelytohim. Whatcanhe sayatfirst? Something like”As I am and think, things exist”,which
can be translated in a proposition as
• E : ”Things exist, like time, space and stuffs I can perceive ”
0
So, the probability for Howard that E is true is .. 1 : P(E ==True|Z)=1, that is it is a certain event, in
1 0
this particular case ”even before” he has experimented it. We can then define a quantity, called Ignorance, such that
Definition 1 The Ignorance h of (this) knowledge is defined as
h (E ,Z)=P(E ==True|Z)−1 → 0 (1)
0 0 0
which, being a constraint on the system S, is null by definition.
In the following, except when needed, we will dropthe ”==True”as we evaluate the truthfulness of a proposition
at a moment t in space ~x, in the system of coordinates (xµ), µ ∈ {0,1,...}, with the knowledge available at this
point in Howard space-time. For these reasons, we say that knowledge are relative, or better, in French, as the word
”knowledge” is too narrow to express all the subtilities of ”Nature”, la connaissance est relative mais le savoir est
absolu. That’s also why in Eq.(1), we have set an arrow to express that, even if Howard ”knows” that E is true, it
0
may be not a reality except for him.
We can thus summarize his update of knowledge by the evolution Z → Z for his state of knowledge (omitting,
0
as said before, many things because of his amnesia) at this point in spacetime, and illustrating it with the following
weighted probability tree (here with only two branches due to the only assertion E ) :
0
P(E |Z)=1
0
Z E 0
E 0 Z (xµ)
0 (2)
III. SECOND PIECE OF KNOWLEDGE
Walking down the corridor, he comes to a door with a frame beside it containing a piece of paper that says
”Somewhere,there is a coinanda dice”. Howarddoesn’twonderabout the door,nor aboutthe factthat he canread
and understand, but he does wonder about the things he has forgotten, the coin and the dice. In his mind, as he
knows what means ”there is”, appear two new propositions :
• E : ”A coin exists”,
1
• E : ”A dice exists”,
2
Reading the paper and having therefore some informations about what can exist, has lead Howard to update his
knowledge such that his state is now Z (xµ)→Z (Z (xµ),x′µ), that is, in terms of probabilities
0 1 0
P(E ∪E |Z )+P(E ∪E |Z ) = P(E |Z )+P(E |Z )+P(E ∪E |Z ) = 1, (3)
1 2 1 1 2 1 1 1 2 1 1 2 1
as E and E are independent. Indeed, the creation of the dice may depend on the creation of the coin, but the
1 2
idea that it exists does not depend on the idea that the coin exists, as here, Howard has no other knowledge about
the construction of the dice and the coin. E ∪E represents everything that is not E or E and can therefore be
1 2 1 2
anything. His Ignorance for what he knows about his situation, after this update, is now defined as
h [E ,E ,E ∪E |Z ]=P(E |Z )+P(E |Z )+P(E ∪E |Z )−1=0 (4)
1 1 2 1 2 0 1 0 2 0 1 2 0
and we can represent the evolution of his state of knowledge as
E
1
P(E |Z )
1 0
P(E 0 |Z)=1 P(E 2 |Z 0 ) E
2
Z
E
0
E
Z 0
0 P(E |Z )
.. 0 E
...
Z
1
(5)
3
where we set E ∪E = E.. for short. In [2], we have shown that, in this case, the update of knowledge leads us to
1 2
define another kind of Ignorance, the one about things he does not know yet, if they will happen, are real or not, ..
etc etc, which is simply given by the sum of the different entropies :
Definition 2 The Ignorance h¯ of what he does not know yetcan naturallybedescribed as thesumofthediverse
entropies that exist due to each event :
h¯ [E ,E ,E |Z (Z (xµ),x′µ)]=− λ (E ,Z (Z (xµ),x′µ)) P(E |Z )×ln( P(E |Z ) ), (6)
1 1 2 .. 1 0 i i 1 0 i 0 i 0
i
X
where λ (E ,Z ,t,~x), Lagrange multipliers, are coefficients we could assume not to be 0 or 1. In the following, it will
i i n
be seen as only λ, as any other greek letters which have the same kind of properties.
Definition 3 The (whole) Ignorance H is given by the Ignorance h of what is known, as constraints, therefore using
Lagrange multipliers, and the Ignorance h¯ of what remains to be known, which can be calculated as it consists of
entropies.
For Howard, at this point, following the probability tree and the fact that Z (Z (xµ),x′µ), his Ignorance is thus
1 0
H[E ,E ,E ,E ∪E ,λ,µ|Z (Z (xµ),x′µ)]
0 1 2 1 2 1 0
= µ ×h [E ,Z ]+µ ×h [E ,E ,E ∪E ,Z ]+h¯ [E ,E ,E ∪E ,Z ]
0 0 0 0 1 1 1 2 1 2 0 1 1 2 1 2 0
= µ ×(P(E |Z )−1)+µ (P(E |Z )+P(E |Z )+P(..|Z )−1)
0 0 0 1 1 0 2 0 0
−λ P(E |Z )ln(P(E |Z ))−λ P(E |Z )ln(P(E |Z ))−λ P(..|Z )ln(P(..|Z )), (7)
1 1 0 1 0 2 2 0 2 0 .. 0 0
from which we will explain the use in the next part. Due to the update from Z to Z , we should not forget that
0 1
P(E |Z)→P(E |Z )aswewrotepreviouslyinEq.(7): thememoryofthetruthofthepropositionisretainedduring
0 0 0
the update.
IV. MINIMISING ONE’S IGNORANCE : THE MAXIMUM ENTROPY PRINCIPLE ON KNOWLEDGE
A. Results of the derivatives
Now let’s say Howard is wondering about the coin, and more importantly, how to determine what it is. He is
therefore asking how to minimize his Ignorance. To do that, he has different ways : using the functional derivatives,
he can derive the Ignorance
• with respect to µ : using only the Ignorance of what is known when he was at his state Z ,
0 0
δH
=0⇔P(E |Z )−1=0 ⇔ P(E |Z )=1 (8)
δµ 0 1 0 1
0(cid:12)Z1
(cid:12)
giving us back the fact that he(cid:12)knows (and remember) for sure that ”Things exist”. Notice that we have set
(cid:12)
Z →Z as we evaluate the proposition ”a` la lumi`ere” of his new possible update.
0 1
• with respect to µ in the same way and for the same reason,
1
δH
=0⇔P(E |Z )+P(E |Z )+P(..|Z )−1=0 ⇔ P(E |Z )+P(E |Z )+P(..|Z )=1 (9)
δµ 1 1 2 1 1 1 1 2 1 1
1(cid:12)Z1
(cid:12)
which is(cid:12) what he knows now about the whole current situation would remain true after the update.
(cid:12)
• with respect to λ : using only the Igorance of what remains to be known for each unknow probability,
i
δH
=0⇔−P(E |Z )ln(P(E |Z ))=0 (10)
δλ i 1 i 1
i(cid:12)Z1
(cid:12)
which leads to what he can speculate a(cid:12)bout E for instance :
(cid:12) 1
– P(E |Z )→0 : in this case, if the coin does not exist, he will think, and even more, could assert, as such.
1 1
– ln(P(E |Z ))=0⇔P(E |Z )=1 : if he comes across the coin, he will have a proof of its existence.
1 1 1 1
From Eq.(9), does it mean for instance that, due to P(E |Z ) = 1 we can conclude that (A) : P(E |Z ) =
1 1 2 1
P(E |Z ) = 0, that is (B) : E and E are false and therefore neither a dice or something else which is not a
.. 1 2 ..
coin, exist ? Of course, not. (A) is true but does not imply (B): by minimizing his Ignorance, Howard is kind
of updating his knowledge ”by anticipating” what should be the answers, going therefore from a state Z to a
1
state Z (still, at another point in spacetime). Indeed, at the moment he will be asserting that the coin exists,
2
it will be about the coin only and he will have no clues concerning the other propositions. That is to say, he
cannotupdate simultaneouslyhisknowledgeaboutdifferentobjectsdue to... causality: whenhe(oryou)first
read the paper about the coin and the dice, the information about the coin came first and then the mecanisms
in his brain about the update have first recorded the informations about the coin (and where/when he had the
information),andatasecondtime,theinformationsaboutthedice. Thismeansalsothat,beingattheprevious
state Z , Howard would have set P(E |Z )=1, leading to P(E |Z )=1 at state Z too !
0 1 0 1 1 1
4
In this example,
– his knowledge will be given by
h [E ,E ,E ,..,Z (Z (Z ,.)),.]=µ (P(E |Z )−1)+µ (P(E |Z )−1)+µ (P(E |Z )+P(E¯ |Z )−1) (11)
2 0 1 2 2 1 0 0 0 1 1 1 1 2 2 1 2 1
– his doubts will be given by
h¯ [E ,E¯ ,Z ,..]=−λ P(E |Z )lnP(E |Z )−λ P(E¯ |Z )lnP(E¯ |Z ) (12)
2 2 2 1 1 2 1 2 1 2 2 1 2 1
– and his state of knowledge Z would be represented by
2
P(E |Z ) E
2 1 2
P(E |Z)=1 E P(E |Z )=1 E
0 0 1 0 1
Z
E 0 E 1 P(E¯ |Z ) E¯
2 1 2
Z
Z 1
0
Z
2
(13)
• derivating with respect to P(E |Z ) : by interacting with both kind of Ignorances, and leading to a much
i n
more general framework if more constraints are added,
δH
– for P(E ,Z) : = 0 naturally due to the constraint setting P(E ,Z) = 1 since H does not
0 δP(E ,Z) 0
0 (cid:12)Z1
depend really on P(E |Z)(cid:12), and as the derivative of 0 is 0 because knowing that E is true leads to no
0 (cid:12) 0
ignorance from the beginni(cid:12)ng. Otherwise it would mean that µ =0, that is, Howard has forgotten about
0
E .
0
– for P(E |Z ) : setting λ 6=0 (otherwise there would be no ”unknown” variables)
i 0 i
δH
=0 ⇔ µ −λ (ln(P(E |Z )+1)=0 (14)
δP(E |Z ) 1 i i 1
i 0 (cid:12)Z1
(cid:12)
(cid:12) (cid:12) ⇔ P(E i |Z 1 )=exp µ λ 1 −1 (15)
(cid:18) i (cid:19)
as in [3] and [6] where a density function J(x), J(x)p(x)dx = C as the constraint, was used instead of
Z
our discret case p =1.
i
i
X
It seems clear enough to see the consequences of derivatives other than those with respect to probabilities, and so
we will look at the latter in a simple case where the ignorances have the same weight, that is, setting λ =µ .
i 1
B. Case where λi=µ1
In this case, an a priori particular one, from
H[E ,E ,E ,..,µ|Z (Z ,xµ)]=µ (P(E |Z )−1) (16)
0 1 2 1 0 0 0 0
+µ P(E |Z )+P(E |Z )+P(..|Z )−1−P(E |Z )ln(P(E |Z ))−P(E |Z )ln(P(E |Z ))−P(..|Z )ln(P(..|Z ))
1 1 0 2 0 0 1 0 1 0 2 0 2 0 0 0
h i
and from Eq.(15), if Howardwants to minimise his Ignorance, then
µ
P(E |Z )=exp 1 −1 =e1−1 =e0 =1 (17)
i 1 λ
(cid:18) i (cid:19)
that is, to assert the existence of the coin or the dice, he should .. find them. Of course, since the beginning this is
δH[E ,E ,E ,..,λ|Z ]
0 1 2 1
obvious, but here we show another way to derive it : from =0,
δµ
1 (cid:12)Z1
(cid:12)
(cid:12)
P(E
1
|Z
1
)+P(E
2
|Z
1
)+P(..|Z
1
)−1−P(E
1
|Z
1
)ln(P(E
1
|Z
1
))−P(E
2
|Z
1
)ln(P(E
2
|Z(cid:12)1 ))−P(..|Z
1
)ln(P(..|Z
1
))=0 (18)
5
andafterevaluatingitwiththehelpoftheconstraintP(E |Z )+P(E |Z )+P(..|Z )−1(thisconstraintwasconsidered
1 1 2 1 1
astrueatthepreviousstate,itshouldalsobethecaseaftertheupdate,whenonepropositionisconfirmed,otherwise
the whole framework would collapse due to inconsitency),
−P(E |Z )ln(P(E |Z ))−P(E |Z )ln(P(E |Z ))−P(..|Z )ln(P(..|Z ))=0 (19)
1 1 1 1 2 1 2 1 1 1
which gives, as a priori all events are independent, the following result :
P(E |Z )→0 or P(E |Z )=1 for i∈{1,2,..} (20)
i 1 i 1
not forgetting that, if P(E |Z )=1, then P(E |Z )=0 and P(E.|Z )=0, so only the event E has been assert as
1 1 2 1 . 1 1
true for Howard, and we recover the case of the Graph.(13).
C. Comment on the constraints (n=1) and if they are missing (i.e. no knowledge)
1. On the constraints : why n=1
n
As set in [2], in Eq.(1) and Eq.(4), we use a constraint of the form 0 = 1− p with n = 1. However, even
i
!
i
it is not yet clear about the value of n, using n>1 wouldbring nothing, as, whe X n evaluating the terms with the help
of the constraints, because they are constraints, the terms derived from it will be null :
n ′ n−1 1− p i =0
i
1− p =n×p × 1− p −−−−X−−−−−−→ 0 (21)
i i i
! ! !
i i
X X
That is why, in this article, we will set n=1 and see what we can know from it.
2. If the constraints are missing : case of no Knowledge
For instance, let us consider in a simple case that H[p ,λ ]=− λ p ×lnp with p >0 or p →0. Then, from
i i i i i i i
i
the derivative w.r.t p for i in 1,2,... X
i
δH
=0⇔−λ (lnp +1)=0⇔λ =0 or p =e−1 (22)
i i i i
δp
i(cid:12)Z
(cid:12)
• if λ
i
=0, this could mean that (cid:12) (cid:12), having no knowledge about the event of p
i
, we do not have an Ignorance about
it, whatever the probabilities p . Thatis to say, ”I do not have concerns about things I do not know they exist”.
i
Je ne m’inqui`ete pas des choses dont je ne connais pas l’existence.
• if p =e−1, then
i
H[.]=− λ p ×lnp =− λ e−1×ln(e−1)=e−1 λ (23)
i i i i i
i i i
X X X
which could mean, related also to the case where maybe λ = 0 for some i, that we would have there a
i
”fundamental”valueforourIgnorance,thatistosay”I know that I am Ignorant but I do not know about what”.
Je sais que je suis ignorant mais je ne sais pas `a propos de quoi, autrement dit, j’ignore ce que je ne sais pas.
Both mathematical consequences seem to have philosophical meaning and are in fact used by everyone, at least
most of the time.
V. ANTICIPATION AS SUPERPOSITION OF CONFIGURATIONS : THE BAYES FORMULA ?
Going backto Howardbefore he assertsthateither E , E or E =E ∪E aretrue,starting fromthe Graph.(5),
1 2 M 1 2
he knowsthatE , E andE arepossible. He couldthereforewonderinwhichorderhe willassertornottheirtruth
1 2 M
and draw the graph as the one in Fig.(1). In the following, we will look at states where E and E should be true, in
1 2
order to see how Bayes formula takes place in this framework.
However, the following is not considered as clear as we would want, the global view showing quite a complexity
about what we should have. As such, we just sketch a possible proof about how we can recover Bayes formula in the
simple case of the state Z , andcomment the more complexe cases of Z , n>2. This workis therefore consideredto
2 n
be in progress.
6
E..
E2 E..
P(E2|E1,Z1)
E2
EM E.. E2
E1
P(EM|E1,Z1) ..E2..
P(E1|Z0) E..
E1
E..
P(E0|Z)=1 P(E2|Z0)E2
Z E0 EM E1
P(EM|Z0)
E1
Z0 E0 E..
..E1..
Z1 EM
E1
E2
E..
E2
E2
..E2..
E1
Z2 E..
E1
Z3 E.. ..E1..
..E1/E2..E2/E1.. E2..E1.. E1..E2..
Z4..
FIG. 1: Anticipating what’s next : in blue, pathsleading to a state where both E1 and E2 are true (at lot are missing) in the
general cas (if 4 updates, there are 12 paths containing E1 and E2
A. The global view
Looking at Fig.(1), we see that the states which verifies E and E have either the probabilitis P(E ∩E ) or
1 2 1 2
P(E ∩E ) such that
2 1
l m n
P(E ∩E )= P E ∩ E E ∩ E ∩E =P(..E ..E ..) (24)
1 2 .. 1 .. 2 .. 1 2
 !   ! 
l,m,n i=1 j=1 k=1
X Y Y Y
   
and
l m n
P(E ∩E )= P E ∩ E E ∩ E ∩E =P(..E ..E ..) (25)
2 1 .. 2 .. 1 .. 2 1
 !   ! 
l,m,n i=1 j=1 k=1
X Y Y Y
   
Proposition 1 The number of paths u containing E and E at the Z state, follows the recurrence relation
n 1 2 n
u =u +2n, u =0 (26)
n+1 n 1
whose solution is
u =n2−n (27)
n
As u =n(n−1) it will always be an even number as expected due to the symmetry E ↔E .
n 1 2
7
P(E2|E1,Z1)
E2
E1
E2
P(E1|Z0) P(E2|E1,Z1)
P(E1|E2,Z1)
E1
P(E0|Z)=1 P(E2|Z0) E2
Z E0 E1
P(EM|Z0)
Z0 E0
⋆
E1
Z1
EM
E2
Z2 E..
FIG. 2: Case of 2 possible updatesafter E0 : 2 paths contain E1 and E2
If we denote (u ) the sequence caracterising the number of paths having both E and E at the state Z ,
n 1 2 n
then
• at Z , there are u =0 paths
1 1
• at Z , there are u =2 paths (0+2)
2 2
• at Z , there are u =6 paths (2+4)
3 3
• at Z , there are u =12 paths (6+6)
4 4
Proof • at Z 5 , there are u 5 =20 paths (12+8)
from which we can see the following recurrence relation u =u +2n for the number of paths containing
n+1 n
bothE andE ,halfofthemconcerntheE ,E orderandtheotherhalftheorderE ,E . Astherecurrence
1 2 1 2 2 2
relation is of order 1 due to the term 2n, the expression of u , using the polynomial method, is the second
n
order u =αn2+βn+γ, and a quick resolution with
n
• u =0=α+β+γ ⇔γ =−α−β
1
• u =2=4α+2β+γ =3α+β ⇔β =2−3α and γ =2α−2
2
• u =6=9α+3(2−3α)+(2α−2)⇔(2α−2)=0⇔α=1,andthusβ =2−3=−1andγ =2−2=0
3
However, due to the complexity it raises, we will focus now on the simple cases Z and Z .
2 3
B. Case of 2 possible updates after E0 : Z2 state
In Fig.(2), we would know that, for the constraints of interest
• γ×(P(E |Z )+P(E |Z )+P(E |Z )−1)=0
1 0 2 0 M 0
• αP(E |Z )×(P(E |E ,Z )+P(E |E ,Z )−1)=0
1 0 2 1 1 .. 1 1
• βP(E |Z )×(P(E |E ,Z )+P(E |E ,Z )−1)=0
2 0 1 2 1 .. 2 1
but also that
P(E ,E |Z )=k P(E ∩E |Z )+k P(E ∩E |Z )=C, (28)
1 2 1 1 1 2 1 2 2 1 1
where C is a constant, and we would a priori think that k =1+1=u =2. Therefore, we think that Ignorance
i 2
i
X
should have an expression as
H[.|Z ]=γ×(P(E |Z )+P(E |Z )+P(E |Z )−1) (29)
2 1 0 2 0 M 0
+αP(E |Z )×(P(E |E ,Z )+P(E |E ,Z )−1)+βP(E |Z )×(P(E |E ,Z )+P(E |E ,Z )−1)+...(30)
1 0 2 1 1 .. 1 1 2 0 1 2 1 .. 2 1
−λ P(E |Z )lnP(E |Z )−λ P(E |Z )lnP(E |Z )−.... (31)
1 1 0 1 0 2 2 0 2 0
+δ(k P(E ∩E |Z )+k P(E ∩E |Z )−C) (32)
1 1 2 1 2 2 1 1
−µ P(E ∩E |Z )lnP(E ∩E |Z )−µ P(E ∩E |Z )lnP(E ∩E |Z ) (33)
1 1 2 1 1 2 1 2 2 1 1 2 1 1
8
where Eq.(29) and Eq.(30) deal with constraints on each branch of the tree, and Eq.(31) with their associated
Ignorance, and Eq.(32) and Eq.(33) do the same but for P(E ,E ), and it should be possible to express them with
1 2
terms in Eq.(29), Eq.(30) and Eq.(31).
Therefore
δH[.]
=0 ⇔ δk −µ (ln(P(E ∩E ))−1)=0⇔δk =µ (ln(P(E ∩E ))−1) (34)
δP(E ∩E ) 1 1 1 2 1 1 1 2
1 2
δH[.]
=0 ⇔ δk −µ (ln(P(E ∩E ))−1)=0⇔δk =µ (ln(P(E ∩E ))−1) (35)
δP(E ∩E ) 2 1 2 1 2 2 2 1
2 1
Setting µ = µ = µ as both P(E ∩E ) and P(E ∩E ) are linked with the constraint in Eq.(28), but also that
1 2 1 2 2 1
k =k =1 as each probability is given by 1 branch, we have
1 2
δ =µ(ln(P(E ∩E ))−1)=µ(ln(P(E ∩E ))−1) (36)
1 2 2 1
⇔ P(E ∩E )=P(E ∩E ) (37)
1 2 2 1
⇔ P(E |Z )×P(E |E ,Z )=P(E |Z )×P(E |E ,Z ) Bayes Formula (38)
1 0 2 1 1 2 0 1 2 1
In fact, we are not sure this ”proof” is correct as we are biased knowing that, in order to anticipate, we should do
it using Bayes Formula. What allows us to get back on our feet is by introducing the Ignorance about P(E1,E )
2
through Eq.(32) and Eq.(33). However, it does not seem to be incoherent, as it is part of our Ignorance about the
(futur of the) system represented by Howard.
C. Case of 3 possible updates after E0 : Z3 state
E..
E2 E..
P(E2|E1,Z1)
E2
EM E..
E1
P(EM|E1,Z1)
P(E1|Z0) E..
E1
E..
P(E0|Z)=1 P(E2|Z0) E2
Z
E0 EM E1
P(EM|Z0)
Z0 E0 E..
Z1
EM
E1
E2
E..
E2
E1
Z2 E..
Z3
E..
E1..E2..
E2..E1..
FIG. 3: Case of 3 possible updates after E0
With Fig.(3),wearewonderingaboutwhatisthe moregeneralBayesFormulawhere weshouldanticipatesomuch
more than 2 steps ahead. We start by first wondering if
6
P(E ,E |Z )= k P({∩,E ,E ,E }|Z ) (39)
1 2 2 i 1 2 .. 2
i
X
9
where {∩,E ,E ,E } represent the 6 permutations of E , E , E . By doing as previously, we would think that the
1 2 .. 1 2 ..
derivatives of the Ignorance should lead also to
P(E ∩E )=P(E ∩E ) (40)
1 2 2 1
3 3
⇔ P(1→2,E )= P(2→1,E ) (41)
.. ..
i i
X X
⇔ P(E ∩E ∩E )+P(E ∩E ∩E )+P(E ∩E ∩E )=P(E ∩E ∩E )+P(E ∩E ∩E )+P(E ∩E ∩E )
.. 1 2 1 .. 2 1 2 .. .. 2 1 2 .. 1 2 1 ..
where P(i→j,E ) is such that E appears always before E .
.. i j
In particular,as the case E →(E ,E ) where E and E would appear at the next update (the last two branches
.. 1 2 1 2
at the bottom in our graph), is in fact the same situation as here where E would be considered as E , we would say
.. 0
that
• P(E ∩E ∩E )=P(E ∩E ∩E ),
.. 1 2 .. 2 1
• but also that P(E ∩E ∩E )=P(E ∩E ∩E )
1 .. 2 2 .. 1
• and thus P(E ∩E ∩E )=P(E ∩E ∩E ).
1 2 .. 2 1 ..
This would seem coherent even for the general case, that is, the Bayes formula P({i,j},..) = P({j,i},..) works for
every configurations with symmetry i↔j, as the 3 equalities just before.
This is of course not a rigorous mathematical proof, and we leave that for later if necessary or if it has not been
demonstrated somewhere else (as it should not be new).
D. Ignoring the anticipation is Ignoring Bayes Formula, that is the question
We have shown here that including probabilities on the states where E and E would appear during its journey,
1 2
thus the states where E ∩E andE ∩E , leads us to incorporatein our Ignorancenew terms whichaccountfor the
1 2 2 1
fact that we do not also know the probabilities of the joined events, which are however also calculable in fine, with
the basic probabilities of the tree ! Consequently, by minimizing Ignorance, we (think that we) were able to recover
Bayes Formula as a deep tool to anticipate, knowing some caracteristics,what would be the values of the other ones.
Thatistosayotherwisethat,includingintheIgnorancealltheprobabilitiesonecanconstructfromtheprobabilities
ofthetree,thisuniquequantityrepresentingHoward’sIgnorance,duetoitscomplexitywhereprobabilitiesarelinked,
will encode all what one should know and guess about the situation. Therefore all informations about what Howard
knows,ignores,canguessornot,couldbecondensedinjusttheIgnorance,representinghismemory,andthemecanism
to remember or anticipate his knowledge could be the one that minimize his Ignorance, respectively with respect to
constraintsformemories,andtotheprobabilitiesforthetwokindofanticipations(theoneabouthiscurrentsituation,
and the one one step ahead).
VI. TWO SIDES OF A COIN LEAD TO A DUCK
A. The algorithm of an update
Openingthedoor,Howardfindshimselfinfrontofanewcorridorinthemiddleofwhich,onthefloor,anobjectstill
unknowntoHowardshines. HowdoesittranslateintoHoward’sbrain? Firstly,inhis”treeofknowledge”,Howardis
nowonthebranch⋆onFig.(2),whereE (”somethingelse”)isverified,andthereforeleadsto(E ,E ,E ). Secondly,
M 1 2 ..
in his brain,
• An event occurs and his state of knwoledge is updated Z →Z (Z ,xµ),
1 2 1
• E is becoming known such as E → E ”I have met an object”, and thus, a new constraint appears 0 =
M M a
P(E |Z )−1 in his Ignorance,and so, in his memory.
a 1
• Consequently, a new branch E is created due to the update, that represents again what he does not know
M
yet. Howard is now facing 3 possibilities (E ,E ,E ) and the probabilities are also updated as they respect
1 2 M
the constraint 0=P(E |Z )+P(E |Z )+P(E |Z )−1 (same as before but with the update Z →Z ),
1 1 2 1 M 1 1 2
• his ”basic” Ignorance is now
H[.|Z ] = µ (P(E |Z )−1)+µ (P(E |Z )−1)+µ (P(E |Z )+P(E |Z )+P(E |Z )−1) (42)
2 0 0 1 a a 1 1 1 1 2 1 M 1
− λ P(E |Z )lnP(E |Z ) (43)
i i 1 i 1
i=1,2,M
X
where Eq.(42) and Eq.(43) represents respectively what he knows and so what is in his memory, and his uncer-
tainties. In the following, except if we say that he forgets one specific knowledge (that is putting µ = 0), we
i
will write Σ in Eq.(42) to indicate what is learned.
10
B. What could it be ?
He could also anticipate and update his a priori, that is, his credences which mesure his belief strength about the
nature of the object. He could then create three new propositions : knowing that E and E are possible,
1 2
1. ”the object is a coin” : E
c
2. ”the object is a dice” : E
d
3. ”the object is a something else” : E
s
How would it translate in the tree of probabilities ? Let us think.
As thepropositionsaboveareconsequencesofE andE ,their probabilitieswouldbe oftheformP(E |E ,E ,Z )
1 2 i 1 2 1
and therefore one would know, first, for instance E , that a coin exists, before assuming that E is true. However,
1 c
this does not mean that one can not verify E before E : indeed, if Howard did not have the knowledge E that a
c 1 1
coinexistbefore comingacrossthe object,andif a paperhadthe propositionE written onit, by readingitfromleft
c
to right, Howard would know that, first, this is related to the object in the corridor, and secondly, that it is a coin,
knowing therefore that, according to the situation, a coin exists, verifying that E is true as a direct consequence.
1
Comment : can he be sure, certain, that this object is really a coin ? The answer is logically no as he has no way
to assert that outside his current situation, but for him, he can consider without trouble that it is true, as it is just
putting a word without clear concepts behind, on a representation of an object. Knowing E is, at this point, true,
c
his memory about it would have the expressionP(E |Z )−1=0 with a Lagrangemultiplier which will be zero if he
c n
forgets about this, or he can transforme the proposition if somehow later, he is able to know that the object was not
in fact a coin : for instance, if living with a lot of persons, all of them call it a ”duck”, then he should think that,
statiscally, he should follow the main opinion about it and change his memory by including terms like
H ew[E ,.]=α(P(E |Z )−0)+β(P(”this object is a duck”|Z )−1)+γ(P(”I was wrong at Z ”|Z )−1)→0 (44)
n c c n n n−1 n
This leads us to consider the following tree
E
c
E
1
E
2
E M (Z 1 ) E c P(E |E ,Z )=1 E 1
1 c 1
E
d
E
s
E
M
(45)
Then, by saying that events are all equiprobable (he is new to this world and therefore has no experience), he could
think that
1
• P(E |Z )=P(E |Z )=P(E |Z )=P(E |Z )=P(E |Z )=P(E |Z )=
1 1 2 1 c 1 d 1 s 1 M 1
6
1
• but also that P(E |E ,Z )= .
c 1 2
5
11
However, because P(E |E )=1, one would have
1 c
1 1 1
• P(E ∩E )=P(E )×P(E |E )= × =
1 c 1 c 1
6 5 30
1 1
• P(E ∩E )=P(E )×P(E |E )= ×1=
c 1 c 1 c
6 6
One reason that these two quantities are not equal, assuming that they should be as it seems logical, is due to the
branches E → E and E → E (not represented on Fig.(45)) where Howard supposed that their weight is the
M M 1 M
sameasalloftheothersbuthedoesnotknowifthereisonlyoneeventoraninfintyinE (asshowninthealgorithm
M
before). Nevertheless, another strange thing seems to exist : from Bayes formula, we can see that
P(E ∩E )=P(E ∩E )⇔P(E )×P(E |E )=P(E )×1=P(E ) (46)
1 c c 1 1 c 1 c c
which could have different results
• P(E )=P(E )=0 there are no coins, fine
1 c
• P(E |E )=P(E )=0 this object is not a coin, fine
c 1 c
• P(E ) = P(E ) not null, and therefore P(E |E ) = 1 : if we find an object, we will think that this object is
1 c c 1
surelya coin. Infact this is true atleastwhenP(E )=1that is when we verifythat the objectis reallya coin,
c
implying that P(E )=1 and so P(E |E )=1.
1 c 1
P(E )
• P(E |E )= c ≤1 , with P(E )>0 and P(E )≤P(E ). In the equiprobable case, then P(E )=P(E )
c 1 P(E ) 1 c 1 c 1
1
and so we recover the case before, even if the number of branches at one node goes to infinity.
• P(E )=1 and so P(E |E )=P(E ), that is, if we verify that a coinexists, then fromthis assertion,we do not
1 c 1 c
know if this object is a coin : both events are independent.
This would be also true for E and E . However, we do not know yet if, due to the complexity of the tree, where E
2 d c
and E can appear in many other branches, our interpretation should be a lot more complexe.
1
C. Here comes Nyarlathotep
Not knowing anything else, Howard was not able to decide about the nature of the object, therefore he set in his
mind that P(E |Z )=P(E |Z )=P(E |Z ). In this case, his Ignorance could be written as
c 1 d 1 s 1
H[.|Z ] = Σ+µ (P(E |Z )+P(E |Z )+P(E |Z )+P(E |Z )+P(E |Z )+P(E |Z )−1) (47)
2 1 1 1 2 1 c 1 d 1 s 1 M 1
+α (P(E |Z )−P(E |Z ))+α (P(E |Z )−P(E |Z ))+α (P(E |Z )−P(E |Z )) (48)
1 c 1 d 1 2 d 1 s 1 3 s 1 c 1
− λ P(E |Z )lnP(E |Z ) (49)
i i 1 i 1
i
X
Derivatives w.r.t P(E |Z ) for i∈{c,d,s} give
i 1
δH
=0⇔µ +α −α −λ (lnP(E |Z )+1)=0 (50)
δP(E |Z ) 1 1 3 c c 1
c 1 (cid:12)Z2
(cid:12)
(cid:12)
(cid:12)
δH
=0⇔µ +α −α −λ (lnP(E |Z )+1)=0 (51)
δP(E |Z ) 1 2 1 d d 1
d 1 (cid:12)Z2
(cid:12)
(cid:12)
(cid:12)
δH
=0⇔µ +α −α −λ (lnP(E |Z )+1)=0 (52)
δP(E |Z ) 1 3 2 s s 1
s 1 (cid:12)Z2
(cid:12)
(cid:12)
However, as they concerne all the objec(cid:12)t, we could set α
1
= α
2
= α
3
= α and λ
i
= λ for i ∈ {c,d,s}, leading to the
same probabilitysuchthat µ1=λ(ln(P(E |Z )+1)whichis in factthe same probabilityas P(E |Z ), P(E |Z ) and
i 2 1 2 2 2
P(E |Z ).
M 2
Adding constraints, in this case, does not bring anything new. The reason is that the constraints he set are not
”real” in the sens that they are coming from Howard’s opinion and concern therefore his anticipation. Moreover, as
shown before, the result should be fine because, setting µ = λ leads again to P(E |Z ) = 1 : all events have the
i 2
same probability to appear to Howard from the point of view of Howard, and the one which would appear is the one
... which appears. This is not a system which send results like a dice or a coin, Howard is a system which receives
interactions from outside and so far, its environmentdoes not favour one piece of information over another (he is not
closed to a particular source of information that would predominate in Howard’s data acquisition). Thus, one should
ingeneralnotthink likethat, atleastmaybe notsettingfor instancethe constraintsashavingallthe samevalue. So,
how constraints could influence Howard ? Here comes Nyarlathotep.
12
1. What does it change ?
Hidden from Howard’s view, Nyarlathotep watches him. Determined to influence Howard’s fate, at the speed of
light squared, he substitutes the object that Howard was observing, which was a coin, puts it in a bag containing six
other coins, two dice and a duck, and, randomly and without looking, scatters them in each corridor around him,
including one object in the one where Howardis standing. Nyarlathotephas also taken care to place a piece of paper
underneatheachobject, stating ”this objectis a ...”. Makingit sothat Howard’snext actionis to pick upthe object,
read the paper and check one of the propositions E , E or E . The probability that Howard observes a coin is now
c d s
P(E |Z ) = 0.7, and is the most likely. This knowledge reflects the situation in which Howard is, but seen from the
c 1
point of view of Nyarlathotep.
Nyarlathotepthendecidestorevealhimself,opensthedoorandlookingHowardintheeye,hepointshisfingeratthe
objectand says”My name is Nobody, the probability that this objectis a coin is 70%”. Not surprisedatall, Howard
update his knowledge Z → Z , setting E ”I have met Nobody” and according to him, P(E |Z (E ))−0.7 = 0.
2 3 N c 3 N
Of course, for Howard, this is an opinion, but as it is also representing the situation, Howard considers it as another
constraint (we could say that Nyarlathotep tricks his brain to do as such). How to translate it with the Ignorance ?
We could add a constraint as before such that
H[.|Z ] = Σ+µ (P(E |Z )+P(E |Z )+P(E |Z )+P(E |Z )+P(E |Z )+P(E |Z )−1) (53)
3 1 1 2 2 2 c 2 d 2 s 2 M 2
+α (P(E |Z )−0.7) (54)
1 c 2
− λ P(E |Z )lnP(E |Z ) (55)
i i 2 i 2
i
X
and therefore
δH[.|Z ]
3 =0⇔µ +α −λ (lnP(E |Z )+1)=0 (56)
δP(E |Z ) 1 1 c c 2
c 2 (cid:12)Z3
(cid:12)
(cid:12)
So, how appears the 0.7 as it should play(cid:12)a role ? We could have also set α
2
(P(E
d
|Z
2
)−0.2) and again, ”0.2” would
not appear. What we could do is to put the information about 0.7 such that at the end P(E |Z ) = 0.7 ... as an
c 3
anticipation ! (again, if it is a coin, then for Howard it will be P(E |Z ) = 1 when he will assert that). Therefore,
c 3
setting µ =λ for all i, we would solve
1 i
δH[.|Z ]
3 =0⇔µ+α −µ(ln(0.7)+1)=0⇔α =µln(0.7) (57)
δP(E |Z ) 1 1
c 2 (cid:12)Z3
(cid:12)
(cid:12)
which is the same as setting the Igno(cid:12)rance as
H[.|Z ] = Σ+µ(P(E |Z )+P(E |Z )+P(E |Z )+P(E |Z )+P(E |Z )−1) (58)
3 1 2 2 2 d 2 s 2 M 2
+µ(1+ln(0.7))P(E |Z ) (59)
c 2
− µP(E |Z )lnP(E |Z ) (60)
i 2 i 2
i
X
0.7
that is for P(E |Z ) : µP(E |Z )(ln(0.7)−lnP(E |Z )) = µP(E |Z )ln . However, this does not work
c 2 c 2 c 2 c 2 P(E |Z )
(cid:18) c 2 (cid:19)
because doing so ...
δH[.|Z ]
3 =0⇔P(E |Z )=1>P(E |Z ) (61)
δP(E |Z ) i 3 c 3
i 2 (cid:12)i6=c,Z3
(cid:12)
(cid:12)
therefore P(E
c
|Z
2
) is the most probable but(cid:12)not according to the minimization of Ignorance.
Howard could also add another proposition to E : if we set E : ”the probability of P(E |Z (E )) is 0.7”, this
N X c 3 N
would be verified by Howard only in a multiverse, after a thousand and thousand of attempts. Therefore, it is not
considered as relevant here.
A possible solution was given a century ago by A. Einstein who could have said ”Everything is described under
a general and special relativity”. Of course, we are not talking about the description of the dynamical evolutions
of objects including space-time, nor the description of objects in quantum domains by Carlo Rovelli’s theory of
relational quantum mechanics [9] (for which the use of Shannon ignorance or constrained entropy might be useful),
but as everything is relatively described from one to another, so are the probabilities ! If we ”want” to keep notion
about the percentage of a probability, we have to think as such ! What represents P(E |Z ) = 0.7 in our case ? It
c 2
means that P(E |Z ) takes 70% of the total probability, that is P(E |Z )=0.7(P(E |Z )+P(E |Z )+P(E |Z )+
c 3 c 3 1 2 2 2 c 2
P(E |Z )+P(E |Z )+P(E |Z )) and so the constraint would become.
d 2 s 2 M 2
P(E |Z )−0.7(P(E |Z )+P(E |Z )+P(E |Z )+P(E |Z )+P(E |Z )+P(E |Z ))=0 (62)
c 3 1 2 2 2 c 2 d 2 s 2 M 2
⇔ 0.3P(E |Z )−0.7(P(E |Z )+P(E |Z )+P(E |Z )+P(E |Z )+P(E |Z ))=0 (63)
c 2 1 2 2 2 d 2 s 2 M 2
13
Keeping a more general case where we set P(E |Z )=β, with 0≤β ≤1, the constraint is now
c 2
(1−β)P(E |Z )−β(P(E |Z )+P(E |Z )+P(E |Z )+P(E |Z )+P(E |Z ))=0 (64)
c 2 1 2 2 2 d 2 s 2 M 2
and the Ignorance is
H[.|Z ] = Σ+µ P(E |Z )+P(E |Z )+P(E |Z )+P(E |Z )+P(E |Z )+P(E |Z )−1 (65)
3 1 2 2 2 c 2 d 2 s 2 M 2
h i
+α (1−β)P(E |Z )−β(P(E |Z )+P(E |Z )+P(E |Z )+P(E |Z )+P(E |Z )) (66)
c 2 1 2 2 2 d 2 s 2 M 2
h i
− λ P(E |Z )lnP(E |Z ). (67)
i i 2 i 2
i
X
Derivatives with respect to P(E |Z ) for i6=c leads to
i 2
δH[.|Z ]
2 =0 ⇔ −λ (lnP(E |Z )+1)+µ−αβ =0 (68)
δP(E |Z ) i i 3
i 2 (cid:12)Z3
(cid:12)
(cid:12) ⇔ µ−αβ =λ i (lnP(E i |Z 3 )+1) (69)
(cid:12)
µ−αβ
⇔ −1=lnP(E |Z ) (70)
λ i 3
i
αβ
µ αβ −
⇔ P(E |Z )=exp − −1 − µ − = − λ →i P(E |Z )=e µ . (71)
i 3 λ λ i 3
(cid:18) i i (cid:19)
Derivatives with respect to P(E |Z ) leads to
c 2
δH[.|Z ]
2 =0 ⇔ −λ (lnP(E |Z )+1)+µ+α(1−β)=0 (72)
δP(E |Z ) c c 3
c 2 (cid:12)Z3
(cid:12)
(cid:12) ⇔ µ−αβ =λ c (lnP(E c |Z 3 )+1)−α (73)
(cid:12)
µ+α(1−β)
⇔ −1=lnP(E |Z ) (74)
λ c 3
c
α(1−β)
⇔ P(E |Z )=exp α + µ − αβ −1 − µ − = − λ →i P(E |Z )=e µ . (75)
c 3 λ λ λ c 3
(cid:18) c c c (cid:19)
Considering the case where ∀i, µ=λ , and setting for simplificity α =kµ, we see that
i lbert
α
−
P(E |Z ) = P(E |Z ) e µ = P(E |Z ) e−k ∀β ! (76)
i6=c 3 c 3 c 3
2. Comments about the results
• Inthiscase,weseefromEq.(76)thattheratioofthedifferentprobabilitieswithrespecttoP(E |Z )isindepen-
c 3
dent of β, which appears only in the expressionof P(E |Z ), in Eq.(75). When α=0 (case with only the basic
c 3
constraint),werecoverthe factthatallthe possibleprobabilitiescanreach1,thatis,they areallequiprobable
in their appearance ! However,in this casewith only one more constraint,we see that it is not true anymore
and one constraint is different
1. if k >0, then P(E |Z ) has a different value than the others, and most importantly, even if P(E |Z )=
c 3 i6=c 3
e−kβ ≤ 1 as 0 ≤ β ≤ 1, we see that P(E |Z ) = ek(1−β) ≥ 1 as k(1−β) ≥ 0, that is P(E |Z ) is greater
c 3 c 3
than 1 and so than the others ! It decreases back to 1 when β =1 (P(E |Z )=1 andthe others are 0), or
c 3
if α=k =0 that is if we do not add more informations about the probabilities.
2. if k <0, this would have been the contrary. However,the constraints we consider here would not have the
same shape : one would be of the form p −1 and the other one of the form 1− p .
i i i i
3. if we add more constraints, we would have more parameters to fine-tune, however, we guess that the ratio
P P
of probabilities will not depend on the value of βs.
• Can we still apply the constraintgiven in Eq.(64) ? No, as it would be true only before the (anticiped) update.
Doing it would lead to
5e−kβ +ek(1−β) =1 ⇔ 5+ek =ekβ ⇔ 5+ek−ekβ =0 (77)
where we see that β can not be equal to 1 : there would have been no unknown probabilities, P(E |Z )→0
i6=c 3
and therefore we would not have to applied the constraint in Eq.(64) and derivatives, as the initial expression
lnβ
setting β = 1 would have no Ignorance ¯h. But, even if the minimum would be for k = , due to the fact
1−β
that (β 6=0) as ex >0 ∀x, Eq.(77) will never be fulfilled as 5+ek−ekβ >0 for any value of k and β.
14
Nevertheless, we could argue that in Eq.(18), setting µ = λ and after deriving w.r.t µ, the constraint was
i
applied leading to probabilities to be 0 or 1 : It was possible because of these specific values. However, when
adding more constraints, this ”equilibrium” becomes unbalanced, probabilities are greater than 1 and it is no
more possible that a sum of positive values is equal to 1 anymore. In fact, Eq.(77) is wrong in the sense that
we have added ”expected” probabilities, that is, when P(E |Z ) = ek(1−β). Then, because the total sum of
c 3
probabilities is still 1, the remaining probabilities should be such that P(E |Z ) = 1−ek(1−β) ! and not
i6=c i 3
as we did in Eq.(77). However, only if k < 0, the sum is positive, but P(E |Z ) will not be considered as the
c 3
P
most probable, as seen above (except in the framework of negative probabilities, the result would be coherent).
What we think happens in this case is in fact the following mechanism : looking only at what becomes the
Ignorance with Eq.(70), Eq.(71) for P(E |Z ) and Eq.(74), Eq.(75) for P(E |Z ), we see that, setting for
i6=c 3 c 3
simplicity λ = µ, α = kµ, and assuming that there are x+1 propositions where x is the number of ones less
i
probable,
lnP(E |Z )=k(1−β) P(E |Z )=ek(1−β) (78)
c 3 c 3
lnP(E |Z )=−kβ P(E |Z )=e−kβ (79)
i6=c 3 i6=c 3
(80)
H[..|Z ] = Σ+µ ek(1−β)+xe−kβ −1 +kµ(1−β)ek(1−β)−kµxβe−kβ (81)
3 postupdate
−µek(1h−β)×k(1−β)−µx i ×e−kβ ×(−kβ) (82)
= Σ+µ ek(1−β)+xe−kβ −1 (83)
+kµ(1 h −β)ek(1−β)−kµxβe i−kβ −kµ(1−β)ek(1−β)+kµxβe−kβ (84)
and after cancellations, remains only
H[..|Z ] =Σ+µ ek(1−β)+xe−kβ −1 (85)
3 postupdate
h i
But as we have seen, µ ek(1−β)+xe−kβ −1 can not be a constraint and should in fact be replaced by
α (P(E |Z ) − 1). Therefore, one way would be to say that the mechanism which prevents the probabili-
c c 3
(cid:2) (cid:3)
ties to be largerthan 1 is, when creatinga node in the tree, to set µ=0 (to clear the previoussituation), to set
α (P(E |Z )−1) as the constraint wich memorizes what would have happened, and set µ( p′ −1) as a new
c c 3 i i
constraint taking account of the new situation (P(E |Z )→p′ =P(E |Z ).
i6=c 2 i i6=c 3
P
Thus,the previousworrieswereinfact... fine,asitwouldhavebeenjustamathematicalanticipation(maybea
better mathematical description exists, with less worrying aspects as the one where probabilities are not really
.. probabilities as here).
3. A possible interpretation : a network of weighted propositions
Depending on the sign of k, and therefore of the value of the Lagrange multiplier α, the ”most probable” (of
probability higher than 1) expected proposition would be either the proposition on which we have more information,
or the others. If we consider the case where k > 0, that could mean that the more we hear from a proposition, even
if at the end its probability will be less than the others (β-independent !), the more we know about it, and thus, the
more we should expect its verification at some point which seems coherent with what we endure in reality : the more
an information is amplified, the more likely we are to come across it in the newspapers, several times and in a short
spaceoftime,andthegreaterourdegreeofconfidenceintheveracityofthisinformation. Thisisofcoursenotcorrect
because we do not know if the information is true, if what we know about it could be coherent, but it is natural to
do so, and this can be seen in what we observe here with the probabilities with the constraint α (P(E |Z)−β) : as
c c
β increases, so is the constraint α about it, being another weights we have in the confidence of an information.
c
If we have informationabout anotherproposition,such that α (P(E |Z)−γ)for instance, then another constraint
d d
will be added in our brain, and then, depending on the weight of α and α , either P(E |Z) or P(E |Z) will be
c d c d
more probable. We can imagine than, in a lifetime, Howard will have a lot of proposition to verify (and so a lot of
weights to adjust), will hear a lot about some of them, and therefore, some weights will be higher than others, and
the total Ignorance will encode all of them as a global quantity but in a really really more complicated expression as
the ones we use : all of this in one quantity will account for Howard’s state, his knowledge, memories and memory,
his assumptions and doubts, ... at a given time; and the processes of minimising his ignorance, as well as his further
anticipations using Bayes’ formula, are mechanisms that allow him to graspthe complexity of the worldaround him.
But its use will be ineffable to explain in details, in a simpler way, as it could be seen as a neuron network with
thousand and thousand of propositions, and relations between them as informations could not be independent !
15
VII. CONCLUSION : MEMORY, SOUVENIRS, IGNORANCE, CREDENCE, ...
Inthis article,wehavefollowedHowardinhis journey to learn,memorizeandanticipate,andwe havebeenable to
describe it in a globalway; using probabilities and Ignorance as defined in [2]. If Howardwould have been a particle,
celloranythingelse,itslocaldescriptionwouldhavealsobeenpossible,asin[3],[4]orwiththeuseintheFreeEnergy
Principle as in [7].
The results we have shown here seem to mathematically account for natural processes that we experience every
day in our behaviour when faced with new information(s). Their scope allows for practical but also philosophical
applications since we can draw conclusions about how we perceive the world.
• As we said previously, it is not because we have a strong credence about a proposition that it will be verified
directly. We can however anticipate it, either by minimising the Ignorance directly with the corresponding
probability and the weights α we have about it (as the values of the probabilities seem to not play a role in
i
theequations),orplanningaheadwithBayes’formula. However,becausethe expectedprobabilitycanbehigher
than 1, one can doubt about it, but this is an anticipation process, not something that will be true in reality.
• Minimising Ignoranceseems to be usefull to anticipate the next step, and Bayes’formulato anticipate two steps
ahead, the latter being a particular case of the former.
• We haveseenalsothe philosophicalimplications ofEq.(22),aboutIgnorancewithoutKnowledge(see also[10]),
leading us to the facts that
• ”I do not have concerns about things I do not know they exist”.
Je ne m’inqui`ete pas des choses dont je ne connais pas l’existence..
• ”I know that I am Ignorant but I do not know about what”.
J’ignore ce que je ne sais pas.
which are of course obvious, at least for anyone like Howard.
• LearningandgoingfromstateZ tostepZ tostepZ ... etcetc,ateachstep/state/nodeinthetree,constraints
0 1
and Ignorance were considered but we think we can distinguish between two kind of constraints :
• at each node α [P(E |Z)+P(E |Z)−1], with the corresponding Ignorance −λ P(E |Z)lnP(E |Z)−
0 0 0 0 0 0
λ ¯0 P(E 0 |Z)lnP(E 0 |Z). Both do not evolve and describe what was the situation at one particular moment
intime: theycanbederivedandonewillfindagainthesameresults,howevertheydonotplayaroleforthe
otherpropositionastheyhavebeenverified: forinstancehere,applyingtheconstraintα [P(E |Z )−1]will
0 0 0
verifyα 0 [P(E 0 |Z)+P(E 0 |Z)−1]=0and−λ 0 P(E 0 |Z)lnP(E 0 |Z)−λ ¯0 P(E 0 |Z)lnP(E 0 |Z)=0. Therefore,
their Lagrange multiplier should not be set directly as 0 (meaning Howard would have forgotten them) as
they still should appear in the memory (in what we call Σ in the previous expression of Ignorance) but
as ”souvenirs/memories” of configurations of Howard’s previous state of Knowledge ! They represent
doubts Howard had over time at different states and he can recall them by applying the same processus,
even at later states.
• constraints like α [P(E |Z )−1] → α [P(E |Z )−1] → α [P(E |Z )−1] → ... which ”evolve” over the
0 0 0 0 0 1 0 0 2
states and assert what are the verified propositions in Howard’s memory. They represent knowledge of
Howard (relatively to its path in life) he has in memory over time.
• WhathappensifweforgetthatapropositionE istrue,thatwenolongerbecometoosureofits truthfulness?
Y
We still are awarethat it is possible and have therefore doubts about it, meaning that the probability/credence
is now P(E |Z) = β . As shown before, its whole Ignorance increases by adding another branch in the tree
Y . Y
and new weight and terms of Ignorance such that
H[E |Z]=α [P(E |Z)−β ]−λ P(E |Z)lnP(E |Z) (86)
Y . Y Y . Y Y Y . Y .
and then we would still apply naturally what we said in Sec.(VIC3) : a loss of certainty is only a new doubt
that appears !
In this paper we have described what could be called a tool, Ignorance, which, like the free energy principle,
is derived from Shannon entropy with constraints. We have also described its applications and implications for a
person’sthinking,learningandrememberingprocess,leadingtoamathematicalmodelthatcouldbeusedtosimulate
the evolution of a person’s memory (see [11] for an attempt). Nevertheless, one could go further, especially in the
philosophical aspect, by including this model in a much more general framework and draw other conclusions such as
theinclusionofOccam’srazorandHume’smaximwhichseemtobedescribablebyBayes’formula(see[12]). However,
this workis beingsavedforlaterandifyouhaveanythoughtsaboutthis workthatyouwouldliketoshare,wewould
be curious and happy to hear them.
16
VIII. ACKNOWLEDGMENTS
The author would like to express his eternal and deepest gratitude to Abhay, Aurelien, Martin, .. and Deusch, for
time and space spend together. Figures were plotted with the help of Geogebra, using Tikz in LateX; and as time
passes, knowledge fade, most of the ”bad English” has been corrected with the help of DeepL/Translator.
[1] Jaynes, E. T. (2003) ”Probability Theory: The Logic of Science”, Cambridge University Press, New York,
ISBN-13978-0-511-06589-7
[2] Cailleteau, T.”Jaynes&Shannon’sConstrained IgnoranceandSurprise”https://doi.org/10.48550/arXiv.2107.05008
[3] Giffin, A., Caticha, A.”Updating Probabilities” https://doi.org/10.1063/1.2423258 (arXiv)
[4] Banavar,J.,Maritan,A.”Themaximumrelativeentropyprinciple”https://doi.org/10.48550/arXiv.cond-mat/0703622
[5] Friston, K. ”The free-energy principle: a unifiedbrain theory?.” Nature reviews neuroscience 11.2 (2010): 127-138.
[6] Sakthivadivel,D.”Towards aGeometryand Analysisfor Bayesian Mechanics”https://arxiv.org/abs/2204.11900 and
”A Constraint Geometry for Inference and Integration ” https://arxiv.org/abs/2203.08119
[7] Ramstead, M., Sakthivadivel,D., Heins, .C, Koudahl,M., Millidge, B., DaCosta, L., Klein, K., Friston, K.”On Bayesian
Mechanics: A Physics of and by Beliefs” https://arxiv.org/abs/2205.11543
[8] Jaynes, E. T. (1957) ”Information Theory and Statistical Mechanics” https://doi.org/10.1103/PhysRev.106.620
[9] Rovelli, C. (1996), ”Relational quantummechanics”, International Journal of Theoretical Physics, 35: 1637–1678.
[10] Raude-Jehanno,G., Piol, M., Prigent, O.”Syntheseof Lasallian Europ. Glob. Think.”, Symposium Brezhonegardol, 2020
[11] LeBloa, V.,Allaire, N.”Impl´ementationsNum´eriquesProbabilistes”, Toutnum´erique&consciencesInformatiques,2021
[12] Changenet, A.,Martin, N.”Vers unevision bay´esiennedela z´et´etique: Justifieret enrichir la d´emarchez´et´etique`apartir
dela formule deBayes”,