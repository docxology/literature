Interpreting Dynamical Systems as Bayesian
Reasoners
Nathaniel Virgo1[0000−0001−8598−590X], Martin Biehl2[0000−0002−1670−6855], and
Simon McGregor3
1Earth-Life Science Institute, Tokyo Institute of Technology, Tokyo 152-8550, Japan
2Araya Inc., Tokyo 107-6024, Japan
3University of Sussex, Falmer, UK
Abstract. A central concept in active inference is that the internal
statesofaphysicalsystemparametriseprobabilitymeasuresoverstates
oftheexternalworld.Thesecanbeseenasanagent’sbeliefs,expressed
asaBayesianpriororposterior.Herewebeginthedevelopmentofagen-
eraltheorythatwouldtelluswhenitisappropriatetointerpretstatesas
representing beliefs in this way. We focus on the case in which a system
can be interpreted as performing either Bayesian filtering or Bayesian
inference. We provide formal definitions of what it means for such an
interpretation to exist, using techniques from category theory.
Keywords: Bayesian filtering · Bayesian Inference · Category Theory.
1 Introduction
A question of current interest is what does it mean for a physical system to be
an agent? That is, given a physical system that interacts with an environment,
whendoesitmakesensetosaythatthesystemislearning about its environment
or trying to achieve a goal, rather than merely being dynamically coupled to
its environment? Here we confine ourselves to the first of these, in a simple
form:givenaphysicalsystemthatisinfluencedbyitssurroundings,underwhat
circumstances can it be said to be performing inference, such that its internal
states could be said to contain ‘knowledge’ or ‘beliefs’ about the outside world?
Our approach has something in common with Dennet’s intentional stance
[17], in that on the one hand we treat the question of whether a system is
performing inference as a matter of interpretation, but on the other hand we
draw a strong connection between interpretations and the underlying physical
dynamics. We provide a formal notion of interpretation for the particular cases
we are interested in (Bayesian filtering and Bayesian inference), such that the
question of whether a system can be consistently interpreted in a particular way
is mathematically well-defined and has a definite answer.
Thequestionofhowtoidentifyagentsinphysicalsystemshasbeenaddressed
in several ways. Some works focus on whether a system’s actions can be seen
as pursuing a goal [33,27], with [31] taking an explicitly Dennettian approach.
Othersfocusmoreonthequestionofidentifyingwhichpartofasystemshouldbe
1202
ceD
72
]IA.sc[
1v32531.2112:viXra
2 N. Virgo et al.
identified as the agent [7,5,6,28,2], or on understanding what the external world
lookslikefromtheagent’spointofview[3,5,6].Anotherapproach,whichwetake
here,istoregardthesystem’sinternalstateasparametrising itsbeliefs.Thatis,
thereisafunctionmappingthesystem’sphysicalstatetoaprobabilitymeasure
that can be seen as a Bayesian prior. This is a key component of work on the
Free Energy Principle (FEP) [19,16,34] and also of [39], although our approach
differsfromtheseinthatourmodelisnotderivedfromthedynamicsofthetrue
environment.Thenotionthatagencyiscloselyrelatedtoparametrisationisalso
central to recent approaches to agency based on category theory [11,38,12].
The idea that states of a system parametrise Bayesian probability distribu-
tions appears more broadly in the Bayesian brain literature [26,30] and has also
arisenincellbiology[29,32].Ourcontributionistomaketheconceptmuchmore
formal, and in so doing, to shed light on the precise relationship between the
interpretation level and the underlying physical level.
On a technical level we formulate the problem of Bayesian filtering at an
abstractlevelusingthetoolsofcategorytheory.Thispartoftheworkisinspired
by [23], which formulates the notion of conjugate prior in terms of category
theory in a similar way. Conjugate priors are convenient because they ensure
the functional form of the posterior is the same as the posterior, in Bayesian
beliefupdating. At thesametime they can be seen as a special case of Bayesian
filtering, as we explain in section 2.3 and appendix B.1. Formulating filtering in
this way allows us to clearly distinguish the role of the physical machine from
the more semantic level at which we can talk about priors and posteriors. We
then flip this perspective around, asking, for a given system, whether it can be
interpreted as implementing Bayesian filtering, and if so under which model. In
this respect our approach generalises that of [8], who studied the special case of
theDirichletdistribution(whichisconjugatepriortoacategoricaldistribution)
in the context of interpreting a physical system as performing inference.
One thing our approach makes clear is that a given system may have more
than one interpretation, and the “correct” interpretation cannot be determined
from the system’s dynamics alone. Another important aspect of our framework
is that an interpretation only depends on the system’s internal dynamics, and
notonthedynamicsoftheexternalworld.Becauseofthis,asystem’spresumed
beliefsmightnotmatchthetruedynamicsoftheworldatall—itsbeliefsmight
be consistent but incorrect — and indeed we can construct examples where the
world “as the system sees it” has a different causal structure from the world as
it really is. (Compare eq. (1) to eq. (7).)
2 Definitions and Results
2.1 Technical preliminaries
Inthefollowing,weusetheconceptsofmeasurable space andMarkov kernel.By
measurablespacewemeanasetequippedwithaσ-algebra,i.e.thekindofthing
onwhichaprobabilitymeasurecanbedefined.Anexampleofameasurablespace
Interpreting Dynamical Systems as Bayesian Reasoners 3
isafiniteset,andareaderwhoisonlyinterestedinthefinitecasecouldmentally
substitute “finite set” wherever we say “measurable space” and “probability
distribution” wherever we say “probability measure.”
GivenameasurablespaceX,wewriteP(X)forthesetofallprobabilitymea-
sures over X. Given measurable spaces X and Y, a Markov kernel is a function
κ: X → P(Y) that maps elements of X to probability measures over Y, with
an additional technical requirement that the function κ be measurable. Markov
kernels are closely related to conditional probability, but they are different in
that a Markov kernel defines a probability measure over Y for every element X,
regardless of whether any probability distribution has been defined over X or
what form such a distribution has. In the case where Y is a finite set, we write
κ(y x)fortheprobabilitythatthekernelκassignstoy whengiventheinputx.
We also make use of a graphical notation known as string diagrams, which
comesfromtheliteratureoncategory-theoreticprobability[13,22].Thisnotation
provides a convenient way to reason about how Markov kernels relate to one
another. The full technical description of this calculus can be found in [22] or
[13],butweprovideabriefintuitiveexplanationinappendixA,aimedatreaders
with no category theory background, along with references to further reading.
2.2 Machines and interpretations
Weareconcernedwithinterpretingaphysicalsystemasperforminginferencesof
some kind on its inputs. We therefore begin by defining a notion corresponding
to a physical system that can take an input from the outside world, which leads
to a change in state, which might be stochastic and might depend on the input.
Definition 1. A machine consists of two measurable spaces, Y (the state space)
and S (the input space), together with a Markov kernel γ: Y ×S →P(Y) called
the update kernel.
Theideaisthatthemachineisinrealityonlyapartofsomelargerstochastic
process. We might typically think of this broader context as represented by the
following causal Bayesian network, although this is not the only possibility.
(1)
HerethevariablesX ,X ,... representthestatesoftheexternalworldatdiffer-
0 1
ent times, which are hidden from the machine’s perspective. S ,S ,... are the
0 1
observable “sensor values” that the machine can access, all of which have the
same sample space, given by S. Similarly, Y ,Y ,... are the machine’s internal
0 1
state at each time step and each has the sample space Y. We assume that each
of the nodes Y ,Y ,... in this network are associated with the same kernel, γ.
1 2
The nodes X and Y represent distributions over initial states of the agent
0 0
and the world. A common ancestor of these nodes could be added, to represent
4 N. Virgo et al.
the possibility that the initial states are correlated. There is no need for any
stationarity assumption in our framework; the initial distribution in eq. (1) can
be arbitrary.
Even though we might think of the machine as existing in a context along
these lines, our notion of interpretation does not depend on the machine’s ex-
ternalenvironmentatall,butonly onthemachine’sinternaldynamics.Thatis,
on the measurable spaces Y and S and on the update kernel γ. This is because,
informallyspeaking,areasonermayhaveconsistentbut wrong beliefsaboutthe
external world, and we wish to include this possibility in our framework. (In
particular, a system that reasons correctly in one environment might be placed
inadifferentenvironmentwherethesameinferencesarenolongercorrect.)Our
notion of interpretation will include a notion of “beliefs” about the external
world. These must be consistent with the machine’s internal dynamics and the
inputs it receives, but they need not relate in any particular way to any ground
truth about the process by which those inputs are generated, since we regard
that as something the reasoner has no direct access to.
Becauseofthiswewillrarelyreasonaboutcausalmodelsdirectly,andinstead
will express our definitions directly in terms of Markov kernels and the relation-
ships between them. The string diagram notation, explained appendix A, will
be indispensable for this.
Wenowdescribeourcentralconcept:aninterpretation ofamachine.Herewe
will present only two kinds of interpretations, Bayesian filtering interpretations
andanimportantspecialcase,Bayesianinferenceinterpretations,butweexpect
these to fit naturally into a much broader family of concepts.
The most important component of an interpretation is what we term an
interpretation map, a function that maps the physical state of a machine to
somethingthatwecanthinkofasabeliefaboutsomeexternalworld.Inthecases
weareconcernedwithinthispaper,a“belief”willbeaprobabilitymeasureover
some hidden variable. An interpretation of a machine will be an interpretation
maptogetherwithsomeadditionaldata(themodel asdefinedbelow),suchthat
a consistency equation is obeyed.
Foragivenmachinetheremaybemanypossibleinterpretations.Weusethe
term reasoner for a machine together with a particular choice of interpretation.
InthecaseofBayesianinferenceinterpretationsandBayesianfilteringinter-
pretations,inwhich‘beliefs’areprobabilitymeasuresoverahiddenvariable,the
interpretation map is a Markov kernel ψ : Y → P(H). Instead of interpreting
H
this stochastically, we think of it as a function that takes a state y ∈Y and re-
turns a probability measure ψ (y) (the belief) over H. This is to be thought of
H
as the reasoner’s subjective knowledge (a Bayesian prior or posterior) about the
hypotheses in H. This kernel plays quite a different role from those associated
with the graphical model in eq. (1), since its purpose is to map states to beliefs,
rather than to model causal influences between random variables.
For an interpretation to be consistent, the reasoner’s beliefs must update in
the appropriate way when the machine receives new data. The precise meaning
of this will depend on what kind of interpretation we are using. For the inter-
Interpreting Dynamical Systems as Bayesian Reasoners 5
pretations we describe here it is given by Bayes’ rule, in a form that we state
precisely below. In future work we can imagine interpretations based on other
principles, such as approximate Bayes (e.g. via the free energy principle).
The idea is that a machine by itself is merely a (possibly stochastic) dynam-
ical process, but if a consistent interpretation exists then it is at least consistent
to ascribe a meaning to its states.
It should be noted that, for a given machine, the question of whether it
can be consistently interpreted in a particular way is in principle an empirical
one, since it depends on the machine’s update kernel, which can in principle
be measured. However, in general a given machine might have multiple non-
equivalent consistent interpretations, and one cannot distinguish between these
empiricallybylookingonlyatthesystem’sinternaldynamics.1Consequentlythe
relationship between interpretations and the empirical, physical world is rather
subtle, and one should keep in mind that our notion of “consistent reasoner”
unavoidably involves an element of choice in which interpretation to adopt.
2.3 Consistency for Bayesian Interpretations
We begin with the more general case of Bayesian filtering interpretations. The
ideaisthatareasonerhasamodel oftheenvironment’sdynamics.Thismodelis
part of the interpretation, and need not match the true environment dynamics.
In the case of filtering, such a model can be described as a Markov kernel
H κ H,thatis,κ: H →P(H×S).TheideaisthatH isthespaceofpossible
S
hidden states of the external world, as modelled by the reasoner. The kernel
κ models a step of this hypothetical external world’s evolution, during which it
bothchangestoanewstateinH andalsoemitsanobservablesensorvalueinS.
A Bayesian filtering interpretation of a machine S γ will then consist
Y Y
of a choice of interpretation map Y ψ H H as described above, together with a
choice of model H κ H. The kernel κ thus describes a reasoner’s beliefs about
S
the next hidden state and the next sensor value, given the current hidden state.
Given the kernels ψ and κ we can define another kernel, which we also
H
consider to be an interpretation map,
H
H
Y ψ S,H(cid:48),H H S := Y ψ H H κ H S. (2)
The kernel ψ maps a state of the machine y ∈ Y to a joint distribution
H,H(cid:48),S
over S and two copies of H, which we think of as the reasoner’s beliefs about
the the next sensor value, the next hidden state, and the current hidden state.
We also define its marginals,
Y ψ S,H(cid:48) H S := Y ψ S,H(cid:48),H H S = Y ψ H H κ H S (3)
1 We leave open the possibility that they could be distinguished by looking at some
broader context, e.g. by discovering that a device’s designer intended a particular
interpretation, or that evolution selected for a particular interpretation.
6 N. Virgo et al.
and
Y ψ S S := Y ψ S,H(cid:48),H = Y ψ H H κ (4)
S S,
which represent the reasoner’s beliefs about the next hidden state and the next
input, and about only the next input, respectively. We can now state the con-
sistency requirement for a Bayesian filtering interpretation.
Definition 2. Given a machineS γ , a consistent Bayesian filtering inter-
Y Y
pretation of γ is given by a measurable space H together with Markov kernels
Y ψ H H and H κ H S that satisfy
H H
ψ
ψ S,H(cid:48) S S = ψ S H S (5)
S
Y γ Y Y γ Y Y
,
with ψ and ψ given by eqs. (3) and (4).
S,H(cid:48) S
The left-hand-side of eq. (5) can be read as sampling from the reasoner’s
joint beliefs about the next hidden state and the next input, and then feeding
the corresponding value of S into the machine as an input. The right-hand-side
can be read as sampling from the reasoner’s belief about its next input, feeding
the result in as its next input, and then sampling from its resulting (posterior)
belief about what it now sees as the current hidden state. The equation says
that these two procedures must give the same result.
In appendix B.1 we give some further intuition for this definition, by consid-
ering the case where S, Y and H are finite sets. An important consequence is
that, in the finite case, whether a given interpretation is consistent or not only
depends on which states are reachable from which other states under a given
input; the actual transition probabilities are irrelevant beyond that. We expect
an analogous statement to hold more generally.
Another important consequence discussed in appendix B.1 is that there is
a large class of machines that only admit trivial interpretations. At least in
the finite case, non-trivial interpretations can only exist if some transitions are
impossible, in the sense that there is a zero probability of transitioning from
y ∈Y to y(cid:48) ∈Y under the input s∈S.
InappendixB.2wegiveamoretechnicalproof,usingstringdiagrams,thatat
leastinthecaseofdeterministicmachines,amachinewithaconsistentBayesian
filteringinterpretationcanindeedberegardedasperformingaBayesianfiltering
task.Thiscanbeseenasextendingsomeoftheideasin[24]onconjugatepriors
to the more general case of Bayesian filtering.
Animportantspecialcaseofdefinition2iswherethemodelκissuchthatthe
hidden state does not change over time. In this case H can be thought of as an
unknownparameterofastatisticalmodel,withthesensorinputsbeingindepen-
dentandidenticallydistributedsamplesfromthemodel.WecalltheseBayesian
inference interpretations.Althoughthefollowingfollowsfromdefinition2under
this assumption, we write it as a separate definition.
Interpreting Dynamical Systems as Bayesian Reasoners 7
Definition 3. Given a machine S γ , a consistentBayesianinferenceinter-
Y Y
pretation of γ is given by a measurable space H together with Markov kernels
Y ψ H H and H φ S that satisfy
H H
ψ
H
ψ φ S S = ψ H φ S S (6)
H H
Y H γ Y Y γ Y Y
.
In appendix B.3 we show that this definition is closely related to the notion
of a conjugate prior, and in particular to the definition of conjugate prior given
by[24]intermsofMarkovkernelsandstringdiagrams.Finally,inappendixB.4
we unpack eq. (6) in more familiar terms, showing that in the discrete case it
does indeed correspond to Bayes’ theorem as usually understood.
In a Bayesian inference interpretation we interpret the reasoner as assuming
itsinputsarei.i.d.samples fromsomedistribution,butthisneednot meanthat
theyactuallyare.UnderaconsistentBayesianinferenceinterpretationareasoner
isinterpretedasmodellingtheworldasifitscausalstructureisasfollows,where
each of the ‘S’ nodes is associated with the kernel φ.
(7)
However, the true dynamics of the world could still correspond to the Bayesian
network in eq. (1) or some other causal structure. The reasoner is simply (inter-
preted as being) unable to perceive the correlations among its inputs.
InappendixCwepresentthreeexamplesofmachineswithconsistentBayesian
inferenceinterpretations.Thefirstexampleisanon-deterministicfinitemachine
with three states. The consistent Bayesian inference interpretation we provide
also involves subjectively impossible observations.
Thesecondexampleisacountablyinfinitedeterministicmachinethatcounts
occurrences of each of two possible observations. The consistent Bayesian inter-
pretation we provide intuitively considers this machine to be inferring the bias
of a coin that is flipped to cause its observations. It uses the standard conjugate
prior to its model as an interpretation map.
The third example is also a countably infinite machine with two possible ob-
servations.However,itonlystoresthedifferencebetweenthenumberofthetwo
possible observations. Intuitively, instead of considering all possible biases of a
coinasthesecondexampletheconsistentBayesianinterpretationweprovidefor
this machine infers which of two specific biases of a coin is causing its observa-
tions. We also hint at how the second machine can “inherit” this interpretation.
3 Discussion
We see the main contribution of this work as a conceptual one. The consistency
equationinvolvedindefinitions2and3canbeseeneitherasaconstraintonthe
8 N. Virgo et al.
machinesthathaveaparticularinterpretationorasaconstraintontheinterpre-
tations that a particular machine allows. Every machine has an interpretation
withrespecttoatrivialmodel(onethathasnoparameter),butinordertohave
an interpretation with respect to a non-trivial model, a machine must at least
obey the constraints discussed in appendix B.1.
SimilarconsistencyequationsshouldexistforapproximateBayesianfiltering
as well as for related inference problems like Bayesian smoothing or prediction.
Even non-Bayesian normative theories about what a system should be repre-
sentingandhowthisshouldchangeunderexternalinfluenceswillprobablyhave
associated consistency equations.
Another direction to extend the concept of consistency equations is to take
intoaccountapossibleinfluenceofthemachine’sstateontheexternalworld.On
the interpretation side this would mean going beyond perception and represen-
tation to also include deliberate actions that combine with beliefs and possibly
also with goals. A machine with such an interpretation might deserve the term
agent instead of reasoner.
Our work is related to other current efforts to capture the notion of agent
using category theory. These include approaches to Bayesian inference [37] and
game theory [10]. The idea that agency is related to parametrisation has also
ariseninthesecontexts[11,38,12].Theseworksfocusonthenotionofalens and
itsgeneralisations.Itisinterestingtonotethatournotionsofinterpretationseem
tobedifferent,andsomewhatsimpler,inthattheylackthebidirectionalnature
of lenses. We conjecture that a more lens-like bidirectional structure would be
neededifweweretoconsiderBayesiansmoothingratherthanBayesianfiltering.
Itwillbeinterestinginfutureworktobetterunderstandtherelationshipbetween
lens-like categories and the concept of interpretation developed in the present
work.
3.1 Relation to the Free Energy Principle
Let us now consider the relation to the Free Energy Principle (FEP) which is
also referred to as active inference. The relevant part of FEP is the part called
“Bayesianmechanics”[19,16,34].Itseemsthattheingredientsforaninterpreta-
tion map can be found in this literature: [16, eq. 3.3] describes a Markov kernel
of an appropriate type, as we detail in appendix D. However, it is not currently
clear to us whether the FEP can be formulated in terms of a consistency equa-
tion that this kernel obeys. Presumably, such an equation would be different
from our definitions 2 and 3, because the FEP is concerned with approximate
rather than exact inference and deals with continuous time.
One important difference between our approach and current formulations of
FEP is that the FEP requires a stationarity assumption on the true dynam-
ics of the agent-environment system. It seems to us that this is used to derive
something that corresponds to a model. In our approach the reasoner’s and the
“ground truth”dynamics of the environment are different things, and partly for
this reason we need no stationarity assumption. We see this conceptual sepa-
ration as an advantage of the consistency equation approach, and we believe
Interpreting Dynamical Systems as Bayesian Reasoners 9
thatbyincorporatingtheseideasitmightbepossibletoformulatetheFEPina
way that would make its assumptions clearer and perhaps even avoid the need
for the stationarity assumption. Although we do not currently know the precise
relationship between our work and the FEP at a technical level, we explore it in
more detail in appendix D.
References
1. Aguilera, M., Millidge, B., Tschantz, A., Buckley, C.L.: How particular is the
physics of the Free Energy Principle? arXiv:2105.11203 [q-bio] (May 2021), http:
//arxiv.org/abs/2105.11203, arXiv: 2105.11203
2. Albantakis, L., Massari, F., Beheler-Amass, M., Tononi, G.: A macro agent and
itsactions.arXiv:2004.00058[cs,q-bio](Mar2020),http://arxiv.org/abs/2004.
00058, arXiv: 2004.00058
3. Ay, N., Lo¨hr, W.: The Umwelt of an embodied agent–a measure-theoretic defini-
tion.TheoryinBiosciences=TheorieinDenBiowissenschaften134(3-4),105–116
(Dec 2015). https://doi.org/10.1007/s12064-015-0217-3
4. Baez,J.,Stay,M.:Physics,Topology,LogicandComputation:ARosettaStone.In:
Coecke,B.(ed.)NewStructuresforPhysics,pp.95–172.LectureNotesinPhysics,
Springer, Berlin, Heidelberg (2011). https://doi.org/10.1007/978-3-642-12821-9 2,
https://doi.org/10.1007/978-3-642-12821-9_2
5. Beer, R.D.: Autopoiesis and Cognition in the Game of Life. Artificial Life 10(3),
309–326 (2004). https://doi.org/10.1162/1064546041255539, /journal/10.1162/
1064546041255539
6. Beer, R.D.: The cognitive domain of a glider in the game of life. Artificial Life
20(2), 183–206 (2014). https://doi.org/10.1162/ARTL a 00125
7. Biehl, M., Ikegami, T., Polani, D.: Towards information based spatiotemporal
patterns as a foundation for agent representation in dynamical systems. In: Pro-
ceedings of the Artificial Life Conference 2016. pp. 722–729. The MIT Press (Jul
2016).https://doi.org/10.7551/978-0-262-33936-0-ch115,https://mitpress.mit.
edu/sites/default/files/titles/content/conf/alife16/ch115.html
8. Biehl,M.,Kanai,R.:DynamicsofaBayesianHyperparameterinaMarkovChain.
In: Verbelen, T., Lanillos, P., Buckley, C.L., De Boom, C. (eds.) Active Inference.
pp.35–41.CommunicationsinComputerandInformationScience,SpringerInter-
national Publishing, Cham (2020). https://doi.org/10.1007/978-3-030-64919-7 5
9. Biehl, M., Pollock, F.A., Kanai, R.: A Technical Critique of Some
Parts of the Free Energy Principle. Entropy 23(3), 293 (Mar 2021).
https://doi.org/10.3390/e23030293, https://www.mdpi.com/1099-4300/23/
3/293, number: 3 Publisher: Multidisciplinary Digital Publishing Institute
10. Bolt, J., Hedges, J., Zahn, P.: Bayesian open games. arXiv:1910.03656 [cs, math]
(Oct 2019), http://arxiv.org/abs/1910.03656, arXiv: 1910.03656
11. Capucci, M., Gavranovi´c, B., Hedges, J., Rischel, E.F.: Towards foundations of
categoricalcybernetics.arXiv:2105.06332[math](May2021),http://arxiv.org/
abs/2105.06332, arXiv: 2105.06332
12. Capucci, M., Ghani, N., Ledent, J., Forsberg, F.N.: Translating Extensive Form
Games to Open Games with Agency. arXiv:2105.06763 [cs, math] (May 2021),
http://arxiv.org/abs/2105.06763, arXiv: 2105.06763
13. Cho, K., Jacobs, B.: Disintegration and Bayesian Inversion via String
Diagrams. Mathematical Structures in Computer Science 29(7), 938–971
10 N. Virgo et al.
(Aug 2019). https://doi.org/10.1017/S0960129518000488, http://arxiv.org/
abs/1709.00322, arXiv: 1709.00322
14. Coecke, B., Paquette, E´.: Categories for the Practising Physicist. In: Coecke, B.
(ed.)NewStructuresforPhysics,pp.173–286.LectureNotesinPhysics,Springer,
Berlin,Heidelberg(2011).https://doi.org/10.1007/978-3-642-12821-9 3,https://
doi.org/10.1007/978-3-642-12821-9_3
15. Coecke, B., Kissinger, A.: Picturing quantum processes: a first course in quan-
tumtheoryanddiagrammaticreasoning.CambridgeUniversityPress,Cambridge,
United Kingdom ; New York, NY, USA (2017)
16. Da Costa, L., Friston, K., Heins, C., Pavliotis, G.A.: Bayesian Mechanics for
Stationary Processes. arXiv:2106.13830 [math-ph, physics:nlin, q-bio] (Jun 2021),
http://arxiv.org/abs/2106.13830, arXiv: 2106.13830
17. Dennett, D.C.: True Believers : The Intentional Strategy and Why It Works. In:
Heath, A.F. (ed.) Scientific Explanation: Papers Based on Herbert Spencer Lec-
tures Given in the University of Oxford, pp. 53–75. Clarendon Press (1981)
18. Fong,B.,Spivak,D.I.:Aninvitationtoappliedcategorytheory:sevensketchesin
compositionality.CambridgeUniversityPress,Cambridge;NewYork,NY(2019)
19. Friston, K.: A free energy principle for a particular physics. arXiv:1906.10184 [q-
bio] (Jun 2019), http://arxiv.org/abs/1906.10184, arXiv: 1906.10184
20. Friston, K., Da Costa, L., Hafner, D., Hesp, C., Parr, T.: Sophis-
ticated Inference. Neural Computation 33(3), 713–763 (Mar 2021).
https://doi.org/10.1162/neco a 01351, https://doi.org/10.1162/neco_a_01351
21. Friston, K., Da Costa, L., Parr, T.: Some interesting observations on the free en-
ergyprinciple.arXiv:2002.04501[q-bio](Feb2020),http://arxiv.org/abs/2002.
04501, arXiv: 2002.04501
22. Fritz, T.: A synthetic approach to Markov kernels, conditional independence and
theorems on sufficient statistics. Advances in Mathematics 370, 107239 (Aug
2020). https://doi.org/10.1016/j.aim.2020.107239, https://www.sciencedirect.
com/science/article/pii/S0001870820302656
23. Jacobs, B.: A channel-based perspective on conjugate priors. Math-
ematical Structures in Computer Science 30(1), 44–61 (Jan 2020).
https://doi.org/10.1017/S0960129519000082, https://www.cambridge.
org/core/journals/mathematical-structures-in-computer-science/
article/channelbased-perspective-on-conjugate-priors/
D7897ABA1AA06E5F586F60CB21BDDB32, publisher: Cambridge University Press
24. Jacobs, B.: A Channel-Based Perspective on Conjugate Priors. arXiv:1707.00269
[cs] (Sep 2018), http://arxiv.org/abs/1707.00269, arXiv: 1707.00269
25. Jacobs, B., Staton, S.: De Finetti’s Construction as a Categorical Limit. In:
Petri¸san, D., Rot, J. (eds.) Coalgebraic Methods in Computer Science. pp. 90–
111.LectureNotesinComputerScience,SpringerInternationalPublishing,Cham
(2020). https://doi.org/10.1007/978-3-030-57201-3 6
26. Knill, D.C., Pouget, A.: The Bayesian brain: the role of uncertainty in
neural coding and computation. Trends in Neurosciences 27(12), 712–719
(Dec 2004). https://doi.org/10.1016/j.tins.2004.10.007, https://www.cell.com/
trends/neurosciences/abstract/S0166-2236(04)00335-2, publisher: Elsevier
27. Kolchinsky, A., Wolpert, D.H.: Semantic information, autonomous agency and
non-equilibrium statistical physics. Interface Focus 8(6), 20180041 (Dec 2018).
https://doi.org/10.1098/rsfs.2018.0041, https://royalsocietypublishing.org/
doi/full/10.1098/rsfs.2018.0041
Interpreting Dynamical Systems as Bayesian Reasoners 11
28. Krakauer, D., Bertschinger, N., Olbrich, E., Flack, J.C., Ay, N.: The infor-
mation theory of individuality. Theory in Biosciences 139(2), 209–223 (Jun
2020). https://doi.org/10.1007/s12064-020-00313-7, https://doi.org/10.1007/
s12064-020-00313-7
29. Libby, E., Perkins, T.J., Swain, P.S.: Noisy information processing through tran-
scriptional regulation. Proceedings of the National Academy of Sciences 104(17),
7151–7156 (Apr 2007)
30. Ma,W.J.,Jazayeri,M.:Neuralcodingofuncertaintyandprobability.AnnualRe-
viewofNeuroscience37,205–220(2014).https://doi.org/10.1146/annurev-neuro-
071013-014017
31. McGregor, S.: The Bayesian stance: Equations for ‘as-if’ sensori-
motor agency. Adaptive Behavior p. 105971231770050 (Mar 2017).
https://doi.org/10.1177/1059712317700501, http://journals.sagepub.com/
doi/10.1177/1059712317700501
32. Nakamura, K., Kobayashi, T.J.: Connection between the Bacterial Chemotactic
Network and Optimal Filtering. Physical Review Letters 126(12), 128102 (Mar
2021).https://doi.org/10.1103/PhysRevLett.126.128102,https://link.aps.org/
doi/10.1103/PhysRevLett.126.128102
33. Orseau, L., McGill, S.M., Legg, S.: Agents and Devices: A Relative Definition
of Agency. arXiv:1805.12387 [cs, stat] (May 2018), http://arxiv.org/abs/1805.
12387, arXiv: 1805.12387
34. Parr, T., Da Costa, L., Friston, K.: Markov blankets, information geometry and
stochastic thermodynamics. Philosophical Transactions of the Royal Society A:
Mathematical,PhysicalandEngineeringSciences378(2164),20190159(Feb2020).
https://doi.org/10.1098/rsta.2019.0159, https://royalsocietypublishing.org/
doi/full/10.1098/rsta.2019.0159
35. Risken,H.,Frank,T.:TheFokker-PlanckEquation:MethodsofSolutionandAp-
plications. Springer Series in Synergetics, Springer-Verlag, Berlin Heidelberg, 2
edn. (1996). https://doi.org/10.1007/978-3-642-61544-3, https://www.springer.
com/gp/book/9783540615309
36. Rosas, F.E., Mediano, P.A.M., Biehl, M., Chandaria, S., Polani, D.: Causal Blan-
kets: Theory and Algorithmic Framework. In: Verbelen, T., Lanillos, P., Buckley,
C.L.,DeBoom,C.(eds.)ActiveInference.pp.187–198.CommunicationsinCom-
puter and Information Science, Springer International Publishing, Cham (2020).
https://doi.org/10.1007/978-3-030-64919-7 19
37. Smithe, T.S.C.: Bayesian Updates Compose Optically. arXiv:2006.01631 [math,
stat] (Jul 2020), http://arxiv.org/abs/2006.01631, arXiv: 2006.01631
38. St Clere Smithe, T.: Cyber Kittens, or Some First Steps Towards Categorical
Cybernetics. Electronic Proceedings in Theoretical Computer Science 333, 108–
124 (Feb 2021). https://doi.org/10.4204/EPTCS.333.8, http://arxiv.org/abs/
2101.10483v1
39. Still,S.,Sivak,D.A.,Bell,A.J.,Crooks,G.E.:Thethermodynamicsofprediction.
arXiv e-print 1203.3271 (Mar 2012), http://arxiv.org/abs/1203.3271, phys.
Rev. Lett. 109, 120604 (2012)
40. Wikipedia contributors: Conjugate prior — Wikipedia, the free encyclope-
dia (2021), https://en.wikipedia.org/w/index.php?title=Conjugate_prior&
oldid=1030202570, [Online; accessed 8-July-2021]
12 N. Virgo et al.
A Category-Theoretic Probability and String Diagrams
In this paper we use some concepts from category-theoretic probability, and in
particular we use a notation known as string diagrams. A full introduction to
thesetopicswouldbeoutofscopeofthepaper,butweincludehereaninformal
introduction to the topic. We do this because, to our knowledge, no concise
introduction currently exists that is focused on (classical) probability and does
not assume a background in category theory. We assume that the reader knows
the definition of a category, but not much more than that.
Appendix A.1 introduces the basic concepts, mostly in the context of dis-
crete probability. In appendix A.2 we briefly comment on how this extends to
the general case of measure-theoretic probability with very little extra work.
In appendix A.3 we explain how to reason about conditional probabilities and
Bayes’ theorem within this category-theoretic context.
These sections contain no original material. Their purpose is to give the
reader enough information to be able to read the string diagram equations in
the main text and later sections of the appendix without needing to consult a
category theory text. However, they are intended neither as an authoritative
technical reference nor as a comprehensive review, and readers should consult
the cited references for full details.
A.1 Introduction to String Diagrams and Category-Theoretic
Probability
A full technical introduction to the use of string diagrams in probability can
be found in [22] or the earlier [13], but these works require some knowledge of
categorytheory.Thestringdiagramnotationpredatesitsuseinprobabilityand
has many other applications. One could consult [4,14,18,15] for tutorial intro-
ductions to diagrammatic reasoning in other fields, of various different flavours.
Here we present it somewhat informally and only in the context of probability.
It should be kept in mind that, despite our somewhat informal introduc-
tion, string diagrams are formal expressions. The main difference between them
and the more familiar kind of mathematical expression formed from strings of
symbols is their two-dimensional syntax. This makes it easier to express cer-
tain concepts. (Particularly those relating to joint distributions, in the case of
probability.)
Weusetheso-calledMarkov category approachtoprobability[22].Themain
idea here is to express everything in terms of measurable spaces and Markov
kernels, whose definitions we outlined in the main text.2 To explain how the
2 Infactformostofthepaperwewillworkmuchmoreabstractlythanthis.Itwould
bemorecorrecttosay“objectsinaMarkovcategory”whereverwesay“measurable
space” and “morphisms in a Markov category” wherever we say “Markov kernel,”
since for most of the paper we will reason at the category level, and we will not
directly invoke the definition of a measurable space. We have chosen to use the
more concrete terms because they express a clear intuition for how these objects
and morphisms are intended to be interpreted.
Interpreting Dynamical Systems as Bayesian Reasoners 13
framework works, let us consider the special case where the only measurable
spaces we are interested in are finite sets (with their power sets as their σ-
algebras).IfAandBarefinitesetsthenaMarkovkernelcanbethoughtofasjust
a function f: A → P(B), where P(B) is the set of all probability distributions
over B. (The set P(B) may be thought of as a (|B|−1)-dimensional simplex,
consistingofallthosevectorsinR|B| whosecomponentsareallnon-negativeand
sum to 1.) Such a function amounts to a |B|-by-|A| stochastic matrix, although
somecareneedstobetakenoverwhichrowscorrespondtowhichelementsofB
and which columns to which elements of A.
Inthisfinitecase,wewritef(b a)todenotetheprobabilitythatthekernelf
assignstotheoutcomeb∈B whengiventheinputa∈A.Weuseathickvertical
line to indicate a close relationship to conditional probability while also empha-
sising that the concept is different: given a kernel f: A → P(B) the quantities
f(b a) are always defined, regardless of whether any probability distribution
has been defined over A, and regardless of whether a has a nonzero probability
according to such a distribution. More common notations include | or ; in place
of .
Wealsowritef(a)fortheprobabilitydistributionoverB thatthefunctionf
returns when given the input a. We could say that f(b a) is defined as f(a)(b).
Given Markov kernels f: A → P(B) and g: B → P(C), we can compose
them to form a new kernel of type A→P(C). We write this f g. It is given by
(cid:35)
(cid:88)
(f g)(c a)= f(b a)g(c b). (8)
(cid:35)
b∈BY
Inthisfinitecasethisissimplymatrixmultiplication,andwecouldhavedenoted
itgf insteadoff g accordingly.(Anothercommonnotationisg◦f.)Weprefer
f g because it pu(cid:35)ts f and g in the same order that they will appear in string
dia(cid:35)grams.
It is straightforward to show that composition is associative, that is
(f g) h=f (g h). (9)
(cid:35) (cid:35) (cid:35) (cid:35)
In addition, for every finite set A there is an identity kernel, which amounts
to just the |A|-by-|A| identity matrix. We write this as id and define it by
A
id (a(cid:48) a)=δ . For every Markov kernel f: A→P(B) we have
A a,a(cid:48)
id f =f =f id . (10)
A B
(cid:35) (cid:35)
These two facts mean that there is a category whose objects are finite sets
and whose morphisms are Markov kernels between finite sets. This category is
called FinStoch.
SinceMarkovkernelsaremorphismsinacategory,wewilloftenwritef: A→•
B instead of f: A→P(B), using the dotted arrow →• to distinguish morphisms
inFinStochandrelatedcategoriesfromordinaryfunctions.(Inthemaintextwe
continue writing them as functions in order to avoid introducing new notation.)
ThecompositionofMarkovkernelscanbegeneralisedtothecaseofmeasure-
theoreticprobability,whichallowsustoreasonaboutcontinuousprobabilityand
14 N. Virgo et al.
moregeneralprobabilitymeasuresusingthesamekindsofdiagramandmuchof
the same reasoning. We briefly discuss this in more detail in appendix A.2. The
main difference is that composition becomes integration over measures rather
than summation.
Probability measures themselves may be seen as a special case of Markov
kernels. Consider a set with a single element, denoted 1={(cid:63)}. (The identity of
theelementdoesnotmatterbecauseallone-elementsetsareisomorphictoeach
other. Category theorists often speak of “the one-element set” for this reason.
We use a star to denote the element.) Then a Markov kernel p: 1 →• A is a
function p: 1 → P(A), which takes an element of 1 and returns a probability
measure over A. Since there is only one element of 1 this means that the kernel
ponlydefinesasingleprobabilitymeasureoverA.WethereforethinkofMarkov
kernels 1→• A and probability measures over A as essentially the same thing.
We now begin to introduce the string diagram notation. A Markov kernel
f: A→• B will be denoted
A f B (11)
.
Thisexpressionmeansmuchthesamethingasthenotationf: A→• B.Itisjust
a formal symbol denoting the kernel f, annotated with type information.
The composition of kernels f: A→• B and g: B →• C is written
A f g C = A f B g C (12)
.
(cid:35)
The left and right hand side of this equation are just two different ways to
write the composite kernel f g, as defined by eq. (8) or its measure-theoretic
generalisation. (cid:35)
In reading a diagram like the right-hand side of eq. (12) we find it helpful
to imagine an element of A travelling along the wire from the left. As it passes
through the kernel f it is stochastically transformed into an element of B, in a
way that might depend on its original value. It then travels further to the right
and is stochastically transformed by g into an element of C. Equation (8) can
be seen as describing this process.
In string diagrams a special notation is used for identity kernels (or identity
morphisms more generally): an identity kernel id is drawn simply as a wire
A
with no box on it,
A . (13)
For any Markov kernel f: A→• B the identity law eq. (10) can then be written
A f B = A f B
(14)
= A f B
.
This allows us to think of the wires as stretchy: we can extend and contract
them at will. We will think of the wires as continuously deformable, rather than
extendingandcontractingindiscreteunits.Thisisjustifiedbytheformaltheory
of string diagrams. (One may informally think of the wire itself as an infinite
Interpreting Dynamical Systems as Bayesian Reasoners 15
chain of identity kernels, all composed together.) This ability to continuously
deform diagrams turns out to be an extremely powerful and useful idea.
Another special notation is used for one-element sets3: they are drawn as
no wire at all. For this reason a probability measure over A, that is, a kernel
p: 1→• A, is drawn as
p A (15)
.
(Morphisms of this kind are sometimes known as “states,” and they are often
drawn as a triangle rather than a box, though here we draw them in the same
style as other morphisms.)
It is worth noting that the kernels p and f above can be composed, yielding
p f B = p A f B (16)
.
(cid:35)
Because of this, although the kernel f: A→• B is defined as a function f: A→
P(B) mapping elements of A to probability distributions over B, we can in-
stead choose to see it as mapping probability measures over A to probability
measures over B. Inthe finitecase, ifwethink offinite probabilitydistributions
asnormalisedandnonnegativevectorsinRn,thenf canbeseenasalinearmap
withthepropertythatitmapspointsinonesimplextopointsinanother.(This
justifies thinking of it as a stochastic matrix.)
The string diagram notation becomes useful when we start thinking about
joint distributions. We do this by drawing wires in parallel. As an example, we
can consider a Markov kernel defined by a function h: A×B → P(C ×D).
This function takes two arguments, an element of A and an element of B, and
it returns a joint probability distribution over C and D. In string diagrams we
write this as
B D
(17)
A h C
.
In symbols, we write h: A⊗B →• C ⊗D. An object like A⊗B, drawn as two
parallel wires, can either be thought of as the measurable space A×B (which
is the Cartesian product of sets in the finite case), or as the space of probability
measures over A×B. The symbol ⊗ is referred to as a monoidal product.
There is some inherent ambiguity in this notation. If we draw three parallel
wires, B C ,itcouldeithermean(A⊗B)⊗C orA⊗(B⊗C).Inthefinitecase,
A
these correspond to the sets (A×B)×C and A×(B×C). These are different
sets, since one is composed of pairs ((a,b),c) and the other of pairs (a,(b,c)).
Thisambiguityisnotimportantinpractice,however,andtheformalmachinery
of monoidal categories allows us to use string diagrams without worrying about
it. We do not give a formal treatment of this here. (A concise summary can be
found in [4].) Instead we simply remark that when we draw three parallel wires
we think of joint distributions over A, B and C, and the precise distinction
between P(A×(B×C)) and P((A×B)×C) will not be important to us.
3 or in a more general context, the unit object of a monoidal category
16 N. Virgo et al.
Inasimilarvein,thespacesAandA⊗1aredifferent,butthedifferenceisnot
important to us, and in fact they are written the same way in string diagrams.
This is because we draw 1 as an invisible wire. This also allows us to write
B
B = = B (18)
A A A .
That is, string diagrams are stretchy in the vertical direction as well as the
horizontal one. We can bend the wires, as long as we don’t deform them so
much that they point backwards, from right to left.
This also allows to write things like
C
A (19)
f
B
for a kernel f: A→• B⊗C.
Wecanalsodrawmorphisms(i.e.Markovkernels)inparallelwitheachother,
for example,
C g D
(20)
A B
f
.
Wewritethisinsymbolsasf⊗g,whichisamorphismoftypeA⊗C →• B⊗D.
In the finite case, it is given by
(f ⊗g)(b,d a,c)=f(b a)g(d c). (21)
The probabilities f(b c) and g(d c) are multiplied together because the two
Markov kernels are operating in parallel. One can imagine an element of A en-
tering from the bottom left and being stochastically transformed by f into an
element of B, while in parallel, and independently, an element of C enters from
the top left and is stochastically transformed by g into an element of D. In
general, in the finite case, f ⊗g is given by the tensor product of the stochas-
tic matrices that represent f and g. (This might give some intuition for the
symbol ⊗.)
Wecancrosswiresovereachother.(Incategorytheoryterms,thecategories
we are concerned with are symmetric monoidal categories.) The diagram
B A
(22)
A B
can be seen as a Markov kernel A⊗B →• B⊗A. In the finite case it is defined
by
swap (b(cid:48),a(cid:48) a,b)=δ δ . (23)
A,B a,a(cid:48) b,b(cid:48)
We have a number of equations that are standard in monoidal category the-
ory, and allow us to freely slide boxes along wires and bend wires to cross over
each other. These can either be shown directly from the definitions above or
(perhaps more usefully) deduced from the definition of a symmetric monoidal
Interpreting Dynamical Systems as Bayesian Reasoners 17
category. Three such equations are as follows. More details can be found in the
references cited above.
B B B B
= (24)
A A A A
C g D C g D
= (25)
A f B A f B
C B = C f B (26)
A f C
A C
So far, everything we have said about string diagrams applies to any sym-
metric monoidal category. However, there are two additional things we can add
that take us much closer to probability theory. These are the ability to copy
and to delete. These operations, and their special properties, do not necessarily
exist in other contexts, such as quantum mechanics. This is a central point of
[4,14]. We will stick to the context of classical probability, however, so copying
and deletion will always be possible in this paper.
Wecoverdeletionfirst.ForeverymeasurablespaceAthereisauniquekernel
oftypeA→1,whichwecalldel .Inthefinitecaseitisgivenbydel ((cid:63) a)=1
A A
for all a∈A. We can think of this as a 1×|A| matrix (i.e. a row vector) whose
entries are all 1. This is the only possible 1×|A| stochastic matrix.
In string diagrams we write such a deletion kernel as a black dot:
A . (27)
Thereisonesuchmorphismforeverymeasurablespace,butwedenotethemall
with the same kind of black dot. These black dots have the property that
A f B = A (28)
foreveryMarkovkernelf.ThissaysthatifwetakesomeinputA,performsome
stochasticoperationf onitandthendeletetheresult,thisisthesameassimply
deleting the input.4
Thesecondspecialoperationiscopying.ForeverymeasurablespaceAthere
isakernelcopy : A→A⊗A,whichwewilldescribeshortly.Wewritethisalso
A
as a black dot, but this time with two output wires rather than one.
A
A (29)
A.
Informally, this kernel takes an outcome a ∈ A and copies it, producing a pair
(a,a)ofidenticalvalues.It’s importanttonotethatit copiesvalues ratherthan
4 In category theory terms, this means that the set of all delete kernels collectively
formsanaturaltransformation.(Specifically,itisanaturaltransformationfromthe
identityfunctortothefunctorthatsendsallobjectsto1andallmorphismstoid1.)
For this reason this property of delete kernels is called “naturality.”
18 N. Virgo et al.
distributions. Its output does not consist of two independent and identically
distributedelementsofAbutrathertwoperfectlycorrelatedelementsofAthat
always have the same value. In the discrete case the copy map is defined as
(cid:40)
1 if a(cid:48)(cid:48) =a(cid:48) =a
copy (a(cid:48)(cid:48),a(cid:48) a)= (30)
A 0 otherwise.
Inadditiontoeq.(28),thecopyanddeletemapsobeythefollowingproperties
[22, definition 2.1]:
A A
= A A (31)
A A
A A
A
A = A = A (32)
A
A A
A = A (33)
A A
B
A⊗B = (34)
A
B
A⊗B A
A⊗B = B (35)
A
A⊗B B
A
Equation (31) says that if we make multiple copies of something it doesn’t
matter which order we make them in. Equation (32) says that if we copy some-
thing and then delete one of the copies, that is the same as doing nothing to it.
Equation(33)saysthatifwecopysomethingandthenswapthecopiesitmakes
no difference. (Because the two copies are the same as each other.)
Equations(34)and(35)aremoretechnical.Theysaythatifwehaveelements
ofAandB wecandeleteorcopythemasasingleelementofA⊗B orseparately,
as elements of A and B, and these should give the same result.
These equations can be derived from the definitions we have given for the
finite case. They may also be derived in various more general measure-theoretic
contexts [13,22].
However, the approach of [22] is instead to treat them as axioms: any sym-
metricmonoidalcategorywithcopyanddeletemapsthatobeyeqs.(28)and(31)
to (35) is called a Markov category. One can do a surprising amount of reason-
ing about probability theory using these axioms alone, although there are also
Markov categories that do not directly resemble the category of measurable
spaces and Markov kernels that we have described. There are various additional
axioms that can to be added as well, which then allow more specific results to
be proven. (See [22] for the details.)
An important thing to note about the copy operator is that, in general,
B f B
A f B (cid:54)= A A (36)
B f B .
Interpreting Dynamical Systems as Bayesian Reasoners 19
Thatis,copyingtheoutputofakernelf isnotthesameascopyingitsinputand
thenapplyingtwocopiesofthekerneltoit.Intuitively,thisisbecausef mightbe
stochastic.Ifwecopytheoutputweendupwithtwoperfectlycorrelatedcopies,
whereas if we copy the input then the stochastic variations will be independent.
However, if the kernel is deterministic then copying its input is indeed the
same as copying its output. In fact, in the Markov category framework this is
the definition of a deterministic Markov kernel: we say a kernel h: A → B is
deterministic if
B h B
A h B = A A (37)
B h B .
Inthispaperweusesquareboxesforkernelsthatareknowntobedeterministic,
and boxes with rounded edges for general, possibly-stochastic kernels.
In the main text, we write Markov kernels as functions f: A → P(B), and
we write deterministic kernels as functions f: A → B. To be more precise,
a deterministic kernel should really also be considered as a function f: A →
P(B), such that eq. (37) is obeyed. However, if we assume we are working in a
categorycalledBorelStoch(whichisacommonassumptionincategory-theoretic
probability) then eq. (37) implies that f always returns a delta measure [22,
example10.5],andinthiscasethereisnotmuchharmintreatingadeterministic
kernel f as a function f: A→B.
A.2 The extension to measure theory
AbovewedescribedthecategoryFinStochandintroducedstringdiagramsmostly
in that context. Here we briefly describe how this generalises to the measure-
theoretic case, which is needed in order to think about continuous probability.
In the measure-theoretic case the objects (X, Y, etc.) are any measurable
spaces rather than only finite sets. Markov kernels are still functions f: X →
P(Y), but now P(Y) is the set of all probability measures on the measurable
space Y. (That is, P(Y) is the set of all functions from the σ-algebra associated
with Y to [0,1], such that Kolmogorov’s axioms are obeyed.) P(Y) can itself
be made into a measurable space in a standard way, and the function f must
obey an additional restriction that it be a measurable function. (This means
that the preimage of every element of P(Y) must be a member of the σ-algebra
associated with X.)
In this case f(x) is a probability measure rather than a probability distri-
bution, and composition is given by integration rather than summation. (See
[22, example 4] for the details.) This gives rise to a category called Stoch, whose
objects are all measurable spaces and whose morphisms are all Markov kernels.
(This category is also known as the Kleisli category of the Giry monad, for
reasons we do not discuss here.)
Unfortunately the category Stoch does not have all of the properties that
onemightwantittohave.(SeeappendixA.3below.)Becauseofthisacommon
approachistoworkinacategorycalledBorelStoch(alsodiscussedin[22,example
20 N. Virgo et al.
4]),inwhichtheobjectsareasubsetofmeasurablespacescalledstandardBorel
spaces,andthemorphismsareallMarkovkernelsbetweenstandardBorelspaces.
Standard Borel spaces include many kinds of measurable space that one would
be likely to use in practice, and in particular they include both finite sets and
Rn with its usual σ-algebra.
In the present paper, the properties of BorelStoch are used in two ways.
Firstly, in BorelStoch we can always use conditionals, as explained in the next
section.Secondly,asanotationalconveniencewetreatdeterministickernelsand
measurable functions as interchangeable, which makes sense in BorelStoch but
doesn’t hold in the more general case of Stoch.
A.3 Conditionals and Bayes’ theorem
Conditional probabilities and Bayes’ theorem play central roles in the theory of
inference.Herewebrieflydiscusshowtheylookinstringdiagrams.Givenajoint
distribution q B wemaywanttosplititupintoaproductofamarginalanda
A
conditional,whichintraditionalnotation,inthediscretecase,wouldbewritten
p(a,b)=p(a)p(b|a).
The category-theoretic approach, as set out in [13,22], is slightly different.
We write the following, which is called a disintegration of q. (The term “disin-
tegration” is used because it is the opposite of integration.)
B
q B = q c B (38)
A A A.
Here, q isthemarginalofAaccordingtothejointdistributionq.Inthefinite
A (cid:80)
case it can be written b∈B q(a,b). The kernelA c B is called a conditional
of p. It is defined by eq. (38), which in the finite case can be written
(cid:32) (cid:33)
(cid:88)
q(a,b)= q(a,b(cid:48)) c(b a). (39)
b(cid:48)∈B
This is closely analogous to the identity p(a,b)=p(a)p(b|a). The difference
is that p(b|a) is defined as p(a,b)/p(a), and is only defined when p(a) > 0. On
the other hand, in eq. (39), if (cid:0)(cid:80) q(a,b(cid:48)) (cid:1) = 0 for some a ∈ A then q(a,b)
b(cid:48)∈B
must be 0 for all b ∈ B, and consequently the equation puts no constraint on
c(b a) in this case.
This means that instead of being undefined in this case, the conditional c
is not uniquely defined: there may be many different kernels c that satisfy the
equation.
This carries over to the general measure-theoretic case as well. If we are in
thecategoryBorelStochthenforanyjointdistribution q B thereexistsatleast
A
oneconditionalA c B thatsatisfieseq.(38),buttheremightbemany.(Inthe
case of Stoch conditionals may fail to exist at all, see [22, example 11.3].)
Interpreting Dynamical Systems as Bayesian Reasoners 21
We may also want to disintegrate a joint distribution that is a function of
some parameter, e.g. Z q B. In this case eq. (38) becomes
A
B c B
Z q A = Z q B A A. (40)
Conceptually this is very similar. We want the disintegration to hold for every
parameter value z ∈ Z, and we define the conditional to be a function of z
as well as of a ∈ A. In the discrete case, eq. (40) is analogous to the identity
p(a,b|z)=p(a|z)p(b|a,z).
Bayes’ theorem is closely related to conditional probability and can be ex-
pressedinasimilarway.Givenaprior q AandakernelA f B,wecandefine
a Bayesian inverse of f with respect to q, which is a kernelB f† A such that
B
B
f
q A A = q A f B f† A (41)
.
The Bayesian inverse f† depends on the prior q as well as on the kernel f. If we
had chosen a different distribution in place of q, the Bayesian inverse f† would
be different. As with conditionals, Bayesian inverses are not necessarily unique,
and for a given f and q there may be many kernels f† that satisfy eq. (41). (In
fact, Bayesian inverses can be seen as a special case of conditionals.)
Wemayalsoconsiderthecasewherethepriortakesaparameter,e.g.Z q A.
InthiscaseaBayesianinverseingeneralalsoneedstodependontheparameter,
which gives us the following more general definition:
B
B
f
Z q A A = Z q A f B f† A (42)
.
Thereferences[13,22,37]containmuchmoredetailaboutBayes’theoreminthis
form.
B More details about Bayesian interpretations
B.1 Unpacking Bayesian filtering interpretations
In this section we give some more intuition for definition 2 and then note some
consequencesofit.ThesectiondealsmostlywiththecasewhereS,Y andH are
discrete sets, meaning that we can reason in terms of probability distributions
rather than measure theory. In this case definition 2 can be written in a form
that makes the relationship to Bayes’ theorem more clear. We define a notion
of subjectively impossible input, which is a value of S that the reasoner believes
with certainty will not occur as its next input. (This does not imply that the
inputactuallyisimpossibleaccordingtothetruedynamicsoftheenvironment.)
22 N. Virgo et al.
We show that definition 2 puts no constraints on the reasoner’s posterior after
receiving a subjectively impossible input.
We also show that the possible interpretations of a machine only depend on
whichstatescantransitiontowhichotherstatesgivenwhichinputs,andnoton
the probabilities of such transitions. In addition, we show that some machines
admit no non-trivial interpretations at all.
In order to unpack definition 2 a little more, let us consider the case where
S, Y and H are discrete. Before starting we note that in the finite case, the
definition of ψ , eq. (4), can be written as
S
(cid:88)
ψ (s y)= ψ (s,h y). (43)
S S,H(cid:48)
h∈H
In this case, eq. (5) can be written in symbols as
ψ (h,s y)γ(y(cid:48) y,s)=ψ (s y)γ(y(cid:48) y,s)ψ (h y(cid:48)), (44)
S,H(cid:48) S H
for all s ∈ S,h,∈ H,y,y(cid:48) ∈ Y. We can cancel γ(y(cid:48) y,s) from both sides on the
assumption that it is positive, yielding
γ(y(cid:48) y,s)>0 =⇒ ψ (h,s y)=ψ (s y)ψ (h y(cid:48)). (45)
S,H(cid:48) S H
The condition γ(y(cid:48) y,s) > 0 means that y(cid:48) ∈ Y is a possible next state
when the machine starts in state y ∈ Y and receives the input s ∈ S. (There
may be many possible next states in this situation because the machine may be
stochastic.)
Let us then suppose that the machine starts in state y, receives an input s,
and transitions to state y(cid:48). Let h be an arbitrary element of H. The number
ψ (h,s y) ∈ [0,1] can then be seen as the reasoner’s prior probability that
S,H(cid:48)
the next state is h and the next input is s. In more traditional notation we
mightwritethisasP(H(cid:48) =h,S =s),whereweleavethestateoftheunderlying
machine implicit. (Here we do not attempt to formalise this in terms of random
variables,butsimplytreatitasakindofnotationalshorthandforψ (h,s y).)
S,H(cid:48)
Wemaythenregardψ (s y)asthereasoner’spriorprobabilitythatthenext
S
(cid:80)
input is s, i.e. P(S =s)= P(H =h,S =s).
h∈H
However,sinceψ (h y(cid:48))isconditionedony(cid:48)ratherthany,weinsteadregard
H
it as the reasoner’s posterior probability that H(cid:48) = h. (We refer to H(cid:48) rather
than H here because after it receives an input its previous “next” hidden state
becomes its current hidden state.)ψ (h y(cid:48)) therefore corresponds to what we
H
might write as P(H(cid:48) =h|S =s).
With this informal shorthand notation eq. (45) then says
P(H(cid:48) =h,S =s)=P(S =s)P(H(cid:48) =h|S =s), (46)
whichhasthesameappearanceasafamiliaridentityfromelementaryprobability
theory. It corresponds to a single step of Bayesian filtering, which we spell out
in more detail in appendix B.2.
Interpreting Dynamical Systems as Bayesian Reasoners 23
This shorthand notation gives some intuition for why eq. (5) has the partic-
ular form it does, but it leaves the dependence on the state of the underlying
machine implicit, and in so doing it obscures an important and subtle point. In
a more traditional context, P(H(cid:48) =h|S =s) is defined by
P(H(cid:48) =h|S =s)=P(H(cid:48) =h,S =s)/P(S =s) (47)
and has no value when P(S = s) = 0. However, in our case P(H(cid:48) = h | S = s)
is a shorthand for ψ (h y(cid:48)), which is defined even when ψ (s y)=0.
H S
In the case where P(S = s) > 0, eq. (5) in the form of eq. (46) demands
that P(H(cid:48) = h | S = s) is indeed equal to P(H(cid:48) = h,S = s)/P(S = s). More
precisely,ifψ (s y)>0thenwemusthaveψ (h y(cid:48))=ψ (h,s y)/ψ (s y).
S H S,H(cid:48) S
However,ifψ (s y)=0theneq.(5)putsnoconstraintsonψ (h,s y)atall,
S S,H(cid:48)
or indeed on ψ (h y).
H
In the case where S is a discrete set (even if Y and H are not discrete),
we say that s ∈ S is a subjectively impossible input for a given state y ∈ Y if
ψ (s y)=0. The point is that the reasoner believes, with certainty, that it will
S
not receive the input s as its next input. The reasoning above says that in this
situation,any posterioroverH isacceptable,becauseBayes’ruledoesn’tspecify
what the posterior should be. We find this somewhat analogous to the fact that
inlogiconecandeduceanypropositionfromacontradiction.Definition2indeed
permits any posterior in the case of a subjectively impossible input. In fact, it
even allows the posterior to be chosen stochastically in this case.
This is in a sense the minimal possible assumption we could make. How-
ever, one could imagine addressing the issue in a different way by changing the
framework, thus introducing a subtly different notion of interpretation than the
one we have presented here. One possibility would be to allow partial interpre-
tations, where ψ becomes a partial function, meaning that not every state of
H
the machine needs to have an interpretation at all. This would allow the poste-
rior to be undefined in the case of a subjectively impossible input, rather than
merely arbitrarily defined. Another possibility would be to strengthen eq. (5)
with additional conditions, forcing the posterior to be meaningful even after a
subjectively impossible input. We suspect that such an approach can lead to an
interestingwaytoformaliseimproperpriors,whicharealsoabouthavingmean-
ingful posteriors in the case of ‘impossible’ inputs, but we leave investigation of
this to future work.
We note one other important consequence of the above reasoning, in the
discrete case. When we express eq. (5) in the form of eq. (45), we see that it
only depends on whether a transition from y to y(cid:48) is possible given an input
s, and not on the probability of such a transition. Thus, for Bayesian filtering
interpretations (and hence also for Bayesian inference interpretations), the only
property of a machine that matters is which states can be reached from which
other states (in a single step) under a given input. (Strictly speaking this only
makes sense in the discrete case, but we expect an analogous statement to this
to hold more generally.)
24 N. Virgo et al.
Finally we note another consequence: eq. (45) implies that if γ(y(cid:48) y,s) > 0
for every y,y(cid:48),s, then
ψ (h,s y)=ψ (s y)ψ (h y(cid:48)), (48)
S,H(cid:48) S H
for all y,y(cid:48) ∈ Y,s ∈ S,h ∈ H. Note that for any given y ∈ Y there must exist
somes∈Ssuchthatψ (s y)>0.Itfollowsthatψ (h y(cid:48))mustbeindependent
S H
of y(cid:48) in this case. In other words, if a machine is such that γ(y(cid:48) y,s) > 0 for
all y,y(cid:48),s then it only admits trivial interpretation maps, in which the beliefs
arethesameforeverystate.Thereforetheexistenceofany non-trivialBayesian
filtering interpretation implies a fairly strong constraint on a discrete machine’s
dynamics, namely that some of its transition probabilities are zero.
B.2 More on Bayesian filtering
In this section we show that definition 2 does indeed correspond to Bayesian
filtering, at least in the case of a deterministic machine. Our proof of this is
inspired by [24, theorem 6.3], which proves an analogous fact about conjugate
priors. The proof we give uses string diagram reasoning, which means that it
holds even in the most general measure-theoretic context; we do not need to
assume that the sets involved are discrete.
Since we restrict ourselves to only deterministic machines in this section, we
will note a couple of things about deterministic machines before we talk about
Bayesian filtering.
We first note that the condition for a machine γ to be deterministic is
(49)
.
This comes from the defining equation for deterministic morphisms, eq. (37),
and also the axiom (35), noting that γ is a kernel with input S⊗Y and output
Y.
Next we prove the following proposition, which is useful for reasoning about
Bayesian filtering interpretations of deterministic machines.
Proposition 1. Suppose Y S γ Y is a deterministic machine, and letY ψ H H
and H κ H be arbitrary Markov kernels. Then ψ and κ form a consistent
S H
Bayesian filtering interpretation of γ (i.e. definition 2 is satisfied) if and only if
(50)
,
with ψ and ψ as defined in eqs. (3) and (4).
S,H(cid:48) S
Interpreting Dynamical Systems as Bayesian Reasoners 25
Proof. To see that definition 2 implies eq. (50) we marginalise eq. (5):
(51)
.
This implies eq. (50) by the rules for Markov categories, specifically eqs. (28)
and (32).
For the other direction we assume eq. (50) holds and calculate
(52)
.
The first step substitutes in the right-hand side of eq. (50), the second rear-
ranges using the rules of Markov categories, and the third uses the determinism
condition. This proves that eq. (5) holds.
WenowconsiderwhataBayesianfilteringtaskinvolves.Theideaisthatthe
reasoner has a model of a hidden Markov process, given by the kernel H κ H.
S
As described in the main text, this kernel can be thought of as a process that
simultaneously transforms the hidden state, stochastically, into a new value and
emits a visible “sensor value.”
Given a kernel of this type, we can iterate it to produce sequences of values
in S. For example, we can write
H H
H κ κ κ H
H κ3 H = (53)
S
S3 S
S,
where S3 means S⊗S⊗S and κn is notation for iterating the kernel n times.
A kernel of this kind, thought of as an infinitely iterated process, is sometimes
26 N. Virgo et al.
called a “coalgebra,” since it is a special case of a more general concept of that
name. (e.g. [25] takes a coalgebraic approach to de Finetti’s theorem.)
For filtering we are interested in inferring the final hidden state of a system,
given a finite sequence of visible states. In order to reason about this, we define
the following kernel:
(54)
.
This can be seen as an interpretation map, mapping the state of a reasoner to
its beliefs about its next n inputs, Sn =(S ,...,S ), along with the final value
1 n
of the hidden state, H . These take the form of a joint distribution between Sn
n
and H . This joint distribution is formed from the reasoner’s initial prior over
n
the initial hidden state H (given by the kernel ψ ) and the model κ, which is
1 H
iterated n times.
We define this because in filtering we wish to make a probabilistic inference
of the final hidden state, H , given the sequence of visible states Sn. To infer
n
H given Sn we seek a disintegration of ψ . (See eq. (38) in appendix A.3.)
n Sn,Hn
Specifically, we seek a kernel ψ : Sn⊗Y →P(H) such that
Hn|Sn
(55)
.
The kernel ψ takes in a sequence Sn of observations and returns the rea-
Hn|Sn
soner’s conditionalbeliefsabout H , giventhe sequence S . Itis alsoa function
n n
of the reasoner’s initial beliefs y ∈Y.
In fact such a kernel can be constructed iteratively in a natural way, if we
assumethatψ andκformaconsistentBayesianfilteringinterpretation.Todo
H
this, we first define the iteration of γ, in a similar way to the iteration of κ:
(56)
,
where there are n copies of γ on the right-hand side. We can then state the
following result, which shows that consistent Bayesian filtering interpretations
can indeed be seen as performing Bayesian filtering, in the discrete case.
Proposition 2. The kernel S Y n γn Y ψ H H is a conditional of ψ Sn,Hn , satis-
fying eq. (55), in that
(57)
.
Interpreting Dynamical Systems as Bayesian Reasoners 27
Proof. We begin by defining the kernel
(58)
.
We also define its iteration, (ψ¯ )n: Y →Y ⊗Sn, analogously to κn and γn. We
S
notethattheconsistencyequationforBayesianfilteringinterpretations,eq.(5),
can be written in terms of κ and ψ¯ , as
S
(59)
.
We then calculate
(60)
,
28 N. Virgo et al.
wherethelaststepisbyapplyingtheotherstepsinductively.Wecanthenapply
a second inductive argument in “the other direction” using eq. (50), as follows:
(61)
,
where the last step is again by applying the other steps inductively.
Wehaveprovedthat S Y n γn Y ψ H H isaconditionalof ψ Sn,Hn .Thekernel
Sn γn Y ψ canbethoughtofasgivingthereasoner’sbeliefsaboutH after
Y H H
receivingagivensequenceSn ofinputs,startingfromagiveninitialstatey ∈Y.
The result shows that these beliefs are consistent with the agent’s prior ψ (y)
H
andthemodelκ,inthesensethattheagent’sfinalposteriorbeliefsaboutH area
conditional of its initial joint beliefs about the sequence Sn and the final hidden
state. We conclude that a deterministic machine with a consistent Bayesian
filtering interpretation can indeed be seen as performing a Bayesian filtering
task. We expect this to be true in the general case of stochastic machines as
well.
B.3 Bayesian inference interpretations and conjugate priors
In the main text we noted that Bayesian inference corresponds to a special case
of Bayesian filtering. By “Bayesian inference” here we mean the case where
the reasoner is interpreted as assuming its inputs are i.i.d. samples from some
knowndistributionwithanunknownparameterspaceH,whichwealsocallthe
hypothesis space.
Thedifferencebetweeninferenceandfilteringisthatweinterpretthereasoner
as believing that the value of H is unknown but fixed. That is, the reasoner
Interpreting Dynamical Systems as Bayesian Reasoners 29
assumes that H doesn’t change over time. This corresponds to a special case of
filtering in which H κ H = H H, for some kernel φ that we also call the
S φ S
model.
Whileκcanbeseenasamodeloftheenvironment’sdynamics,φhasmoreof
thecharacterofastatisticalmodel.Itisamodelofhowtheagent’ssensorvalues
depend on the unknown value of the hidden parameter H. However, we do not
putanyconstraintsonthehypothesisspaceH orthemodelφ.Inparticular,we
do not assume that φ is an injective function H →P(S), and we allow the case
where H is a finite set.
In the case of inference rather than filtering, the kernels ψ and ψ from
S S,H(cid:48)
eqs. (3) and (4) can be written
Y ψ S = Y ψ H φ S (62)
S H
and
H
H
Y ψ S,H S = Y ψ H H S (63)
φ
.
We write ψ instead of ψ because in the i.i.d. inference case there is only
S,H S,H(cid:48)
onehiddenvariable,thatis,H(cid:48) =H.Thus,thejointdistributionψ (y)canbe
S,H
seenasthereasoner’sjointbeliefaboutitsnextinputandthehiddenvariableH,
whenitsunderlyingmachineisinstatey.TheconsistencyequationforBayesian
inference, eq. (6), then follows by substituting these for ψ and ψ in eq. (5),
S,H(cid:48) S
the consistency equation for Bayesian filtering interpretations.
As with Bayesian filtering interpretations, it is useful to consider the case in
which the underlying machine is deterministic (but not necessarily discrete). In
proposition1wegaveasimplerversionoftheconsistencyequationforBayesian
filtering interpretations, which is equivalent to definition 2 in the case of a de-
terministic machine. In the inference case we can substitute eqs. (62) and (63)
into this simplified consistency equation (eq. (50)) to obtain
S
S
φ
Y ψ H H H = Y ψ H H φ S γ Y ψ H (64)
H .
This is exactly the equation given by [24, eq. 16] as a definition of a conjugate
prior.
Both sides of eq. (64) express a joint distribution between S and H, as a
function of Y. In the context of conjugate priors, φ is considered to be a family
of distributions, with parameters H. Our interpretation map ψ corresponds to
H
another family of distributions, which is a conjugate prior to φ. The machine
stateY correspondstotheso-calledhyperparameters,i.e.theparametersofψ .
H
This shift in perspective makes sense. In a computational context, conjugate
priors are often useful precisely because they offer a way to perform inference
withoutneedingtodirectlycalculateBayesianinversesatrun-time.Instead,the
implementation only needs to keep track of the hyperparameters and update
30 N. Virgo et al.
them in response to data. This update takes place according to a deterministic
function, whose form depends on the family φ and its conjugate prior ψ . This
H
updating of the hyperparameters is the role played by γ: it takes in a data
point in S along with the current value of the hyperparameters, and returns the
updated hyperparameters. Equation (64) asserts that this must done in such a
way that the new value of Y does indeed correspond to the correct Bayesian
posterior, when mapped to a distribution over H by the kernel ψ .
H
We note that it is somewhat nontrivial to find a pair of kernels ψ , φ and a
H
functionγsuchthateq.(64)isobeyed.However,manysuchexamplesareknown.
(Althoughitisnotanauthoritativesource,ausefullistcanbefoundonline[40,
under“Tableofconjugatedistributions”],whichexplicitlygivesbothkernelsand
theupdatefunctionforeachexample.)Anyexampleofaconjugatepriorcanbe
seen as a deterministic machine together with a consistent Bayesian inference
interpretation. In addition, in appendix C we give a number of examples of a
different flavour, in that in our examples H is either a finite or a countable set.
B.4 Unpacking Bayesian inference interpretations
Wenowunpackdefinition3byconvertingeq.(6)intomorefamiliartermsinthe
case where all the spaces are discrete sets, as we did for filtering interpretations
in appendix B.1.
In the case where Y, H and S are finite sets, eq. (6) can be written as
ψ (h y)φ(s h)γ(y(cid:48) s,m)=ψ (s y)γ(y(cid:48) s,y)ψ (h y(cid:48)), (65)
H S H
or equivalently,
γ(y(cid:48) s,y)>0 =⇒ ψ (h y)φ(s h)=ψ (s y)ψ (h y(cid:48)), (66)
H S H
since we can cancel γ(y(cid:48) s,y) if we assume it is positive. For γ(y(cid:48) s,y) to be
positive means that it is possible for the machine to transition from state y ∈Y
to state y(cid:48) ∈Y after receiving the input s∈S.
We can now give an intuitive interpretation to the terms in this equation.
If the machine starts in state y, receives input s, and transitions to state y(cid:48) as
a result, then we can regard ψ (h y) as the reasoner’s prior beliefs about the
H
hypothesis h, ψ (s y) as its prior beliefs about the input s, and ψ (h y(cid:48)) as
S H
the reasoner’s posterior belief about the hypothesis h. Equation (66) can then
be compared, term by term, to the much more familiar equation
p(h)p(s|h)=p(s)p(h|s). (67)
Herewehavewrittenp(s|h)inplaceofφ(s h)andp(h|s)inplaceofψ (h y(cid:48))
H
in order to emphasise the similarity to Bayes’ theorem in a more familiar form.
Our definition, in the form of eq. (6) or eq. (65), differs from this in that it
explicitly takes account of the machine’s state, and φ and ψ are defined by
H
Markov kernels rather than conditional probabilities.
Interpreting Dynamical Systems as Bayesian Reasoners 31
We note that, as in the case of filtering (appendix B.1), our definition of
a consistent Bayesian inference interpretation allows the posterior to be arbi-
trary in the case of subjectively impossible inputs, i.e. those s ∈ S for which
(cid:80)
ψ (h y)φ(s h) = 0 for a given state y ∈ Y. Given such an input the
h∈H H
reasonermayupdateitsposteriortoanythingatall.Aswithfiltering,weregard
thisastheminimalassumptionwecouldhavemade,butwecanimagineseveral
other choices that one could make instead. These include allowing the posterior
to be undefined in such cases; requiring it to be undefined; requiring it to obey
some additional consistency equation such that the posterior would make sense
even on subjectively impossible inputs; or requiring φ and ψ to be such that
H
subjectively impossible inputs do not exist. We would consider these to be sub-
tly different kinds of interpretation, and we leave their further investigation to
future work.
C Details of examples
C.1 An Interpretation Of A Non-Deterministic Finite Machine
Weherepresentanon-deterministicfinitemachinewithinternalstatespaceY =
{y ,y ,y } and sensory input space S = {s ,s }. One Bayesian interpretation
0 1 2 1 2
s
2
s
1 y
1
s
2
s
y s 1
0 1
s
1
y
s 2
2 s
2
Fig.1. Transitions for a three-state machine. Deterministic transitions are depicted
usingboldarrows,andnon-deterministictransitionsusingregulararrows.Theprecise
probability values for non-deterministic transitions are not shown, since we only need
to know that they are non-zero.
of this machine, for a hidden state space H ={h ,h }, is as follows (where δ is
1 2
the Kronecker delta):
φ(s h )=δ
i j ij
(cid:40)
δ if j ∈{1,2} (68)
ψ(h y )= ij
i j
0.5 if j =0.
32 N. Virgo et al.
Under this interpretation, the model φ ascribed to the machine is that sensory
inputs transparently reflect the hidden state. The machine, in internal state y ,
0
is taken to be uncertain about the hidden state; in state y ∈{y ,y } it is taken
i 1 2
to be certain that the hidden state is h . The dynamics of the machine match
i
thisinterpretation:ittransitionsdeterministicallytoy whenreceivinginputs ,
i i
unless s is “subjectively impossible” (s at m , and s at m ). Behaviour on
i 2 1 1 2
subjectivelyimpossibleinputsisnotconstrainedbytheconsistencyequation,so
this is a consistent Bayesian interpretation.
C.2 Machine counting occurrences of different observations
Wenowconsideracountablyinfinitedeterministicmachine(Y ,S,γ ).LetY =
0 0 0
N+×N+ (N+ excludes 0) and the input space be S = {+1,−1}. The machine
deterministically computes the function f : (Y ×S) → Y , in the sense that
0 0 0
γ (f (y,s) y,s) = 1. Essentially, it keeps distinct count of how many +1 and
0 0
−1 inputs it has received. Formally:
(cid:40)
(i+1,j) if s=+1
f ((i,j),s)= (69)
0
(i,j+1) if s=−1
One consistent Bayesian interpretation (ψ ,φ ) for machine γ uses hypothesis
0 0 0
space H =[0,1] and model:
0
φ (s h)=hδ−1(s)(1−h)δ+1(s) (70)
0
where
(cid:40)
1 if u=v
δ (v):= (71)
u
0 else.
Thismodelisknownasthecategoricaldistributionfortwooutcomes(orjustthe
Bernoulli distribution). The machine states were deliberately chosen to be the
hyperparameters of a possible interpretation map ψ :Y →H which is known
0 0 0
as the Dirichlet distribution (and in this special case also as Beta-distribution):
1
ψ (h (i,j))= hi−1(1−h)j−1 (72)
0 B(i,j)
where B(i,j) is the Beta function.
This interpretation map (the Dirichlet distribution) is the conjugate priors
forcategoricaldistributions.Thisimpliesthat(ψ ,φ)formaconsistentBayesian
0
inference interpretation, as explained in appendix B.3.
C.3 Machine tracking differences between the number of
occurrences of different observations
We now consider another countably infinite deterministic machine (Y ,S,γ )
1 1
which has the same input space as the machine in appendix C.2. Let Y = Z
1
Interpreting Dynamical Systems as Bayesian Reasoners 33
and the input space again be S = {+1,−1}. The machine γ deterministically
0
computes a function f :(Y ×S)→Y , in the sense that γ (f (y,s) y,s)=1.
1 1 1 1 1
Machine γ only counts how many more +1 inputs it has received than −1
1
inputs. Formally:
f (k,s)=k+s. (73)
1
One consistent Bayesian interpretation (ψ ,φ ) for machine γ uses hypothesis
1 1 1
space H ={h ,h } and model:
1 +1 −1
(cid:40)
0.75 if i=s
φ(s h )= (74)
i
0.25 otherwise.
The interpretation map ψ :Y →H is
1 1 1
1
ψ (h k)=
1 +1 2(1+0.75k0.25−k)
(75)
1
ψ (h k)=
1 −1 2(1+0.75−k0.25k)
Itisrelativelyeasytoverifythat(ψ ,φ )isaconsistentBayesianinterpretation
1 1
with γ ’s dynamics.
1
As a teaser for future work we may note the following. Since machine γ of
0
appendix C.2 stores the individual counts for s and s inputs, it also implicitly
0 1
keeps track of the difference between those counts; γ only keeps track of this
1
difference. Consequently, we can define a deterministic kernel g : Y → P(Y )
0 1
that maps any state (i,j) ∈ Y of γ to g(i,j) := δ which is a probability
0 0 i−j
measure over the state space of γ . It turns out that for this map, for any
1
k(cid:48) ∈Y ,s∈S and (i,j)∈Y we have
1 0
(cid:88)
(γ g)(k(cid:48) (i,j),s)= γ (k(cid:48) k,s)g(k (i,j)). (76)
0 1
(cid:35)
k
This implies that we can construct an interpretation of machine γ from the
0
interpretation (ψ ,φ ) of γ . For this we precompose the interpretation map ψ
1 1 1 1
for γ with the machine map g to get a consistent Bayesian inference interpre-
1
tation (g ψ ,φ ) for γ . In future work we intend to further develop the theory
1 1 0
of how a(cid:35)consistent interpretation of one deterministic machine can be “pulled
back” to other machines that are related in a similar way to eq. (76).
D Details on the relation to the FEP
We here try to identify the structures in the FEP that are analogous to the
notions of machine γ, model κ, and interpretation map ψ . This suggests that,
H
at least in some treatments of FEP, there is an implicit concept that is close
to what we have called a reasoner. We will call this putative concept the FEP
reasoner.
34 N. Virgo et al.
Large parts of the FEP literature do not explicitly deal with FEP reasoners
but are sometimes presented as based on them (e.g. in [20]). The parts that
construct the FEP reasoner are those called “Bayesian mechanics” and are still
evolving. A standard reference is [19] but this is known to contain some issues
[9,21,1]. The most recent version can be found in [16].
UnderstandingpreciselytherelationshipbetweentheconceptsofourBayesian
andtheFEPreasonerisfuturework.Thefollowingarepreliminaryobservations.
D.1 Machine
WefirstidentifythestructureintheFEPsetupthatismostcloselyrelatedtoa
machineandisalsosaidtoappeartoperformBayesianinference.Unfortunately,
the latest iteration of the conditions under which there exists an FEP reasoner,
which is [16], does not make this particular structure as explicit as the previous
version [19]. We will therefore identify this structure in the older version. A
corresponding structure should also exist in the newer version and we will hint
at how it may differ.
The FEP setup in [19] consists of four sets of variables η ∈ E,s ∈ S,a ∈
A,µ ∈ M called external, sensory, active, and internal states with E,S,A,M
finite dimensional real vector spaces. These variables obey the stochastic differ-
ential equations
η˙ =f (η,s,a)+ω
η η
s˙ =f (η,s,a)+ω
s s
(77)
a˙ =f (s,a,µ)+ω
a a
µ˙ =f (s,a,µ)+ω
µ µ
where ω ,ω ,ω ,ω are independent Gaussian noise terms. The FEP goes be-
η s a µ
yond the scope of a reasoner and formulates a concept of agent. The concept
of an agent should, as part of its interpretation, make it possible to talk about
deliberate actions. In the FEP deliberate actions are associated to the active
states a. At the same time, the internal states are only involved in inference (or
filtering)andthespecialcasewheretherearenoactivestatesseemstobewithin
the scope of the FEP. This should still leave us with a FEP reasoner and make
it more comparable to our Bayesian reasoner. We therefore consider the special
case where there are no active states such that we get:
η˙ =f (η,s)+ω
η η
s˙ =f (η,s)+ω (78)
s s
µ˙ =f (s,µ)+ω .
µ µ
This looks like a continuous time version of the Bayesian network in eq. (1) and
has the somewhat significant feature that all influences from the external states
η are mediated by the sensory states s. This suggests that it is possible to see
the sensory states s ∈ S as inputs to a machine state µ ∈ M with the external
states η ∈E “hidden behind” the sensory states.
Interpreting Dynamical Systems as Bayesian Reasoners 35
Theinternalstatesµ∈M aresupposedtoappeartoinfertheexternalstates.
So the state space Y of the machine of the FEP reasoner should be identified
with M. Going by their name and their role in the earlier dynamics of eq. (77)
it seems reasonable to identify the sensory state space S with the input state
space (also S in our notation) of the machine.
This brings us to the machine’s kernel γ. Our formalism does not deal with
continuous-timekernelsatthemomentsoweonlymakesomeinformalcomments
here.Notethatnoneofthefollowingstatementsshouldbeconsideredasproven.
Since all variables together form a (time-homogeneous) Markov process, we can
choose times t,t+τ with τ > 0 and write the conditional probability density
(assuming things are well behaved enough) at a state (η(cid:48),s(cid:48),µ(cid:48)) at t+τ given a
state(η,s,µ)attimetasp(η(cid:48),s(cid:48),µ(cid:48),t+τ |η,s,µ,t)(thisnotationistakenfrom
[35, p.31]). We can then marginalise out η(cid:48) and s(cid:48) to get p(µ(cid:48),t+τ | η,s,µ,t)
which looks a bit closer to a machine kernel but still depends also on η. We
cannot just drop η from this expression even if we assume eq. (78) holds since
within a time interval [t,t+τ] with τ >0 the influence from η would propagate
through the intermediate values of the sensory states to µ(cid:48). Instead we here
condition on all those intermediate values of the sensory state between t and
t+τ. Write s[t:t+τ] for a part of the trajectory of the sensory state between
t and t+τ that starts in s. Then, assuming eq. (78) we should get:
p(µ(cid:48),t+τ |η,s[t:t+τ],µ,t)=p(µ(cid:48),t+τ |s[t:t+τ],µ,t). (79)
In order to make this look even more like a kernel we may take the limit as
τ →0 and so we write
γ(µ(cid:48) |µ,s):= limp(µ(cid:48),t+τ |s[t:t+τ],µ,t) (80)
τ→0
which is just a notation for an expression that hopefully provides sufficient in-
tuition for our purposes.
What is important is that within the system eq. (78) there should be a
(continuous-time) machine describing the dynamics of the internal states in re-
sponse to sensory states.
In [16] the structure of eq. (77) and thus eq. (78) is no longer assumed. This
means all variables can directly influence each other and the sensory states no
longer play a special role. However, the sensory (and usually the active states)
are still special due to an additional assumption. The larger process has to have
a stationary distribution p(η,s,a,µ) that factorises according to
p(η,s,a,µ)=p(η|s,a)p(µ|s,a)p(s,a) (81)
whichisreferredtoasaMarkovblanket.Withthisassumptiononly,onecanno
longer assume that the sensory states s[t:t+τ] can “shield” those states from
direct influence by external states, which makes it more difficult to compare the
dynamics to our setup. A solution may be to use a continuous-time version of
the approach in [36]. Below we ignore this issue and assume that we have the
structure of eq. (78).
36 N. Virgo et al.
D.2 Model
Forareasonerwealsoneedamodelandaninterpretationmap.Asalreadymen-
tionedtheFEPassumesthatthesystemineq.(77)hasastationarydistribution
p(η,s,µ). One purpose of this assumption seems to be the definition of what we
callthemodel.InthelanguageoftheFEPliteraturethestationarydistribution
definesthegenerativemodel.Here,generativemodelreferstoajointprobability
distribution over causes (parameters/hidden variables) and observed variables.
In[16,Section3.b)]thegenerativemodelisdefinedtobep(η,s,µ)withη asthe
hiddenvariablesandobservedvariables(s,µ).Wearenotsurewhyµisalsoseen
as an observed variable and not only s. This could mean that the machine state
µ itself is also modelled by an FEP reasoner. However, this would need further
investigation that we leave for future work. So we resort to a previous version
where only the marginalised stationary distribution p(η,s) was considered as
the generative model ([34, Fig.3],[19, p.101]). In that case the hidden variable
spaceH inournotationshouldbeidentifiedwiththeexternalstatespaceE and
the model (in our sense) is a conditional distribution induced by the stationary
distribution:
φ(s|η):=p(s|η). (82)
Note that, this choice of a model by itself does not immediately tell us whether
the FEP reasoner does filtering or just inference in the sense of definition 3. A
model like φ(s η) can be part of a filtering kernel κ as well. In both cases we
also need an interpretation map.
D.3 Interpretation map
For the interpretation map ψ we need a kernel of type M → P(E). Indeed, a
H
kernelthathastherighttypecanbeidentifiedintheFEPliterature.Thiskernel
is denoted q (η) and we will identify ψ (η µ)=q (η). The kernel’s definition,
µ H µ
however, relies on another assumption of the FEP, namely the existence of a
“synchronisation map” σ :M →E. To construct σ let us first define two other
functions g :S →M and g :S →E via
M E
f (s):=E [µ]
M p(µ|s)
(83)
f (s):=E [η]
E p(η|s)
and then set
σ(µ):=f (f−1(µ)) (84)
E M
whichisassumedtobewelldefined.Fordetailsonwhenthisexistsinthelinear
casesee[1,16].Withthiswecandefineq (η)andinturntheinterpretationmap
µ
ψ .ThismapsaninternalstateµtotheGaussiandistributionwithmeanvalue
H
equal to σ(µ):
ψ(η µ):=q (η):=N(η;σ(µ),Σ(µ)) (85)
µ
Interpreting Dynamical Systems as Bayesian Reasoners 37
where the variance Σ(µ) is defined as the variance of the best Gaussian approx-
imation to the model p(s|η = σ(µ)) when the external state is equal to σ(µ)
[34, Eq.2.4]. Note that in [16] the whole stationary distribution is assumed as
Gaussian and so p(η|µ) in the corresponding equation in that publication (i.e.
Eq.3.3) is also a Gaussian.
In conclusion, the necessary ingredients for something like a Bayesian rea-
soner seem to be present in the FEP literature. One thing that is special about
the FEP reasoner is that its model κ and interpretation map ψ are derived
H
from features of the process that the machine is embedded in.
We do not know whether there is an appropriate notion of consistency equa-
tionthattheFEPreasonerobeys.Presumably,insteadoftheequationforexact
inference that we have presented, such an equation would express the idea that
theFEPreasonerperformsapproximateinferenceintheformoffreeenergymin-
imisation. Other differences are that the FEP takes place in continuous time,
and perhaps more significantly, that it deals with deliberate actions as well as
inference. However, it is not inconceivable that these could be expressed in the
form of a consistency equation.
In the current formulations of the FEP, the interpretation is derived from
the properties of the ‘true’ environment, such as the stationary distribution, or
the synchronisation map σ. In our consistency equation approach, this need not
bethecase,sinceareasoner’sbeliefsonlyneedtobeconsistentandneednotbe
correct. This means in particular that no stationarity assumption is needed.
Nonetheless, perhaps an important idea behind the FEP is that the model
thatmostcloselycorrespondstothetrueenvironmentcanbeconsideredthebest
one.Aconsistencyequationapproachwouldstillbehelpful,inordertosystemat-
icallyexplorewhetherandhowinterpretationsshouldrelatetothelargerprocess
in which the machine is embedded.