Interpreting Dynamical Systems as Bayesian
Reasoners
Nathaniel Virgo1[0000−0001−8598−590X], Martin Biehl2[0000−0002−1670−6855], and
Simon McGregor3
1Earth-Life Science Institute, Tokyo Institute of Technology, Tokyo 152-8550, Japan
2Araya Inc., Tokyo 107-6024, Japan
3University of Sussex, Falmer, UK
Abstract. A central concept in active inference is that the internal
states of a physical system parametrise probability measures over states
of the external world. These can be seen as an agent’s beliefs, expressed
as a Bayesian prior or posterior. Here we begin the development of a gen-
eral theory that would tell us when it is appropriate to interpret states as
representing beliefs in this way. We focus on the case in which a system
can be interpreted as performing either Bayesian ﬁltering or Bayesian
inference. We provide formal deﬁnitions of what it means for such an
interpretation to exist, using techniques from category theory.
Keywords: Bayesian ﬁltering · Bayesian Inference · Category Theory.
1 Introduction
A question of current interest is what does it mean for a physical system to be
an agent? That is, given a physical system that interacts with an environment,
when does it make sense to say that the system is learning about its environment
or trying to achieve a goal , rather than merely being dynamically coupled to
its environment? Here we conﬁne ourselves to the ﬁrst of these, in a simple
form: given a physical system that is inﬂuenced by its surroundings, under what
circumstances can it be said to be performing inference, such that its internal
states could be said to contain ‘knowledge’ or ‘beliefs’ about the outside world?
Our approach has something in common with Dennet’s intentional stance
[17], in that on the one hand we treat the question of whether a system is
performing inference as a matter of interpretation, but on the other hand we
draw a strong connection between interpretations and the underlying physical
dynamics. We provide a formal notion of interpretation for the particular cases
we are interested in (Bayesian ﬁltering and Bayesian inference), such that the
question of whether a system can be consistently interpreted in a particular way
is mathematically well-deﬁned and has a deﬁnite answer.
The question of how to identify agents in physical systems has been addressed
in several ways. Some works focus on whether a system’s actions can be seen
as pursuing a goal [33,27], with [31] taking an explicitly Dennettian approach.
Others focus more on the question of identifying which part of a system should be
arXiv:2112.13523v1  [cs.AI]  27 Dec 2021
2 N. Virgo et al.
identiﬁed as the agent [7,5,6,28,2], or on understanding what the external world
looks like from the agent’s point of view [3,5,6]. Another approach, which we take
here, is to regard the system’s internal state as parametrising its beliefs. That is,
there is a function mapping the system’s physical state to a probability measure
that can be seen as a Bayesian prior. This is a key component of work on the
Free Energy Principle (FEP) [19,16,34] and also of [39], although our approach
diﬀers from these in that our model is not derived from the dynamics of the true
environment. The notion that agency is closely related to parametrisation is also
central to recent approaches to agency based on category theory [11,38,12].
The idea that states of a system parametrise Bayesian probability distribu-
tions appears more broadly in the Bayesian brain literature [26,30] and has also
arisen in cell biology [29,32]. Our contribution is to make the concept much more
formal, and in so doing, to shed light on the precise relationship between the
interpretation level and the underlying physical level.
On a technical level we formulate the problem of Bayesian ﬁltering at an
abstract level using the tools of category theory. This part of the work is inspired
by [23], which formulates the notion of conjugate prior in terms of category
theory in a similar way. Conjugate priors are convenient because they ensure
the functional form of the posterior is the same as the posterior, in Bayesian
belief updating. At the same time they can be seen as a special case of Bayesian
ﬁltering, as we explain in section 2.3 and appendix B.1. Formulating ﬁltering in
this way allows us to clearly distinguish the role of the physical machine from
the more semantic level at which we can talk about priors and posteriors. We
then ﬂip this perspective around, asking, for a given system, whether it can be
interpreted as implementing Bayesian ﬁltering, and if so under which model. In
this respect our approach generalises that of [8], who studied the special case of
the Dirichlet distribution (which is conjugate prior to a categorical distribution)
in the context of interpreting a physical system as performing inference.
One thing our approach makes clear is that a given system may have more
than one interpretation, and the “correct” interpretation cannot be determined
from the system’s dynamics alone. Another important aspect of our framework
is that an interpretation only depends on the system’s internal dynamics, and
not on the dynamics of the external world. Because of this, a system’s presumed
beliefs might not match the true dynamics of the world at all — its beliefs might
be consistent but incorrect — and indeed we can construct examples where the
world “as the system sees it” has a diﬀerent causal structure from the world as
it really is. (Compare eq. (1) to eq. (7).)
2 Deﬁnitions and Results
2.1 Technical preliminaries
In the following, we use the concepts of measurable space and Markov kernel. By
measurable space we mean a set equipped with a σ-algebra, i.e. the kind of thing
on which a probability measure can be deﬁned. An example of a measurable space
Interpreting Dynamical Systems as Bayesian Reasoners 3
is a ﬁnite set, and a reader who is only interested in the ﬁnite case could mentally
substitute “ﬁnite set” wherever we say “measurable space” and “probability
distribution” wherever we say “probability measure.”
Given a measurable spaceX, we writeP(X) for the set of all probability mea-
sures over X. Given measurable spaces X and Y, a Markov kernel is a function
κ: X →P(Y) that maps elements of X to probability measures over Y, with
an additional technical requirement that the function κ be measurable. Markov
kernels are closely related to conditional probability, but they are diﬀerent in
that a Markov kernel deﬁnes a probability measure over Y for every element X,
regardless of whether any probability distribution has been deﬁned over X or
what form such a distribution has. In the case where Y is a ﬁnite set, we write
κ(y x) for the probability that the kernel κassigns to y when given the input x.
We also make use of a graphical notation known as string diagrams, which
comes from the literature on category-theoretic probability [13,22]. This notation
provides a convenient way to reason about how Markov kernels relate to one
another. The full technical description of this calculus can be found in [22] or
[13], but we provide a brief intuitive explanation in appendix A, aimed at readers
with no category theory background, along with references to further reading.
2.2 Machines and interpretations
We are concerned with interpreting a physical system as performing inferences of
some kind on its inputs. We therefore begin by deﬁning a notion corresponding
to a physical system that can take an input from the outside world, which leads
to a change in state, which might be stochastic and might depend on the input.
Deﬁnition 1. A machine consists of two measurable spaces, Y (the state space)
and S (the input space), together with a Markov kernel γ: Y ×S →P(Y) called
the update kernel.
The idea is that the machine is in reality only a part of some larger stochastic
process. We might typically think of this broader context as represented by the
following causal Bayesian network, although this is not the only possibility.
(1)
Here the variables X0,X1,... represent the states of the external world at diﬀer-
ent times, which are hidden from the machine’s perspective. S0,S1,... are the
observable “sensor values” that the machine can access, all of which have the
same sample space, given by S. Similarly, Y0,Y1,... are the machine’s internal
state at each time step and each has the sample space Y. We assume that each
of the nodes Y1,Y2,... in this network are associated with the same kernel, γ.
The nodes X0 and Y0 represent distributions over initial states of the agent
and the world. A common ancestor of these nodes could be added, to represent
4 N. Virgo et al.
the possibility that the initial states are correlated. There is no need for any
stationarity assumption in our framework; the initial distribution in eq. (1) can
be arbitrary.
Even though we might think of the machine as existing in a context along
these lines, our notion of interpretation does not depend on the machine’s ex-
ternal environment at all, but only on the machine’s internal dynamics. That is,
on the measurable spaces Y and S and on the update kernel γ. This is because,
informally speaking, a reasoner may have consistent but wrong beliefs about the
external world, and we wish to include this possibility in our framework. (In
particular, a system that reasons correctly in one environment might be placed
in a diﬀerent environment where the same inferences are no longer correct.) Our
notion of interpretation will include a notion of “beliefs” about the external
world. These must be consistent with the machine’s internal dynamics and the
inputs it receives, but they need not relate in any particular way to any ground
truth about the process by which those inputs are generated, since we regard
that as something the reasoner has no direct access to.
Because of this we will rarely reason about causal models directly, and instead
will express our deﬁnitions directly in terms of Markov kernels and the relation-
ships between them. The string diagram notation, explained appendix A, will
be indispensable for this.
We now describe our central concept: aninterpretation of a machine. Here we
will present only two kinds of interpretations, Bayesian ﬁltering interpretations
and an important special case, Bayesian inference interpretations, but we expect
these to ﬁt naturally into a much broader family of concepts.
The most important component of an interpretation is what we term an
interpretation map , a function that maps the physical state of a machine to
something that we can think of as a belief about some external world. In the cases
we are concerned with in this paper, a “belief” will be a probability measure over
some hidden variable. An interpretation of a machine will be an interpretation
map together with some additional data (the model as deﬁned below), such that
a consistency equation is obeyed.
For a given machine there may be many possible interpretations. We use the
term reasoner for a machine together with a particular choice of interpretation.
In the case of Bayesian inference interpretations and Bayesian ﬁltering inter-
pretations, in which ‘beliefs’ are probability measures over a hidden variable, the
interpretation map is a Markov kernel ψH: Y →P(H). Instead of interpreting
this stochastically, we think of it as a function that takes a state y∈Y and re-
turns a probability measure ψH(y) (the belief) over H. This is to be thought of
as the reasoner’s subjective knowledge (a Bayesian prior or posterior) about the
hypotheses in H. This kernel plays quite a diﬀerent role from those associated
with the graphical model in eq. (1), since its purpose is to map states to beliefs,
rather than to model causal inﬂuences between random variables.
For an interpretation to be consistent, the reasoner’s beliefs must update in
the appropriate way when the machine receives new data. The precise meaning
of this will depend on what kind of interpretation we are using. For the inter-
Interpreting Dynamical Systems as Bayesian Reasoners 5
pretations we describe here it is given by Bayes’ rule, in a form that we state
precisely below. In future work we can imagine interpretations based on other
principles, such as approximate Bayes (e.g. via the free energy principle).
The idea is that a machine by itself is merely a (possibly stochastic) dynam-
ical process, but if a consistent interpretation exists then it is at least consistent
to ascribe a meaning to its states.
It should be noted that, for a given machine, the question of whether it
can be consistently interpreted in a particular way is in principle an empirical
one, since it depends on the machine’s update kernel, which can in principle
be measured. However, in general a given machine might have multiple non-
equivalent consistent interpretations, and one cannot distinguish between these
empirically by looking only at the system’s internal dynamics.1 Consequently the
relationship between interpretations and the empirical, physical world is rather
subtle, and one should keep in mind that our notion of “consistent reasoner”
unavoidably involves an element of choice in which interpretation to adopt.
2.3 Consistency for Bayesian Interpretations
We begin with the more general case of Bayesian ﬁltering interpretations. The
idea is that a reasoner has a model of the environment’s dynamics. This model is
part of the interpretation, and need not match the true environment dynamics.
In the case of ﬁltering, such a model can be described as a Markov kernel
κ S
HH , that is, κ: H →P(H×S). The idea is that H is the space of possible
hidden states of the external world, as modelled by the reasoner. The kernel
κ models a step of this hypothetical external world’s evolution, during which it
both changes to a new state in H and also emits an observable sensor value in S.
A Bayesian ﬁltering interpretation of a machine γS
Y Y will then consist
of a choice of interpretation map ψHY H as described above, together with a
choice of model κ S
HH . The kernel κthus describes a reasoner’s beliefs about
the next hidden state and the next sensor value, given the current hidden state.
Given the kernels ψH and κ we can deﬁne another kernel, which we also
consider to be an interpretation map,
Y ψS,H′,H
H
H
S
:= HY κψH
H
H
S.
(2)
The kernel ψH,H′,S maps a state of the machine y ∈Y to a joint distribution
over S and two copies of H, which we think of as the reasoner’s beliefs about
the the next sensor value, the next hidden state, and the current hidden state.
We also deﬁne its marginals,
Y ψS,H′ H
S := Y ψS,H′,H H
S
= HY κψH
H
S
(3)
1 We leave open the possibility that they could be distinguished by looking at some
broader context, e.g. by discovering that a device’s designer intended a particular
interpretation, or that evolution selected for a particular interpretation.
6 N. Virgo et al.
and
Y ψS S := Y ψS,H′,H
S
= HY κψH
S, (4)
which represent the reasoner’s beliefs about the next hidden state and the next
input, and about only the next input, respectively. We can now state the con-
sistency requirement for a Bayesian ﬁltering interpretation.
Deﬁnition 2. Given a machine γS
Y Y, a consistent Bayesian ﬁltering inter-
pretation of γ is given by a measurable space H together with Markov kernels
ψHY H and κH H
S that satisfy
Y Y
SψS,H′
γ
S
H
=
Y Y
ψS
S
γ
S
Y
ψH
H
,
(5)
with ψS,H′ and ψS given by eqs. (3) and (4).
The left-hand-side of eq. (5) can be read as sampling from the reasoner’s
joint beliefs about the next hidden state and the next input, and then feeding
the corresponding value of S into the machine as an input. The right-hand-side
can be read as sampling from the reasoner’s belief about its next input, feeding
the result in as its next input, and then sampling from its resulting (posterior)
belief about what it now sees as the current hidden state. The equation says
that these two procedures must give the same result.
In appendix B.1 we give some further intuition for this deﬁnition, by consid-
ering the case where S, Y and H are ﬁnite sets. An important consequence is
that, in the ﬁnite case, whether a given interpretation is consistent or not only
depends on which states are reachable from which other states under a given
input; the actual transition probabilities are irrelevant beyond that. We expect
an analogous statement to hold more generally.
Another important consequence discussed in appendix B.1 is that there is
a large class of machines that only admit trivial interpretations. At least in
the ﬁnite case, non-trivial interpretations can only exist if some transitions are
impossible, in the sense that there is a zero probability of transitioning from
y∈Y to y′∈Y under the input s∈S.
In appendix B.2 we give a more technical proof, using string diagrams, that at
least in the case of deterministic machines, a machine with a consistent Bayesian
ﬁltering interpretation can indeed be regarded as performing a Bayesian ﬁltering
task. This can be seen as extending some of the ideas in [24] on conjugate priors
to the more general case of Bayesian ﬁltering.
An important special case of deﬁnition 2 is where the modelκis such that the
hidden state does not change over time. In this case H can be thought of as an
unknown parameter of a statistical model, with the sensor inputs being indepen-
dent and identically distributed samples from the model. We call these Bayesian
inference interpretations. Although the following follows from deﬁnition 2 under
this assumption, we write it as a separate deﬁnition.
Interpreting Dynamical Systems as Bayesian Reasoners 7
Deﬁnition 3. Given a machine γS
Y Y,a consistent Bayesian inference inter-
pretation of γ is given by a measurable space H together with Markov kernels
ψHY H and φH S that satisfy
Y Y
SψH φ
H γ
S
H
=
Y Y
SψH
H φ
γ
S
Y
ψH
H
.
(6)
In appendix B.3 we show that this deﬁnition is closely related to the notion
of a conjugate prior, and in particular to the deﬁnition of conjugate prior given
by [24] in terms of Markov kernels and string diagrams. Finally, in appendix B.4
we unpack eq. (6) in more familiar terms, showing that in the discrete case it
does indeed correspond to Bayes’ theorem as usually understood.
In a Bayesian inference interpretation we interpret the reasoner as assuming
its inputs are i.i.d. samples from some distribution, but this need not mean that
they actually are. Under a consistent Bayesian inference interpretation a reasoner
is interpreted as modelling the world as if its causal structure is as follows, where
each of the ‘S’ nodes is associated with the kernel φ.
(7)
However, the true dynamics of the world could still correspond to the Bayesian
network in eq. (1) or some other causal structure. The reasoner is simply (inter-
preted as being) unable to perceive the correlations among its inputs.
In appendix C we present three examples of machines with consistent Bayesian
inference interpretations. The ﬁrst example is a non-deterministic ﬁnite machine
with three states. The consistent Bayesian inference interpretation we provide
also involves subjectively impossible observations.
The second example is a countably inﬁnite deterministic machine that counts
occurrences of each of two possible observations. The consistent Bayesian inter-
pretation we provide intuitively considers this machine to be inferring the bias
of a coin that is ﬂipped to cause its observations. It uses the standard conjugate
prior to its model as an interpretation map.
The third example is also a countably inﬁnite machine with two possible ob-
servations. However, it only stores the diﬀerence between the number of the two
possible observations. Intuitively, instead of considering all possible biases of a
coin as the second example the consistent Bayesian interpretation we provide for
this machine infers which of two speciﬁc biases of a coin is causing its observa-
tions. We also hint at how the second machine can “inherit” this interpretation.
3 Discussion
We see the main contribution of this work as a conceptual one. The consistency
equation involved in deﬁnitions 2 and 3 can be seen either as a constraint on the
8 N. Virgo et al.
machines that have a particular interpretation or as a constraint on the interpre-
tations that a particular machine allows. Every machine has an interpretation
with respect to a trivial model (one that has no parameter), but in order to have
an interpretation with respect to a non-trivial model, a machine must at least
obey the constraints discussed in appendix B.1.
Similar consistency equations should exist for approximate Bayesian ﬁltering
as well as for related inference problems like Bayesian smoothing or prediction.
Even non-Bayesian normative theories about what a system should be repre-
senting and how this should change under external inﬂuences will probably have
associated consistency equations.
Another direction to extend the concept of consistency equations is to take
into account a possible inﬂuence of the machine’s state on the external world. On
the interpretation side this would mean going beyond perception and represen-
tation to also include deliberate actions that combine with beliefs and possibly
also with goals. A machine with such an interpretation might deserve the term
agent instead of reasoner.
Our work is related to other current eﬀorts to capture the notion of agent
using category theory. These include approaches to Bayesian inference [37] and
game theory [10]. The idea that agency is related to parametrisation has also
arisen in these contexts [11,38,12]. These works focus on the notion of a lens and
its generalisations. It is interesting to note that our notions of interpretation seem
to be diﬀerent, and somewhat simpler, in that they lack the bidirectional nature
of lenses. We conjecture that a more lens-like bidirectional structure would be
needed if we were to consider Bayesian smoothing rather than Bayesian ﬁltering.
It will be interesting in future work to better understand the relationship between
lens-like categories and the concept of interpretation developed in the present
work.
3.1 Relation to the Free Energy Principle
Let us now consider the relation to the Free Energy Principle (FEP) which is
also referred to as active inference. The relevant part of FEP is the part called
“Bayesian mechanics” [19,16,34]. It seems that the ingredients for an interpreta-
tion map can be found in this literature: [16, eq. 3.3] describes a Markov kernel
of an appropriate type, as we detail in appendix D. However, it is not currently
clear to us whether the FEP can be formulated in terms of a consistency equa-
tion that this kernel obeys. Presumably, such an equation would be diﬀerent
from our deﬁnitions 2 and 3, because the FEP is concerned with approximate
rather than exact inference and deals with continuous time.
One important diﬀerence between our approach and current formulations of
FEP is that the FEP requires a stationarity assumption on the true dynam-
ics of the agent-environment system. It seems to us that this is used to derive
something that corresponds to a model. In our approach the reasoner’s and the
“ground truth” dynamics of the environment are diﬀerent things, and partly for
this reason we need no stationarity assumption. We see this conceptual sepa-
ration as an advantage of the consistency equation approach, and we believe
Interpreting Dynamical Systems as Bayesian Reasoners 9
that by incorporating these ideas it might be possible to formulate the FEP in a
way that would make its assumptions clearer and perhaps even avoid the need
for the stationarity assumption. Although we do not currently know the precise
relationship between our work and the FEP at a technical level, we explore it in
more detail in appendix D.
References
1. Aguilera, M., Millidge, B., Tschantz, A., Buckley, C.L.: How particular is the
physics of the Free Energy Principle? arXiv:2105.11203 [q-bio] (May 2021), http:
//arxiv.org/abs/2105.11203, arXiv: 2105.11203
2. Albantakis, L., Massari, F., Beheler-Amass, M., Tononi, G.: A macro agent and
its actions. arXiv:2004.00058 [cs, q-bio] (Mar 2020),http://arxiv.org/abs/2004.
00058, arXiv: 2004.00058
3. Ay, N., L¨ ohr, W.: The Umwelt of an embodied agent–a measure-theoretic deﬁni-
tion. Theory in Biosciences = Theorie in Den Biowissenschaften 134(3-4), 105–116
(Dec 2015). https://doi.org/10.1007/s12064-015-0217-3
4. Baez, J., Stay, M.: Physics, Topology, Logic and Computation: A Rosetta Stone. In:
Coecke, B. (ed.) New Structures for Physics, pp. 95–172. Lecture Notes in Physics,
Springer, Berlin, Heidelberg (2011). https://doi.org/10.1007/978-3-642-12821-9 2,
https://doi.org/10.1007/978-3-642-12821-9_2
5. Beer, R.D.: Autopoiesis and Cognition in the Game of Life. Artiﬁcial Life 10(3),
309–326 (2004). https://doi.org/10.1162/1064546041255539, /journal/10.1162/
1064546041255539
6. Beer, R.D.: The cognitive domain of a glider in the game of life. Artiﬁcial Life
20(2), 183–206 (2014). https://doi.org/10.1162/ARTL a 00125
7. Biehl, M., Ikegami, T., Polani, D.: Towards information based spatiotemporal
patterns as a foundation for agent representation in dynamical systems. In: Pro-
ceedings of the Artiﬁcial Life Conference 2016. pp. 722–729. The MIT Press (Jul
2016). https://doi.org/10.7551/978-0-262-33936-0-ch115, https://mitpress.mit.
edu/sites/default/files/titles/content/conf/alife16/ch115.html
8. Biehl, M., Kanai, R.: Dynamics of a Bayesian Hyperparameter in a Markov Chain.
In: Verbelen, T., Lanillos, P., Buckley, C.L., De Boom, C. (eds.) Active Inference.
pp. 35–41. Communications in Computer and Information Science, Springer Inter-
national Publishing, Cham (2020). https://doi.org/10.1007/978-3-030-64919-7 5
9. Biehl, M., Pollock, F.A., Kanai, R.: A Technical Critique of Some
Parts of the Free Energy Principle. Entropy 23(3), 293 (Mar 2021).
https://doi.org/10.3390/e23030293, https://www.mdpi.com/1099-4300/23/
3/293, number: 3 Publisher: Multidisciplinary Digital Publishing Institute
10. Bolt, J., Hedges, J., Zahn, P.: Bayesian open games. arXiv:1910.03656 [cs, math]
(Oct 2019), http://arxiv.org/abs/1910.03656, arXiv: 1910.03656
11. Capucci, M., Gavranovi´ c, B., Hedges, J., Rischel, E.F.: Towards foundations of
categorical cybernetics. arXiv:2105.06332 [math] (May 2021), http://arxiv.org/
abs/2105.06332, arXiv: 2105.06332
12. Capucci, M., Ghani, N., Ledent, J., Forsberg, F.N.: Translating Extensive Form
Games to Open Games with Agency. arXiv:2105.06763 [cs, math] (May 2021),
http://arxiv.org/abs/2105.06763, arXiv: 2105.06763
13. Cho, K., Jacobs, B.: Disintegration and Bayesian Inversion via String
Diagrams. Mathematical Structures in Computer Science 29(7), 938–971
10 N. Virgo et al.
(Aug 2019). https://doi.org/10.1017/S0960129518000488, http://arxiv.org/
abs/1709.00322, arXiv: 1709.00322
14. Coecke, B., Paquette, ´E.: Categories for the Practising Physicist. In: Coecke, B.
(ed.) New Structures for Physics, pp. 173–286. Lecture Notes in Physics, Springer,
Berlin, Heidelberg (2011). https://doi.org/10.1007/978-3-642-12821-9 3, https://
doi.org/10.1007/978-3-642-12821-9_3
15. Coecke, B., Kissinger, A.: Picturing quantum processes: a ﬁrst course in quan-
tum theory and diagrammatic reasoning. Cambridge University Press, Cambridge,
United Kingdom ; New York, NY, USA (2017)
16. Da Costa, L., Friston, K., Heins, C., Pavliotis, G.A.: Bayesian Mechanics for
Stationary Processes. arXiv:2106.13830 [math-ph, physics:nlin, q-bio] (Jun 2021),
http://arxiv.org/abs/2106.13830, arXiv: 2106.13830
17. Dennett, D.C.: True Believers : The Intentional Strategy and Why It Works. In:
Heath, A.F. (ed.) Scientiﬁc Explanation: Papers Based on Herbert Spencer Lec-
tures Given in the University of Oxford, pp. 53–75. Clarendon Press (1981)
18. Fong, B., Spivak, D.I.: An invitation to applied category theory: seven sketches in
compositionality. Cambridge University Press, Cambridge ; New York, NY (2019)
19. Friston, K.: A free energy principle for a particular physics. arXiv:1906.10184 [q-
bio] (Jun 2019), http://arxiv.org/abs/1906.10184, arXiv: 1906.10184
20. Friston, K., Da Costa, L., Hafner, D., Hesp, C., Parr, T.: Sophis-
ticated Inference. Neural Computation 33(3), 713–763 (Mar 2021).
https://doi.org/10.1162/neco a 01351, https://doi.org/10.1162/neco_a_01351
21. Friston, K., Da Costa, L., Parr, T.: Some interesting observations on the free en-
ergy principle. arXiv:2002.04501 [q-bio] (Feb 2020), http://arxiv.org/abs/2002.
04501, arXiv: 2002.04501
22. Fritz, T.: A synthetic approach to Markov kernels, conditional independence and
theorems on suﬃcient statistics. Advances in Mathematics 370, 107239 (Aug
2020). https://doi.org/10.1016/j.aim.2020.107239, https://www.sciencedirect.
com/science/article/pii/S0001870820302656
23. Jacobs, B.: A channel-based perspective on conjugate priors. Math-
ematical Structures in Computer Science 30(1), 44–61 (Jan 2020).
https://doi.org/10.1017/S0960129519000082, https://www.cambridge.
org/core/journals/mathematical-structures-in-computer-science/
article/channelbased-perspective-on-conjugate-priors/
D7897ABA1AA06E5F586F60CB21BDDB32, publisher: Cambridge University Press
24. Jacobs, B.: A Channel-Based Perspective on Conjugate Priors. arXiv:1707.00269
[cs] (Sep 2018), http://arxiv.org/abs/1707.00269, arXiv: 1707.00269
25. Jacobs, B., Staton, S.: De Finetti’s Construction as a Categorical Limit. In:
Petri¸ san, D., Rot, J. (eds.) Coalgebraic Methods in Computer Science. pp. 90–
111. Lecture Notes in Computer Science, Springer International Publishing, Cham
(2020). https://doi.org/10.1007/978-3-030-57201-3 6
26. Knill, D.C., Pouget, A.: The Bayesian brain: the role of uncertainty in
neural coding and computation. Trends in Neurosciences 27(12), 712–719
(Dec 2004). https://doi.org/10.1016/j.tins.2004.10.007, https://www.cell.com/
trends/neurosciences/abstract/S0166-2236(04)00335-2, publisher: Elsevier
27. Kolchinsky, A., Wolpert, D.H.: Semantic information, autonomous agency and
non-equilibrium statistical physics. Interface Focus 8(6), 20180041 (Dec 2018).
https://doi.org/10.1098/rsfs.2018.0041, https://royalsocietypublishing.org/
doi/full/10.1098/rsfs.2018.0041
Interpreting Dynamical Systems as Bayesian Reasoners 11
28. Krakauer, D., Bertschinger, N., Olbrich, E., Flack, J.C., Ay, N.: The infor-
mation theory of individuality. Theory in Biosciences 139(2), 209–223 (Jun
2020). https://doi.org/10.1007/s12064-020-00313-7, https://doi.org/10.1007/
s12064-020-00313-7
29. Libby, E., Perkins, T.J., Swain, P.S.: Noisy information processing through tran-
scriptional regulation. Proceedings of the National Academy of Sciences 104(17),
7151–7156 (Apr 2007)
30. Ma, W.J., Jazayeri, M.: Neural coding of uncertainty and probability. Annual Re-
view of Neuroscience 37, 205–220 (2014). https://doi.org/10.1146/annurev-neuro-
071013-014017
31. McGregor, S.: The Bayesian stance: Equations for ‘as-if’ sensori-
motor agency. Adaptive Behavior p. 105971231770050 (Mar 2017).
https://doi.org/10.1177/1059712317700501, http://journals.sagepub.com/
doi/10.1177/1059712317700501
32. Nakamura, K., Kobayashi, T.J.: Connection between the Bacterial Chemotactic
Network and Optimal Filtering. Physical Review Letters 126(12), 128102 (Mar
2021). https://doi.org/10.1103/PhysRevLett.126.128102, https://link.aps.org/
doi/10.1103/PhysRevLett.126.128102
33. Orseau, L., McGill, S.M., Legg, S.: Agents and Devices: A Relative Deﬁnition
of Agency. arXiv:1805.12387 [cs, stat] (May 2018), http://arxiv.org/abs/1805.
12387, arXiv: 1805.12387
34. Parr, T., Da Costa, L., Friston, K.: Markov blankets, information geometry and
stochastic thermodynamics. Philosophical Transactions of the Royal Society A:
Mathematical, Physical and Engineering Sciences378(2164), 20190159 (Feb 2020).
https://doi.org/10.1098/rsta.2019.0159, https://royalsocietypublishing.org/
doi/full/10.1098/rsta.2019.0159
35. Risken, H., Frank, T.: The Fokker-Planck Equation: Methods of Solution and Ap-
plications. Springer Series in Synergetics, Springer-Verlag, Berlin Heidelberg, 2
edn. (1996). https://doi.org/10.1007/978-3-642-61544-3, https://www.springer.
com/gp/book/9783540615309
36. Rosas, F.E., Mediano, P.A.M., Biehl, M., Chandaria, S., Polani, D.: Causal Blan-
kets: Theory and Algorithmic Framework. In: Verbelen, T., Lanillos, P., Buckley,
C.L., De Boom, C. (eds.) Active Inference. pp. 187–198. Communications in Com-
puter and Information Science, Springer International Publishing, Cham (2020).
https://doi.org/10.1007/978-3-030-64919-7 19
37. Smithe, T.S.C.: Bayesian Updates Compose Optically. arXiv:2006.01631 [math,
stat] (Jul 2020), http://arxiv.org/abs/2006.01631, arXiv: 2006.01631
38. St Clere Smithe, T.: Cyber Kittens, or Some First Steps Towards Categorical
Cybernetics. Electronic Proceedings in Theoretical Computer Science 333, 108–
124 (Feb 2021). https://doi.org/10.4204/EPTCS.333.8, http://arxiv.org/abs/
2101.10483v1
39. Still, S., Sivak, D.A., Bell, A.J., Crooks, G.E.: The thermodynamics of prediction.
arXiv e-print 1203.3271 (Mar 2012), http://arxiv.org/abs/1203.3271, phys.
Rev. Lett. 109, 120604 (2012)
40. Wikipedia contributors: Conjugate prior — Wikipedia, the free encyclope-
dia (2021), https://en.wikipedia.org/w/index.php?title=Conjugate_prior&
oldid=1030202570, [Online; accessed 8-July-2021]
12 N. Virgo et al.
A Category-Theoretic Probability and String Diagrams
In this paper we use some concepts from category-theoretic probability, and in
particular we use a notation known as string diagrams. A full introduction to
these topics would be out of scope of the paper, but we include here an informal
introduction to the topic. We do this because, to our knowledge, no concise
introduction currently exists that is focused on (classical) probability and does
not assume a background in category theory. We assume that the reader knows
the deﬁnition of a category, but not much more than that.
Appendix A.1 introduces the basic concepts, mostly in the context of dis-
crete probability. In appendix A.2 we brieﬂy comment on how this extends to
the general case of measure-theoretic probability with very little extra work.
In appendix A.3 we explain how to reason about conditional probabilities and
Bayes’ theorem within this category-theoretic context.
These sections contain no original material. Their purpose is to give the
reader enough information to be able to read the string diagram equations in
the main text and later sections of the appendix without needing to consult a
category theory text. However, they are intended neither as an authoritative
technical reference nor as a comprehensive review, and readers should consult
the cited references for full details.
A.1 Introduction to String Diagrams and Category-Theoretic
Probability
A full technical introduction to the use of string diagrams in probability can
be found in [22] or the earlier [13], but these works require some knowledge of
category theory. The string diagram notation predates its use in probability and
has many other applications. One could consult [4,14,18,15] for tutorial intro-
ductions to diagrammatic reasoning in other ﬁelds, of various diﬀerent ﬂavours.
Here we present it somewhat informally and only in the context of probability.
It should be kept in mind that, despite our somewhat informal introduc-
tion, string diagrams are formal expressions. The main diﬀerence between them
and the more familiar kind of mathematical expression formed from strings of
symbols is their two-dimensional syntax. This makes it easier to express cer-
tain concepts. (Particularly those relating to joint distributions, in the case of
probability.)
We use the so-called Markov category approach to probability [22]. The main
idea here is to express everything in terms of measurable spaces and Markov
kernels, whose deﬁnitions we outlined in the main text. 2 To explain how the
2 In fact for most of the paper we will work much more abstractly than this. It would
be more correct to say “objects in a Markov category” wherever we say “measurable
space” and “morphisms in a Markov category” wherever we say “Markov kernel,”
since for most of the paper we will reason at the category level, and we will not
directly invoke the deﬁnition of a measurable space. We have chosen to use the
more concrete terms because they express a clear intuition for how these objects
and morphisms are intended to be interpreted.
Interpreting Dynamical Systems as Bayesian Reasoners 13
framework works, let us consider the special case where the only measurable
spaces we are interested in are ﬁnite sets (with their power sets as their σ-
algebras). If Aand Bare ﬁnite sets then a Markov kernel can be thought of as just
a function f: A→P(B), where P(B) is the set of all probability distributions
over B. (The set P(B) may be thought of as a ( |B|− 1)-dimensional simplex,
consisting of all those vectors in R|B|whose components are all non-negative and
sum to 1.) Such a function amounts to a |B|-by-|A|stochastic matrix, although
some care needs to be taken over which rows correspond to which elements of B
and which columns to which elements of A.
In this ﬁnite case, we write f(b a) to denote the probability that the kernel f
assigns to the outcome b∈Bwhen given the input a∈A. We use a thick vertical
line to indicate a close relationship to conditional probability while also empha-
sising that the concept is diﬀerent: given a kernel f: A →P(B) the quantities
f(b a) are always deﬁned, regardless of whether any probability distribution
has been deﬁned over A, and regardless of whether a has a nonzero probability
according to such a distribution. More common notations include |or ; in place
of .
We also write f(a) for the probability distribution over Bthat the function f
returns when given the input a. We could say that f(b a) is deﬁned as f(a)(b).
Given Markov kernels f: A →P(B) and g: B →P(C), we can compose
them to form a new kernel of type A→P(C). We write this f# g. It is given by
(f # g)(c a) =
∑
b∈BY
f(b a) g(c b). (8)
In this ﬁnite case this is simply matrix multiplication, and we could have denoted
it gf instead of f# g accordingly. (Another common notation is g◦f.) We prefer
f # g because it puts f and g in the same order that they will appear in string
diagrams.
It is straightforward to show that composition is associative, that is
(f # g) # h= f # (g# h). (9)
In addition, for every ﬁnite set A there is an identity kernel, which amounts
to just the |A|-by-|A|identity matrix. We write this as idA and deﬁne it by
idA(a′ a) = δa,a′. For every Markov kernel f: A→P(B) we have
idA # f = f = f # idB. (10)
These two facts mean that there is a category whose objects are ﬁnite sets
and whose morphisms are Markov kernels between ﬁnite sets. This category is
called FinStoch.
Since Markov kernels are morphisms in a category, we will often writef: A→•
B instead of f: A→P(B), using the dotted arrow →• to distinguish morphisms
in FinStoch and related categories from ordinary functions. (In the main text we
continue writing them as functions in order to avoid introducing new notation.)
The composition of Markov kernels can be generalised to the case of measure-
theoretic probability, which allows us to reason about continuous probability and
14 N. Virgo et al.
more general probability measures using the same kinds of diagram and much of
the same reasoning. We brieﬂy discuss this in more detail in appendix A.2. The
main diﬀerence is that composition becomes integration over measures rather
than summation.
Probability measures themselves may be seen as a special case of Markov
kernels. Consider a set with a single element, denoted 1 = {⋆}. (The identity of
the element does not matter because all one-element sets are isomorphic to each
other. Category theorists often speak of “the one-element set” for this reason.
We use a star to denote the element.) Then a Markov kernel p: 1 →• A is a
function p: 1 →P(A), which takes an element of 1 and returns a probability
measure over A. Since there is only one element of 1 this means that the kernel
ponly deﬁnes a single probability measure over A. We therefore think of Markov
kernels 1 →• A and probability measures over A as essentially the same thing.
We now begin to introduce the string diagram notation. A Markov kernel
f: A→• B will be denoted
fA B
. (11)
This expression means much the same thing as the notation f: A→• B. It is just
a formal symbol denoting the kernel f, annotated with type information.
The composition of kernels f: A→• B and g: B →• C is written
f # gA C = fA B g C
. (12)
The left and right hand side of this equation are just two diﬀerent ways to
write the composite kernel f # g, as deﬁned by eq. (8) or its measure-theoretic
generalisation.
In reading a diagram like the right-hand side of eq. (12) we ﬁnd it helpful
to imagine an element of A travelling along the wire from the left. As it passes
through the kernel f it is stochastically transformed into an element of B, in a
way that might depend on its original value. It then travels further to the right
and is stochastically transformed by g into an element of C. Equation (8) can
be seen as describing this process.
In string diagrams a special notation is used for identity kernels (or identity
morphisms more generally): an identity kernel idA is drawn simply as a wire
with no box on it,
A . (13)
For any Markov kernel f: A→• B the identity law eq. (10) can then be written
fA B = fA B
= fA B
.
(14)
This allows us to think of the wires as stretchy: we can extend and contract
them at will. We will think of the wires as continuously deformable, rather than
extending and contracting in discrete units. This is justiﬁed by the formal theory
of string diagrams. (One may informally think of the wire itself as an inﬁnite
Interpreting Dynamical Systems as Bayesian Reasoners 15
chain of identity kernels, all composed together.) This ability to continuously
deform diagrams turns out to be an extremely powerful and useful idea.
Another special notation is used for one-element sets 3: they are drawn as
no wire at all. For this reason a probability measure over A, that is, a kernel
p: 1 →• A, is drawn as
p A
. (15)
(Morphisms of this kind are sometimes known as “states,” and they are often
drawn as a triangle rather than a box, though here we draw them in the same
style as other morphisms.)
It is worth noting that the kernels p and f above can be composed, yielding
p# f B = p A f B
. (16)
Because of this, although the kernel f: A→• B is deﬁned as a function f: A→
P(B) mapping elements of A to probability distributions over B, we can in-
stead choose to see it as mapping probability measures over A to probability
measures over B. In the ﬁnite case, if we think of ﬁnite probability distributions
as normalised and nonnegative vectors in Rn, then f can be seen as a linear map
with the property that it maps points in one simplex to points in another. (This
justiﬁes thinking of it as a stochastic matrix.)
The string diagram notation becomes useful when we start thinking about
joint distributions. We do this by drawing wires in parallel. As an example, we
can consider a Markov kernel deﬁned by a function h: A×B →P(C ×D).
This function takes two arguments, an element of A and an element of B, and
it returns a joint probability distribution over C and D. In string diagrams we
write this as
h
B
A
D
C
.
(17)
In symbols, we write h: A⊗B →• C⊗D. An object like A⊗B, drawn as two
parallel wires, can either be thought of as the measurable space A×B (which
is the Cartesian product of sets in the ﬁnite case), or as the space of probability
measures over A×B. The symbol ⊗is referred to as a monoidal product.
There is some inherent ambiguity in this notation. If we draw three parallel
wires,
ABC ,it could either mean (A⊗B)⊗C or A⊗(B⊗C). In the ﬁnite case,
these correspond to the sets ( A×B) ×C and A×(B×C). These are diﬀerent
sets, since one is composed of pairs (( a,b),c) and the other of pairs ( a,(b,c)).
This ambiguity is not important in practice, however, and the formal machinery
of monoidal categories allows us to use string diagrams without worrying about
it. We do not give a formal treatment of this here. (A concise summary can be
found in [4].) Instead we simply remark that when we draw three parallel wires
we think of joint distributions over A, B and C, and the precise distinction
between P(A×(B×C)) and P((A×B) ×C) will not be important to us.
3 or in a more general context, the unit object of a monoidal category
16 N. Virgo et al.
In a similar vein, the spacesAand A⊗1 are diﬀerent, but the diﬀerence is not
important to us, and in fact they are written the same way in string diagrams.
This is because we draw 1 as an invisible wire. This also allows us to write
A
B =
A
B
= A
B
.
(18)
That is, string diagrams are stretchy in the vertical direction as well as the
horizontal one. We can bend the wires, as long as we don’t deform them so
much that they point backwards, from right to left.
This also allows to write things like
A
C
Bf (19)
for a kernel f: A→• B⊗C.
We can also draw morphisms (i.e. Markov kernels) in parallel with each other,
for example,
f
gC
A
D
B
.
(20)
We write this in symbols as f⊗g, which is a morphism of type A⊗C →• B⊗D.
In the ﬁnite case, it is given by
(f ⊗g)(b,d a,c) = f(b a) g(d c). (21)
The probabilities f(b c) and g(d c) are multiplied together because the two
Markov kernels are operating in parallel. One can imagine an element of A en-
tering from the bottom left and being stochastically transformed by f into an
element of B, while in parallel, and independently, an element of C enters from
the top left and is stochastically transformed by g into an element of D. In
general, in the ﬁnite case, f ⊗g is given by the tensor product of the stochas-
tic matrices that represent f and g. (This might give some intuition for the
symbol ⊗.)
We can cross wires over each other. (In category theory terms, the categories
we are concerned with are symmetric monoidal categories.) The diagram
A
B
B
A
(22)
can be seen as a Markov kernel A⊗B →• B⊗A. In the ﬁnite case it is deﬁned
by
swapA,B(b′,a′ a,b) = δa,a′δb,b′. (23)
We have a number of equations that are standard in monoidal category the-
ory, and allow us to freely slide boxes along wires and bend wires to cross over
each other. These can either be shown directly from the deﬁnitions above or
(perhaps more usefully) deduced from the deﬁnition of a symmetric monoidal
Interpreting Dynamical Systems as Bayesian Reasoners 17
category. Three such equations are as follows. More details can be found in the
references cited above.
A
B
A
B
=
A
B
A
B
(24)
f
gC
A
D
B
= f
gC
A
D
B
(25)
f
C
A
B
C = fC
A
B
C
(26)
So far, everything we have said about string diagrams applies to any sym-
metric monoidal category. However, there are two additional things we can add
that take us much closer to probability theory. These are the ability to copy
and to delete. These operations, and their special properties, do not necessarily
exist in other contexts, such as quantum mechanics. This is a central point of
[4,14]. We will stick to the context of classical probability, however, so copying
and deletion will always be possible in this paper.
We cover deletion ﬁrst. For every measurable spaceAthere is a unique kernel
of type A→1 , which we call delA. In the ﬁnite case it is given by delA(⋆ a) = 1
for all a∈A. We can think of this as a 1 ×|A|matrix (i.e. a row vector) whose
entries are all 1. This is the only possible 1 ×|A|stochastic matrix.
In string diagrams we write such a deletion kernel as a black dot:
A . (27)
There is one such morphism for every measurable space, but we denote them all
with the same kind of black dot. These black dots have the property that
f BA = A (28)
for every Markov kernel f. This says that if we take some input A, perform some
stochastic operation f on it and then delete the result, this is the same as simply
deleting the input.4
The second special operation is copying. For every measurable space Athere
is a kernel copyA: A→A⊗A, which we will describe shortly. We write this also
as a black dot, but this time with two output wires rather than one.
A
A
A . (29)
Informally, this kernel takes an outcome a ∈A and copies it, producing a pair
(a,a) of identical values. It’s important to note that it copies values rather than
4 In category theory terms, this means that the set of all delete kernels collectively
forms a natural transformation. (Speciﬁcally, it is a natural transformation from the
identity functor to the functor that sends all objects to 1 and all morphisms to id1 .)
For this reason this property of delete kernels is called “naturality.”
18 N. Virgo et al.
distributions. Its output does not consist of two independent and identically
distributed elements of Abut rather two perfectly correlated elements of Athat
always have the same value. In the discrete case the copy map is deﬁned as
copyA(a′′,a′ a) =
{
1 if a′′= a′= a
0 otherwise. (30)
In addition to eq. (28), the copy and delete maps obey the following properties
[22, deﬁnition 2.1]:
A
A
A
A
= A
A
A
A
(31)
A
A
= A = A
A
(32)
A
A
A
= A
A
A
(33)
A⊗B =
A
B
(34)
A⊗B
A⊗B
A⊗B
= A
A
A
B
B
B
(35)
Equation (31) says that if we make multiple copies of something it doesn’t
matter which order we make them in. Equation (32) says that if we copy some-
thing and then delete one of the copies, that is the same as doing nothing to it.
Equation (33) says that if we copy something and then swap the copies it makes
no diﬀerence. (Because the two copies are the same as each other.)
Equations (34) and (35) are more technical. They say that if we have elements
of Aand Bwe can delete or copy them as a single element ofA⊗Bor separately,
as elements of A and B, and these should give the same result.
These equations can be derived from the deﬁnitions we have given for the
ﬁnite case. They may also be derived in various more general measure-theoretic
contexts [13,22].
However, the approach of [22] is instead to treat them as axioms: any sym-
metric monoidal category with copy and delete maps that obey eqs. (28) and (31)
to (35) is called a Markov category. One can do a surprising amount of reason-
ing about probability theory using these axioms alone, although there are also
Markov categories that do not directly resemble the category of measurable
spaces and Markov kernels that we have described. There are various additional
axioms that can to be added as well, which then allow more speciﬁc results to
be proven. (See [22] for the details.)
An important thing to note about the copy operator is that, in general,
BA f
B
B
̸= AA
f
f
B
B .
(36)
Interpreting Dynamical Systems as Bayesian Reasoners 19
That is, copying the output of a kernelf is not the same as copying its input and
then applying two copies of the kernel to it. Intuitively, this is becausef might be
stochastic. If we copy the output we end up with two perfectly correlated copies,
whereas if we copy the input then the stochastic variations will be independent.
However, if the kernel is deterministic then copying its input is indeed the
same as copying its output. In fact, in the Markov category framework this is
the deﬁnition of a deterministic Markov kernel: we say a kernel h: A →B is
deterministic if
BA h
B
B
= AA
h
h
B
B .
(37)
In this paper we use square boxes for kernels that are known to be deterministic,
and boxes with rounded edges for general, possibly-stochastic kernels.
In the main text, we write Markov kernels as functions f: A →P(B), and
we write deterministic kernels as functions f: A → B. To be more precise,
a deterministic kernel should really also be considered as a function f: A →
P(B), such that eq. (37) is obeyed. However, if we assume we are working in a
category called BorelStoch (which is a common assumption in category-theoretic
probability) then eq. (37) implies that f always returns a delta measure [22,
example 10.5], and in this case there is not much harm in treating a deterministic
kernel f as a function f: A→B.
A.2 The extension to measure theory
Above we described the categoryFinStoch and introduced string diagrams mostly
in that context. Here we brieﬂy describe how this generalises to the measure-
theoretic case, which is needed in order to think about continuous probability.
In the measure-theoretic case the objects ( X, Y, etc.) are any measurable
spaces rather than only ﬁnite sets. Markov kernels are still functions f: X →
P(Y), but now P(Y) is the set of all probability measures on the measurable
space Y. (That is, P(Y) is the set of all functions from the σ-algebra associated
with Y to [0 ,1], such that Kolmogorov’s axioms are obeyed.) P(Y) can itself
be made into a measurable space in a standard way, and the function f must
obey an additional restriction that it be a measurable function. (This means
that the preimage of every element of P(Y) must be a member of the σ-algebra
associated with X.)
In this case f(x) is a probability measure rather than a probability distri-
bution, and composition is given by integration rather than summation. (See
[22, example 4] for the details.) This gives rise to a category called Stoch, whose
objects are all measurable spaces and whose morphisms are all Markov kernels.
(This category is also known as the Kleisli category of the Giry monad, for
reasons we do not discuss here.)
Unfortunately the category Stoch does not have all of the properties that
one might want it to have. (See appendix A.3 below.) Because of this a common
approach is to work in a category calledBorelStoch (also discussed in [22, example
20 N. Virgo et al.
4]), in which the objects are a subset of measurable spaces called standard Borel
spaces, and the morphisms are all Markov kernels between standard Borel spaces.
Standard Borel spaces include many kinds of measurable space that one would
be likely to use in practice, and in particular they include both ﬁnite sets and
Rn with its usual σ-algebra.
In the present paper, the properties of BorelStoch are used in two ways.
Firstly, in BorelStoch we can always use conditionals, as explained in the next
section. Secondly, as a notational convenience we treat deterministic kernels and
measurable functions as interchangeable, which makes sense in BorelStoch but
doesn’t hold in the more general case of Stoch.
A.3 Conditionals and Bayes’ theorem
Conditional probabilities and Bayes’ theorem play central roles in the theory of
inference. Here we brieﬂy discuss how they look in string diagrams. Given a joint
distribution q A
B we may want to split it up into a product of a marginal and a
conditional, which in traditional notation, in the discrete case, would be written
p(a,b) = p(a) p(b|a).
The category-theoretic approach, as set out in [13,22], is slightly diﬀerent.
We write the following, which is called a disintegration of q. (The term “disin-
tegration” is used because it is the opposite of integration.)
q B
A
= q
B
A
c B
A.
(38)
Here, q Ais the marginal of Aaccording to the joint distributionq. In the ﬁnite
case it can be written ∑
b∈Bq(a,b). The kernel cA B is called a conditional
of p. It is deﬁned by eq. (38), which in the ﬁnite case can be written
q(a,b) =
(∑
b′∈B
q(a,b′)
)
c(b a). (39)
This is closely analogous to the identity p(a,b) = p(a) p(b|a). The diﬀerence
is that p(b|a) is deﬁned as p(a,b)/p(a), and is only deﬁned when p(a) >0. On
the other hand, in eq. (39), if
(∑
b′∈Bq(a,b′)
)
= 0 for some a ∈A then q(a,b)
must be 0 for all b ∈B, and consequently the equation puts no constraint on
c(b a) in this case.
This means that instead of being undeﬁned in this case, the conditional c
is not uniquely deﬁned: there may be many diﬀerent kernels c that satisfy the
equation.
This carries over to the general measure-theoretic case as well. If we are in
the category BorelStoch then for any joint distribution q A
B there exists at least
one conditional cA B that satisﬁes eq. (38), but there might be many. (In the
case of Stoch conditionals may fail to exist at all, see [22, example 11.3].)
Interpreting Dynamical Systems as Bayesian Reasoners 21
We may also want to disintegrate a joint distribution that is a function of
some parameter, e.g. q A
BZ . In this case eq. (38) becomes
q B
A
Z = q B
A
c B
A
Z
.
(40)
Conceptually this is very similar. We want the disintegration to hold for every
parameter value z ∈Z, and we deﬁne the conditional to be a function of z
as well as of a ∈A. In the discrete case, eq. (40) is analogous to the identity
p(a,b |z) = p(a|z) p(b|a,z).
Bayes’ theorem is closely related to conditional probability and can be ex-
pressed in a similar way. Given a prior q A and a kernel fA B, we can deﬁne
a Bayesian inverse of f with respect to q, which is a kernel f†B A such that
q A
Bf
A
= q A f B
f†
B
A
.
(41)
The Bayesian inverse f†depends on the prior q as well as on the kernel f. If we
had chosen a diﬀerent distribution in place of q, the Bayesian inverse f† would
be diﬀerent. As with conditionals, Bayesian inverses are not necessarily unique,
and for a given f and q there may be many kernels f†that satisfy eq. (41). (In
fact, Bayesian inverses can be seen as a special case of conditionals.)
We may also consider the case where the prior takes a parameter, e.g. qZ A.
In this case a Bayesian inverse in general also needs to depend on the parameter,
which gives us the following more general deﬁnition:
q A
Bf
AZ = q A f B
f†
B
AZ
.
(42)
The references [13,22,37] contain much more detail about Bayes’ theorem in this
form.
B More details about Bayesian interpretations
B.1 Unpacking Bayesian ﬁltering interpretations
In this section we give some more intuition for deﬁnition 2 and then note some
consequences of it. The section deals mostly with the case where S, Y and H are
discrete sets, meaning that we can reason in terms of probability distributions
rather than measure theory. In this case deﬁnition 2 can be written in a form
that makes the relationship to Bayes’ theorem more clear. We deﬁne a notion
of subjectively impossible input, which is a value of S that the reasoner believes
with certainty will not occur as its next input. (This does not imply that the
input actually is impossible according to the true dynamics of the environment.)
22 N. Virgo et al.
We show that deﬁnition 2 puts no constraints on the reasoner’s posterior after
receiving a subjectively impossible input.
We also show that the possible interpretations of a machine only depend on
which states can transition to which other states given which inputs, and not on
the probabilities of such transitions. In addition, we show that some machines
admit no non-trivial interpretations at all.
In order to unpack deﬁnition 2 a little more, let us consider the case where
S, Y and H are discrete. Before starting we note that in the ﬁnite case, the
deﬁnition of ψS, eq. (4), can be written as
ψS(s y) =
∑
h∈H
ψS,H′(s,h y). (43)
In this case, eq. (5) can be written in symbols as
ψS,H′(h,s y)γ(y′ y,s) = ψS(s y)γ(y′ y,s)ψH(h y′), (44)
for all s∈S,h, ∈H,y,y ′∈Y. We can cancel γ(y′ y,s) from both sides on the
assumption that it is positive, yielding
γ(y′ y,s) >0 = ⇒ ψS,H′(h,s y) = ψS(s y)ψH(h y′). (45)
The condition γ(y′ y,s) > 0 means that y′ ∈ Y is a possible next state
when the machine starts in state y ∈Y and receives the input s ∈S. (There
may be many possible next states in this situation because the machine may be
stochastic.)
Let us then suppose that the machine starts in state y, receives an input s,
and transitions to state y′. Let h be an arbitrary element of H. The number
ψS,H′(h,s y) ∈[0,1] can then be seen as the reasoner’s prior probability that
the next state is h and the next input is s. In more traditional notation we
might write this as P(H′= h,S = s), where we leave the state of the underlying
machine implicit. (Here we do not attempt to formalise this in terms of random
variables, but simply treat it as a kind of notational shorthand forψS,H′(h,s y).)
We may then regardψS(s y) as the reasoner’s prior probability that the next
input is s, i.e. P(S = s) = ∑
h∈H P(H = h,S = s).
However, sinceψH(h y′) is conditioned ony′rather than y, we instead regard
it as the reasoner’s posterior probability that H′ = h. (We refer to H′ rather
than H here because after it receives an input its previous “next” hidden state
becomes its current hidden state.) ψH(h y′) therefore corresponds to what we
might write as P(H′= h|S = s).
With this informal shorthand notation eq. (45) then says
P(H′= h,S = s) = P(S = s) P(H′= h|S = s), (46)
which has the same appearance as a familiar identity from elementary probability
theory. It corresponds to a single step of Bayesian ﬁltering, which we spell out
in more detail in appendix B.2.
Interpreting Dynamical Systems as Bayesian Reasoners 23
This shorthand notation gives some intuition for why eq. (5) has the partic-
ular form it does, but it leaves the dependence on the state of the underlying
machine implicit, and in so doing it obscures an important and subtle point. In
a more traditional context, P(H′= h|S = s) is deﬁned by
P(H′= h|S = s) = P(H′= h,S = s)/P(S = s) (47)
and has no value when P(S = s) = 0. However, in our case P(H′= h|S = s)
is a shorthand for ψH(h y′), which is deﬁned even when ψS(s y) = 0.
In the case where P(S = s) > 0, eq. (5) in the form of eq. (46) demands
that P(H′ = h |S = s) is indeed equal to P(H′ = h,S = s)/P(S = s). More
precisely, if ψS(s y) >0 then we must have ψH(h y′) = ψS,H′(h,s y)/ψS(s y).
However, if ψS(s y) = 0 then eq. (5) puts no constraints on ψS,H′(h,s y) at all,
or indeed on ψH(h y).
In the case where S is a discrete set (even if Y and H are not discrete),
we say that s ∈S is a subjectively impossible input for a given state y ∈Y if
ψS(s y) = 0. The point is that the reasoner believes, with certainty, that it will
not receive the input s as its next input. The reasoning above says that in this
situation, any posterior over H is acceptable, because Bayes’ rule doesn’t specify
what the posterior should be. We ﬁnd this somewhat analogous to the fact that
in logic one can deduce any proposition from a contradiction. Deﬁnition 2 indeed
permits any posterior in the case of a subjectively impossible input. In fact, it
even allows the posterior to be chosen stochastically in this case.
This is in a sense the minimal possible assumption we could make. How-
ever, one could imagine addressing the issue in a diﬀerent way by changing the
framework, thus introducing a subtly diﬀerent notion of interpretation than the
one we have presented here. One possibility would be to allow partial interpre-
tations, where ψH becomes a partial function, meaning that not every state of
the machine needs to have an interpretation at all. This would allow the poste-
rior to be undeﬁned in the case of a subjectively impossible input, rather than
merely arbitrarily deﬁned. Another possibility would be to strengthen eq. (5)
with additional conditions, forcing the posterior to be meaningful even after a
subjectively impossible input. We suspect that such an approach can lead to an
interesting way to formalise improper priors, which are also about having mean-
ingful posteriors in the case of ‘impossible’ inputs, but we leave investigation of
this to future work.
We note one other important consequence of the above reasoning, in the
discrete case. When we express eq. (5) in the form of eq. (45), we see that it
only depends on whether a transition from y to y′ is possible given an input
s, and not on the probability of such a transition. Thus, for Bayesian ﬁltering
interpretations (and hence also for Bayesian inference interpretations), the only
property of a machine that matters is which states can be reached from which
other states (in a single step) under a given input. (Strictly speaking this only
makes sense in the discrete case, but we expect an analogous statement to this
to hold more generally.)
24 N. Virgo et al.
Finally we note another consequence: eq. (45) implies that if γ(y′ y,s) >0
for every y,y′,s, then
ψS,H′(h,s y) = ψS(s y)ψH(h y′), (48)
for all y,y′ ∈Y,s ∈S,h ∈H. Note that for any given y ∈Y there must exist
some s∈Ssuch that ψS(s y) >0. It follows thatψH(h y′) must be independent
of y′ in this case. In other words, if a machine is such that γ(y′ y,s) > 0 for
all y,y′,s then it only admits trivial interpretation maps, in which the beliefs
are the same for every state. Therefore the existence of any non-trivial Bayesian
ﬁltering interpretation implies a fairly strong constraint on a discrete machine’s
dynamics, namely that some of its transition probabilities are zero.
B.2 More on Bayesian ﬁltering
In this section we show that deﬁnition 2 does indeed correspond to Bayesian
ﬁltering, at least in the case of a deterministic machine. Our proof of this is
inspired by [24, theorem 6.3], which proves an analogous fact about conjugate
priors. The proof we give uses string diagram reasoning, which means that it
holds even in the most general measure-theoretic context; we do not need to
assume that the sets involved are discrete.
Since we restrict ourselves to only deterministic machines in this section, we
will note a couple of things about deterministic machines before we talk about
Bayesian ﬁltering.
We ﬁrst note that the condition for a machine γ to be deterministic is
.
(49)
This comes from the deﬁning equation for deterministic morphisms, eq. (37),
and also the axiom (35), noting that γ is a kernel with input S⊗Y and output
Y.
Next we prove the following proposition, which is useful for reasoning about
Bayesian ﬁltering interpretations of deterministic machines.
Proposition 1. Suppose γS
Y Y is a deterministic machine, and let ψHY H
and κ S
HH be arbitrary Markov kernels. Then ψH and κ form a consistent
Bayesian ﬁltering interpretation of γ (i.e. deﬁnition 2 is satisﬁed) if and only if
,
(50)
with ψS,H′ and ψS as deﬁned in eqs. (3) and (4).
Interpreting Dynamical Systems as Bayesian Reasoners 25
Proof. To see that deﬁnition 2 implies eq. (50) we marginalise eq. (5):
.
(51)
This implies eq. (50) by the rules for Markov categories, speciﬁcally eqs. (28)
and (32).
For the other direction we assume eq. (50) holds and calculate
.
(52)
The ﬁrst step substitutes in the right-hand side of eq. (50), the second rear-
ranges using the rules of Markov categories, and the third uses the determinism
condition. This proves that eq. (5) holds.
We now consider what a Bayesian ﬁltering task involves. The idea is that the
reasoner has a model of a hidden Markov process, given by the kernel κ S
HH .
As described in the main text, this kernel can be thought of as a process that
simultaneously transforms the hidden state, stochastically, into a new value and
emits a visible “sensor value.”
Given a kernel of this type, we can iterate it to produce sequences of values
in S. For example, we can write
κ3 H
S3
H
=
κκκ
S
S
S
HH HH
,
(53)
where S3 means S⊗S⊗S and κn is notation for iterating the kernel n times.
A kernel of this kind, thought of as an inﬁnitely iterated process, is sometimes
26 N. Virgo et al.
called a “coalgebra,” since it is a special case of a more general concept of that
name. (e.g. [25] takes a coalgebraic approach to de Finetti’s theorem.)
For ﬁltering we are interested in inferring the ﬁnal hidden state of a system,
given a ﬁnite sequence of visible states. In order to reason about this, we deﬁne
the following kernel:
.
(54)
This can be seen as an interpretation map, mapping the state of a reasoner to
its beliefs about its next n inputs, Sn = (S1,...,S n), along with the ﬁnal value
of the hidden state, Hn. These take the form of a joint distribution between Sn
and Hn. This joint distribution is formed from the reasoner’s initial prior over
the initial hidden state H1 (given by the kernel ψH) and the model κ, which is
iterated n times.
We deﬁne this because in ﬁltering we wish to make a probabilistic inference
of the ﬁnal hidden state, Hn, given the sequence of visible states Sn. To infer
Hn given Sn we seek a disintegration of ψSn,Hn. (See eq. (38) in appendix A.3.)
Speciﬁcally, we seek a kernel ψHn|Sn : Sn ⊗Y →P(H) such that
.
(55)
The kernel ψHn|Sn takes in a sequence Sn of observations and returns the rea-
soner’s conditional beliefs about Hn, given the sequence Sn. It is also a function
of the reasoner’s initial beliefs y∈Y.
In fact such a kernel can be constructed iteratively in a natural way, if we
assume that ψH and κform a consistent Bayesian ﬁltering interpretation. To do
this, we ﬁrst deﬁne the iteration of γ, in a similar way to the iteration of κ:
,
(56)
where there are n copies of γ on the right-hand side. We can then state the
following result, which shows that consistent Bayesian ﬁltering interpretations
can indeed be seen as performing Bayesian ﬁltering, in the discrete case.
Proposition 2. The kernel γnSn
Y Y ψH H is a conditional of ψSn,Hn, satis-
fying eq. (55), in that
.
(57)
Interpreting Dynamical Systems as Bayesian Reasoners 27
Proof. We begin by deﬁning the kernel
.
(58)
We also deﬁne its iteration, ( ¯ψS)n: Y →Y ⊗Sn, analogously to κn and γn. We
note that the consistency equation for Bayesian ﬁltering interpretations, eq. (5),
can be written in terms of κ and ¯ψS, as
.
(59)
We then calculate
,
(60)
28 N. Virgo et al.
where the last step is by applying the other steps inductively. We can then apply
a second inductive argument in “the other direction” using eq. (50), as follows:
,
(61)
where the last step is again by applying the other steps inductively.
We have proved that γnSn
Y Y ψH H is a conditional of ψSn,Hn. The kernel
γnSn
Y Y ψH H can be thought of as giving the reasoner’s beliefs about H after
receiving a given sequence Sn of inputs, starting from a given initial state y∈Y.
The result shows that these beliefs are consistent with the agent’s prior ψH(y)
and the model κ, in the sense that the agent’s ﬁnal posterior beliefs aboutHare a
conditional of its initial joint beliefs about the sequence Sn and the ﬁnal hidden
state. We conclude that a deterministic machine with a consistent Bayesian
ﬁltering interpretation can indeed be seen as performing a Bayesian ﬁltering
task. We expect this to be true in the general case of stochastic machines as
well.
B.3 Bayesian inference interpretations and conjugate priors
In the main text we noted that Bayesian inference corresponds to a special case
of Bayesian ﬁltering. By “Bayesian inference” here we mean the case where
the reasoner is interpreted as assuming its inputs are i.i.d. samples from some
known distribution with an unknown parameter space H, which we also call the
hypothesis space.
The diﬀerence between inference and ﬁltering is that we interpret the reasoner
as believing that the value of H is unknown but ﬁxed. That is, the reasoner
Interpreting Dynamical Systems as Bayesian Reasoners 29
assumes that H doesn’t change over time. This corresponds to a special case of
ﬁltering in which κ S
HH = φ S
HH , for some kernel φ that we also call the
model.
While κcan be seen as a model of the environment’s dynamics, φhas more of
the character of a statistical model. It is a model of how the agent’s sensor values
depend on the unknown value of the hidden parameter H. However, we do not
put any constraints on the hypothesis space H or the model φ. In particular, we
do not assume that φ is an injective function H →P(S), and we allow the case
where H is a ﬁnite set.
In the case of inference rather than ﬁltering, the kernels ψS and ψS,H′ from
eqs. (3) and (4) can be written
ψS
Y S = ψH
Y H φ S (62)
and
Y ψS,H
H
S
= ψH
Y H
H
φ S
.
(63)
We write ψS,H instead of ψS,H′ because in the i.i.d. inference case there is only
one hidden variable, that is,H′= H. Thus, the joint distributionψS,H(y) can be
seen as the reasoner’s joint belief about its next input and the hidden variableH,
when its underlying machine is in state y. The consistency equation for Bayesian
inference, eq. (6), then follows by substituting these for ψS,H′ and ψS in eq. (5),
the consistency equation for Bayesian ﬁltering interpretations.
As with Bayesian ﬁltering interpretations, it is useful to consider the case in
which the underlying machine is deterministic (but not necessarily discrete). In
proposition 1 we gave a simpler version of the consistency equation for Bayesian
ﬁltering interpretations, which is equivalent to deﬁnition 2 in the case of a de-
terministic machine. In the inference case we can substitute eqs. (62) and (63)
into this simpliﬁed consistency equation (eq. (50)) to obtain
ψH
Y H
Sφ
H
= ψH
H φY S
S
γ Y ψH
H
.
(64)
This is exactly the equation given by [24, eq. 16] as a deﬁnition of a conjugate
prior.
Both sides of eq. (64) express a joint distribution between S and H, as a
function of Y. In the context of conjugate priors, φ is considered to be a family
of distributions, with parameters H. Our interpretation map ψH corresponds to
another family of distributions, which is a conjugate prior to φ. The machine
state Y corresponds to the so-called hyperparameters, i.e. the parameters of ψH.
This shift in perspective makes sense. In a computational context, conjugate
priors are often useful precisely because they oﬀer a way to perform inference
without needing to directly calculate Bayesian inverses at run-time. Instead, the
implementation only needs to keep track of the hyperparameters and update
30 N. Virgo et al.
them in response to data. This update takes place according to a deterministic
function, whose form depends on the family φ and its conjugate prior ψH. This
updating of the hyperparameters is the role played by γ: it takes in a data
point in S along with the current value of the hyperparameters, and returns the
updated hyperparameters. Equation (64) asserts that this must done in such a
way that the new value of Y does indeed correspond to the correct Bayesian
posterior, when mapped to a distribution over H by the kernel ψH.
We note that it is somewhat nontrivial to ﬁnd a pair of kernels ψH, φand a
function γsuch that eq. (64) is obeyed. However, many such examples are known.
(Although it is not an authoritative source, a useful list can be found online [40,
under “Table of conjugate distributions”], which explicitly gives both kernels and
the update function for each example.) Any example of a conjugate prior can be
seen as a deterministic machine together with a consistent Bayesian inference
interpretation. In addition, in appendix C we give a number of examples of a
diﬀerent ﬂavour, in that in our examples H is either a ﬁnite or a countable set.
B.4 Unpacking Bayesian inference interpretations
We now unpack deﬁnition 3 by converting eq. (6) into more familiar terms in the
case where all the spaces are discrete sets, as we did for ﬁltering interpretations
in appendix B.1.
In the case where Y, H and S are ﬁnite sets, eq. (6) can be written as
ψH(h y) φ(s h) γ(y′ s,m) = ψS(s y) γ(y′ s,y) ψH(h y′), (65)
or equivalently,
γ(y′ s,y) >0 = ⇒ ψH(h y) φ(s h) = ψS(s y) ψH(h y′), (66)
since we can cancel γ(y′ s,y) if we assume it is positive. For γ(y′ s,y) to be
positive means that it is possible for the machine to transition from state y∈Y
to state y′∈Y after receiving the input s∈S.
We can now give an intuitive interpretation to the terms in this equation.
If the machine starts in state y, receives input s, and transitions to state y′ as
a result, then we can regard ψH(h y) as the reasoner’s prior beliefs about the
hypothesis h, ψS(s y) as its prior beliefs about the input s, and ψH(h y′) as
the reasoner’s posterior belief about the hypothesis h. Equation (66) can then
be compared, term by term, to the much more familiar equation
p(h) p(s|h) = p(s) p(h|s). (67)
Here we have writtenp(s|h) in place of φ(s h) and p(h|s) in place of ψH(h y′)
in order to emphasise the similarity to Bayes’ theorem in a more familiar form.
Our deﬁnition, in the form of eq. (6) or eq. (65), diﬀers from this in that it
explicitly takes account of the machine’s state, and φ and ψH are deﬁned by
Markov kernels rather than conditional probabilities.
Interpreting Dynamical Systems as Bayesian Reasoners 31
We note that, as in the case of ﬁltering (appendix B.1), our deﬁnition of
a consistent Bayesian inference interpretation allows the posterior to be arbi-
trary in the case of subjectively impossible inputs, i.e. those s ∈S for which∑
h∈H ψH(h y)φ(s h) = 0 for a given state y ∈Y. Given such an input the
reasoner may update its posterior to anything at all. As with ﬁltering, we regard
this as the minimal assumption we could have made, but we can imagine several
other choices that one could make instead. These include allowing the posterior
to be undeﬁned in such cases; requiring it to be undeﬁned; requiring it to obey
some additional consistency equation such that the posterior would make sense
even on subjectively impossible inputs; or requiring φ and ψH to be such that
subjectively impossible inputs do not exist. We would consider these to be sub-
tly diﬀerent kinds of interpretation, and we leave their further investigation to
future work.
C Details of examples
C.1 An Interpretation Of A Non-Deterministic Finite Machine
We here present a non-deterministic ﬁnite machine with internal state spaceY =
{y0,y1,y2}and sensory input space S = {s1,s2}. One Bayesian interpretation
y0
y2
y1s1
s2
s2
s1
s1
s2
s1
s2
Fig. 1.Transitions for a three-state machine. Deterministic transitions are depicted
using bold arrows, and non-deterministic transitions using regular arrows. The precise
probability values for non-deterministic transitions are not shown, since we only need
to know that they are non-zero.
of this machine, for a hidden state space H = {h1,h2}, is as follows (where δ is
the Kronecker delta):
φ(si hj) = δij
ψ(hi yj) =
{
δij if j ∈{1,2}
0.5 if j = 0.
(68)
32 N. Virgo et al.
Under this interpretation, the model φ ascribed to the machine is that sensory
inputs transparently reﬂect the hidden state. The machine, in internal state y0,
is taken to be uncertain about the hidden state; in state yi ∈{y1,y2}it is taken
to be certain that the hidden state is hi. The dynamics of the machine match
this interpretation: it transitions deterministically to yi when receiving input si,
unless si is “subjectively impossible” ( s2 at m1, and s1 at m2). Behaviour on
subjectively impossible inputs is not constrained by the consistency equation, so
this is a consistent Bayesian interpretation.
C.2 Machine counting occurrences of diﬀerent observations
We now consider a countably inﬁnite deterministic machine (Y0,S,γ 0). Let Y0 =
N+ ×N+ (N+ excludes 0) and the input space be S = {+1,−1}. The machine
deterministically computes the function f0 : (Y0 ×S) →Y0, in the sense that
γ0(f0(y,s) y,s) = 1. Essentially, it keeps distinct count of how many +1 and
−1 inputs it has received. Formally:
f0((i,j),s) =
{
(i+ 1,j) if s= +1
(i,j + 1) if s= −1 (69)
One consistent Bayesian interpretation ( ψ0,φ0) for machine γ0 uses hypothesis
space H0 = [0,1] and model:
φ0(s h) = hδ−1(s)(1 −h)δ+1(s) (70)
where
δu(v) :=
{
1 if u= v
0 else. (71)
This model is known as the categorical distribution for two outcomes (or just the
Bernoulli distribution). The machine states were deliberately chosen to be the
hyperparameters of a possible interpretation map ψ0 : Y0 →H0 which is known
as the Dirichlet distribution (and in this special case also as Beta-distribution):
ψ0(h (i,j)) = 1
B(i,j)hi−1(1 −h)j−1 (72)
where B(i,j) is the Beta function.
This interpretation map (the Dirichlet distribution) is the conjugate priors
for categorical distributions. This implies that (ψ0,φ) form a consistent Bayesian
inference interpretation, as explained in appendix B.3.
C.3 Machine tracking diﬀerences between the number of
occurrences of diﬀerent observations
We now consider another countably inﬁnite deterministic machine ( Y1,S,γ 1)
which has the same input space as the machine in appendix C.2. Let Y1 = Z
Interpreting Dynamical Systems as Bayesian Reasoners 33
and the input space again be S = {+1,−1}. The machine γ0 deterministically
computes a function f1 : (Y1 ×S) →Y1, in the sense that γ1(f1(y,s) y,s) = 1.
Machine γ1 only counts how many more +1 inputs it has received than −1
inputs. Formally:
f1(k,s) = k+ s. (73)
One consistent Bayesian interpretation ( ψ1,φ1) for machine γ1 uses hypothesis
space H1 = {h+1,h−1}and model:
φ(s hi) =
{
0.75 if i= s
0.25 otherwise. (74)
The interpretation map ψ1 : Y1 →H1 is
ψ1(h+1 k) = 1
2(1 + 0.75k0.25−k)
ψ1(h−1 k) = 1
2(1 + 0.75−k0.25k)
(75)
It is relatively easy to verify that (ψ1,φ1) is a consistent Bayesian interpretation
with γ1’s dynamics.
As a teaser for future work we may note the following. Since machine γ0 of
appendix C.2 stores the individual counts for s0 and s1 inputs, it also implicitly
keeps track of the diﬀerence between those counts; γ1 only keeps track of this
diﬀerence. Consequently, we can deﬁne a deterministic kernel g : Y0 →P(Y1)
that maps any state ( i,j) ∈Y0 of γ0 to g(i,j) := δi−j which is a probability
measure over the state space of γ1. It turns out that for this map, for any
k′∈Y1,s ∈S and (i,j) ∈Y0 we have
(γ0 # g)(k′ (i,j),s) =
∑
k
γ1(k′ k,s)g(k (i,j)). (76)
This implies that we can construct an interpretation of machine γ0 from the
interpretation (ψ1,φ1) of γ1. For this we precompose the interpretation map ψ1
for γ1 with the machine map g to get a consistent Bayesian inference interpre-
tation (g# ψ1,φ1) for γ0. In future work we intend to further develop the theory
of how a consistent interpretation of one deterministic machine can be “pulled
back” to other machines that are related in a similar way to eq. (76).
D Details on the relation to the FEP
We here try to identify the structures in the FEP that are analogous to the
notions of machine γ, model κ, and interpretation map ψH. This suggests that,
at least in some treatments of FEP, there is an implicit concept that is close
to what we have called a reasoner. We will call this putative concept the FEP
reasoner.
34 N. Virgo et al.
Large parts of the FEP literature do not explicitly deal with FEP reasoners
but are sometimes presented as based on them (e.g. in [20]). The parts that
construct the FEP reasoner are those called “Bayesian mechanics” and are still
evolving. A standard reference is [19] but this is known to contain some issues
[9,21,1]. The most recent version can be found in [16].
Understanding precisely the relationship between the concepts of our Bayesian
and the FEP reasoner is future work. The following are preliminary observations.
D.1 Machine
We ﬁrst identify the structure in the FEP setup that is most closely related to a
machine and is also said to appear to perform Bayesian inference. Unfortunately,
the latest iteration of the conditions under which there exists an FEP reasoner,
which is [16], does not make this particular structure as explicit as the previous
version [19]. We will therefore identify this structure in the older version. A
corresponding structure should also exist in the newer version and we will hint
at how it may diﬀer.
The FEP setup in [19] consists of four sets of variables η ∈E,s ∈S,a ∈
A,µ ∈M called external, sensory, active, and internal states with E,S,A,M
ﬁnite dimensional real vector spaces. These variables obey the stochastic diﬀer-
ential equations
˙η= fη(η,s,a ) + ωη
˙s= fs(η,s,a ) + ωs
˙a= fa(s,a,µ ) + ωa
˙µ= fµ(s,a,µ ) + ωµ
(77)
where ωη,ωs,ωa,ωµ are independent Gaussian noise terms. The FEP goes be-
yond the scope of a reasoner and formulates a concept of agent. The concept
of an agent should, as part of its interpretation, make it possible to talk about
deliberate actions. In the FEP deliberate actions are associated to the active
states a. At the same time, the internal states are only involved in inference (or
ﬁltering) and the special case where there are no active states seems to be within
the scope of the FEP. This should still leave us with a FEP reasoner and make
it more comparable to our Bayesian reasoner. We therefore consider the special
case where there are no active states such that we get:
˙η= fη(η,s) + ωη
˙s= fs(η,s) + ωs
˙µ= fµ(s,µ) + ωµ.
(78)
This looks like a continuous time version of the Bayesian network in eq. (1) and
has the somewhat signiﬁcant feature that all inﬂuences from the external states
η are mediated by the sensory states s. This suggests that it is possible to see
the sensory states s∈S as inputs to a machine state µ∈M with the external
states η∈E “hidden behind” the sensory states.
Interpreting Dynamical Systems as Bayesian Reasoners 35
The internal states µ∈M are supposed to appear to infer the external states.
So the state space Y of the machine of the FEP reasoner should be identiﬁed
with M. Going by their name and their role in the earlier dynamics of eq. (77)
it seems reasonable to identify the sensory state space S with the input state
space (also S in our notation) of the machine.
This brings us to the machine’s kernel γ. Our formalism does not deal with
continuous-time kernels at the moment so we only make some informal comments
here. Note that none of the following statements should be considered as proven.
Since all variables together form a (time-homogeneous) Markov process, we can
choose times t,t + τ with τ >0 and write the conditional probability density
(assuming things are well behaved enough) at a state ( η′,s′,µ′) at t+ τ given a
state (η,s,µ ) at time tas p(η′,s′,µ′,t+ τ |η,s,µ,t ) (this notation is taken from
[35, p.31]). We can then marginalise out η′ and s′ to get p(µ′,t + τ |η,s,µ,t )
which looks a bit closer to a machine kernel but still depends also on η. We
cannot just drop η from this expression even if we assume eq. (78) holds since
within a time interval [t,t + τ] with τ >0 the inﬂuence from η would propagate
through the intermediate values of the sensory states to µ′. Instead we here
condition on all those intermediate values of the sensory state between t and
t+ τ. Write s[t: t+ τ] for a part of the trajectory of the sensory state between
t and t+ τ that starts in s. Then, assuming eq. (78) we should get:
p(µ′,t + τ |η,s[t: t+ τ],µ,t ) = p(µ′,t + τ |s[t: t+ τ],µ,t ). (79)
In order to make this look even more like a kernel we may take the limit as
τ →0 and so we write
γ(µ′|µ,s) := lim
τ→0
p(µ′,t + τ |s[t: t+ τ],µ,t ) (80)
which is just a notation for an expression that hopefully provides suﬃcient in-
tuition for our purposes.
What is important is that within the system eq. (78) there should be a
(continuous-time) machine describing the dynamics of the internal states in re-
sponse to sensory states.
In [16] the structure of eq. (77) and thus eq. (78) is no longer assumed. This
means all variables can directly inﬂuence each other and the sensory states no
longer play a special role. However, the sensory (and usually the active states)
are still special due to an additional assumption. The larger process has to have
a stationary distribution p(η,s,a,µ ) that factorises according to
p(η,s,a,µ ) = p(η|s,a)p(µ|s,a)p(s,a) (81)
which is referred to as a Markov blanket. With this assumption only, one can no
longer assume that the sensory states s[t: t+ τ] can “shield” those states from
direct inﬂuence by external states, which makes it more diﬃcult to compare the
dynamics to our setup. A solution may be to use a continuous-time version of
the approach in [36]. Below we ignore this issue and assume that we have the
structure of eq. (78).
36 N. Virgo et al.
D.2 Model
For a reasoner we also need a model and an interpretation map. As already men-
tioned the FEP assumes that the system in eq. (77) has a stationary distribution
p(η,s,µ ). One purpose of this assumption seems to be the deﬁnition of what we
call the model. In the language of the FEP literature the stationary distribution
deﬁnes the generative model. Here, generative model refers to a joint probability
distribution over causes (parameters/hidden variables) and observed variables.
In [16, Section 3.b)] the generative model is deﬁned to be p(η,s,µ ) with η as the
hidden variables and observed variables (s,µ). We are not sure whyµis also seen
as an observed variable and not only s. This could mean that the machine state
µ itself is also modelled by an FEP reasoner. However, this would need further
investigation that we leave for future work. So we resort to a previous version
where only the marginalised stationary distribution p(η,s) was considered as
the generative model ([34, Fig.3],[19, p.101]). In that case the hidden variable
space H in our notation should be identiﬁed with the external state space E and
the model (in our sense) is a conditional distribution induced by the stationary
distribution:
φ(s|η) := p(s|η). (82)
Note that, this choice of a model by itself does not immediately tell us whether
the FEP reasoner does ﬁltering or just inference in the sense of deﬁnition 3. A
model like φ(s η) can be part of a ﬁltering kernel κ as well. In both cases we
also need an interpretation map.
D.3 Interpretation map
For the interpretation map ψH we need a kernel of type M →P(E). Indeed, a
kernel that has the right type can be identiﬁed in the FEP literature. This kernel
is denoted qµ(η) and we will identify ψH(η µ) = qµ(η). The kernel’s deﬁnition,
however, relies on another assumption of the FEP, namely the existence of a
“synchronisation map” σ : M →E. To construct σ let us ﬁrst deﬁne two other
functions gM : S →M and gE : S →E via
fM(s) := Ep(µ|s)[µ]
fE(s) := Ep(η|s)[η] (83)
and then set
σ(µ) := fE(f−1
M (µ)) (84)
which is assumed to be well deﬁned. For details on when this exists in the linear
case see [1,16]. With this we can deﬁne qµ(η) and in turn the interpretation map
ψH. This maps an internal state µto the Gaussian distribution with mean value
equal to σ(µ):
ψ(η µ) := qµ(η) := N(η; σ(µ),Σ(µ)) (85)
Interpreting Dynamical Systems as Bayesian Reasoners 37
where the variance Σ(µ) is deﬁned as the variance of the best Gaussian approx-
imation to the model p(s|η = σ(µ)) when the external state is equal to σ(µ)
[34, Eq.2.4]. Note that in [16] the whole stationary distribution is assumed as
Gaussian and so p(η|µ) in the corresponding equation in that publication (i.e.
Eq.3.3) is also a Gaussian.
In conclusion, the necessary ingredients for something like a Bayesian rea-
soner seem to be present in the FEP literature. One thing that is special about
the FEP reasoner is that its model κ and interpretation map ψH are derived
from features of the process that the machine is embedded in.
We do not know whether there is an appropriate notion of consistency equa-
tion that the FEP reasoner obeys. Presumably, instead of the equation for exact
inference that we have presented, such an equation would express the idea that
the FEP reasoner performs approximate inference in the form of free energy min-
imisation. Other diﬀerences are that the FEP takes place in continuous time,
and perhaps more signiﬁcantly, that it deals with deliberate actions as well as
inference. However, it is not inconceivable that these could be expressed in the
form of a consistency equation.
In the current formulations of the FEP, the interpretation is derived from
the properties of the ‘true’ environment, such as the stationary distribution, or
the synchronisation map σ. In our consistency equation approach, this need not
be the case, since a reasoner’s beliefs only need to be consistent and need not be
correct. This means in particular that no stationarity assumption is needed.
Nonetheless, perhaps an important idea behind the FEP is that the model
that most closely corresponds to the true environment can be considered the best
one. A consistency equation approach would still be helpful, in order to systemat-
ically explore whether and how interpretations should relate to the larger process
in which the machine is embedded.