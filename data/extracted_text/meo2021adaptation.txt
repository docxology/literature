1
Adaptation through prediction: multisensory
active inference torque control
Cristian Meoa, Giovanni Franzesea, Corrado Pezzatoa, Max Spahna and Pablo Lanillosb
Abstract—Adaptation to external and internal changes is Bayesian model evidence. This approach, which grounds on
major for robotic systems in uncertain environments. Here we variational inference and dynamical systems estimation [12],
present a novel multisensory active inference torque controller
hasstrongconnectionswithBayesianfiltering[29]andcontrol
for industrial arms that shows how prediction can be used to
as inference [21], as it both estimates the system state and
resolve adaptation. Our controller, inspired by the predictive
brain hypothesis, improves the capabilities of current active computes the control commands as a result of the inference
inference approaches by incorporating learning and multimodal process. Recent experiments in humans indicates that sensory
integration of low and high-dimensional sensor inputs (e.g., raw prediction errors may be responsible for body estimation
images) while simplifying the architecture. We performed a
and also involuntary adaptive active strategies that suppress
systematic evaluation of our model on a 7DoF Franka Emika
multisensory conflicts [16]. Here we show that once the robot
Pandarobotarmbycomparingitsbehaviorwithpreviousactive
inference baselines and classic controllers, analyzing both qual- has learned to predict the (multi)sensory input then it can
itatively and quantitatively adaptation capabilities and control exploit those predictions to adapt to unexpected world/body
accuracy. Results showed improved control accuracy in goal- variations, such as measurements noise, force disturbances,
directed reaching with high noise rejection due to multimodal
environmental changes (e.g., gravity or elasticity constraints)
filtering,andadaptabilitytodynamicalinertialchanges,elasticity
and internal changes (e.g., inertia or motor stiffness). We
constraints and human disturbances without the need to relearn
the model nor parameter retuning. combine state representation learning [19] with variational
free energy optimization in generalized coordinates [8, 22]
toinferthetorquesneededtoachievegoal-directedbehaviors.
I. INTRODUCTION We evaluated our approach in several real-world experiments
Real world complex robots, such as airplanes, cars and ma- with a 7DoF Franka Emika Panda robot arm and comparing
nipulators may need to process unstructured high-dimensional it to state-of-the-art baselines in AIF and classic controllers.
data coming from different sensors depending on the domain
ortask(e.g.,LIDARincars,sonarinsubmarinesanddifferent
A. Related Works
sensorstomeasuretheinternalstateoftheroboticsystem).In
thiscontext,oneofthebiggestchallengesismappingthisrich In 2003 Yamashita and Tani [30] described a robotic ex-
stream of multisensory information into a lower-dimensional periment that can be linked with the theory of what now
space that integrates and compresses all modalities into a is established as active inference [8]. They were able to
latent representation; the agent could then use this embedded generate motor primitives from sensorimotor experience in a
latent representation that encodes the state of the robot and top-down fashion. Since then, many researchers have pursued
the world aiding the controller. Another key challenge is the design of these type of biologically (functional) plausible
how to use this enconded representation to deal with real controllers [4]. Recently, a state estimation algorithm and
world applications with changes and uncertainty. These en- an AIF-based reaching controller for humanoid robots were
vironments may always present unmodeled behaviours, such proposedin[15]and[22]respectively,showingrobustsensory
as air turbulence in airplanes, unmodeled dynamics of water fusion (visual, proprioceptive and tactile) and adaptability to
streams, or unexpected parameter changes. In the last years, unexpected sensory changes in real experiments. However,
some proof-of-concept studies in robotics have shown that they could only handle low-dimensional inputs and did not
Active Inference (AIF) may be a powerful framework to implement low-level torque control. Latterly, adaptive active
address challenges [18], such as adaptation [22, 28], ro- inference torque controllers [2, 25] showed better perfor-
bustness [1, 2] and multisensory integration [17, 20]. AIF mances than a state-of-the-art model reference adaptive con-
is prominent in neuroscientific literature as a biologically troller. However, they cannot handle high-dimensional inputs.
plausible mathematical construct of the brain based on the Furthermore, an AIF planning algorithm was presented in
Free Energy Principle (FEP) [7]. According to this theory, [11, 27], showing that the introduction of visual working
the brain learns a generative model of the world/body that memoryandthevariationalinferencemechanismsignificantly
is used to perform state estimation (perception) as well as improve the performance in planning adequate goal-directed
to execute control (actions), optimizing one single objective: actions.[28]showedtheplausabilityofusingneuralnetworks
architectures to scale AIF to raw images inputs. Lastly, in a
a:FacultyofMechanicalEngineering,DepartmentofCognitiveRobotics,
previousworkwepresentedaMultimodalVariationalAutoen-
DelftUniversityofTechnology,Delft,TheNetherlands
coder Active Inference (MAIC-VAE) [20] torque controller,
b: Donders Institute for Brain, Cognition and behaviour, Department of
ArtificialIntelligence,RadboudUniversity,Nijmegen,TheNetherlands. which integrated visual and joint sensory spaces. However,
1202
ceD
31
]OR.sc[
1v25760.2112:viXra
2
a clear and systematic comparison on adaptation between Generative models. Twogenerativemodelsgoverntherobot:
AIF and classic controllers is still missing. Besides, [20] the mapping function between the robot’s state and the
did not present the generalized mathematical framework of sensory input g(z˜) (e.g., forward kinematics) and the
multisensory active inference torque control scheme and the dynamics of the internal state f(z˜) [3].
experiments were only in simulation.
x˜ =g(z˜)+˜r (2)
B. Contribution Dz˜=f(z˜)+w˜ (3)
We describe the multisensory active inference controller
where r ∼ N(0,Σ ) and w ∼ N(0,Σ ) are the
(MAIC) which extends current active inference control ap- x˜ z˜
sensoryandprocessnoiserespectively.Σ andΣ arethe
proaches in the literature by allowing function learning [14, x˜ z˜
covariance matrices that represent the controller’s confi-
17] through multimodal state representation learning [19]
dence about each sensory input and about its dynamics
while maintaining the adaptation capabilities of an active
respectively.
inference controller and working at the level of torque. We
Variational Free Energy (VFE). The VFE is the optimiza-
providethegeneralmathematicalframeworkoftheMAICand
tion objective for both estimation and control. We use
we derive two versions of the proposed algorithm as proof-
the definition of the F based on [8], where the action
of-concepts.Finally,weexperimentallyevaluatedtheproposed
is implicit within the observation model x(a). Using the
algorithmona7DOFFrankaEmikaPandaarmunderdifferent
KL-divergence the VFE is:
conditions.WesystematicallycomparedtheMAICwithstate-
of-the-art torque active inference controllers, such as the AIC
F =KL[q(z˜)||p(z˜|x˜)]−logp(x˜) (4)
[25]andtheuAIC[2],andstandardcontrollers,suchasmodel
predictivecontrol(MPC)andjointimpedancecontrol(IC).We
where q(z˜), p(z˜|x˜) and p(x˜) are the variational density,
present both qualitative and quantitative analysis in different
posterior and prior distribution. The VFE is an upper
experiments, focusing on adaptation capability and control
bound on the model evidence, and the minimization of
accuracy.
the VFE will result in a minimization of surprise, and
thus, a maximization of model evidence.
II. AIFGENERALFORMULATIONANDNOTATION
State estimation using gradient optimization:
Hereweintroducethestandardequationsandconceptsfrom
the AIF literature [7], and the notation used in this paper, ˜z˙ =Dz˜−k ∇ F(x˜,z˜) (5)
z z˜
framed for unimodal estimation and control of robotic sys-
tems[22].Theaimoftherobotistoinferitsstate(unobserved Control using gradient optimization:
variable) by means of noisy sensory inputs (observed). For
∂x˜
that purpose, it can refine its state using the measurements a˙ =−k ∇ F(x˜,z˜) (6)
or perform actions to fit the observed world to its internal
a∂a x˜
model. This is dually computed by optimizing the variational where k and k are the gradient descent step sizes. The
z a
free energy, a bound on the Bayesian model evidence [3]. VFEhasaclosedformundertheLaplaceandMean-field
System variables. State, observations, actions and their n- approximations [3, 22] and it is defined as:
order time derivatives (generalized coordinates).
x=[x 1 ,x 2 ,...,x c ] , sensors observations (c sensors) F(z˜,x˜)(cid:44)−lnp(z˜,x˜)− 1 ln(2π|Σ|)(cid:39)−p(x˜|z˜)p(z˜)
2
r=[r ,r ,...,r ] , sensory noise (c sensors)
1 2 c (cid:44)(x˜−g(z˜))TΣ−1(x˜−g(z˜))
x˜ =[x,x(1),...,x(nd)] , generalized sensors
+(Dz˜−f(z˜)
x
)
˜
TΣ−1(Dz˜−f(z˜))
z˜
z˜=[z,z(1),...,z(nd)] , multimodal system state 1 1
+ ln|Σ |+ ln|Σ | (7)
µ˜ =[µ,µ(1),...,µ(nd)] , proprioceptive state 2 x˜ 2 z˜
˜r=[r,r(1),...,r(nd)] , generalized sensory noise whereΣistheoptimalvariancewhichoptimizestheVFE
[3]. The first two terms of Eq. (7) are the sensor and
w˜ =[w,w(1),...,w(nd)] , state fluctuations
dynamics prediction error, while the last two are sensory
a=[a 1 ,a 2 ,...,a p ] , actions (p actuators) and dynamics log variances (uncertainty associated).
(1) Defining the goal through the internal dynamics. As in
[28] we define the system internal dynamics f(z˜) as:
Where the notation x(n) = dnx is adopted for the n-
dtn
th order derivative and n d is the chosen number of ∂g(z˜)
f(z˜,ρ=x )= (x −g(z˜)) (8)
generalised motions. Depending on the formulation the d ∂z˜ d
action a can be force, torque, acceleration or velocity. In
whereρ=x steersthesystemtowardsthedesiredtarget.
this work action refers to torque. We further define the d
time-derivative of the state vector Dz˜ as: In other words, the desired goal x d produces an error
respect the inferred state g(z˜) which causes an action
d
Dz˜= ([z,z(cid:48),...,zn])=[z(cid:48),z(cid:48)(cid:48),...,zn+1] towards x itself.
dt d
3
III. ARCHITECTUREANDDESIGN:MULTIMODALACTIVE (MAIC-GP), while in the second case we scale to the full
INFERENCECONTROLLER rawimagesx
v
(i.e.high-dimensionalsensoryinputs),learning
the mapping through a multimodal variational autoencoder
Aslongaswecanlearnthegenerativemappingofacertain
(MAIC-VAE).
sensoryspace,wecanaddanymodalitytoEq.(5),combining
free energy optimization [8] with generative model learning
andperformingsensoryintegration.Theonlineestimationand A. MAIC-GP
control problem is solved by optimizing the VFE through
Here we describe the multimodal active inference for low-
gradient optimization, computing Eq. (5) and (6). We first in-
dimensional inputs (e.g., end-effector position). We define
troducetherequiredpreliminaries.Consequently,weillustrate
the multi-sensory state and the sensory generative functions
the multimodal active inference update equations and the full
respectively as:
algorithm. x=[x , x ] (11)
q ee
g (µ)=µ (12)
q
A. Multimodal Active Inference
g (µ)=GP (µ) (13)
ee ee
As discussed in [3], Eq. (7) can be extended for different
modalities. Hence, state estimation and control equations can where g q (µ), as in [25], is the proprioceptive generative
be derived for the multimodal case as well. We define the sensory function (i.e., joint states), and g ee (µ) is the end-
sensory generative function g(z˜) with multiple modalities as effectorgenerativesensoryfunction.Sincethisimplementation
g(z˜) = [g (z˜),...,g (z˜)]. Therefore, substituting Eq. (7) into isaproof-of-conceptandweareassumingthatwedonotknow
1 c
Eq. (5) and (6) and rewriting it for the multimodal case, we the system dynamics, as in [15], g ee (µ) is computed using
can obtain the multimodal state estimation update law: a Gaussian Process (GP) regressor between proprioceptive
sensory input and end-effector positions. This approach is
c (cid:18) (cid:19)
z˜˙ =Dz˜+ (cid:88) k ∂g m (z˜) Σ−1(x −g (z˜)) particularly useful because we can compute a closed form for
m ∂z˜ m m m thederivativeofthegaussianprocesswithrespecttothebeliefs
m=1
∂f(z˜,ρ) µ, which is required for the multimodal state update law, Eq.
+k z ∂z˜ Σ− z˜ 1(x d −f(z˜,ρ)) (9) (9).
1) Learning: We train the model through guided self-
and the control equation:
supervised learning. This generated a dataset of 9261 pairs
c
a˙ =− (cid:88) k ∂ x Σ−1(x −g (z˜)) (10) end-effector positions and joint values (X ee ,X q ). We use a
am a m m m m squared exponential kernel k of the form:
m=1
where k m and k am are state estimation and control gradient k(x q i ,x q j )=σ f 2 e (− 2 1(xqi −xqj )TΘ(xqi −xqj )) +σ n 2d ij (14)
descent step sizes related to modality m, and ∂
a
x
m
= ∂
∂
x
a
m.
wherex ,x ∈X ,d istheKronockerdeltafunctionand
Algorithm1illustratesthegeneralmultimodalactiveinference q i q j q ij
Θ is the hyperparameters diagonal matrix. We can compute
controller scheme.
theend-effectorlocationgivenanyjointstateconfigurationas:
Algorithm 1 MAIC
g (µ)=k(µ,X )K−1X (15)
ee q ee
Require: x ={x ,x ,...,x }
while ¬go d al rea d c 1 hed d2 do dc Finally, we can compute the derivative of g ee (µ) with respect
to µ as:
x=[x ,x ,...,x ]←cSensors
1 2 c
∂g (µ)
StateEstimation ee =−Θ−1(µ−X )T[k(µ,X )T ·α] (16)
z˜˙ ←multimodal state updatelaw Eq.(9) ∂µ q q
where K is the covariance matrix, α = K−1X and ·
Control Action ee
a˙ =− (cid:80)c k ∂ x Σ−1(x −g (z˜)) representselement-wisemultiplication.Additionalinformation
m=1 am a m m m m about GP learning procedure can be found in Appendix B.
Euler Integration 2) State estimation and Control: Substituting Eq. (12) and
z˜+=δ t z˜˙ (13) into Eq. (9) and (10), we can now write the state
a+=δ t a˙ estimation update laws:
end while ∂g (µ)
µ˙ =µ(1)+k Σ−1(cid:15) +k Σ−1 ee (cid:15) −k Σ−1(cid:15)
µ q xq ee ee ∂µ xee µ µ µ
(17)
IV. ALGORITHMIMPLEMENTATIONS
µ˙(1) =µ(2)+k Σ−1(cid:15) −k Σ−1(cid:15) −k Σ−1 (cid:15) (18)
In this work we present two different implementations of µ q˙ q˙ µ µ µ µ µ(1) µ(1)
the same algorithm as proofs-of-concept, chancing the dimen- µ˙(2) =−k Σ−1 (cid:15) (19)
µ µ(1) µ(1)
sionality of the used sensory input. In the first case we use
end-effector positions (i.e. low-dimensional sensory inputs) where Σ−1 are the inverse variance (precision) matrices
i
x ,learningthegenerativemappingwithGaussianProcesses related to state observations and internal state beliefs and
ee
4
(cid:15) are the Sensory Prediction Errors (SPE), with i ∈ As we do not have access to the high-order generalized
i
{x ,x ,x ,µ,µ(1)}. SPE represent the errors between ex- coordinates of the latent space z(cid:48),z(cid:48)(cid:48), we track both the
q q˙ ee
pected sensory inputs and observed ones and are defined as: multimodal shared latent space z and the higher orders of
the proprioceptive (joints) state µ(1),µ(2). Thus, we update
(cid:15) =x −µ (20)
xq q the proprioceptive state velocity and acceleration using Eq.
(cid:15) xq˙ =x q˙ −µ(1) (21) (18) and Eq. (19), while the joint angles are predicted by the
(cid:15) xee =x ee −g ee (µ) (22) MVAE: µ = g q (z). Finally, as before the action (torque) is
computedbyoptimizingtheVFEusingEq.(6).Here,sincewe
(cid:15) =µ(1)+µ−x (23)
µ q
d cannoteasilycomputethepartialderivativeofg withrespect
v
(cid:15) =µ(1)+µ(2) (24)
µ(1) to the action, we only consider the proprioceptive errors.
Finally, we can rewrite the control equation as: Thus, the torque commands are updated with the following
differential equation:
∂g (µ)
a˙ =−k (∂ x Σ−1(cid:15) +∂ x Σ−1(cid:15) +∂ x ee Σ−1(cid:15) )
a a q q xq a q˙ q˙ xq˙ a ee ∂µ ee xee a˙ =−k (Σ−1(cid:15) +Σ−1(cid:15) ) (31)
(25) a q xq q˙ xq˙
Note that, as in [25], inEq. (25) the partial derivatives with
whereeveninthiscasewejustconsiderthesignofthepartial
respect to the action are set to identity matrices, encoding derivatives ∂ µ,∂ µ(1).
a a
just the sign of the relation between actions and the change
in the observations. Although we can compute the action
V. RESULTS
inverse models ∂ x ,∂ x ,∂ x through online learning A. Experiments and evaluation measures
a q a q˙ a ee
usingregressors[14],welettheadaptivecontrollerabsorbthe
WesystematicallyevaluatedourMAICapproachina7DOF
non-linearities.Thus,asdescribedby[25]wejustconsiderthe
Franka Emika Panda robot arm. We performed three different
sign of the derivatives.
experimental analyses and compared the MAIC approach
against two state-of-the-art torque active inference controllers
B. MAIC-VAE
(AIC[25] and uAIC[2]) and two classic controllers: model
Herewedescribethemultimodalactiveinferencecontroller predictivecontrol(MPC,AppendixA)andimpedancecontrol
for high-dimensional sensory inputs. We use the autoencoder (IC, Appendix E).
architecture to compress the information into a common 1) Qualitative analysis in sequential reaching (Sec. V-C).
latent space z that represents the system internal state. We We evaluated MAIC approaches qualitative behaviours,
definethemulti-sensorystateandsensorygenerativefunctions focusing on how multimodal filtering affects control
respectively as: accuracy on the presented controllers.
2) Adaptation study (Sec. V-D). We evaluated the re-
x=[x , x ] (26)
q v
sponse of the system to unmodeled dynamics and en-
g (z)=decoder (z) (27)
q q vironment variations by altering dynamically the mass
g v (z)=decoder v (z) (28) matrix (Inertial Experiment), by adding an elastic con-
straint(ConstrainExperiment),byaddingrandomhuman
where decoder (z) and decoder (z) describe the mapping
q v
disturbances (Human disturbances experiment) and by
between z and the sensory spaces. The interested reader can
addingrandomnoisetothepublishedjointsvalues(Noisy
find a detailed description of MAIC-VAE in [20].
1) Generative models learning: The multimodal varia- Experiment).
tional autoencoder (MVAE) was trained through guided self- 3) Ablation analysis in sequential reaching (Sec. V-C). We
supervised learning. The dataset generated (50000 samples) evaluatedthealgorithmaccuracyandbehaviourremoving
consisted in pairs of images with size (128x128) and joint an- the extra modality from the algorithm.
gles(X ,X ).Inordertoacceleratethetraining,weincluded In order to evaluate the experiments, we used the following
v q
a precision mask Π = Σ−1, computed by the variance of evaluation metrics:
xv xv
all images and highlighting the pixels with more information. • Jointsperceptionerror.Itistheerrorbetweentheinferred
The augmented reconstruction loss employed was: (belief) and the observed joint angle. The more accurate
thepredictionsare,thelowerwillbetheperceptionerror.
L=MSE((1+Π )g (z), x )+MSE(g (z),x ) (29)
xv v v q q
• Joints goal error. It is the error between the current joint
wherex q ∈X q andx v ∈X v .AppendixCprovidesadetailed angles and the desired ones (goal).
description of MVAE learning procedure. • Image reconstruction error. It is the error between the
2) State Estimation and Control: As in MAIC-GP, substi- predicted visual input and the observed image. It is com-
tutingthedefinedgenerativemappings,Eq.(27)and(28),into puted as the Frobenius norm of the difference between
Eq. (9) and (10), we can rewrite the state estimation update current and goal images. It describes the accuracy of the
law: visual generative model.
z˙ =k ∂g vΣ−1(x −g (z))+k ∂g qΣ−1(x −g (z)) • End-effector reconstruction error. It is the Euclidean
v ∂z xv v v q ∂z q q q distancebetweenthepredictedend-effectorpositionsand
∂f theonescomputedthroughtheforwardkinematicsofthe
−k Σ−1(x −f(z,ρ)) (30)
z∂z f d observed joints.
5
To summarize, joints perception and image reconstruction 1) MAIC-VAEqualitativebehaviour: Figures2a,2band2c
errors measure how well the state is estimated, while joints illustrate MAIC-VAE qualitative internal behaviour. It can be
goal errors give a measure of how well the control task is seenthatbothmodalitiesaresuccessfullyestimated.However,
executed. Fig. 2a shows that joints reconstructions present overshoot,
leading to a similar behaviour on the control task, as shown
B. Experimental setup and parameters
on Fig. 3. Moreover, the robot updates its internal belief
Experiments were performed on the 7DOF Franka Panda by approximating the conditional density, maximizing the
robotarmusingROS[13]astheinterface,Pytorch[23]forthe likelihood of the observed sensations and then generates an
MVAEandSklearn [24]fortheGaussianProcesses.AnIntel action that results in a new sensory state, which is consistent
RealsenseD455camerawasusedtoacquirevisualgreyscaled with the current internal representation. However, the visual
images with size 128x128 pixels. The camera was centred in decoder require much more computational time than the main
front of the robot arm with a distance of 0.8 m. control loop, leading to the irregular behaviour showed on
The tuning parameters for the MAIC controllers are:
• Σ xv : Variance representing the visual sensory data con-
fidence which was set as the variances of the training
dataset.
0.8
• δ t =0.001: Euler integration step;
• Σ q =3,Σ q˙ =3,Σ µ =5,Σ µ(1) =5,Σ f =4,Σ ee =6: Variances 0.6
representing the confidence of internal belief about the 0.4
states; 0.2
• k µ =18.67,k q =1.5,k v =0.2,k ee =1.4,k a =9: The learning 0.0
rates for state update and control actions respectively
-0.2
were manually tuned in the ideal settings experiment.
-0.4
All experiments were executed on a computer with CPU: -0.6
Intel core i7 8th Gen, GPU: Nvidia GeForce GTX 1050 Ti. 1 0 17 34 51 68 85
time [s]
C. Qualitative analysis in a sequential reaching task
In order to analyse MAIC qualitative behaviour, we de-
signed a sequential reaching task with desired goals x =
d
[x , x ] and x = [x , x ], respectively defined for
q
d
eed d q
d
vd
MAIC-GP and MAIC-VAE. The sequential reaching task
is evaluated using four different desired states, defined by
the final joint angles {x ,x ,x ,x }, expressed in
q q q q
d1 d2 d3 d4
radiants:
• x q =[0.45, −0.38, 0.32, −2.45, 0.14, 2.06, 1.26]
d1 • x q =[0.70, −0.15, 0.10, −2.65, 0.31, 2.55, 1.23] d2
• x q =[−0.03,−0.73,−0.25,−2.69,−0.18, 1.83, 0.79] d3 • x q =[0.31, −0.47, 0.38, −2.16, 0.14, 1.71, 1.28] d4
thedesiredend-effectorpositions{x ,x ,x ,x }
eed1 eed2 eed3 eed4
and the desired visual input {x ,x ,x ,x }, where
vd1 vd2 vd3 vd4
(a) x (b) x (c) x (d) x
vd1 vd2 vd3 vd4
Fig. 1: Goal poses images.
bothdesiredend-effectorpositionsandvisualinputaredefined
consistently with the desired joint positions. In order to
select unbiased desired goals, all the desired joint poses were
randomly sampled from the dataset. In all experiments the
robot starts from the home position (x =x rad).
q q
home d4
1For reproducibility, the code is publicly available at https://github.com/
Cmeo97/MAIC.
]dar[
rrE
tnioJ
J_0 J_3 J_5
J_1 J_4 J_6
J_2
21
18
15
12
9
6
3
0 0 10 20 30 40 50 60 70 80
time [s]
(a) MAIC-VAE: Joints perception
error
]lexiP[
rrE_lexiP
Im_Err
(b) Image reconstruction error
(c) Sequence of some predicted visual input g (z)
v
0.6 0.4
0.2
0
-0.2
-0.4
-0.6
0 17 34 51 68 85
time [s]
]dar[
tnioj
rrE
j_0 j_3 j_5
j_1 j_4 j_6 j_2 0.4
0.35 0.3 0.25
0.2
0.15
0.1
0.05
0 0 17 34 51 68 85
time [s]
(d) MAIC-GP: Joints perception
error
]m[ rotceffE-dnE
rrE
End-Effector reconstruction error
(e) End-effector reconstruction
error
Fig. 2: Qualitative analysis of the error measures in the
sequential reaching of four goals. All errors present peaks
when a new goal is set. (a-d) Each line represents the error
between the i-th joint belief and the ground truth. (b) Image
reconstruction error. (c) Sequence of the predicted images by
the generative model along the trajectory. (e) End-effector
Reconstruction error.
Fig. 2a. Although Fig. 2b shows that image reconstructions
present different errors for different poses, Fig. 2c shows that
the image reconstructions through the experiment are well
6
reconstructed.
2) MAIC-GP qualitative behaviour: Figures 2d and 2e
illustrate MAIC-GP qualitative internal behaviour. As in the
previous case, both modalities are successfully estimated.
Figure 2d shows that MAIC-GP joint estimations do not
overshoot.
3) Vanilla Comparison: Figure 2 illustrates the qualitative
behaviour of the compared controllers. From one goal to the
nextonetheerrorsdropdown.Althoughthejointbelieferrors
(Fig. 2a) show synchronous convergence without significant
steady-state errors, due to slow algorithmic frequency the
MVAE-AIC behaviour is not smooth.
0.5
0.4
0.3
0.2
0.1
0.0
0 17 34 51 68 85
time [s]
]dar[
stnioJ
rrE
the robustness against variations on inertial parameters. First,
weattachedabottlehalffullofwatertothe5thjoint(Fig.5a).
Asaresult,duetowatermovements,therobotinertiachanges
dynamically. Second, we constrained the robot with an elastic
band (Fig. 5b), connecting the first robot link to the last one
and, therefore, introducing a substantial change in the robot
dynamics.Third,weperturbedtherobotalongtheexperiment
pushing it along random directions and, therefore, testing if
they are able to recover from human random disturbances. Fi-
nally,wereevaluatedthecontrollersinthepresenceofsensory
noise, focusing on the robot behaviour. Again, we compared
our algorithm implementations (MAIC-GP and MAIC-VAE)
with AIC, uAIC, MPC and an IC. All controllers parameters
AIC MPC MAIC-VAE were the same as in the previous experiments: no retuning
uAIC MAIC-GP IC wasdone.TableIreportstheroot-mean-squareerrors(RMSE)
and the related standard deviations (std) which represent all
theresultscollectedduringtheexperiments,themostaccurate
results are highlighted in black bold and the second most
accurate in blue bold. In order to evaluate quantitatively both
steady-state errors, transient behaviour and average errors we
presentbothRMSEandstdforeachphase.OnaverageMAIC-
GP is the most robust against dynamic parameters change
and the most adaptive to unmodeled dynamics, while MAIC-
VAE is the best one on noise rejection. Only at the steady-
Fig. 3: Vanilla comparison. Lines represent the average of state (after 10 seconds of execution) AIC has the lowest
absolute joints goal errors. Peaks are present when the new error on both Vanilla and Human disturbances experiments
goal is set. and uAIC at inertial experiment due to its integration term.
Furthermore, at the steady-state MAIC-GP adapts better in
Moreover, some goals can be better reconstructed than the constraint experiment and MAIC-VAE is the best one on
others, resulting in different steady-state errors. The reason is noise rejection. Finally, although both MPC and IC reported
that different z solutions lead to similar images. Furthermore, the worst performances in all experiments, they presented
duetodynamicalmodelerrors,MPCandICpresentsignificant significantoffsetsalreadyinthevanillacomparison.Therefore,
steady-state errors. Finally, MAIC-VAE and uAIC overshoot, we will focus just on their qualitative behaviours. We now
while all the other present overdamped behaviours. present the details of each experiment:
1) Inertial experiment: A bottle half full of water has been
D. Adaptation Study attached to the 5th robot joint. The water moves along the
experiment, changing the inertial characteristic of the object
attached to the robot. Figure 5a illustrates the controllers’
qualitative behaviours during the inertial experiment. It can
be seen that, due to the unmodeled dynamics, IC and MPC
showdifferentoffsetsthantheonesinthevanillacomparison.
Moreover, MPC shows an unstable behaviour in one of the
desired poses. Furthermore, since all the active inference
controllers do not use any robot model, they are not affected
by the change of dynamics. Table I shows that on average
the most accurate controllers are MAIC-GP (3.33E-03), uAIC
(3.38E-03) and MAIC-VAE (3.40E-03).
(a) Inertial (b) Constraint
Experiment Experiment
2) Elastic constraint experiment: The experiment aims to
Fig. 4: Experimental setup. (a) Inertial experiment: a bottle drastically change the underlying dynamics of the system.
half full of water is attached to the 5th joint. (b) Constraint Specifically, a rubber band was attached to the robot. To
Experiment setup: an elastic band links the first to the 5th prevent the robot from entering to safety mode, we chose to
joint. link the first joint to the last one. We bounded the elastic ten-
sion to a sustainable value. Figure 5b shows that both classic
To investigate our approach adaptability to unmodeled dy- and unimodal AIF controllers are significantly affected by the
namics and environment variations we systematically tested elastic tension, presenting remarkable offsets. By contrast, as
thecontrollersinfourexperiments.Thefirstthreeexperiments recorded on Tab. I, MAIC-GP and MAIC-VAE present the
aim to evaluate the adaptability to unmodeled dynamics and highest control accuracy.
7
VanillaExperiment InertialExperiment ConstraintExperiment HumandisturbancesExp NoisyExperiment
Controllers
RMSE std RMSE std RMSE std RMSE std RMSE std
tnemirepxElluF AIC 4.04E-03 4.85E-03 7.23E-03 3.05E-02 5.41E-03 1.42E-02 4.07E-03 1.21E-02 4.91E-03 3.33E-02
uAIC 3.28E-03 1.32E-02 3.38E-03 1.16E-02 4.10E-03 8.88E-03 3.32E-03 9.56E-03 3.03E-03 2.20E-02
MAIC-VAE 3.18E-03 1.78E-02 3.40E-03 1.45E-02 3.65E-03 2.26E-02 3.62E-03 1.44E-02 2.38E-03 1.81E-02
MAIC-GP 3.09E-03 1.71E-02 3.33E-03 1.89E-02 3.20E-03 1.50E-02 3.13E-03 2.20E-02 3.40E-03 1.91E-02
MPC 2.41E-02 6.81E-03 4.43E-02 1.77E-02 3.31E-02 7.84E-03 2.20E-01 5.00E-02 4.95E-02 1.32E-02
IC 9.45E-03 2.07E-02 1.95E-02 1.87E-02 1.54E-02 1.23E-02 9.76E-03 2.04E-02 4.84E-03 2.13E-02
tneisnarT
AIC 8.09E-03 3.97E-02 9.67E-03 4.18E-02 9.94E-03 1.97E-02 8.14E-03 1.68E-02 9.76E-03 4.22E-02
uAIC 6.54E-03 1.85E-02 6.75E-03 1.62E-02 8.03E-03 1.24E-02 6.62E-03 1.33E-02 8.98E-03 2.50E-02
MAIC-VAE 6.36E-03 2.48E-02 6.76E-03 2.02E-02 7.26E-03 3.15E-02 6.48E-03 2.01E-02 6.63E-03 2.71E-02
MAIC-GP 6.18E-03 2.38E-02 6.63E-03 2.63E-02 6.40E-03 2.09E-02 6.26E-03 3.03E-02 6.78E-03 2.66E-02
MPC 3.12E-02 9.45E-03 7.04E-02 2.47E-02 5.17E-02 1.09E-02 2.23E-01 4.96E-02 3.36E-02 1.82E-02
IC 1.63E-02 2.89E-02 3.48E-02 2.62E-02 2.72E-02 1.72E-02 1.69E-02 2.86E-02 1.86E-02 2.98E-02
etats-ydaetS
AIC 1.77E-06 1.84E-06 4.88E-05 6.30E-07 8.70E-04 1.50E-03 1.77E-06 8.79E-05 8.33E-05 7.37E-04
uAIC 1.19E-05 1.14E-05 1.26E-05 1.86E-05 1.69E-04 2.79E-04 3.201E-05 3.32E-05 5.89E-04 7.38E-03
MAIC-VAE 3.29E-05 2.97E-05 3.50E-05 4.25E-05 3.55E-05 4.16E-05 3.31E-05 3.71E-05 4.04E-05 3.35E-04
MAIC-GP 1.66E-05 2.02E-05 1.77E-05 2.47E-05 1.54E-05 8.67E-05 1.69E-05 3.21E-03 7.15E-05 4.90E-04
MPC 1.70E-02 1.54E-03 1.81E-02 1.75E-03 1.44E-02 1.26E-03 1.18E-01 5.04E-02 1.81E-02 3.19E-03
IC 2.61E-03 2.55E-03 4.32E-03 3.57E-04 3.64E-03 2.45E-03 2.62E-03 2.70E-03 2.91E-03 5.07E-03
TABLEI:Quantitativejointsgoalerrorscomparison.RMSE[rad]andstd[rad]ofthejointserrorsarepresented,lowesterrors
areshowedinblack boldandsecondlowestinblue bold.Errorsarecomputedforthefullexperiment,transientphase(0-10s)
and steady-state (10-20s).
0.5
0.4
0.3
0.2
0.1
0.0
0 17 34 51 68 85
time [s]
]dar[
stnioJ
rrE
AIC MPC MAIC-VAE
uAIC MAIC-GP IC
0.4
0.3
0.2
0.1
0.0
0 17 34 51 68 85
time [s]
(a) Inertial Experiment
]dar[
stnioJ
rrE
AIC MPC MAIC-VAE
uAIC MAIC-GP IC
0.5
0.4
0.3
0.2
0.1
0.0
0 17 34 51 68 85
time [s]
(b) Constraint Experiment
]dar[
stnioJ
rrE
AIC MPC MAIC-VAE
uAIC MAIC-GP IC
(c) Human Disturbances Experiment
Fig. 5: Lines represent the average of absolute joints goal errors. Peaks coincide with the instants when a new goal is set,
overshoots instead are present some seconds later, when the error already dropped substantially. 5c) Red rectangles show the
time intervals on which the disturbances are applied, small peaks represent human disturbances.
3) Human disturbances experiment: This experiment aims allowing a smooth control behaviour. All the other controllers
to evaluate compliance and controllers recovery ability after oscillate significantly more along the experiment.
randomdisturbances.Todothis,ahumanoperatorpushedthe
robot in random directions along the experiment. Red shaded E. Ablation Study
areas on Fig. 5c indicate the periods on which the robot is In order to evaluate the effect of the extra modalities,
disturbed. Apart from the MPC, which is not able to recover we performed an ablation study removing the extra modality
and perform the task, all the other ones fully recover from from the algorithm scheme. Figure 7 shows that by removing
the disturbances, showing a safe behaviour in case of human the visual modality the behaviour becomes much smoother.
disturbances. Indeed, the control loop frequency increase from 120Hz to
4) Noise experiment: We reevaluated the controller be- 1000Hz. However, Tab. II reports that the control accuracy
haviour in the presence of proprioceptive noise, focusing on does not change significantly. Moreover, from Fig. 7 it can be
the noise rejection capabilities of the six controllers. Proprio- seen that controllers response behaviours do not change when
ceptivenoisewasimplementedasadditivenoisesampledfrom they are ablated.
a Normal distribution r ∼N(0,Σ =0.1). Figure 6 shows
that MAIC controllers w q ere the mo r s q t adaptive, presenting the VI. LIMITATIONSANDADVANTAGES
smoothest behaviours. The reason is that multimodal filtering Ontheonehand,althoughthequantitativetablecomparison
acts as a filter for the injected noise, reducing its effect and showsthatonaverageMAICimplementationsaremoreadap-
8
0.5
0.4
0.3
0.2
0.1
0.0
0 17 34 51 68 85
time [s]
]dar[
stnioJ
rrE
AIC MPC MAIC-VAE
uAIC MAIC-GP IC
Fig. 6: Noisy experiment. Lines represent the average of
absolute joints goal errors. Peaks coincide with the instants
when a new goal is set.
0.5
0.4
0.3
0.2
0.1
0.0
0 17 34 51 68 85
time [s]
]dar[
stnioJ
rrE
MAIC-VAE MAIC-GP
MAIC-VAE-ablated MAIC-GP-ablated
Fig.7:Ablationstudy.Linesrepresenttheaverageofabsolute
joints goal errors. Peaks are present when the new goal is set.
tive and accurate, they still have limitations. First of all, mul-
timodal filtering requires more computational time, leading to
irregular behaviours. Indeed, the ablation study clearly shows
thatwhenremovingthevisualmodality,thecontrolbehaviour
becomessignificantlysmoother.UsingafasterGPUmaysolve
this issue. Moreover, the multimodal state estimation depends
on the accuracy of the learned generative mapping. In all ex-
periments we used a black background to facilitate the image
reconstruction.Furthermore,anotherlimitationisthatforgoal-
directed behaviours we need to provide the desired values for
all the sensor modalities, which may not be always available.
However,asin[26],itmaybepossibletocombineMAICwith
a high-level controller in order to control complex robotics
systems (e.g. soft robots). On the other hand, MAIC can
incorporate any type and number of sensors besides the end-
effectorpositionorimages.Itcanworkinanimaginaryregime
tnemirepxElluF
(appendix D) by mentally simulating the expected behaviour,
opening many opportunities for future research such as model
predictive active inference controllers, where the controller
predictN stepshead.Besides,themultimodalfilteringscheme
can be integrated into other kinds of controllers, such as an
IC.
VII. CONCLUSION
We described MAIC, a scalable multisensory enhancement
of the torque proprioceptive AIF controller presented in [25]
and the velocity controller presented in [22]. Our approach
makes use of the alleged adaptability and robustness of AIF,
taking advantage of previous works and overcoming some
related limitations. We solved state estimation by combining
representation learning and multimodal filtering with varia-
tionalfreeenergyoptimization,improvingtherepresentational
power and adaptability. Hence, we can perform online multi-
sensory torque control, without the use of any dynamic or
kinematic model of the robot at runtime. Furthermore, we
performed a systematic comparison of several controllers on
different experiments providing both qualitative and quanti-
tative analysis on a robotic manipulator. Results showed that
our proposed algorithm is more adaptive than state-of-the-art
torqueAIFbaselinesandclassicalcontrollers(MPCandIC),it
was more accurate in the presence of sensory noise, showing
the strongest noise rejection capability. MAICs were highly
adaptive and robust to different contexts, such as changes in
the robot dynamics (i.e., elastic constraint) and changes in
the robot properties (i.e. inertial properties). Furthermore, our
simplified architecture makes the controller easy to deploy in
any robotic manipulator. In line with the Bayesian hypothesis
of how the brain processes the information from the senses,
this work reinforces the idea that learning to predict can be
directly transformed into adaptive control. The experimental
validation shows the viability of this approach to standard
industrial robotic tasks.
REFERENCES
[1] Mohamed Baioumy, Paul Duckworth, Bruno Lacerda,
and Nick Hawes. Active inference for integrated
state-estimation, control, and learning. arXiv preprint
arXiv:2005.05894, 2020.
[2] Mohamed Baioumy, Corrado Pezzato, Riccardo Ferrari,
Carlos Hernandez Corbato, and Nick Hawes. Fault-
tolerantcontrolofrobotmanipulatorswithsensoryfaults
using unbiased active inference. In European Control
Conference, ECC, 2021.
[3] Christopher L Buckley, Chang Sub Kim, Simon McGre-
RMSE[rad] std[rad]
gor, and Anil K Seth. The free energy principle for
MAIC-VAE 3.18E-03 1.78E-02
action and perception: A mathematical review. Journal
MAIC-VAE-ablated 3.21E-03 1.36E-02 of Mathematical Psychology, 81:55–79, 2017.
MAIC-GP 3.09E-03 1.71E-02 [4] AlejandraCiria,GuidoSchillaci,GiovanniPezzulo,Ver-
MAIC-GP-ablated 4.04E-03 4.84E-03 ena V Hafner, and Bruno Lara. Predictive processing
in cognitive robotics: a review. Neural Computation,
TABLE II: Ablation study: quantitative analysis. RMSE [rad]
33(5):1402–1432, 2021.
and std[rad] are shown for both MAICs and their ablated
[5] AlexanderDomahidiandJuanJerez.Forcesprofessional.
versions. Lowest errors are showed in black bold and second
Embotech AG, url=https://embotech.com/FORCES-Pro,
lowest in blue bold.
2014–2019.
9
[6] Roy Featherstone. Rigid body dynamics algorithms. [23] Adam Paszke, Sam Gross, Francisco Massa, Adam
Springer, 2014. Lerer, James Bradbury, Gregory Chanan, Trevor Killeen,
[7] Karl Friston. The free-energy principle: a unified brain Zeming Lin, Natalia Gimelshein, Luca Antiga, Alban
theory? Nature neuroscience, 11(2):127–138, 2010. Desmaison, Andreas Kopf, Edward Yang, Zachary De-
[8] Karl J Friston, Jean Daunizeau, James Kilner, and Ste- Vito, and Raison. Pytorch: An imperative style, high-
fan J Kiebel. Action and behavior: a free-energy formu- performancedeeplearninglibrary.InAdvancesinNeural
lation. Biological cybernetics, 102(3):227–260, 2010. Information Processing Systems 32, pages 8024–8035.
[9] Neville Hogan. Impedance control: An approach to Curran Associates, Inc., 2019.
manipulation: Part i—theory. 1985. [24] F. Pedregosa, G. Varoquaux, A. Gramfort, V. Michel,
[10] Lill Maria Gjerde Johannessen, Mathias Hauan Arbo, B. Thirion, O. Grisel, M. Blondel, P. Prettenhofer,
and Jan Tommy Gravdahl. Robot dynamics with urdf R.Weiss,V.Dubourg,J.Vanderplas,A.Passos,D.Cour-
& casadi. In 2019 7th (ICCMA). IEEE, 2019. napeau,M.Brucher,M.Perrot,andE.Duchesnay.Scikit-
[11] Minju Jung, Takazumi Matsumoto, and Jun Tani. Goal- learn: Machine learning in Python. Journal of Machine
directed behavior under variational predictive coding: Learning Research, 12:2825–2830, 2011.
Dynamic organization of visual attention and working [25] CorradoPezzato,RiccardoFerrari,andCarlosHerna´ndez
memory. IROS, 2019. Corbato. A novel adaptive controller for robot manip-
[12] Frinston K.J, Trujillo-Barreto N., and Daunizeau. Dem: ulators based on active inference. IEEE Robotics and
avariationaltreatmentofdynamicsystems. NeuroImage, Automation Letters, 5(2):2973–2980, 2020.
41, pp. 849-885, 2008. [26] Jeffrey Frederic Queißer, Barbara Hammer, Hisashi Ishi-
[13] Anis Koubaa. Robot Operating System (ROS): The hara, Minoru Asada, and Jochen Jakob Steil. Skill
Complete Reference (Volume 2). Springer Publishing memories for parameterized dynamic action primitives
Company, Incorporated, 1st edition, 2017. on the pneumatically driven humanoid robot child af-
[14] PabloLanillosandGordonCheng. Activeinferencewith fetto. In 2018 Joint IEEE 8th International Conference
functionlearningforrobotbodyperception. InProc.Int. on Development and Learning and Epigenetic Robotics
Workshop Continual Unsupervised Sensorimotor Learn., (ICDL-EpiRob), pages 39–45, 2018.
pages 1–5, 2018. [27] Jeffrey Frederic QueiSSer, Minju Jung, Takazumi Mat-
[15] Pablo Lanillos and Gordon Cheng. Adaptive robot body sumoto, and Jun Tani. Emergence of Content-Agnostic
learning and estimation through predictive coding. In Information Processing by a Robot Using Active Infer-
2018 IEEE/RSJ International Conference on Intelligent ence, Visual Attention, Working Memory, and Planning.
Robots and Systems (IROS), pages 4083–4090. IEEE, Neural Computation, 33(9):2353–2407, 08 2021.
2018. [28] Cansu Sancaktar, Marcel AJ van Gerven, and Pablo
[16] Pablo Lanillos, Sae Franklin, and David W Franklin. Lanillos. End-to-end pixel-based deep active inference
Thepredictivebraininaction:Involuntaryactionsreduce for body perception and action. In Joint IEEE 10th
body prediction errors. bioRxiv, 2020. International Conference on Development and Learning
[17] Pablo Lanillos, Jordi Pages, and Gordon Cheng. Robot and Epigenetic Robotics (ICDL-EpiRob). IEEE, 2020.
self/other distinction: active inference meets neural net- [29] Simo Sa¨rkka¨. Bayesian filtering and smoothing. Num-
works learning in a mirror. In Proceedings of the 24th ber 3. Cambridge University Press, 2013.
European Conference on Artificial Intelligence (ECAI), [30] YuichiYamashitaandJunTani. Emergenceoffunctional
pages 2410 – 2416, 2020. hierarchy in a multiple timescale neural network model:
[18] Pablo Lanillos and Marcel van Gerven. Neuroscience- a humanoid robot experiment. PLoS computational
inspiredperception-actioninrobotics:applyingactivein- biology, 4(11):e1000220, 2008.
ference for state estimation, control and self-perception. [31] A.Zanelli,A.Domahidi,J.Jerez,andM.Morari. Forces
arXiv preprint arXiv:2105.04261, 2021. nlp:anefficientimplementationofinterior-pointmethods
[19] Timothe´e Lesort, Natalia D´ıaz-Rodr´ıguez, Jean-Franois for multistage nonlinear nonconvex programs. Interna-
Goudou, and David Filliat. State representation learning tional Journal of Control, pages 1–17, 2017.
for control: An overview. Neural Networks, 108:379–
392, 2018.
[20] Cristian Meo and Pablo Lanillos. Multimodal vae active
inference controller. arXiv preprint arXiv:2103.04412,
2021.
[21] Beren Millidge, Alexander Tschantz, Anil K Seth, and
Christopher L Buckley. On the relationship between
activeinferenceandcontrolasinference.InInternational
Workshop on Active Inference, 2020.
[22] GuillermoOliver,PabloLanillos,andGordonCheng. An
empiricalstudyofactiveinferenceonahumanoidrobot.
IEEETransactionsonCognitiveandDevelopmentalSys-
tems, 2021.
10
APPENDIX over the defined workspace, splitting the cubic workspaces
A. Model Predictive Controller into 9261 points, 21 for every direction (i.e. x, y and z
axis). Consequently, we used an inverse kinematics algorithm
The results are compared to a standard model predictive
fromroboticstoolbox-pythoninordertodefinethejointvalues
torque control (MPC) formulation.
relatedtotheobtainedend-effectorpositions.Weusedthe80%
1) Optimization problem: Neglecting external forces, the
of these paired set as training set and the remaining 20% as
dynamics of the system are defined by the equation of motion
test set. Finally, from figure 8 It can be seen that on average
as
the reconstruction error is roughly 0.010m.
τ =M(q)q¨+C(q,q˙)q+g(q),
whichiscomposedofthemassmatrixM,theCoriolismatrix
C and the gravitational forces g [6]. Various approaches to
compute the forward dynamics have been proposed [10]. The
forward dynamics can be discretized to obtain the transition
function
z =f(z ,a ),
k+1 k k
wherezistheconcatenatedvectorofjointpositions,velocities
and accelerations.
The control problem can be formulated as an optimization
problem as follows
N
(cid:88)
J(cid:63) = min J(z ,a ), (32)
k k
z0:N,a0:Nk=0
s.t. z =f(z ,a ), (33)
k+1 k k
a ∈U,z ∈Z, (34)
k k
z =z(0), (35)
0
where J isthe objective function,U and Z arethe admissible
sets of actions and states respectively and z is the initial Fig. 8: End-effector reconstruction error.
0
condition. The objective function was formulated as follows
J(z ,a )=(q −q )TW (q −q )+aTW a ,
k k k goal goal k goal k a k
(36) C. Multimodal VAE training
where W and W are the weighting matrices for the goal
goal τ In order to create the image dataset we used an impedance
configuration and the actions respectively.
controller to explore the workspace defined in Appendix B
2) Realization: Inthiswork,weusedtherecursiveNewton
and collect pictures of the robot in different poses. We used
Euler algorithm to solve the forward dynamics and a second
the joint values from the GP training set as reference for the
orderexplicitRunge-Kuttaintegrator.Theparametersettingis
controller and with subscriber we collected both joints values
summarized in Table III. In accordance to the time step the
and related images, creating a dataset of 50000 samples of
control frequency is 10Hz.
paired joint values and images. The multimodal VAE was
parameter value then trained using the loss function defined by eq. (29). The
N 20 network architecture and parameters are publicly available
∆t 0.1s at https://github.com/Cmeo97/MAIC. Figure 9 presents the
W
goal
400I7
Wa diag([1.75,2,2.5,5,20,18.75,62.5]) averagereconstructionlossduringthetraining,50epochswere
used to train the network.
TABLE III: Parameter setting for MPC
The optimization problem is solved using the nonlinear D. Mental simulation
solverproposedin[31]andthecorrespondingimplementation
Unlike most of the AIF controllers present in literature, a
[5]. The forward dynamics are computed using [10].
greatadvantageofcombiningourapproachwithamultimodal
VAE is the possibility to perform imagined simulations. In
B. GP training otherwords,givenx ,theentireexperimentcanbesimulated.
d
Figure 8 illustrates a 3D scatter plot that shows a heatmap Since sensory data are not available, the state update law
of the end-effector reconstruction errors. Moreover, the axes becomes:
∂f
define the cartesian workspace we considered in our experi- z˙ =−k Σ−1(x −f(z,ρ)) (37)
z∂z f d
ments,wheretherobotbaseisplacedatx ={0,0,0}and
base
is frontally directed toward the x-direction. What is more, in Asaresult,performingtheintegrationstepofthenewinternal
ordertodefinethetrainingsetwecreatedacubicgridofpoints state and decoding it, the updated {x ,x } can be computed
v q
11
Fig. 9: Image reconstruction error.
0.8
0.6
0.4
0.2
0
-0.2
-0.4
-0.6
0 17 34 51 68 85
time [s]
]dar[
tnioj
rrE
j_0 j_3 j_5
j_1 j_4 j_6
j_2
(a) Imagined joints errors
26
24
22
20
18
16
14
12
0 10 20 30 40 50 60 70 80
time [s]
]lexip[
egamI
rrE
than in the normal regime (Fig. 2a) as it does not need to
accommodate the real dynamics of the robot.
E. Impedance Controller
The presented impedance controller [9] is based on the
following dynamic equation:
τ =K(q −q)+D(−q˙)+C(q,q˙)q+g(q),
goal
whereKisthesetjointstiffnessDisthecorrespondingcritical
damping, C is the Coriolis matrix, and g is the gravitational
term.Consideringthatthedynamicsoftherobotaredescribed
by
M(q)q¨+C(q,q˙)+g(g)=τ +τ (38)
ext
with the impedance controller the dynamics results in
M(q)q¨=K(q −q)+D(−q˙)+τ (39)
goal ext
this translates in a second order critically damped dynamics
of the robot in the the transition towards the desired goal.
err_Image
(b) Imagined image reconstruction error
Fig.10:Mentalsimulationofsequentialreachingoffourgoals.
Thegoalisupdatedontimestepswherepeaksarepresent.(a)
Joints errors of an imagined simulation. Each line represents
the error of the i-th joint. (b) Image reconstruction errors of
an imagined simulation.
and the new errors can be back-propagated again, creating a
loop that allows the system to do imaginary simulations.
Fig. 10a and 10b show respectively imagined joints error
and images reconstruction error through the entire simulation.
These results show that the errors converge faster to zero