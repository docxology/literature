Fix these issues in your summary:
- Too short: 175 words (minimum 200)

Current summary:
Okay, here’s a revised summary of the paper, adhering to all the specified guidelines:**Cognitive Effort in the Two-Step Task: An Active Inference Drift-Diffusion Model Approach**This study investigates the mechanisms underlying cognitive effort in the two-step task, comparing predictions from an active inference drift-diffusion model (AIF-DDM) with traditional models. The research aims to determine how individuals’ choices are influenced by factors such as uncertainty and cognitive load.Specifically, the study examined the relationship between reaction time (RT) and the drift-diffusion model, incorporating key elements of the model’s predictions.The research utilized a quantitative approach, generating and analyzing RT data from participants. The analysis focused on comparing the predictions of the AIF-DDM with traditional models, considering the factors that influence decision-making. The study’s findings provide insights into the neural mechanisms underlying cognitive effort, offering a more nuanced understanding of how individuals make choices in complex situations.The research utilized a quantitative approach, generating and analyzing RT data from participants. The study’s findings provide insights into the neural mechanisms underlying cognitive effort, offering a more nuanced understanding of how individuals make

Paper text:
Cognitive Effort in the Two-Step Task: An Active
Inference Drift-Diffusion Model Approach
Álvaro Garrido-Pérez1[0009−0003−5481−8166], Viktor Lemoine1, Amrapali
Pednekar1[0009−0005−6194−3955], Yara Khaluf2[0000−0002−5590−9321], and Pieter
Simoens1[0000−0002−9569−9373]
1 IDLab, Department of Information Technology, Ghent University - imec, Belgium
alvaro.garridoperez@ugent.be
2 Wageningen University & Research, Wageningen, The Netherlands
Abstract. High-leveltheoriesrootedintheBayesianBrainHypothesis
often frame cognitive effort as the cost of resolving the conflict between
habits and optimal policies. In parallel, evidence accumulator models
(EAMs)provideamechanisticaccountofhoweffortarisesfromcompeti-
tionbetweenthesubjectivevaluesofavailableoptions.AlthoughEAMs
have been combined with frameworks like Reinforcement Learning to
bridgethegapbetweenhigh-leveltheoriesandprocess-levelmechanisms,
relatively less attention has been paid to their implications for a unified
notionofcognitiveeffort.Here,wecombineActiveInference(AIF)with
the Drift-Diffusion Model (DDM) to investigate whether the resulting
AIF-DDMcansimultaneouslycapturetheeffortarisingfrombothhabit
violation and value discriminability. To our knowledge, this is the first
time AIF has been combined with an EAM. We tested the AIF-DDM
on a behavioral dataset from the two-step task and compared its pre-
dictions to an information-theoretic definition of cognitive effort based
onAIF.Themodel’spredictionssuccessfullyaccountedforsecond-stage
reaction times but failed to capture the dynamics of the first stage. We
argue the latter discrepancy likely stems from the experimental design
ratherthanafundamentalflawinthemodel’sassumptionsaboutcogni-
tiveeffort.Accordingly,weproposeseveralmodificationsofthetwo-step
tasktobettermeasureandisolatecognitiveeffort.Finally,wefoundthat
integrating the DDM significantly improved parameter recovery, which
could help future studies to obtain more reliable parameter estimates.
Keywords: Active inference · Drift-diffusion model · Cognitive effort
1 Introduction
Building upon the Bayesian Brain Hypothesis (BBH), numerous studies in the
past decade have tried to formalize cognitive effort using information-theoretic
principles[25].AccordingtotheBBH,humansmaintainaninternalworldmodel
encoded in prior beliefs, which they continuously update as they interact with
the environment. Within this context, cognitive effort arises from the conflict
5202
peS
21
]CN.oib-q[
2v53440.8052:viXra
2 A. Garrido-Pérez et al.
between a pre-existing belief about how to act (a habit) and an updated belief
about the optimal policy [10].
In a decision-making task, cognitive effort may also arise from the competi-
tion between the subjective values of the available choices. When these values
are closer together—that is, when value discriminability is low—reaction times
(RTs)tendtoincrease(e.g.,[7,3]).AlthoughRTsarenotadirectmeasureofcog-
nitiveeffort,theyareoftenusedasaproxy(e.g.,[24]),basedontheassumption
that slower responses reflect more information processing.
From an information-theoretic perspective, the effect of value discriminabil-
ity on RTs can be understood as the additional cognitive effort required to re-
solve increased choice uncertainty [13,8,6]. Yet, information theory provides no
explicit account of the underlying deliberation process, which complicates the
task of linking its predictions to specific neural signatures. In contrast, evidence
accumulatormodels(EAMs)offeramechanisticexplanationforhowvaluecom-
petition shapes decision speed, which may be empirically tested (e.g., [18]).
A major limitation of using EAMs to study cognitive effort is that they are
agnostic to how beliefs are formed. This limitation is often addressed by com-
bining EAMs with Reinforcement Learning (RL) [11]. However, in recent years,
Active Inference (AIF) has emerged as a powerful alternative to RL, offering a
first-principles perspective on perception, learning, and decision-making [5].
Here, we investigate whether integrating a Drift Diffusion Model (DDM),
a prominent class of EAM, with AIF can simultaneously capture the influence
of both value discriminability and habit violation on cognitive effort. To our
knowledge, this is the first attempt to combine AIF with an EAM to model
humanbehaviour.WeevaluatetheintegratedAIF-DDMusingthetwo-steptask,
a version of the multi-armed bandit in which participants must plan two steps
ahead [2]. Furthermore, we compare its predictions with a recently proposed
definition of cognitive effort in AIF [10].
Our work builds directly on a recent study that developed an AIF model of
the two-step task [4]. The study demonstrated that AIF outperformed a Hybrid
Reinforcement Learning (HRL) model (which combines model-free and model-
based strategies [16]) in two out of four datasets, while achieving comparable
performance in the remaining two. Moreover, the authors provided compelling
evidence for directed exploration—a key differentiator between AIF and HRL.
Despite these achievements, the study could not determine which specific AIF
learningmechanismsparticipantswereusing.Givenpriorevidencethatintegrat-
ingaDDMintoanHRLmodelimprovedthereliabilityofmodel-basedestimates
[16], we tested whether the combined AIF–DDM could resolve this ambiguity.
2 Methods
2.1 Participants and behavioural task
In this section, we will briefly describe the two-step task and the behavioural
dataset that we used to fit the computational models. For more details on the
Cognitive Effort in the Two-Step Task 3
experimental procedure, we encourage reading the paper that made the dataset
publicly available [17].
As the name suggests, each trial of the two-step task consists of two stages
(Fig. 1). In the first stage, participants choose between two actions. Each action
leadstooneofthetwosecond-stagestatesthroughaprobabilistictransitionthat
is either common (p = 0.7) or rare (p = 0.3). Importantly, the two first-stage
actions have opposite most-likely transitions. These transition probabilities re-
main constant throughout the task. After transitioning to a second-stage state,
participantsmakeafinalchoicebetweentwoactions.Eachofthesesecond-stage
actionsresultsinamonetaryrewardornoreward,dependingonitscurrentout-
come probability.Incontrasttothefixedtransitions,theseoutcomeprobabilities
fluctuate independently over time, following Gaussian random walks.
Fig.1: Abstract representation of the two-step task. At the first stage (top), a
choice leads to one of two second-stage states (bottom). Transitions are either
common (p=0.7, thick arrows) or rare (p=0.3). The two initial actions have
opposing common transitions. A second-stage choice may result in a monetary
reward with a probability that fluctuates over time.
We analysed data from the "Magic Carpet" dataset, which was made avail-
ableby[17]andoriginallycomprised24participants.Inthisexperiment,partici-
pantshada2-seconddeadlinetorespondateachstage.Everytimethisdeadline
wassurpassed,thetrialwaslabelledasamissed trialandtheparticipantmoved
on to the next stage or trial. Before conducting any analysis, we identified and
removedthesetrials.WealsoconsideredinvalidtrialsthosewithatleastoneRT
smallerthan100ms(toexcludeanticipatoryresponsesthataretoofasttoreflect
genuine deliberation [9]). Finally, any participant with more than 10% invalid
trials was removed from the dataset. One participant was excluded under this
criterion, with 44.1% of their trials being either missed or too fast. Therefore,
the original sample size was reduced to n=23. In total, 6.53% of the data was
excludedfromtheanalysis(includingallthedatafromtheremovedparticipant).
4 A. Garrido-Pérez et al.
2.2 An active inference drift-diffusion model of the two-step task
Inthissection,weintroducetheAIFmodeldevelopedby[4]anddiscusshowwe
integrate it with a DDM. Further explanations of the equations are provided in
Appendix A. To establish a comparative benchmark, we implemented an HRL-
DDM.Sincethelattermodelissecondarytoourmainanalysis,itsmathematical
formulation is only detailed in Appendix B.
In what follows, we will use the same notation as in [4]. For a given trial t,
thefirst-stagestateandchosenactionsaredenotedbys anda ,respectively.
1,t 1,t
Likewise, the second-stage state and chosen action are denoted by s and a ,
2,t 2,t
respectively.Notethatthefirst-stagestatecanonlybes ,butthesecond-stage
A
state may be s or s , depending on the transition (see Fig. 1). Outcomes
B C
o ∈ {0,1} represent the observed reward (or absence of it) after choosing a
t
second-stage action.
According to the AIF model developed by [4], an agent performing the two-
steptaskisequippedwithagenerativemodel(i.e.,asetofbeliefsabouthowthe
task environment evolves given its actions). In the two-step task, agents must
learn the outcome probabilities of each of the four second-stage actions. We will
refer to the set of these four probabilities as θ, and the belief distribution over
θ, at a given trial t, π (θ). In addition, the agent must learn the four transition
t
probabilitiesp(s |s ,a ).However,aspointedoutby[4],thesetransitionsare
2,t 1,t 1,t
accurately learned in a few trials and therefore, action-selection is only sensitive
to information regarding outcome probabilities.
Thus, an agent performing the two-step task must optimally balance getting
as many rewards as possible (exploitation) and learning the four outcome prob-
abilities (exploration). According to AIF, this balance is achieved by selecting
actions that minimize a quantity known as Expected Free Energy (EFE), which
in this case is given by the following equation:
G (a)=−E [lnp(o |C)]−E [D (π (θ)|o ,a∥π (θ))] (1)
t p(ot;πt(θ)|a) t p(ot;πt(θ)|a) KL t t t
(cid:124) (cid:123)(cid:122) (cid:125) (cid:124) (cid:123)(cid:122) (cid:125)
Realisingpreferences Modelparameterexploration
(Exploitation) (ActiveLearning)
WhereG (a)istheEFEofagivenactionatagiventrial,p(o |C)isthedistri-
t t
butionoverpriorpreferredobservations(Eq.5,AppendixA),whichdependson
a free parameter λ. Note that in the two-step task, the preferred observation is
togettherewardafterasecond-stagechoice.D istheKullback-Leiblerdiver-
KL
gence between prior beliefs about second-stage outcome probabilities π (θ) and
t
posteriorbeliefsafterselectinganactionandobservingitsoutcome.p(o ;π (θ)|a)
t t
isadistributionequaltop(o |θ,a)π (θ).Notethat,unliketraditionalEFEformu-
t t
lations, there is no hidden state exploration term because in the real experiment
participants can always see the state in which they are [15].
Eq. 1 can be used to calculate EFEs for second-stage actions. However, for
first-stage actions, the level of optimality depends upon the EFEs of the final
states and the transition probabilities. Therefore, for the first-stage actions, the
EFE equation is given by:
Cognitive Effort in the Two-Step Task 5
(cid:88) (cid:88)
G(a )=p(s |s ,a ) G(a ) + p(s |s ,a ) G(a ) (2)
j B A j 2 C A j 2
a2∈AB a2∈AC
Where A and A are the sets of available actions in the second-stage states
B C
s and s respectively, and G(a ) are the second-stage EFEs given by Eq. 1.
B C 2
Previous studies have reported a tendency for participants to repeat initial-
stage actions, regardless of the outcome history [4]. Within AIF, this behaviour
is formalised through a habit term E. In the model of [4], E is parameterised
by κ, which modulates the extent of an agent’s reliance on habits (see Eq. 6,
Appendix A).
At the first stage, an agent will select an action that minimizes the EFE
corrected by the habitual bias Gnet(s ,a )=G (s ,a )+E(a ). At the second
t 1 1 t 1 1 1
stage, no habitual bias is assumed, and therefore Gnet(s ,a )=G (s ,a ).
t 2 2 t 2 2
For the original AIF model [4], the choice probabilities of an agent at trial
t, stage p = {1,2} and state s, will be given by the softmax distribution of the
corresponding net EFEs parametrized by an inverse temperature parameter, γ
p
(one for each stage). However, for the AIF-DDM the choice will be determined
by a drift-diffusion process, with a non-decision time t , boundary separation
nd
a and a drift rate v , that depends on the difference in Gnet of the two
bs p,s,t
available actions such that:
v =vmod[Gnet(s,a)−Gnet(s,a′)], a,a′ ∈A (3)
p,s,t p t t s
Where A is the set of available actions at state s, and vmod is a free pa-
s p
rameter that regulates the sensitivity to Gnet differences (which can also be
interpreted as the agent’s information-processing speed). Following the original
AIF model [4], we fit a separate vmod parameter for each stage, an approach
p
analogous to the use of stage-specific inverse temperatures.
In the classical DDM, a starting-point bias parameter z is often included.
However,inthetwo-steptask,thesymbolsrepresentingthedifferentactionswere
randomly displayed either on the left or the right of the screen [17]. Therefore,
we set z =0.5 (effectively cancelling the bias in the drift-diffusion process).
After completing every trial, the agent updates its beliefs about the second-
stage outcome probabilities. In [4], the updating rules for the prior distribution
over outcome probabilities (Eqs. 8 and 9 in Appendix A), depend on four free
parameters: the learning rate l, the prior volatility, v , which modulates the
PS
influence of surprise on the agent’s beliefs, volatility of sampled actions v ,
SD
whichmodulateshowbeliefsoverchosenactionsdecay,orareforgotten,andthe
volatility of unsampled actions v , similar to v but for unchosen actions.
UD SD
The study by [3] tested four AIF variants distinguished by their learning
rules: a No Unsampled-Decay model (AIF , v = 0); a No Sampled-Decay
NUD UD
model (AIF , v = 0), a No Predictive Surprise model (AIF , v = 0)
NSD SD NPS PS
and a model including all the learning mechanisms (AIF ). Although solid
FULL
evidence was found favouring AIF over HRL, the best-fitting AIF variant could
not be determined [4]. Consequently, we fitted all four models in our analysis.
6 A. Garrido-Pérez et al.
2.3 Cognitive effort and active inference
A recent formalisation of cognitive effort (ξ) based on AIF defines it as the
KL divergence between context-sensitive beliefs about how to act P (π) and
G
context-insensitive prior beliefs, or habits P (π) [10]:
E
ξ ≜D [P (π)||P (π)]=E [lnP (π)]− E [lnP (π)] (4)
KL G E PG G PG E
(cid:124) (cid:123)(cid:122) (cid:125) (cid:124) (cid:123)(cid:122) (cid:125) (cid:124) (cid:123)(cid:122) (cid:125)
Effort Contextsensitive Contextinsensitive
P (π)=Cat(σ(−E)) P (π)=Cat(σ(−G−E))
E G
Where G and E are vectors comprising the context-sensitive EFEs and the
context-insensitive priors (or habits) of the available actions, respectively.
From Eq. 4, two key predictions can be derived. First, high effort will be
experienced when there is an incongruence between G and E. Second, when
the elements of G are of similar magnitude to one another, cognitive effort is
minimal regardless of E.
Forthefirststageofthetwo-steptask,theAIF-DDMalignswiththefirstpre-
dictionofEq.4.Forachoicebetweenactionsa anda ,withG=[G ,G ],and
A B A B
E=[E ,E ], RTs should increase as the magnitude of the drift rate decreases,
A B
whichisproportionalto|∆Gnet|=|G +E −G −E |.Therefore,higherRTs
A A B B
may occur when, for example |G | ≫ |G |, |E | ≪ |E | and |G | ≈ |E |. In
A B A B A B
other words, when there is an incongruence between G and E.
However, our model contradicts the second prediction of Eq. 4, because for
a constant E, RTs should increase as |G | gets closer to |G |. Interestingly,
A B
for the second stage, Eq. 4 predicts minimal effort if we assume no habits (i.e.
E = E = 0), in contrast to AIF-DDM, where effort can still be high if the
A B
context-sensitive EFEs are closely matched.
2.4 Model fitting and comparison procedures
WefollowedthesameMaximumLikelihoodEstimate(MLE)procedureasin[4],
tofitthemodels’freeparameterstothebehaviouraldata3.Foreachparticipant
andmodel,wefoundtheparametersetwiththehighestlikelihoodusingScipy’s
’L-BFGS-B’ algorithm [19]. This step was repeated 35 times for each partici-
pant, with different (uniformly) randomized initializations for all parameters.
After completing all the runs, we selected the parameter set with the maximum
likelihood and used its value for model comparison.
For the pure AIF and HRL models, we computed the likelihoods using the
choice probability distributions of each model. For AIF-DDM and HRL-DDM
however, the likelihoods were given by the Wiener’s First-Passage Time Distri-
bution (WFPT) provided by the HDDM Python package [22]. Further details
can be found in Appendix C.
3 Code available at https://github.com/decide-ugent/aif-ddm
Cognitive Effort in the Two-Step Task 7
For model comparison, we relied on the Statistical Parametric Mapping
(SPM)[21]andVariationalBayesianAnalysis(VBA)[1]toolboxes,usingMAT-
LAB R2022b. We performed a group-level random-effect Bayesian model selec-
tion (BMS) procedure, which requires the log-model evidence (LME) of each
modelforeachparticipant.WeusedtwoLMEapproximations:theBayesianIn-
formation Criterion (BIC) and the Akaike’s Information Criterion (AIC) scores
[12](seeAppendixC).UsingtheBMSprocedure,weestimatedfourmodelcom-
parisonmetrics:theExpectedPosteriorProbability(EPP);theEstimatedModel
Frequency (EMF), or the proportion of participants best fit by the model; the
Exceedance Probability (EP), which quantifies the likelihood that the model is
more frequent than competing models across participants; and the Protected
Exceedance Probability (PEP), similar to EP but accounting for the possibility
that apparent differences in model frequencies arise due to chance [14].
The SPM toolbox allows comparing the performance of model families (i.e.,
models that share a common feature). As in [4], we use this feature to com-
pare the overall AIF performance (considering its four variants) to HRL. Since
PEPs are unavailable for family-level inference, we only calculate EPs for these
analyses.
2.5 Model and parameter recovery procedures
To perform the parameter recovery analysis, we simulated a dataset for each
model using parameter values sampled from uniform distributions with ranges
equal to those used to fit the real dataset. Next, we fitted the synthetic dataset
andobtainednew(recovered)parameters.Finally,wecheckediftheoriginaland
recoveredparameterswerecorrelatedbycalculatingPearson’scorrelations.This
process was repeated 23 times (equal to the number of participants in the real
experiment) for each model.
For the model recovery analysis, each model was first used to simulate a full
experimentaldatasetwiththesameparametersetsasintheparameterrecovery
analysis. We then fitted all models to each simulated dataset and calculated
the proportion of times each model was identified as best-fitting. Results were
summarized in a confusion matrix (Fig. 2).
3 Results
3.1 Model recovery analysis
ModelrecoveryanalysisindicatesthatAIF-DDM isfrequentlymisclassified
FULL
aseitherAIF-DDM orAIF-DDM (Fig.2).Thepoorrecoverylikelystems
NSD NSD
from the full model encompassing all update rules present in the other two
models [4]. The rest of the models had a better but modest recovery (except
HRL-DDM, which had a perfect recovery). Thus, combining AIF with a DDM
could not help substantially to differentiate between different learning variants
as we hypothesised. Overall, both AIC and BIC scores show similar results.
Although the AIC score seems slightly more reliable since it could achieve a
better recovery for both AIF-DDM and AIF-DDM .
FULL NUD
8 A. Garrido-Pérez et al.
Fig.2:Modelrecoveryresults.Eachcellcontainsthefractionofsimulatedexper-
iments from a given true model, for which a corresponding model was classified
as the best-fitting, according to the BIC score (left) or the AIC score (right).
3.2 Model comparison results
TheBMSanalysisrevealeddifferentresultsdependingonthescoreused.Accord-
ing to the BIC score, AIF-DDM and AIF-DDM dominated moderately
NSD NPS
across participants with Expected Posterior Probabilities, EPP = [0.39,0.31],
Protected Exceedance Probabilities, PEP = [0.63,0.29] and Estimated Model
Frequencies, EMF = [0.44,0.35], respectively (see Fig. 5, first row). However,
according to the AIC scores AIF-DDM was the best-fitting model with
FULL
EPP=0.57,PEP=0.97andEMF=0.7(seeFig.5,secondrow).Thedisagree-
ment between AIC and BIC scores was also reported for the model comparison
between pure HRL and AIF models [4], and likely stems from the fact that BIC
penalizes complexity more than AIC.
Even though the two BMS procedures produced conflicting results, we se-
lected AIF-DDM as the best-fitting model, and focus exclusively on its
FULL
results in the subsequent sections. This decision was based on the model re-
covery analysis, which showed that the full model is frequently misclassified as
either AIF-DDM or AIF-DDM . Nonetheless, we acknowledge that the
NSD NPS
BIC-based comparison favoured AIF-DDM and AIF-DDM , so we repli-
NSD NPS
cated our analysis for these models and show their results in Appendix D. We
excluded AIF-DDM from further analysis as it performed poorly in both
NUD
BMS procedures. Finally, the model family selection analysis revealed similar
resultstothosereportedinthestudythatcomparedpureAIFandHRL[4].We
found that the AIF-DDM family outperformed the HRL-DDM model according
to both BIC (EP = 1, EMF = 0.9, EPP = 0.88) and AIC (EP = 1, EMF =
0.92, EPP = 0.9) scores.
Cognitive Effort in the Two-Step Task 9
3.3 Parameter recovery analysis
IntegratingaDDMwithAIFsubstantiallyimprovedtherecoveryoftheparame-
terssharedbetweenAIF-DDMandpureAIFmodels(seeAppendixE,Table1).
ForthepureAIFmodels,parameterrecoverywasfarfromperfect.Forexample,
for AIF , only v had a Pearson’s correlation greater than .6 between its
FULL DU
ground-truth and recovered values. In contrast, for the AIF-DDM models, v ,
DU
v , v , a and t showed excellent recovery (r > .90, p < .001), l and κ
DS PS bs nd
were well recovered (r > .84, p < .001) and p and λ had a moderate recovery
r
(r >.67, p<.001). The drift rate parameters vmod and vmod had moderate-to-
1 2
poor recovery, depending on the specific model. Nonetheless, their recovery was
stillsuperiortothatoftheinversetemperatureparameters(γ andγ )fromthe
1 2
pure AIF model.
3.4 Expected free energy discriminability affects second stage, but
not first stage reaction times
To evaluate the models’ goodness-of-fit and predictive accuracy, we compared
model-simulated behaviour on the two-step task to the observed behaviour of
participants.Thiswasdoneusingadecile-binnedanalysisbasedontheabsolute
differenceinthenetEFEbetweenthetwoactions,|∆Gnet|.ForeachAIF-DDM
model (except AIF-DDM ), we first computed the trial-by-trial |∆Gnet| for
NUD
eachparticipantforbothstages,basedontheirbest-fitmodelparameters,choice
history, and the experienced sequence of rewards and transitions. From the re-
sulting distribution of |∆Gnet| values, for each participant and stage, we iden-
tified the decile boundaries (10th-90th percentiles). We then binned each trial’s
observedRTandchoiceintooneoftendecilebinsaccordingtoits|∆Gnet|value.
For example, a trial with a |∆Gnet| value below the 10th percentile was placed
in the first bin (0th-10th). Within each bin, we calculated two metrics for each
participant: (1) the mean RT, and (2) the probability of choosing the action
with the lower net EFE, P(choose Gnet). These participant-level metrics were
min
thenaveragedacrossparticipantsforeachdecilebin.Finally,foreachtrialstage,
we generated 100 simulations to estimate the model’s predicted RT and choice
probability.Thesesimulatedmetricswerethenbinnedandaveragedinthesame
way as the observed data.
The simulation analysis results were qualitatively similar across all models,
therefore we only display the predictions of the AIF-DDM model as an
FULL
example in Fig. 3. Equivalent plots for the remaining models are presented in
theAppendixF.Inbothstages,participantsweremorelikelytoselecttheaction
with the minimum net EFE as the value of |∆Gnet| increased. This trend was
well-captured by all the AIF-DDM models (see Appendix F).
The AIF-DDM models also predict that the mean RT should decrease as a
functionofEFEdiscriminability(i.e.,as|∆Gnet|increases)forbothstages.This
effect can be observed for the second stage; however, it is almost negligible for
the first one (Fig. 3, bottom left).
10 A. Garrido-Pérez et al.
Fig.3: Comparison of observed (blue) and model-predicted (orange) behaviour.
Lines show the mean choice probability (top) and mean reaction time (bot-
tom)acrossparticipants,binnedbynetExpectedFreeEnergy(|∆Gnet|)deciles.
Shaded areas are ±1 standard error of the mean.
Multiple explanations may account for the mismatch in first-stage RTs. The
firstconcernsthe2-seconddeadline.AsdescribedinSection2.1,allmissedtrials
were excluded from the analysis, effectively truncating the observed RT distri-
bution. In contrast, the AIF-DDM models do not impose this time restriction,
resulting in higher predicted RT means (see Appendix G for further details).
However, this effect alone is unlikely to fully explain the misfit, since the second
stage had the same deadline, yet a far less pronounced mismatch.
A second possible explanation stems from the well-documented tendency for
participants to repeat their previous first-stage choice [4]. In both AIF(-DDM)
and HRL(-DDM), a habit term is included only in the first-stage equations. It
is therefore plausible that, for most first-stage choices, the habit strength of the
previously selected option is sufficient to produce fast responses—even in trials
falling into the lowest |∆Gnet| deciles. In contrast, with the lack of a habit term
in the second-stage equations, |∆Gnet| values may be smaller or more variable.
This effect was particularly notable for the participant with the largest fitted κ
value (where κ regulates the tendency to repeat the previous first-stage choice).
However, it was not observed for the rest of the participants (see Fig. 4).
A third potential explanation is that a substantial portion of the cognitive
effort in the initial stage may arise from mental simulation or partial explo-
ration of the decision tree, a process not accounted for by the assumption that
RTs depend solely on |∆Gnet|. Nevertheless, the limited complexity of the task
(involving only four possible branches) constrains the extent of such planning.
Cognitive Effort in the Two-Step Task 11
Fig.4: Observed reaction time (RT) vs. |∆Gnet| for the AIF-DDM model,
FULL
separated by task stage. Each circle represents a single trial. Trials from the
’sticky’ participant, identified by the highest fitted κ value, are shown in red.
Trials from all other participants are shown in blue. For the sticky participant,
notice the cluster of first-stage trials with high |∆Gnet| values compared to the
second-stage trials that are more concentrated at low |∆Gnet| values.
3.5 The lack of net EFE discriminability effect on first-stage
reaction times might be explained by the experimental design
Afinalpotentialexplanationforthelackof|∆Gnet|effectonfirst-stageRTsisthe
experimental design. In the trial sequence of the two-step task, the elapsed time
fromthemomentparticipantsmakethesecond-stagechoiceoftheprevioustrial
until they are presented with the first-stage options of the next trial is variable
and long (3.2-3.8s). This time interval could allow participants to engage in
"pre-thinking" about their upcoming first-stage choice before the options are
presented. As a result, the recorded first-stage RT may only capture the final
execution of an already made decision, rather than the full deliberation process.
In contrast, the interval between the first- and second-stage choices is fixed and
shorter(2s),leavinglessroomforpre-thinkingandmakingthesecond-stageRT
a more reliable measure of cognitive effort.
The difference in inter-choice intervals could also explain why mean first-
stageRTsareshorterthanmeansecond-stageRTs(seeFig.3),whichmayseem
counterintuitive since, according to AIF, participants in the first stage should
engage in planning, a more costly cognitive process than the one-shot second-
stage decision.
4 Discussion
In this study, we introduced a novel AIF-DDM and evaluated its predictions in
thetwo-steptask.Wediscussedthedifferencebetweenthemodelpredictionsand
arecentlydevelopedinformation-theoreticformalismofcognitiveeffortbasedon
AIF (Eq. 4, [10]).
Our model predicts that both the need to overcome a pre-existing habit and
the difficulty of discriminating between options with similar subjective values
(EFEs) increase cognitive effort during the first stage of the two-step task. We
12 A. Garrido-Pérez et al.
arguethatforthefirststage,botheffectscanberegardedasasinglecompetition
process between the ’habit-corrected’ or net EFEs of the available options. For
the second stage, habits are assumed to play no role, and therefore, the model
predicts that cognitive effort only depends on the discriminability between pure
context-sensitive EFEs.
We found empirical evidence that EFE discriminability affects second-stage
RTs of the two-step task as predicted by the AIF-DDM model – an effect that
is not captured by the information-theoretic formalism. However, we found that
the discriminability between the habit-corrected EFEs had a negligible effect
on the first-stage RTs, contrary to the AIF-DDM predictions. We argue that
the latter observation could be a result of the long inter-trial intervals that
may allow participants to "pre-think" their choice before being presented with
the options. Thus, first-stage RTs may only reflect motor execution, not the
preceding cognitive effort.
Lastly,wefoundthatintegratingaDDMwithAIFdidnothelptodistinguish
between different learning mechanisms proposed by [4]. However, the DDM in-
tegrationimprovedparameterrecoverycomparedtopureAIF.Thelatterresult
was expected, since the same effect has been reported for HRL in the two-step
task [16]. Nonetheless, the result might be relevant for computational psychia-
t

Rewrite the summary fixing the issues. Use exact title: Cognitive Effort in the Two-Step Task: An Active Inference Drift-Diffusion Model Approach
PROFESSIONAL TONE: Begin directly with content - NO conversational openings.
NO REPETITION. Each sentence must be unique. Vary attribution phrases.
Extract quotes VERBATIM from paper text - do NOT modify or "correct" them.