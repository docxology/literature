### OverviewThis summary presents the key findings of the paper "Mobile Manipulation with Active Inference for Long-Horizon Rearrangement Tasks," investigating a hierarchical active inference architecture for robot manipulation. The authors demonstrate that this approach outperforms state-of-the-art baselines across three challenging Habitat Benchmark tasks – TidyHouse, PrepareGroceries, and SetTable – marking a significant advancement in long-horizon robotic manipulation.### MethodologyThe core of the research lies in a fully hierarchical hybrid active inference architecture. The system combines a high-level active inference model with a whole-body controller based on continuous hierarchical active inference. The high-level model orchestrates task-relevant actions, while the whole-body controller manages the robot’s movements and interactions. The system utilizes variational Bayes Gaussian splatting (VBGS) for perception, creating a3D representation of the environment. The key components include a kinematic generative model, which computes the absolute position and orientation of the current link, and a whole-body controller that manages the robot’s movements and interactions. The system employs a hierarchical approach, with the high-level model orchestrating task-relevant actions, while the whole-body controller manages the robot’s movements and interactions. The system utilizes variational Bayes Gaussian splatting (VBGS) for perception, creating a3D representation of the environment. The key components include a kinematic generative model, which computes the absolute position and orientation of the current link, and a whole-body controller that manages the robot’s movements and interactions. The system utilizes variational Bayes Gaussian splatting (VBGS) for perception, creating a3D representation of the environment. The key components include a kinematic generative model, which computes the absolute position and orientation of the current link, and a whole-body controller that manages the robot’s movements and interactions. The system utilizes variational Bayes Gaussian splatting (VBGS) for perception, creating a3D representation of the environment. The key components include a kinematic generative model, which computes the absolute position and orientation of the current link, and a whole-body controller that manages the robot’s movements and interactions. The system utilizes variational Bayes Gaussian splatting (VBGS) for perception, creating a3D representation of the environment. The key components include a kinematic generative model, which computes the absolute position and orientation of the current link, and a whole-body controller that manages the robot’s movements and interactions. The system utilizes variational Bayes Gaussian splatting (VBGS) for perception, creating a3D representation of the environment. The key components include a kinematic generative model, which computes the absolute position and orientation of the current link, and a whole-body controller that manages the robot’s movements and interactions. The system utilizes variational Bayes Gaussian splatting (VBGS) for perception, creating a3D representation of the environment. The key components include a kinematic generative model, which computes the absolute position and orientation of the current link, and a whole-body controller that manages the robot’s movements and interactions. The system utilizes variational Bayes Gaussian splatting (VBGS) for perception, creating a3D representation of the environment. The key components include a kinematic generative model, which computes the absolute position and orientation of the current link, and a whole-body controller that manages the robot’s movements and interactions. The system utilizes variational Bayes Gaussian splatting (VBGS) for perception, creating a3D representation of the environment. The key components include a kinematic generative model, which computes the absolute position and orientation of the current link, and a whole-body controller that manages the robot’s movements and interactions. The system utilizes variational Bayes Gaussian splatting (VBGS) for perception, creating a3D representation of the environment. The key components include a kinematic generative model, which computes the absolute position and orientation of the current link, and a whole-body controller that manages the robot’s movements and interactions. The system utilizes variational Bayes Gaussian splatting (VBGS) for perception, creating a3D representation of the environment. The key components include a kinematic generative model, which computes the absolute position and orientation of the current link, and a whole-body controller that manages the robot’s movements and interactions. The system utilizes variational Bayes Gaussian splatting (VBGS) for perception, creating a3D representation of the environment. The key components include a kinematic generative model, which computes the absolute position and orientation of the current link, and a whole-body controller that manages the robot’s movements and interactions. The system utilizes variational Bayes Gaussian splatting (VBGS) for perception, creating a3D representation of the environment. The key components include a kinematic generative model, which computes the absolute position and orientation of the current link, and a whole-body controller that manages the robot’s movements and interactions. The system utilizes variational Bayes Gaussian splatting (VBGS) for perception, creating a3D representation of the environment. The key components include a kinematic generative model, which computes the absolute position and orientation of the current link, and a whole-body controller that manages the robot’s movements and interactions. The system utilizes variational Bayes Gaussian splatting (VBGS) for perception, creating a3D representation of the environment. The key components include a kinematic generative model, which computes the absolute position and orientation of the current link, and a whole-body controller that manages the robot’s movements and interactions. The system utilizes variational Bayes Gaussian splatting (VBGS) for perception, creating a3D representation of the environment. The key components include a kinematic generative model, which computes the absolute position and orientation of the current link, and a whole-body controller that manages the robot’s movements and interactions. The system utilizes variational Bayes Gaussian splatting (VBGS) for perception, creating a3D representation of the environment. The key components include a kinematic generative model, which computes the absolute position and orientation of the current link, and a whole-body controller that manages the robot’s movements and interactions. The system utilizes variational Bayes Gaussian splatting (VBGS) for perception, creating a3D representation of the environment. The key components include a kinematic generative model, which computes the absolute position and orientation of the current link, and a whole-body controller that manages the robot’s movements and interactions. The system utilizes variational Bayes Gaussian splatting (VBGS) for perception, creating a3D representation of the environment. The key components include a kinematic generative model, which computes the absolute position and orientation of the current link, and a whole-body controller that manages the robot’s movements and interactions. The system utilizes variational Bayes Gaussian splatting (VBGS) for perception, creating a3D representation of the environment. The key components include a kinematic generative model, which computes the absolute position and orientation of the current link, and a whole-body controller that manages the robot’s movements and interactions. The system utilizes variational Bayes Gaussian splatting (VBGS) for perception, creating a3D representation of the environment. The key components include a kinematic generative model, which computes the absolute position and orientation of the current link, and a whole-body controller that manages the robot’s movements and interactions. The system utilizes variational Bayes Gaussian splatting (VBGS) for perception, creating a3D representation of the environment. The key components include a kinematic generative model, which computes the absolute position and orientation of the current link, and a whole-body controller that manages the robot’s movements and interactions. The system utilizes variational Bayes Gaussian splatting (VBGS) for perception, creating a3D representation of the environment. The key components include a kinematic generative model, which computes the absolute position and orientation of the current link, and a whole-body controller that manages the robot’s movements and interactions. The system utilizes variational Bayes Gaussian splatting (VBGS) for perception, creating a3D representation of the environment. The key components include a kinematic generative model, which computes the absolute position and orientation of the current link, and a whole-body controller that manages the robot’s movements and interactions. The system utilizes variational Bayes Gaussian splatting (VBGS) for perception, creating a3D representation of the environment. The key components include a kinematic generative model, which computes the absolute position and orientation of the current link, and a whole-body controller that manages the robot’s movements and interactions. The system utilizes variational Bayes Gaussian splatting (VBGS) for perception, creating a3D representation of the environment. The key components include a kinematic generative model, which computes the absolute position and orientation of the current link, and a whole-body controller that manages the robot’s movements and interactions. The system utilizes variational Bayes Gaussian splatting (VBGS) for perception, creating a3D representation of the environment. The key components include a kinematic generative model, which computes the absolute position and orientation of the current link, and a whole-body controller that manages the robot’s movements and interactions. The system utilizes variational Bayes Gaussian splatting (VBGS) for perception, creating a3D representation of the environment. The key components include a kinematic generative model, which computes the absolute position and orientation of the current link, and a whole-body controller that manages the robot’s movements and interactions. The system utilizes variational Bayes Gaussian splatting (VBGS) for perception, creating a3D representation of the environment. The key components include a kinematic generative model, which computes the absolute position and orientation of the current link, and