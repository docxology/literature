### OverviewThis paper investigates the control of multi-joint dynamical systems using a coupled active inference agent approach. The authors propose a system consisting of multiple scalar autoregressive model-based agents, coupled together by virtue of sharing memories. Each subagent infers parameters through Bayesian filtering and controls by minimizing expected free energy over a finite time horizon. The core contribution of this work is demonstrating that a coupled agent of this kind is able to learn the dynamics of a double mass-spring-damper system, and drive it to a desired position through a balance of explorative and exploitative actions. It outperforms the uncoupled subagents in terms of surprise and goal alignment.### MethodologyThe authors present a system based on active inference, drawing inspiration from cognitive science. The core of the approach is the use of autoregressive models, which are well-suited for resource-constrained mechatronics systems. The model consists of multiple scalar autoregressive agents, coupled together by virtue of sharing memories. Each subagent infers parameters through Bayesian filtering and controls by minimizing expected free energy over a finite time horizon. The model is characterized by a likelihood function of the form:p(y |θ,τ,u ,u¯ ,y¯ )=N(cid:0)y |θ⊺(cid:2)u u¯ y¯ ,τ−1(cid:1).The prior distribution on the parameters is a multivariate Gaussian - univariate Gamma distribution [27, ID: D5]. The model incorporates a memory buffer to store past observations and controls, allowing the agents to learn from their experiences. The agents use a Bayesian filtering approach to update their parameter beliefs based on new data. The control policy is determined by minimizing the expected free energy, which represents the trade-off between exploration and exploitation. The authors quantify the system’s parameters using a Gaussian-Gamma prior distribution. The model is implemented using a two-step approach: first, the parameters are inferred from the data, and second, the control policy is optimized based on the inferred parameters. The authors use a one-step ahead prediction, which means that the agents predict the outcome of their actions one step into the future.### ResultsThe authors demonstrate the effectiveness of their approach by applying it to a double mass-spring-damper system. They found that a coupled agent of this kind is able to learn the dynamics of the system and drive it to a desired position through a balance of explorative and exploitative actions. The authors report that the coupled agent outperforms the uncoupled subagents in terms of surprise and goal alignment. Specifically, the coupled agent achieves a lower prediction variance and a more accurate alignment with the desired values within the first20 time steps. After reaching the goal prior, oscillations around it diminish over time, resulting in a stable state where both displacements remain within a narrow range of the desired values, as indicated by the low prediction variance. In contrast, the uncoupled agents oscillate more wildly (until around timestep45) and have more difficulty maintaining close adherence to the goal prior. The higher prediction variance further highlights the increased uncertainty and instability in the performance of uncoupled ARX-EFE agents compared to CARX-EFE. The control signals (Fig.2b) provide further insight into the observed differences in stabilization performance. Both sets of agents start with a brief initial phase of inactivity, during which the control signals remain at zero, keeping the system in its initial, stable state. Following this inactivity phase, both sets of agents apply non-zero control inputs characterized by relatively large oscillations where they learn the input-output relationship before moving to the goal prior. After reaching the goal prior, the control pulse width of one agent in each set gradually converges to specific values (0.0 for the coupled agent,0.4 for the uncoupled agent), while the other agent in the set alternates between a high and a low control value of the control space U. These oscillations are more narrow for the agent in control of mass m , compared to the uncoupled ARX-EFE agent controlling mass m .### DiscussionImproved ability to stabilize and lower prediction variance demonstrated by CARX-EFE suggest a significant advantage in scenarios requiring reliable convergence, such as robotic control and adaptive systems in unpredictable environments. However, the current findings are based on a single simulation run, necessitating further validation. Conducting Monte Carlo experiments would confirm the robustness of CARX-EFE’s advantages across varied conditions. Future work should also evaluate the CARX-EFE agents on nonlinear and underactuated systems, like a double pendulum or acrobot, to assess their ability to generalize. Additionally, benchmarking against other control methods could provide insights into the relative strength of CARX-EFE agents. The current implementation of CARX-EFE agents relies on a one-step ahead prediction, making their performance sensitive to the system update step size (∆t). Addressing this limitation by extending the prediction capability could reduce the dependence on these parameters, and possibly improve the efficiency of the coupled approach.### ConclusionWe investigated the control of a multi-joint mechanical system by coupling multiple autoregressive active inference agents that minimize expected free energy. We evaluate the effect of sharing data buffers (i.e., memories) in the autoregressive models of the agents. Our experiments demonstrate that coupling significantly improves the agent’s ability to achieve both better goal alignment and lower prediction error. CARX-EFE agents consistently outperformed their uncoupled counterparts, showing lower prediction uncertainty with higher prediction accuracy (lower surprise), and greater long-term stability around the goal prior. It is important to note that the agent is limited to one-step-ahead predictions. Future research should focus on extending the horizon of the agents, and improving the optimization procedure in MAP estimation.Acknowledgments. The authors gratefully acknowledge support by the Eindhoven Artificial Intelligence Systems Institute and the Ministry of Education, Culture and Science of the Government of the Netherlands.Disclosure of Interests. The authors have no competing interests to declare that are relevant to the content of this article.