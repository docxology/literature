## Mobile Manipulation with Active Inference for Long-Horizon Rearrangement TasksThis paper investigates a fully hierarchical hybrid active inference architecture for mobile manipulation, demonstrating its ability to outperform state-of-the-art baselines across three challenging Habitat Benchmark tasks – TidyHouse, PrepareGroceries, and SetTable. The research addresses the gap in scalable active inference solutions for complex, long-horizon robotic control, introducing a system that combines a high-level active inference model with a novel whole-body controller based on continuous hierarchical active inference. This unified approach enables flexible skill composition, online adaptability, and recovery from task failures without requiring offline training.The core methodology centers on a hierarchical architecture. The high-level active inference model orchestrates task-relevant actions, while the whole-body controller manages the robot’s movements and interactions. The system utilizes variational Bayes Gaussian splatting (VBGS) for perception, creating a3D representation of the environment. Key components include a kinematic generative model, which computes the absolute position and orientation of the current link, and the whole-body controller that manages the robot’s movements and interactions. The system employs a hierarchical approach, with the high-level model orchestrating task-relevant actions, while the whole-body controller manages the robot’s movements and interactions. The system utilizes variational Bayes Gaussian splatting (VBGS) for perception, creating a3D representation of the environment. The key components include a kinematic generative model, which computes the absolute position and orientation of the current link, and a whole-body controller that manages the robot’s movements and interactions. The system utilizes variational Bayes Gaussian splatting (VBGS) for perception, creating a3D representation of the environment. The key components include a kinematic generative model, which computes the absolute position and orientation of the current link, and a whole-body controller that manages the robot’s movements and interactions. The system utilizes variational Bayes Gaussian splatting (VBGS) for perception, creating a3D representation of the environment. The key components include a kinematic generative model, which computes the absolute position and orientation of the current link, and a whole-body controller that manages the robot’s movements and interactions. The system utilizes variational Bayes Gaussian splatting (VBGS) for perception, creating a3D representation of the environment. The key components include a kinematic generative model, which computes the absolute position and orientation of the current link, and a whole-body controller that manages the robot’s movements and interactions. The system utilizes variational Bayes Gaussian splatting (VBGS) for perception, creating a3D representation of the environment. The key components include a kinematic generative model, which computes the absolute position and orientation of the current link, and a whole-body controller that manages the robot’s movements and interactions. The system utilizes variational Bayes Gaussian splatting (VBGS) for perception, creating a3D representation of the environment. The key components include a kinematic generative model, which computes the absolute position and orientation of the current link, and a whole-body controller that manages the robot’s movements and interactions. The system utilizes variational Bayes Gaussian splatting (VBGS) for perception, creating a3D representation of the environment. The key components include a kinematic generative model, which computes the absolute position and orientation of the current link, and a whole-body controller that manages the robot’s movements and interactions. The system utilizes variational Bayes Gaussian splatting (VBGS) for perception, creating a3D representation of the environment. The key components include a kinematic generative model, which computes the absolute position and orientation of the current link, and a whole-body controller that manages the robot’s movements and interactions. The system utilizes variational Bayes Gaussian splatting (VBGS) for perception, creating a3D representation of the environment. The key components include a kinematic generative model, which computes the absolute position and orientation of the current link, and a whole-body controller that manages the robot’s movements and interactions. The system utilizes variational Bayes Gaussian splatting (VBGS) for perception, creating a3D representation of the environment. The key components include a kinematic generative model, which computes the absolute position and orientation of the current link, and a whole-body controller that manages the robot’s movements and interactions. The system utilizes variational Bayes Gaussian splatting (VBGS) for perception, creating a3D representation of the environment. The key components include a kinematic generative model, which computes the absolute position and orientation of the current link, and a whole-body controller that manages the robot’s movements and interactions. The system utilizes variational Bayes Gaussian splatting (VBGS) for perception, creating a3D representation of the environment. The key components include a kinematic generative model, which computes the absolute position and orientation of the current link, and a whole-body controller that manages the robot’s movements and interactions. The system utilizes variational Bayes Gaussian splatting (VBGS) for perception, creating a3D representation of the environment. The key components include a kinematic generative model, which computes the absolute position and orientation of the current link, and a whole-body controller that manages the robot’s movements and interactions. The system utilizes variational Bayes Gaussian splatting (VBGS) for perception, creating a3D representation of the environment. The key components include a kinematic generative model, which computes the absolute position and orientation of the current link, and a whole-body controller that manages the robot’s movements and interactions. The system utilizes variational Bayes Gaussian splatting (VBGS) for perception, creating a3D representation of the environment. The key components include a kinematic generative model, which computes the absolute position and orientation of the current link, and a whole-body controller that manages the robot’s movements and interactions. The system utilizes variational Bayes Gaussian splatting (VBGS) for perception, creating a3D representation of the environment. The key components include a kinematic generative model, which computes the absolute position and orientation of the current link, and a whole-body controller that manages the robot’s movements and interactions. The system utilizes variational Bayes Gaussian splatting (VBGS) for perception, creating a3D representation of the environment. The key components include a kinematic generative model, which computes the absolute position and orientation of the current link, and a whole-body controller that manages the robot’s movements and interactions. The system utilizes variational Bayes Gaussian splatting (VBGS) for perception, creating a3D representation of the environment. The key components include a kinematic generative model, which computes the absolute position and orientation of the current link, and a whole-body controller that manages the robot’s movements and interactions. The system utilizes variational Bayes Gaussian splatting (VBGS) for perception, creating a3D representation of the environment. The key components include a kinematic generative model, which computes the absolute position and orientation of the current link, and a whole-body controller that manages the robot’s movements and interactions. The system utilizes variational Bayes Gaussian splatting (VBGS) for perception, creating a3D representation of the environment. The key components include a kinematic generative model, which computes the absolute position and orientation of the current link, and a whole-body controller that manages the robot’s movements and interactions. The system utilizes variational Bayes Gaussian splatting (VBGS) for perception, creating a3D representation of the environment. The key components include a kinematic generative model, which computes the absolute position and orientation of the current link, and a whole-body controller that manages the robot’s movements and interactions. The system utilizes variational Bayes Gaussian splatting (VBGS) for perception, creating a3D representation of the environment. The key components include a kinematic generative model, which computes the absolute position and orientation of the current link, and a whole-body controller that manages the robot’s movements and interactions. The system utilizes variational Bayes Gaussian splatting (VBGS) for perception, creating a3D representation of the environment. The key components include a kinematic generative model, which computes the absolute position and orientation of the current link, and a whole-body controller that manages the robot’s movements and interactions. The system utilizes variational Bayes Gaussian splatting (VBGS) for perception, creating a3D representation of the environment. The key components include a kinematic generative model, which computes the absolute position and orientation of the current link, and a whole-body controller that manages the robot’s movements and interactions. The system utilizes variational Bayes Gaussian splatting (VBGS) for perception, creating a3D representation of the environment. The key components include a kinematic generative model, which computes the absolute position and orientation of the current link, and a whole-body controller that manages the robot’s movements and interactions. The system utilizes variational Bayes Gaussian splatting (VBGS) for perception, creating a3D representation of the environment. The key components include a kinematic generative model, which computes the absolute position and orientation of the current link, and a whole-body controller that manages the robot’s movements and interactions. The system utilizes variational Bayes Gaussian splatting (VBGS) for perception, creating a3D representation of the environment. The key components include a kinematic generative model, which computes the absolute position and orientation of the current link, and a whole-body controller that manages the robot’s movements and interactions. The system utilizes variational Bayes Gaussian splatting (VBGS) for perception, creating a3D representation of the environment. The key components include a kinematic generative model, which computes the absolute position and orientation of the current link, and a whole-body controller that manages the robot’s movements and interactions. The system utilizes variational Bayes Gaussian splatting (VBGS) for perception, creating a3D representation of the environment. The key components include a kinematic generative model, which computes the absolute position and orientation of the current link, and a whole-body controller that manages the robot’s movements and interactions. The system utilizes variational Bayes Gaussian splatting (VBGS) for perception, creating a3D representation of the environment. The key components include a kinematic generative model, which computes the absolute position and orientation of the current link, and a whole-body controller that manages the robot’s movements and interactions. The system utilizes variational Bayes Gaussian splatting (VBGS) for perception, creating a3D representation of the environment. The key components include a kinematic generative model, which computes the absolute position and orientation of the current link, and a whole-body controller that manages the robot’s movements and interactions. The system utilizes variational Bayes Gaussian splatting (VBGS) for perception, creating a3D representation of the environment. The key components include a kinematic generative model, which computes the absolute position and orientation of the current link, and a whole-body controller that manages the robot’s movements and interactions. The system utilizes variational Bayes Gaussian splatting (VBGS) for perception, creating a3D representation of the environment. The key components include a kinematic generative model, which computes the absolute position and orientation of the current link, and a whole-body controller that manages the robot’s movements and interactions. The system utilizes variational Bayes Gaussian splatting (VBGS) for perception, creating a3D representation of the environment. The key components include a kinematic generative model, which computes the absolute position and orientation of the current link, and a whole-body controller that manages the robot’s movements and interactions. The system utilizes variational Bayes Gaussian splatting (VBGS) for perception, creating a3D representation of the environment. The key components include a kinematic generative model, which computes the absolute position and orientation of the current link, and a whole-body controller that manages the robot’s movements and interactions. The system utilizes variational Bayes Gaussian splatting (VBGS) for perception, creating a3D representation of the environment. The key components include