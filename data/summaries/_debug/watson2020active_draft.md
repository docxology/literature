### OverviewThis paper, “Active Inference or Control as Inference? A Unifying View,” by Watson, Imohiosen, and Peters, investigates the relationship between active inference (AI) and control as inference (CaI). The authors argue that AI, a probabilistic framework for sensorimotor behavior, can be framed as a partially-observed, inference-based optimal control problem, offering a more principled and computationally tractable approach. The core of their argument rests on the idea that AI’s free-energy objective aligns with the ELBO, and that the framework can be directly translated into a control problem. The paper highlights the need for a unified view of AI and CaI, emphasizing the potential for improved practical implementations.### MethodologyThe authors’ methodology centers on a critical analysis of active inference by framing it through the lens of control as inference (CaI). They outline a problem formulation that includes a known stochastic, continuous, discrete-time, partially-observed, nonlinear, dynamical system with state x∈Rdx, observations y∈Rdy, and control inputs u∈Rdu, operating over a time horizon T. They define the states in upper case to denote the variables over the time horizon, i.e. U = {u ,...,u }. The joint distribution (generative model) p(Y,X,U) factorizes into several interpretable distributions: The dynamics p(x |x ,u ), observation model p(y | x ,u ), and behavior policy p(u |x ). They then detail variational inference for latent variable models, utilizing the Kullback-Liebler (KL) divergence, e.g. minD [q || p] w.r.t. θ.KL θ is more complex inference tasks can be described by observationsy influenced by unseen latent variables x. Given an observation y∗, maximizing the likelihood involves integrating over the hidden states, and so is termed the marginal likelihood p(y∗)= p(y=y∗,x)dx. Unfortunately this marginalization is typically intractable in closed-form. A more useful objective may be obtained by applying a variational approximation of latent state q (x | y∗) = q (x | y=y∗) to θ θ the logmarginallikelihoodandobtaininga lowerbound viaJensen’s inequality [17] log p(y∗,x)dx=log p(y∗,x)q q θ θ ( ( x x | | y y ∗ ∗ ) ) dx=logE x∼qθ(·|y∗) h q p θ ( ( y x ∗ | , y x ∗ ) )i , (1) ≥E x∼qθ(·|y∗) h log q p θ ( ( y x ∗ | , y x ∗ ) )i =-D KL [q θ (x|y∗)||p(x,y∗)], (2) =E x∼qθ(·|y∗) [logp(y∗ |x)]−D KL [q θ (x|y∗)||p(x)], (3) where equations2,3 are variations of the ‘evidence lower bound objective’ (ELBO). The expectation maximization (EM) algorithm [17], can be understood via Equation3 as iteratively estimating the latent states (minimizing the KL term via q) in the E step and maximizing the likelihood term in the M step.### ResultsThe authors demonstrate that AI can be framed as a partially-observed CaI. They show that the free-energy principle, which is the negative of the ELBO, is used to describe the distance between future predicted and desired observations, where u is directly represented as a policy u = π(x), so F(y∗,x |π) over the future trajectory is minimized. They provide a specific example of a linear Gaussian system, where the state x and action u are defined as x∈Rdx and u∈Rdu, respectively. They state: “We show that AI may be framed as partially-observed CaI when the cost function is defined specifically in the observation states.” Furthermore, they detail the use of message passing to estimate the state and control inputs, which is a key component of the CaI framework. They also note that AI has yet to demonstrate the sophisticated control achieved by advanced optimal methods, such as differential dynamic programming [20].### DiscussionIn summary, this paper presents a compelling argument for framing active inference as control as inference. By unifying these two frameworks, the authors provide a more principled and computationally tractable approach. The paper’s key contribution is the demonstration that AI’s free-energy objective aligns with the ELBO, and that the framework can be directly translated into a control problem. The authors state: “The authors state: “The free-energy principle…is a unified brain theory?””. They emphasize the need for a unified view of AI and CaI, emphasizing the potential for improved practical implementations.### ConclusionWe have derived an equivalent formulation to active inference by considering partially-observed, inference-based optimal control, which has a principled derivation and is well-suited for approximate inference. While we have delin-eated state estimation as operating on past measurement and control as planning future actions (Equation15), both AI and i2c demonstrate the duality between estimation and control due to the mathematical similarity when both are treated probabilistically. We hope the inclusion of the CaI literature enables a greater theoretical understanding of AI and more effective implementations through approximate inference.