Fix these issues in your summary:
- Too short: 165 words (minimum 200)

Current summary:
Okay, hereâ€™s a revised summary of the paper â€œActive Inference for an Intelligent Agent in Autonomous Reconnaissance Missionsâ€ adhering to your specifications.**Active Inference for an Intelligent Agent in Autonomous Reconnaissance Missions**This research investigates the application of active inference for creating intelligent agents capable of autonomous reconnaissance tasks. The study centers on a system that utilizes a dynamic, data-driven approach to achieve situational awareness, demonstrating a novel method for generating insights from complex environments. The core of the system is a generative model that incorporates dynamic simulations and sensor data to produce a comprehensive understanding of the surrounding environment.The systemâ€™s architecture is based on a dynamic, data-driven approach to achieve situational awareness. The central component is a generative model that incorporates dynamic simulations and sensor data to produce a comprehensive understanding of the surrounding environment. The system achieves this by leveraging a dynamic, data-driven approach to achieve situational awareness. The system achieves this by utilizing a dynamic, data-driven approach to achieve situational awareness. The system achieves

Paper text:
Presented at the 6th International Workshop on Active Inference, 15â€“17 October 2025, Montreal, 
Canada. 
Active Inference for an Intelligent Agent in Autonomous 
Reconnaissance Missions 
Johan Schubert[0000-0002-0262-9908], Farzad Kamrani[0000-0001-9448-6803], 
Tove Gustavi[0009-0003-1886-9265] 
Swedish Defence Research Agency, SE-164 90 Stockholm, Sweden 
{johan.schubert,farzad.kamrani,tove.gustavi}@foi.se 
Abstractâ€”We develop an active inference route-planning method for the au-
tonomous control of intelligent agents. The aim is to reconnoiter a geographical 
area to maintain a common operational picture. To achieve this, we construct an 
evidence map that reflects our current understanding of the situation, incorporat-
ing both positive and â€œnegativeâ€ sensor observations of possible target objects 
collected over time, and diffusing the evidence across the map as time progresses. 
The generative model of active inferenc e uses Dempster-Shafer theory and a 
Gaussian sensor model, which provides input to the agent. The generative process 
employs a Bayesian approach to update a posterior probability distribution. We 
calculate the variational free energy for all positions within the area by assessing 
the divergence between a pignistic probability distribution of the evidence map 
and a posterior probability distribution of  a target object based on the observa-
tions, including the level of surprise associated with receiving new observations. 
Using the free energy, we direct the agentsâ€™ movements in a simulation by taking 
an incremental step toward a position th at minimizes the free energy. This ap-
proach addresses the challenge of explor ation and exploitation, allowing agents 
to balance searching extensive areas of the geographical map while tracking iden-
tified target objects. 
Keywordsâ€”active inference, free energy principle, autonomous agents. 
1 Introduction 
This paper focuses on active inference [1, 2] for the autonomous control of an intelli-
gent agent (e.g., a reconnaissance Unmanned Aerial Vehicle (UAV)) aimed at achiev-
ing and maintaining the best possible situational awareness over time. Active inference 
is a methodology for autonomous decision-making. This methodology is generic and 
based on the concept that a system aims to  minimize its surprise when receiving new 
information. What is unique about active inference is that the method includes two par-
allel approaches for an agent to seek cons istency between reality and the systemâ€™s de-
scription of the environment: either the syst emâ€™s internal representation is updated as 
new information is received, or actions are taken against the environment to change it 
so that it is consistent with its perception. 
2  J. Schubert, F. Kamrani, and T. Gustavi 
Minimizing surprise is inherently impossible. Instead, we aim for the best possible 
action by choosing the one that minimizes fr ee energy. Free energy is an information 
theory concept that refers to the divergence between two probability distributions and 
the element of surprise. One distribution reflects our perception of reality, often de-
scribed as a dynamic common operational picture, while the other is the probability 
after a current observation. When these two distributions align closely, the free energy 
is low. In active inference, the agent seeks to position itself so that its observations 
correspond with its reality model. 
Section 2 formulates the problem statement. Section 3 shows related works. Section 
4 introduces the fundamentals of active inference and free energy. Section 5 provides a 
brief overview of Dempster-Shafer theory, which updates the dynamic common oper-
ational picture. Section 6 describes the simulation environment and sensor model. In 
Section 7, we mathematically describe how to control an agent using active inference 
by minimizing free energy. Section 8 offers an overview of the implementation, and 
finally, Section 9 presents the conclusions drawn from this work. 
2 Problem Statement and Persistent Surveillance 
2.1 Problem Statement 
In the field of autonomous systems, the task of continuously monitoring a specific area 
over an indefinite period is referred to as persistent surveillance. Real-world applica-
tions for persistent surveillance systems in clude surveillance of areas around critical 
infrastructure and military facilities to detect potential intruders with malicious intent. 
It can also be used for surveillance at popular beaches to prevent drowning incidents 
and for monitoring wildlife in sensitive natural areas for preservation purposes. UAVs 
are particularly well-suited for this type of surveillance task due to their wide-angle 
views, speed, and the relative absence of ob stacles in their operational environments, 
which facilitates trajectory planning for the autonomous agents. 
In this paper, we consider a scenario in  which an autonomous agent is assigned the 
task of continuously monito ring a designated area to maintain an accurate and up-to-
date dynamic common operational picture. The agent must be capable of detecting both 
fixed and moving targets and should ideally be able to keep track of the approximate 
locations of these targets, even when they are out of sensor range. Moving targets must 
therefore be revisited as often as necessary  to prevent losing track of them. Addition-
ally, it is requested that no part of the designated area should be left unobserved for 
more than a specified time. 
In persistent surveillance scenarios, the trajectory planning problem for autonomous 
agents is usually defined by a set of specific goals and constraints, which may have 
different priorities. Various methods can be employed to implement the actual trajec-
tory planning or motion control (as discussed in Section 7). This paper specifically aims 
to investigate the feasibility of using active inference for trajectory planning and gen-
eration. The primary research question addressed in this paper can be formulated as 
follows: 
 Active Inference for an Intelligent Agent 3 
Can active inference be used to solve the motion control problem for a single UAV 
conducting multi-objective persistent surveillance over a predefined 2D area? 
2.2 An Active Inference Approach to Persistent Surveillance 
To effectively implement the active infere nce framework for motion control in a per-
sistent surveillance context, several key components must be defined. 
A generative model describes all possible states and their transitions to address these 
considerations. Information about these states is derived from observations made over 
time, allowing us to update our understand ing of the current state. We express uncer-
tainty in the model using Dempster-Shafer theo ry [3, 4]. In this model, the states are 
represented stochastically; each possible transition of target basic belief from one state 
(e.g., position) to the next is specified by transition probabilities. The states are dynam-
ically updated at each time step using a di ffusion algorithm. This model indicates the 
current basic belief of the existence of at least one target object within each possible 
state (see Section 7.1). 
A generative process complements the generative model by managing new observa-
tions made with the agentâ€™s sensor. In the generative process, we use a Bayesian ap-
proach. This process updates the probabilities of all positions within the agentâ€™s sensor 
radius. This update calculates a new probability for each position based on the current 
sensor model while considering the existing probabilities (see Section 7.2). 
Since we cannot directly minimize the surprise an agent experiences when receiving 
new observations, we focus on minimizing the free energy, which serves as an upper 
bound for that surprise. The free energy is defined as the sum of the divergence between 
two probability distributions and the level of surprise, and is our objective function to 
direct the agentsâ€™ movements. For each location within the sensor radius, we compare 
the probability obtained from the generative model with the probability derived from 
observations, striving to minimize the divergence between the two (see Section 7.3). 
At each time step, we calculate the free ener gy for all locations within the sensorâ€™s 
radius. The agent then takes a fixed-length step in the direction that minimizes free 
energy. This approach enables the agent to control itself autonomously, ensuring it 
achieves the best possible common operational picture. The agentâ€™s control is modeled 
by a Multi-Agent Dynamic Simulator (MADS) developed in-house. 
3 Related Works 
3.1 Persistent Surveillance and Motion Control 
Over the years, different methods for addressing the control problem in persistent sur-
veillance (also referred to as persistent mon itoring) have been proposed. This section 
briefly describes some examples. 
Hari et al. [5] examine a persistent monitoring mission for a single UAV, tasked with 
repeatedly visiting n targets of equal priority. Since the targets are fixed, the problem 
simplifies to a classic traveling salesman problem. Brown and Anderson [6] explore a 
4  J. Schubert, F. Kamrani, and T. Gustavi 
more complex maritime surveillance scenario that includes constraints on UAV dynam-
ics and formulate a multi-objective optimization problem aimed at maximizing infor-
mation gain and minimizing fuel consumption. Feasible and optimal solutions are found 
using a trajectory generation method combined with a particle swarm optimization al-
gorithm. Similar to the problem discussed here (in this paper), HÃ¼bel et al. [7] introduce 
a dynamic â€œinformation mapâ€ subject to information decay and use it to derive a gradi-
ent-based control that drives a group of agents to continuously update their situational 
awareness by surveilling an area. Additionally, the authors propose a time-varying den-
sity function that can be integrated into the control algorithm to model moving points 
of interest. Another approach to increase the probability of autonomous agents observ-
ing moving targets during surveillance missions was proposed by Ramasamy and 
Ghose [8]. Assuming that the probability of observing a target is non-uniformly distrib-
uted across a monitored area, Ramasamy and Ghose assign an â€œimportanceâ€ degree to 
each grid point in a discretized map where the UAV in the scenario has detected a 
target. The importance of a grid point depends on the number of detections made there 
and increases the chances of the UAV revisiting that location. Lastly, there is additional 
work documented in the literature that employs reinforcement learning for persistent 
surveillance control. Chen et al. [9] use a multi-agent reinforcement learning approach 
to learn policies for each agent in a team, tasked with continuously monitoring a 2D 
environment with stationary obstacles. To accomplish this, the problem is modeled so 
that a penalty is applied at every time step if a point in the environment is left unmoni-
tored. Mishra et al. [10] present another example of a reinforcement-learning-based 
method for persistent surveillance. 
3.2 Active Inference for Estimation and Control 
Active inference connects perception and action through variational free energy. The-
oretical links to classical estimation and control show that minimizing variational free 
energy yields objectives that combine information-theoretic surprise with control costs, 
leading to linear-quadratic-Gaussian behavior in linear-Gaussian environments [11]. In 
practical terms, active inference has been employed for state estimation of a quadcopter 
using dynamic expectation maximization (DEM). DEM is a perception scheme inspired 
by the brain, based on a data-driven model-learning algorithm [12]. Additionally, active 
inference has been used for adaptive manipulation control in the absence of detailed 
environment models in industrial robots. This method has proven to be scalable even 
when the dynamics of the environment are not explicitly modeled [13]. Active infer-
ence has also been applied to the adaptive control of robot arms using multimodal per-
ception-action and variational autoencoder (VAE)-based state representations. This ap-
proach does not require a dynamic or kinematic model of the robot [14]. Furthermore, 
active inference has been used to develop a torque controller that integrates raw vision 
and proprioception in a streamlined design for a 7-degrees-of-freedom Franka Emika 
Panda robot, capable of online adaptation to changes in dynamics and human interfer-
ence [15]. It has also been employed for fault-tolerant control under sensor faults, de-
livering unbiased state estimation and simp lifying action specification [16]. These re-
sults support our use of free energy for closed-loop control with a soft sensor model.  
 Active Inference for an Intelligent Agent 5 
3.3 Active Inference for Navigation, Exploration, and Bandit Problems 
For mobile agents, active inference under hierarchical generative models enables 
goalâ€‘oriented navigation with topologically consistent maps and practical robot deploy-
ments [17]. Modular active inference systems support flexible, goal-driven navigation, 
avoiding obstacles and choosing high-confidence paths with strong zero-shot generali-
zation to new settings [18]. Curiosity-driven learning for robotic tasks, using the free 
energy principle, employs Bayesian neural networks to represent epistemic uncertainty 
and model complex behaviors [19]. Moreover, retrospective (residual) surprise has 
been introduced as a computational element in active inference, serving as a lower 
bound on the expected free energy [20]. In decision-making, contextual multi-armed 
bandits (CMABs) extend the classical bandit problem by conditioning action selection 
on observed contextual information. Recent active inference models of CMABs 
[21, 22] use expected free energy to guide context-based action selection, balancing 
exploration and exploitation under uncertaintyâ€”an effect we replicate in our approach 
through minimizing a spatial free-energy field over the evidence map. 
3.4 Multi-agent Active Inference, Organizational Adaptation, and Complex 
Tasks 
In multi-agent settings, active inference is used to design adaptive organizations, where 
roles and structures change by minimizing team-level free energy [23â€“25]. For complex 
robotic tasks, active inference combines with behavior trees to enable continuous plan-
ning and robust execution with fewer nodes [26]. Meanwhile, non-modular, cognitively 
inspired active inference architectures are explored for robustness against unknown in-
puts [27]. Recent work extends active inference to autonomous driving by incorporat-
ing action-oriented priors that link perception and control, leading to more human-like, 
collision-avoidant behavior [28]. In socially interactive and multi-agent scenarios, ac-
tive inference applies to human-robot kinesthetic interaction, where meta-priors adjust 
compliance and counter-forces during physical contact [29], and to empathic, socially 
compliant agents that adapt their movements to surrounding individuals and contextual 
norms [30], demonstrating the flexibility of the free-energy framework for coordination 
and interaction tasks. Active inference also applies to hierarchical, embodied percep-
tion-action loops, where multiple sensorimotor pathways associated with different body 
parts are dynamically combined, enabling the robot to reconfigure control and activate 
only the necessary joints for a given task [31]. Our method differs by operationalizing 
free energy over a spatial Dempster-Shafer evidence map and a deterministic soft sen-
sor model, then guiding the agent to move in the direction that minimizes this per-cell 
objective at each step. 
3.5 Our Contribution 
Compared to surveillance controllers [5â€“10] , we introduce a Dempster-Shafer-based 
evidence map with diffusion and a deterministic soft-output sensor model to generate 
cell-wise evidential scores. Then, we steer the platform by minimizing a grid-based 
6  J. Schubert, F. Kamrani, and T. Gustavi 
free-energy objective that compares a pignistic distribution [32] to a posterior derived 
from the latest observation, including observation surprisal. Compared to active infer-
ence controllers and expected free energy-planning methods [13â€“31], our contribution 
is a computationally lightweight free-energy  minimization over the grid map that ( i) 
separates observation and state evidence, ( ii) avoids Monte Carlo sampling by using 
deterministic soft observations, and (iii) provides an effective exploration-exploitation 
balance for persistent reconnaissance. 
4 Active Inference and Free Energy 
The generative model and the generative proce ss are stochastic in nature. Let the out-
come space over all possible states be Î˜ = áˆ¼ğ‘‡, ğ¹áˆ½, where ğ‘‡ denotes the presence of at 
least one target object, and ğ¹ represents the absence of a target object. 
4.1 The Generative Model 
The generative model outlines all possible states and transitions [1, 2]. In this context, 
the states are represented by grid cells, indicating all possible positions on a map. The 
agent and the target objects can transition between states, moving from any grid cell to 
its nearest neighboring cells. 
The probability in the generative model is denoted by ğ‘
à¯«à¯¬
à¯§ áˆºğœ—áˆ», where ğœ— is the state 
and ğ‘à¯«à¯¬
à¯§  is the probability for a grid cell ğ‘à¯«à¯¬ at time ğ‘¡. In each grid cell, we have 
ğ‘à¯«à¯¬
à¯§ áˆºğœ— = ğ‘‡áˆ»+ ğ‘à¯«à¯¬
à¯§ áˆºğœ— = ğ¹áˆ» = 1.                                           áˆº1áˆ» 
We determine the probabilities ğ‘à¯«à¯¬
à¯§  for all grid cells ğ‘à¯«à¯¬ in our stochastic common op-
erational picture based on all observations gathered throughout the scenario. These ob-
servations form our understanding of the situation. More about how ğ‘à¯«à¯¬
à¯§  is calculated 
when scouting with an agent can be found in Chapter 4. 
4.2 The Generative Process 
In the generative process, we handle new ob servations. At each time step, we have an 
incoming a priori probability ğ‘à¯«à¯¬
à¯§ áˆºğœ—áˆ». This probability is equal to the posterior proba-
bility at the previous time step. 
We set 
ğ‘à¯«à¯¬
à¯§ áˆºğœ—áˆ» = ğ‘à¯«à¯¬
à¯§à¬¿à¬µáˆºğœ—|ğœ‘áˆ».                                                    áˆº2áˆ» 
In addition, we initialize the a priori probability for time 0 according to 
ğ‘à¯«à¯¬
à¬´ áˆºğœ—áˆ» = ğœ€.                                                             áˆº3áˆ» 
Using Bayes theorem, we can calculate the posterior probability ğ‘à¯«à¯¬
à¯§ áˆºğœ—|ğœ‘áˆ» in the grid 
cell ğ‘à¯«à¯¬ for the current time step ğ‘¡ based on the a priori probability. 
 Active Inference for an Intelligent Agent 7 
We have 
ğ‘à¯«à¯¬
à¯§ áˆºğœ—|ğœ‘áˆ» = ğ‘à¯«à¯¬
à¯§ áˆºğœ‘|ğœ—áˆ»
ğ‘à¯«à¯¬à¯§ áˆºğœ‘áˆ» ğ‘à¯«à¯¬
à¯§ áˆºğœ—áˆ»,                                            áˆº4áˆ» 
where ğ‘à¯«à¯¬
à¯§ áˆºğœ‘|ğœ—áˆ» represents the likelihood, which indicates the detection probability for 
an observation ğœ‘ = ğ‘‡, as determined by the sensor model, when we have a target object 
ğœ— = ğ‘‡ in the grid cell ğ‘à¯«à¯¬ at time ğ‘¡. In this context, ğ‘à¯«à¯¬
à¯§ áˆºğœ‘áˆ» represents the probability 
of obtaining an observation. The probability can be calculated according to 
ğ‘à¯«à¯¬
à¯§ áˆºğœ‘áˆ» = ğ‘à¯«à¯¬
à¯§ áˆºğœ‘|ğœ— = ğ‘‡áˆ»âˆ™ğ‘à¯«à¯¬
à¯§ áˆºğœ— = ğ‘‡áˆ»+ ğ‘à¯«à¯¬
à¯§ áˆºğœ‘|ğœ— = ğ¹áˆ»âˆ™ğ‘à¯«à¯¬
à¯§ áˆºğœ— = ğ¹áˆ»,       (5) 
where ğ‘à¯«à¯¬
à¯§ (ğœ— = ğ‘‡) denotes the a priori probability discussed earlier, and 
ğ‘à¯«à¯¬
à¯§ (ğœ— = ğ¹) =1 âˆ’ğ‘à¯«à¯¬
à¯§ (ğœ— = ğ‘‡).                                           (6) 
Additionally, ğ‘à¯«à¯¬
à¯§ (ğœ‘|ğœ— = ğ‘‡) represents the likelihood, which is the detection probabil-
ity of the sensor model, with 
ğ‘à¯«à¯¬
à¯§ (ğœ‘|ğœ— = ğ¹) =1 âˆ’ğ‘à¯«à¯¬
à¯§ (ğœ‘|ğœ— = ğ‘‡).                                      (7) 
4.3 The Free Energy 
Based on the generative modelâ€™s ğ‘à¯«à¯¬
à¯§ (ğœ—) and the generative processâ€™s ğ‘à¯«à¯¬
à¯§ (ğœ—|ğœ‘), we 
can now calculate the free energy ğ¹à¯«à¯¬
à¯§  for all grid cells ğ‘à¯«à¯¬ at time ğ‘¡. 
We have 
ğ¹à¯«à¯¬
à¯§ = ğ·à¯„à¯…àµ£ğ‘à¯«à¯¬
à¯§ (ğœ—) âˆ¥ğ‘à¯«à¯¬
à¯§ (ğœ—|ğœ‘)àµ§âˆ’ğ‘™ğ‘›àµ£ğ‘ à¯«à¯¬
à¯§ (ğœ‘)àµ§                                             
= àµ¥ à·ğ‘ à¯«à¯¬
à¯§ (ğœ—) âˆ™ğ‘™ğ‘›á‰† ğ‘à¯«à¯¬
à¯§ (ğœ—)
ğ‘à¯«à¯¬à¯§ (ğœ—|ğœ‘)á‰‡
à°£âˆˆáˆ¼à¯,à®¿áˆ½
àµ©âˆ’ğ‘™ğ‘›àµ£ğ‘ à¯«à¯¬
à¯§ (ğœ‘)àµ§                       (8) 
here ğ·à¯„à¯… is the Kullback-Leibler di vergence [33]. The term âˆ’ğ‘™ğ‘›àµ£ğ‘à¯«à¯¬
à¯§ (ğœ‘)àµ§ represents 
the degree of surprise from an observation, ğ‘à¯«à¯¬
à¯§ (ğœ—) is the probability according to the 
generative model, and ğ‘à¯«à¯¬
à¯§ (ğœ—|ğœ‘) is the posterior probability according to the generative 
process, calculated at each time poin t based on Bayes theorem. Finally, ğ‘à¯«à¯¬
à¯§ (ğœ‘) is the 
probability of an observation as derived in equation (5). 
In active inference, the action that minimizes ğ¹à¯«à¯¬
à¯§  is chosen. This action may involve 
moving to ğ‘à¯«à¯¬ or in its direction. 
5 Dempster-Shafer Theory 
In Dempster-Shafer theory [3, 4], belief is assigned to a proposition through a basic 
belief assignment. The proposition is represented by a subset ğ´ of an exhaustive set of 
mutually exclusive possibilities, referred to as a sample space Î˜. 
8  J. Schubert, F. Kamrani, and T. Gustavi 
The basic belief function ğ‘š is defined as a function from the power set of Î˜ to the 
interval áˆ¾0, 1áˆ¿ 
ğ‘š:2 à®€ â†’ áˆ¾0,1áˆ¿                                                           (9) 
where ğ‘š(âˆ…) =0  and 
à·ğ‘š (ğ´)
à®ºâŠ†à®€
= 1.                                                        (10) 
Here, ğ‘š(ğ´) represents the basic belief assigned to ğ´. 
If we receive additional information abou t the same hypothesis from a different 
source, we combine the two basic belief functions to create a more comprehensive un-
derstanding. This is achieved by computing the orthogonal combination using Demp-
sterâ€™s rule. Let ğµ be a subset of ğ‘šà¬µ and ğ¶ be a subset of ğ‘šà¬¶. The combination of ğ‘šà¬µ 
and ğ‘šà¬¶ results in a new basic belief function ğ‘šà¬µ âŠ•ğ‘šà¬¶ where 
ğ‘šà¬µ âŠ•ğ‘šà¬¶(ğ´) = ğ¾âˆ™ à· ğ‘š(ğµ)
à®»â‹‚à®¼à­€à®º
âˆ™ğ‘š(ğ¶),                                (11) 
where ğ¾ is a normalization constant. 
6 Simulation Environment and Sensor Model 
6.1 Simulation Environment 
The world is represented as a 2D map of a designated reconnaissance area. This map is 
divided into a grid of ğ‘šÃ— ğ‘› square cells indexed based on a coordinate system. Using 
a 2D representation is a deliberate simplification justified by the fact that the scenario 
being examined is much larger in its x and y dimensions compared to any variation in 
its z dimension. Although the simulator can perform 3D movements, this feature was 
disabled during the simulations conducted. The positions of both the agent and any 
target objects are indicated using cell indices in the format ğ‘à¯«à¯¬, where ğ‘¥ and ğ‘¦ are inte-
gers. Each cell is assumed to be large enough  to contain the agent or a target object 
within the reconnaissance area. 
We conduct experiments using active inference for UAV control in M ATLAB. The 
previously mentioned 2D map is the foundation for the generative model describing the 
environment. The simulation environment includes both fixed and moving target ob-
jects. Two predefined movement patterns are available for the moving target objects: 
stationary (no movement) or movement along a straight line. 
We represent uncertainty in the model us ing Dempster-Shafer theory [3, 4]. This 
uncertainty, at the mapâ€™s cell level, provides two evidence-based likelihood values. The 
first is a basic belief, denoted as ğ‘š
à¯«à¯¬
à¯§ (ğœ— = ğ‘‡), which ranges from 0 to 1. It represents 
the basic belief at time t that the cell ğ‘à¯«à¯¬ contains at least one target object. The second 
is an estimated likelihood value, also between 0 and 1, denoted as ğ‘šà¯«à¯¬
à¯§ (ğœ— = ğ¹). This 
 Active Inference for an Intelligent Agent 9 
indicates the basic belief that, at time t, the cell does not contain any target objects. The 
formulas for diffusing basic belief to neighboring cells in the generative model are de-
signed to be independent of the gridâ€™s topology. For example, moving from a square 
grid topology, used in this experiment, to a hexagonal topology only requires changing 
the parameter N, which represents the number of neighboring cells in equations (12) 
and (13) (see Section 7.1). This change adjusts N from eight to six. 
6.2 Sensor Model 
The sensor model serves as an intelligent image sensor designed for ground scouting. 
Its detection radius lets it reliably identify and classify objects as targets or non-targets. 
Each time an object is positively classified as a target, the method also provides a quan-
titative estimate, denoted as ğ‘š
à¯«à¯¬
à¯§ (ğœ— = ğ‘‡), representing the basic belief that this classi-
fication is correct. If an object is identified as a target, the sensor calculates an estimate 
of its coordinates on a 2D map. 
Since the sensor does not actively monitor or classify the absence of targets within 
the search area, it is more challenging to quantify evidence for this condition. If an area 
has been scanned without identified targets, it suggests no targets are present. In loca-
tions where no targets are detected, the sensor  provides a default estimate, denoted as 
ğ‘šà¯«à¯¬
à¯§ (ğœ— = ğ¹), for the basic belief of target absence. The terrain in the area can influence 
this estimate; for instance, the likelihood of detecting targets is generally lower in for-
ests compared to open fields. 
We implement a simplified version of the se nsor model used in the simulations to 
mimic its behavior as described above. The detection probability for target objects is 
set to 1, meaning that all target objects are detected. However, the probability that a 
detected target object is co rrectly classified is set to 0.7. Additionally, we assume the 
sensor does not generate false detections of target objects. Therefore, the uncertainties 
in the simulated sensor output arise exclusively from the classification process. 
The implementation is based on the premise that a real sensorâ€™s ability to classify 
target objects primarily depends on the distance between the sensor and the potential 
target object. The sensor operates most relia bly when it is focused on objects directly 
beneath the agent to which it is mounted. Consequently, the sensorâ€™s capability to de-
termine whether an area is free of target obj ects is expected to decline as the distance 
from the sensor increases. In the implementation, the default values of ğ‘š
à¯«à¯¬
à¯§ (ğœ— = ğ‘‡) =
0.7 and ğ‘šà¯«à¯¬
à¯§ (ğœ— = ğ¹) =0 . 3 are applied. These values correspond to the maximum ex-
pected levels of ğ‘šà¯«à¯¬
à¯§ (ğœ— = ğ‘‡) and ğ‘šà¯«à¯¬
à¯§ (ğœ— = ğ¹) in real-world scenarios. During the sim-
ulation, these default values generate realistic outputs for ğ‘šà¯«à¯¬
à¯§ (ğœ— = ğ‘‡) and 
ğ‘šà¯«à¯¬
à¯§ (ğœ— = ğ¹) as the simulated sensor moves across the 2D map. One-dimensional 
Gaussian functions are used to model how these values decrease with increasing dis-
tance from the sensor. 
When the sensor model is utilized in a simulation, two matrices, with basic beliefs 
ğ‘šà¯«à¯¬
à¯§ (ğœ— = ğ‘‡) and ğ‘šà¯«à¯¬
à¯§ (ğœ— = ğ¹), are generated for all grid cells ğ‘à¯«à¯¬ within the sensor 
radius using two Gaussian functions. The first Gaussian function, which produces 
higher values, is multiplied by a factor to set its maximum value equal to 
10  J. Schubert, F. Kamrani, and T. Gustavi 
ğ‘šà¯«à¯¬
à¯—à¯˜à¯™à¯”à¯¨à¯Ÿà¯§(ğœ— = ğ‘‡) =0 . 7. This function generates ğ‘šà¯«à¯¬
à¯§ (ğœ— = ğ‘‡) for grid cells that contain 
target objects, while for these cells, ğ‘šà¯«à¯¬
à¯§ (ğœ— = ğ¹) is set to 0. The second Gaussian func-
tion is employed similarly to create ğ‘šà¯«à¯¬
à¯§ (ğœ— = ğ¹) for grid cells that do not contain target 
objects. This function is scaled so that its maximum value equals ğ‘šà¯«à¯¬
à¯—à¯˜à¯™à¯”à¯¨à¯Ÿà¯§(ğœ— = ğ¹) =
0.3. In these grid cells, ğ‘šà¯«à¯¬
à¯§ (ğœ— = ğ‘‡) is set to 0. In other words, in the simulation, our 
sensor does not draw a stochastic categorical observation; instead, it produces a 
deterministic soft output interpreted as the expected correctness of a positive detection 
for each cell within the radius. We encode this soft observation as a score in [0, 1] and, 
for brevity, we write it using the same ğ‘šà¯«à¯¬
à¯§ (â¦) symbols as our map-based evidence. 
Thus, when ğ‘šà¯«à¯¬
à¯§ (ğœ— = ğ‘‡) appears below in the context of the sensor, it should be read 
as a soft observation score produced by the sensor model, not as a posterior belief about 
the state. 
To enhance the sensor modelâ€™s realism, we introduce an assumed standard deviation, 
referred to as ğœà¯£à¯¢à¯¦à¯œà¯§à¯œà¯¢à¯¡, which represents the error in the sensorâ€™s position estimate for 
identified target objects. Considering the an ticipated positioning uncertainty of a sen-
sor, the values for ğ‘šà¯«à¯¬
à¯§ (ğœ— = ğ‘‡) and ğ‘šà¯«à¯¬
à¯§ (ğœ— = ğ¹) in grid cells located within a distance 
less than the sensorâ€™s radius ğ‘Ÿàµ«ğœà¯£à¯¢à¯¦à¯œà¯§à¯œà¯¢à¯¡àµ¯ are adjusted: ğ‘šà¯«à¯¬
à¯§ (ğœ— = ğ‘‡) is determined by 
the distance to the estimated target position. A Gaussian function, with an appropriate 
standard deviation, is applied for this calculation; ğ‘šà¯«à¯¬
à¯§ (ğœ— = ğ¹) is set equal to 0. 
The Gaussian sensor model is utilized in  the generative Dempster-Shafer model to 
quantify the observation basic belief ğ‘šà¯«à¯¬
à¯§ (ğœ—) and in the generative Bayesian process as 
its likelihood ğ‘à¯«à¯¬
à¯§ (ğœ‘|ğœ—). 
7 Controlling an Intelligent Agent 
7.1 The Generative Model 
This work presents the common operational picture using an evidence map, denoted as 
ğº. This evidence map is structured as a grid composed of multiple cells. Each cell cor-
responds to a specific segment of the geogra phical area being monitored, as a grid is 
overlaid on the map of that area. Thus, each cell represents a distinct portion of the 
surveillance zone. 
Each cell ğ‘à¯«à¯¬ in the evidence map is associated with two basic beliefs: ğ‘šà¯«à¯¬
à¯§ (ğœ— = ğ‘‡) 
and ğ‘šà¯«à¯¬
à¯§ (ğœ— = ğ¹). Here, ğ‘šà¯«à¯¬
à¯§ (ğœ— = ğ‘‡) indicates the basic belief that the cell at time ğ‘¡ 
contains at least one object of interest, while ğ‘šà¯«à¯¬
à¯§ (ğœ— = ğ¹) represents the basic belief 
that the cell is empty. The following conditions apply to the basic beliefs: 
ğ‘šà¯«à¯¬
à¯§ (ğœ— = ğ‘‡), ğ‘šà¯«à¯¬
à¯§ (ğœ— = ğ¹) â‰¥ 0, and ğ‘šà¯«à¯¬
à¯§ (ğœ— = ğ‘‡) + ğ‘šà¯«à¯¬
à¯§ (ğœ— = ğ¹) â‰¤ 1 for all cells ğ‘à¯«à¯¬ 
at all times ğ‘¡. The basic belief for cell ğ‘à¯«à¯¬ at time ğ‘¡ is represented by the pair 
á‰€ğ‘šà¯«à¯¬
à¯§ (ğœ— = ğ‘‡), ğ‘šà¯«à¯¬
à¯§ (ğœ— = ğ¹)á‰, with uncertainty defined as 1 âˆ’ğ‘šà¯«à¯¬
à¯§ (ğœ— = ğ‘‡) âˆ’
ğ‘šà¯«à¯¬
à¯§ (ğœ— = ğ¹). 
In Fig. 1, the green area represents ğ‘šà¯«à¯¬
à¯§ (ğœ— = ğ‘‡), the red area represents 
ğ‘šà¯«à¯¬
à¯§ (ğœ— = ğ¹), and the white area indicates the uncertainty. 
 Active Inference for an Intelligent Agent 11 
 
ğ‘šà¯«à¯¬
à¯§ (ğœ— = ğ‘‡)                                                        ğ‘šà¯«à¯¬
à¯§ (ğœ— = ğ¹) 
Fig 1. Illustration of evidence and uncertainty in cell ğ‘à¯«à¯¬. Green in

Rewrite the summary fixing the issues. Use exact title: Active Inference for an Intelligent Agent in Autonomous Reconnaissance Missions
PROFESSIONAL TONE: Begin directly with content - NO conversational openings.
NO REPETITION. Each sentence must be unique. Vary attribution phrases.
Extract quotes VERBATIM from paper text - do NOT modify or "correct" them.