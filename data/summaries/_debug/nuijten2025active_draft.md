### OverviewThis summary extracts key claims, findings, and methodological details from the paper “Active Inference is a Subtype of Variational Inference” by Wouter W. L. Nuijten and Mykola Lukashchuk. The paper argues that Active Inference, a neurobiological explanation of intelligent behavior, can be formally unified with variational inference, demonstrating that the epistemic drive within Active Inference is a unique entropic contribution. The paper introduces a novel message-passing scheme for Active Inference, enabling scalable implementation and overcoming the computational intractability of traditional methods.### MethodologyThe authors build upon recent theory recasting EFE minimization as variational inference. They formally unify Active Inference with Planning-as-Inference, showing that the epistemic drive corresponds to an entropic contribution. The core of their approach involves a message-passing scheme that can be locally minimized on a factor graph. This scheme is based on introducing region-extended Bethe coordinates and anr-channel reparameterization coordinate, which effectively transforms the degenerate conditional entropy into a local cross-entropy. The scheme allows for the computation of the expected free energy, which is the core of Active Inference. The authors also introduce a novel message-passing scheme that can be locally minimized on a factor graph. This scheme introduces region-extended Bethe coordinates and anr-channel reparameterization coordinate, which together turn a degenerate conditional entropy into a local cross-entropy and render the overall objective computationally feasible for local optimization on a factor graph.The authors state: "Active Inference proposes an alternative approach to planning under uncertainty. It provides a neurobiological explanation of intelligent behavior and posits that the optimal policy that balances exploitative and exploratory behavior emerges when minimizing a quantity known as the Expected Free Energy (EFE) [Friston et al.,2015, Parr and Friston,2019, Da Costa et al.,2020]."They further note: "However, the EFE is an objective that is defined over sequences of actions and does therefore not define a variational objective over beliefs that we can optimize."The authors also state: “We will take a closer look at the objective defined by De Vries et al. [2025] and frame it as a form of entropy corrected inference, comparing it to other formulations of planning as inference.”### ResultsThe key finding of the paper is the formal unification of Active Inference with variational inference. The authors demonstrate that the epistemic drive within Active Inference corresponds to a unique entropic contribution. The message-passing scheme they introduce enables scalable Active Inference, overcoming the computational intractability of traditional methods. The authors state: “The main contributions of this paper are twofold: We formally reframe Active Inference’s EFE minimization as a form of entropy corrected inference, explicitly demonstrating that the epistemic drive corresponds to a unique entropic contribution. We derive a message passing scheme for this unified objective, providing a method to implement scalable Active Inference.”Specifically, the authors show that the variational objective presented in De Vries et al. [2025] can be rearranged in the following way:Fp[q] =Zq(y,x, θ,u) log q(y,x, θ,u)p(y,x, θ,u)dydxdθdu+TXt=1H[qy,t]−H[q(x t, θ)] +H[q(x t−1, ut)]−H[q(x t, xt−1, ut)] +H[q(y t, xt, θ)]−H[q(xt, θ)].The authors also state: “In this section, we recover Active Inference as a form of entropy corrected inference. We will consider the following standard variational inference scheme:Fp[q] =Zq(y,x, θ,u) log q(y,x, θ,u)p(y,x, θ,u)dydxdθdu+TXt=1H[q(yt, xt, θ)]−H[q(x t, θ)].”### DiscussionThe paper highlights the importance of considering epistemic factors in planning under uncertainty. The authors argue that Active Inference provides a principled framework for incorporating these factors, leading to more robust and adaptive behavior. The message-passing scheme they introduce is a key innovation, enabling scalable Active Inference. The authors state: “To implement our scheme, we must address the nontrivial factor graph structure shown in Figure2. To our knowledge, this is the first time that a message-passing scheme has been implemented for Active Inference.”The authors also state: “The complexity of the scheme is that the state space quickly grows with the size of the system.”The authors also state: “The scheme derived in this work warrants a hierarchical state-space partitioning, which would allow us to avoid the quadratic complexity within state-space partitions.”The authors also state: “The scheme derived in this work warrants a hierarchical state-space partitioning, which would allow us to avoid the quadratic complexity within state-space partitions.”