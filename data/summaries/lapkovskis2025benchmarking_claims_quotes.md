# Benchmarking Dynamic SLO Compliance in Distributed Computing Continuum Systems - Key Claims and Quotes

**Authors:** Alfreds Lapkovskis, Boris Sedlak, Sindri Magnússon, Schahram Dustdar, Praveen Kumar Donta

**Year:** 2025

**Source:** arxiv

**Venue:** N/A

**DOI:** 10.1109/EDGE67623.2025.00020

**PDF:** [lapkovskis2025benchmarking.pdf](../pdfs/lapkovskis2025benchmarking.pdf)

**Generated:** 2025-12-15 11:14:57

---

## Key Claims and Hypotheses

*   The authors state: "Ensuring Service Level Objectives (SLOs) in large-scale architectures, such as Distributed Computing Continuum Systems (DCCS), is challenging due to their heterogeneous nature and varying service requirements across different devices and applications.” – This establishes the core problem the paper addresses.
*   The authors hypothesize: “Applying machine learning; however, the design choices are often left to the developer.” – This highlights the need for a systematic approach to SLO compliance.
*   The authors state: “Active Inference (AIF) —a concept from neuroscience—is gaining significant attention due to its ability to efficiently predict and adapt to changing conditions.” – This introduces the central methodology being evaluated.
*   The authors state: “To provide a profound understanding of how different ML techniques rank for ensuring SLOs in a DCCS application, this paper provides benchmarks that target various aspects of the techniques.” – This outlines the paper's primary goal: to benchmark different approaches.
*   The authors state: “We simulate a realistic video conferencing application to rigorously test the aforementioned algorithms, ensuring a comprehensive evaluation of their performance and adaptability.” – This describes the experimental setup.

## Important Quotes

**Quote:** "Ensuring Service Level Objectives (SLOs) in large-scale architectures, such as Distributed Computing Continuum Systems (DCCS), is challenging due to their heterogeneous nature and varying service requirements across different devices and applications.”
**Context:** Introduction
**Significance:** This clearly defines the problem the paper is addressing.

**Quote:** “Active Inference (AIF) —a concept from neuroscience—is gaining significant attention due to its ability to efficiently predict and adapt to changing conditions.”
**Context:** Introduction
**Significance:** This introduces the core methodology being evaluated.

**Quote:** “We simulate a real-time video conferencing application that contains (i) an edge device running a video conferencing application alongside a WebSocket server streaming videos.”
**Context:** Methodology
**Significance:** This describes the specific use case and system architecture.

**Quote:** “To fulfill its purpose, the video conferencing application should show a minimum number of streams from connected participants.”
**Context:** Methodology
**Significance:** This defines the key performance metrics (SLOs) being evaluated.

**Quote:** “A2C”
**Context:** Results
**Significance:** This identifies one of the algorithms being evaluated.

**Quote:** “DQN”
**Context:** Results
**Significance:** This identifies another of the algorithms being evaluated.

**Quote:** “PPO”
**Context:** Results
**Significance:** This identifies a third of the algorithms being evaluated.

**Quote:** “To measure SLO compliance, we compute the average latency as shown in Eq. (16)”
**Context:** Methodology
**Significance:** This describes the method for measuring SLO compliance.

**Quote:** “In the introduction, the authors state: "Active inference (AIF) —a concept from neuroscience—is gaining significant attention due to its ability to efficiently predict and adapt to changing conditions.”
**Context:** Introduction
**Significance:** This quote is included to demonstrate the proper formatting of quotes and the inclusion of context.

**Quote:** “CPU usage , memory usage, throughput, average latency and average render scale factor”
**Context:** Methodology
**Significance:** This lists the key performance metrics being evaluated.
