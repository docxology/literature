# PCA Loadings Summary

This document provides an interpretation of the Principal Component Analysis (PCA) 
loadings, showing which words contribute most to each principal component.

## Overview

- **Total Components Analyzed**: 5
- **Total Variance Explained**: 100.00%

## Component Analysis

### Principal Component 1 (PC1)

- **Variance Explained**: 43.60%

#### Top Contributing Words

| Rank | Word | Loading |
|------|------|---------|
| 1 | learning | 0.2976 |
| 2 | technical | -0.2971 |
| 3 | markov | -0.2971 |
| 4 | bayesian | -0.2591 |
| 5 | formulation | -0.2177 |
| 6 | blanket | -0.2177 |
| 7 | various | -0.2177 |
| 8 | markov blanket | -0.2177 |
| 9 | formulation free | -0.2177 |
| 10 | active | 0.2099 |
| 11 | active inference | 0.2099 |
| 12 | deep | 0.1767 |
| 13 | investigate | 0.1541 |
| 14 | world | 0.1523 |
| 15 | bayesian inference | -0.1443 |
| 16 | complex | 0.1298 |
| 17 | seen | 0.1298 |
| 18 | works | -0.1257 |
| 19 | newer | -0.1257 |
| 20 | machine learning | 0.1209 |

#### Interpretation

**Positive contributors** (high loading): learning, active, active inference, deep, investigate
**Negative contributors** (low loading): technical, markov, bayesian, formulation, blanket

---

### Principal Component 2 (PC2)

- **Variance Explained**: 30.64%

#### Top Contributing Words

| Rank | Word | Loading |
|------|------|---------|
| 1 | learning | 0.3052 |
| 2 | seen | -0.2925 |
| 3 | complex | -0.2925 |
| 4 | learn | -0.2895 |
| 5 | world | -0.2502 |
| 6 | inference | 0.2329 |
| 7 | active inference | 0.2327 |
| 8 | active | 0.2327 |
| 9 | deep | 0.1934 |
| 10 | variational | 0.1727 |
| 11 | use | -0.1691 |
| 12 | systems | -0.1613 |
| 13 | investigate | 0.1511 |
| 14 | theory | 0.1478 |
| 15 | assumptions | -0.1344 |
| 16 | local | -0.1281 |
| 17 | quantity | -0.1281 |
| 18 | detailed | -0.1281 |
| 19 | finally | -0.1281 |
| 20 | account | -0.1281 |

#### Interpretation

**Positive contributors** (high loading): learning, inference, active inference, active, deep
**Negative contributors** (low loading): seen, complex, learn, world, use

---

### Principal Component 3 (PC3)

- **Variance Explained**: 14.38%

#### Top Contributing Words

| Rank | Word | Loading |
|------|------|---------|
| 1 | variational | 0.4193 |
| 2 | theory | 0.2939 |
| 3 | states | -0.2843 |
| 4 | works | 0.2417 |
| 5 | newer | 0.2417 |
| 6 | general | 0.2389 |
| 7 | additionally | 0.2389 |
| 8 | use | -0.2203 |
| 9 | active | -0.2149 |
| 10 | active inference | -0.2149 |
| 11 | inference | -0.1817 |
| 12 | bayesian | -0.1731 |
| 13 | assumptions | 0.1546 |
| 14 | deep | -0.1544 |
| 15 | machine learning | 0.1151 |
| 16 | machine | 0.1151 |
| 17 | world | -0.1142 |
| 18 | complex | 0.0947 |
| 19 | seen | 0.0947 |
| 20 | finally | 0.0912 |

#### Interpretation

**Positive contributors** (high loading): variational, theory, works, newer, general
**Negative contributors** (low loading): states, use, active, active inference, inference

---

### Principal Component 4 (PC4)

- **Variance Explained**: 11.37%

#### Top Contributing Words

| Rank | Word | Loading |
|------|------|---------|
| 1 | works | 0.3519 |
| 2 | newer | 0.3519 |
| 3 | bayesian | -0.3209 |
| 4 | machine | -0.2175 |
| 5 | machine learning | -0.2175 |
| 6 | world | 0.2161 |
| 7 | point | 0.2089 |
| 8 | active | 0.1881 |
| 9 | active inference | 0.1881 |
| 10 | assumptions | 0.1851 |
| 11 | theory | -0.1796 |
| 12 | systems | -0.1748 |
| 13 | bayesian inference | -0.1600 |
| 14 | use | -0.1518 |
| 15 | investigate | -0.1516 |
| 16 | learn | 0.1501 |
| 17 | states | -0.1279 |
| 18 | deep | 0.1221 |
| 19 | like | 0.1081 |
| 20 | model | 0.1081 |

#### Interpretation

**Positive contributors** (high loading): works, newer, world, point, active
**Negative contributors** (low loading): bayesian, machine, machine learning, theory, systems

---

### Principal Component 5 (PC5)

- **Variance Explained**: 0.00%

#### Top Contributing Words

| Rank | Word | Loading |
|------|------|---------|
| 1 | account | 0.6225 |
| 2 | action | -0.3958 |
| 3 | technical | 0.1856 |
| 4 | markov | 0.1856 |
| 5 | inference | 0.1811 |
| 6 | newer | -0.1536 |
| 7 | works | -0.1536 |
| 8 | use | 0.1523 |
| 9 | bayesian | -0.1477 |
| 10 | investigate | -0.1436 |
| 11 | world | -0.1241 |
| 12 | theory | 0.1209 |
| 13 | complex | -0.1165 |
| 14 | seen | -0.1165 |
| 15 | blanket | -0.1129 |
| 16 | various | -0.1129 |
| 17 | formulation | -0.1129 |
| 18 | formulation free | -0.1129 |
| 19 | markov blanket | -0.1129 |
| 20 | systems | -0.1090 |

#### Interpretation

**Positive contributors** (high loading): account, technical, markov, inference, use
**Negative contributors** (low loading): action, newer, works, bayesian, investigate

---

## Summary

The loadings indicate which words (features) are most strongly associated with each 
principal component. Positive loadings indicate words that increase with the component, 
while negative loadings indicate words that decrease.

### Key Insights

- Components with higher explained variance capture more of the overall variation in the corpus.
- Words with large absolute loadings are the most important for that component.
- Components can be interpreted as themes or topics in the literature.
